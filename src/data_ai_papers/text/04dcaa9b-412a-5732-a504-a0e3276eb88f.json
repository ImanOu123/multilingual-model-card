{"title": "NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages", "authors": "Genta Indra Winata; Alham Fikri; Samuel Cahyawijaya; Rahmad Mahendra; Fajri Koto; Ade Romadhony; Kemal Kurniawan; David Moeljadi; Radityo Eko Prasojo; Pascale Fung; Timothy Baldwin; Jey Han Lau; Rico Sennrich; Sebastian Ruder;  Mbzuai; Universitas Indonesia", "pub_date": "", "abstract": "Natural language processing (NLP) has significant impact on society via technologies such as machine translation and search engines. Despite its success, NLP technology is only widely available for high-resource languages such as English and Mandarin Chinese, and remains inaccessible to many languages due to the unavailability of data resources and benchmarks. In this work, we focus on developing resources for languages of Indonesia. Despite being the second most linguistically-diverse country, most languages in Indonesia are categorized as endangered and some are even extinct. We develop the first-ever parallel resource for 10 low-resource languages in Indonesia. Our resource includes sentiment and machine translation datasets, and bilingual lexicons. We provide extensive analysis, and describe challenges for creating such resources. Our hope is that this work will spark more NLP research on Indonesian and other underrepresented languages.", "sections": [{"heading": "Introduction", "text": "Indonesia is one of the most populous and linguistically-diverse countries in the world, with more than 700 languages spoken across the country (Aji et al., 2022;Eberhard et al., 2021). However, while many of these languages are spoken by millions of people they have received little attention from the NLP community. There are very few public datasets, preventing the global research community from exploring these languages. To this end, we introduce NusaX, 1 a high-quality multilingual parallel corpus that covers 10 local languages from Indonesia: Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\nThe NusaX dataset was created by translating SmSA (Purwarianti and Crisdayanti, 2019) -an existing Indonesian sentiment analysis dataset containing comments and reviews from the IndoNLU benchmark (Wilie et al., 2020) -using competent bilingual speakers, coupled with additional human-assisted quality assurance. Sentiment analysis is one of the most popular NLP tasks, and has been explored in many applications in Indonesia, including presidential elections (Ibrahim et al., 2015;Budiharto and Meiliana, 2018), product reviews (Fauzi, 2019), stock forecasting (Cakra and Trisedya, 2015;Sagala et al., 2020), and COVID-19 monitoring (Nurdeni et al., 2021). By translating an existing text, we additionally produce a parallel corpus, which is useful for building and evaluating translation systems. As we translate from a regional high-resource language (Indonesian), we ensure that the topics and entities reflected in the data are culturally relevant to the other languages, which is generally not the case when translating an English dataset (Conneau et al., 2018;Ponti et al., 2020). We apply the corpus to two downstream tasks: sentiment analysis and machine translation. We use the new benchmark to assess the performance of existing Indonesian language models (LMs), multilingual LMs, and classical machine learning methods.\nOur contributions are as follows:\n\u2022 We propose NusaX, the first high-quality human annotated parallel corpus in 10 languages from Indonesia, and corresponding parallel data in Indonesian and English, covering the tasks of sentiment analysis and machine translation. \u2022 We provide an extensive evaluation of deep learning and classical NLP/machine learning methods on downstream tasks in few-shot and full-data settings. \u2022 We conduct comprehensive analysis of the languages under study both from linguistic Figure 1: Language taxonomy of the 10 focus languages and Indonesian, according to Ethnologue (Eberhard et al., 2021). The color represents the language category level in the taxonomy. Purple denotes language, and other colors denote language family. and empirical perspectives, the cross-lingual transferability of existing monolingual and multilingual LMs, and an efficiency analysis of various methods for NLP tasks in extremely low-resource languages.", "publication_ref": ["b3", "b17", "b70", "b26", "b9", "b20", "b11", "b56", "b44", "b13", "b47", "b17"], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "Focus Languages", "text": "We work on 10 local languages in Indonesia: Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak. Most of these languages have a population of over 2 million speakers (van Esch et al., 2022;Aji et al., 2022), but are underrepresented in NLP research. Figure 1 shows the taxonomy of these languages and Indonesian. Geographically, these languages are spoken on different big islands in Indonesia, including Sumatra, Borneo, Java, Madura, and Sulawesi. The languages belong to the Austronesian language family under the Malayo-Polynesian subgroup. While some of the covered languages are written in multiple scripts, we use the Latin script in NusaX, which has become predominant for all covered languages. Indonesian (ind) is the national language of Indonesia based on the 1945 Constitution of the Republic of Indonesia (article 36). It is written in Latin script, and was developed from literary \"Classical Malay\" of the Riau-Johor sultanate (Sneddon, 2003), with regional variants. Its lexical similar-ity to Standard Malay is over 80%. It has a rich affixation system, including a variety of prefixes, suffixes, circumfixes, and reduplication. Most of the affixes in Indonesian are derivational (Pisceldo et al., 2008).\nAcehnese (ace) is a language spoken mainly in the Aceh province. Although it is the de facto language of Aceh, language use is shifting to Indonesian in urban areas. Acehnese has features typical of the Mon-Khmer languages of mainland Southeast Asia, a result of its former status as part of the early Chamic dialect continuum on the coast of Vietnam. In addition to the large number of diphthongs, it has a high percentage of monosyllabic root morphemes.\nBalinese (ban) is a language spoken mainly in the Bali province. It has three main dialects: Highland Balinese, Lowland Balinese, and Nusa Penida. Since the early 20th century, it has mainly been written in the Latin script, but also has its own Balinese script. The word order in Balinese is SVO. Balinese has three sociolinguistic registers (Arka, 2003).\nBanjarese (bjn) is a language spoken in Kalimantan (Central, East, South, and West Kalimantan provinces). It is dominant in the South Kalimantan Province and is also growing rapidly in the Central and Eastern Kalimantan provinces. It has two main dialects: Kuala and Hulu. Although it is a Malayic language, it has many Javanese loanwords, probably acquired during the Majapahit period from the late thirteenth century until the fifteenth century (Blust et al., 2013). It has 73% of lexical similarity with Indonesian and is written in Arabic and Latin scripts (Eberhard et al., 2021).\nBuginese (bug) is a language spoken mainly in the South Sulawesi, Southeast Sulawesi, Central Sulawesi, and West Sulawesi provinces. The word order is SVO. Verb affixes are used to mark persons. Historically, it was written in the Buginese script (derived from Brahmi script), but is mainly written in Latin script now (Eberhard et al., 2021). Buginese employs sentence patterns, pronouns, and other terms to express politeness (Weda, 2016).\nMadurese (mad) is a language spoken in the East Java province, mainly on Madura Island, south and west of Surabaya city, Bawean, Kangean, and Sapudi islands. It has vowel harmony, gemination, rich affixation, reduplication, and SVO basic word order (Davies, 2010).\nMinangkabau (min) is a language spoken mainly in West Sumatra and other provinces on Sumatra Island such as Bengkulu and Riau. Although it is classified as Malay, it is not intelligible with Indonesian. Standard Minangkabau voice can be characterised as an Indonesian-type system, whereas colloquial Minangkabau voice is more effectively characterised as a Sundic-type system (Crouch, 2009). Javanese (jav) is a language spoken mainly on Java Island. It is the de facto language of provincial identity in central and eastern Java. The number of native Javanese speakers is greater than the number of Indonesian L1 speakers (Eberhard et al., 2021). Javanese consists of several regional dialects, which differ primarily in pronunciation and vocabulary. Javanese has an elaborate system of speech levels related to the relation of the speaker to the interlocutor that depend on social status, age, kinship distance, and familiarity (Wedhawati et al., 2001). It used to be written in Javanese script, but since the 20th century has mostly been written in Latin script.\nNgaju (nij) is a language spoken in the Central Kalimantan province. It is widely used as a language for trade in much of Kalimantan, from the Barito to the Sampit River. It has various affixes and reduplication, and its word order is similar to Indonesian. Pronouns have enclitic forms to mark possessors in a noun phrase or passive agents (Uchibori and Shibata, 1988).\nSundanese (sun) is a language spoken mainly in the Banten and West Java provinces. It is the de facto language of provincial identity in western Java. The main dialects are Bogor (Krawang), Pringan, and Cirebon. It has elaborate coding of respect levels. It has been written in Latin script since the mid-19th century but was previously written in Arabic, Javanese, and Sundanese scripts. Sundanese is a predominantly SVO language, and has voice marking and incorporates some (optional) actor-verb agreement, i.e., number and person (Kurniawan, 2013).\nToba Batak (bbc) is a language spoken in the North Sumatra province. Similarly to Acehnese, it is slowly being replaced by Indonesian in urban and migrant areas. It used to be written in the Batak script but is mainly written in Latin script now. The Batak languages are verb-initial, and have verb systems reminiscent of Philippine languages, although they differ from them in many details (Blust et al., 2013).", "publication_ref": ["b64", "b3", "b59", "b46", "b4", "b8", "b17", "b17", "b66", "b15", "b14", "b17", "b67", "b63", "b33", "b8"], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "Data Construction", "text": "Our data collection process consists of several steps. First, we take an existing dataset in a high-resource local language (Indonesian) as a base for expansion to the other ten languages, and ask human annotators to translate the text. To ensure the quality of the final translation, we run quality assurance with additional human annotators.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Annotator Recruitment", "text": "Eliciting or annotating data in underrepresented languages generally requires working with local language communities in order to identify competent bilingual speakers (Nekoto et al., 2020). In the Indonesian setting, this challenge is compounded by the fact that most languages have several dialects. As dialects in Indonesian languages may have significant differences in word usage and meaning (Aji et al., 2022), it is important to recruit annotators who speak the same or similar dialects to ensure that translations are mutually intelligible.\nIn this work, we employ at least 2 expert annotators who are native speakers of each local language and Indonesian. To filter the recruited annotators, we first ask annotator candidates to translate three samples. We then conduct a peer review by asking whether they can understand the translations of other annotators for the same language, using the hired annotators as translators as well as translation validators. We also conducted 2 hours of training to introduce the user interface of the annotation system for selected workers. For English translations, we hire annotators based on their English proficiency test scores with an IELTS score \u2265 6.5 or TOEFL PBT score \u2265 600.", "publication_ref": ["b3"], "figure_ref": [], "table_ref": []}, {"heading": "Data Filtering and Sampling", "text": "We base our dataset on SmSA, the largest publicly available Indonesian sentiment analysis dataset from the IndoNLU benchmark (Purwarianti and Crisdayanti, 2019;Wilie et al., 2020). SmSA is an expert-annotated sentence-level multi-domain sentiment analysis dataset consisting of more than 11,000 instances of comments and reviews collected from several online platforms such as Twitter, Zomato, and TripAdvisor. We filter the data to remove abusive language and personallyidentifying information by manually inspecting all sentences. We randomly select 1,000 samples via stratified sampling for translation, ensuring that the label distribution is balanced.", "publication_ref": ["b70"], "figure_ref": [], "table_ref": []}, {"heading": "Human Translation", "text": "We instructed the annotators to retain the meaning of the text and to keep entities such as persons, organizations, locations, and time with no target language translation the same. Specifically, we instructed them to: (1) maintain the sentence's sentiment polarity; (2) preserve entities; and (3) maintain the complete information content of the original text.\nInitially, we asked the translators to maintain the typography. Most sentences from the original dataset are written in an informal tone, with non-standard spelling, e.g., elongated vowels and punctuation. When the sentence is translated into the target language, direct translation can sound unnatural. For example, translating the Indonesian word kangeeeen (originally kangen; en: miss) to taragaaaak (originally taragak) in Minangkabau may sound unnatural. Similarly, the original sentence may also contain typos. Due to the difficulty of accurately assessing typographical consistency of translations, we removed this as a criterion.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Human-Assisted Quality Assurance", "text": "We conduct quality control (QC) between two annotators by having annotator A check the translations of annotator B, and vice versa. We include the corrected translations in our dataset. To ensure the quality assurance is performed well, we randomly perturb 5% of the sentences by removing a random sequence of words. The quality assurance annotators are then expected to notice the perturbed sentences and fix them.\nWe analyze the quality assurance edits for Balinese, Sundanese, and Javanese, which are spoken by the authors of this paper. For each language, we randomly sample 100 translations that have been edited by a QC annotator. We classify edits as follows: Typos and Mechanics: Edit that involves correcting typos, punctuation, casing, white spaces/dashes, and numerical formatting. Orthography: Edit that changes the spelling of words due to orthographic variation in local languages without a standard orthography. The word sounds and means the same before and after editing, and both are used by natives. The QC annotator might feel that one writing variant is more natural/commonly used, and hence make this change. Translation: The words used by the translator are still in Indonesian and the QC annotator translates them to the local language.\nWord edit: The QC annotator paraphrases a word/phrase. This also includes adding/removing words and morpheme changes.\nMajor changes: Other edits that significantly alter the original translation.\nThe results are shown in Table 1. Generally, word edits make up the majority of QC modifications, which involve replacing a word/phrase with a synonym or altering a morpheme slightly. In contrast, major changes are extremely rare. We also see changes to the orthography around 10% of the time. Other types of edits vary between languages. Sundanese has significantly less typos compared to other languages, but a considerably higher number of translation edits. We suspect this is because code-switching with Indonesian happens regularly in Sundanese, which results in many Indonesian words being adopted despite the existence of equivalent Sundanese translations. ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Bilingual Lexicon Creation", "text": "Bilingual lexicons are useful for data augmentation (Wang et al., 2022) and evaluating cross-lingual representations (Artetxe et al., 2018). We select 400 words from an Indonesian lexicon 2 to be translated into the 10 local languages and English. For each language, we employ two annotators and ask them to translate the word into all possible lexemes. The translations from both annotators are combined. We obtain 800-1,600 word pairs for each of our 11 language pairs (from Indonesian to the remaining languages). We augment the bilingual lexicon with data from PanLex (Kamholz et al., 2014).\n4 NusaX Benchmark", "publication_ref": ["b65", "b5", "b28"], "figure_ref": [], "table_ref": []}, {"heading": "Tasks", "text": "We develop two tasks -sentiment analysis and machine translation -based on the datasets covering 12 languages, including Indonesian, English, and the 10 local languages. For the NusaX sentiment dataset, each language has the same label distribution and we show the label distribution of each dataset subset in Table 2. We maintain the label ratio in each dataset subset to ensure a similar distribution. More details of the dataset are provided in Appendix C.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_2"]}, {"heading": "Sentiment Analysis", "text": "Sentiment analysis is an NLP task that aims to identify the sentiment of a given text document.\nThe sentiment is commonly categorized into 3 classes: positive, negative, and neutral. We focus our dataset construction on sentiment analysis because it is one of the most widely explored tasks in Indonesia (Aji et al., 2022) due to broad industrial relevance, such as for competitor and marketing analysis, and detection of unfavorable rumors for risk management (Socher et al., 2013). After translating 1,000 instances from the sentiment analysis dataset (SmSA), we have a sentiment analysis dataset for each translated language. For each language, we split the dataset into 500 train, 100 validation, and 400 test examples. In total, our dataset contains 6,000 train, 1,200 validation, and 4,800 test instances across 12 languages (Indonesian, English and the 10 local languages).", "publication_ref": ["b3", "b60"], "figure_ref": [], "table_ref": []}, {"heading": "Machine Translation", "text": "Indonesia consists of 700+ languages covering three different language families (Aji et al., 2022). Despite its linguistic diversity, existing machine translation systems only cover a small fraction of Indonesian languages, mainly Indonesian (the national language), Sundanese, and Javanese. To broaden the coverage of existing machine translation systems for underrepresented local languages, we construct a machine translation dataset using our translated sentiment corpus, which results in a parallel corpus between all language pairs. In other words, we have 132 possible parallel corpora, each with 1,000 samples (500 train, 100 validation, and 400 test instances) which can be used to train machine translation models. Compared to many other MT evaluation datasets, our data is in the review domain and is not English-centric.  ", "publication_ref": ["b3"], "figure_ref": [], "table_ref": []}, {"heading": "Baselines", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Classical Machine Learning", "text": "Classical machine learning approaches are still widely used by local Indonesian researchers and institutions due to their efficiency (Nityasya et al., 2021). The trade-off between performance and compute cost is particularly important in situations with limited compute, which are common for lowresource languages. We therefore use classical methods as baselines for our comparison. Namely, we use naive Bayes, SVM, and logistic regression for the classification tasks. For MT, we employ a naive baseline that copies the original Indonesian text, a dictionary-based substitution method using the bilingual lexicon, and a phrase-based MT system based on Moses (Koehn et al., 2007).", "publication_ref": ["b68", "b30"], "figure_ref": [], "table_ref": []}, {"heading": "Pre-trained Local Language Models", "text": "Recent developments in neural pre-trained LMs have brought substantial improvements in various NLP tasks. Despite the lack of resources in Indonesian and local languages, there have been some efforts in developing large pre-trained LMs for Indonesian and major local languages.\nIndoBERT (Wilie et al., 2020) and Sundanese-BERT (Wongso et al., 2022) are two popular LMs for natural language understanding (NLU) tasks in Indonesian and Sundanese. IndoBART and In-doGPT have also been introduced for natural language generation (NLG) tasks in Indonesian, Sundanese, and Javanese (Cahyawijaya et al., 2021). We employ these LMs as baselines to assess their adaptability to other languages.", "publication_ref": ["b70", "b73", "b10"], "figure_ref": [], "table_ref": []}, {"heading": "Massively Multilingual LMs", "text": "We consider large pre-trained multilingual LMs to further understand their applicability to lowresource languages. Specifically, we experiment with mBERT (Devlin et al., 2019) and XLM-R (Conneau et al., 2020) for sentiment analysis, and mBART  and mT5 (Xue et al., 2021) for machine translation. We provide the hyper-parameters of all models in Appendix B.  5 Results", "publication_ref": ["b16", "b12"], "figure_ref": [], "table_ref": []}, {"heading": "Overall Results", "text": "Sentiment Analysis Table 3 shows the sentiment analysis performance of various models across different local languages, trained and evaluated using data in the same language. Fine-tuned large LMs such as IndoBERT LARGE and XLM-R LARGE generally achieve the best performance. XLM-R models achieve strong performance on some languages, such as Indonesian (idn), Banjarese (bjn), English (eng), Javanese (jav), and Minangkabau (min). Many of these languages are included in XLM-R's pre-training data while others may benefit from positive transfer from related languages.\nFor instance, Banjarese is similar to Malay and Indonesian (Nasution et al., 2021), while Minangkabau shares some words and syntax with Indonesian . IndoBERT models, despite only being pre-trained on Indonesian, also show good performance across some local languages, suggesting transferability from Indonesian to the local languages.\nThe classic approaches are surprisingly competitive with the neural methods, with logistic regression even outperforming IndoBERT LARGE and XLM-R on Acehnese (ace), Buginese (bug), and Toba Batak (bbc). These results indicate that both Indonesian and multilingual pre-trained LMs cannot transfer well to these languages, which is supported by the fact that these languages are very distinct from Indonesian, Sundanese, Javanese, or Minangkabau -the languages covered by IndoBERT and XLM-R.", "publication_ref": ["b40"], "figure_ref": [], "table_ref": ["tab_4"]}, {"heading": "Machine Translation", "text": "We show the results on machine translation in Table 4 (x \u2192 idn) based on SacreBLEU (Post, 2018). As some local lan-guages are similar to Indonesian, we observe that the Copy baseline (which does not do any translation) performs quite well. Minangkabau (min) and Banjarese (bjn) achieve high BLEU without any translation despite not being included in the LM pre-training data, due to their similarity with Indonesian Nasution et al., 2021). Since these local languages share grammatical structure with Indonesian, dictionary-based word substitution yields a reasonable improvement.\nBoth PBSMT and fine-tuned LMs reach encouraging performance levels despite the limited training data, which we again attribute to the target languages' similarity to Indonesian. In contrast, the performance for translating Indonesian languages from/to English is extremely poor as shown in Table 5, demonstrating the importance of non-English-centric translation. Overall, we observe good translation performance across local languages. Thus, there is an opportunity to utilize translation models to create new synthetic datasets in local languages via translation from a related high-resource language, not only for Indonesian local languages but also other underrepresented languages. However, note that even for language pairs where the SacreBLEU score is very high, we observe translation deficiencies stemming from the small amount of training data: rare words may just be copied with PBSMT, and mistranslated with NMT.\nSimilar effects are also observed for (idn \u2192 x) translation, as shown in Table 6. Similar to (x \u2192 idn) translations, we observe that the Copy baseline performs quite well on Minangkabau (min) and Banjarese (bjn) due to their similarity with Indonesian Nasution et al., 2021). Dictionary-based word substitution also yields a reasonable improvement especially for Ja-  vanese (jav), Minangkabau (min), and Sundanese (sun) due to the high similarity of the grammatical structure with Indonesian. PBSMT and finetuned IndoBARTv2 models achieve the best scores over multiple local languages despite the limited training data, which is also attributed to the target languages' similarity to Indonesian.", "publication_ref": ["b48", "b40", "b40"], "figure_ref": [], "table_ref": ["tab_6"]}, {"heading": "Cross-lingual Capability of LMs", "text": "From a linguistic perspective, local languages in Indonesia share similarities according to language family. Many local languages share a similar grammatical structure and have some vocabulary overlap. Following prior work that demonstrates positive transfer between closely-related languages (Cahyawijaya et al., 2021;Hu et al., 2020;Khanuja et al., 2020;, we analyze the transferability between closely-related languages in the Malayo-Polynesian language family. Empirically, we show the cross-lingual capability of the best performing model (XLM-R LARGE ) in the zero-shot cross-lingual setting for sentiment analysis. The heatmap is shown in Figure 2. In general, most languages, except for Buginese (bug) and Toba Batak (bbc), can be used effectively as the source language, reaching \u223c70-75% F1 on average, compared to an average of 80% F1 in the monolingual setting (cf. XLM-R LARGE in Table 3). This empirical result aligns with the fact that both Buginese (bug) and Toba Batak (bbc) have very low vocabulary overlap with Indonesian (cf. Copy in Tables 4 and 6). Interestingly, despite coming from a completely different language family, English can also be effectively used as the source language for all 10 local languages, likely due to its prevalence during pre-training.\nThese results demonstrate that we can take advantage of language similarity by transferring knowledge from Indonesian and other local languages to perform zero-shot or few-shot classification in closely-related languages. New datasets for underrepresented languages that are closely related to high-resource languages thus do not necessarily need to be large, which make the development of NLP datasets in low-resource languages more affordable than may initially appear to be the case.", "publication_ref": ["b10", "b25", "b29"], "figure_ref": ["fig_0"], "table_ref": ["tab_4"]}, {"heading": "Multilingual Capability", "text": "We explore training multilingual models, as most Indonesian local languages share similarities. For sentiment analysis, we concatenate the training  ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Data Collection Challenges", "text": "In this section, we discuss challenges faced during data collection.\nFinding annotators We found collecting the NusaX dataset challenging. First of all, finding local language-speaking annotators is not easy, and popular platforms such as MTurk do not support these languages. Instead, we looked for annota-tors through local Indonesian networks and forums, such as the INACL forum, local campus forums, or the Indonesian polyglot community. We intended to cover as many local languages as possible, but based on the available annotators, only the 10 languages presented in this paper were possible, as we needed at least 2 annotators for each language.\nSearching for annotators online is not easy, due to disparities in Internet penetration in different parts of Indonesia. Hence, we might not reach potential annotators through online communities alone. However, holding an in-person workshop for data collection is also not practical; Indonesia is an archipelago and traveling between islands is costly. Similar challenges occur in many other regions, including Africa and South America.\nCommunication with annotators Communication between the authors and annotators was done through WhatsApp, as the most popular communication tool in Indonesian (Mulyono et al., 2021). Annotation was conducted through spreadsheets. We found that some of the annotators use mobile apps instead of a desktop for annotation. Their reasons include ease of use, no access to a laptop, and better keyboard support for typing diacritics. In the most extreme case, one annotator printed out the sheet and performed the annotation on paper, then took a picture of the paper and sent it back to us. We found some annotators to be difficult to contact, due to other commitments such as college or work. Some of them were not responsive and had to be replaced by new annotators.", "publication_ref": ["b39"], "figure_ref": [], "table_ref": []}, {"heading": "Related Work", "text": "Multilingual Parallel Corpora Several multilingual parallel corpora have been developed to support studies on machine translation such as GCP (Imamura andSumita, 2018), Leipzig (Gold-hahn et al., 2012), JRC Acquis (Steinberger et al., 2006), TUFS Asian Language Parallel (Nomoto et al., 2018), Intercorp (ek\u010cerm\u00e1k andRosen, 2012), DARPA LORELEI (Strassel and Tracey, 2016), Asian Language Treebank (Riza et al., 2016), FLORES (Guzm\u00e1n et al., 2019), the Bible Parallel Corpus (Resnik et al., 1999;Black, 2019), JW-300 (Agi\u0107 and Vuli\u0107, 2019), BiToD (Lin et al., 2021), and WikiMatrix (Schwenk et al., 2021). Guzm\u00e1n et al. (2019) describe the procedure to generate high-quality translations as part of FLO-RES. Similar to FLORES, we also conducted QC of the translations.\nEmerging Language Benchmarks Recently, benchmarks in underrepresented languages have emerged, such as MasakhaNER (Adelani et al., 2021), AmericasNLI (Ebrahimi et al., 2022), PMIndia (Haddow and Kirefu, 2020), Samanantar (Ramesh et al., 2022), andNaijaSenti (Muhammad et al., 2022). Particularly, for Indonesian languages, NLP benchmarks have been developed such as IndoNLU (Wilie et al., 2020), IndoLEM , IndoNLG (Cahyawijaya et al., 2021), IndoNLI (Mahendra et al., 2021), and English-Indonesian machine translation (Guntara et al., 2020).", "publication_ref": ["b27", "b61", "b19", "b62", "b55", "b23", "b54", "b7", "b1", "b72", "b58", "b23", "b18", "b24", "b70", "b10", "b37", "b22"], "figure_ref": [], "table_ref": []}, {"heading": "Datasets for Indonesian Local Languages", "text": "Only a limited number of labeled datasets exist for local languages in Indonesia. WikiAnn (Pan et al., 2017) -a weakly-supervised named entity recognition dataset -covers Acehnese, Javanese, Minangkabau, and Sundanese. Putri et al. ( 2021) built a multilingual dataset for abusive language and hate speech detection involving Javanese, Sundanese, Madurese, Minangkabau, and Musi languages. Sakti and Nakamura (2013) constructed speech corpora for Javanese, Sundanese, Balinese, and Toba Batak. Few datasets exist for individual languages, e.g., sentiment analysis and machine translation in Minangkabau  and emotion classification in Sundanese (Putra et al., 2020). Finally, some datasets focus on colloquial Indonesian mixed with local languages in the scope of morphological analysis (Wibowo et al., 2021) and style transfer (Wibowo et al., 2020).", "publication_ref": ["b45", "b57", "b50", "b68", "b69"], "figure_ref": [], "table_ref": []}, {"heading": "Conclusion", "text": "In this paper, we propose NusaX, the first parallel corpus for 10 low-resource Indonesian languages. We create a new benchmark for sentiment analysis and machine translation in zero-shot and full-data settings. We present a comprehensive analysis of the language similarity of these languages from both linguistic and empirical perspectives by assessing the cross-lingual transferability of existing Indonesian and multilingual pre-trained models. We hope NusaX can enable NLP research for under-represented languages, and can be used as a testbed for adaptation or few-shot learning methods that take advantage of similarities between languages. NusaX opens up the possibility for future research that focuses on covering more local languages, and additionally, further extension to other tasks and domains. Our study on cross-lingual transfer enables further exploration on cross-lingual zero-shot learning for more diverse tasks in local languages. Our guidelines and discussion of data collection issues may also motivate future work on more efficient high-quality data collection for extremely low-resource languages. ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A Data Statement for NusaX", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A.2 Executive Summary", "text": "NusaX is a multilingual parallel corpus across 10 local languages in Indonesia: Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak. The data was translated obtained by human translation from Indonesian and human-assisted quality assurance.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A.3 Curation Rationale", "text": "The goal of the dataset creation process is to provide gold-standard sentiment analysis corpora for Indonesian local languages. The Indonesian data is sampled from SmSA (Purwarianti and Crisdayanti, 2019), an Indonesian sentiment analysis corpus. SmSA is chosen among other corpora (e.g., HoASA (Azhar et al., 2019) based on (1) the agreement of our manual re-annotation of a small and randomly selected samples and (2) manual inspection to ensure that the topics are diverse. After sampling, the data is edited and/or filtered to remove harmful contents and maintain quality. Several criteria are used in this process:\n1. Is the sentiment label correct? 2. Does the sentence contain multiple sentiments? 3. Does the sentence contain harmful content that discriminates against race, religion, or other protected groups? 4. Does the sentence contain an attack toward an individual or is abusive? 5. Is the sentence politically charged? 6. Is the sentence overly Bandung/Sundacentric? 3 7. Will the sentence be difficult to translate into local languages? 8. Are there any misspellings?", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A.4 Documentation for Source Datasets", "text": "NusaX is obtained by translating SmSA (Purwarianti and Crisdayanti, 2019), an Indonesian sentiment analysis dataset.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A.5 Language Variety", "text": "NusaX covers a total of 10 local languages spoken in Indonesia (ID) as shown in Table 8.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_10"]}, {"heading": "A.6 Speaker Demographic", "text": "The SmSA dataset was obtained from social media and online forums: Twitter, Zomato, TripAdvisor, Facebook, Instagram, Qraved. We can assume the users' age ranges from 25 to 34 years, which is the age range of the majority of Indonesian social media users 4 .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A.7 Annotator Demographic", "text": "A total of 28 translators are employed in the translation process. All translators are Indonesian and recruited by via either online surveys or personal contacts. They are then selected based on (1) the selfreported fluency in the local language into which they would be translating and (2) the highest education level achieved. Those who (a) are native speakers of or fluent in the target local language and (b) finished at least high school education (id: SMA/sederajat) are selected.\nAcehnese There are 3 translators for Acehnese, but only 2 of them responded when asked for demographic information. Thus, what follows is the demographic information of only those 2 translators. One has some experience in translation work, while the other does not. One identifies as male, and the other as female. Both are in their 20s. Lastly, one works as a freelancer, while the other is a farmer.  Banjarese Two translators are employed for Banjarese, but only one responded when asked for demographic information. The translator has prior experience in translation work, identifies as male, is in his 40s, and works as a university lecturer.\nBuginese Buginese is translated by 2 people, but only one responded when asked for demographic information. The person has prior translation experience, identifies as male, is aged 30-39 years old, and runs an Islamic boarding school as a living.\nJavanese Four translators are employed for Javanese, but one did not respond when asked for demographic information. The other three have prior experience in translation work. Among them, two identify as female, and one as male. All of them are in their 20s. Two of them are university students, and the other one works as a freelance assistant editor. Ngaju Two translators work on Ngaju, but only one responded when asked for demographic information. The translator has prior experience, identifies as female, is aged no less than 50 years old, and is a stay-at-home mother.\nSundanese There are 5 translators for Sundanese, four of which identify as female, and the other one as male. Three translators are in their 20s, one is younger than 20 years old, and the remaining one is in their 30s. The translators work as a school teacher, a university student, a university lecturer, and the remaining two as employees in a private company.\nToba Batak Three translators are employed for Toba Batak. One has prior translation experience. Two translators identify as male while the other as female. All three are in their 20s. One works for a private company, and the others are university students.  For statistical models, we use a spaCy as our toolkit, and we perform grid-search over the parameter ranges shown in  best performing model over the devset. For all pretrained LMs, we perform grid-search over batch size and learning rate while keeping the other hyperparameters fixed. The list of hyperparameters is shown in Table 10.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_15"]}, {"heading": "B Hyperparameters", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B.2 Machine Translation", "text": "Table 11 shows the hyperparameters of deep learning models on machine translation.  ", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_17"]}, {"heading": "C Dataset Statistics", "text": "In this section, we present more detail statistics of our NusaX datasets. To evaluate the difference between each language in the NusaX dataset, we analyze the vocabulary characteristic for each language. We collect the vocabulary for each language by removing all the punctuation in the sentence and tokenize the sentence with the spaCy tokenizer. 5 We show the vocabulary size and the top-10 words for each language on Table 12, and the vocabulary histogram for each language in Figure 4. We can see that the most common words between Indonesian and other local languages vary a lot, despite having a similar vocabulary size and histogram pat-5 https://github.com/explosion/spaCy tern. This shows the intuitive difference between Indonesian and local languages in Indonesia. We further measure the vocabulary overlap over different language pairs. We measure the vocabulary overlap for each pair of languages by measuring the intersection over union (IoU) of the two vocabularies. We show the vocabulary overlap in Figure 3. From the results, we can conclude that English has the smallest vocabulary overlap with the other languages. This makes sense since English comes from a different language family, i.e., Indo-European language under the Germanic language branch, while the others are from the Austronesian language family under the Malayo-Polynesian branch. Other languages that have low vocabulary overlap are Buginese (bug) and Toba Batak (bbc). This aligns with our discussion in \u00a75, which shows the distinction between these languages and the other languages in the NusaX dataset.    ", "publication_ref": [], "figure_ref": ["fig_3"], "table_ref": ["tab_2"]}, {"heading": "Acknowledgments", "text": "We thank Dea Adhista and all annotators who helped us in building the corpus. We are grateful to Alexander Gutkin and Xinyu Hua for feedback on a draft of this manuscript. This work has been partially funded by Kata.ai (001/SD/YGI-NLP/1/2022) and PF20-43679 Hong Kong PhD Fellowship Scheme, Research Grant Council, Hong Kong.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Limitations", "text": "We created data for low-resource languages, which increases the accessibility of NLP research for marginalized communities. However, we were only able to cover 10 languages with only 1000 samples each, due to cost and the number of available annotators. This dataset has limited domain coverage and may also contain biases towards certain groups or entities. We tried our best to eliminate negative biases based on a manual inspection of the data. As our dataset was translated, there may be some translationese artifacts in the resulting corpus. We invited annotators based on their fluency level on a particular language. However, the fluency level is self-declared, and there is no mechanism to verify it, except for several languages that are spoken by authors of this paper. The dialect used in the dataset also depends on the annotator, for languages with multiple dialects.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Thierno Ibrahima DIOP, Abdoulaye Diallo, Adewale Akinfaderin, Tendai Marengereke, and Salomey Osei. 2021. MasakhaNER: Named Entity Recognition for African Languages", "journal": "", "year": "", "authors": "Jade David Ifeoluwa Adelani; Graham Abbott;  Neubig; D Daniel; Julia 'souza; Constantine Kreutzer; Chester Lignos; Happy Palen-Michel; Shruti Buzaaba; Sebastian Rijhwani; Stephen Ruder;  Mayhew;  Israel Abebe Azime; H Shamsuddeen; Chris Chinenye Muhammad; Joyce Emezue; Perez Nakatumba-Nabende; Aremu Ogayo; Catherine Anuoluwapo; Derguene Gitau; Jesujoba Mbaye;  Alabi; Tajuddeen Seid Muhie Yimam; Ignatius Rabiu Gwadabe; Rubungo Andre Ezeani; Jonathan Niyongabo; Verrah Mukiibi; Iroro Otiende; Davis Orife; Samba David;  Ngom"}, {"ref_id": "b1", "title": "JW300: A widecoverage parallel corpus for low-resource languages", "journal": "Association for Computational Linguistics", "year": "2019", "authors": "\u017deljko Agi\u0107; Ivan Vuli\u0107"}, {"ref_id": "b2", "title": "In neural machine translation, what does transfer learning transfer?", "journal": "", "year": "2020", "authors": "Alham Fikri Aji; Nikolay Bogoychev; Kenneth Heafield; Rico Sennrich"}, {"ref_id": "b3", "title": "One country, 700+ languages: NLP challenges for underrepresented languages and dialects in Indonesia", "journal": "Association for Computational Linguistics", "year": "2022", "authors": "Alham Fikri Aji; Genta Indra Winata; Fajri Koto; Samuel Cahyawijaya; Ade Romadhony; Rahmad Mahendra; Kemal Kurniawan; David Moeljadi; Radityo Eko Prasojo; Timothy Baldwin; Jey Han Lau; Sebastian Ruder"}, {"ref_id": "b4", "title": "Balinese morphosyntax: a lexicalfunctional approach", "journal": "", "year": "2003", "authors": "Arka I Wayan"}, {"ref_id": "b5", "title": "A robust self-learning method for fully unsupervised cross-lingual mappings of word embeddings", "journal": "Long Papers", "year": "2018", "authors": "Mikel Artetxe; Gorka Labaka; Eneko Agirre"}, {"ref_id": "b6", "title": "Multi-label aspect categorization with convolutional neural networks and extreme gradient boosting", "journal": "IEEE", "year": "2019", "authors": "Masayu Annisa Nurul Azhar; Arie Pratama Leylia Khodra;  Sutiono"}, {"ref_id": "b7", "title": "Cmu wilderness multilingual speech dataset", "journal": "IEEE", "year": "2019", "authors": "Alan W Black"}, {"ref_id": "b8", "title": "The Austronesian Languages", "journal": "", "year": "2013", "authors": "Robert Blust"}, {"ref_id": "b9", "title": "Prediction and analysis of indonesia presidential election from twitter using sentiment analysis", "journal": "Journal of Big data", "year": "2018", "authors": "Widodo Budiharto; Meiliana Meiliana"}, {"ref_id": "b10", "title": "IndoNLG: Benchmark and resources for evaluating Indonesian natural language generation", "journal": "Association for Computational Linguistics", "year": "2021", "authors": "Samuel Cahyawijaya; Bryan Genta Indra Winata; Karissa Wilie; Xiaohong Vincentio; Adhiguna Li; Sebastian Kuncoro;  Ruder; Syafri Zhi Yuan Lim; Masayu Bahar; Ayu Khodra; Pascale Purwarianti;  Fung"}, {"ref_id": "b11", "title": "Stock price prediction using linear regression based on sentiment analysis", "journal": "IEEE", "year": "2015", "authors": "Yahya Eru Cakra;  Bayu Distiawan Trisedya"}, {"ref_id": "b12", "title": "Unsupervised cross-lingual representation learning at scale", "journal": "", "year": "2020", "authors": "Alexis Conneau; Kartikay Khandelwal; Naman Goyal; Vishrav Chaudhary; Guillaume Wenzek; Francisco Guzm\u00e1n; Edouard Grave; Myle Ott; Luke Zettlemoyer; Veselin Stoyanov"}, {"ref_id": "b13", "title": "XNLI: Evaluating crosslingual sentence representations", "journal": "", "year": "2018", "authors": "Alexis Conneau; Ruty Rinott; Guillaume Lample; Adina Williams; Samuel Bowman; Holger Schwenk; Veselin Stoyanov"}, {"ref_id": "b14", "title": "Voice and verb morphology in Minangkabau, a language of West Sumatra, Indonesia", "journal": "", "year": "2009", "authors": "Sophie Elizabeth Crouch"}, {"ref_id": "b15", "title": "A grammar of Madurese", "journal": "Mouton De Gruyter", "year": "2010", "authors": "D William;  Davies"}, {"ref_id": "b16", "title": "Bert: Pre-training of deep bidirectional transformers for language understanding", "journal": "", "year": "2019", "authors": "Jacob Devlin; Ming-Wei Chang; Kenton Lee; Kristina Toutanova"}, {"ref_id": "b17", "title": "Ethnologue: Languages of the World. Twenty-fourth edition", "journal": "", "year": "2021", "authors": "David M Eberhard; Gary F Simons; Charles D Fennig"}, {"ref_id": "b18", "title": "AmericasNLI: Evaluating zero-shot natural language understanding of pretrained multilingual models in truly low-resource languages", "journal": "Long Papers", "year": "2022", "authors": "Abteen Ebrahimi; Manuel Mager; Arturo Oncevay; Vishrav Chaudhary; Luis Chiruzzo; Angela Fan; John Ortega; Ricardo Ramos; Annette Rios; Ivan Vladimir Meza Ruiz; Gustavo Gim\u00e9nez-Lugo; Elisabeth Mager; Graham Neubig; Alexis Palmer; Rolando Coto-Solano; Thang Vu; Katharina Kann"}, {"ref_id": "b19", "title": "The case of intercorp, a multilingual parallel corpus", "journal": "International Journal of Corpus Linguistics", "year": "2012", "authors": "Franti Ek\u010derm\u00e1k; Alexandr Rosen"}, {"ref_id": "b20", "title": "Word2vec model for sentiment analysis of product reviews in indonesian language", "journal": "International Journal of Electrical and Computer Engineering", "year": "2019", "authors": "Ali Fauzi"}, {"ref_id": "b21", "title": "Building large monolingual dictionaries at the Leipzig corpora collection: From 100 to 200 languages", "journal": "", "year": "2012", "authors": "Dirk Goldhahn; Thomas Eckart; Uwe Quasthoff"}, {"ref_id": "b22", "title": "Benchmarking multidomain englishindonesian machine translation", "journal": "", "year": "2020", "authors": "Alham Tri Wahyu Guntara; Radityo Eko Fikri Aji;  Prasojo"}, {"ref_id": "b23", "title": "The FLORES evaluation datasets for low-resource machine translation: Nepali-English and Sinhala-English", "journal": "", "year": "2019", "authors": "Francisco Guzm\u00e1n; Peng-Jen Chen; Myle Ott; Juan Pino; Guillaume Lample; Philipp Koehn; Vishrav Chaudhary; Marc'aurelio Ranzato"}, {"ref_id": "b24", "title": "Pmindia-a collection of parallel corpora of languages of india", "journal": "", "year": "2020", "authors": "Barry Haddow; Faheem Kirefu"}, {"ref_id": "b25", "title": "XTREME: A Massively Multilingual Multitask Benchmark for Evaluating Cross-lingual Generalization", "journal": "", "year": "2020", "authors": "Junjie Hu; Sebastian Ruder; Aditya Siddhant; Graham Neubig; Orhan Firat; Melvin Johnson"}, {"ref_id": "b26", "title": "Buzzer detection and sentiment analysis for predicting presidential election results in a twitter nation", "journal": "IEEE", "year": "2015", "authors": "Mochamad Ibrahim; Omar Abdillah; F Alfan; Mirna Wicaksono;  Adriani"}, {"ref_id": "b27", "title": "Multilingual parallel corpus for global communication plan", "journal": "", "year": "2018", "authors": "Kenji Imamura; Eiichiro Sumita"}, {"ref_id": "b28", "title": "PanLex: Building a resource for panlingual lexical translation", "journal": "", "year": "2014", "authors": "David Kamholz; Jonathan Pool; Susan Colowick"}, {"ref_id": "b29", "title": "Gluecos: An evaluation benchmark for codeswitched nlp", "journal": "", "year": "2020", "authors": "Simran Khanuja; Sandipan Dandapat; Anirudh Srinivasan; Sunayana Sitaram; Monojit Choudhury"}, {"ref_id": "b30", "title": "Moses: Open source toolkit for statistical machine translation", "journal": "", "year": "2007", "authors": "Philipp Koehn; Hieu Hoang; Alexandra Birch; Chris Callison-Burch; Marcello Federico; Nicola Bertoldi; Brooke Cowan; Wade Shen; Christine Moran; Richard Zens"}, {"ref_id": "b31", "title": "Towards computational linguistics in Minangkabau language: Studies on sentiment analysis and machine translation", "journal": "Association for Computational Linguistics", "year": "2020", "authors": "Fajri Koto; Ikhwan Koto"}, {"ref_id": "b32", "title": "Indolem and indobert: A benchmark dataset and pre-trained language model for indonesian nlp", "journal": "", "year": "2020", "authors": "Fajri Koto; Afshin Rahimi; Jey Han Lau; Timothy Baldwin"}, {"ref_id": "b33", "title": "Sundanese complementation", "journal": "", "year": "2013", "authors": "Eri Kurniawan"}, {"ref_id": "b34", "title": "", "journal": "", "year": "", "authors": "Zhaojiang Lin; Andrea Madotto; Peng Genta Indra Winata; Feijun Xu; Yuxiang Jiang; Chen Hu;  Shi"}, {"ref_id": "b35", "title": "BiToD: A bilingual multidomain dataset for task-oriented dialogue modeling", "journal": "", "year": "2021", "authors": "Pascale Fung"}, {"ref_id": "b36", "title": "Multilingual denoising pretraining for neural machine translation", "journal": "", "year": "2020", "authors": "Yinhan Liu; Jiatao Gu; Naman Goyal; Xian Li; Sergey Edunov; Marjan Ghazvininejad; Mike Lewis; Luke Zettlemoyer"}, {"ref_id": "b37", "title": "IndoNLI: A natural language inference dataset for Indonesian", "journal": "Association for Computational Linguistics", "year": "2021", "authors": "Rahmad Mahendra; Alham Fikri Aji; Samuel Louvan; Fahrurrozi Rahman; Clara Vania"}, {"ref_id": "b38", "title": "Anuoluwapo Aremu, and Idris Abdulmumin. 2022. Nai-jaSenti: A nigerian Twitter sentiment corpus for multilingual sentiment analysis", "journal": "European Language Resources Association", "year": "", "authors": "David Shamsuddeen Hassan Muhammad;  Adelani"}, {"ref_id": "b39", "title": "The application of whatsapp to support online learning during the covid-19 pandemic in indonesia", "journal": "Heliyon", "year": "2021", "authors": "Herri Mulyono; Gunawan Suryoputro; Shafa Ramadhanya Jamil"}, {"ref_id": "b40", "title": "Plan optimization to bilingual dictionary induction for low-resource language families", "journal": "", "year": "2021", "authors": "Yohei Arbi Haza Nasution; Toru Murakami;  Ishida"}, {"ref_id": "b41", "title": "Alp \u00d6ktem, Adewale Akinfaderin, and Abdallah Bashir. 2020. Participatory Research for Low-resourced Machine Translation: A Case Study in African Languages", "journal": "", "year": "", "authors": "Wilhelmina Nekoto; Vukosi Marivate; Tshinondiwa Matsila; Timi Fasubaa; Tajudeen Kolawole; Taiwo Fagbohungbe; Shamsuddee Hassan Solomon Oluwole Akinola; Salomon Muhammad; Salomey Kabongo; Sackey Osei; Rubungo Andre Freshia; Ricky Niyongabo; Perez Macharm; Orevaoghene Ogayo; Musie Ahia; Mofe Meressa; Masabata Adeyemi; Lawrence Mokgesi-Selinga; Laura Jane Okegbemi; Kolawole Martinus; Kevin Tajudeen; Kelechi Degila; Kathleen Ogueji; Julia Siminyu; Jason Kreutzer; Jamiil Toure Webster; Jade Ali; Iroro Abbott;  Orife"}, {"ref_id": "b42", "title": "Haryo Akbarianto Wibowo, Radityo Eko Prasojo, and Alham Fikri Aji. 2021. Costs to consider in adopting NLP for your business", "journal": "", "year": "", "authors": " Made Nindyatama Nityasya"}, {"ref_id": "b43", "title": "Tufs asian language parallel corpus (talpco)", "journal": "", "year": "2018", "authors": "Hiroki Nomoto; Kenji Okano; David Moeljadi; Hideo Sawada"}, {"ref_id": "b44", "title": "Sentiment analysis on covid19 vaccines in indonesia: From the perspective of sinovac and pfizer", "journal": "IEEE", "year": "2021", "authors": "Indra Deden Ade Nurdeni; Aris Budi Budi;  Santoso"}, {"ref_id": "b45", "title": "Cross-lingual name tagging and linking for 282 languages", "journal": "Long Papers", "year": "2017", "authors": "Xiaoman Pan; Boliang Zhang; Jonathan May; Joel Nothman; Kevin Knight; Heng Ji"}, {"ref_id": "b46", "title": "A two-level morphological analyser for the Indonesian language", "journal": "", "year": "2008", "authors": "Femphy Pisceldo; Rahmad Mahendra; Ruli Manurung;  Arka"}, {"ref_id": "b47", "title": "XCOPA: A multilingual dataset for causal commonsense reasoning", "journal": "", "year": "2020", "authors": "Goran Edoardo Maria Ponti; Olga Glava\u0161; Qianchu Majewska; Ivan Liu; Anna Vuli\u0107;  Korhonen"}, {"ref_id": "b48", "title": "A call for clarity in reporting BLEU scores", "journal": "", "year": "2018", "authors": "Matt Post"}, {"ref_id": "b49", "title": "Improving bi-lstm performance for indonesian sentiment analysis using paragraph vector", "journal": "IEEE", "year": "2019", "authors": ""}, {"ref_id": "b50", "title": "Sundanese twitter dataset for emotion classification", "journal": "IEEE", "year": "2020", "authors": "Fathin Oddy Virgantara Putra; Triana Muhammad Wasmanson; Shoffin Nahwa Harmini;  Utama"}, {"ref_id": "b51", "title": "Abusive language and hate speech detection for Indonesian-local language in social media text", "journal": "Springer International Publishing", "year": "2021", "authors": ""}, {"ref_id": "b52", "title": "", "journal": "", "year": "", "authors": "Gowtham Ramesh; Sumanth Doddapaneni; Aravinth Bheemaraj; Mayank Jobanputra"}, {"ref_id": "b53", "title": "Pratyush Kumar, and Mitesh Shantadevi Khapra. 2022. Samanantar: The Largest Publicly Available Parallel Corpora Collection for 11 Indic Languages", "journal": "Transactions of the Association for Computational Linguistics", "year": "", "authors": "Ajitesh Sharma; Sujit Sahoo; Harshita Diddee; J Mahalakshmi; Divyanshu Kakwani; Navneet Kumar; Aswin Pradeep; Srihari Nagaraj; Kumar Deepak; Anoop Vivek Raghavan;  Kunchukuttan"}, {"ref_id": "b54", "title": "The bible as a parallel corpus: Annotating the 'book of 2000 tongues'. Computers and the Humanities", "journal": "", "year": "1999", "authors": "Philip Resnik; Mari Broman Olsen; Mona Diab"}, {"ref_id": "b55", "title": "Conference of The Oriental Chapter of International Committee for Coordination and Standardization of Speech Databases and Assessment Techniques (O-COCOSDA)", "journal": "IEEE", "year": "2016", "authors": "Hammam Riza; Michael Purwoadi; Teduh Uliniansyah; Ai Aw; Sharifah Ti;  Mahani Aljunied; Chi Luong;  Mai;  Vu Tat Thang; Phuong Nguyen; Vichet Thai; Sethserey Chea;  Sam"}, {"ref_id": "b56", "title": "Stock price movement prediction using technical analysis and sentiment analysis", "journal": "", "year": "2020", "authors": "Tommy Wijaya Sagala; Mei Silviana Saputri; Rahmad Mahendra; Indra Budi"}, {"ref_id": "b57", "title": "Towards language preservation: Design and collection of graphemically balanced and parallel speech corpora of indonesian ethnic languages", "journal": "IEEE", "year": "2013", "authors": "Sakriani Sakti; Satoshi Nakamura"}, {"ref_id": "b58", "title": "Wiki-Matrix: Mining 135M parallel sentences in 1620 language pairs from Wikipedia", "journal": "", "year": "2021", "authors": "Holger Schwenk; Vishrav Chaudhary; Shuo Sun; Hongyu Gong; Francisco Guzm\u00e1n"}, {"ref_id": "b59", "title": "The Indonesian language: Its history and role in modern society", "journal": "UNSW Press", "year": "2003", "authors": "James Neil Sneddon"}, {"ref_id": "b60", "title": "Recursive deep models for semantic compositionality over a sentiment treebank", "journal": "", "year": "2013", "authors": "Richard Socher; Alex Perelygin; Jean Wu; Jason Chuang; D Christopher;  Manning; Y Andrew; Christopher Ng;  Potts"}, {"ref_id": "b61", "title": "The jrc-acquis: A multilingual aligned parallel corpus with 20+ languages", "journal": "", "year": "2006", "authors": "Ralf Steinberger; Bruno Pouliquen; Anna Widiger; Camelia Ignat"}, {"ref_id": "b62", "title": "Lorelei language packs: Data, tools, and resources for technology development in low resource languages", "journal": "", "year": "2016", "authors": "Stephanie Strassel; Jennifer Tracey"}, {"ref_id": "b63", "title": "Ngaju-Dayak Language. The Sanseido Encyclopedia of Linguistics", "journal": "Languages of The World", "year": "1988", "authors": "Motomitsu Uchibori; Norio Shibata"}, {"ref_id": "b64", "title": "Writing system and speaker metadata for 2,800+ language varieties", "journal": "", "year": "2022", "authors": "Tamar Daan Van Esch; Sebastian Lucassen; Isaac Ruder; Clara E Caswell;  Rivera"}, {"ref_id": "b65", "title": "Expanding pretrained models to thousands more languages via lexicon-based adaptation", "journal": "Association for Computational Linguistics", "year": "2022", "authors": "Xinyi Wang; Sebastian Ruder; Graham Neubig"}, {"ref_id": "b66", "title": "Syntactic variation of buginese, a language in austronesian great family", "journal": "", "year": "2016", "authors": "Sukardi Weda"}, {"ref_id": "b67", "title": "Syamsul Arifin, Sumadi Sumadi, and Laginem Laginem", "journal": "", "year": "2001", "authors": "Wedhawati Wedhawati; E S N Wiwin; Herawati Sri Nardiati; Restu Herawati; Marsono Sukesti; Edi Marsono; Dirgo Setiyanto;  Sabariyanto"}, {"ref_id": "b68", "title": "IndoCollex: A testbed for morphological transformation of Indonesian word colloquialism", "journal": "", "year": "2021", "authors": "Made Haryo Akbarianto Wibowo; Afra Nindyatama Nityasya; Suci Feyza Aky\u00fcrek; Alham Fitriany; Radityo Eko Fikri Aji; Derry Tanti Prasojo;  Wijaya"}, {"ref_id": "b69", "title": "Semi-supervised low-resource style transfer of Indonesian informal to formal language with iterative forward-translation", "journal": "IEEE", "year": "2020", "authors": "Tatag Aziz Haryo Akbarianto Wibowo; Muhammad Prawiro;  Ihsan"}, {"ref_id": "b70", "title": "IndoNLU: Benchmark and resources for evaluating Indonesian natural language understanding", "journal": "Association for Computational Linguistics", "year": "2020", "authors": "Bryan Wilie; Karissa Vincentio; Samuel Genta Indra Winata; Xiaohong Cahyawijaya;  Li; Sidik Zhi Yuan Lim; Rahmad Soleman; Pascale Mahendra; Syafri Fung; Ayu Bahar;  Purwarianti"}, {"ref_id": "b71", "title": "Crosslingual few-shot learning on unseen languages", "journal": "", "year": "2022", "authors": "Genta Winata; Shijie Wu; Mayank Kulkarni; Thamar Solorio; Daniel Preo\u0163iuc-Pietro"}, {"ref_id": "b72", "title": "Language models are few-shot multilingual learners", "journal": "", "year": "2021", "authors": "Andrea Genta Indra Winata; Zhaojiang Madotto; Rosanne Lin; Jason Liu; Pascale Yosinski;  Fung"}, {"ref_id": "b73", "title": "Pre-trained transformer-based language models for sundanese", "journal": "Journal of Big Data", "year": "2022", "authors": "Wilson Wongso; Henry Lucky; Derwin Suhartono"}, {"ref_id": "b74", "title": "2021. mT5: A massively multilingual pre-trained text-to-text transformer", "journal": "", "year": "", "authors": "Linting Xue; Noah Constant; Adam Roberts; Mihir Kale; Rami Al-Rfou; Aditya Siddhant; Aditya Barua; Colin Raffel"}, {"ref_id": "b75", "title": "5% 9.9% 9.8% 8.7% 11.7% 9.7% 9.2% 10.9% 10.3% 10.0% 9", "journal": "", "year": "", "authors": ""}, {"ref_id": "b76", "title": "Figure 3: Vocabulary overlap between language pairs in NusaX dataset", "journal": "", "year": "", "authors": ""}], "figures": [{"figure_label": "2", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 2 :2Figure 2: Zero-shot cross-lingual results for the sentiment analysis task with XLM-R LARGE . The model is trained on the language indicated on the x-axis and evaluated on all languages.", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "A. 11General Information Dataset title NusaX Dataset curators Alham Fikri Aji (MBZUAI), Rahmad Mahendra (Universitas Indonesia), Samuel Cahyawijaya (HKUST), Ade Romadhony (Telkom University, Indonesia), Genta Indra Winata (Bloomberg), Fajri Koto (University of Melbourne), Kemal Kurniawan (University of Melbourne) Dataset version 1.0 (May 2022) Data statement author Kemal Kurniawan (University of Melbourne) Data statement version 1.0 (February 2022)", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 4 :4Figure 4: Word frequency histogram for each language in NusaX.", "figure_data": ""}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Label distribution of NusaX Sentiment dataset.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "72.6 73.0 71.9 73.7 76.5 73.1 69.4 66.8 73.2 68.8 71.9 72.0 SVM 75.7 75.3 76.7 74.8 77.2 75.0 78.7 71.3 73.8 76.7 75.1 74.3 75.4 LR 77.4 76.3 76.3 75.0 77.2 75.9 74.7 73.7 74.7 74.8 73.4 75.8 75.4 IndoBERT BASE 75.4 74.8 70.0 83.1 73.9 79.5 90.0 81.7 77.8 82.5 75.8 77.5 78.5 IndoBERT LARGE76.3 79.5 74.0 83.2 70.9 87.3 90.2 85.6 77.2 82.9 75.8 77.2 80.0", "figure_data": "Modelaceban bbc bjnbug eng indjavmad min nijsun avgNaive Bayes 72.5 IndoLEM BASE 72.6 65.4 61.7 71.2 66.9 71.2 87.6 74.5 71.8 68.9 69.3 71.7 71.1mBERT BASE XLM-R BASE XLM-R LARGE72.2 70.6 69.3 70.4 68.0 84.1 78.0 73.2 67.4 74.9 70.2 74.5 72.7 73.9 72.8 62.3 76.6 66.6 90.8 88.4 78.9 69.7 79.1 75.0 80.1 76.2 75.9 77.1 65.5 86.3 70.0 92.6 91.6 84.2 74.9 83.1 73.3 86.0 80.0"}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "Sentiment analysis results in macro-F1 (%). Models were trained and evaluated on each language.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "24.17 12.07 15.38 11.17 PBSMT 25.17 41.22 20.94 47.80 15.21 6.68 46.99 38.39 60.56 32.86 41.79 34.33 Results of the machine translation task from other languages to Indonesian (x \u2192 idn) based on SacreBLEU.", "figure_data": "Modelacebanbbcbjnx \u2192 idn bugengjavmadminnijsunavgCopy5.889.994.28 15.993.440.579.295.11 18.107.519.248.13Word Substitution 7.89 IndoGPT 7.33 12.30 5.02 16.17 3.52 1.67 17.34 7.01 13.23 5.27 19.53 1.98 4.26 27.31 13.75 23.03 10.83 23.18 13.58IndoBARTv2 mBART-50 mT5 BASE24.44 40.49 19.94 47.81 12.64 11.73 50.64 36.10 58.38 33.50 45.96 34.69 18.45 34.23 17.43 41.73 10.87 17.92 39.66 32.11 59.66 29.84 35.19 30.64 18.59 21.73 12.85 42.29 2.64 12.96 45.22 32.35 58.65 25.61 36.58 28.13Table 4: Modelavg. SacreBLEU ind x x ind eng x x engPBSMT IndoBARTv2 28.21 28.72 mBART-50 24.6934.33 34.69 30.644.56 6.36 7.205.84 7.46 6.45"}, {"figure_label": "5", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_7", "figure_caption": "12.38 10.23 PBSMT 20.47 26.48 18.18 42.08 10.84 7.73 39.08 33.26 52.21 29.58 36.04 28.72 Results of the machine translation task from Indonesian to other languages (idn \u2192 x) in SacreBLEU.", "figure_data": "Modelacebanbbcbjnind \u2192 x bugengjavmadminnijsunavgCopy5.89 10.004.28 15.993.450.569.295.11 18.107.529.248.13Word Substitution 9.76 IndoGPT 7.60 10.31 5.99 17.51 3.57 0.76 14.75 7.58 22.34 9.60 14.17 8.20 22.23 5.18 5.89 24.05 14.44 26.95 17.56 23.15 15.58IndoBARTv2 mBART-5019.21 27.08 18.41 40.03 11.06 11.53 39.97 28.95 48.48 27.11 38.46 28.21 17.21 22.67 17.79 34.26 10.78 3.90 35.33 28.63 43.87 25.91 31.21 24.69mT5 BASE14.79 18.07 18.22 38.646.68 11.21 33.480.96 45.84 13.59 33.79 21.39Table 6: LanguageSingle Multi LOLOAcehnese Balinese Banjarese Buginese English Indonesian Javanese Madurese Minangkabau Ngaju Sundanese Toba batak75.9 77.1 86.3 70.0 92.6 91.6 84.2 74.9 83.1 73.3 86.0 65.576.96 80.13 84.85 67.86 91.05 91.13 88.19 79.41 85.29 78.82 86.02 70.0075.79 77.83 82.68 63.67 89.88 90.62 87.39 78.52 84.45 76.31 84.41 68.76Average80.0481.6480.03"}, {"figure_label": "7", "figure_type": "table", "figure_id": "tab_8", "figure_caption": "", "figure_data": ": Sentiment analysis results for macro-F1 (%) of XLM-R LARGE in the multilingual setting.data of all languages. Additionally, we also ex-plore Leave-One-Language-Out (LOLO), wherewe train on all data except for the test language.The LOLO setting arguably reflects the most realis-tic scenario where we do not have training data fora particular language, but we do have access to datain other local languages. The multilingual resultsfor sentiment analysis are shown in Table 7. Multi-lingual training outperforms monolingual training,while LOLO matches the performance of trainingon target language data. Related language data isthus often sufficient for good cross-lingual results."}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_9", "figure_caption": "Balinese Three people translate into Balinese. Two of them have previous experience in translation work, and both identify as female. The other one, who identifies as male, does not have such", "figure_data": "LanguageISO 639-3 Annotators' Dialect ExampleAcehneseaceBanda AcehMeureutoh rumoh di Medan keunong ie rayaBalinesebanLowlandSatusan umah ring medan merendem banjirToba BatakbbcToba, HumbangMarratus jabu di medan na hona banjiBanjaresebjnHulu, KualaRatusan rumah di medan tarandam banjirBuginesebugSidrapMaddatu bola okko medan nala lempeJavanesejavMatramanAtusan omah ing medan kebanjiranMaduresemadSitubondoRatosan bangko e medan tarendem banjirMinangkabauminPadang, AgamRatuihan rumah di medan tarandam banjirNgajunijKapuas, KahayanRatusan huma hong medan lelep awi banjirSundanesesunPrianganRatusan bumi di medan karendem banjir"}, {"figure_label": "8", "figure_type": "table", "figure_id": "tab_10", "figure_caption": "Local languages spoken in Indonesia (ID) that are covered in NusaX.", "figure_data": "experience. Two of them are aged 20-29 years old,while the other is in their 30s. Their occupationsare university lecturer, school teacher, and civilemployee respectively."}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_11", "figure_caption": "Madurese There are 3 translators for Madurese. Only one of them has previous experience in translation work. Two of them identify as female, while the other as male. One person is aged under 20 years old and is a university student. The others are 20-29 years old and work as a school teacher and an employee in a private company respectively.", "figure_data": "employee, a university student, and a senior dataannotator respectively.Minangkabau Three people translate into Mi-nangkabau. Two of them have previous transla-tion experience. All three identify as female andare aged 20-29 years old. They work as a civil"}, {"figure_label": "9", "figure_type": "table", "figure_id": "tab_13", "figure_caption": "Hyperparameters of statistical models on sentiment analysis.", "figure_data": ""}, {"figure_label": "9", "figure_type": "table", "figure_id": "tab_14", "figure_caption": "and select the", "figure_data": "HyperparamsValueslearning rate batch size num epochs[1e-4, 5e-5, 1e-5, 5e-6, 1e-6] [4, 8, 16, 32] 100early stop3max norm10optimizerAdamAdam \u03b2(0.9, 0.999)Adam \u03b30.9Adam \u03f51e-8"}, {"figure_label": "10", "figure_type": "table", "figure_id": "tab_15", "figure_caption": "Hyperparameters of pre-trained LMs on sentiment analysis. Bold denotes the best hyperparameter setting.", "figure_data": ""}, {"figure_label": "11", "figure_type": "table", "figure_id": "tab_17", "figure_caption": "Hyperparameters of pretrained LMs on machine translation.", "figure_data": ""}, {"figure_label": "12", "figure_type": "table", "figure_id": "tab_19", "figure_caption": "Vocabulary size (in bracket) and top-10 words on each language in the NusaX dataset.", "figure_data": ""}], "formulas": [], "doi": "10.1162/tacl_a_00416"}