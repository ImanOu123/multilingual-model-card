{"title": "An Alignment-based Approach to Text Segmentation Similarity Scoring", "authors": "Gerardo Ocampo Diaz; Jessica Ouyang", "pub_date": "", "abstract": "Text segmentation is a natural language processing task with popular applications, such as topic segmentation, element discourse extraction, and sentence tokenization. Much work has been done to develop accurate segmentation similarity metrics, but even the most advanced metrics used today, B, and WindowDiff, exhibit incorrect behavior due to their evaluation of boundaries in isolation. In this paper, we present a new segment-alignment based approach to segmentation similarity scoring and a new similarity metric A. We show that A does not exhibit the erratic behavior of B and WindowDiff, quantify the likelihood of B and WindowDiff misbehaving through simulation, and discuss the versatility of alignment-based approaches for segmentation similarity scoring. We make our implementation of A publicly available and encourage the community to explore more sophisticated approaches to text segmentation similarity scoring.", "sections": [{"heading": "Introduction", "text": "Text segmentation is a natural language processing (NLP) task that consists of dividing a sequence of text elements into segments.\nLet T = e 1 , e 2 , e 3 ...e n be a sequence of text elements (e.g. words, sentences, paragraphs, etc...). A segmentation S of T is given by a binary string Q = [0|1] n\u22121 that encodes boundaries between the elements of T . The ith character of Q codifies the presence of a boundary (1) or lack thereof (0) between e i and e i+1 in S. S contains m \u2212 1 boundaries and partitions T into m segments 1 .\nMeasuring similarity between segmentations is not simple. The most straightforward approach is to frame a segmentation as a series of decisions made at every potential boundary position (PBP), 1 This definition corresponds to single-type segmentation. A multi-type version also exists where different boundary types are considered, enabling the encoding of different types of segments and even hierarchical relations between them. which exist between every pair of elements in T , and to calculate the average PBP agreement, but this does not match human intuition well. Consider how S in Figure 1 compares with h1 and h2 in Figure 2: h 1 agrees with S in 4 out of 5 positions (one missing boundary), while h 2 agrees with S in only 3 out of 5 positions (one missing and one \"extra\" boundary). Yet it is easy to agree that h 2 is actually closer to S, as it has simply \"shifted\" the boundary in S one unit to the right.  To address this, researchers have proposed a variety of similarity metrics that distinguish \"soft\" and \"hard\" errors (shifted versus missing/extra boundaries). However, existing metrics look at boundary errors in isolation; they do not consider the impact that errors have on segments around them. Consider how hypothesis segmentations h 3 and h 4 compare to a reference segmentation r in Figure 3. Both have a boundary that is shifted one PBP to the right, which results in an\"extra\" element in the segment to the left of the PBP and a missing element in the segment to the right. However, the resulting segment distortion is not the same. In h 3 , only 1/2 of the elements in the the first segment are correct, while 1/2 of the reference elements are missing from the second segment; in h 4 , the third segment has 4/5 correct elements, and the fourth segment has 1/4 missing elements. It is easy to argue then that h 4 is closer to r than h 3 , but current metrics are unable to distinguish between them.\nWe propose a new similarity metric based on segment alignment, which scores segmentations based on how well their segments match, rather than their boundaries (Section 3). We show that our metric aligns more closely with human intuition than existing metrics (Section 4) and quantify the errors encountered by those metrics (Section 5). Code for our new metric and relevant materials are made publicly available at https://github.com/sierra98x/resources.", "publication_ref": [], "figure_ref": ["fig_0", "fig_2", "fig_3"], "table_ref": []}, {"heading": "Existing Metrics", "text": "Current segmentation similarity metrics fall into two categories: window-based metrics try to capture errors by sliding a window across the element sequence T and comparing the boundaries in both segmentations; in contrast, edit-based metrics try to find a sequence of boundary edit operations that would make both segmentations equal.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Window-Based Metrics", "text": "WindowDiff (Pevzner and Hearst, 2002) and P k (Beeferman et al., 1999) are the most popular similarity metrics currently used. P k is defined as \"the probability that a random pair of elements, k elements apart, will be classified inconsistently by two segmentations as belonging/not belonging in the same segment.\" Given an element sequence T of length n, a reference segmentation r, and an alternate segmentation h, a window of size k + 1 is slid across the elements (k is recommended by the authors to be half the average segment size in r); at every window position, the segmentations are compared based on the elements at the edges of the window, e i and e i+k ; if the segmentations disagree on whether the elements belong in the same segment, a penalty of 1 is added; finally, the penalty sum is divided by the number of windows: where \u03b4(x i,j ) is true iff e i , e j are in the same segment in segmentation x.\nP k (r, h) = 1 n \u2212 k i=n\u2212k i=1,j=i+k \u03b4(r i,j ) \u0338 = \u03b4(h i,j )\nThere are a variety of situations where P k penalizes errors inconsistently (Pevzner and Hearst, 2002): it penalizes missing boundaries more than extra boundaries, fails to penalize extra boundaries that are in close proximity to correct boundaries, and is also quite sensitive to the window size k.\nWindowDiff improves on P k by using a different penalty criteria. Instead of comparing the elements at the window edges, WindowDiff counts the number of boundaries between the edge elements and assigns a penalty of 1 if the number is inconsistent between segmentations:\nWD(r, h) = 1 n \u2212 k i=n\u2212k i=1,j=i+k b(r i,j ) \u0338 = b(h i,j )\nwhere b(x i,j ) is the boundary count between e i and e j in segmentation x.\nWindowDiff solves some of P k 's inconsistency problems, but still produces unintuitive scores and penalizes errors at the edges of the element sequence less than those towards the middle (a weakness shared with P k ). WindowDiff is usually reported along with P k rather than instead of it. Lamprier et al. (2007) present a simple correction to WindowDiff: adding k \u2212 1 extra elements at the beginning and end of the sequence T ensures that errors at every PBP are penalized an equal number of times. Further, they argue that WindowDiff is unfair because the expected score of a random segmenter depends on the number of boundaries in the reference r. To address this, they present two normalized versions of WindowDiff, NWin and TNWin, which take into account the expected WindowDiff scores of two random segmentations with the same cardinality as the reference and hypothesis segmentations being evaluated.\nFinally, Scaiano and Inkpen (2012) propose WinPR, which uses the element padding correction from (Lamprier et al., 2007) and categorizes the errors at each window into true positives (correct boundaries), false positives (extra boundaries), true negatives (correct empty PBPs), and false negatives (missing boundaries), allowing for finer-grained error analysis and the calculation of F1 scores.\nAlthough WinPR is an improvement on Win-dowDiff, it has not been widely adopted by the community and, like NWin, depends on the correctness of WindowDiff; the improvements presented in WinPR and NWin do not offset the core theoretical issues with WindowDiff. The th Thus, throughout the rest of this paper, we will limit our discussion of window-based metrics to WindowDiff and P k .", "publication_ref": ["b8", "b0", "b8", "b6", "b9", "b6"], "figure_ref": [], "table_ref": []}, {"heading": "Edit-Based Metrics", "text": "Edit-based segmentation similarity metrics are based on ideas introduced by Damerau-Levenshtein string edit distance (Damerau, 1964;Levenshtein, 1966) and partially replicated by Generalized Hamming Distance (Bookstein et al., 2002). The general idea is that every segmentation can be framed as a sequence of boundaries, each placed at a specific position. If we define a set of edit operations (with costs) that can modify any sequence of boundaries, the distance between two segmentations can be measured as the cost of the optimal sequence of edit operations required to make the two segmentations equal. The optimal sequence of edit operations is equivalent to a boundary alignment between the segmentations.\nSegmentation Similarity (Fournier and Inkpen, 2012) and Boundary Similarity (Fournier and Inkpen, 2012)  Segmentation Similarity (S) (Fournier and Inkpen, 2012) assigns a constant cost to all edit Figure 5: Example segmentation alignment with boundary edit operations (Fournier, 2013).\noperations and normalizes the resulting distance based on the total number of possible boundaries for the given element sequence. The idea behind this normalization is to scale the cost based on the potential complexity of the segmentation in question; the intuition is that a constant cost is less impactful on a longer/more complex sequence than it is on a shorter/simpler one.\nLet A e , T e S e be the sets of the optimal boundary addition/deletion, transposition, and substitution operations required to align a pair of segmentations, h 1 and h 2 , over a sequence of elements T . Further, let b be the number of boundary types (in the case of multi-type segmentation) available.\nS(h 1 , h 2 , T ) = 1 \u2212 |A e | + |T e | + |S e | b(|T | \u2212 1)\nFournier and Inkpen argue that S a) produces scores that align favorably with human intuition compared to WindowDiff in three key examples, b) has reduced sensitivity to variations in segment sizes compared to WindowDiff, and c) produces more accurate inter-annotator agreement scores than WindowDiff in one dataset. It is also noted that S can be used for multi-type segmentation, where traditional window-based methods can not.\nBoundary Similarity (B) (Fournier, 2013) improves S by introducing weighted-costs transpositions/substitutions, improving the edit distance normalization factor, and producing a confusion matrix from the edit operations to calculate F1 scores.\nB(h 1 , h 2 , T ) = 1 \u2212 |A e | + t(T e , k) + s(S e , B t ) |A e | + |T e | + |S e | + |M |\nwhere k is the maximum transposition distance, |M | is the number of matching boundary pairs between the two segmentations, B t is the set of boundary types, and t and s are functions that return the weighted sums of T e (transpositions) and S e (substitutions). The normalization factor in B produces behavior that aligns more closely with human judgement than in S.\nWhen comparing scores generated by WindowDiff, P k , S, and B on a handful of key examples, Fournier argues that B produces behavior that falls more in line with human intuition. B is further shown on one dataset to produce more reliable interannotator agreement scores when compared to S, as S-based inter-annotator agreement scores are shown to be inflated, and also to overcome Win-dowDiff's bias towards segmentations with few or tightly-clustered boundaries when evaluating three segmenters.\nAs we will demonstrate Section 4, however, B (and WindowDiff) disregards the impact of individual mistakes on the surrounding segments, which leads to scores that do not align well with human judgement in key scenarios.", "publication_ref": ["b3", "b7", "b2", "b5", "b5", "b5", "b4", "b4"], "figure_ref": [], "table_ref": []}, {"heading": "An Alignment-Based Approach to Segmentation Similarity Scoring", "text": "In Section 1, Figure 2, we presented an example that showcased the importance of weighing boundary differences in terms of the impact they have on their corresponding segments. None of the current metrics attempt to do this, and they can not be easily modified to do so. We propose to measure similarity between a pair of segmentations by comparing the segments defined in them. The intuition is straightforward: two segmentations are similar iff the segments defined by them are similar. Inspired by alignments from machine translation and string comparison, our approach measures segmentation similarity by finding the maximum likelihood segment alignment and scoring its correctness.\nThe concept of the most likely alignment is based on two key observations. First, it only makes sense to align overlapping segments. Second, the overlap between two segments is a good indicator for their \"closeness\", which tells us if they should be aligned. Thus, the maximum likelihood alignment (MLA) is one where every segment is aligned to its closest other segment. Consider the example alignment in Figure 6: h 2 has fuzzily merged the first two segments in h 1 into a single segment, which results in the third segment from h 1 having a slightly shifted boundary in h 2 . Here, it does not make sense to align the third segment in h 1 with the first segment in h 2 ; even if they overlap, the third segment in h 1 overlaps mainly with the second segment in h 2 .\nThe MLA can be found greedily in O(m 1 + m 2 ) time, where m 1 and m 2 are the number of segments in h 1 and h 2 , respectively. We only need to find the closest segment for any given segment 5 . Figure 7 shows pseudocode for generating the MLA 6 .  The MLA depends on the closeness function c. For a generic alignment, where all elements in the element sequence are considered equal, we recommend a simple intersect ratio function i between two segments, x and y:", "publication_ref": [], "figure_ref": ["fig_2", "fig_6", "fig_8"], "table_ref": []}, {"heading": "MLA(h1", "text": "i(x, y) = intersect(x, y) |x|\nThe MLA explains the differences between a pair of segmentations in terms of boundaries: in Figure 8, missing/extra boundaries are indicated by the existence of segments with more than one aligned segment. The first segment in h 3 is aligned to two segments in h 4 because h 4 contains an extra boundary; similarly, the third segment in h 4 is aligned to two segments in h 3 because the third segment in h 4 is missing a boundary present in h 3 . Furthermore, the existence of pairs of aligned segments with no alignments to any other segments are indicators of matches or transpositions, such as the last segments in h 3 and h 4 . Once the MLA has been generated, a function should be chosen to map the MLA to a similarity score. A simple approach is to assign a weight to every alignment edge, using a function g, and normalize by the number of edges in the MLA. This generic similarity score A is defined as:\nA(h 1 , h 2 , c, g) = edge\u2208MLA(h 1 ,h 2 ,c) g(edge) # edges in MLA(h 1 , h 2 , c)\nA variety of edge weighting functions can be used: clustering similarity functions such as the rand index, or set similarity metrics such as the overlap coefficient, the S\u00f8rensen-Dice coefficient, or the Jaccard index. Both symmetric and asymmetric weighting functions can be used, as the edges generated by the MLA function are directed; we recommend the Jaccard index, since it guarantees a symmetrical segmentation similarity score. Further, the Jaccard version of A can be easily modified to distinguish between \"soft\" and \"hard\" mistakes by penalizing edges with weights under some threshold t. The Jaccard index, J \u2208 [0, 1], between two sets S and T is defined as:\nJ(S, T ) = |intersect(S, T )| |union(S, T )|\nThe MLA approach with similarity score function A compares favorably to WindowDiff, B, and similar metrics in terms of error analysis, as the MLA structure and edge weights provide information about segmentation differences in terms of both boundaries and segments.\nFurther, the separation between the MLA algorithm and the similarity score function A makes our approach quite versatile, as the MLA may instead be scored with a different, task-specific similarity scoring function. Consider the reference segmentation r and candidate segmentations h 1 and h 2 in Figure 9: h 1 and h 2 are equidistant to r under A with Jaccard (0.58), B, and WindowDiff. However, for a task like topic segmentation, h 2 may be preferred, as it contains \"meta\" topics that consistently match two topics each in r, whereas h 1 contains two correct topics, but one really bad third topic, which is a mixture of four topics in r. Conversely, for a task like sentence segmentation, h 1 may be preferred, as it correctly identifies two sentences, where h 2 contains only incorrect sentences. The MLA could be used in conjunction with a similarity scoring function that imposes exponentially increasing penalties on segments with many alignments to favor h 2 , while a scoring function that considers only the highest weighted edge for any given segment would favor h 1 . Finally, as we will show in the following section, a straightforward implementation of A, using the intersect ratio i as the closeness function and the Jaccard index J as the edge weight function, behaves favorably compared to current metrics in a key set of examples.", "publication_ref": [], "figure_ref": ["fig_9", "fig_10"], "table_ref": []}, {"heading": "Similarity Metric Behavior", "text": "In this section, we outline three erratic behaviors from B and WindowDiff, and compare these metrics against A in a series of example segmentations.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Cross-Boundary Transpositions", "text": "Since B and WindowDiff look at each boundary in isolation, they consider all boundary shifts with the same distance to be equally bad, resulting in pseudo-transpositions, where one boundary crosses over another, being penalized the same as standard transpositions. It is easy to argue against this, as a boundary shift that crosses another boundary is not a true transposition, but rather a pair of overand under-segmentations. This is illustrated in Figure 10, where h 1 is clearly closer to the reference segmentation r than is h 2 . h 1 transposes the leftmost boundary of r two units to the right, while h 2 pseudo-transposes the rightmost boundary two units to the left, crossing over the middle boundary. h 2 results in an oversegmentation of the second segment and undersegmentation of the third and fourth segments of r. A correctly identifies this behavior because it works on segment alignments; B and WindowDiff, however, incorrectly score h 1 and h 2 as being equally close to r. ", "publication_ref": [], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Constant Cost Transpositions", "text": "B and WindowDiff measure the cost of a transposition based on its absolute distance, without considering the impact it has on the surrounding segments. This quickly leads to problematic behavior, as any given pair of segmentations that contain transpositions with the same distance will get the same score (assuming all other boundary operations are the same). Figure 11 illustrates this problem: B and WindowDiff score both segmentations equally, even though the impact of the transposed boundaries is not the same. Both h 1 and h 2 transpose a boundary by one unit, but in h 1 this results in a single extra/missing token in segments originally of size five, while in h 2 , the extra/missing token affects segments originally of size two, impacting them more significantly. A produces proper behavior here, weighing the distance of the transposition in relation to the corresponding segment sizes.", "publication_ref": [], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Vanishing Transpositions", "text": "Unlike A, the sensitivity of B and WindowDiff to \"near-misses\" (transpositions) is regulated by constants. B defines a maximum transposition distance, while WindowDiff utilizes a fixed window size. This causes problematic behavior, as boundary shifts beyond the maximum transposition distance for each metric look the same, which is compounded with the disregard for segment sizes mentioned in the previous subsection. The five segmentation pairs in Figure 12 illustrate this behavior. Although the pairs are ordered by increasing similarity, B and WindowDiff score three out of five pairs equally using their default maximum transposition distance values of 1. The behavior of B is particularly concerning, as it jumps from a relatively high score of 0.75 for the fourth pair, to a very low score of 0.33 for the third pair. In contrast, A correctly matches the first segments and second segments in each pair and considers the relative impact of the transposition given the size of the segments involved.\nh 1a h 1b h 2a h 2b h 3a h 3b h 4a h 4b h 5a h 5b Pair A B (k=1) 1 \u2212 WD (k=2) (h 1a , h 1b ) 0.", "publication_ref": [], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Alignment with Human Intuition", "text": "We perform a simple experiment to verify whether human judgement of segmentation similarity is sensitive to the kind of errors previously described. We hand-craft 3 reference segmentations r, each with a pair of alternate segmentations, h 1 and h 2 , that exemplify each of the problems described in this section (cross-boundary transpositions, constant cost transpositions, and vanishing transpositions). We present each of these 3 instances to 6 NLP graduate students and ask them to indicate whether the alternate segmentations, h 1 and h 2 are equally similar to their reference segmentation r, or whether one is more similar than the other. For all 3 reference segmentations, all 6 students agree that h 1 and h 2 are not equally similar to r; in fact, they prefer the candidate segmentation that has the smallest relative impact on the segments being transposed. The document presented to students and the tally of their responses is available in Appendix A.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Error Quantification", "text": "We quantify the likelihood of WindowDiff and B behaving erroneously through simulation 7 . For the three main error types described in Section 4, we first instantiate every possible reference segmentation r for sequences of length n \u2208 [5,20]. We then try to find two alternate segmentations h 1 and h 2 that B or WindowDiff score as equally similar to r, but in fact are not. Finally, for both B and WindowDiff, we present the ratio of reference segmentations r of length n for which such errorproducing pairs h 1 and h 2 exist. We also include A in our simulations and verify that it does not behave erroneously in any of the tested scenarios, so it is not included in our discussion.\nTo simplify our analysis, we use the Lampriercorrected version of WindowDiff (Lamprier et al., 2007), which pads the beginning and end of the sequence with k \u2212 1 elements. The number of errors produced by this version is a lower bound on the number of errors produced by the original Win-dowDiff, which penalizes boundary mismatches at the edges less than those at the center.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Cross-Boundary Transpositions", "text": "We consider B and WindowDiff (WD) to behave erroneously if a pair of segmentations h 1 and h 2 are judged equally similar to r, where h 2 pseudotransposes a boundary by x units, crossing an existing boundary from r, and h 1 performs a standard transposition on any boundary, i.e., does not transpose across boundaries, also by x units. We only consider h 1 where the two segments on either side of the transposed boundary have Jaccard > 0.5 with their corresponding original segments in r, i.e. the transposition can reasonably be considered a \"soft\" mistake where the affected segments are still more similar to the originals than not, in contrast to the pseudo-transposition in h 2 , where, by crossing a boundary, h 2 effectively oversegments one reference segment and undersegments another (Figure 10). Figure 13 shows the percentage of the reference segmentation space for which such erroneous pairs h 1 , h 2 exist, for both B and WD with various sequence lengths n. First, note that B and WD behave similarly; both B and WD penalize transpositions based solely on distance, so it is expected that they would judge any erroneous pair h 1 , h 2 to be equidistant to r if both h 1 , h 2 transpose one boundary by the same distance. Second, the relationship between the number of segments m and the total number of elements in the sequence n reveals an interesting trend: when the number of segments is too low or too high, it is impossible to construct erroneous pairs. For example, erroneous pairs cannot be constructed for m = 2 because there is no \"second\" boundary to transpose across; similarly, when m approaches n, the segments become unit-sized and can no longer be involved in either normal or cross-boundary transpositions. Thirdly, the increasing-decreasing behavior of the curves stems from the \"soft\" transposition constraint that we impose on h 1 . It can be shown that the smallest possible sizes for two adjacent segments containing a \"soft\" transposition are 5 and 3; this is because the minimum (pseudo-)transposition distance required to cross a boundary is 2 units. Once m is large enough that the average segment size is less than 3, it becomes increasingly hard to find such adjacent segments of sizes 5 and 3, so the number of erroneous h 1 , h 2 pairs decreases steadily.", "publication_ref": [], "figure_ref": ["fig_0", "fig_0"], "table_ref": []}, {"heading": "Constant Cost Transpositions", "text": "Here, B and WD behave erroneously if a pair of segmentations h 1 and h 2 are judged equally similar to r, where h 1 \"soft\" transposes a boundary by x units, and h 2 \"hard\" transposes any boundary by x units, i.e., the segments on either side of the transposition in h 2 have Jaccard < 0.5 with their corresponding original segments in r. The trend in Figure 14 can be explained as follows: if the ratio between the number of segments m and the sequence length n is too low, the segments are so large that it is rare to find a pair of segments such that transposing their boundary results in a \"hard\" error; conversely, when the ratio is too high, all segments are small, so it becomes increasingly hard to find \"soft\" transpositions. Like in Figure 10, B and WD follow the same trend because h 1 , h 2 transpose by the same number of units; in addition, we see once again that the number of erroneous pairs starts decreasing once the average segment size (m/n ratio) drops below 3.", "publication_ref": [], "figure_ref": ["fig_0", "fig_0"], "table_ref": []}, {"heading": "Vanishing Transpositions", "text": "Here, B and WD behave erroneously if a pair of segmentations h 1 and h 2 are judged equally similar to r, where h 1 transposes a boundary by x units and h 2 transposes the same boundary by y > x units. Again, we only consider h 1 with \"soft\" transpositions, where the two segments on either side of the transposed boundary have Jaccard > 0.5 with the corresponding original segments from r; h 2 may have a \"soft\" or \"hard\" transposition.\nFigure 15 differs from Figures 13 and 14 in that B and WD behave differently for this error type, which makes sense, given that this is the only ex- periment where h 1 , h 2 do not transpose by the same number of units: recall that B has a fixed maximum transposition size (default value of 1) beyond which transpositions can not be distinguished, while WD's maximum transposition size depends on the window size k, which is equal to half the average segment size, and thus a function of m and n. The global peak in error rate for WD occurs when k is so small that no transpositions are allowed; B makes fewer mistakes than WD because B always allows transpositions of size 1. The local minimum between the first and second maxima for WD is caused by the step-wise nature of the k function, since the window size must be a whole number.", "publication_ref": [], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Limitations", "text": "While we have seen that A performs favorably when compared to B and WindowDiff, further investigation may be warranted on the general MLA approach. First, the space of potential alignments for a given pair of segmentations can be quite large, and while a simple greedy intersection ratio approach generates sensible alignments, edge cases may exhibit undesirable behavior.\nConsider Figure 16: h 0 deletes a boundary from r, while h 1 and h 2 transpose it different distances. However, A gives h 2 a worse score than h 0 ; this behavior is explained by the MLA between r and h 2 containing a diagonal alignment between the first segment in h 2 and the second segment in r, due to the first segment in r being very small -so small that transposing its boundary by two units is considered worse than deleting it. The intersect ratio closeness function in A uses segment size to distinguish \"soft\" and \"hard\" transpositions; as we saw in Figure 12, when the segments are longer, A will match the left and right segments of a twounit transposition with the original segments in r, resulting in a similarity score greater than h 0 . However, specific applications may lean towards favoring \"soft\" transpositions over deletions regardless of segment size, which would require a) a different segment-to-segment closeness function c, or b) maximizing some global MLA function, such as Maximum Spanning Tree.\nSecond, in Figure 9, we presented a reference segmentation r and two different candidate segmentations h 1 and h 2 that are scored equally by A, B, and WD. Here, the fact that A can not distinguish between them is not due to the MLA, as there is only one possible alignment between each candidate and r. Thus, it may be of interest to develop more sophisticated MLA scoring functions, in order to distinguish between h 1 and h 2 .", "publication_ref": [], "figure_ref": ["fig_0", "fig_0", "fig_10"], "table_ref": []}, {"heading": "Conclusion", "text": "In this paper, we present a new alignment-based approach to text segmentation similarity scoring and present a new similarity metric A. We show that, unlike A, the most advanced segmentation similarity metrics, B and WindowDiff, behave erratically in three key scenarios. We discuss the versatility of alignment-based approaches when paired with different alignment and scoring functions, and show that A, B, and WindowDiff exhibit intricate behaviors that should be explored in the future. We make our implementation of A publicly available 8 in hope that it encourages the NLP community to explore more sophisticated approaches to text segmentation similarity scoring. The students achieved perfect agreement on the evaluation and judged as more similar the candidate segmentation with the smallest impact on the gold segments.\nInstance H1 Votes H2 Votes Same Votes AT 0 6 0 RTC 6 0 0 VT 6 0 0 ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A Human Judgement Test", "text": "The following text was presented to 6 graduate NLP students to verify their sensibility to crossboundary transposition, constant cost transposition, and vanishing transposition errors. For clarity, we have added error type labels to the questions, but the students were not shown these labels during the evaluation.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Statistical models for text segmentation. Machine learning", "journal": "", "year": "1999", "authors": "Doug Beeferman; Adam Berger; John Lafferty"}, {"ref_id": "b1", "title": "Natural language processing with Python: analyzing text with the natural language toolkit", "journal": "Reilly Media, Inc", "year": "2009", "authors": "Steven Bird; Ewan Klein; Edward Loper"}, {"ref_id": "b2", "title": "Generalized hamming distance", "journal": "Inf. Retr", "year": "2002", "authors": "Abraham Bookstein; Vladimir A Kulyukin; Timo Raita"}, {"ref_id": "b3", "title": "A technique for computer detection and correction of spelling errors", "journal": "Commun. ACM", "year": "1964", "authors": "Fred J Damerau"}, {"ref_id": "b4", "title": "Evaluating text segmentation using boundary edit distance", "journal": "Long Papers", "year": "2013", "authors": "Chris Fournier"}, {"ref_id": "b5", "title": "Segmentation similarity and agreement", "journal": "Association for Computational Linguistics", "year": "2012", "authors": "Chris Fournier; Diana Inkpen"}, {"ref_id": "b6", "title": "On evaluation methodologies for text segmentation algorithms", "journal": "", "year": "2007", "authors": "Tassadit Sylvain Lamprier; Bernard Amghar; Frederic Levrat;  Saubion"}, {"ref_id": "b7", "title": "Binary codes capable of correcting deletions, insertions and reversals", "journal": "", "year": "1966", "authors": "Vladimir I Levenshtein"}, {"ref_id": "b8", "title": "A critique and improvement of an evaluation metric for text segmentation", "journal": "Computational Linguistics", "year": "2002", "authors": "Lev Pevzner; Marti A Hearst"}, {"ref_id": "b9", "title": "Getting more from segmentation evaluation", "journal": "Association for Computational Linguistics", "year": "2012", "authors": "Martin Scaiano; Diana Inkpen"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "SFigure 1 :1Figure 1: Example segmentation with Q = 00100.", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "h 11Dogs are cute Very fast cars h 2 Dogs are cute Very fast cars", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 2 :2Figure 2: Alternate segmentations to S from Figure 1.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 3 :3Figure 3: Three similar segmentations.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 4 :4Figure 4: Illustration of P k and WindowDiff with k = 4 (Pevzner and Hearst, 2002). Penalized windows indicated by dashed lines.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "are both based on the same set of boundary edit operations: \u2022 Match: Mark a boundary as correct (no cost). \u2022 Addition/Deletion: Insert or delete a boundary. \u2022 K-Transposition: Shift a boundary to the left or right by a max of k units 2 . Default k = 1 3 . \u2022 Substitution: Replace a boundary with one of a different type 4 .", "figure_data": ""}, {"figure_label": "6", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Figure 6 :6Figure 6: Sample maximum likelihood alignment.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": ",h2,fn: c): for each segment p in h1 | for each p-overlapping segment q in h2 | | closeness = c(p,q) | r = max c(p,x) segment in h2 | align p (source) to r (target) repeat for h2 return list of alignment edges", "figure_data": ""}, {"figure_label": "7", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "Figure 7 :7Figure 7: Maximum likelihood alignment algorithm.", "figure_data": ""}, {"figure_label": "8", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "Figure 8 :8Figure 8: Maximum likelihood alignment.", "figure_data": ""}, {"figure_label": "9", "figure_type": "figure", "figure_id": "fig_10", "figure_caption": "Figure 9 :9Figure 9: Reference segmentation and two candidates.", "figure_data": ""}, {"figure_label": "11", "figure_type": "figure", "figure_id": "fig_11", "figure_caption": "Figure 11 :11Figure 10: Cross-boundary pseudo-transposition.", "figure_data": ""}, {"figure_label": "13", "figure_type": "figure", "figure_id": "fig_12", "figure_caption": "Figure 13 :13Figure 13: Ratio of potential cross-transposition errors for B and WindowDiff.", "figure_data": ""}, {"figure_label": "14", "figure_type": "figure", "figure_id": "fig_13", "figure_caption": "Figure 14 :14Figure 14: Ratio of potential constant cost transposition errors for B and WindowDiff.", "figure_data": ""}, {"figure_label": "15", "figure_type": "figure", "figure_id": "fig_14", "figure_caption": "Figure 15 :15Figure 15: Ratio of potential vanishing transposition errors for B and WindowDiff.", "figure_data": ""}, {"figure_label": "16", "figure_type": "figure", "figure_id": "fig_15", "figure_caption": "Figure 16 :16Figure 16: Intricate behavior of A.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_16", "figure_caption": "Intro====Asegmentation splits a sequence of elements into meaningful, non-overlapping segments. Ex. Split a transcript into utterances: I did not go to work yesterday, did you? | No, Johnathan filled in for me. Note: For simplicity, the elements in every segmentation example are masked. The previous example would look like this: A.A.A.A.A.A.A.A.A|B.B.B.B.B.B Questions=== For each of the following instances, 3 segmentations are presented: Gold, H1, and H2. Determine whether H1 or H2 is closer to gold, or if they are the same, according to your interpretation. -AT [Cross-Boundary Transposition (LABEL NOT SHOWN)] A|B|C.C.C.C.C.C.C.C.C.C|D.D.D.D.D.D.D.D.D.D -Gold A.B|C|C.C.C.C.C.C.C.C.C|D.D.D.D.D.D.D.D.D.D -H1 A|B|C.C.C.C.C.C.C.C.C.C|D.D.D.D.D.D.D.D.D.D -Gold A|B|C.C.C.C.C.C.C.C.C.C.D.D|D.D.D.D.D.D.D.D -H2 -RTC [Constant Cost Transposition (LABEL NOT SHOWN)] A|B.B|C.C.C.C.C.C.C.C|D.D.D.D.D.D.D.D -Gold A|B.B|C.C.C.C.C.C.C.C.D|D.D.D.D.D.D.D -H1 A|B.B|C.C.C.C.C.C.C.C|D.D.D.D.D.D.D.D -Gold A.B|B|C.C.C.C.C.C.C.C|D.D.D.D.D.D.D.D -H2 -VT [Vanishing Transposition (LABEL NOT SHOWN)] A.A.A.A.A.A.A.A|B.B.B.B.B.B.B.B -Gold A.A.A.A.A.A.A.A.B.B|B.B.B.B.B.B -H1 A.A.A.A.A.A.A.A|B.B.B.B.B.B.B.B -Gold A.A.A.A.A.A.A.A.B.B.B|B.B.B.B.B -H2", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "P k (r, h) = 1 n \u2212 k i=n\u2212k i=1,j=i+k \u03b4(r i,j ) \u0338 = \u03b4(h i,j )", "formula_coordinates": [2.0, 82.02, 740.91, 195.94, 37.57]}, {"formula_id": "formula_1", "formula_text": "WD(r, h) = 1 n \u2212 k i=n\u2212k i=1,j=i+k b(r i,j ) \u0338 = b(h i,j )", "formula_coordinates": [2.0, 314.86, 430.94, 200.84, 37.57]}, {"formula_id": "formula_2", "formula_text": "S(h 1 , h 2 , T ) = 1 \u2212 |A e | + |T e | + |S e | b(|T | \u2212 1)", "formula_coordinates": [3.0, 330.02, 390.64, 169.34, 33.79]}, {"formula_id": "formula_3", "formula_text": "B(h 1 , h 2 , T ) = 1 \u2212 |A e | + t(T e , k) + s(S e , B t ) |A e | + |T e | + |S e | + |M |", "formula_coordinates": [3.0, 308.54, 632.9, 212.29, 33.79]}, {"formula_id": "formula_4", "formula_text": "i(x, y) = intersect(x, y) |x|", "formula_coordinates": [4.0, 361.15, 502.64, 107.08, 35.42]}, {"formula_id": "formula_5", "formula_text": "A(h 1 , h 2 , c, g) = edge\u2208MLA(h 1 ,h 2 ,c) g(edge) # edges in MLA(h 1 , h 2 , c)", "formula_coordinates": [5.0, 79.78, 261.69, 199.24, 28.77]}, {"formula_id": "formula_6", "formula_text": "J(S, T ) = |intersect(S, T )| |union(S, T )|", "formula_coordinates": [5.0, 118.53, 499.6, 121.74, 33.79]}, {"formula_id": "formula_7", "formula_text": "h 1a h 1b h 2a h 2b h 3a h 3b h 4a h 4b h 5a h 5b Pair A B (k=1) 1 \u2212 WD (k=2) (h 1a , h 1b ) 0.", "formula_coordinates": [6.0, 313.32, 74.51, 200.83, 239.84]}], "doi": "10.1023/A:1020499411651"}