{"title": "RETHINKING THE EXPRESSIVE POWER OF GNNS VIA GRAPH BICONNECTIVITY", "authors": "Bohang Zhang; Shengjie Luo; Liwei Wang; Di He", "pub_date": "2024-02-11", "abstract": "Designing expressive Graph Neural Networks (GNNs) is a central topic in learning graph-structured data. While numerous approaches have been proposed to improve GNNs in terms of the Weisfeiler-Lehman (WL) test, generally there is still a lack of deep understanding of what additional power they can systematically and provably gain. In this paper, we take a fundamentally different perspective to study the expressive power of GNNs beyond the WL test. Specifically, we introduce a novel class of expressivity metrics via graph biconnectivity and highlight their importance in both theory and practice. As biconnectivity can be easily calculated using simple algorithms that have linear computational costs, it is natural to expect that popular GNNs can learn it easily as well. However, after a thorough review of prior GNN architectures, we surprisingly find that most of them are not expressive for any of these metrics. The only exception is the ESAN framework , for which we give a theoretical justification of its power. We proceed to introduce a principled and more efficient approach, called the Generalized Distance Weisfeiler-Lehman (GD-WL), which is provably expressive for all biconnectivity metrics. Practically, we show GD-WL can be implemented by a Transformer-like architecture that preserves expressiveness and enjoys full parallelizability. A set of experiments on both synthetic and real datasets demonstrates that our approach can consistently outperform prior GNN architectures.", "sections": [{"heading": "INTRODUCTION", "text": "Graph neural networks (GNNs) have recently become the dominant approach for graph representation learning. Among numerous architectures, message-passing neural networks (MPNNs) are arguably the most popular design paradigm and have achieved great success in various fields Kipf & Welling, 2017;). However, one major drawback of MPNNs lies in the limited expressiveness: as pointed out by ; Morris et al. (2019), they can never be more powerful than the classic 1-dimensional Weisfeiler-Lehman (1-WL) test in distinguishing non-isomorphic graphs (Weisfeiler & Leman, 1968). This inspired a variety of works to design provably more powerful GNNs that go beyond the 1-WL test.\nOne line of subsequent works aimed to propose GNNs that match the higher-order WL variants (Morris et al., 2019;Maron et al., 2019c;a;Geerts & Reutter, 2022). While being highly expressive, such an approach suffers from severe computation/memory costs. Moreover, there have been concerns about whether the achieved expressiveness is necessary for real-world tasks (Veli\u010dkovi\u0107, 2022). In light of this, other recent works sought to develop new GNN architectures with improved expressiveness while still keeping the message-passing framework for efficiency Bodnar et al., 2021b;a;Wijesinghe & Wang, 2022, and see Appendix A for more recent advances). However, most of these works mainly justify their expressiveness by giving toy examples where WL algorithms fail to distinguish, e.g., by focusing on regular graphs. On the theoretical side, it is quite unclear what additional power they can systematically and provably gain. More fundamentally, to the best of our knowledge (see Appendix D.1), there is still a lack of principled and convincing metrics beyond the WL hierarchy to formally measure the expressive power and to guide the design of provably better GNN architectures. In this paper, we systematically study the problem of designing expressive GNNs from a novel perspective of graph biconnectivity. Biconnectivity has long been a central topic in graph theory (Bollob\u00e1s, 1998). It comprises a series of important concepts such as cut vertex (articulation point), cut edge (bridge), biconnected component, and block cut tree (see Section 2 for formal definitions).\nIntuitively, biconnectivity provides a structural description of a graph by decomposing it into disjoint sub-components and linking them via cut vertices/edges to form a tree structure (cf. Figure 1(b,c)).\nAs can be seen, biconnectivity purely captures the intrinsic structure of a graph.\nThe significance of graph biconnectivity can be reflected in various aspects. Firstly, from a theoretical point of view, it is a basic graph property and is linked to many fundamental topics in graph theory, ranging from path-related problems to network flow (Granot & Veinott Jr, 1985) and spanning trees (Kapoor & Ramesh, 1995), and is highly relevant to planar graph isomorphism (Hopcroft & Tarjan, 1972). Secondly, from a practical point of view, cut vertices/edges have substantial values in many real applications. For example, chemical reactions are highly related to edge-biconnectivity of the molecule graph, where the breakage of molecular bonds usually occurs at the cut edges and each biconnected component often remains unchanged after the reaction. As another example, social networks are related to vertex-biconnectivity, where cut vertices play an important role in linking between different groups of people (biconnected components). Finally, from a computational point of view, the problems related to biconnectivity (e.g., finding cut vertices/edges or constructing block cut trees) can all be efficiently solved using classic algorithms (Tarjan, 1972), with a computation complexity equal to graph size (which is the same as an MPNN). Therefore, one may naturally expect that popular GNNs should be able to learn all things related to biconnectivity without difficulty.\nUnfortunately, we show this is not the case. After a thorough analysis of four classes of representative GNN architectures in literature (see Section 3.1), we find that surprisingly, none of them could even solve the easiest biconnectivity problem: to distinguish whether a graph has cut vertices/edges or not (corresponding to a graph-level binary classification). As a result, they obviously failed in the following harder tasks: (i) identifying all cut vertices (a node-level task); (ii) identifying all cut edges (an edge-level task); (iii) the graph-level task for general biconnectivity problems, e.g., distinguishing a pair of graphs that have non-isomorphic block cut trees. This raises the following question: can we design GNNs with provable expressiveness for biconnectivity problems?\nWe first give an affirmative answer to the above question. By conducting a deep analysis of the recently proposed Equivariant Subgraph Aggregation Network (ESAN) , we prove that the DSS-WL algorithm with node marking policy can precisely identify both cut vertices and cut edges. This provides a new understanding as well as a strong theoretical justification for the expressive power of DSS-WL and its recent extensions . Furthermore, we give a fine-grained analysis of several key factors in the framework, such as the graph generation policy and the aggregation scheme, by showing that neither (i) the ego-network policy without marking nor (ii) a variant of the weaker DS-WL algorithm can identify cut vertices.\nHowever, GNNs designed based on DSS-WL are usually sophisticated and suffer from high computation/memory costs. The main contribution in this paper is then to give a principled and efficient way to design GNNs that are expressive for biconnectivity problems. Targeting this question, we restart from the classic 1-WL algorithm and figure out a major weakness in distinguishing biconnectivity: the lack of distance information between nodes. Indeed, the importance of distance information is theoretically justified in our proof for analyzing the expressive power of DSS-WL.\nTo this end, we introduce a novel color refinement framework, formalized as Generalized Distance Weisfeiler-Lehman (GD-WL), by directly encoding a general distance metric into the WL aggrega-Table 1: Summary of theoretical results on the expressive power of different GNN models for various biconnectivity problems. We also list the time/space complexity (per WL iteration) for each WL algorithm, where n and m are the number of nodes and edges of a graph, respectively. tion procedure. We first prove that as a special case, the Shortest Path Distance WL (SPD-WL) is expressive for all edge-biconnectivity problems, thus providing a novel understanding of its empirical success. However, it still cannot identify cut vertices. We further suggest an alternative called the Resistance Distance WL (RD-WL) for vertex-biconnectivity. To sum up, all biconnectivity problems can be provably solved within our proposed GD-WL framework.\nFinally, we give a worst-case analysis of the proposed GD-WL framework. We discuss its limitations by proving that the expressive power of both SPD-WL and RD-WL can be bounded by the standard 2-FWL test (Cai et al., 1992). Consequently, 2-FWL is fully expressive for all biconnectivity metrics. Besides, since GD-WL heavily relies on distance information, we proceed to analyze its power in distinguishing the class of distance-regular graphs (Brouwer et al., 1989). Surprisingly, we show GD-WL matches the power of 2-FWL in this case, which strongly justifies its high expressiveness in distinguishing hard graphs. A summary of our theoretical contributions is given in Table 1.\nis a vertex-biconnected component of G if G[S] is vertex-biconnected and for any proper superset T \u228b S, G[T ] is not vertex-biconnected. We can similarly define the concepts of cut edge (or bridge) and edge-biconnected component (we omit them for brevity). Finally, denote BCC V (G) (resp. BCC E (G)) as the set of all vertex-biconnected (resp. edge-biconnected) components.\nTwo non-adjacent nodes u, v \u2208 V are in the same vertex-biconnected component iff there are two paths from u to v that do not intersect (except at endpoints). Two nodes u, v are in the same edgebiconnected component iff there are two paths from u to v that do not share an edge. On the other hand, if two nodes are in different vertex/edge-biconnected components, any path between them must go through some cut vertex/edge. Therefore, cut vertices/edges can be regarded as \"hubs\" in a graph that link different subgraphs into a whole. Furthermore, the link between cut vertices/edges and biconnected components forms a tree structure, which are called the block cut tree (cf. Figure 1). Definition 2.3. (Block cut-edge tree) The block cut-edge tree of graph G = (V, E) is defined as follows: BCETree(G) := (BCC E (G), E E ), where E E := {S 1 , S 2 } : S 1 , S 2 \u2208 BCC E (G), \u2203u \u2208 S 1 , v \u2208 S 2 , s.t. {u, v} \u2208 E . Definition 2.4. (Block cut-vertex tree) The block cut-vertex tree of graph G = (V, E) is defined as follows: BCVTree(G) := (BCC V (G) \u222a V Cut , E V ), where V Cut \u2282 V is the set containing all cut vertices of G and E V := {S, v} : S \u2208 BCC V (G), v \u2208 V Cut , v \u2208 S . The following theorem shows that all concepts related to biconnectivity can be efficiently computed. Theorem 2.5. (Tarjan, 1972) The problems related to biconnectivity, including identifying all cut vertices/edges, finding all biconnected components (BCC V (G) and BCC E (G)), and building block cut trees (BCVTree(G) and BCETree(G)), can all be solved using the Depth-First Search algorithm, within a computation complexity linear in the graph size, i.e. \u0398(|V| + |E|).\nIsomorphism and color refinement algorithms. Two graphs G = (V G , E G ) and H = (V H , E H ) are isomorphic (denoted as G \u2243 H) if there is an isomorphism (bijective mapping) f : V G \u2192 V H such that for any nodes u, v \u2208 V G , {u, v} \u2208 E G iff {f (u), f (v)} \u2208 E H . A color refinement algorithm is an algorithm that outputs a color mapping \u03c7 G : V G \u2192 C when taking graph G as input, where C is called the color set. A valid color refinement algorithm must preserve invariance under isomorphism, i.e., \u03c7 G (u) = \u03c7 H (f (u)) for isomorphism f and node u \u2208 V G . As a result, it can be used as a necessary test for graph isomorphism by comparing the multisets {{\u03c7 G (u) : u \u2208 V G }} and {{\u03c7 H (u) : u \u2208 V H }}, which we call the graph representations. Similarly, \u03c7 G (u) can be seen as the node feature of u \u2208 V G , and {{\u03c7 G (u), \u03c7 G (v)}} corresponds to the edge feature of {u, v} \u2208 E G . All algorithms studied in this paper fit the color refinement framework, and please refer to Appendix B for a precise description of several representatives (e.g., the classic 1-WL and k-FWL algorithms).\nProblem setup. This paper focuses on the following three types of problems with increasing difficulties. Firstly, we say a color refinement algorithm can distinguish whether a graph is vertex/edgebiconnected, if for any graphs G, H where G is vertex/edge-biconnected but H is not, their graph representations are different\n, i.e. {{\u03c7 G (u) : u \u2208 V G }} \u0338 = {{\u03c7 H (u) : u \u2208 V H }}.\nSecondly, we say a color refinement algorithm can identify cut vertices if for any graphs G, H and nodes\nu \u2208 V G , v \u2208 V H where u is a cut vertex but v is not, their node features are different, i.e. \u03c7 G (u) \u0338 = \u03c7 H (v). Similarly, it can identify cut edges if for any {u, v} \u2208 E G and {w, x} \u2208 E H where {u, v} is a cut edge but {w, x} is not, their edge features are different, i.e. {{\u03c7 G (u), \u03c7 G (v)}} \u0338 = {{\u03c7 H (w), \u03c7 H (x)}}.\nFinally, we say a color refinement algorithm can distinguish block cut-vertex/edge trees, if for any graphs G, H satisfying BCVTree(G)\n\u0338 \u2243 BCVTree(H) (or BCETree(G) \u0338 \u2243 BCETree(H)), their graph representations are different, i.e. {{\u03c7 G (u) : u \u2208 V G }} \u0338 = {{\u03c7 H (u) : u \u2208 V H }}.", "publication_ref": ["b47", "b59", "b85", "b59", "b57", "b33", "b81", "b13", "b14", "b35", "b43", "b39", "b75", "b18", "b17", "b75"], "figure_ref": ["fig_0", "fig_0"], "table_ref": []}, {"heading": "INVESTIGATING KNOWN GNN ARCHITECTURES VIA BICONNECTIVITY", "text": "In this section, we provide a comprehensive investigation of popular GNN variants in literature, including the classic MPNNs, Graph Substructure Networks (GSN)  and its variant (Barcel\u00f3 et al., 2021), GNN with lifting transformations (MPSN and CWN) (Bodnar et al., 2021b;a), GraphSNN (Wijesinghe & Wang, 2022), and Subgraph GNNs (e.g., ). Surprisingly, we find most of these works are not expressive for any biconnectivity problems listed above. The only exceptions are the ESAN  and several variants, where we give a rigorous justification of their expressive power for both vertex/edge-biconnectivity. . Graphs in the first row have cut vertices (outlined in bold red) and some also have cut edges (denoted as red lines), while graphs in the second row do not have any cut vertex or cut edge.", "publication_ref": ["b10", "b13"], "figure_ref": [], "table_ref": []}, {"heading": "COUNTEREXAMPLES", "text": "1-WL/MPNNs. We first consider the classic 1-WL. We provide two principled class of counterexamples which are formally defined in Examples C.9 and C.10, with a few special cases illustrated in Figure 2. For each pair of graphs in Figure 2, the color of each node is drawn according to the 1-WL color mapping. It can be seen that the two graph representations are the same. Therefore, 1-WL cannot distinguish any biconnectivity problem listed in Section 2.\nSubstructure Counting WL/GSN.  developed a principled approach to boost the expressiveness of MPNNs by incorporating substructure counts into node features or the 1-WL aggregation procedure. The resulting algorithm, which we call the SC-WL, is detailed in Appendix B.3. However, we show no matter what sub-structures are used, the corresponding GSN still cannot solve any biconnectivity problem listed in Section 2. We give a proof in Appendix C.2 for the general case that allows arbitrary substructures, based on Examples C.9 and C.10. We also point out that our negative result applies to the similar GNN variant in Barcel\u00f3 et al. (2021).  (Zhao et al., 2022), andNGNN (Zhang &Li, 2021). Due to space limit, we defer the corresponding negative results in Propositions C.13, C.15 and C.16.\nTheorem 3.1. Let H = {H 1 , \u2022 \u2022 \u2022 , H k }, H i = (V i , E i )", "publication_ref": ["b10", "b51"], "figure_ref": ["fig_1", "fig_1"], "table_ref": []}, {"heading": "PROVABLE EXPRESSIVENESS OF ESAN AND DSS-WL", "text": "We next switch our attention to a new type of GNN framework proposed in , called the Equivariant Subgraph Aggregation Networks (ESAN). The central algorithm in EASN is called the DSS-WL. Given a graph G, DSS-WL first generates a bag of vertex-shared (sub)graphs\nB \u03c0 G = {{G 1 , \u2022 \u2022 \u2022 , G m }}\naccording to a graph generation policy \u03c0. Then in each iteration t, the algorithm refines the color of each node v in each subgraph G i by jointly aggregating its neighboring colors in the own subgraph and across all subgraphs. The aggregation formula can be written as:\nA fundamental question regarding DSS-WL is how expressive it is. While a straightforward analysis shows that DSS-WL is strictly more powerful than 1-WL, an in-depth understanding on what additional power DSS-WL gains over 1-WL is still limited. The only new result is the very recent work of , who showed a 3-WL upper bound for the expressivity of DSS-WL. Yet, such a result actually gives a limitation of DSS-WL rather than showing its power. Moreover, there is a large gap between the highly strong 3-WL and the weak 1-WL. In the following, we take a different perspective and prove that DSS-WL is expressive for both types of biconnectivity problems. Theorem 3.2. Let G = (V G , E G ) and H = (V H , E H ) be two graphs, and let \u03c7 G and \u03c7 H be the corresponding DSS-WL color mapping with node marking policy. Then the following holds:\n\u2022 For any two nodes w \u2208 V G and x \u2208 V H , if \u03c7 G (w) = \u03c7 H (x), then w is a cut vertex if and only if x is a cut vertex.\n\u2022 For any two edges {w 1 , w 2 } \u2208 E G and {x 1 , x 2 } \u2208 E H , if {{\u03c7 G (w 1 ), \u03c7 G (w 2 )}} = {{\u03c7 H (x 1 ), \u03c7 H (x 2 )}}, then {w 1 , w 2 } is a cut edge if and only if {x 1 , x 2 } is a cut edge.\nThe proof of Theorem 3.2 is highly technical and is deferred to Appendix C.3. By using the basic results derived in Appendix C.1, we conduct a careful analysis of the DSS-WL color mapping and discover several important properties. They give insights on why DSS-WL can succeed in distinguishing biconnectivity, as we will discuss below.\nHow can DSS-WL distinguish biconnectivity? We find that a crucial advantage of DSS-WL over the classic 1-WL is that DSS-WL color mapping implicitly encodes distance information (see Lemma C.19(e) and Corollary C.24). For example, two nodes u\n\u2208 V G , v \u2208 V H will have dif- ferent DSS-WL colors if the distance set {{dis G (u, w) : w \u2208 V G }} differs from {{dis H (v, w) : w \u2208 V H }}.\nOur proof highlights that distance information plays a vital role in distinguishing edgebiconnectivity when combining with color refinement algorithms (detailed in Section 4), and it also helps distinguish vertex-biconnectivity (see the proof of Lemma C.22). Consequently, our analysis provides a novel understanding and a strong justification for the success of DSS-WL in two aspects: the graph representation computed by DSS-WL intrinsically encodes distance and biconnectivity information, both of which are fundamental structural properties of graphs but are lacking in 1-WL.\nDiscussions on graph generation policies. Note that Theorem 3.2 holds for node marking policy.\nIn fact, the ability of DSS-WL to encode distance information heavily relies on node marking as shown in the proof of Lemma C.19. In contrast, we prove that the ego-network policy \u03c0 EGO(k) cannot distinguish cut vertices (Proposition C.14), using the counterexample given in Figure 2(c). Therefore, our result shows an inherent advantage of node marking than the ego-network policy in distinguishing a class of non-isomorphic graphs, which is raised as an open question in Bevilacqua et al. (2022, Section 5). It also highlights a theoretical limitation of \u03c0 EGO(k) compared with its node marking version \u03c0 EGOM(k) , a subtle difference that may not have received sufficient attention yet. For example, both the GNN-AK and GNN-AK-ctx architecture (Zhao et al., 2022) cannot solve vertex-biconnectivity problems since it is similar to \u03c0 EGO(k) (see Proposition C.15). On the other hand, the GNN-AK+ does not suffer from such a drawback although it also uses \u03c0 EGO(k) , because it further adds distance encoding in each subgraph (which is more expressive than node marking).\nDiscussions on DS-WL. ; Cotta et al. (2021) also considered a weaker version of DSS-WL, called the DS-WL, which aggregates the node color in each subgraph without interaction across different subgraphs (see formula ( 10)). We show in Proposition C.16 that unfortunately, DS-WL with common node-based policies cannot identify cut vertices when the color of each node v is defined as its associated subgraph representation G v . This theoretically reveals the importance of cross-graph aggregation and justifies the design of DSS-WL. Finally, we point out that Qian et al. (2022) very recently proposed an extension of DS-WL that adds a final cross-graph aggregation procedure, for which our negative result may not hold. It may be an interesting direction to theoretically analyze the expressiveness of this type of DS-WL in future work.", "publication_ref": ["b51", "b23", "b66"], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "GENERALIZED DISTANCE WEISFEILER-LEHMAN TEST", "text": "After an extensive review of prior GNN architectures, in this section we would like to formally study the following problem: can we design a principled and efficient GNN framework with provable expressiveness for biconnectivity? In fact, while in Section 3.2 we have proved that DSS-WL can solve biconnectivity problems, it is still far from enough. Firstly, the corresponding GNNs based on DSS-WL is usually sophisticated due to the complex aggregation formula (1), which inspires us to study whether simpler architectures exist. More importantly, DSS-WL suffers from high computational costs in both time and memory. Indeed, it requires \u0398(n 2 ) space and \u0398(nm) time per iteration (using policy \u03c0 NM ) to compute node colors for a graph with n nodes and m edges, which is n times costly than 1-WL. Given the theoretical linear lower bound in Theorem 2.5, one may naturally raise the question of how to close the gap by developing more efficient color refinement algorithms.\nWe approach the problem by rethinking the classic 1-WL test. We argue that a major weakness of 1-WL is that it is agnostic to distance information between nodes, partly because each node can only \"see\" its neighbors in aggregation. On the other hand, the DSS-WL color mapping implicitly encodes distance information as shown in Section 3.2, which inspires us to formally study whether incorporating distance in the aggregation procedure is crucial for solving biconnectivity problems.\nTo this end, we introduce a novel color refinement framework which we call Generalized Distance Weisfeiler-Lehman (GD-WL). The update rule of GD-WL is very simple and can be written as:\n\u03c7 t G (v) := hash {{(d G (v, u), \u03c7 t\u22121 G (u)) : u \u2208 V}} ,(3)\nwhere d G can be an arbitrary distance metric. The full algorithm is described in Algorithm 4.\nSPD-WL for edge-biconnectivity. As a special case, when choosing the shortest path distance d G = dis G , we obtain an algorithm which we call SPD-WL. It can be equivalently written as\n\u03c7 t G (v) := hash \u03c7 t\u22121 G (v), {{\u03c7 t\u22121 G (u) : u \u2208 N G (v)}}, {{\u03c7 t\u22121 G (u) : dis G (v, u) = 2}}, \u2022 \u2022 \u2022 , {{\u03c7 t\u22121 G (u) : dis G (v, u) = n \u2212 1}}, {{\u03c7 t\u22121 G (u) : dis G (v, u) = \u221e}} .(4)\nFrom ( 4) it is clear that SPD-WL is strictly more powerful than 1-WL since it additionally aggregates the k-hop neighbors for all k > 1. There have been several prior works related to SPD-WL, including using distance encoding as node features  or performing k-hop aggregation for some small k (see Appendix D.2 for more related works and discussions). Yet, these works are either purely empirical or provide limited theoretical analysis (e.g., by focusing only on regular graphs). Instead, we introduce the general and more expressive SPD-WL framework with a rather different motivation and perform a systematic study on its expressive power. Our key result confirms that SPD-WL is fully expressive for all edge-biconnectivity problems listed in Section 2. Theorem 4.1. Let G = (V G , E G ) and H = (V H , E H ) be two graphs, and let \u03c7 G and \u03c7 H be the corresponding SPD-WL color mapping. Then the following holds:\n\u2022 For any two edges {w 1 , w 2 } \u2208 E G and {x 1 , x 2 } \u2208 E H , if {{\u03c7 G (w 1 ), \u03c7 G (w 2 )}} = {{\u03c7 H (x 1 ), \u03c7 H (x 2 )}}, then {w 1 , w 2 } is a cut edge if and only if {x 1 , x 2 } is a cut edge.\n\u2022 If {{\u03c7 G (w) : w \u2208 V G }} = {{\u03c7 H (w) : w \u2208 V H }}, then BCETree(G) \u2243 BCETree(H).\nTheorem 4.1 is highly non-trivial and perhaps surprising at first sight, as it combines three seemingly unrelated concepts (i.e., SPD, biconnectivity, and the WL test) into a unified conclusion. We give a proof in Appendix C.4, which separately considers two cases: \u03c7 G (w 1 ) \u0338 = \u03c7 G (w 2 ) and \u03c7 G (w 1 ) = \u03c7 G (w 2 ) (see Figure 2(b,d) for examples). For each case, the key technique in the proof is to construct an auxiliary graph (Definitions C.26 and C.34) that precisely characterizes the structural relationship between nodes that have specific colors (see Corollaries C.31 and C.40). Finally, we highlight that the second item of Theorem 4.1 may be particularly interesting: while distinguishing general nonisomorphic graphs are known to be hard (Cai et al., 1992;Babai, 2016), we show distinguishing non-isomorphic graphs with different block cut-edge trees can be much easily solved by SPD-WL.\nRD-WL for vertex-biconnectivity. Unfortunately, while SPD-WL is fully expressive for edgebiconnectivity, it is not expressive for vertex-biconnectivity. We give a simple counterexample in Figure 2(c), where SPD-WL cannot distinguish the two graphs. Nevertheless, we find that by using a different distance metric, problems related to vertex-biconnectivity can also be fully solved. We propose such a choice called the Resistance Distance (RD) (denoted as dis R G ), which is also a basic metric in graph theory (Doyle & Snell, 1984;Klein & Randi\u0107, 1993;Sanmart\u0131n et al., 2022). Formally, the value of dis R G (u, v) is defined to be the effective resistance between nodes u and v when treating G as an electrical network where each edge corresponds to a resistance of one ohm. We note that other generalized distances can also be considered Velingker et al., 2022). RD has many elegant properties. First, it is a valid metric: indeed, RD is non-negative, semidefinite, symmetric, and satisfies the triangular inequality (see Appendix E.2). Moreover, similar to SPD, we also have 0\n\u2264 dis R G (u, v) \u2264 n \u2212 1, and dis R G (u, v) = dis G (u, v) if G is a tree.\nIn Appendix E.2, we further show that RD is highly related to the graph Laplacian and can be efficiently calculated.\nTheorem 4.2. Let G = (V G , E G ) and H = (V H , E H ) be two graphs, and let \u03c7 G and \u03c7 H be the corresponding RD-WL color mapping. Then the following holds:\n\u2022 For any two nodes w \u2208 V G and x \u2208 V H , if \u03c7 G (w) = \u03c7 H (x), then w is a cut vertex if and only if x is a cut vertex.\n\u2022 If {{\u03c7 G (w) : w \u2208 V G }} = {{\u03c7 H (w) : w \u2208 V H }}, then BCVTree(G) \u2243 BCVTree(H).\nThe form of Theorem 4.2 exactly parallels Theorem 4.1, which shows that RD-WL is fully expressive for vertex-biconnectivity. We give a proof of Theorem 4.1 in Appendix C.5. In particular, the proof of the second item is highly technical due to the challenges in analyzing the (complex) structure of the block cut-vertex tree. It also highlights that distinguishing non-isomorphic graphs that have different BCVTrees is much easier than the general case.\nCombining Theorems 4.1 and 4.2 immediately yields the following corollary, showing that all biconnectivity problems can be solved within our proposed GD-WL framework.\nCorollary 4.3. When using both SPD and RD (i.e., by setting\nd G (u, v) := (dis G (u, v), dis R G (u, v))\n), the corresponding GD-WL is fully expressive for both vertex-biconnectivity and edge-biconnectivity.\nComputational cost. The GD-WL framework only needs a complexity of \u0398(n) space and \u0398(n 2 ) time per-iteration for a graph of n nodes and m edges, both of which are strictly less than DSS-WL. In particular, GD-WL has the same space complexity as 1-WL, which can be crucial for large-scale tasks. On the other hand, one may ask how much computational overhead there is in preprocessing pairwise distances between nodes. We show in Appendix E that the computational cost can be trivially upper bounded by O(nm) for SPD and O(n 3 ) for RD. Note that the preprocessing step only needs to be executed once, and we find that the cost is negligible compared to the GNN architecture.\nPractical implementation. One of the main advantages of GD-WL is its high degree of parallelizability. In particular, we find GD-WL can be easily implemented using a Transformer-like architecture by injecting distance information into Multi-head Attention (Vaswani et al., 2017), similar to the structural encoding in Graphormer (Ying et al., 2021a). The attention layer can be written as:\nY h = \u03d5 h 1 (D) \u2299 softmax XW h Q (XW h K ) \u22a4 + \u03d5 h 2 (D) XW h V ,(5)\nwhere X \u2208 R n\u00d7d is the input node features of the previous layer, D \u2208 R n\u00d7n is the distance matrix such that\nD uv = d G (u, v), W h Q , W h K , W h V \u2208 R d\u00d7d H\nare learnable weight matrices of the h-th head, \u03d5 h 1 and \u03d5 h 2 are elementwise functions applied to D (possibly parameterized), and \u2299 denotes the elementwise multiplication. The results Y h \u2208 R n\u00d7d H across all heads h are then combined and projected to obtain the final output\nY = h Y h W h O where W h O \u2208 R d H \u00d7d .\nWe call the resulting architecture Graphormer-GD, and the full structure of Graphormer-GD is provided in Appendix E.3.\nIt is easy to see that the mapping from X to Y in (5) is equivariant and simulates the GD-WL aggregation. Importantly, we have the following expressivity result, which precisely characterizes the power and limits of Graphormer-GD. We give a proof in Appendix E.3. Theorem 4.4. Graphormer-GD is at most as powerful as GD-WL in distinguishing non-isomorphic graphs. Moreover, when choosing proper functions \u03d5 h 1 and \u03d5 h 2 and using a sufficiently large number of heads and layers, Graphormer-GD is as powerful as GD-WL.\nOn the expressivity upper bound of GD-WL. To complete the theoretical analysis, we finally provide an upper bound of the expressive power for our proposed SPD-WL and RD-WL, by studying the relationship with the standard 2-FWL (3-WL) algorithm. Theorem 4.5. The 2-FWL algorithm is more powerful than both SPD-WL and RD-WL. Formally, the 2-FWL color mapping induces a finer vertex partition than that of both SPD-WL and RD-WL.\nWe give a proof in Appendix C.6. Using Theorem 4.5, we arrive at the important corollary: Corollary 4.6. The 2-FWL is fully expressive for both vertex-biconnectivity and edge-biconnectivity.\nA worst-case analysis of GD-WL for distance-regular graphs. Since GD-WL heavily relies on distance information, one may wonder about its expressiveness in the worst-case scenario where distance information may not help distinguish certain non-isomorphic graphs, in particular, the class of distance-regular graphs (Brouwer et al., 1989). Due to space limit, we provide a comprehensive study of this question in Appendix C.7, where we give a precise and complete characterization of  what types of distance-regular graphs SPD-WL/RD-WL/2-FWL can distinguish (with both theoretical results and counterexamples). The main result is present as follows: Theorem 4.7. RD-WL is strictly more powerful than SPD-WL in distinguishing non-isomorphic distance-regular graphs. Moreover, RD-WL is as powerful as 2-FWL in distinguishing nonisomorphic distance-regular graphs.\nThe above theorem strongly justifies the power of resistance distance and our proposed GD-WL. Importantly, to our knowledge, this is the first result showing that a more efficient WL algorithm can match the expressive power of 2-FWL in distinguishing distance-regular graphs.", "publication_ref": ["b18", "b8", "b25", "b48", "b68", "b83", "b80", "b86", "b17"], "figure_ref": ["fig_1", "fig_1"], "table_ref": []}, {"heading": "EXPERIMENTS", "text": "In this section, we perform empirical evaluations of our proposed Graphormer-GD. We mainly consider the following two sets of experiments. Firstly, we would like to verify whether Graphormer-GD can indeed learn biconnectivity-related metrics easily as our theory predicts. Secondly, we would like to investigate whether GNNs with sufficient expressiveness for biconnectivity can also help real-world tasks and benefit the generalization performance as well. The code and models will be made publicly available at https://github.com/lsj2408/Graphormer-GD. Synthetic tasks. To test the expressive power of GNNs for biconnectivity metrics, we separately consider two tasks: (i) Cut Vertex Detection and (ii) Cut Edge Detection. Given a GNN model that outputs node features, we add a learnable prediction head that takes each node feature (or two node features corresponding to each edge) as input and predicts whether it is a cut vertex (cut edge) or not. The evaluation metric for both tasks is the graph-level accuracy, i.e., given a graph, the model prediction is considered correct only when all the cut vertices/edges are correctly identified. To make the results convincing, we construct a challenging dataset that comprises various types of hard graphs, including the regular graphs with cut vertices/edges and also Examples C.9 and C.10 mentioned in Section 3. We also choose several GNN baselines with different levels of expressive power: (i) classic MPNNs (Kipf & Welling, 2017;; (ii) Graph Substructure Network ; (iii) Graphormer (Ying et al., 2021a). The details of model configurations, dataset, and training procedure are provided in Appendix F.1.\nThe results are presented in Table 2. It can be seen that baseline GNNs cannot perfectly solve these synthetic tasks. In contrast, the Graphormer-GD achieves 100% accuracy on both tasks, implying that it can easily learn biconnectivity metrics even in very difficult graphs. Moreover, while using only SPD suffices to identify cut edges, it is still necessary to further incorporate RD to identify cut vertices. This is consistent with our theoretical results in Theorems 4.1, 4.2 and 4.4.\nReal-world tasks. We further study the empirical performance of our Graphormer-GD on the realworld benchmark: ZINC from Benchmarking-GNNs . To show the scalability of Graphormer-GD, we train our models on both ZINC-Full (consisting of 250K molecular graphs) and ZINC-Subset (12K selected graphs). We comprehensively compare our model with prior ex- pressive GNNs that have been publicly released. For a fair comparison, we ensure that the parameter budget of both Graphormer-GD and other compared models are around 500K, following . Details of baselines and settings are presented in Appendix F.2.\nThe results are shown in Table 3, where our score is averaged over four experiments with different seeds. We also list the per-epoch training time of different models on ZINC-subset as well as their model parameters. It can be seen that Graphormer-GD surpasses or matches all competitive baselines on the test set of both ZINC-Subset and ZINC-Full. Furthermore, we find that the empirical performance of compared models align with their expressive power measured by graph biconnectivity. For example, Subgraph GNNs that are expressive for biconnectivity also consistently outperform classic MPNNs by a large margin. Compared with Subgraph GNNs, the main advantage of Graphormer-GD is that it is simpler to implement, has stronger parallelizability, while still achieving better performance. Therefore, we believe our proposed architecture is both effective and efficient and can be well extended to more practical scenarios like drug discovery.\nOther tasks. We also perform node-level experiments on two popular datasets: the Brazil-Airports and the Europe-Airports. Due to space limit, the results are shown in Appendix F.3.", "publication_ref": ["b47", "b86"], "figure_ref": [], "table_ref": ["tab_2", "tab_3"]}, {"heading": "CONCLUSION", "text": "In this paper, we systematically investigate the expressive power of GNNs via the perspective of graph biconnectivity. Through the novel lens, we gain strong theoretical insights into the power and limits of existing popular GNNs. We then introduce the principled GD-WL framework that is fully expressive for all biconnectivity metrics. We further design the Graphormer-GD architecture that is provably powerful while enjoying practical efficiency and parallelizability. Experiments on both synthetic and real-world datasets demonstrate the effectiveness of Graphormer-GD.\nThere are still many promising directions that have not yet been explored. Firstly, it remains an important open problem whether biconnectivity can be solved more efficiently in o(n 2 ) time using equivariant GNNs. Secondly, a deep understanding of GD-WL is generally lacking. For example, we conjecture that RD-WL can encode graph spectral  and is strictly more powerful than SPD-WL in distinguishing general graphs. Thirdly, it may be interesting to further investigate more expressive distance (structural) encoding schemes beyond RD-WL and explore how to encode them in Graph Transformers. Finally, one can extend biconnectivity to a hierarchy of higher-order variants (e.g., tri-connectivity), which provides a completely different view parallel to the WL hierarchy to study the expressive power and guide designing provably powerful GNNs architectures.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "ACKNOWLEDGMENTS", "text": "Bohang Zhang is grateful to Ruichen Li for his great help in discussing and checking several of the main results in this paper, including Theorems 3.1, 3.2, 4.1 and 4.7. In particular, after the initial submission, Ruichen Li discovered a simpler proof of Lemma C.28 and helped complete the proof of Theorem C.61. Bohang Zhang would also thank Yiheng Du, Kai Yang amd Ruichen Li for correcting some small mistakes in the proof of Lemmas C.20 and C.45. ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A RECENT ADVANCES IN EXPRESSIVE GNNS", "text": "Since the seminal works of ; Morris et al. (2019), extensive studies have devoted to developing new GNN architectures with better expressiveness beyond the 1-WL test. These works can be broadly classified into the following categories.\nHigher-order GNNs. One straightforward way to design provably more expressive GNNs is inspired by the higher-order WL tests (see Appendix B.2). Instead of performing node feature aggregation, these higher-order GNNs calculate a feature vector for each k-tuple of nodes (k \u2265 2) and perform aggregation between features of different tuples using tensor operations (Morris et al., 2019;Maron et al., 2019b;c;a;Keriven & Peyr\u00e9, 2019;Azizian & Lelarge, 2021;Geerts & Reutter, 2022). In particular,  leveraged equivariant matrix multiplication to design network layers that mimic the 2-FWL aggregation. Due to the huge computational cost of higher-order GNNs, several recent works considered improving efficiency by leveraging the sparse and local nature of graphs and designing a \"local\" version of the k-WL aggregation, which comes at the cost of some expressiveness (Morris et al., 2020;2022). The work of Vignac et al. (2020) can also be seen as a local 2-order GNN and its expressive power is bounded by 3-IGN (Maron et al., 2019c).\nSubstructure-based GNNs. Another way to design more expressive GNNs is inspired by studying the failure cases of 1-WL test. In particular, Chen et al. ( 2020) pointed out that standard MPNNs cannot detect/count common substructures such as cycles, cliques, and paths. Based on this finding,  designed the Graph Substructure Network (GSN) by incorporating substructure counting into node features using a preprocessing step. Such an approach was later extended by Barcel\u00f3 et al. (2021)  Subgraph GNNs. In fact, the graphs indistinguishable by 1-WL tend to possess a high degree of symmetry (e.g., see Figure 2). Based on this observation, a variety of recent approaches sought to break the symmetry by feeding subgraphs into an MPNN. To maintain equivariance, a set of subgraphs is generated symmetrically from the original graph using predefined policies, and the final output is aggregated across all subgraphs. There have been several subgraph generation policies in prior works, such as node deletion (Cotta et al., 2021), edge deletion , node marking (Papp & Wattenhofer, 2022), and ego-networks (Zhao et al., 2022;Zhang & Li, 2021;You et al., 2021). These works also slightly differ in the aggregation schemes. In particular,  developed a unified framework, called ESAN, which includes per-layer aggregation across subgraphs and thus enjoys better expressiveness. Very recently,  further extended the framework based on a more relaxed symmetry analysis and proved an upper bound of its expressiveness to be 3-WL. Qian et al. (2022) provided a theoretical analysis of how subgraph GNNs relate to k-FWL and also designed an approach to learn policies.\nNon-equivariant GNNs. Perhaps one of the simplest way to break the intrinsic symmetry of 1-WL aggregation is to use non-equivariant GNNs. Indeed, Loukas (2020) proved that if each node in a GNN is equipped with a unique identifier, then standard MPNNs can already be Turing universal.\nThere have been several works that exploit this idea to build powerful GNNs, such as using port numbering (Sato et al., 2019), relational pooling (Murphy et al., 2019), random features (Sato et al., 2021;Abboud et al., 2021), or dropout techniques (Papp et al., 2021). However, since the resulting architectures cannot fully preserve equivariance, the sample complexity required for training and generalization may not be guaranteed (Garg et al., 2020). Therefore, in this paper we only focus on analyzing and designing equivariant GNNs.  2022) utilized spectral information of graphs to achieve better expressiveness beyond 1-WL. Talak et al. (2021) proposed the Neural Tree Network that performs message passing between higher-order subgraphs instead of node-level aggregation.\nFinally, for a comprehensive survey on expressive GNNs, we refer readers to Sato (2020) and .", "publication_ref": ["b59", "b59", "b56", "b44", "b6", "b33", "b60", "b81", "b84", "b57", "b10", "b23", "b51", "b66", "b52", "b70", "b63", "b71", "b0", "b65", "b32", "b74", "b69"], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "B THE WEISFEILER-LEHMAN ALGORITHMS AND RECENTLY PROPOSED VARIANTS", "text": "In this section, we give a precise description on the family of Weisfeiler-Lehman algorithms and several recently proposed variants that are studied in this paper. We first present the classic 1-WL algorithm (Weisfeiler & Leman, 1968) and the more advanced k-FWL (Cai et al., 1992;Morris et al., 2019). Then we present several recently proposed WL variants, including WL with Substructure Counting (SC-WL) , Overlap Subgraph WL (OS-WL) (Wijesinghe & Wang, 2022), Equivariant Subgraph Aggregation WL (DSS-WL)  and Generalized Distance WL (GD-WL).\nThroughout this section, we assume hash : X \u2192 C is an injective hash function that can map \"arbitrary objects\" to a color in C where C is an abstract set called the color set. Formally, the domain X comprises all the objects we are interested in:\n\u2022 R \u2282 X and C \u2282 X ;\n\u2022 For any finite multiset M with elements in X , M \u2208 X ;\n\u2022 For any tuple c \u2208 X k of finite dimension k \u2208 N + , c \u2208 X .", "publication_ref": ["b85", "b18", "b59"], "figure_ref": [], "table_ref": []}, {"heading": "B.1 1-WL TEST", "text": "Given a graph G = (V, E), the 1-dimensional Weisfeiler-Lehman algorithm (1-WL), also called the color refinement algorithm, iteratively calculates a color mapping \u03c7 G from each vertex v \u2208 V to a color \u03c7 G (v) \u2208 C. The pseudo code of 1-WL is presented in Algorithm 1. Intuitively, at the beginning the color of each vertex is initialized to be the same. Then in each iteration, 1-WL algorithm updates each vertex color by combining its own color with the neighborhood color multiset using a hash function. This procedure is repeated for a sufficiently large number of iterations T , e.g. T = |V|. \nv \u2208 V for t \u2190 1 to T do for each v \u2208 V do \u03c7 t G (v) := hash \u03c7 t\u22121 G (v), {{\u03c7 t\u22121 G (u) : u \u2208 N G (v)}} Return: \u03c7 T G\nAt each iteration, the color mapping \u03c7 t G induces a partition of the vertex set V with an equivalence relation\n\u223c \u03c7 t G defined to be u \u223c \u03c7 t G v \u21d0\u21d2 \u03c7 t G (u) = \u03c7 t G (v) for u, v \u2208 V.\nWe call each equivalence class a color class with an associated color c \u2208 C, denoted as (\u03c7 t G ) \u22121 (c) := {v \u2208 V : \u03c7 t G (v) = c}. The corresponding partition is then denoted as\nP t G = {(\u03c7 t G ) \u22121 (c) : c \u2208 C t G } where C t G := {\u03c7 t G (v) : v \u2208 V} is the color set containing all the presented colors of vertices in G.\nAn important observation is that each 1-WL iteration refines the partition P t G to a finer partition\nP t+1 G , because for any u, v \u2208 V, u \u223c \u03c7 t+1 G v implies u \u223c \u03c7 t G v.\nSince the number of vertices |V| is finite, there must exist an iteration T stable < |V| such that P Tstable\nG = P Tstable+1 G . It follows that P t G = P Tstable G\nfor all t \u2265 T stable , i.e. the partition stabilizes. We thus denote P G := P Tstable G as the stable partition induced by the 1-WL algorithm, and denote \u03c7 G as any stable color mapping (i.e. by picking any \u03c7 t G with t \u2265 T stable ). We can similarly define the inverse mapping \u03c7 \u22121 G . The mapping \u03c7 G serves as a node feature extractor so that \u03c7 G (v) is the representation of node v \u2208 V. Correspondingly, the multiset {{\u03c7 G (v) : v \u2208 V}} can serve as the representation of graph G.\nThe 1-WL algorithm can be used to distinguish whether two graphs G and H are isomorphic, by comparing their graph representations {{\u03c7 G (v) : v \u2208 V}} and {{\u03c7 H (v) : v \u2208 V}}. If the two multisets are not equivalent, then G and H are clearly non-isomorphic. Thus 1-WL is a necessary condition to test graph isomorphism. Nevertheless, the 1-WL test fails when {{\u03c7 G (v) : v \u2208 V}} = {{\u03c7 H (v) : v \u2208 V}} but G and H are still non-isomorphic (see Figure 2 for a counterexample). This motivates the more powerful higher-order WL tests, which are illustrated in the next subsection.", "publication_ref": [], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "B.2 k-FWL TEST", "text": "In this section, we present a family of algorithms called the k-dimensional Folklore Weisfeiler-Lehman algorithms (k-FWL). Instead of calculating a node color mapping, k-FWL computes a color mapping on each k-tuple of nodes. The pseudo code of k-FWL (k \u2265 2) is presented in Algorithm 2.\nAlgorithm 2: The k-dimensional Folklore Weisfeiler-Lehman Algorithm Input : Graph G = (V, E) and the number of iterations T Output: Color mapping \u03c7 G : V k \u2192 C Initialize: Pick three fixed different elements c 0 , c 1 , c node \u2208 C, let \u03c7 0 G (v) := hash(vec(A v )) for each v \u2208 V k where A v \u2208 C k\u00d7k is a matrix with elements\nA v ij = c node if v i = v j c 0 if v i \u0338 = v j and {v i , v j } / \u2208 E c 1 if v i \u0338 = v j and {v i , v j } \u2208 E (6) for t \u2190 1 to T do for each v \u2208 V k do \u03c7 t G (v) := hash \u03c7 t\u22121 G (v), {{(\u03c7 t\u22121 G (N 1 (v, u)), \u2022 \u2022 \u2022 , \u03c7 t\u22121 G (N k (v, u))) : u \u2208 V}} where N i (v, u) = (v 1 , \u2022 \u2022 \u2022 , v i\u22121 , u, v i+1 , \u2022 \u2022 \u2022 , v k ) Return: \u03c7 T G\nIntuitively, at the beginning, the color of each vertex tuple v encodes the full structure (i.e. isomophism type) of the subgraph induced by the ordered vertex set {v i : i \u2208 [k]}, by hashing the \"adjacency\" matrix A v defined in (6). Then in each iteration, k-FWL algorithm updates the color of each vertex tuple by combining its own color with the \"neighborhood\" color using a hash function. Here, the neighborhood of a tuple v is all the tuples that differ v by exactly one element. These k \u00d7 |V| neighborhood colors are grouped into a multiset of size |V| where each element is a k-tuple. Finally, the update procedure is repeated for a sufficiently large number of iterations T , e.g.\nT = |V| k .\nSimiar to 1-WL, the k-FWL color mapping \u03c7 t G induces a partition of the set of vertex k-tuples V k , and each k-FWL iteration refines the partition of the previous iteration. Since the number of vertex k-tuples |V| k is finite, there must exist an iteration T stable < |V| k such that the partition no longer changes after t \u2265 T stable . We denote the stable color mapping as \u03c7 G by picking any \u03c7 t G with t \u2265 T stable .\nThe k-FWL algorithm can be used to distinguish whether two graphs G and H are isomorphic, by comparing their graph representations {{\u03c7 G (v) : v \u2208 V k }} and {{\u03c7 H (v) : v \u2208 V k }}. It has been proved that k-FWL is strictly more powerful than 1-WL in distinguishing non-isomorphic graphs, and (k + 1)-FWL is strictly more powerful than k-FWL for all k \u2265 2 (Cai et al., 1992).\nMoreover, the k-FWL algorithm can also be used to extract node representations as with 1-WL. To do this, we can simply define \u03c7 G (v) := \u03c7 G (v, \u2022 \u2022 \u2022 , v) as the vertex color of the k-FWL algorithm (without abuse of notation), which induces a partition P G over vertex set V. It has been shown that this partition is finer than the partition induces by 1-WL, and also the vertex partition induced by (k + 1)-FWL is finer than that of k-FWL (Kiefer, 2020).", "publication_ref": ["b18"], "figure_ref": [], "table_ref": []}, {"heading": "B.3 WL WITH SUBSTRUCTURE COUNTING (SC-WL)", "text": "Recently,  proposed a variant of the 1-WL algorithm by incorporating the socalled substructure counting into WL aggregation procedure. This yields a algorithm that is provably powerful than the original 1-WL test.\nTo describe the algorithm, we first need the notation of automorphism group. Given a graph H = (V H , E H ), an automorphism of H is a bijective mapping f : V H \u2192 V H such that for any two vertices u, v \u2208 V H , {u, v} \u2208 E H \u21d0\u21d2 {f (u), f (v)} \u2208 E H . It follows that all automorphisms of H form a group under function composition, which is called the automorphism group and denoted as Aut(H).\nThe automorphism group Aut(H) yields a partition of the vertex set V, called orbits. Formally, given a vertex v \u2208 V H , define its orbit Orb H (v) = {u \u2208 V H : \u2203f \u2208 Aut(H), f (u) = v}. The set of all orbits H\\ Aut(H\n) := {Orb H (v) : v \u2208 V H } is called the quotient of the automorphism. Denote d H = |H\\ Aut(H)| and denote the elements in H\\ Aut(H) as {O V H,i } d H i=1 .\nWe are now ready to describe the procedure of SC-WL.\nPre-processing. Depending on the tasks, one first specify a set of (small) connected graphs H = {H 1 , \u2022 \u2022 \u2022 , H k }, which will be used for sub-structure counting in the input graph G. Popular choices of these small graphs are cycles of different lengths (e.g., triangle or square) and cliques. Given a graph G = (V G , E G ), for each vertex v \u2208 V G and each graph H \u2208 H, the following quantities are calculated:\nx\nV H,i (v) := G[S] : S \u2282 V, G[S] \u2243 H, v \u2208 S, f G[S]\u2192V H (v) \u2208 O V H,i , i \u2208 [d H ](7)\nwhere f G[S]\u2192V H is any isomorphism that maps the vertices of graph G[S] to those of graph H. Intuitively, x V H,i (v) counts the number of induced subgraphs of G that is isomorphic to H and contains node v, such that the orbit of v is similar to the orbit O V H,i . The counts corresponding to different orbits O V H,i and different graphs H are finally combined and concatenated into a vector:\nx V (v) = [x V H1 (v) \u22a4 , \u2022 \u2022 \u2022 , x V H k (v) \u22a4 ] \u22a4 \u2208 N D + (8)\nwhere the dimension of\nx V (v) is D = i\u2208[k] d i .\nMessage Passing. The message passing procedure is similar to Algorithm 1, except that the aggregation formula (Line 4) is replaced by the following update rule:\n\u03c7 t G (v) := hash \u03c7 t\u22121 G (v), x V (v), {{(\u03c7 t\u22121 G (u), x V (u)) : u \u2208 N G (v)}}(9)\nwhich incorporates the substructure counts (7, 8). Note that the update rule ( 9) is slightly simpler than the original paper (Bouritsas et al., 2022, Section 3.2), but the expressive power of the two formulations are the same.\nFinally, we note that the above procedure counts substructures and calculates features x V for each vertex of G. One can similarly consider calculating substructure counts for each edge of G, and the conclusion in this paper (Theorem 3.1) still holds. Please refer to  for more details on how to calculate edge features.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B.4 EQUIVARIANT SUBGRAPH AGGREGATION WL (DSS-WL)", "text": "Recently,  developd a new type of graph neural networks, called Equivariant Subgraph Aggregation Networks, as well as a new WL variant named DSS-WL. Given a graph G = (V, E), DSS-WL first generates a bag of graphs B \u03c0 G = {{G 1 , \u2022 \u2022 \u2022 , G m }} which share the vertices, i.e. G i = (V, E i ), but differ in the edge sets E i . Here \u03c0 denotes the graph generation policy which determines the edge set E i for each graph G i . The initial coloring \u03c7 0 Gi (v) for each node v \u2208 V in graph G i is also determined by \u03c0 and can be different across different nodes and graphs. In each iteration, the algorithm refines the color of each node by jointly aggregating its neighboring colors in the own graph and across different graphs. This procedure is repeated for a sufficiently large iterations T to obtain the stable color mappings \u03c7 Gi and \u03c7 G . The pseudo code of DSS-WL is presented in Algorithm 3.\nThe key component in the DSS-WL algorithm is the graph generation policy \u03c0 which must maintain symmetry, i.e., be equivairant under permutation of the vertex set. We list several common choices below:\n\u2022 Node marking policy \u03c0 = \u03c0 NM . In this policy, we have B \u03c0 G = {{G v : v \u2208 V}} where G v = G, i.e., there are |V| graphs in B \u03c0 G whose structures are the completely the same. The difference, however, lies in the initial coloring which marks the special node v in the following way: \u03c7 0 Gv (v) = c 1 and \u03c7 0 Gv (u) = c 0 for other nodes u \u0338 = v, where c 0 , c 1 \u2208 C are two different colors.\n\u2022 Node deletion policy \u03c0 = \u03c0 ND . The bag of graphs for this policy is also defined as\nB \u03c0 G = {{G v : v \u2208 V}}, but each graph G v = (V, E v ) has a different edge set E v := E\\{{v, w} : w \u2208 N G (v)}.\nIntuitively, it removes all edges that connects to node v and thus makes v an isolated node. The initial coloring is chosen as a constant \u03c7 0 Gi (v) = c 0 for all v \u2208 V and G i \u2208 B \u03c0 G for some fixed color c 0 \u2208 C. \nB \u03c0 G = {{G i }} m i=1 , G i = (V, E i ) and initial coloring \u03c7 0 Gi for i \u2208 [m] according to policy \u03c0 Let \u03c7 0 G (v) := hash {{\u03c7 t Gi (v) : i \u2208 [m]}} for each v \u2208 V for t \u2190 1 to T do for each v \u2208 V do for i \u2190 1 to m do \u03c7 t Gi (v) := hash \u03c7 t\u22121 Gi (v), {{\u03c7 t\u22121 Gi (u) : u \u2208 N Gi (v)}}, \u03c7 t\u22121 G (v), {{\u03c7 t\u22121 G (u) : u \u2208 N G (v)}} \u03c7 t G (v) := hash {{\u03c7 t Gi (v) : i \u2208 [m]}} Return: \u03c7 T G \u2022 Ego network policy \u03c0 = \u03c0 EGO(k) .\nIn this policy, we also have\nB \u03c0 G = {{G v : v \u2208 V}}, G v = (V, E v ). The edge set E v is defined as E v := {{u, w} \u2208 E : dis G (u, v) \u2264 k, dis G (w, v) \u2264\nk}, which corresponds to a subgraph containing all the k-hop neighbors of v and isolating other nodes. The initial coloring is chosen as \u03c7 0\nGi\n(v) = c 0 for all v \u2208 V and G i \u2208 B \u03c0 G\nwhere c 0 \u2208 C is a constant. One can also consider the ego network policy with marking \u03c0 = \u03c0 EGOM(k) , by marking the initial color of the special node v for each G v .\nWe note that for all the above policies,\n|B \u03c0 G | = |V|.\nThere are other choices such as the edge deletion policy ), but we do not discuss them in this paper. A straightforward analysis yields that DSS-WL with any above policy is strictly powerful than the classic 1-WL algorithm. Also, node marking policy has been shown to be not less powerful than the node deletion policy (Papp & Wattenhofer, 2022).\nFinally, we highlight that ; Cotta et al. (2021) also proposed a weaker version of DSS-WL, called the DS-WL algorithm. The difference is that for DS-WL, Lines 6 and 7 in Algorithm 3 are replaced by a simple 1-WL aggregation:\n\u03c7 t Gi (v) := hash \u03c7 t\u22121 Gi (v), {{\u03c7 t\u22121 Gi (u) : u \u2208 N G (v)}} . (10\n)\nHowever, the original formulation of DS-WL  only outputs a graph representation {{{{\u03c7 Gi (v) : v \u2208 V}} : G i \u2208 B \u03c0 G }} rather than outputs each node color, which does not suit the node-level tasks (e.g., finding cut vertices). Nevertheless, there are simple adaptations that makes DS-WL output a color mapping \u03c7 G . We will study these adaptations in Appendix C.2 (see the paragraph above Proposition C.16) and discuss their limitations compared with DSS-WL.", "publication_ref": ["b64", "b23"], "figure_ref": [], "table_ref": []}, {"heading": "B.5 GENERALIZED DISTANCE WL (GD-WL)", "text": "In this paper, we study a new variant of the color refinement algorithm, called the Generalized Distance WL (GD-WL). The complete algorithm is described below. As a special case, when choosing d G = dis G , the resulting algorithm is called the Shortest Path Distance WL (SPD-WL), which is strictly powerful than the classic 1-WL. \nAlgorithm 4: The Genealized Distance Weisfeiler-Lehman Algorithm Input : Graph G = (V, E), distance metric d G : V \u00d7 V \u2192 R + ,\nG (v) := c 0 for all v \u2208 V for t \u2190 1 to T do for each v \u2208 V do \u03c7 t G (v) := hash {{(d G (v, u), \u03c7 t\u22121 G (u)) : u \u2208 V}} Return: \u03c7 T G C PROOF OF THEOREMS\nThis section provides all the missing proofs in this paper. For the convenience of reading, we will restate each theorem before giving a proof.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C.1 PROPERTIES OF COLOR REFINEMENT ALGORITHMS", "text": "In this subsection, we first derive several important properties that are shared by a general class of color refinement algorithms. They will serve as key lemmas in our subsequent proofs. Here, a general color refinement algorithm takes a graph G = (V G , E G ) as input and calculates a color mapping \u03c7 G : V G \u2192 C. We first define a concept called the WL-condition. Definition C.1. A color mapping \u03c7 G : V G \u2192 C is said to satisfy the WL-condition if for any two vertices u, v with the same color (i.e. \u03c7 G (u) = \u03c7 G (v)) and any color c \u2208 C,\n|N G (u) \u2229 \u03c7 \u22121 G (c)| = |N G (v) \u2229 \u03c7 \u22121 G (c)|, where \u03c7 \u22121 G is the inverse mapping of \u03c7 G . Remark C.2.\nThe WL-condition can be further generalized to handle two graphs. Let \u03c7 G : V G \u2192 C and \u03c7 H : V H \u2192 C be two color mappings obtained by applying the same color refinement algorithm for graphs G and H, respectively. \u03c7 G and \u03c7 H are said to jointly satisfy the WL-condition, if for any two vertices u \u2208 V G and v \u2208 V H with the same color (\u03c7 G (u) = \u03c7 H (v)) and any color c \u2208 C,\n|N G (u) \u2229 \u03c7 \u22121 G (c)| = |N H (v) \u2229 \u03c7 \u22121 H (c)|. It clearly implies Definition C.1 by choosing G = H.\nIt is easy to see that the classic 1-WL algorithm (Algorithm 1) satisfies the WL-condition. In fact, many of the presented algorithms in this paper satisfy such a condition as we will show below, such as DSS-WL (Algorithm 3), SPD-WL (Algorithm 4 with d G = dis G ), and k-FWL (Algorithm 2). Proposition C.3. Consider the DSS-WL algorithm (Algorithm 4) with arbitrary graph selection policy \u03c0. Let \u03c7 G and \u03c7 H be the color mappings for graphs G and H, and let {{\u03c7 Gi : i \u2208 [m G ]}} and {{\u03c7 Hi : i \u2208 [m H ]}} be the color mapping for subgraphs generated by \u03c0. Then,\n\u2022 \u03c7 G and \u03c7 H jointly satisfy the WL-condition;\n\u2022 \u03c7 Gi and \u03c7 Hj jointly satisfy the WL-condition for any i \u2208 [m G ] and j \u2208 [m H ].\nProof. We first prove the second bullet of Proposition C.3. By definition of the DSS-WL aggregation procedure (Line 6 in Algorithm 3), \u03c7 Gi (u) = \u03c7 Hi (v) already implies {{\u03c7 Gi (w) :\nw \u2208 N Gi (u)}} = {{\u03c7 Hj (w) : w \u2208 N Hj (v)}}. Namely, |{w : w \u2208 N Gi (u) \u2229 \u03c7 \u22121 Gi (c)}| = |{w : w \u2208 N Hj (v) \u2229 \u03c7 \u22121\nHj (c)}| holds for any c \u2208 C. We then turn to the first bullet. If Proof. If \u03c7 G (u) = \u03c7 H (v) for some nodes u, v, then by the update rule (Line 4 in Algorithm 4)\n\u03c7 G (u) = \u03c7 H (v), then {{\u03c7 Gi (u) : i \u2208 [m G ]}} = {{\u03c7 Hj (v) : j \u2208 [m H ]}} (\n{{(dis G (u, w), \u03c7 G (w)) : w \u2208 V}} = {{(dis G (v, w), \u03c7 G (w)) : w \u2208 V}}.\nSince w \u2208 N G (u) if and only if dis G (u, w) = 1, we have\n{{\u03c7 G (w) : w \u2208 N G (u)}} = {{\u03c7 G (w) : w \u2208 N G (v)}}.\nTherefore, for any c \u2208 C, |{w :\nw \u2208 N G (u) \u2229 \u03c7 \u22121 G (c)}| = |{w : w \u2208 N G (v) \u2229 \u03c7 \u22121 G(\nc)}|. Proposition C.5. Let \u03c7 G and \u03c7 H be two vertex color mappings returned by the k-FWL algorithm (k \u2265 2). Then \u03c7 G and \u03c7 H jointly satisfy the WL-condition.\nProof. Let \u03c7 G (u) = \u03c7 H (v) for some u \u2208 V G and v \u2208 V H . By the update formula (Line 4 in Algorithm 2), {{\u03c7 G (u, \u2022 \u2022 \u2022 , u, w) : w \u2208 V G }} = {{\u03c7 H (v, \u2022 \u2022 \u2022 , v, w) : w \u2208 V H }}. Note that for any nodes w 1 \u2208 V G , w 2 \u2208 V H and any x 1 \u2208 N G (w 1 ), x 2 / \u2208 N H (w 2 ), one has \u03c7 G (w 1 , \u2022 \u2022 \u2022 , w 1 , x 1 ) \u0338 = \u03c7 H (w 2 , \u2022 \u2022 \u2022 , w 2 , x 2 )\n. This is obtained by the definition of the initialization mapping \u03c7 0 G and the fact that\n\u03c7 G refines \u03c7 0 G . Consequently, {{\u03c7 G (u, \u2022 \u2022 \u2022 , u, w) : w \u2208 N G (u)}} = {{\u03c7 G (v, \u2022 \u2022 \u2022 , v, w) : w \u2208 N H (v)}}. Next, we can use the fact that if \u03c7 G (u, \u2022 \u2022 \u2022 , u, w 1 ) = \u03c7 G (v, \u2022 \u2022 \u2022 , v, w 2 ) for some w 1 , w 2 \u2208 V, then \u03c7 G (w 1 ) = \u03c7 G (w 2 ) (see Lemma C.6). Therefore, {{\u03c7 G (w) : w \u2208 N G (u)}} = {{\u03c7 G (w) : w \u2208 N H (v)\n}}, which concludes the proof.\nTo complete the proof of Proposition C.5, it remains to prove the following lemma: Lemma C.6. Let \u03c7 G and \u03c7 H be color mappings for graphs G and H in the k-FWL algorithm (k \u2265 2). Denote cat i,j (w,\nx) := (w, \u2022 \u2022 \u2022 , w i times , x, \u2022 \u2022 \u2022 , xj times\n).\nThen for any i \u2208 [k \u2212 1] and any nodes u, w\n\u2208 V G , v, x \u2208 V H , if \u03c7 G (cat k\u2212i,i (u, w)) = \u03c7 H (cat k\u2212i,i (v, x)), then \u03c7 G (cat k\u2212i\u22121,i+1 (u, w)) = \u03c7 H (cat k\u2212i\u22121,i+1 (v, x)). Consequently, \u03c7 G (w) = \u03c7 H (x).\nProof. By the update formula (Line\n4 in Algorithm 2), \u03c7 G (cat k\u2212i,i (u, w)) = \u03c7 H (cat k\u2212i,i (v, x)) implies that {{\u03c7 G (cat k\u2212i\u22121,1,i (u, y, w)) : y \u2208 V G }} = {{\u03c7 H (cat k\u2212i\u22121,1,i (v, y, x)) : y \u2208 V H }}. Note that for any j \u2208 [k \u2212 1] and any z \u2208 V k G , z \u2032 \u2208 V k H with z j = z j+1 but z \u2032 j \u0338 = z \u2032 j+1 , one has \u03c7 G (z) \u0338 = \u03c7 H (z \u2032 )\n. This is obtained by the definition of the initialization mapping \u03c7 0 G and the fact that \u03c7 G refines \u03c7 0 G . Therefore, we have \u03c7 G (cat\nk\u2212i\u22121,i+1 (u, w)) = \u03c7 H (cat k\u2212i\u22121,i+1 (v, x)), as desired.\nEquipped with the concept of WL-condition, we now present several key results. In the following, let \u03c7 G : V G \u2192 C and \u03c7 H : V H \u2192 C be two color mappings jointly satisfying the WL-condition. \nu i ) = \u03c7 G (v i ) holds for all i \u2208 [d].\nProof. The proof is based on induction over the path length d. For the base case of d = 1, if the conclusion does not hold, then there exists two vertices u \u2208 V G , v \u2208 V H with the same color (i.e.\n\u03c7 G (u) = \u03c7 H (v)) and a color c = \u03c7 G (v 1 ) such that N G (u) \u2229 \u03c7 \u22121 G (c) \u0338 = \u2205 but N H (v) \u2229 \u03c7 \u22121 H (c) = \u2205.\nThis obviously contradicts the WL-condition. For the induction step on the path length d, one can just split it by two parts\n(v 0 , \u2022 \u2022 \u2022 , v d\u22121 ) and (v d\u22121 , v d ). Separately using induction yields two paths (u 0 , \u2022 \u2022 \u2022 , u d\u22121 ) and (u d\u22121 , u d ) such that \u03c7 H (u i ) = \u03c7 G (v i ) for all i \u2208 [d].\nBy linking the two paths we have completed the proof.\nFinally, let us define the shortest path distance between node u and vertex set S as dis G (u, S) := min v\u2208S dis G (u, v). The above lemma directly yields the following corollary:\nCorollary C.8. For any color c \u2208 {\u03c7 G (w) : w \u2208 V G } and any two vertices u \u2208 V G , v \u2208 V H with the same color (i.e. \u03c7 G (u) = \u03c7 H (v)), dis G (u, \u03c7 \u22121 G (c)) = dis H (v, \u03c7 \u22121 H (c)).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C.2 COUNTEREXAMPLES", "text": "We provides the following two families of counterexamples, which most prior works cannot distinguish.\nExample C.9. Let G 1 = (V, E 1 ) and G 2 = (V, E 2 ) be a pair of graphs with n = 2km + 1 nodes where m, k are two positive integers satisfying mk \u2265 3. Denote V = [n] and define the edge sets as follows:\nE 1 = {{i, (i mod 2km) + 1} : i \u2208 [2km]} \u222a {{n, i} : i \u2208 [2km], i mod m = 0} , E 2 = {{i, (i mod km) + 1} : i \u2208 [km]} \u222a {{i + km, (i mod km) + km + 1} : i \u2208 [km]} \u222a {{n, i} : i \u2208 [2km], i mod m = 0} .\nSee Figure 2(a-c) for an illustration of three cases:\n(i) m = 2, k = 2; (ii) m = 4, k = 1; (iii) m = 1, k = 4.\nIt is easy to see that regardless of the chosen of m and k, G 1 always has no cut vertex but G 2 do always have a cut vertex with node number n. The case of k = 1 is more special, for which G 2 actually has three cut vertices with node number m, 2m, and n, respectively, and it even has two cut edges {m, n} and {2m, n} (Figure 2(b)). Example C.10. Let G 1 = (V, E 1 ) and G 2 = (V, E 2 ) be a pair of graphs with n = 2m nodes where m \u2265 3 is an arbitrary integer. Denote V = [n] and define the edge sets as follows:\nE 1 = {{i, (i mod n) + 1} : i \u2208 [n]} \u222a {{m, 2m}} , E 2 = {{i, (i mod m) + 1} : i \u2208 [m]} \u222a {{i + m, (i mod m) + m + 1} : i \u2208 [m]} \u222a {{m, 2m}} .\nSee Figure 2(d) for an illustration of the case n = 8. It is easy to see that G 1 does not have any cut vertex or cut edge, but G 2 do have two cut vertices with node number m and 2m, and has a cut edge {m, 2m}. Theorem C.11.\nLet H = {H 1 , \u2022 \u2022 \u2022 , H k }, H i = (V i , E i )\nbe any set of connected graphs and denote\nn V = max i\u2208[k] |V i |.\nThen SC-WL (Appendix B.3) using the substructure set H can neither distinguish whether a given graph has cut vertices nor distinguish whether it has cut edges. Moreover, there exist counterexample graphs whose size (both in terms of vertices and edges) is O(n V ).\nProof. We would like to prove that SC-WL cannot distinguish both Examples C.9 and C.10 when n V < m (m is defined in these examples). First note that for both examples, any cycle in both G 1 and G 2 has a length of at least m. Since the number of nodes in H i is O(n V ), if H i contains cycles, it will not occur in both G 1 and G 2 , thus taking no effect in distinguishing the two graphs. As a result, we can simply assume all graphs in H are trees (connected graphs with no cycles). Below, we provide a complete proof for Example C.9, which already yields the conclusion that SC-WL can neither distinguish cut vertices nor cut edges. We omit the proof for Example C.10 since the proof technique is similar.\nProof for Example C.9. Let H i be a tree with less than m vertices where m is defined in Example C.9. By symmetry of the two graphs G 1 and G 2 , it suffices to prove the following two types of equations:\nx V G1 (n) = x V G2 (n) and x V G1 (i) = x V G2 (i) for all m < i \u2264 2m\n, where x V is defined in (8). We first aim to prove that\nx V G1 (v) = x V G2 (v) for v \u2208 {m + 1, \u2022 \u2022 \u2022 , 2m}.\nConsider an induced subgraph G 1 [S] which is isomorphic to H i and contains node v. Define the set T := {jm : j \u2208 [k]}\u2229S. For ease of presentation, we define an operation cir(x, a, b) that outputs an integer y in the range of (a, b] such that y has the same remainder as x (mod b \u2212 a). Formally, cir(x, a, b) = y if a < y \u2264 b and x \u2261 y (mod b \u2212 a).", "publication_ref": [], "figure_ref": ["fig_1", "fig_1", "fig_1"], "table_ref": []}, {"heading": "\u2022 If n /", "text": "\u2208 S, then it is easy to see that G 1 [S] is a chain, i.e., no vertices have a degree larger than 2. We define the following mapping g\nS : S \u2192 [n], such that g S (u) = cir(u, m, 2m) if k = 1, cir(u, 0, km) if k \u2265 2.\nIn this way, the chain\nG 1 [S] is mapped to a chain of G 2 that contains v. Concretely, denote g S (S) = {g S (u) : u \u2208 S}, then G 2 [g S (S)] \u2243 G 1 [S] \u2243 H i , and obviously the orbit of v in G 2 [g S (S)] matches the orbit of v in G 1 [S].\nSee Figure 4(a,b) for an illustration of this case.\n\u2022 If n \u2208 S, then it is easy to see that the set T \u0338 = \u2205. We will similarly construct a mapping g S : S \u2192 [n] that maps S to g S (S) satisfying g S (v) = v, which is defined as follows. For each u \u2208 S\\{n}, we find a unique vertex w u in T such that dis G1[S] (u, w u ) is the minimum. Note that the node w u is well-defined since T \u0338 = \u2205 and any path in G 1 [S] from u to a node in T goes through w u . Define\ng S (u) = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 cir(u, m, 2m) if k = 1 and w u = w v , cir(u, 0, m) if k = 1 and w u \u0338 = w v , cir(u, 0, km)\nif k > 1 and w u \u2264 km, cir(u, km, 2km) if k > 1 and w u > km.\nWe also define g S (n) = n. Such a definition guarantees that for any\nx 1 , x 2 \u2208 S, {x 1 , x 2 } \u2208 E G1 \u21d0\u21d2 {g S (x 1 ), g S (x 2 )} \u2208 E G2 . Therefore, G 2 [g S (S)] \u2243 G 1 [S] \u2243 H i .\nMoreover, observe that g S (u) \u2261 u (mod m) always holds, and thus it is easy to see that the orbit of v in G 2 [g S (S)] matches the orbit of v in G 1 [S]. See Figure 4(c,d) for an illustration of this case. Finally, note that for any two different sets S 1 and S 2 such that G\n2 \u22121 +2 +1 2 \u22121 +1 +2 1 1 2 \u2026 \u2026 \u22121 \u2026 \u2026 2 \u22121 2 1 2 2 \u22121 2 2 \u22121 2 2 +1 1 2 \u22121 +1 +2 +2 \u2026 \u22121 +1 \u2026 \u2026 2 +1 3 \u22121 3 3 +1 \u2026 4 \u22121 4 3 \u22121 3 3 +1 4 \u22121 4 2 \u22121 1 \u22121 +1 2 +2 \u2026 \u22121 +1 +2 2 \u22121 2 2 2 \u2026 \u2026 \u2026 2 1 2 \u22121 +1 2 \u22121 2 2 +1 3 \u22121 3 3 +1 4 \u22121 4 1 \u22121 +1 +2 2 \u22121 2 2 +1 4 \u22121 4 +2 \u2026 \u2026 \u2026 \u2026 3 \u22121 3 3 +1 (a) n / \u2208 S, k = 1 (b) n / \u2208 S, k > 1 (c) n \u2208 S, k = 1 (d) n \u2208 S, k > 1\n1 [S 1 ] \u2243 G 1 [S 2 ] \u2243 H i , we have g S1 (S 1 ) \u0338 = g S2 (S 2 ), which guarantees that the mapping g : {S \u2282 [n] : G 1 [S] \u2243 H i , v \u2208 S} \u2192 {S \u2282 [n] : G 2 [S] \u2243 H i , v\n\u2208 S} defined to be g(S) = g S (S) is injective. One can further check that the mapping g is also surjective, and thus it is bijective. This means\nx V G1 (v) = x V G2 (v) for v \u2208 {m, \u2022 \u2022 \u2022 , 2m \u2212 1}. The proof for x V G1 (n) = x V G2 (n)\nis almost the same, so we omit it here. Noting that under classic 1-WL, the colors \u03c7 G1 (v) = \u03c7 G2 (v) are also the same. Therefore, adding the features x V (v) does not help distinguish the two graphs. We have finished the proof for Example C.9.\nUsing a similar cycle analysis as the above proof, we have the following negative result for Simplicial WL (Bodnar et al., 2021b) and Cellular WL (Bodnar et al., 2021a): Proposition C.12. Consider the SWL algorithm (Bodnar et al., 2021b), or more generally, the CWL algorithms with either k-CL, k-IC, or k-C as lifting maps (k \u2265 3 is an integer) (Bodnar et al., 2021a, Definition 14). These algorithms can neither distinguish whether a given graph has cut vertices nor distinguish whether it has cut edges.\nProof. Observe that the counterexample graphs in both Examples C.9 and C.10 do not have cliques. Therefore, SWL (or CWL with k-CL) reduces to the classic 1-WL and thus fails to distinguish them. Since the lengths of any cycles in these counterexample graphs are at least m (m is defined in Examples C.9 and C.10), we have that CWL with k-IC or k-C also reduces to 1-WL when m > k. Therefore, there exists graphs whose size is O(k) such that CWL can neither distinguish cut vertices nor cut edges.\nFinally, we point out that even if k is not a constant (i.e., can scale to the graph size), CWL with k-IC still fails to distinguish whether a given graph has cut vertices. This is because for Example C.9 with k \u2265 2 (e.g. Figure 2(b,c)), CWL with IC still outputs the same graph representation for both G 1 and G 2 . This happens because all the 2-dimensional cells in these examples are cycles of an equal length of m + 2 and one can easily check that they have the same CWL color.\nWe finally turn to the case of subgraph-based WL variants. Proposition C.13. The Overlap Subgraph WL (Wijesinghe & Wang, 2022) using any subgraph mapping \u03c9 can neither distinguish whether a given graph has cut vertices nor distinguish whether it has cut edges.\nProof. An important limitation of OS-WL is that if a graph does not contain triangles, then any overlap subgraph S uv between two adjacent nodes u, v will only have one edge {u, v}. Consequently, the subgraph mapping \u03c9 does not take effect can OS-WL reduces to the classic 1-WL. Therefore, Example C.9 with m > 1 and Example C.10 with m > 3 still apply here since the graphs G 1 and G 2 do not contain triangles (see Figure 2 Proposition C.14. The DSS-WL with ego network policy without marking cannot distinguish the graphs in Example C.9 with m = 1 (Figure 2(c)).\nProof. First note that for any two vertices u, v in either G 1 or G 2 defined in Example C.9, their shortest path distance does not exceed 2. Thus we only need to consider the ego network policy \u03c0 EGO(1) and \u03c0 EGO(2) .\n\u2022 For \u03c0 EGO(2) , the ego graphs of all nodes are simply the original graph and thus all graphs in the bag B \u03c0 and equal. Thus DSS-WL reduces to the classic 1-WL and cannot distinguish G 1 and G 2 .\n\u2022 For \u03c0 EGO(1) , the ego graph of each node v \u0338 = n is a graph with 5 edges, having a shape of two triangles sharing one edge. These ego graphs are clearly isomorphic. The ego graph of the special node n is the original graph containing all edges. It is easy to see that the vertex partition of DSS-WL becomes stable only after one iteration, and the color mapping of G 1 and G 2 is the same. Therefore, DSS-WL cannot distinguish G 1 and G 2 .\nWe thus conclude the proof.\nProposition C.15. The GNN-AK architecture proposed in Zhao et al. (2022) cannot distinguish whether a given graph has cut vertices.\nProof. The GNN-AK architecture is quite similar to DSS-WL using the ego network policy but is weaker. There is also a subtle difference: GNN-AK adds the so-called centroid encoding. However, unlike node marking that is performed before the WL procedure, centroid encoding is performed after the WL procedure. The subtle difference causes GNN-AK to be unable to distinguish between the two graphs G 1 and G 2 .\nWe finally consider the DS-WL algorithm proposed in Cotta et al. (2021); .\nAs discussed in Appendix B.4, the original DS-WL formulation only outputs a graph representation rather than node colors. There are two simple ways to define nodes colors for DS-WL:\n\u2022 If the graph generation policy \u03c0 is node-based, then each subgraph in\nB \u03c0 G = {{G i }} |V| i=1\nis uniquely associated to a specific node v \u2208 V. We can thus use the graph representation of each subgraph G i as the color of each node. This strategy has appeared in prior works, e.g. Zhao et al. (2022).\n\u2022 For a general graph generation policy \u03c0, there no longer exists an explicit bijective mapping between nodes and subgraphs. In this case, another possible way is to define \u03c7 G (v) := {{\u03c7 Gi (v) : G i \u2208 B \u03c0 G }}, similar to DSS-WL. This approach is recently introduced by Qian et al. (2022). However, such a strategy loses the memory advantage of DS-WL (i.e., needing \u0398(|V||B \u03c0 G |) memory complexity rather than \u0398(|V|+|B \u03c0 G |)), and is less expressive than DSS-WL. We thus do not study this variant in the present work. Proposition C.16. The DS-WL algorithm with node marking/deletion policy cannot distinguish cut vertices when each node's color is defined as its associated subgraph representation.\nProof. One can similarly check that for Example C.9 with m = 1 (see Figure 2(c)), the color of node n will be the same for both graphs G 1 and G 2 . Therefore, DS-WL cannot identify cut vertices.\nFinally, using a similar proof technique, the NGNN architecture proposed in Zhang & Li (2021) (with shortest path distance encoding) cannot identify cut vertices.", "publication_ref": ["b13", "b12", "b13", "b51", "b23", "b51"], "figure_ref": ["fig_11", "fig_11", "fig_1", "fig_1", "fig_1", "fig_1"], "table_ref": []}, {"heading": "C.3 PROOF OF THEOREM 3.2", "text": "Theorem C.17. Let G = (V, E G ) and H = (V, E H ) be two graphs, and let \u03c7 G and \u03c7 H be the corresponding DSS-WL color mapping with node marking policy. Then the following holds:\n\u2022 For any two nodes w \u2208 V in G and x \u2208 V in H, if \u03c7 G (w) = \u03c7 H (x), then w is a cut vertex in graph G if and only if x is a cut vertex in graph H.\n\u2022 For any two edges {w 1 , w 2 } \u2208 E G and {x 1 , x 2 } \u2208 E H , if {{\u03c7 G (w 1 ), \u03c7 G (w 2 )}} = {{\u03c7 H (x 1 ), \u03c7 H (x 2 )}}, then {w 1 , w 2 } is a cut edge if and only if {x 1 , x 2 } is a cut edge.\nProof. We divide the proof into two parts in Appendices C.3.1 and C.3.2, separately focusing on proving each bullet of Theorem 3.2. Before going into the proof, we first define several notations. Denote \u03c7 u G (v) as the color of node v under the DSS-WL algorithm when marking u as a special node. By definition of DSS-WL (Line 7 in Algorithm 3), \u03c7 G (v) = hash ({{\u03c7 u G (v) : u \u2208 V}}). We can similarly define the inverse mappings (\u03c7 u G ) \u22121 . We first present a lemma which can help us exclude the case of disconnected graphs. Lemma C.18. Given a node w, let S G (w) \u2282 V be the connected component in graph G that comprises node w. For any two nodes w \u2208 V in G and\nx \u2208 V in H, if \u03c7 G (w) = \u03c7 H (x), then \u03c7 G[S G (w)] (w) = \u03c7 H[S H (x)] (x). Proof. We first prove that if \u03c7 G (w) = \u03c7 H (x), then {{\u03c7 u G (w) : u \u2208 S G (w)}} = {{\u03c7 u H (x) : u \u2208 S H (x)}}. First note that for any nodes u, w in G and v, x in H, if u \u2208 S G (w) but v / \u2208 S H (x), then \u03c7 u G (w) \u0338 = \u03c7 v H (x)\n. This is because DSS-WL only performs neighborhood aggregation, and the marking v cannot propagate to node x while the marking u can propagate to node w. By definition we have\n\u03c7 G (w) = hash ({{\u03c7 u G (w) : u \u2208 S G (w)}} \u222a {{\u03c7 v G (w) : v / \u2208 S G (w)}}) .\nSimilarly,\n\u03c7 H (x) = hash ({{\u03c7 u H (x) : u \u2208 S H (x)}} \u222a {{\u03c7 v H (x) : v / \u2208 S H (x)}}) . Since \u03c7 G (w) = \u03c7 H (x), we have {{\u03c7 u G : u \u2208 S G (w)}} = {{\u03c7 u H : u \u2208 S H (x)}}. This clearly implies {{\u03c7 u G[S G (w)] : u \u2208 S G (w)}} = {{\u03c7 u H[S H (x)] : u \u2208 S H (x)}}, and thus \u03c7 G[S G (w)] (w) = \u03c7 H[S H (x)] (x).\nNote that w is a cut vertex in G implies w is a cut vertex in G[S G (w)]. Therefore, based on Lemma C.18, we can restrict our attention to subgraphs G[S G (w)] and H[S H (x)] instead of the original (potentially disconnected) graphs. In other words, in the subsequent proof we can simply assume that both graphs G and H are connected.\nWe next present several simple but important properties regrading the DSS-WL color mapping as well as the subgraph color mappings. Lemma C.19. Let u, w be two nodes in connected graph G and v, x be two nodes in connected graph H. Then the following holds:\n(a) If w = u and x \u0338 = v, then \u03c7 u G (w) \u0338 = \u03c7 v H (x); (b) If \u03c7 u G (w) = \u03c7 v H (x), then \u03c7 G (w) = \u03c7 H (x); (c) If \u03c7 u G (w) = \u03c7 v H (x), then \u03c7 G (u) = \u03c7 H (v); (d) \u03c7 G (w) = \u03c7 H (x) if and only if \u03c7 w G (w) = \u03c7 x H (x); (e) If \u03c7 u G (w) = \u03c7 v H (x), then dis G (u, w) = dis H (v, x).\nProof. Item (a) holds because in DSS-WL, the node with marking cannot have the same color as a node without marking. This can be rigorously proved by induction over the iteration t in the DSS-WL algorithm (Line 6 in Algorithm 3).\nItem (b) simply follows by definition of the DSS-WL aggregation procedure since the color \u03c7 u G (w) encodes the color of \u03c7 G (w).\nWe next prove item (c), which follows by using the WL-condition of DSS-WL algorithm (Proposition C.3). Since G is connected, there is a path from w to u. Therefore, in graph H there is also a path from x to some node v \u2032 satisfying \u03c7 u G (u) = \u03c7 v H (v \u2032 ) (Lemma C.7). Now using item (a), it can only be the case v \u2032 = v and thus \u03c7 u G (u) = \u03c7 v H (v). Finally, by item (b) we obtain the desired result. We next prove item (d). On the one hand, item (b) already shows that \u03c7 w G (w) = \u03c7 x G (x) =\u21d2 \u03c7 G (w) = \u03c7 H (x). On the other hand, by definition of the DSS-WL algorithm,\n\u03c7 G (w) = hash ({{\u03c7 w G (w)}} \u222a {{\u03c7 u G (w) : u \u2208 V\\{w}}}) , \u03c7 H (x) = hash ({{\u03c7 x H (x)}} \u222a {{\u03c7 v H (x) : v \u2208 V\\{x}}}) .\nSince \u03c7 G (w) = \u03c7 H (x) and \u03c7 w G (w) \u0338 = \u03c7 v H (x) holds for all v \u2208 V\\{x} (by item (a)), we obtain \u03c7 w G (w) = \u03c7 x G (x). We finally prove item (e), which again can be derived from the WL-condition of DSS-WL algorithm. If \u03c7 u G (w) = \u03c7 v H (x), then by Corollary C.8 we have dis G (w, (\u03c7\nu G ) \u22121 (\u03c7 u G (u))) = dis H (x, (\u03c7 v H ) \u22121 (\u03c7 u G (u))).\nUsing item (a), we have (\u03c7 u G ) \u22121 (\u03c7 u G (u)) = {u} and for any v \n\u2032 \u0338 = v, \u03c7 v H (v \u2032 ) \u0338 = \u03c7 v H (v\nG = C d+1 H . Note that for any nodes x 1 , x 2 satisfying \u03c7 u G (x 1 ) = \u03c7 v H (x 2 ), {{\u03c7 u G (w) : w \u2208 N G (x 1 )}} = {{\u03c7 v H (w) : w \u2208 N H (x 2 )}}. Therefore, by the induction assumption C d G = C d H , x\u2208N d G (u) {{\u03c7 u G (w) : w \u2208 N G (x)}} = x\u2208N d H (v) {{\u03c7 v H (w) : w \u2208 N H (x)}}. We next claim that C d G \u2229 C d \u2032 G = \u2205 for any d \u0338 = d \u2032 .\nThis is because for any nodes w 1 and w 2 with the same color \u03c7 u G (w 1 ) = \u03c7 u G (w 2 ), by Lemma C.19(e) we have dis G (w 1 , u) = dis G (w 2 , u). Using this property, we obtain\nx\u2208N d G (u) {{\u03c7 u G (w) : w \u2208 N G (x) \u2229 N d+1 G (u)}} = x\u2208N d H (v) {{\u03c7 v H (w) : w \u2208 N H (x) \u2229 N d+1 H (v)}}.\nIt is equivalent to the following equation:\nw\u2208N d+1 G (u) {{\u03c7 u G (w)}} \u00d7 |N G (w) \u2229 N d G (u)| = w\u2208N d+1 H (v) {{\u03c7 v H (w)}} \u00d7 |N H (w) \u2229 N d H (v)|.\nwhere {{c}} \u00d7 m is a multiset containing m repeated elements c. Finally, observe that if \u03c7 u G (w 1 ) = \u03c7 v H (w 2 ) for some nodes w 1 and w 2 , then\n|N G (w 1 ) \u2229 N d G (u)| = |N H (w 2 ) \u2229 N d H (v)| (because C d G \u2229 C d \u2032 G = \u2205 for any d \u0338 = d \u2032 ). Consequently, {{\u03c7 u G (w) : w \u2208 N d+1 G (u)}} = {{\u03c7 v H (w) : w \u2208 N d+1 H (v)}}, namely C d+1 G = C d+1 H .\nWe have thus completed the proof of the induction step.\nWe now present the following key result, which shows an important property of the color mapping for DSS-WL: Corollary C.21. Let u, v \u2208 V be two nodes in connected graph G with the same DSS-WL color, i.e. \u03c7 G (u) = \u03c7 G (v). Then for any color c \u2208 C, {{\u03c7 u G (w) :\nw \u2208 \u03c7 \u22121 G (c)}} = {{\u03c7 v G (w) : w \u2208 \u03c7 \u22121 G (c)}}. Proof. First observe that if \u03c7 G (u) = \u03c7 G (v), then \u03c7 u G (u) = \u03c7 v G (v) (by Lemma C.19(d)). Con- sequently, {{\u03c7 u G (w) : w \u2208 V}} = {{\u03c7 v G (w) : w \u2208 V}} holds by Lemma C.20. If {{\u03c7 u G (w) : w \u2208 \u03c7 \u22121 G (c)}} \u0338 = {{\u03c7 v G (w) : w \u2208 \u03c7 \u22121 G (c)}}, then there must exist two nodes w 1 \u2208 \u03c7 \u22121 G (c) and w 2 / \u2208 \u03c7 \u22121 G (c), such that \u03c7 u G (w 1 ) = \u03c7 v G (w 2 )\n. Therefore, by Lemma C.19(b) we have \u03c7 G (w 1 ) = \u03c7 G (w 2 ), yielding a contradiction.\nIn the subsequent proof, we assume the connected graph G is not vertex-biconnected and let u \u2208 V be a cut vertex in G. Let {S i } m i=1 (m \u2265 2) be the partition of the vertex set V\\{u}, representing each connected component after removing node u. Lemma C.22. There is at most one set\nS i satisfying S i \u2229 \u03c7 \u22121 G (\u03c7 G (u)) \u0338 = \u2205. In other words, if S i \u2229 \u03c7 \u22121 G (\u03c7 G (u)) \u0338 = \u2205 for some i \u2208 [m], then for any j \u2208 [m] and j \u0338 = i, S j \u2229 \u03c7 \u22121 G (\u03c7 G (u)) = \u2205. Proof. When |\u03c7 \u22121 G (\u03c7 G (u))| = 1, the conclusion clearly holds. If |\u03c7 \u22121 G (\u03c7 G (u))| > 1, then we can pick a node u 1 \u2208 \u03c7 \u22121 G (\u03c7 G (u)) that maximizes the shortest path distance dis G (u 1 , u). Let u 1 \u2208 S i for some i \u2208 [m].\nIf the lemma does not hold, then we can pick another node 5(a) for an illustration of this paragraph.\nu 2 \u2208 \u03c7 \u22121 G (\u03c7 G (u)) and u 2 / \u2208 S i . Since u 1 and u 2 are in different connected component after removing u, dis G (u 1 , u 2 ) = dis G (u 1 , u) + dis G (u 2 , u). See Figure\nBy Corollary C.21, {{\u03c7 u1 G (w) : w \u2208 \u03c7 \u22121 G (\u03c7 G (u))}} = {{\u03c7 u G (w) : w \u2208 \u03c7 \u22121 G (\u03c7 G (u))}}. There- fore, there must exist a node u 3 \u2208 \u03c7 \u22121 G (\u03c7 G (u)) satisfying \u03c7 u1 G (u 2 ) = \u03c7 u G (u 3 ). We thus have dis G (u 2 , u 1 ) = dis G (u 3 , u) by Lemma C.19(e). On the other hand, by definition of the node u 1 , dis G (u 1 , u) \u2265 dis G (u 3 , u). Therefore, dis G (u 2 , u 1 ) = dis G (u 1 , u) + dis G (u 2 , u) > dis G (u 3 , u).\nThis yields a contradiction and concludes the proof. Lemma C.19(d). Based on the WL-condition of the mappings \u03c7 u G and \u03c7 u \u2032 G , by Lemma C.7 there exists a node w \u2032 with color \u03c7 u \u2032 G (w \u2032 ) = \u03c7 u G (w) (because there is a path from node u to w). See Figure 5(b) for an illustration of this paragraph. Suppose u \u2032 is not a cut vertex. Then there is a path P from w \u2032 to u without going through node u \u2032 . Denote Lemma C.19(a)). Again by using the WL-condition, there exists a path Q = (y 0 , Lemma C.19(b). By the definition of w and Lemma C.22, any path from w to\nLemma C.23. For all u \u2032 \u2208 \u03c7 \u22121 G (\u03c7 G (u)), u \u2032 it is a cut vertex of G. Proof. When |\u03c7 \u22121 G (\u03c7 G (u))| = 1, the conclusion clearly holds. Now assume |\u03c7 \u22121 G (\u03c7 G (u))| > 1. Since u is a cut vertex in G, by Lemma C.22, there exists a set S j such that S j \u2229 \u03c7 \u22121 G (\u03c7 G (u)) = \u2205. Pick any node w \u2208 S j , then \u03c7 G (w) \u0338 = \u03c7 G (u). Let u \u2032 \u0338 = u be any node with color \u03c7 G (u) = \u03c7 G (u \u2032 ). It follows that \u03c7 u G (u) = \u03c7 u \u2032 G (u \u2032 ) by\nP = (x 0 , \u2022 \u2022 \u2022 , x d ) where x 0 = w \u2032 and x d = u. It follows that \u03c7 u \u2032 G (x i ) \u0338 = \u03c7 u \u2032 G (u \u2032 ) for all i \u2208 [d] (by\n\u2022 \u2022 \u2022 , y d ) satisfying y 0 = w and \u03c7 u G (y i ) = \u03c7 u \u2032 G (x i ) for all i \u2208 [d]. In particular, \u03c7 u G (y d ) = \u03c7 u \u2032 G (u), which implies \u03c7 G (y d ) = \u03c7 G (u) by using\ny d \u2208 \u03c7 \u22121 G (\u03c7 G (u)) must go through node u, implying that \u03c7 u G (y i ) = \u03c7 u G (u) for some i \u2208 [d]. However, we have proved that \u03c7 u G (y i ) = \u03c7 u \u2032 G (x i ) \u0338 = \u03c7 u \u2032 G (u \u2032 ) = \u03c7 u G (u), yielding a contradiction. Therefore, u \u2032 is a cut vertex.\nUsing a similar proof technique as the one in Lemma C.23, we can prove the first part of Theorem 3.2. Suppose u \u2032 \u2208 \u03c7 \u22121 H (\u03c7 G (u)) and we want to prove that u \u2032 is a cut vertex of graph H. We first consider the case when\nObserve that |\u03c7 \u22121 G (\u03c7 G (u))| = |\u03c7 \u22121 H (\u03c7 H (u))|. (A simple proof is as follows: \u03c7 G (u) = \u03c7 H (u \u2032 ) implies \u03c7 u G (u) = \u03c7 u \u2032 H (u \u2032 ) by\n|\u03c7 \u22121 G (\u03c7 G (u))| = |\u03c7 \u22121 H (\u03c7 H (u))| > 1.\nFollowing the above proof, we can similarly pick w \u2208 S j in G and not a cut vertex, then there is a path Lemma C.19(a)). Using the WL-condition, there exists a path Q = (y 0 , u). See Figure 6(a) for an illustration of this paragraph.\nw \u2032 in H satisfying \u03c7 G (w) \u0338 = \u03c7 G (u) and \u03c7 u \u2032 H (w \u2032 ) = \u03c7 u G (w). Since |\u03c7 \u22121 G (\u03c7 G (u))| > 1, we can pick a node u H \u2208 \u03c7 \u22121 H (\u03c7 G (u)) in H such that u H \u0338 = u \u2032 . If u \u2032 is \u2032 \u2032 Graph Graph \u2032 \u2032 \u2032 Graph Graph(\nP = (x 0 , \u2022 \u2022 \u2022 , x d ) in H where x 0 = w \u2032 and x d = u H , such that \u03c7 u \u2032 H (x i ) \u0338 = \u03c7 u \u2032 H (u \u2032 ) for all i \u2208 [d] (by\n\u2022 \u2022 \u2022 , y d ) in G satisfying y 0 = w and \u03c7 u G (y i ) = \u03c7 u \u2032 H (x i ) for all i \u2208 [d]. In particular, \u03c7 u G (y d ) = \u03c7 u \u2032 H (u H ), which implies \u03c7 G (y d ) = \u03c7 G (u H ) by using Lemma C.19(b). However, any path from w to y d \u2208 \u03c7 \u22121 G (\u03c7 G (u)) must go through node u, implying that \u03c7 u G (y i ) = \u03c7 u G (u) for some i \u2208 [d]. This yields a contradiction because \u03c7 u G (y i ) = \u03c7 u \u2032 H (x i ) \u0338 = \u03c7 u \u2032 H (u \u2032 ) = \u03c7 u G(\nWe finally consider the case when\n|\u03c7 \u22121 G (\u03c7 G (u))| = |\u03c7 \u22121 H (\u03c7 H (u))| = 1.\nLet w \u2208 S 1 and x \u2208 S 2 be two nodes in G that belongs to different connected components when removing node u, then \n\u03c7 G (w) \u0338 = \u03c7 G (u) and \u03c7 G (x) \u0338 = \u03c7 G (u). Since \u03c7 G (u) = \u03c7 H (u \u2032 ), by the WL-condition (Lemma C.7) there is a node w \u2032 \u2208 \u03c7 \u22121 H (\u03c7 G (w)) in H. Consequently, \u03c7 w G (w) = \u03c7 w \u2032 H (w \u2032 ) (Lemma C.19(d)). Again by the WL-condition, there is a node x \u2032 \u2208 (\u03c7 w \u2032 H ) \u22121 (\u03c7 w G (x)) in H. Clearly, w \u2032 \u0338 = u \u2032 and x \u2032 \u0338 = u \u2032 (because they have different colors). If u \u2032 is not a cut vertex, then there is path P = (y 0 , \u2022 \u2022 \u2022 , y d ) in H such that y 0 = x \u2032 , y d = w \u2032 and y i \u0338 = u \u2032 for all i \u2208 [d]. It follows that for all i \u2208 [d], \u03c7 H (y i ) \u0338 = \u03c7 H (u \u2032 )\nG (z i ) = \u03c7 w \u2032 H (y i ) implies \u03c7 G (z i ) = \u03c7 H (y i ) and thus \u03c7 G (z i ) \u0338 = \u03c7 H (u \u2032 ) = \u03c7 G (u) holds for all i \u2208 [d] and thus z i \u0338 = u.\nIn other words, we have found a path from x to w without going through node u, which yields a contradiction as u is a cut vertex. We have thus finished the proof.", "publication_ref": [], "figure_ref": ["fig_14", "fig_14", "fig_16"], "table_ref": []}, {"heading": "C.3.2 PROOF FOR THE SECOND PART OF THEOREM 3.2", "text": "The proof is based on the following key result: Corollary C.24. Let w and x be two nodes in connected graph G with the same DSS-WL color, i.e. \u03c7 G (w) = \u03c7 G (x). Then for any color c \u2208 C,\n{{dis G (w, v) : v \u2208 \u03c7 \u22121 G (c)}} = {{dis G (x, v) : v \u2208 \u03c7 \u22121 G (c)}}. Proof. By Corollary C.21, we have {{\u03c7 w G (v) : v \u2208 \u03c7 \u22121 G (c)}} = {{\u03c7 x G (v) : v \u2208 \u03c7 \u22121 G (c)}}. Since for any nodes u, v, \u03c7 w G (u) = \u03c7 x G (v) implies dis G (u, w) = dis G (v, x) (by Lemma C.\n19(e)), we have obtained the desired conclusion. Equivalently, the above corollary says that if \u03c7 G (w) = \u03c7 G (x), then the following two multisets are equivalent:\n{{(dis G (w, v), \u03c7 G (v)) : v \u2208 V}} = {{(dis G (x, v), \u03c7 G (v)) : v \u2208 V}}.\nTherefore, it guarantees that the vertex partition induced by the DSS-WL color mapping is finer than that of the SPD-WL (Algorithm 4 with d G = dis G ). We can thus invoke Theorem 4.1, which directly concludes the proof (due to Proposition C.56).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C.4 PROOF OF THEOREM 4.1", "text": "Theorem C.25. Let G = (V, E G ) and H = (V, E H ) be two graphs, and let \u03c7 G and \u03c7 H be the corresponding SPD-WL color mapping. Then the following holds:\n\u2022 For any two edges {w 1 , w 2 } \u2208 E G and {x 1 , x 2 } \u2208 E H , if {{\u03c7 G (w 1 ), \u03c7 G (w 2 )}} = {{\u03c7 H (x 1\n), \u03c7 H (x 2 )}}, then {w 1 , w 2 } is a cut edge if and only if {x 1 , x 2 } is a cut edge.\n\u2022 If the graph representations of G and H are the same under SPD-WL, then their block cut-edge trees (Definition 2.3) are isomorphic. Mathematically, {{\u03c7 G (w) : w \u2208 V}} = {{\u03c7 H (w) : w \u2208 V}} implies that BCETree(G) \u2243 BCETree(H).\nProof Sketch. The proof of Theorem 4.1 is highly non-trivial and is divided into three parts (presented in Appendices C.4.1 to C.4.3, respectively). We first consider the special setting when both G and H are connected and {{\u03c7 G (w) : w \u2208 V}} = {{\u03c7 H (w) : w \u2208 V}}. Assume G is not edge-biconnected, and let {u, v} \u2208 E G be a cut edge in G. We separately consider two cases:\n\u03c7 G (u) \u0338 = \u03c7 G (v) (Appendix C.4.1) and \u03c7 G (u) = \u03c7 G (v) (Appendix C.4.\n2), and prove that any edge\n{u \u2032 , v \u2032 } \u2208 E H satisfying {{\u03c7 G (u), \u03c7 G (v)}} = {{\u03c7 H (u \u2032 ), \u03c7 H (v \u2032\n)}} is also a cut edge of H. This basically finishes the proof of the first bullet in the theorem. Finally, we consider the general setting where graphs G, H can be disconnected and their representation is not the same in Appendix C.4.3, and complete the proof of Theorem 4.1.\nWithout abuse of notation, throughout Appendices C.4.1 and C.4.2 we redefine the color set C := {\u03c7 G (w) : w \u2208 V} = {\u03c7 H (w) : w \u2208 V} to focus only on colors that are present in G (or H), rather than all (irrelevant) colors in the range of a hash function.\nC.4.1 THE CASE OF \u03c7 G (u) \u0338 = \u03c7 G (v) FOR CONNECTED GRAPHS\nWe first define several notations. Throughout this case, denote {S u , S v } as the partition of V, representing the two connected components after removing the edge {u, v} such that u \u2208 S u , v \u2208 S v , S u \u2229 S v = \u2205 and S u \u222a S v = V. We then define an important concept called the color graph. \nG C = (C, E G C ) where E G C = {{{\u03c7 G (w), \u03c7 G (x)}} : {w, x} \u2208 E G }.\nNote that G C can have self loops, so each edge is denoted as a multiset with two elements.\nLemma C.27. Let S = \u03c7 \u22121 G (\u03c7 G (u)) \u222a \u03c7 \u22121 G (\u03c7 G (v)) be the set containing vertices with color \u03c7 G (u) or \u03c7 G (v). Then either S \u2229 S u = {u} or S \u2229 S v = {v}.\nProof. Assume the lemma does not hold, i.e. |S \u2229 S u | > 1 and |S \u2229 S v | > 1. We first prove that\n\u03c7 \u22121 G (\u03c7 G (u)) \u2229 S v \u0338 = \u2205 and \u03c7 \u22121 G (\u03c7 G (v)) \u2229 S u \u0338 = \u2205.\nBy symmetry, we only need to prove the former. Suppose\n\u03c7 \u22121 G (\u03c7 G (u)) \u2229 S v = \u2205, then (\u03c7 \u22121 G (\u03c7 G (v)) \u2229 S v )\\{v} \u0338 = \u2205 (because |S \u2229 S v | > 1), and thus there exists v \u2032 \u2208 S v , v \u2032 \u0338 = v such that \u03c7 G (v \u2032 ) = \u03c7 G (v). Note that v \u2032 must connect to a node u \u2032 with \u03c7 G (u \u2032 ) = \u03c7 G (u). Since {u, v} is a cut edge in G, u \u2032 \u2208 S v . Therefore, \u03c7 \u22121 G (\u03c7 G (u)) \u2229 S v \u0338 = \u2205, yielding a contradiction.\nThis paragraph is illustrated in Figure 7(a).\nWe next prove that at least one of the following two conditions holds (which are symmetric):\n(i) (\u03c7 \u22121 G (\u03c7 G (u)) \u2229 S u )\\{u} \u0338 = \u2205; (ii) (\u03c7 \u22121 G (\u03c7 G (v)) \u2229 S v )\\{v} \u0338 = \u2205. Based on the above paragraph, there exists v \u2032 \u2208 S u satisfying \u03c7 G (v \u2032 ) = \u03c7 G (v). Note that v \u2032 must connect to a node with color \u03c7 G (u). If condition (i) does not hold, i.e. \u03c7 \u22121 G (\u03c7 G (u)) \u2229 S u = {u}, then v \u2032 must connect to u. This means |N G (u) \u2229 \u03c7 \u22121 G (\u03c7 G (v))| \u2265 2. Again using \u03c7 \u22121 G (\u03c7 G (u)) \u2229 S v \u0338 = \u2205 (the above paragraph), we can pick such a node u \u2032 \u2208 \u03c7 \u22121 G (\u03c7 G (u)) \u2229 S v . By the WL-condition (Proposition C.4), |N G (u \u2032 ) \u2229 \u03c7 \u22121 G (\u03c7 G (v))| \u2265 2, which implies |S v \u2229 \u03c7 \u22121 G (\u03c7 G (v))| \u2265 2. Thus (\u03c7 \u22121 G (\u03c7 G (v)) \u2229 S v )\\{v} \u0338 = \u2205 holds,\nwhich is exactly the condition (ii). This paragraph is illustrated in Figure 7(b).\nBased on the above two paragraphs, by symmetry we can without loss of generality assume\n\u03c7 \u22121 G (\u03c7 G (u)) \u2229 S v \u0338 = \u2205 and (\u03c7 \u22121 G (\u03c7 G (u)) \u2229 S u )\\{u} \u0338 = \u2205.\nWe are now ready to derive a contradiction. To do this, pick\u0169 = arg max w\u2208\u03c7 \u22121 G (\u03c7 G (u)) dis G (u, w) and separately consider the following two cases:  \n\u2022\u0169 \u2208 S u . Then by picking a node x \u2208 S v \u2229 \u03c7 \u22121 G (\u03c7 G (u)), it follows that dis G (x,\u0169) = dis G (x, v) + dis G (u,\u0169) + 1 > dis G (u,\u0169).\nx \u2208 (S u \u2229 \u03c7 \u22121 G (\u03c7 G (u)))\\{u}, it follows that dis G (x,\u0169) \u2265 dis G (x, u) + dis G (u,\u0169) > dis G (u,\u0169).\nIn both cases, x and u cannot have the same color under SPD-WL because max\nw\u2208\u03c7 \u22121 G (\u03c7 G (u)) dis G (u, w) = dis G (u,\u0169) < dis G (x,\u0169) \u2264 max w\u2208\u03c7 \u22121 G (\u03c7 G (u)) dis G (x, w).\nThis yields a contradiction and concludes the proof.\nBased on Lemma C.27, in the subsequent proof we can without loss of generality assume\n\u03c7 \u22121 G (\u03c7 G (u)) \u2229 S u = {u} and \u03c7 \u22121 G (\u03c7 G (v)) \u2229 S u = \u2205.\nThis leads to the following lemma:\nLemma C.28. For any u 1 , u 2 \u2208 \u03c7 \u22121 G (\u03c7 G (u)), u 1 \u0338 = u 2 , any path from u 1 to u 2 goes through a node v \u2032 \u2208 \u03c7 \u22121 G (\u03c7 G (v)). Proof. Note that \u03c7 \u22121 G (\u03c7 G (u)) \u2229 S u = {u}. If |\u03c7 \u22121 G (\u03c7 G (u)) \u2229 S v | \u2264 1, the conclusion is clear since any path from u 1 to u 2 goes through v. Now suppose |\u03c7 \u22121 G (\u03c7 G (u)) \u2229 S v | > 1 and the lemma does not hold. Then there exist two different nodes u \u2032 1 , u \u2032 2 \u2208 \u03c7 \u22121 G (\u03c7 G (u)\n) \u2229 S v and a path P from u \u2032 1 to u \u2032 2 without going through any node in the set \u03c7 \u22121 G (\u03c7 G (v)). Pick u 1 , u 2 and P such that the length |P | is minimal. Split P into two parts P 1 and P 2 with endpoints {u 1 , w} and {w, u 2 } such that |P\n1 | \u2264 |P 2 | \u2264 |P 1 | + 1 and |P 1 | + |P 2 | = |P |. Note that |P | \u2265 2 since {u 1 , u 2 } / \u2208 E G (otherwise u cannot have the same color as u 1 because \u03c7 \u22121 G (u) \u2229 S u = {u}). Therefore, w \u0338 = u 1 and w \u0338 = u 2 . Also note that \u03c7 G (w) \u0338 = \u03c7 G (u) since |P | is minimal. Since SPD-WL satisfies the WL-condition (Proposition C.4), there is a path (not necessarily simple) from u to some w \u2032 \u2208 \u03c7 \u22121 G (\u03c7 G (w)) of length |P 1 | without going through nodes in the set \u03c7 \u22121 G (\u03c7 G (v)\n) (according to Lemma C.7). Therefore, w \u2032 \u2208 S u . See Figure 8 for an illustration of this paragraph.\nWe next prove that dis G (u,\nw \u2032 ) = |P 1 |. First, we obviously have dis G (u, w \u2032 ) \u2264 |P 1 |. Moreover, since w \u2032 , u \u2208 S u and \u03c7 \u22121 G (\u03c7 G (v)) \u2229 S u = \u2205 (Lemma C.27\n), any shortest path from w \u2032 to u does not go through nodes in the set \u03c7 \u22121 G (\u03c7 G (v)). Again using the WL-condition, there exists a path P 3 (not necessarily simple) from w to some u\n3 \u2208 \u03c7 \u22121 G (\u03c7 G (u)) of length |P 3 | = dis G (u, w \u2032 ) without going through nodes in the set \u03c7 \u22121 G (\u03c7 G (v)\n) (according to Lemma C.7). It follows that u 3 \u2208 S v . Consider the following two cases:\n\u2022 If u 3 = u 1 , by the minimal length of P we have |P 1 | \u2264 |P 3 | = dis G (u, w \u2032 ) \u2264 |P 1 | and thus dis G (u, w \u2032 ) = |P 1 |.\n\u2022 If u 3 \u0338 = u 1 , by linking the path P 1 and P 3 , there will be a path of length |P\n1 | + |P 3 | from u 1 to u 3 without going through nodes in \u03c7 \u22121 G (\u03c7 G (v)). Since P has the minimal length, |P 1 | + |P 2 | \u2264 |P 1 | + |P 3 |. Therefore, |P 2 | \u2264 |P 3 | = dis G (u, w \u2032 ) and thus by definition |P 1 | \u2264 |P 2 | \u2264 dis G (u, w \u2032 ) \u2264 |P 1 |. Therefore, |P 1 | = |P 2 | = dis G (u, w \u2032 ). Now define the set D(x) := {u \u2032 : u \u2032 \u2208 \u03c7 \u22121 G (\u03c7 G (u)), dis G (x, u \u2032 ) \u2264 |P 2 |}.\nLet us focus on the cardinality of the sets D(w) and D(w \u2032 ). It follows that D(w \u2032 ) = {u}, because for any other node\nu \u2032 \u2208 \u03c7 \u22121 G (\u03c7 G (u)), u \u2032 \u0338 = u, we have u \u2032 \u2208 S v and thus dis G (w \u2032 , u \u2032 ) > dis G (w \u2032 , v) = dis G (w \u2032 , u) + 1 = |P 1 | + 1 \u2265 |P 2 |.\nTherefore, |D(w \u2032 )| = 1. On the other hand, we clearly have |D(w)| \u2265 2 since both u 1 , u 2 \u2208 D(w). Consequently, w and w \u2032 cannot have the same color under the SPD-WL algorithm because |D(w \u2032 )| \u0338 = |D(w \u2032 )|. This yields a contradiction and completes the proof.\nThe next lemma presents an important property of the color graph G C (defined in Definition C.26).\nLemma C.29. G C has a cut edge {{\u03c7 G (u), \u03c7 G (v)}}. Proof. Suppose {{\u03c7 G (u), \u03c7 G (v)}} is not a cut edge of G C . Then there is a simple cycle (c 1 , \u2022 \u2022 \u2022 , c m ) where c 1 = \u03c7 G (u), c m = \u03c7 G (v)\nand m > 2. Namely, there exists a simple path from c 1 to c m with length \u2265 2. By the definition of G C and the WL-condition, there exists a sequence of nodes of G {w i } m i=1 where w 1 = u and \u03c7(w\ni ) = c i such that {w i , w i+1 } \u2208 E G , i \u2208 [m \u2212 1]. Note that w i \u0338 = u for i = {2, \u2022 \u2022 \u2022 , m} and w 2 \u0338 = v because (c 1 , \u2022 \u2022 \u2022 , c m ) is a simple path. Therefore, w i \u2208 S u for all i \u2208 [m]. However, it contradicts |S \u2229 S u | = 1 (Lemma C.27) since \u03c7 G (w m ) = \u03c7 G (v).\nCombining Lemmas C.27 to C.29, we arrived at the following corollary:\nCorollary C.30. For all u \u2032 \u2208 \u03c7 \u22121 G (\u03c7 G (u)) and v \u2032 \u2208 \u03c7 \u22121 G (\u03c7 G (v)), if {u \u2032 , v \u2032 } \u2208 E G , then it is a cut edge of G. Proof. If {u \u2032 , v \u2032 } is not a cut edge, there is a simple cycle going through {u \u2032 , v \u2032 }. Denote it as (w 1 , \u2022 \u2022 \u2022 , w m ) where w 1 = u \u2032 , w m = v \u2032 , m > 2. By Lemma C.27, w 2 / \u2208 \u03c7 G (v), otherwise u \u2032 will connect to at least two different nodes w 2 , w m \u2208 \u03c7 \u22121 G (\u03c7 G (v)\n) and thus u \u2032 and u cannot have the same color under SPD-WL. Let j be the index such that j = min{j \u2208 [m] : \u03c7 G (w j ) = \u03c7 G (v)}, then j > 2. Consider the path (w 1 , \u2022 \u2022 \u2022 , w j ). It follows that \u03c7 G (w k ) \u0338 = \u03c7 G (u) for all k \u2208 {2, \u2022 \u2022 \u2022 , j} by Lemma C.28 (otherwise there is a path from node w 1 to some node\nw i \u2208 \u03c7 \u22121 G (\u03c7 G (u)) (i \u2208 {2, \u2022 \u2022 \u2022 , j}) that does not go through nodes in the set \u03c7 \u22121 G (\u03c7 G (v)), a contradiction). Therefore, (\u03c7 G (w 1 ), \u2022 \u2022 \u2022 , \u03c7 G (w j )) is a path of length \u2265 2 in G C from \u03c7 G (u) to \u03c7 G (v) (not necessarily simple), without going through the edge {{\u03c7 G (u), \u03c7 G (v)}}. This contradicts Lemma C.29, which says that {{\u03c7 G (u), \u03c7 G (v)}} is a cut edge in G C . Based on Lemma C.29, the cut edge {{\u03c7 G (u), \u03c7 G (v)}} partitions the vertices C of the color graph G C into two classes. Denote them as {C u , C v } where \u03c7 G (u) \u2208 C u and \u03c7 G (v) \u2208 C v .\nThe next corollary characterizes the structure of the node colors calculated in SPD-WL. Corollary C.31. For any w satisfying \u03c7 G (w) \u2208 C u , there exists a cut edge  Proof. By the definition of C u , any node c \u2208 C u in the color graph can reach the node \u03c7 G (u) without going through \u03c7 G (v). Therefore, there exists some u \u2032 \u2208 \u03c7 \u22121 G (\u03c7 G (u)) such that there exists a path P 1 from w to u \u2032 without going through nodes in the set \u03c7 \u22121 G (\u03c7 G (v)). Also, there exists a node v \u2032 \u2208 N G (u \u2032 ) with \u03c7 G (v \u2032 ) = \u03c7 G (v) due to the color of u \u2032 . By Corollary C.30, {u \u2032 , v \u2032 } is a cut edge of G. Clearly, w \u2208 S u \u2032 .\n{u \u2032 , v \u2032 }, u \u2032 \u2208 \u03c7 \u22121 G (\u03c7 G (u)), v \u2032 \u2208 \u03c7 \u22121 G (\u03c7 G (v)), that partitions V into two classes S u \u2032 \u222a S v \u2032 , u \u2032 , w \u2208 S u \u2032 , v \u2032 \u2208 S v \u2032 , such that \u03c7 \u22121 G (\u03c7 G (u \u2032 )) \u222a S u \u2032 = {u \u2032 } and \u03c7 \u22121 G (\u03c7 G (v \u2032 )) \u222a S u \u2032 = \u2205. Remark C.\nv \u2032 = v. Then \u03c7 \u22121 G (\u03c7 G (u \u2032 )) \u222a S u \u2032 = {u \u2032 } and \u03c7 \u22121 G (\u03c7 G (v \u2032 )) \u222a S u \u2032 = \u2205\nWe next prove the following fact: for any x \u2208 S u \u2032 , \u03c7 G (x) \u2208 C u . Otherwise, one can pick a node x \u2208 S u \u2032 with color \u03c7 G (x) \u2208 C v . Consider the shortest path between nodes x and u \u2032 , denoted as (y 1 , \u2022 \u2022 \u2022 , y m ) where y 1 = x and y m = u \u2032 . It follows that y i \u2208 S u for all i \u2208 [m]. Denote \nc i = \u03c7 G (y i ), i \u2208 [m]. Then (c 1 , \u2022 \u2022 \u2022 , c m ) is a path (not necessarily simple) in the color graph G C . Now pick the index j = max{j \u2208 [m] : c j \u2208 C v } (which is well-defined because c 1 \u2208 C v ). It follows that j < m (since y m \u2208 C u ), c j = \u03c7 G (v) and c j+1 = \u03c7 G (u) (because {{\u03c7 G (u), \u03c7 G (v)\n}} is a cut edge that partitions the color graph G C into C u and C v ). Consider the following two cases (see Figure 9(b) for an illustration):\n\u2022 j = m\u22121. Then u \u2032 connects to both nodes y j and v \u2032 with color \u03c7 G (y\nj ) = \u03c7 G (v \u2032 ) = \u03c7 G (v).\nThis contradicts Lemma C.27 since u only connects to one node v with color \u03c7 G (v).\n\u2022\nj < m \u2212 1. Then y j+1 \u0338 = u \u2032 because the path (y 1 , \u2022 \u2022 \u2022 , y m ) is simple. Howover, one has \u03c7 G (y i ) \u0338 = \u03c7 G (v) for all i \u2208 {j +1, \u2022 \u2022 \u2022\n, m} by definition of j. This contradicts Lemma C.28.\nThis completes the proof that for any\nx \u2208 S u \u2032 , \u03c7 G (x) \u2208 C u . Therefore, \u03c7 \u22121 G (\u03c7 G (v \u2032 )) \u222a S u \u2032 = \u2205. We finally prove that \u03c7 \u22121 G (\u03c7 G (u)) \u222a S u \u2032 = {u \u2032 }. If not, pick u \u2032\u2032 \u2208 \u03c7 \u22121 G (\u03c7 G (u)\n) \u222a S u \u2032 and u \u2032\u2032 \u0338 = u \u2032 . By Lemma C.28, the shortest path between u \u2032 and u \u2032\u2032 goes through some node v \u2032\u2032 with color \u03c7 G (v). Clearly, v \u2032\u2032 \u2208 S u , which contradicts the above paragraph and concludes the proof.\nWe have already fully characterized the properties of cut edges {u \u2032 , v \u2032 } with color {\u03c7 G (u), \u03c7 G (v)}. Now we switch our focus to the graph H. We first prove a general result that holds for arbitrary H. Lemma C.33. Let {w 1 , w 2 } \u2208 E H and P is a path with the minimum length from w 1 to w 2 without going through edge {w 1 , w 2 }. In other words, linking path P with the edge {w 1 , w 2 } forms a simple cycle Q. Then for any two nodes\nx 1 , x 2 in Q, dis H (x 1 , x 2 ) = dis Q (x 1 , x 2 ).\nProof. Split the cycle Q into two paths Q 1 and Q 2 with endpoints {x 1 , x 2 } where Q 1 contains the edge {w 1 , w 2 } and Q 2 does not contain {w 1 , w 2 }. Assume the above lemma does not hold and dis H (w, x) < dis Q (w, x). It means that there exists a path R in H from x 1 to x 2 for which |R| < min(|Q 1 |, |Q 2 |). Note that the edge {u, v} occurs at most once in R. Separately consider two cases:\n\u2022 {w 1 , w 2 } occurs in R. Then linking R with Q 2 forms a cycle that contains {w 1 , w 2 } exactly once;\n\u2022 {w 1 , w 2 } does not occur in R. Then linking R with Q 1 forms a cycle that contains {w 1 , w 2 } exactly once.\nIn both cases, the cycle has a length less than |Q|. This contradicts the condition that P is a path with minimum length from w 1 to w 2 without passing edge {w 1 , w 2 }.\nWe can similarly consider the color graph H  \nh(c) = \u03c7 H (u) if dis H C (c, \u03c7 H (u)) < dis H C (c, \u03c7 H (v)), \u03c7 H (v) if dis H C (c, \u03c7 H (u)) > dis H C (c, \u03c7 H (v)).(11)\nNote that it never happens that dis\nH C (c, \u03c7 H (u)) = dis H C (c, \u03c7 H (v)) because {{\u03c7 H (u), \u03c7 H (v)}} is a cut edge of H C .\nAssume {u, v} is not a cut edge in H. Then there exists a path (w 1 , \u2022 \u2022 \u2022 , w m ) in H with w 1 = u and w m = v without going through {u, v}. We pick such a path with the minimum length, then the path is simple. Since h(\u03c7 H (u)) \u2208 C u and h(\u03c7 Since the graph representations of G and H are the same under SPD-WL, there exists a node w \u2032 with color \u03c7 G (w \u2032 ) = \u03c7 H (w k ) and two different nodes\nH (v)) \u2208 C v , there is a minimum index j \u2208 [m \u2212 1] such that h(\u03c7 H (w j )) \u2208 C\nu \u2032 1 , u \u2032 2 with color \u03c7 G (u \u2032 1 ) = \u03c7 G (u \u2032 2 ) = \u03c7 G (u), such that dis G (w \u2032 , u \u2032 1 ) = dis H (w k , w 1 ) and dis G (w \u2032 , u \u2032 2 ) = dis H (w k , w j ). In particular, |dis G (w \u2032 , u \u2032 1 ) \u2212 dis G (w \u2032 , u \u2032 2 )| \u2264 1.\nNote that by the definition of indices j and k, in the color graph H C there is a path from \u03c7 H (w k ) to \u03c7 H (u) without going through nodes in the set\n\u03c7 \u22121 H (\u03c7 H (v)), so \u03c7 H (w k ) \u2208 C u , namely \u03c7 G (w \u2032 ) \u2208 C u . By Corollary C.31, there is a cut edge {u \u2032 w , v \u2032 w } that partitions G into two vertex sets S u \u2032 w , S v \u2032 w , with w \u2032 , u \u2032 w \u2208 S u \u2032 w , v \u2032 w \u2208 S v \u2032 w . Note that u \u2032 w \u0338 = u \u2032\n1 and u \u2032 w \u0338 = u \u2032 2 (otherwise by Corollary C.31 any path from w \u2032 to a node u \u2032 \u0338 = u \u2032 w with color \u03c7 G (u \u2032 ) = \u03c7 G (u) must first go through u \u2032 w and then go through v \u2032 w , implying that |dis G (w\n\u2032 , u \u2032 1 ) \u2212 dis G (w \u2032 , u \u2032\n2 )| \u2265 2 and yielding a contradiction). Therefore, dis G (w\n\u2032 , u \u2032 1 ) > dis G (w \u2032 , u \u2032 w ) and dis G (w \u2032 , u \u2032 2 ) > dis G (w \u2032 , u \u2032 w ).\nWe give an illustration of the structure of G in Figure 10(b) based on this paragraph.", "publication_ref": [], "figure_ref": ["fig_19", "fig_19", "fig_20", "fig_23", "fig_0"], "table_ref": []}, {"heading": "Pick any", "text": "v w \u2208 \u03c7 \u22121 H (\u03c7 H (v)) satisfying dis H (v w , w k ) = dis G (v \u2032 w , w \u2032 ).\nDenote the operation dropmin(S) := S\\{{min S}} that takes a multiset S and removes one of the minimum elements in S. We have\ndropmin({{dis G (w \u2032 , u G ) : u G \u2208 \u03c7 \u22121 G (\u03c7 G (u))}}) = dropmin({{dis G (w \u2032 , v \u2032 w ) + dis G (v \u2032 w , u G ) : u G \u2208 \u03c7 \u22121 G (\u03c7 G (u))}}) (by Corollary C.31) = dropmin({{dis H (w k , v w ) + dis H (v w , u H ) : u H \u2208 \u03c7 \u22121 H (\u03c7 H (u))}}) and also dropmin({{dis G (w \u2032 , u G ) : u G \u2208 \u03c7 \u22121 G (\u03c7 G (u))) = dropmin({{dis H (w k , u H ) : u H \u2208 \u03c7 \u22121 H (\u03c7 H (u)\n)}}) due to the same color \u03c7 G (w \u2032 ) = \u03c7 H (w k ). Combining the above two equations and noting that dis H (w k , v w ) + dis H (v w , u H ) \u2265 dis H (w k , u H ), we obtain the following result: for any u H \u2208 \u03c7 \u22121 H (\u03c7 H (u)) for which dis H (w k , v w ) + dis H (v w , u H ) > dis G (w \u2032 , u \u2032 w ), dis H (w k , v w ) + dis H (v w , u H ) = dis H (w k , u H ). In particular, dis H (w k , w 1 ) = dis H (w k , v w ) + dis H (v w , w 1 ), dis H (w k , w j ) = dis H (w k , v w ) + dis H (v w , w j ).\nTherefore, dis H (w 1 , w j ) = dis H (w 1 , w k ) + dis H (w k , w j ) = 2dis H (w k , v w ) + dis H (v w , w 1 ) + dis H (v w , w j ) \u2265 2dis H (w k , v w ) + dis H (w 1 , w j ),\nWe can now prove some useful properties of the auxiliary graph G A based on Lemmas C.35 and C.36. Corollary C.37. For any c 1 , c 2 \u2208 C, {{(u, c 1 ), (u, c 2 )}} \u2208 E G A if and only if {{(v, c 1 ), (v, c 2 )}} \u2208 E G A .\nProof. By definition of E A G , if {{(u, c 1 ), (u, c 2 )}} \u2208 E G A , then there exists two vertices\nw 1 \u2208 f \u22121 G (u, c 1 ) and w 2 \u2208 f \u22121 G (u, c 2 ) such that {w 1 , w 2 } \u2208 E G . By Lemma C.36, either \u03c7 G (w 1 ) \u0338 = \u03c7 G (u) or \u03c7 G (w 2 ) \u0338 = \u03c7 G (u). Without loss of generality, assume c 1 \u0338 = \u03c7 G (u). By Lemma C.35, there exists x 1 \u2208 f \u22121 G (v, c 1 ). Since \u03c7 G (x 1 ) = \u03c7 G (w 1 ), x 1 must also connect to a node x 2 with \u03c7 G (x 2 ) = c 2 . The edge {x 1 , x 2 } \u0338 = {u, v} because \u03c7 G (x 1 ) = c 1 \u0338 = \u03c7 G (u). Therefore, f (x 2 ) = (v, c 2 ), namely {{(v, c 1 ), (v, c 2 )}} \u2208 E A G .\nThe following lemma establishes the distance relationship between graphs G and G A .\nLemma C.38. The following holds:\n\u2022 For any w, w \u2032 \u2208 V, dis G (w, w \u2032 ) \u2265 dis G A (f (w), f (w \u2032 )).\n\u2022 For any \u03be, \u03be \u2032 \u2208 V G A and any node w \u2208 f \u22121 G (\u03be), there exists a node\nw \u2032 \u2208 f \u22121 G (\u03be \u2032 ) such that dis G (w, w \u2032 ) = dis G A (\u03be, \u03be \u2032 ).\nProof. The first bullet is trivial since for all {w, w \u2032 } \u2208 E G , {{f (w), f (w \u2032 )}} \u2208 E G A by Definition C.34. We prove the second bullet in the following. Note that G A can have self-loops, but for any \u03be, \u03be \u2032 \u2208 V A , the shortest path between \u03be and \u03be \u2032 will not go through self-loops. We only need to prove that for all {{\u03be, \u03be \u2032 }} \u2208 E A , \u03be \u0338 = \u03be \u2032 and all w \u2208 f \u22121 G (\u03be), there exists w \u2032 \u2208 f \u22121 G (\u03be \u2032 ) such that {w, w \u2032 } \u2208 E G . This will imply that for any \u03be, \u03be \u2032 \u2208 V G A and any node w \u2208 f \u22121 G (\u03be), there exists a node \nw \u2032 \u2208 f \u22121 G (\u03be \u2032 ) such that dis G (w, w \u2032 ) \u2264 dis G A (\u03be, \u03be \u2032 ),\nx \u2208 f \u22121 G (\u03be) and x \u2032 \u2208 f \u22121 G (\u03be \u2032 ), such that {x, x \u2032 } \u2208 E G . Note that h G (x) = h G (x \u2032 ) because {x, x \u2032 } \u0338 = {u, v}. Since \u03c7 G (x) = \u03c7 G (w), there exists w \u2032 \u2208 \u03c7 \u22121 G (\u03c7 G (x \u2032 )\n) such that {w, w \u2032 } \u2208 E G . It must hold that h G (w) = h G (w \u2032 ) (otherwise {w, w \u2032 } = {u, v} and thus {{\u03be,\n\u03be \u2032 }} = {{(u, \u03c7 G (u)), (v, \u03c7 G (v))). Therefore, h G (w \u2032 ) = h G (w) = h G (x) = h G (x \u2032 ) and thus f G (w \u2032 ) = f G (x \u2032 ), namely w \u2032 \u2208 f \u22121 G (\u03be \u2032 ).\nLemma C.38 leads to the following corollary: Corollary C.39. The following holds:\n\u2022 For any w, w \u2032 \u2208 V satisfying \u03c7 G (w) = \u03c7 G (w \u2032 ) and h G (w) = h G (w \u2032 ) (i.e. f G (w) = f G (w \u2032 )), dis G (u, w) = dis G (u, w \u2032 ) and dis G (v, w) = dis G (v, w \u2032 ); \u2022 For any w, w \u2032 \u2208 V satisfying \u03c7 G (w) = \u03c7 G (w \u2032 ) and h G (w) \u0338 = h G (w \u2032 ), dis G (u, w) = dis G (v, w \u2032 ) and dis G (v, w) = dis G (u, w \u2032 ).\nProof. Proof of the first bullet: by Lemma C.38, there exists two nodes  We claim that all elements in the set D G,\u0338 = (w, c 1 ) are the same. This is because for any\nu 1 , u 2 \u2208 f \u22121 G (f G (u)) such that dis G (u 1 , w) = dis G A (f G (u), f G (w)) and dis G (u 2 , w \u2032 ) = dis G A (f G (u), f G (w \u2032 )). Therefore, dis G (u 1 , w) = dis G (u 2 , w \u2032 ).\n(w) = h G (w \u2032 ), it must be u 1 = u 2 = u, namely dis G (u, w) = dis G (u, w \u2032 ). The proof of dis G (v, w) = dis G (v \u2032 , w \u2032 ) is similar.\nx \u2208 \u03c7 \u22121 G (c 1 ), h G (x) \u0338 = h G (w), we have dis G (w, x) = dis G (w, h(w)) + 1 + dis G (h(x), x),\nand by Corollary C.39 dis G (h(x), x) has an equal value for different x. Since {w \u2032 , x \u2032 } \u2208 E H , we have 1 \u2208 D H,\u0338 = (w \u2032 , c 1 ) and thus all elements in D G,\u0338 = (w, c 1 ) equals 1. Therefore, c 1 = \u03c7 G (u). Analogously, c 2 = \u03c7 G (u). Therefore, c 1 = \u03c7 H (u) = \u03c7 H (v) = c 2 .\nLet S u = {w \u2208 V : h H (w) = u} and S v = {w \u2208 V : h H (w) = v}. Then the above argument implies that if w \u2208 S u , x \u2208 S v and {w, x} \u2208 E G , then {w, x} = {u, v}. Therefore {u, v} is a cut edge of graph H.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C.4.3 THE GENERAL CASE", "text": "The above proof assumes that the graphs G and H are both connected, and their graph representations are euqal, i.e. {{\u03c7 G (w) : w \u2208 V}} = {{\u03c7 H (w) : w \u2208 V}}. In the subsequent proof we remove these assumptions and prove the general setting. Lemma C.43. Either of the following two properties holds:\n\u2022 {{\u03c7 G (w) : w \u2208 V}} = {{\u03c7 H (w) : w \u2208 V}};\n\u2022 {{\u03c7 G (w) : w \u2208 V}} \u2229 {{\u03c7 H (w) : w \u2208 V}} = \u2205.\nProof. Consider the GD-WL procedure defined in Algorithm 4 with arbitrary distance function d G .\nSuppose at iteration t \u2265 T , {{\u03c7 t G (w) : w \u2208 V}} \u0338 = {{\u03c7 t H (w) : w \u2208 V}}. Then at iteration t + 1, we have for each\nv \u2208 V, \u03c7 t+1 G (v) = hash {{hash(d G (v, u), \u03c7 t G (u)) : u \u2208 V}} . Therefore, \u03c7 t+1 H (v) \u0338 = \u03c7 t+1 G (u) for all u \u2208 V G and v \u2208 V H , namely {{\u03c7 t+1 G(\nw) : w \u2208 V}} \u2229 {{\u03c7 t+1 H (w) : w \u2208 V}} = \u2205. Finally, by the injective property of the hash function, for any t \u2265 T + 1, the above equation always holds. Therefore, the stable color mappings \u03c7 G and \u03c7 H satisfy Lemma C.43.\nThe above lemma implies that if there exists edges {w 1 , w 2 } \u2208 E G , {x 1 , x 2 } \u2208 E H satisfying {{\u03c7 G (w 1 ), \u03c7 G (w 2 )}} = {{\u03c7 H (x 1 ), \u03c7 H (x 2 )}}, then {{\u03c7 G (w) : w \u2208 V}} = {{\u03c7 H (w) : w \u2208 V}}. Also, SPD-WL ensures that both graphs are either connected or disconnected. If they are both connected, the previous proof (Appendices C.4.1 and C.4.2) ensures that {w 1 , w 2 } is a cut edge of G if and only if {x 1 , x 2 } is a cut edge of H. For the disconnected case, let S G \u2282 V be the largest connected component containing nodes w 1 , w 2 , and similarly denote S H \u2282 V as the largest connected component containing nodes \nx 1 , x 2 . Obviously, |S G | = |S H | due to the facts that dis G (w 1 , y) = \u221e \u0338 = dis G (w 1 , y \u2032 ) for all y / \u2208 S G , y \u2032 \u2208 S G\n\u2208 S H , \u03c7 G (u G ) = \u03c7 H (u H ) implies that \u03c7 G[S G ] (u G ) = \u03c7 H[S H ] (u H ). Therefore, {w 1 , w 2 } is a cut edge of G[S G ] if and only if {x 1 , x 2 } is a cut edge of H[S H ]. By the dinifition of S G and S H , {w 1 , w 2 } is a cut edge of G if and only if {x 1 , x 2 } is a cut edge of H.\nIt remains to prove that {{\u03c7 G (w) : w \u2208 V}} = {{\u03c7 H (w) : w \u2208 V}} implies BCETree(G) \u2243 BCETree(H). By definition of the block cut-edge tree, each cut edge of G corresponds to a tree edge in BCETree(G) and each biconnected component of G corresponds to a node of BCETree(G). We still only focus on the case of connected graphs G, H, and it is straightforward to extend the proof to the general (disconnected) case using a similar technique as the previous paragraph.\nGiven a fixed SPD-WL graph representation R, consider any graphs G = (V, E G ) satisfying {{\u03c7 G (w) : w \u2208 V}} = R. Since we have proved that the SPD-WL node feature \u03c7 G (v), v \u2208 V precisely locates all the cut edges, the multiset\nC E := {{{\u03c7 G (u), \u03c7 G (v)} : {u, v} \u2208 E G is a cut edge}} \u2022 If v\nis not a cut vertex, given any nodes u, w, u \u0338 = v, w \u0338 = v, we can partition the set of all hitting paths P uw from u to w (not necessarily simple) into two sets P v uw and P v uw such that all paths P \u2208 P v uw contain v and no path P \u2208 P \n| = h G (u, v) + h G (v, w). We can similarly prove that h G (w, u) < h G (w, v) + h G (v, u).\n\u2022 If v is a cut vertex, then there exist two different nodes u, w \u2208 V, u \u0338 = v, w \u0338 = v, such that any path from u to w goes through v. A similar analysis yields the conclusion that h\nG (u, w) = h G (u, v) + h G (v, w) and h G (w, u) = h G (w, v) + h G (v, u).\nThis completes the proof of Lemma C.45.\nIn the subsequent proof, assume u \u2208 V is a cut vertex of G, and let {S i } m i=1 (m \u2265 2) be the partition of the vertex set V\\{u}, representing each connected component after removing node u. We have the following lemma (which has a similar form as Lemma C. \nG (u) \u0338 = \u03c7 1 H (v). Namely, \u03c7 G (u) \u0338 = \u03c7 H (v)\nfor all nodes u in G and v in H, implying that SPD-WL can distinguish the two graphs. On the other hand, if \u03ba(G) = \u03ba(H), then for any node u in G and v in H we have \u03c7 1 G (u) = \u03c7 1 H (v). Similarly, \u03c7 t G (u) = \u03c7 t H (v) for any iteration t \u2208 N, and thus SPD-WL cannot distinguish the two graphs.\nProof of the second item of Theorem C.58. The key insight is that given a distance-regular graph, the resistance distance between a pair of nodes (u, v) only depends on its SPD. Formally, for any nodes u, v, w, x in a distance-regular graph G, dis G (u, v) = dis G (w, x) implies that dis R G (u, v) = dis R G (w, x). Actually, we have the following stronger result:\nTheorem C.61. For any two nodes u, v in a connected distance-regular graph G,\ndis R G (u, v) = r dis G (u,v) where the sequence {r d } D(G)\nd=0 is recursively defined as follows:\nr d = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 0 if d = 0, r d\u22121 + 2 nk d\u22121 b d\u22121 D(G) i=d k i if d \u2208 [D(G)],(20)\nwhere\n\u03b9(G) = {b 0 , \u2022 \u2022 \u2022 , b D(G)\u22121 ; c 1 , \u2022 \u2022 \u2022 , c D(G) } is the intersection array of G and \u03ba(G) = (k 1 , \u2022 \u2022 \u2022 , k D(G)\n) is its k-hop-neighbor array.\nProof. Let R \u2208 R n\u00d7n be the RD matrix. Based on Theorem E.1, R can be expressed as R = diag(M)11 \u22a4 + 11 \u22a4 diag(M) \u2212 2M, where M = L + 1 n 11 \u22a4 \u22121 and L is the graph Laplacian matrix. Now let R = [r dis G (u,v) ] u,v\u2208V be the matrix with elements defined in (20). The key step is to prove that 2M = c11 \u22a4 \u2212 R for some c \u2208 R. This will yield\nR = 1 2 diag(c11 \u22a4 \u2212 R)11 \u22a4 + 11 \u22a4 diag(c11 \u22a4 \u2212 R) \u2212 c11 \u22a4 + R = R\n(since diag( R) = O) and finish the proof.\nWe now prove 2M = c11 \u22a4 \u2212 R for some c \u2208 R, namely L + 1 n 11 \u22a4 c11 \u22a4 \u2212 R = 2I. Note that R is a symmetric matrix and satisfy R1 = c 1 1 for some c 1 \u2208 R because G is distance-regular. Combined the fact that L1 = 0, we have\nL + 1 n 11 \u22a4 c11 \u22a4 \u2212 R = c \u2212 c 1 n 11 \u22a4 \u2212 L R.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "It thus suffices to prove that", "text": "L R = c11 \u22a4 \u2212 2I for some c \u2208 R. Let us calculate each element [L R] uv (u, v \u2208 V). We have [L R] uv = k 1 r dis G (u,v) \u2212 D(G) d=0 r d |N G (u) \u2229 N d G (v)|.(21)\nNow consider the following three cases:\n\u2022 u = v. In this case, r dis G (u,v) = 0 and we have u, v). In this case, in ( 21) the term\nD(G) d=1 r d |N G (u) \u2229 N d G (v)| = r 1 k 1 = 2(n \u2212 1) n by using b 0 = k 1 and k 0 = 0. Thus [L R] uv = \u2212 2(n\u22121) n . \u2022 u \u0338 = v and dis G (u, v) < D(G). Denote j = dis G (\nN G (u) \u2229 N d G (v) \u0338 = \u2205 only when d \u2208 {j \u2212 1, j, j + 1},", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "and by definition of intersection array", "text": "It thus suffices to prove that\n{{(\u03c7 t G (u, z), \u03c7 t G (z, v)) : z \u2208 V G }} = {{(\u03c7 t H (w, z), \u03c7 t H (z, x)) : z \u2208 V H }}.(24)\nBy Lemma C.60, we have\n{{(dis G (u, z), dis G (z, v)) : z \u2208 V G }} = {{(dis H (w, z), dis H (z, x)) : z \u2208 V H }}.\nThis already yields (24) by the induction result of iteration t. We thus complete the proof.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "D FURTHER DISCUSSIONS WITH PRIOR WORKS D.1 KNOWN METRICS FOR MEASURING THE EXPRESSIVE POWER OF GNNS", "text": "In this subsection, we review existing metrics used in prior works to measure the expressiveness of GNNs. We will discuss the limitations of these metrics and argue why biconnectivity may serve as a more reasonable and compelling criterion in designing powerful GNN architectures.\nWL hierarchy. Since the discovery of the relationship between MPNNs and 1-WL test Morris et al., 2019), the WL hierarchy has been considered as the most standard metric to guide designing expressive GNNs. However, achieving an expressive power that matches the 2-FWL test is already highly difficult. Indeed, each iteration of the 2-FWL algorithm already requires a complexity of \u2126(n 3 ) time and \u0398(n 2 ) space for a graph with n vertices (Immerman & Lander, 1990). Therefore, it is impossible to design expressive GNNs using this metric while maintaining its computational efficiency. Moreover, whether achieving higher-order WL expressiveness is necessary and helpful for real-world tasks has been questioned by recent works (Veli\u010dkovi\u0107, 2022).\nStructural metrics. Another line of works thus sought different metrics to measure the expressive power of GNNs. Several popular choices are the ability of counting substructures (Arvind et al., 2020;Chen et al., 2020;, detecting cycles (Loukas, 2020;Vignac et al., 2020;Huang et al., 2023), calculating the graph diameter (Garg et al., 2020;Loukas, 2020) or other graphrelated (combinatorial) problems (Sato et al., 2019). Yet, all these metrics have a common drawback: the corresponding problems may be too hard for GNNs to solve. Indeed, we show in Table 4 that solving any above task requires a computation complexity that grows super-linear w.r.t. the graph size even using advanced algorithms. Therefore, it is quite natural that standard MPNNs are not expressive for these metrics, since no GNNs can solve these tasks while being efficient. Consequently, instead of using GNNs to directly learn these metrics, these works had to use a precomputation step which can be costly in the worst case.  (Tarjan, 1972) Due to the lack of proper metrics, most subsequent works mainly justify the expressive power of their proposed GNNs by focusing on regular graphs Bodnar et al., 2021b;Feng et al., 2022;Velingker et al., 2022, to list a few), which hardly appear in practice.\nIn contrast, the biconnectivity metrics proposed in this paper are different from all prior metrics, in that (i) it is a basic graph property and has significant values in both theory and applications; (i) it can be efficiently calculated with a complexity linear in the graph size, and thus it is reasonable to expect that these metrics should be learned by expressive GNNs.", "publication_ref": ["b59", "b42", "b81", "b5", "b21", "b52", "b84", "b41", "b32", "b52", "b70", "b75", "b13", "b29", "b83"], "figure_ref": [], "table_ref": ["tab_5"]}, {"heading": "D.2 GNNS WITH DISTANCE ENCODING", "text": "In this subsection, we review prior works that are related to our proposed GD-WL. In the research field of expressive GNNs, the idea of incorporating distance first appeared in , where the authors mainly considered using distance encoding as node features and showed that distance can help distinguish regular graphs. They also considered an approach similar to k-hop aggregation by incorporating distance into the message-passing procedure (but without a systematic study).\nZhang & Li (2021) designed a subgraph GNN that also uses (generalized) distance encoding as node features in each subgraph. Ying et al. (2021a) designed a Transformer architecture that incorporates distance information and empirically showed excellent performance. Very recently, Feng et al. (2022) formally studied the expressive power of k-hop GNNs. Yet, they still restricted the analysis to regular graphs. The concurrent work of Abboud et al. (2022) designed the shortest path network which is highly similar to our proposed SPD-WL. They showed the resulting model can alleviate the bottlenecks and over-squashing problems for MPNNs (Alon & Yahav, 2021;Topping et al., 2022) due to the increased receptive field.\nCompared with prior works, our contribution lies in the following three aspects:\n\u2022 We formalize the principled and more expressive GD-WL framework, which comprises SPD-WL as a special case. Our framework is theoretically clean and generalizes all prior works in a unified manner.\n\u2022 We systematically and theoretically analyze the expressive power of SPD-WL for general graphs and highlight a fundamental advantage in distinguishing edge-biconnectivity.\n\u2022 We design a Transformer-based GNN that is provably as expressive as GD-WL. Thus, our framework is not only for theoretical analysis, but can also be easily implemented with good empirical performance on real-world tasks.\nDiscussions with the concurrent work of Velingker et al. (2022). After the initial submission, we became aware of a concurrent work (Velingker et al., 2022) which also explored the use of Resistance Distance to enhance the expressiveness of standard MPNNs. Here, we provide a comprehensive comparison of these two works. Overall, the main difference is that their approach incorporates RD (and several related affinity measures) into node/edge features (like Zhang & Li (2021)), while we combine RD to design a new WL aggregation procedure. As for the theoretical analysis, they only give a few toy examples of regular graphs to justify the expressive power beyond the 1-WL test, while we give a systematic analysis of the power of RD-WL for general graphs and point out that it is fully expressive for vertex-biconnectivity. In Velingker et al. (2022), the authors also made comparisons to SPD and conjectured that RD may have additional advantages than SPD in terms of expressiveness. In fact, this question is formally answered in our work, by proving that RD-WL is expressive for vertex-biconnectivity while SPD-WL is not. Another important contribution of our work is that we provide an upper bound of the expressive power of RD-WL to be 2-FWL (3-WL), which reveals the limit of incorporating RD information. We also provide a precise and complete characterization for the expressiveness of RD-WL in distinguishing distance-regular graphs, which reveals that RD-WL can match the power of 2-FWL in distinguishing these hard graphs.", "publication_ref": ["b29", "b1", "b4", "b78", "b83", "b83", "b83"], "figure_ref": [], "table_ref": []}, {"heading": "E IMPLEMENTATION OF GENERALIZED DISTANCE WEISFEILER-LEHMAN", "text": "In this section, we give implementation details of GD-WL and our proposed GNN architecture. We also give detailed analysis of its computation complexity. Below, assume the input graph G = (V, E) has n vertices and m edges.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "E.1 PREPROCESSING SHORTEST PATH DISTANCE", "text": "Shortest Path Distance can be easily calculated using the Floyd-Warshall algorithm (Floyd, 1962), which has a complexity of \u0398(n 3 ). For sparse graphs typically encountered in practice (i.e. m = o(n 2 )), a more clever way is to use breadth-first search that computes the distance from a given node to all other nodes in the graph. The time complexity can be improved to \u0398(nm).\n(SUN)  is developed based on the symmetry analysis of a series of existing Subgraph GNNs and an upper bound on their expressive power, which theoretically unifies previous architectures and performs well across several graph representation learning benchmarks.\nLast, we compare several Graph Transformer models. GraphTransformer (GT) (Dwivedi & Bresson, 2021) uses the Transformer model on graph tasks, which only aggregates the information from neighbor nodes to ensure graph sparsity, and proposes to use Laplacian eigenvector as positional encoding. Spectral Attention Network (SAN) (Kreuzer et al., 2021) uses a learned positional encoding (LPE) that can take advantage of the full Laplacian spectrum to learn the position of each node in a given graph. Graphormer (Ying et al., 2021a) develops the centrality encoding, spatial encoding, and edge encoding to incorporate the graph structure information into the Transformer model. Universal RPE (URPE) (Luo et al., 2022b) first shows that there exist continuous sequenceto-sequence functions which RPE-based Transformers cannot approximate, and develops a novel and universal attention module called Universal RPE-based Attention. The effectiveness of URPE has been verified across language and graph benchmarks (e.g., the ZINC dataset).\nSettings. Our Graphormer-GD consists of 12 layers. The dimension of hidden layers and feedforward layers are set to 80. The number of Gaussian Basis kernels is set to 128. The number of attention heads is set to 8. The batch size is selected from [128,256,512]. We use AdamW (Kingma & Ba, 2014) as the optimizer, and set its hyperparameter \u03f5 to 1e-8 and (\u03b2 1 , \u03b2 2 ) to (0.9, 0.999). The peak learning rate is selected from [4e-4, 5e-4]. The model is trained for 600k and 800k steps with a 60K-step warm-up stage for ZINC-Subset and ZINC-Full respectively. After the warm-up stage, the learning rate decays linearly to zero. The dropout ratio is selected from [0.0, 0.1]. The weight decay is selected from [0.0, 0.01]. All models are trained on 4 NVIDIA Tesla V100 GPUs.", "publication_ref": ["b30", "b26", "b49", "b86", "b54", "b46"], "figure_ref": [], "table_ref": []}, {"heading": "F.3 MORE TASKS", "text": "Node-level Tasks. We further conduct experiments on real-world node-level tasks. Following , we benchmark our model on two real-world graphs: Brazil-Airports and Europe-Airports, both of which are air traffic networks and are collected by Ackland et al. (2005) from the government websites. The nodes in each graph represent airports and each edge represents that there are commercial flights between the connected nodes. The Brazil-Airports graph has 131 nodes, 1038 edges in total and its diameter is 5. The Europe-Airports graph has 399 nodes, 5995 edges in total and its diameter is 5. The airport nodes are divided into 4 different levels according to the annual passenger flow distribution by 3 quantiles: 25%, 50%, and 75%. The task is to predict the level of each airport node. We follow  to split the nodes of each graph into train/validation/test subsets with the ratio being 0.8/0.1/0.1, respectively. The test accuracy of the best checkpoint on the validation set is reported. We use different seeds to repeat the experiments 20 times and report the average accuracy.\nFollowing , we choose several competitive baselines including classical MPNNs (GCN, GraphSAGE, GIN), Struc2vec and Distance-encoding based GNNs (DE-GNN-SPD, DE-GNN-LP, DEA-GNN-SPD). We refer interested readers to  for detailed descriptions of baselines. For our Graphormer-GD, the dimension of hidden layers and feed-forward layers are set to 80. The number of layers is selected from [3,6]. The number of Gaussian Basis kernels is set to 128. The number of attention heads is set to 8. The batch size is selected from [4,8,16,32]. We use AdamW (Kingma & Ba, 2014) as the optimizer, and set its hyperparameter \u03f5 to 1e-8 and (\u03b2 1 , \u03b2 2 ) to (0.9, 0.999). The peak learning rate is selected from [2e-4, 7e-5, 4e-5]. The total number of training steps is selected from [500,1000,2000]. The ratio of the warm-up stage is set to 10%. After the warm-up stage, the learning rate decays linearly to zero. The dropout ratio is selected from [0.0, 0.1, 0.5]. All models are trained on 1 NVIDIA Tesla V100 GPUs.\nThe results are presented in Table 5. We can see that our model outperforms these baselines on both datasets with a slightly larger variance value due to the small scale of the datasets.", "publication_ref": ["b2", "b46"], "figure_ref": [], "table_ref": []}, {"heading": "F.4 EFFICIENCY EVALUATION", "text": "We further conduct experiments to measure the efficiency of our approach by profiling the time cost per training epoch. We compare the efficiency of Graphormer-GD with other baselines along with the number of model parameters on the ZINC-subset from . The number of layers and the hidden dimension of our Graphormer-GD are set to 12 and 80 respectively. The number of attention heads is set to 8. The batch size is set to 128, which is the same as the settings of all baselines. We run profiling of all models on a 16GB NVIDIA Tesla V100 GPU. For all baselines, we evaluate the time costs based on the publicly available codes of  and Ying et al. (2021a). The results are presented in Table 6.\nFrom Table 6, we can draw the following conclusions. Firstly, the efficiency of Graphormer-GD is in the same order of magnitude as classic MPNNs despite the fact that the computation complexity of Graphormer-GD is higher than MPNNs (i.e., \u0398(n 2 ) v.s. \u0398(n + m) for a graph with n nodes and m edges). This may be due to the high parallelizability of the Transformer layers. Secondly, Graphormer-GD is much more efficient than higher-order GNNs as reflected by the computation complexity in Table 1. Finally, Graphormer-GD is almost as efficient as the original Graphormer, since the newly introduced module to encode the Resistance Distance takes negligible additional time compared to that of the whole architecture.   505,341 6.02 MoNet (Monti et al., 2017) 504,013 7.19 GIN  509,549 8.05 GAT  531,345 8.28 GatedGCN-PE (Bresson & Laurent, 2017) ", "publication_ref": ["b86", "b58", "b16"], "figure_ref": [], "table_ref": ["tab_6", "tab_6"]}, {"heading": "", "text": "implying w k = v w . However, \u03c7 H (w k ) \u2208 C u while \u03c7 H (v w ) \u2208 C v , yielding a contradiction.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C.4.2 THE CASE OF \u03c7 G (u) = \u03c7 G (v) FOR CONNECTED GRAPHS", "text": "We first define several notations. Define the mapping f G : V \u2192 {u, v} \u00d7 C as follows: f G (w) = (h G (w), \u03c7 G (w)) where\nIt is easy to see that h G is well-defined for all w \u2208 V because {u, v} is a cut edge of G. We further define the following auxiliary graph: Definition C.34. (Auxiliary graph) Define the auxiliary graph G A = (V G A , E G A ) where V G A := {u, v} \u00d7 C and E G A := {{{f G (w 1 ), f G (w 2 )}} : {w 1 , w 2 } \u2208 E G }. Note that G A can have self loops, so each edge is denoted as a multiset with two elements.\nIt is straightforward to see that there is only one edge in G A with the form {{(u, c 1 ), (v, c 2 )}} \u2208 E G A for some c 1 , c 2 \u2208 C since {u, v} is a cut edge of G. Therefore, the only edge is {{(u, \u03c7 G (u)), (v, \u03c7 G (v))}} and is a cut edge in G A .\nWe also define f \u22121 G as the inverse mapping of f G , i.e. f \u22121 G (z, c) = {w \u2208 V : f G (w) = (z, c)}. We first prove that f \u22121 G is well-defined on the domain V G A . Lemma C.35. f G is a surjection.\nProof. Suppose that f G is not a surjection. Then there exists a color c \u2208 C such that either f \u22121 G (u, c) or f \u22121 G (v, c) is an empty set. Without loss of generality, assume f \u22121 G (v, c) = \u2205, then f \u22121 G (u, c) \u0338 = \u2205. Pick any w \u2208 f \u22121 G (u, c). Obviously, w \u0338 = u (otherwise f \u22121 G (v, \u03c7 G (v)) = \u2205, a contradiction). Then we claim that for any x \u2208 N G (w), f \u22121 G (v, \u03c7 G (x)) is empty. Note that x \u2208 f \u22121 G (u, \u03c7 G (x)). If the claim does not hold, take x \u2032 \u2208 f \u22121 G (v, \u03c7 G (x)). Since x connects to a node with color c and \u03c7 G (x) = \u03c7 G (x \u2032 ), x \u2032 must also connect to a node with color c. Denote the node that connects to x \u2032 with color c as w \u2032 . Then w \u2032 \u2208 f \u22121 G (v, c), yielding a contradiction. By induction, for any x such that there exists a path from x to w without going through the edge {u, v}, we have f \u22121 G (v, \u03c7 G (x)) = \u2205. This finally implies f \u22121 G (v, \u03c7 G (v)) = \u2205, leading to a contradiction. Therefore, f is a surjection.\nProof. Pick u \u2032 = arg max u \u2032 \u2208f \u22121 G (u,\u03c7(u)) dis G (u, u \u2032 ) and similarly pick v \u2032 . It follows that any path between u \u2032 and v \u2032 goes through edge {u, v}. Therefore, dis G (u \u2032 , v \u2032 ) = dis G (u, u \u2032 )+dis G (v, v \u2032 )+1. Since all nodes u, u \u2032 , v, v \u2032 have the same color under SPD-WL, there exists a node w \u2208 \u03c7 \u22121 G (\u03c7 G (u)) satisfying dis G (u, w) = dis G (u \u2032 , v \u2032 ) and thus dis G (u, w) > dis G (u, u \u2032 ). By definition of the node u \u2032 , f G (w) \u0338 = (u, \u03c7(u)) and thus f G (w) = (v, \u03c7(u)). Therefore, dis G (u, w) = dis G (v, w) + 1, which implies that dis G (v, w) = dis G (v, v \u2032 ) + dis G (u, u \u2032 ).\nSince dis G (v, w) \u2264 dis G (v, v \u2032 ), we have dis G (v, w) = dis G (v, v \u2032 ) and u = u \u2032 . A similar argument yields v = v \u2032 , finishing the proof. Next, we switch our focus to the graph H. Since we have assumed that the graph representations of G and H are the same, i.e. {{\u03c7 G (w) : w \u2208 V}} = {{\u03c7 H (w) : w \u2208 V}}, the size of the set {w \u2208 V : \u03c7 H (w) = \u03c7 G (u)} must be 2. We may denote the elements as u and v without abuse of notation and thus {u, v} \u2208 E H . Also for any w \u2208 V, we have dis H (w, u) \u0338 = dis H (w, v). Therefore, we can similarly define the mapping f H : V \u2192 {u, v} \u00d7 V and the mapping h H : V \u2192 {u, v} as in (12). The auxiliary graph H A is defined analogous to Definition C.34. Lemma C.41. For any c \u2208 C, |f \u22121 H (u, c\nimplying that u and v cannot have the same color under SPD-WL. This already concludes the proof by using Corollary C.40 as\nWe finally present a technical lemma which will be used in the subsequent proof. Lemma C.42. Given node w \u2208 V and color c \u2208 C, define multisets\nwhich concludes the proof.\nIn the following, we will prove that {u, v} is a cut edge in graph H. Consider an edge {{(u, c 1 ), (v, c 2 )}} \u2208 E H A (such an edge exists because {{(u, \u03c7 H (u)), (v, \u03c7 H (v))}} \u2208 E A H ). We will prove that this is the only case, i.e. it must be c\nSince w \u2032 and w have the same color under SPD-WL,\nis fixed (fully determined by R, not G). Denote C V := {c1,c2}\u2208C E {c 1 , c } as the set that contains the color of endpoints of all cut edges. For each cut edge {u, v} \u2208 E G , denote S G,u and S G,v be the vertex partition corresponding to the two connected components after removing the edge {u, v},\nIt suffices to prove that given a cut edge {u, v} \u2208 E G with color {\u03c7 G (u), \u03c7 G (v)}, the multiset {{\u03c7 G (w) : w \u2208 S G,u , \u03c7 G (w) \u2208 C V }} can be determined purely based on R and the edge color {{\u03c7 G (u), \u03c7 G (v)}}, rather than the specific graph G or edge {u, v}. This basically concludes the proof, since the BCETree can be uniquely constructed as follows: if {{\u03c7 G (w) : w \u2208 S G,u , \u03c7 G (w) \u2208 C V }} = {{\u03c7 G (u)}} (i.e. with only one element), then {{\u03c7 G (u), \u03c7 G (v)}} is a leaf edge of the BCETree such that \u03c7 G (u) connects to a biconnected component that is a leaf of the BCETree. After finding all the leaf edges, we can then find the BCETree edges that connect to leaf edges and determine which leaf edges they connect. The procedure can be recursively executed until the full BCETree is constructed. The whole procedure does not depend on the specific graph G and only depends on R.\nWe now show how to determine {{\u03c7 G (w) :\nwhere {{c}} \u00d7 m denotes a multiset with m repeated elements c, and D(c u , c) + 1 := {{d + 1 : \u2022 For any two nodes w \u2208 V in G and x \u2208 V in H, if \u03c7 G (w) = \u03c7 H (x), then w is a cut vertex of G if and only if x is a cut vertex of H.\n\u2022 If the graph representations of G and H are the same under RD-WL, then their block cut-vertex trees (Definition 2.4) are isomorphic. Mathematically, {{\u03c7 G (w) : w \u2208 V}} = {{\u03c7 H (w) : w \u2208 V}} implies that BCVTree(G) \u2243 BCVTree(H).\nProof Sketch. First observe that Lemma C.43 holds for general distances and thus applies here. Therefore, if \u03c7 G (w) = \u03c7 H (x), the graph representations will be the same, i.e. {{\u03c7 G (w) : w \u2208 V}} = {{\u03c7 H (w) : w \u2208 V}}. By a similar analysis as SPD-WL (Appendix C.4.3), we can only focus on the case that both graphs are connected. We prove the first bullet of Theorem 4.2 in Appendix C.5.1 and prove the second bullet in Appendix C.5.2, both assuming that G and H are connected and their graph representations are the same.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C.5.1 PROOF OF THE FIRST PART", "text": "We first present a key property of the Resistance Distance, which surprisingly relates to the cut vertices in a graph. Lemma C.45. Let G = (V, E) be a connected graph and v \u2208 V. Then v is a cut vertex of G if and only if there exists two nodes u, w\nProof. We use the key finding that the Resistance Distance is equivalent to the Commute Time Distance multiplied by a constant (Chandra et al., 1996, see also Appendix E.2), i.e. dis C G (u, w) = 2|E| dis R G (u, w). Here, the Commute Time Distance is defined as dis C G (u, w) := h G (u, w) + h G (w, u) where h G (u, w) is the average hitting time from u to w in a random walk (Appendix E.2).\nLemma C.46. There is at most one set\nand thus Lemma C.46 clearly holds. Otherwise, u i \u2208 S i for some i. We will prove that for any j\nIf the above conclusion does not holds, then we can pick a set S j and a vertex u j \u2208 S j \u2229\u03c7 \u22121 G (\u03c7 G (u)). Since u is a cut vertex and S i , S j are different connected components, by Lemma C.45 we have\n, which means that u and u i cannot have the same RD-WL color.\nThe next lemma presents a key result which is similar to Corollary C.30.\nProof. If |\u03c7 \u22121 G (\u03c7 G (u))| = 1, then Lemma C.47 clearly holds. Otherwise, by Lemma C.46 there exists two sets S i and S j satisfying\nthere exists a node w \u2032 \u2208 \u03c7 \u22121 G (\u03c7 G (w)) such that dis R G (u, w) = dis R G (u \u2032 , w \u2032 ). Then we have 15) where ( 14) holds because u is a cut vertex and all u \u2032\u2032 \u0338 = u are in the set S i but w \u2208 S j (Lemma C.46), and (15) holds because \u03c7 G (u) = \u03c7 G (u \u2032 ). On the other hands,\n). Pick u \u2032\u2032 = u, then clearly u \u2032\u2032 \u0338 = u \u2032 and u \u2032\u2032 \u0338 = w. Lemma C.45 shows that u \u2032 is a cut vertex, which concludes the proof. See Figure 11 for an illustration of the above proof. \nwhere w is defined in the proof of Lemma C.47. Then, there exists u\n. Following the procedure of the above proof, we can obtain that dis R H (w H , u\nand we can denote the node in \u03c7 \u22121 H (\u03c7 G (u)) as u without abuse of notation. Choose arbitrary two nodes w 1 \u2208 S 1 and w 2 \u2208 S 2 , then dis R\nand u is a cut vertex in H (Lemma C.45).", "publication_ref": ["b19"], "figure_ref": [], "table_ref": []}, {"heading": "C.5.2 PROOF OF THE SECOND PART", "text": "We first introduce some notations. As before, we assume G and H are connected and {{\u03c7 G (w) : w \u2208 V}} = {{\u03c7 H (w) : w \u2208 V}}. As we will consider multiple cut vertices in the following proof, we adopt the notation\n, which represents the set of connected components of graph G after removing node u. Here, m G (u) is the number of connected components after removing node u, which is greater than 1 if u is a cut vertex. It follows that\nbe two indices and pick nodes w \u2208 S G,i (u) and w \u2032 \u2208 S H,j (u \u2032 ). Assume w and w \u2032 have the same color, i.e. \u03c7 G (w) = \u03c7 H (w \u2032 ). Then the following holds:\nProof. Proof of the first bullet: since i \u2208 M G (u), any path from w to a node\nSince the color of nodes w and w \u2032 are the same under RD-WL, we have\nand thus dis R H (w \u2032 , u \u2032 ) = dis R G (w, u). Proof of the second bullet: first note that dis R H (w \u2032 , u\nIf the lemma does not hold, then dis R H (w \u2032 , u \u2032 ) = dis R G (w, u). Consequently,\n) because w \u2032 and u \u2032\u2032 are in the same connected component (Lemma C.45). This yields a contradiction and concludes the proof.\nThen either of the following holds:\nThen there exists nodes w \u2208 S G,i (u) in G and w \u2032 \u2208 S H,j (u \u2032 ) in H, satisfying \u03c7 G (w) = \u03c7 H (w \u2032 ). Our goal is to prove that {{\u03c7 G (w) : w \u2208 S G,i (u)}} = {{\u03c7 H (w) : w \u2208 S H,j (u \u2032 )}}. It thus suffices to prove that for any color  Lemma C.48 and Corollary C.49 leads to the following key corollary:", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "This is simply because for any", "text": ".\nProof. If both u and u \u2032 are not cut vertices, Corollary C.51 trivially holds since m G (u) = m H (u \u2032 ) = 1 and S G,1 (u) = V\\{u}, S H,1 (u \u2032 ) = V\\{u \u2032 }. Now assume u and u \u2032 are both cut vertices. We first claim that\nTo prove the claim, it suffices to prove that for each color c \u2208 C,\nAlso note that by Lemma C.48, for any two nodes w\nIn other words, the following two sets does not intersect:\n). This proves (17) and thus ( 16) holds.\nWe next claim that\nThis simply follows by using ( 16) and Corollary C.49. Finally, ( 18) already yields the desired conclusion because:\nIn both cases, Corollary C.51 holds.\nWe are now ready to prove that {{\u03c7 G (w) :\nRecall that in a block cut-vertex tree BCVTree(G), there are two types of nodes: all cut vertices of G, and all biconnected components of G. Each edge in BCVTree(G) is connected between a cut vertex u \u2208 V and a biconnected component B \u2282 V such that u \u2208 B.\nGiven a fixed RD-WL graph representation R, consider any graph G = (V, E G ) satisfying {{\u03c7 G (w) : w \u2208 V}} = R. First, all cut vertices of G can be determined purely from R using the node colors. We denote the cut vertex color multiset as\nNext, the number m G (u) for each cut vertex u can be determined only by its color \u03c7 G (u) (by Corollary C.51), which is equal to the degree of node u in BCVTree(G). We now give a procedure to construct BCVTree(G), which purely depends on R rather than the specific graph G.\nWe examine the multisets T (u) := {{{{\u03c7 G (w) :\nfor all cut vertices u, which only depends on R and \u03c7 G (u) rather than the specific graph G or node u by Corollary C.51. See Figure 12(b) for an illustration of T (u) for four types of cut vertices u. In the first step, we find all cut vertices u such that S\u2208T\nis the indicator function. In other words, we find cut vertices u such that there is at most one connected component S G,i (u) that contains cut vertices. These cut vertices u will serve as \"leaf (cut vertex) nodes\" in BCVTree(G), in the sense that it connects to at most one internal node in BCVTree(G). The number of BCVTree leaf After finding all the \"leaf (cut vertex) nodes\", we can then find cut vertex nodes v such that when removing all \"leaf (cut vertex) nodes\" in the BCVTree, v will serve as a \"leaf (cut vertex) node\". To do this, we compute for each cut vertex v and each biconnected component B v associated with v, whether B v has no cut vertex or all cut vertices in B v correspond to the \"leaf (cut vertex) nodes\" in BCVTree(G). Then, we check whether a cut vertex v satisfies\nu contains all colors corresponding to \"leaf (cut vertex) nodes\". These vertices v will serve as new \"leaf (cut vertex) nodes\" when removing all \"leaf (cut vertex) nodes\" in the BCVTree, and the connection between such vertices v and \"leaf (cut vertex) nodes\" can also be determined (see Figure 12(d) for an illustration). The procedure can be recursively executed until the full BCVTree is constructed (see Figure 12(f)), and the whole procedure does not depend on the specific graph G and only depends on R, which completes the proof.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C.6 PROOF OF THEOREM 4.5", "text": "Given a graph G = (V, E), let \u03c7 t G be the 2-FWL color mapping after the t-th iteration (see Algorithm 2 for details), and let \u03c7 G be the stable 2-FWL color mapping. The following result is useful for the subsequent proof:\nbe nodes in graph G and t be an integer. The following holds:\nProof. By the initial coloring (6) of 2-FWL, \u03c7 G (u, v) can have the following three types of values: \n2 ) using ( 19). This concludes the proof of the case t \u2265 1 by a simple induction.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "For a path", "text": ") which is a tuple of length d \u2212 1. We have the following key lemma:\n, then the following holds:\n) be the set of all paths (not necessarily simple) from node u to node v of length d.\n) be the set of all hitting paths (not necessarily simple) from node u to node v of length d. Then, {{\u03c9(Q) :\nProof. We prove the lemma by induction over iteration t. We first prove the base case t = 0.\n\u2022 If u 1 = v 1 , then by Lemma C.52 u 2 = v 2 . Note that obviously |P 1 (u, u)| = 0 and |Q 1 (u, u)| = 0 for any node u, namely\nwhere both sets have a single element that is an empty tuple (0-dimension).\nNow suppose that the conclusion of Lemma C.53 holds in iteration t, we will prove that it also holds in iteration t + 1. First note that for any two nodes u, v,\n, then by definition of 2-FWL update formula ( 19) v2) |P t+1 (u 2 , w)| and thus we have\nFurther using the third bullet of Lemma C.52 and rearranging the two multisets yields\nThis concludes the proof of the induction step.\nThe above lemma directly yields the following corollary:", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "As for the Resistance Distance dis R", "text": "G , it is equivalent to the Commute Time Distance multiplied by a constant (Chandra et al., 1996\nwhere Q i (u, v) is the set containing all hitting paths of length i from u to v, and q(P\n. By Lemma C.53, we have P \u2208Qi(u1,v1) q(P ) = P \u2208Qi(u2,v2) q(P ) and P \u2208Qi(v1,u1) q(P ) = P \u2208Qi(v2,u2) q(P ) for all i \u2265 0 (the case i = 0 trivially holds) and thus\nWe are now ready to prove Theorem 4.5.\nTheorem C.55. The 2-FWL algorithm is more powerful than both SPD-WL and RD-WL. \nw 2 ) for some nodes w 1 and w 2 , then \u03c7 G (w 1 ) = \u03c7 G (w 2 ). Therefore, by using Corollary C.54 we obtain that if \u03c7\nThe above equantions show that the partition induced by \u03c7 2FWL G is finer than both \u03c7 SPDWL G and \u03c7 RDWL G and conclude the proof.\nFinally, the following proposition trivially holds and will be used to prove Corollary 4.6.\nProposition C.56. Given a graph G = (V, E G ), let \u03c7 G and\u03c7 G be two color mappings induced by two different (general) color refinement algorithms, respectively. If the vertex partition induced by the mapping \u03c7 G is finer than that of\u03c7 G , then:\n\u2022 The mapping \u03c7 G can distinguish cut vertices/edges if\u03c7 G can distinguish cut vertices/edges;\n\u2022 The mapping \u03c7 G can distinguish the isomorphism type of BCVTree(G)/BCETree(G) if\u03c7 G can distinguish the isomorphism type of BCVTree(G)/BCETree(G).\nCorollary 4.6 is a simple consequence of Theorem 4.5 and Proposition C.56.", "publication_ref": ["b19"], "figure_ref": [], "table_ref": []}, {"heading": "C.7 PROOF OF THEOREM 4.7", "text": "In this subsection, we give more fine-grained theoretical results on the expressiveness upper bound of GD-WL by considering the special problem of distinguishing distance-regular graphs, a class of hard graphs that are highly relevant to the GD-WL framework. We provide a full characterization of what types of distance-regular graphs different GD-WL algorithms can or cannot distinguish, with both proofs and counterexamples.\nGiven a graph G = (V, E), let N i G (u) = {w \u2208 V : dis G (u, w) = i} be the i-hop neighbors of u in G and let D(G) := max u,v\u2208V dis G (u, v) be the diameter of G. We say G is distanceregular if for all i, j \u2208 [D(G)] and all nodes u, v, w, x \u2208 V with dis G (u, v) = dis G (w, x), we have\nFrom the definition, it is straightforward to see that for all u, v \u2208 V and\n, the number of i-hop neighbors is the same for all nodes. We thus denote \u03ba(G) \nWe now present our main results. Theorem C.58. Let G and H be two connected distance-regular graphs. Then the following holds:\n\u2022 SPD-WL can distinguish the two graphs if and only if their k-hop-neighbor arrays differ, i.e. \u03ba(G) \u0338 = \u03ba(H).\n\u2022 RD-WL can distinguish the two graphs if and only if their intersection arrays differ, i.e. \u03b9(G) \u0338 = \u03b9(H).\n\u2022 2-FWL can distinguish the two graphs if and only if their intersection arrays differ, i.e. \u03b9(G) \u0338 = \u03b9(H).\nTheorem C.58 precisely characterizes the equivalence class of all distance-regular graphs for different types of algorithms. Combined the fact that \u03b9(G) = \u03b9(H) implies \u03ba(G) = \u03ba(H) (see e.g. van Dam et al. (2014, page 8)), we immediately arrive at the following corollary: Corollary C.59. RD-WL is strictly more powerful than SPD-WL in distinguishing non-isomorphic distance-regular graphs. Moreover, RD-WL is as powerful as 2-FWL in distinguishing nonisomorphic distance-regular graphs.\nCounterexamples. We provide representitive counterexamples in Figure 3 for both SPD-WL and RD-WL. In Figure 3(a), both the Dodecahedron and the Desargues graph have 20 vertices and the same k-hop-neighbor array (3, 6, 6, 3, 1), and thus SPD-WL cannot distinguish them. However, they have the different intersection array (i.e., {3, 2, 1, 1, 1; 1, 1, 1, 2, 3} for Dodecahedron and {3, 2, 2, 1, 1; 1, 1, 2, 2, 3} for the Desargues graph), and thus RD-WL can distinguish them. In Figure 3(b), we make use of the well-known 4x4 rook's graph and the Shrikhande graph, both of which are strongly regular and thus distance-regular. They have the same intersection array {6, 3; 1, 2} and thus both RD-WL and 2-FWL cannot distinguish them although they are non-isomorphic.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C.7.1 PROOF OF THEOREM C.58", "text": "We first present a lemma that links the definition of distance-regular graph to its intersection array. The proof is based on the Bose-Mesner algebra and its association scheme, and please refer to van Dam et al. (2014, Sections 2.5 and 2.6) for details. Lemma C.60. Let G and H be two graphs with the same intersection array, and suppose nodes u, v, w, x satisfy dis G (u, v) = dis G (w, x).\nProof of the first item of Theorem C.58. This part is straightforward. Consider the SPD-WL color mapping \u03c7 1 G of graph G after the first iteration. Then for two graphs G, H with n nodes,\nwhere in the second last step we use the recursive relation of r j , and in the last step we use the fact that k j = kj\u22121bj\u22121 cj for any j \u2208 [D(G)] (see e.g. van Dam et al. (2014, page 8)).\n\u2022 u \u0338 = v and dis G (u, v) = D(G). This case is similar as the previous one. Denote j = dis G (u, v), and\nwhere we again use k j = kj\u22121bj\u22121 cj .\nCombining the above three cases, we conclude that L R = 2 n 11 \u22a4 \u22122I, which finishes the proof.\nWe are now ready to prove the main result. Let G = (V G , E G ) and H = (V H , E H ) be two distanceregular graphs. We first prove that if \u03b9(G) = \u03b9(H), then RD-WL cannot distinguish the two graphs. This is a simple consequence of Theorem C.61. Combined with the fact that \u03ba(G) = \u03ba(H), we have {dis R G (u, w) : w \u2208 V G } = {dis R H (v, w) : w \u2208 V H } for any nodes u \u2208 V G and v \u2208 V H . Therefore, after the first iteration, the RD-WL color mappings \u03c7 1 G and \u03c7 1 H satisfy \u03c7 1 G (u) = \u03c7 1 H (v) for all u \u2208 V G and v \u2208 V H . Similarly, after the t-th iteration we still have \u03c7 t G (u) = \u03c7 t H (v) for all u \u2208 V G and v \u2208 V H and thus RD-WL cannot distinguish the two graphs.\nIt remains to prove that if \u03b9(G) \u0338 = \u03b9(H), then RD-WL can distinguish the two graphs. First observe that in Theorem C.61, r i < r j holds for any i < j. Therefore, for any nodes u \u2208\nwhere {{r}} \u00d7 k is a multiset containing k repeated elements of value r. If \u03b9(G) \u0338 = \u03b9(H), then there exists a minimal index d such that\n. Therefore, ( 22) does not hold and \u03c7 1 G (u) \u0338 = \u03c7 1 H (v) for any u \u2208 V G and v \u2208 V H , namely, RD-WL can distinguish the two graphs.\nProof of the third item of Theorem C.58. First, if \u03b9(G) \u0338 = \u03b9(H), then 2-FWL can distinguish graphs G and H. This is simply due to the fact that 2-FWL is more powerful than RD-WL (Theorem 4.5). It remains to prove that if \u03b9(G) = \u03b9(H), then 2-FWL cannot distinguish graphs G and H.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Let \u03c7 t", "text": "G : V G \u00d7 V G \u2192 C be the 2-FWL color mapping of graph G after t iterations. We aim to prove that for any nodes u, v \u2208 V G and w, x \u2208 V H , if dis G (u, v) = dis G (w, x), then \u03c7 t G (u, v) = \u03c7 t H (w, x) for any t \u2208 N. We prove it by induction. The base case of t = 0 trivially holds. Now suppose the case of t holds and let us consider the color mapping after t + 1 iterations. By the 2-FWL update rule (2),", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "E.2 PREPROCESSING RESISTANCE DISTANCE", "text": "In this subsection, we first describe several important properties of Resistance Distance. Based on these properties, we give a simple yet efficient algorithm to calculate Resistance Distance.\nEquivalence between Resistance Distance (RD) and Commute Time Distance (CTD). Chandra et al. (1996) established an important relationship between RD and CTD, by proving that dis C G (u, v) = 2m dis R G (u, v) holds for any graph G and any nodes u, v \u2208 V. Here, the Commute Time Distance is defined as v, u) where h G (u, v) is the average hitting time from u to v in a random walk. Concretely, h G (u, v) is equal to the average number of edges passed in a random walk when starting from u and reaching v for the first time. Mathmatically, it satisfies the following recursive relation:\n(25) The above equation can be used to calculate CTD and thus RD, as we will show later.\nResistance Distance is a graph metric. We say a function d G : V \u00d7 V \u2192 R is a graph metric if it is non-negative, positive semidefinite, symmetric, and satisfies triangular inequality. Let G be a connected graph. Then Resistance Distance dis R G is a valid graph metric because: u, w). This can be seen from the definition of CTD, since dis C G (u, v)+dis C G (v, w) is equal to the average hitting time from u to w under the condition of passing node v, which is obviously larger than dis R G (u, w). Comparing RD with SPD. It is easy to see that RD is always no larger than SPD, i.e. dis R G (u, v) \u2264 dis G (u, v). This is because for any subgraph G \u2032 of G, we have dis R G (u, v) \u2264 dis R G \u2032 (u, v), and when G \u2032 is chosen to contain only the edges that belong to the shortest path between u and v, we have u, v). Therefore, the range of RD is the same as SPD, i.e. 0 \u2264 dis R G (u, v) \u2264 n \u2212 1. However, unlike SPD which is an integer, RD can be a general rational number. RD can thus be seen as a more fine-grained distance metric than SPD. Nevertheless, RD is still discrete and there are only finitely many possible values of dis R G (u, v) when n is fixed. Relationship to graph Laplacian. We have the following theorem: Theorem E.1. Let G = (V, E) be a connected graph, V = [n], and let L \u2208 S n be the graph Laplacian. Then\n, where M \u2208 S n is a symmetric matrix defined as\n\u22a4 . Define the probability matrix P such that P ij = 0 if {i, j} / \u2208 E and P ij = 1/ deg G (i) if {i, j} \u2208 E. Then for any i \u0338 = j, (25) can be equivalently written as h(i, j) = 1 + n k=1 P ik h(k, j) \u2212 P ij h(j, j).\n(\nNow define a matrixH such thatH ij = 1 + n k=1 P ikHkj \u2212 P ijHjj , thenH ij = h(i, j) for all i \u0338 = j (althoughH ii \u0338 = 0 = h(i, i)).H can be equivalently written as\nwhere diag(H) is the diagnal matrix with elementsH ii for i \u2208 [n].\nWe first calculate diag(H). Noting that d \u22a4 P = d, we have\nand thus\nNow define H =H \u2212 diag(H), then H ij = h(i, j) for all i, j \u2208 [n]. We will calculate H in the following proof. We first write ( 27) equivalently as H + diag(H) = 11 \u22a4 + PH. Then by multiplying D, we have D(I \u2212 P)H = D11 \u22a4 \u2212 D diag(H).\n(29) Using the fact that D(I \u2212 P) = L and (28), we obtain\nNext, noting that L1 = 0, we have\nOne important property is that the matrix L + 1 n 11 \u22a4 is invertible (see Gutman & Xiao (2004, Theorem 4) for a proof). Combining ( 30) and ( 31) we have\nBy taking diagonal elements and noting that diag(H) = O, we otain\nNamely,\nSubstituting ( 34) into (32) yields\nTherefore,\nThis finally yields dis R G (i, j) = 1 2m dis C G (i, j) = 1 2m (H+H \u22a4 ) = M i,i +M j,j \u22122M i,j and concludes the proof.\nComputational Complexity. The graph Laplacian can be calculated in O(n 2 ) time, and M can be calculated by matrix inversion which requires O(n 3 ) time. Therefore, the overall computational complexity is O(n 3 ) (or O(n 2.376 ) using advanced matrix multiplication algorithms).\nFor sparse graphs typically encountered in practice (i.e. m = o(n 2 )), one may similarly ask whether a complexity that depends on m can be achieved. We conjecture that it should be possible. Below, we give another algorithm to calculate L + 1 n 11 \u22a4 \u22121 . Note that the graph Laplacian L can be equivalently written as L = EE \u22a4 , where E \u2208 R n\u00d7m is defined as\nwhere we denote\nNoting that each e i is highly sparse with only two non-zero elements.\nWe suspect that one can obtain an O(nm) complexity using techniques similar to the Sherman-Morrison-Woodbury update. We leave it as an open problem.", "publication_ref": ["b19"], "figure_ref": [], "table_ref": []}, {"heading": "E.3 TRANSFORMER-BASED IMPLEMENTATION", "text": "Graphormer-GD. The model is built on the Graphormer (Ying et al., 2021a) model, which use the Transformer (Vaswani et al., 2017) as the backbone network. A Transformer block consists of two layers: a self-attention layer followed by a feed-forward layer, with both layers having normalization (e.g., LayerNorm (Ba et al., 2016)) and skip connections (He et al., 2016). Denote X (l) \u2208 R n\u00d7d as the input to the (l + 1)-th block and define X (0) = X, where n is the number of nodes and d is the feature dimension. For an input X (l) , the (l + 1)-th block works as follows:\nwhere\nis the number of attention heads, d H is the dimension of each head, and r is the dimension of the hidden layer. A h (X) is usually referred to as the attention matrix.\nNote that the self-attention layer and the feed-forward layer introduced in ( 39) and ( 40) do not encode any structural information of the input graph. As stated in Section 4, we incorporate the distance information into the attention layers of our Graphormer-GD model. The calculation of the attention matrix in ( 38) is modified as:\nwhere D \u2208 R n\u00d7n is the distance matrix such that D uv = d G (u, v), \u03d5 h 1 and \u03d5 h 2 are element-wise functions applied to D, and \u2299 denotes the element-wise multiplication. In this way, the graph structural information can be captured by our Graphormer-GD model.\nAs stated in Section 4, we mainly consider two distance metrics: Shortest Path Distance dis G and Resistance Distance dis R G . For SPD, we follow Ying et al. (2021a) to use their shortest path distance encoding. Formally, let D SPD be the SPD matrix such that D SPD uv = dis G (u, v). The function \u03d5 1 and \u03d5 2 can simply be parameterized by two learnable vectors v 1 and v 2 , so that \u03d5 1 (D SPD uv ) is a learnable scalar corresponding to v 1 D SPD uv (and similarly for \u03d5 2 ). If two nodes u and v are not in the same connected component, i.e., D SPD uv = \u221e, a special learnable scalar is assigned. For RD, we use the Gaussian Basis kernels (Scholkopf et al., 1997) to encode the value since it may not be an integer. The encoded values from different Gaussian Basis kernels are concatenated and further transformed by a two-layer MLP. We integrate both the SPD encoding and the RD encoding to obtain \u03d5 l,h 1 (D) and \u03d5 l,h 2 (D). Note that these two matrices are parameterized by different sets of parameters. Following Ying et al. (2021a), we also incorporate the degree of each node in the input layer using a degree embedding.\nRelationship between Graphormer-GD and GD-WL. As stated in Section 4, the expressive power of Graphormer-GD is at most as powerful as GD-WL. We will prove that it is actually as powerful as GD-WL under mild assumptions. We first restate the Lemma 5 from , which shows that sum aggregators can represent injective functions over multisets.\nLemma E.2. (Xu et al., 2019, Lemma 5) Assume the set X is countable. Then there exists a function f : X \u2192 R n so that the function h(X ) :=\nx\u2208X f (x) is unique for each multisetX \u2282 X of bounded size. Moreover, any multiset function g can be decomposed as g(X ) = \u03d5( x\u2208X f (x)) for some function \u03d5.\nWe are now ready to present the detailed proof of the Theorem 4.4, which is restated as follows:\nTheorem E.3. Graphormer-GD is at most as powerful as GD-WL. Moreover, when choosing proper functions \u03d5 h 1 and \u03d5 h 2 and using a sufficiently large number of heads and layers, Graphormer-GD is as powerful as GD-WL.\nProof. Consider all graphs with no more than n nodes. The total number of possible values of both SPD and RD are thus finite and depends on n (see Appendix E.2). Let \nIntuitively, this reformulation indicates that in each iteration, GD-WL updates the color of node v by hashing a tuple of color multisets, where each multiset is obtained by injectively aggregating the colors of all nodes u \u2208 V with certain distance configuration to node v. Therefore, to express GD-WL, the model suffices to update the representation of each node following the above procedure.\nWe show Graphormer-GD can achieve this goal. Recall that for the h-th head, the attention matrix is defined as \u03d5 h 1 (D) \u2299 softmax XW h Q (XW h K ) \u22a4 + \u03d5 h 2 (D) . For the function \u03d5 h 1 , we define it to be the indicator function \u03d5 h 1 (d) := I(d = d G,h ). For the function \u03d5 h 2 , we set it to be constant irrespective to the matrix D. Let W h Q , W h K be zero matrices. It can be seen that the term softmax XW h Q (XW h K ) \u22a4 + \u03d5 h 2 (D) reduces to 1 |V| 11 \u22a4 , and thus for each node v, the output in the h-th attention head is the sum aggregation of representations of node u satisfying d G (u, v) = d G,h . Formally,\nNote that the constant 1 |V| can be extracted with an additional head and be concatenated to the node representations. Moreover, the node representation X is processed via the feed-forward network in the previous layer (see (40). Thus, we can invoke Lemma E.2 and prove that the h-th attention head in Graphormer-GD can implement an injective aggregating function for {{\u03c7 t\u22121 G (u) : u \u2208 V, d G (u, v) = d G,h }}. Therefore, by using a sufficiently large number of attention heads, the multiset representations \u03c7 t,k G , k \u2208 [|D n |] can be injectively obtained. Finally, the multi-head attention defined in ( 39) is equivalent to first concatenating the output of each attention head and then using a linear mapping to transform the results. Thus, the concatenation is clearly an injective mapping of the tuple of multisets \u03c7 t,1 G , \u03c7 t,2 G , ..., \u03c7 t,|Dn| G\n. When the linear mapping has irrelational weights, the projection will also be injective. Therefore, one attention layer followed by the feed-forward network can implement the aggregation formula (42). Thus, our Graphormer-GD is able to simulate the GD-WL when using a sufficiant number of layers, which concludes the proof.", "publication_ref": ["b80", "b7", "b38", "b72"], "figure_ref": [], "table_ref": []}, {"heading": "F EXPERIMENTAL DETAILS", "text": "F.1 SYNTHETIC TASKS Data Generation and Evaluation Metrics. We carefully design several graph generators to examine the expressive power of compared models on graph biconnectivity tasks. First, we include the two families of graphs presented in Examples C.9 and C.10 (Appendix C.2). We further introduce a rich family of regular graphs with both cut vertices and cut edges. Each graph in this family is constructed by first randomly generating several connected components and then linking them via cut edges while simultaneously ensuring that each node has the same degree. Combining the above three families of hard graphs, we online generate data instances to train the compared models. For each data instance, the total number of nodes is upper bounded by 120. We use graph-level accuracy as the metric. That is, for each graph, the prediction of the model is considered correct only when all and only the cut vertices/edges are correctly identified. We use different seeds to repeat the experiments 5 times and report the average accuracy.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "The surprising power of graph neural networks with random node initialization", "journal": "", "year": "2021", "authors": "Ralph Abboud; \u0130smaililkan Ceylan; Martin Grohe; Thomas Lukasiewicz"}, {"ref_id": "b1", "title": "Shortest path networks for graph property prediction", "journal": "", "year": "2022", "authors": "Ralph Abboud; Radoslav Dimitrov; Ismail Ilkan Ceylan"}, {"ref_id": "b2", "title": "Mapping the us political blogosphere: Are conservative bloggers more prominent?", "journal": "", "year": "2005", "authors": "Robert Ackland"}, {"ref_id": "b3", "title": "Finding and counting given length cycles", "journal": "Algorithmica", "year": "1997", "authors": "Noga Alon; Raphael Yuster; Uri Zwick"}, {"ref_id": "b4", "title": "On the bottleneck of graph neural networks and its practical implications", "journal": "", "year": "2021", "authors": "Uri Alon; Eran Yahav"}, {"ref_id": "b5", "title": "On weisfeiler-leman invariance: Subgraph counts and related graph properties", "journal": "Journal of Computer and System Sciences", "year": "2020", "authors": "Vikraman Arvind; Frank Fuhlbr\u00fcck; Johannes K\u00f6bler; Oleg Verbitsky"}, {"ref_id": "b6", "title": "Expressive power of invariant and equivariant graph neural networks", "journal": "", "year": "2021", "authors": "Waiss Azizian; Marc Lelarge"}, {"ref_id": "b7", "title": "", "journal": "", "year": "2016", "authors": "Jimmy Lei Ba; Jamie Ryan Kiros; Geoffrey E Hinton"}, {"ref_id": "b8", "title": "Graph isomorphism in quasipolynomial time", "journal": "", "year": "2016", "authors": "L\u00e1szl\u00f3 Babai"}, {"ref_id": "b9", "title": "Breaking the limits of message passing graph neural networks", "journal": "PMLR", "year": "2021", "authors": "Muhammet Balcilar; Pierre H\u00e9roux; Benoit Gauzere; Pascal Vasseur; S\u00e9bastien Adam; Paul Honeine"}, {"ref_id": "b10", "title": "Graph neural networks with local graph parameters", "journal": "", "year": "2021", "authors": "Pablo Barcel\u00f3; Floris Geerts; Juan Reutter; Maksimilian Ryschkov"}, {"ref_id": "b11", "title": "Equivariant subgraph aggregation networks", "journal": "", "year": "2022", "authors": "Beatrice Bevilacqua; Fabrizio Frasca; Derek Lim; Balasubramaniam Srinivasan; Chen Cai; Gopinath Balamurugan; Haggai Michael M Bronstein;  Maron"}, {"ref_id": "b12", "title": "Weisfeiler and lehman go cellular: CW networks", "journal": "", "year": "2021", "authors": "Cristian Bodnar; Fabrizio Frasca; Nina Otter; Yu Guang Wang; Pietro Li\u00f2; Guido Montufar; Michael M Bronstein"}, {"ref_id": "b13", "title": "Weisfeiler and lehman go topological: Message passing simplicial networks", "journal": "PMLR", "year": "2021", "authors": "Cristian Bodnar; Fabrizio Frasca; Yuguang Wang; Nina Otter; F Guido; Pietro Montufar; Michael Lio;  Bronstein"}, {"ref_id": "b14", "title": "Modern graph theory", "journal": "Springer Science & Business Media", "year": "1998", "authors": "B\u00e9la Bollob\u00e1s"}, {"ref_id": "b15", "title": "Improving graph neural network expressivity via subgraph isomorphism counting", "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": "2022", "authors": "Giorgos Bouritsas; Fabrizio Frasca; P Stefanos; Michael Zafeiriou;  Bronstein"}, {"ref_id": "b16", "title": "", "journal": "", "year": "2017", "authors": "Xavier Bresson; Thomas Laurent"}, {"ref_id": "b17", "title": "Distance-regular graphs", "journal": "Springer", "year": "1989", "authors": "E Andries;  Brouwer; M Arjeh;  Cohen; M Arjeh; Arnold Cohen;  Neumaier"}, {"ref_id": "b18", "title": "An optimal lower bound on the number of variables for graph identification", "journal": "Combinatorica", "year": "1992", "authors": "Jin-Yi Cai; Martin F\u00fcrer; Neil Immerman"}, {"ref_id": "b19", "title": "The electrical resistance of a graph captures its commute and cover times", "journal": "computational complexity", "year": "1996", "authors": "K Ashok; Prabhakar Chandra;  Raghavan; L Walter; Roman Ruzzo; Prasoon Smolensky;  Tiwari"}, {"ref_id": "b20", "title": "On the equivalence between graph isomorphism testing and function approximation with gnns", "journal": "", "year": "2019", "authors": "Zhengdao Chen; Soledad Villar; Lei Chen; Joan Bruna"}, {"ref_id": "b21", "title": "Can graph neural networks count substructures?", "journal": "", "year": "2020", "authors": "Zhengdao Chen; Lei Chen; Soledad Villar; Joan Bruna"}, {"ref_id": "b22", "title": "Principal neighbourhood aggregation for graph nets", "journal": "", "year": "2020", "authors": "Gabriele Corso; Luca Cavalleri; Dominique Beaini; Pietro Li\u00f2; Petar Veli\u010dkovi\u0107"}, {"ref_id": "b23", "title": "Reconstruction for powerful graph representations", "journal": "", "year": "2021", "authors": "Leonardo Cotta; Christopher Morris; Bruno Ribeiro"}, {"ref_id": "b24", "title": "Natural graph networks", "journal": "", "year": "2020", "authors": "Taco Pim De Haan; Max Cohen;  Welling"}, {"ref_id": "b25", "title": "Random walks and electric networks", "journal": "American Mathematical Soc", "year": "1984", "authors": "G Peter; J Laurie Doyle;  Snell"}, {"ref_id": "b26", "title": "A generalization of transformer networks to graphs", "journal": "AAAI Workshop on Deep Learning on Graphs: Methods and Applications", "year": "2021", "authors": "Vijay Prakash Dwivedi; Xavier Bresson"}, {"ref_id": "b27", "title": "Benchmarking graph neural networks", "journal": "", "year": "2020", "authors": "Vijay Prakash Dwivedi; K Chaitanya; Thomas Joshi; Yoshua Laurent; Xavier Bengio;  Bresson"}, {"ref_id": "b28", "title": "Weisfeiler and leman go infinite: Spectral and combinatorial pre-colorings", "journal": "", "year": "2022", "authors": "Or Feldman; Amit Boyarski; Shai Feldman; Dani Kogan; Avi Mendelson; Chaim Baskin"}, {"ref_id": "b29", "title": "How powerful are k-hop message passing graph neural networks", "journal": "", "year": "2022", "authors": "Jiarui Feng; Yixin Chen; Fuhai Li; Anindya Sarkar; Muhan Zhang"}, {"ref_id": "b30", "title": "Algorithm 97: shortest path", "journal": "Communications of the ACM", "year": "1962", "authors": "W Robert;  Floyd"}, {"ref_id": "b31", "title": "Understanding and extending subgraph gnns by rethinking their symmetries", "journal": "", "year": "2022", "authors": "Fabrizio Frasca; Beatrice Bevilacqua; Michael Bronstein; Haggai Maron"}, {"ref_id": "b32", "title": "Generalization and representational limits of graph neural networks", "journal": "PMLR", "year": "2020", "authors": "Vikas Garg; Stefanie Jegelka; Tommi Jaakkola"}, {"ref_id": "b33", "title": "Expressiveness and approximation properties of graph neural networks", "journal": "", "year": "2022", "authors": "Floris Geerts; L Juan;  Reutter"}, {"ref_id": "b34", "title": "Neural message passing for quantum chemistry", "journal": "PMLR", "year": "2017", "authors": "Justin Gilmer; S Samuel;  Schoenholz; F Patrick; Oriol Riley; George E Vinyals;  Dahl"}, {"ref_id": "b35", "title": "Substitutes, complements and ripples in network flows", "journal": "Mathematics of Operations Research", "year": "1985", "authors": "Frieda Granot; F Arthur;  Veinott"}, {"ref_id": "b36", "title": "Generalized inverse of the laplacian matrix and some applications", "journal": "", "year": "2004", "authors": "Ivan Gutman;  Xiao"}, {"ref_id": "b37", "title": "Inductive representation learning on large graphs", "journal": "", "year": "2017", "authors": "Rex William L Hamilton; Jure Ying;  Leskovec"}, {"ref_id": "b38", "title": "Deep residual learning for image recognition", "journal": "", "year": "2016", "authors": "Kaiming He; Xiangyu Zhang; Shaoqing Ren; Jian Sun"}, {"ref_id": "b39", "title": "Isomorphism of planar graphs", "journal": "Springer", "year": "1972", "authors": "E John; Robert Endre Hopcroft;  Tarjan"}, {"ref_id": "b40", "title": "Topological graph neural networks. In International Conference on Learning Representations", "journal": "", "year": "2022", "authors": "Max Horn; Edward De Brouwer; Michael Moor; Yves Moreau; Bastian Rieck; Karsten Borgwardt"}, {"ref_id": "b41", "title": "Boosting the cycle counting power of graph neural networks with i$\u02c62$-GNNs", "journal": "", "year": "2023", "authors": "Yinan Huang; Xingang Peng; Jianzhu Ma; Muhan Zhang"}, {"ref_id": "b42", "title": "Describing graphs: A first-order approach to graph canonization", "journal": "Springer", "year": "1990", "authors": "Neil Immerman; Eric Lander"}, {"ref_id": "b43", "title": "Algorithms for enumerating all spanning trees of undirected and weighted graphs", "journal": "SIAM Journal on Computing", "year": "1995", "authors": "Sanjiv Kapoor; Hariharan Ramesh"}, {"ref_id": "b44", "title": "Universal invariant and equivariant graph neural networks", "journal": "", "year": "2019", "authors": "Nicolas Keriven; Gabriel Peyr\u00e9"}, {"ref_id": "b45", "title": "Power and limits of the Weisfeiler-Leman algorithm", "journal": "", "year": "2020", "authors": "Sandra Kiefer"}, {"ref_id": "b46", "title": "Adam: A method for stochastic optimization", "journal": "", "year": "2014", "authors": "P Diederik; Jimmy Kingma;  Ba"}, {"ref_id": "b47", "title": "Semi-supervised classification with graph convolutional networks", "journal": "", "year": "2017", "authors": "N Thomas; Max Kipf;  Welling"}, {"ref_id": "b48", "title": "Resistance distance", "journal": "Journal of mathematical chemistry", "year": "1993", "authors": "J Douglas; Milan Klein;  Randi\u0107"}, {"ref_id": "b49", "title": "Rethinking graph transformers with spectral attention", "journal": "", "year": "2021", "authors": "Devin Kreuzer; Dominique Beaini; Will Hamilton; Vincent L\u00e9tourneau; Prudencio Tossou"}, {"ref_id": "b50", "title": "Distance encoding: design provably more powerful neural networks for graph representation learning", "journal": "", "year": "2020", "authors": "Pan Li; Yanbang Wang; Hongwei Wang; Jure Leskovec"}, {"ref_id": "b51", "title": "Sign and basis invariant networks for spectral graph representation learning", "journal": "", "year": "2022", "authors": "Derek Lim; Joshua Robinson; Lingxiao Zhao; Tess Smidt; Suvrit Sra; Haggai Maron; Stefanie Jegelka"}, {"ref_id": "b52", "title": "What graph neural networks cannot learn: depth vs width", "journal": "", "year": "2020", "authors": "Andreas Loukas"}, {"ref_id": "b53", "title": "One transformer can understand both 2d & 3d molecular data", "journal": "", "year": "2022", "authors": "Shengjie Luo; Tianlang Chen; Yixian Xu; Shuxin Zheng; Tie-Yan Liu; Liwei Wang; Di He"}, {"ref_id": "b54", "title": "Your transformer may not be as powerful as you expect", "journal": "", "year": "2022", "authors": "Shengjie Luo; Shanda Li; Shuxin Zheng; Tie-Yan Liu; Liwei Wang; Di He"}, {"ref_id": "b55", "title": "Provably powerful graph networks", "journal": "", "year": "2019", "authors": "Heli Haggai Maron; Hadar Ben-Hamu; Yaron Serviansky;  Lipman"}, {"ref_id": "b56", "title": "Invariant and equivariant graph networks", "journal": "", "year": "2019", "authors": "Heli Haggai Maron; Nadav Ben-Hamu; Yaron Shamir;  Lipman"}, {"ref_id": "b57", "title": "On the universality of invariant networks", "journal": "PMLR", "year": "2019", "authors": "Haggai Maron; Ethan Fetaya; Nimrod Segol; Yaron Lipman"}, {"ref_id": "b58", "title": "Geometric deep learning on graphs and manifolds using mixture model cnns", "journal": "", "year": "2017", "authors": "Federico Monti; Davide Boscaini; Jonathan Masci; Emanuele Rodola; Jan Svoboda; Michael M Bronstein"}, {"ref_id": "b59", "title": "Weisfeiler and leman go neural: Higher-order graph neural networks", "journal": "", "year": "2019", "authors": "Christopher Morris; Martin Ritzert; Matthias Fey; L William; Jan Eric Hamilton; Gaurav Lenssen; Martin Rattan;  Grohe"}, {"ref_id": "b60", "title": "Weisfeiler and leman go sparse: towards scalable higher-order graph embeddings", "journal": "", "year": "2020", "authors": "Christopher Morris; Gaurav Rattan; Petra Mutzel"}, {"ref_id": "b61", "title": "Weisfeiler and leman go machine learning: The story so far", "journal": "", "year": "2021", "authors": "Christopher Morris; Yaron Lipman; Haggai Maron; Bastian Rieck; M Nils; Martin Kriege; Matthias Grohe; Karsten Fey;  Borgwardt"}, {"ref_id": "b62", "title": "Speqnets: Sparsityaware permutation-equivariant graph networks", "journal": "PMLR", "year": "2022", "authors": "Christopher Morris; Gaurav Rattan; Sandra Kiefer; Siamak Ravanbakhsh"}, {"ref_id": "b63", "title": "Relational pooling for graph representations", "journal": "PMLR", "year": "2019", "authors": "Ryan Murphy; Balasubramaniam Srinivasan; Vinayak Rao; Bruno Ribeiro"}, {"ref_id": "b64", "title": "A theoretical comparison of graph neural network extensions", "journal": "", "year": "2022", "authors": "Andr\u00e1s P\u00e1l; Roger Papp;  Wattenhofer"}, {"ref_id": "b65", "title": "Dropgnn: random dropouts increase the expressiveness of graph neural networks", "journal": "", "year": "2021", "authors": "Karolis P\u00e1l Andr\u00e1s Papp; Lukas Martinkus; Roger Faber;  Wattenhofer"}, {"ref_id": "b66", "title": "Ordered subgraph aggregation networks", "journal": "", "year": "2022", "authors": "Chendi Qian; Gaurav Rattan; Floris Geerts; Christopher Morris; Mathias Niepert"}, {"ref_id": "b67", "title": "Learning node representations from structural identity", "journal": "", "year": "2017", "authors": " Leonardo Fr Ribeiro; H P Pedro; Daniel R Saverese;  Figueiredo"}, {"ref_id": "b68", "title": "The algebraic path problem for graph metrics", "journal": "PMLR", "year": "2022", "authors": "Enrique Fita Sanmart\u0131n; Sebastian Damrich; Fred Hamprecht"}, {"ref_id": "b69", "title": "A survey on the expressive power of graph neural networks", "journal": "", "year": "2020", "authors": "Ryoma Sato"}, {"ref_id": "b70", "title": "Approximation ratios of graph neural networks for combinatorial problems", "journal": "", "year": "2019", "authors": "Ryoma Sato; Makoto Yamada; Hisashi Kashima"}, {"ref_id": "b71", "title": "Random features strengthen graph neural networks", "journal": "SIAM", "year": "2021", "authors": "Ryoma Sato; Makoto Yamada; Hisashi Kashima"}, {"ref_id": "b72", "title": "Comparing support vector machines with gaussian kernels to radial basis function classifiers", "journal": "IEEE transactions on Signal Processing", "year": "1997", "authors": "Bernhard Scholkopf; Kah-Kay Sung; J C Christopher; Federico Burges; Partha Girosi; Tomaso Niyogi; Vladimir Poggio;  Vapnik"}, {"ref_id": "b73", "title": "Benchmarking graphormer on large-scale molecular modeling datasets", "journal": "", "year": "2022", "authors": "Yu Shi; Shuxin Zheng; Guolin Ke; Yifei Shen; Jiacheng You; Jiyan He; Shengjie Luo; Chang Liu; Di He; Tie-Yan Liu"}, {"ref_id": "b74", "title": "Neural trees for learning on graphs", "journal": "", "year": "2021", "authors": "Rajat Talak; Siyi Hu; Lisa Peng; Luca Carlone"}, {"ref_id": "b75", "title": "Depth-first search and linear graph algorithms", "journal": "SIAM journal on computing", "year": "1972", "authors": "Robert Tarjan"}, {"ref_id": "b76", "title": "Autobahn: Automorphism-based graph neural nets", "journal": "", "year": "2021", "authors": "Erik Thiede; Wenda Zhou; Risi Kondor"}, {"ref_id": "b77", "title": "Graph learning with 1d convolutions on random walks", "journal": "", "year": "2021", "authors": "Jan Toenshoff; Martin Ritzert; Hinrikus Wolf; Martin Grohe"}, {"ref_id": "b78", "title": "Understanding over-squashing and bottlenecks on graphs via curvature", "journal": "", "year": "2022", "authors": "Jake Topping; Francesco Di Giovanni; Benjamin Paul Chamberlain; Xiaowen Dong; Michael M Bronstein"}, {"ref_id": "b79", "title": "", "journal": "", "year": "2014", "authors": " Edwin R Van Dam; H Jack; Hajime Koolen;  Tanaka"}, {"ref_id": "b80", "title": "Attention is all you need", "journal": "", "year": "2017", "authors": "Ashish Vaswani; Noam Shazeer; Niki Parmar; Jakob Uszkoreit; Llion Jones; Aidan N Gomez; \u0141ukasz Kaiser; Illia Polosukhin"}, {"ref_id": "b81", "title": "Message passing all the way up", "journal": "", "year": "2022", "authors": "Petar Veli\u010dkovi\u0107"}, {"ref_id": "b82", "title": "Graph attention networks", "journal": "", "year": "2018", "authors": "Petar Veli\u010dkovi\u0107; Guillem Cucurull; Arantxa Casanova; Adriana Romero; Pietro Li\u00f2; Yoshua Bengio"}, {"ref_id": "b83", "title": "Petar Veli\u010dkovi\u0107, and Sreenivas Gollapudi. Affinityaware graph networks", "journal": "", "year": "2022", "authors": "Ameya Velingker; Ali Kemal Sinop; Ira Ktena"}, {"ref_id": "b84", "title": "Building powerful and equivariant graph neural networks with structural message-passing", "journal": "", "year": "2020", "authors": "Cl\u00e9ment Vignac; Andreas Loukas; Pascal Frossard"}, {"ref_id": "b85", "title": "The reduction of a graph to canonical form and the algebra which appears therein", "journal": "NTI, Series", "year": "1968", "authors": "Boris Weisfeiler; Andrei Leman"}, {"ref_id": "b86", "title": "We also compare the Graph Substructure Network (Bouritsas et al., 2022), which extracts graph substructures to improve the expressive power of MPNNs. The substructure counts are incorporated into node features or the aggregation procedure. Lastly, we also compare the Graphormer model", "journal": "", "year": "2017", "authors": "; Gat ( Baselines;  Veli\u010dkovi\u0107"}, {"ref_id": "b87", "title": "The dimension of hidden layers and feedforward layers is set to 768. The number of Gaussian Basis kernels is set to 128. The number of attention heads is set to 64. The batch size is set to 32. We use AdamW (Kingma & Ba, 2014) as the optimizer and set its hyperparameter \u03f5 to 1e-8 and (\u03b2 1 , \u03b2 2 ) to (0.9, 0.999). The peak learning rate is set to 9e-5. The model is trained for 100k steps with a 6K-step warm-up stage", "journal": "", "year": "", "authors": " Settings"}, {"ref_id": "b88", "title": "It is a real-world dataset that consists of 250K molecular graphs. The task is to predict the constrained solubility of a molecule, which is an important chemical property for drug discovery. We train our models on both the ZINC-Full and ZINC-Subset (12K selected graphs following", "journal": "", "year": "2020", "authors": " Dwivedi"}, {"ref_id": "b89", "title": "For a fair comparison, we set the parameter budget of the model to be around 500K following Dwivedi et al. (2020)", "journal": "", "year": "", "authors": " Baselines"}, {"ref_id": "b90", "title": "Besides, we also include several popularly used models. Mixture Model Network (MoNet) (Monti et al., 2017) introduces a general architecture to learn on graphs and manifolds using the Bayesian Gaussian Mixture Model. Gated Graph ConvNet (GatedGCN) considers residual connections, batch normalization, and edge gates to design an anisotropic variant of GCN", "journal": "", "year": "2017", "authors": "( Xu"}, {"ref_id": "b91", "title": "RingGNN extends the family of order-2 Graph G-invariant Networks without going into higher order tensors and is able to distinguish between non-isomorphic regular graphs where order-2 G-invariant networks provably fail", "journal": "", "year": "2019", "authors": " Maron"}, {"ref_id": "b92", "title": "2022) extracts graph substructures to improve the expressive power of MPNNs. The substructure counts are incorporated into node features or the aggregation procedure. We also compare the Cellular Isomorphism Network (Bodnar et al., 2021a), which extends theoretical results on Simplicial Complexes to regular Cell Complexes. Such generalization provides a powerful set of graph \"lifting", "journal": "", "year": "", "authors": " Bouritsas"}, {"ref_id": "b93", "title": "2022) follows a similar manner to develop Subgraph GNNs with different generation policies. Equivariant Subgraph Aggregation Networks (ESAN) (Bevilacqua et al., 2022) develops a unified framework that includes per-layer aggregation across subgraphs, which are generated using pre-defined policies like edge deletion and ego-networks. Subgraph Union Network Table 5: Average Accuracy on Brazil-Airports and Europe-Airports datasets. Experiments are repeated for 20 times with different seeds. We use * to indicate the best performance", "journal": "", "year": "", "authors": "Gnn-Ak ( Zhao"}, {"ref_id": "b94", "title": "", "journal": "", "year": "2017", "authors": "( Graphsage;  Hamilton"}, {"ref_id": "b95", "title": "", "journal": "", "year": "2019", "authors": " Gin (xu"}, {"ref_id": "b96", "title": "", "journal": "", "year": "2017", "authors": "( Struc2vec;  Ribeiro"}, {"ref_id": "b97", "title": "", "journal": "", "year": "", "authors": "De-Gnn-Spd ( Li"}, {"ref_id": "b98", "title": "", "journal": "", "year": "2020", "authors": "De-Gnn-Lp ( Li"}, {"ref_id": "b99", "title": "", "journal": "", "year": "2020", "authors": "Dea-Gnn-Spd ( Li"}, {"ref_id": "b100", "title": "", "journal": "", "year": "", "authors": " Graphormer-Gd"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 :1Figure 1: An illustration of edge-biconnectivity and vertex-biconnectivity. Cut vertices/edges are outlined in bold red. Gray nodes in (b)/(c) are edge/vertex-biconnected components, respectively.", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 2 :2Figure 2: Illustration of four representative counterexamples (see Examples C.9 and C.10 for general definitions). Graphs in the first row have cut vertices (outlined in bold red) and some also have cut edges (denoted as red lines), while graphs in the second row do not have any cut vertex or cut edge.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "SPD-WL fails while RD-WL succeeds. (b) Both SPD-WL and RD-WL fail.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 3 :3Figure 3: Illustration of non-isomorphic distance-regular graphs.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "based on homomorphism counting. Bodnar et al. (2021b;a); Thiede et al. (2021); Horn et al. (2022) further developed novel WL aggregation schemes that take into account these substructures (e.g., cycles or cliques).Toenshoff et al. (2021) considered using random walk techniques to generate small substructures.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Other approaches. Wijesinghe & Wang (2022); de Haan et al. (2020) designed novel variants of MPNNs based on more powerful neighborhood aggregation schemes that are aware of the local graph structure, rather than simply treating neighboring nodes as a set. Li et al. (2020); Velingker et al. (2022) incorporated distance encoding into node/edge features to enhance the expressive power of MPNNs. Balcilar et al. (2021); Feldman et al. (", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Algorithm 1 :1The 1-dimensional Weisfeiler-Lehman Algorithm Input : Graph G = (V, E) and the number of iterations T Output: Color mapping \u03c7 G : V \u2192 C Initialize: Pick a fixed (arbitrary) element c 0 \u2208 C, and let \u03c7 0 G (v) := c 0 for all", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "Algorithm 3 :3DSS Weisfeiler-Lehman Algorithm   Input : Graph G = (V, E), the number of iterations T , and graph selection policy \u03c0 Output: Color mapping \u03c7 G : V \u2192 C Initialize: Generate a bag of graphs", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "and the number of iterations T Output: Color mapping \u03c7 G : V \u2192 C Initialize: Pick a fixed (arbitrary) element c 0 \u2208 C, and let \u03c7 0", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "Line 7 in Algorithm 3). Then there exists a pair of indices i \u2208 [m G ] and j \u2208 [m H ] such that \u03c7 Gi (u) = \u03c7 Hj (v). By definition of the DSS-WL aggregation, it implies {{\u03c7 G (w) : w \u2208 N G (u)}} = {{\u03c7 H (w) : w \u2208 N H (v)}} and concludes the proof. Proposition C.4. Let \u03c7 G and \u03c7 H be two mappings returned by SPD-WL (Algorithm 4 with d G = dis G ) for graphs G and H, respectively. Then \u03c7 G and \u03c7 H jointly satisfy the WL-condition.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_10", "figure_caption": "Lemma C.7. Let (v 0 , \u2022 \u2022 \u2022 , v d ) be any path (not necessarily simple) of length d in graph G. Then for any node u 0 \u2208 \u03c7 \u22121 H (\u03c7 G (v 0 )) in graph H, there exists a path (u 0 , \u2022 \u2022 \u2022 , u d ) of the same length d starting at u 0 , such that \u03c7 H (", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_11", "figure_caption": "Figure 4 :4Figure 4: Illustration of the proof of Theorem 3.1. The trees G 1 [S], G 2 [g(S)] are outlined by orange.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_12", "figure_caption": "(a,b,d)). Moreover, Example C.9 with m = 1 (see Figure2(c)) is also a counterexample as discussed in Wijesinghe & Wang (2022, Figure2(a)).", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_13", "figure_caption": "). Therefore, it can only be the case that (\u03c7 v H ) \u22121 (\u03c7 u G (u)) = {v} and \u03c7 v H (v) = \u03c7 u G (u). This yields dis G (u, w) = dis G (v, x) and concludes the proof.C.3.1 PROOF FOR THE FIRST PART OF THEOREM 3.2 The following technical lemma is useful in the subsequent proof: Lemma C.20. Let u, v \u2208 V be two nodes in connected graphs G and H, respectively. If \u03c7 u G (u) = \u03c7 v H (v), then {{\u03c7 u G (w) : w \u2208 V}} = {{\u03c7 v H (w) : w \u2208 V}}. Proof. Let N d G (u) := {w \u2208 V : dis G (u, w) = d} be the d-hop neighbors of node u in graph G, and denote C d G := {{\u03c7 u G (w) : w \u2208 N d G (u)}} as the multiset containing the color of all nodes w with distance d to node u. We can similarly denote N d H (v) := {w : dis H (v, w) = d} and C d H = {{\u03c7 v H (w) : w \u2208 N d H (v)}}. It suffices to prove that for all d \u2208 N + , C d G = C d H . We will prove the above result by induction. The case of d = 0 is trivial. Now suppose the case of d is true (i.e., C d G = C d H ) and we want to prove C d+1", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_14", "figure_caption": "Figure 5 :5Figure 5: Several illustrations to help understand the lemmas.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_15", "figure_caption": "Lemma C.19(d), and thus using Lemma C.20 we have {{\u03c7 u G (w) : w \u2208 V}} = {{\u03c7 u \u2032 H (w) : w \u2208 V}} and finally obtain {{\u03c7 G (w) : w \u2208 V}} = {{\u03c7 H (w) : w \u2208 V}} by Lemma C.19(b).)", "figure_data": ""}, {"figure_label": "6", "figure_type": "figure", "figure_id": "fig_16", "figure_caption": "Figure 6 :6Figure 6: Several illustrations to help understand the main proof of Theorem 3.2.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_17", "figure_caption": "by our assumption |\u03c7 \u22121 H (\u03c7 H (u))| = 1, and thus \u03c7 w \u2032 H (y i ) \u0338 = \u03c7 w \u2032 H (u \u2032 ) (by Lemma C.19(b)). Since \u03c7 w G (x) = \u03c7 w \u2032 H (x \u2032 ), by the WL-condition (Lemma C.7), there is a path Q = (z 0 , \u2022 \u2022 \u2022 , z d ) in G satisfying z 0 = x and z i \u2208 (\u03c7 w G ) \u22121 (\u03c7 w \u2032 H (y i )) for i \u2208 [d]. See Figure 6(b) for an illustration of this paragraph. Clearly, we have z d = w using \u03c7 w G (z d ) = \u03c7 w \u2032 H (w \u2032 ) and Lemma C.19(a). On the other hand, by Lemma C.19(b), \u03c7 w", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_18", "figure_caption": "Definition C.26. (Color graph) Define the auxiliary color graph", "figure_data": ""}, {"figure_label": "7", "figure_type": "figure", "figure_id": "fig_19", "figure_caption": "Figure 7 :7Figure 7: Illustration of the proof of Lemma C.27.", "figure_data": ""}, {"figure_label": "8", "figure_type": "figure", "figure_id": "fig_20", "figure_caption": "Figure 8 :8Figure 8: Illustration of the proof of Lemma C.28.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_21", "figure_caption": "32. Corollary C.31 can be seen as a generalized version of Lemma C.27. Indeed, when w \u2208 S u , one can pick u \u2032 = u and", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_22", "figure_caption": "hold due to Lemma C.27. In general, Corollary C.31 says that all the cut edges with color {\u03c7 G (u), \u03c7 G (v)} play an equal role: Lemma C.27 applies for any chosen cut edge {u \u2032 , v \u2032 }. An illustration of Corollary C.31 is given in Figure9(a).", "figure_data": ""}, {"figure_label": "9", "figure_type": "figure", "figure_id": "fig_23", "figure_caption": "Figure 9 :9Figure 9: Illustration of Corollary C.31 and its proof.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_24", "figure_caption": "C = (C, E H C ) defined in Definition C.26. Note that we have assumed that the graph representations of G and H are the same, i.e. {{\u03c7 G (w) : w \u2208 V}} = {{\u03c7 H (w) : w \u2208 V}}. It follows that H C is isomorphic to G C and the identity vertex mapping is an isomorphism, i.e., {{c 1 , c 2 }} \u2208 E G C \u21d0\u21d2 {{c 1 , c 2 }} \u2208 E H C . Therefore, {{\u03c7 G (u), \u03c7 G (v)}} is a cut edge of H C (Lemma C.29) that splits the vertices C into two classes C u , C v . Since the vertex labels of H are not important, we can without abuse of notation let u, v be two nodes such that", "figure_data": ""}, {"figure_label": "10", "figure_type": "figure", "figure_id": "fig_25", "figure_caption": "Figure 10 :10Figure 10: Illustrations to help understand the proof of the main result.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_26", "figure_caption": "u and h(\u03c7 H (w j+1 )) \u2208 C v . By definition of C u , C v and the cut edge {{\u03c7 H (u), \u03c7 H (v)}}, it follows that \u03c7 H (w j ) = \u03c7 H (u) and \u03c7 H (w j+1 ) = \u03c7 H (v). Denote u \u2032 := w j . Note that j \u0338 = 1 and j \u0338 = 2, otherwise u either connects to two nodes w 2 and w m with color \u03c7 H (w 2 ) = \u03c7 H (w m ) = \u03c7 H (v), or connects to the node u \u2032 with color \u03c7 H (u \u2032 ) = \u03c7 H (u), contradicting \u03c7 H (u) = \u03c7 G (u). Pick k = \u2308j/2\u2309. By Lemma C.33, (w 1 , \u2022 \u2022 \u2022 , w k ) is the shortest path between u and w k , and (w k , \u2022 \u2022 \u2022 , w j ) is the shortest path between w k and u \u2032 . We give an illustration of the structure of H in Figure 10(a) based on this paragraph.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_27", "figure_caption": "which completes the proof by combining the first bullet in Lemma C.38. The case of {{\u03be, \u03be \u2032 }} = {{(u, \u03c7 G (u)), (v, \u03c7 G (v))}} is trivial. Now assume that {{\u03be, \u03be \u2032 }} \u0338 = {{(u, \u03c7 G (u)), (v, \u03c7 G (v))}}. By Definition C.34, there exists", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_28", "figure_caption": "However, by Lemma C.36 and the condition h G", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_29", "figure_caption": "Proof of the second bullet: Let \u03c7 G (w) = \u03c7 G (w \u2032 ) = c. Without loss of generality, assume f G (w) = (u, c) and f (w \u2032 ) = (v, c). By Lemma C.38, it suffices to prove thatdis G A ((u, \u03c7 G (u)), (u, c)) = dis G A ((v, \u03c7 G (v)),(v, c)). By the definition of G A and its cut edge {{(u, \u03c7 G (u), (v, \u03c7 G (v))}}, the shortest path between (u, \u03c7 G (u)) and (u, c) must only go through nodes in the set {(u, c 1 ) : c 1 \u2208 C}, and similarly the shortest path between (v, \u03c7 G (v)) and (v, c) must only go through nodes in {(v, c 2 ) : c 2 \u2208 C}. Finally, Corollary C.37 says that for c 1 , c 2 \u2208 C, {{(u, c 1 ), (u, c 2 )}} \u2208 G A if and only if {{(v, c 1 ), (v, c 2 )}} \u2208 G A . We thus conclude that dis G A ((u, \u03c7 G (u)), (u, c)) = dis G A ((v, \u03c7 G (v)), (v, c)) and dis G (u, w) = dis G (v, w \u2032 ).By Lemma C.41, |D H,= (w \u2032 , c 1 )| = |D H,\u0338 = (w \u2032 , c )| = |D G,= (w, c 1 )| = |D G,\u0338 = (w, c 1 )|. Therefore, D G,\u0338 = (w, c 1 ) = D H,\u0338 = (w \u2032 , c 1 ).", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_30", "figure_caption": "and that the two edges {w 1 , w 2 } \u2208 E G , {x 1 , x 2 } have the same color under SPD-WL. Moreover, {{\u03c7 G (w) : w \u2208 S G }} = {{\u03c7 H (w) : w \u2208 S H }}. Now consider re-execute the SPD-WL algorithm on subgraphs G[S G ] and H[S H ] induced by the vertices in set S G and S H , respectively. It follows that for any u G \u2208 S G and u H", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_31", "figure_caption": "vuw contains v. Clearly, P v uw \u0338 = \u2205. Given a path P = (x 0 , \u2022 \u2022 \u2022 , x m ), define the probability function q(P ) := 1/ m\u22121 i=0 deg G (x i ). Then by definitions of the average hitting time h, h G (u, w) = 1 )q(P 2 )(|P 1 | + |P 2 |) +", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_32", "figure_caption": "27): any node u in G and v in H, |N j G (u)| = |N j H (v)| holds for some j \u2208 [max(D(G), D(H))] and thus \u03c7 1", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "WL SC-WL CWL OS-WL DSS-WL DS-WL SPD-WL GD-WL 2-FWL", "figure_data": "Section 3.1Section 3.2Section 4ModelMPNN GSN CWN GraphSNNESANOurs3-IGNWL variant 1-Cut vertex \u2717\u2717\u2717\u2717\u2713\u2717\u2717\u2713\u2713Cut edge\u2717\u2717\u2717\u2717\u2713Unknown\u2713\u2713\u2713BCVTree\u2717\u2717\u2717\u2717\u2713Unknown\u2717\u2713\u2713BCETree\u2717\u2717\u2717\u2717\u2713Unknown\u2713\u2713\u2713Ref. Theorem-3.1C.12C.133.2C.164.14.2, 4.34.6Timen+m n+m-n+mn(n+m) n(n+m)n 2n 2n 3Space 1nn-nn 2nnnn 2"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "", "figure_data": ": Accuracy on cut vertex (articulation point) andcut edge (bridge) detection tasks.ModelCut Vertex DetectionCut Edge DetectionGCN (Kipf & Welling, 2017)51.5%\u00b11.3% 62.4%\u00b11.8%GAT (Veli\u010dkovi\u0107 et al., 2018)52.0%\u00b11.3% 62.8%\u00b11.9%GIN (Xu et al., 2019)53.9%\u00b11.7% 63.1%\u00b12.2%GSN (Bouritsas et al., 2022)60.1%\u00b11.9% 70.7%\u00b12.1%Graphormer (Ying et al., 2021a) 76.4%\u00b12.8% 84.5%\u00b13.3%Graphormer-GD (ours)100%100%-w/o. Resistance Distance83.3%\u00b12.7%100%"}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "Mean Absolute Error (MAE) on ZINC test set. Following, the parameter budget of compared models is set to 500k. We use * to indicate the best performance.", "figure_data": "MethodModelTime (s) ParamsTest MAE ZINC-Subset ZINC-FullGIN (Xu et al., 2019)8.05509,5490.526\u00b10.0510.088\u00b10.002GraphSAGE (Hamilton et al., 2017)6.02505,3410.398\u00b10.0020.126\u00b10.003GAT (Veli\u010dkovi\u0107 et al., 2018)8.28531,3450.384\u00b10.0070.111\u00b10.002MPNNsGCN (Kipf & Welling, 2017)5.85505,0790.367\u00b10.0110.113\u00b10.002MoNet (Monti et al., 2017)7.19504,0130.292\u00b10.0060.090\u00b10.002GatedGCN-PE(Bresson & Laurent, 2017)10.74505,0110.214\u00b10.006-MPNN(sum) (Gilmer et al., 2017)-480,8050.145\u00b10.007-PNA (Corso et al., 2020)-387,1550.142\u00b10.010-Higher-orderRingGNN (Chen et al., 2019)178.03527,2830.353\u00b10.019-GNNs3WLGNN (Maron et al., 2019a)179.35507,6030.303\u00b10.068-Substructure-GSN (Bouritsas et al., 2022)-\u223c500k0.101\u00b10.010-based GNNsCIN-Small (Bodnar et al., 2021a)-\u223c100k0.094\u00b10.0040.044\u00b10.003NGNN (Zhang & Li, 2021)-\u223c500k0.111\u00b10.0030.029\u00b10.001Subgraph GNNsDSS-GNN (Bevilacqua et al., 2022) GNN-AK (Zhao et al., 2022) GNN-AK+ (Zhao et al., 2022)---445,709 \u223c500k \u223c500k0.097\u00b10.006 0.105\u00b10.010 0.091\u00b10.011---SUN (Frasca et al., 2022)15.04526,4890.083\u00b10.003-GT (Dwivedi & Bresson, 2021)-588,9290.226\u00b10.014-GraphSAN (Kreuzer et al., 2021)-508,5770.139\u00b10.006-TransformersGraphormer (Ying et al., 2021a)12.26489,3210.122\u00b10.0060.052\u00b10.005URPE (Luo et al., 2022b)12.40491,7370.086\u00b10.0070.028\u00b10.002GD-WLGraphormer-GD (ours)12.52502,7930.081\u00b10.009"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "Chengxuan Ying, Tianle Cai, Shengjie Luo, Shuxin Zheng, Guolin Ke, Di He, Yanming Shen, and Tie-Yan Liu. Do transformers really perform badly for graph representation? Advances in Neural Information Processing Systems, 34, 2021a. Chengxuan Ying, Mingqi Yang, Shuxin Zheng, Guolin Ke, Shengjie Luo, Tianle Cai, Chenglin Wu, Yuxin Wang, Yanming Shen, and Di He. First place solution of kdd cup 2021 ogb large-scale challenge graph-level track. arXiv preprint arXiv:2106.08279, 2021b. Jiaxuan You, Jonathan M Gomes-Selman, Rex Ying, and Jure Leskovec. Identity-aware graph neural networks. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pp. 10737-10745, 2021. WL Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . B.2 k-FWL Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . B.3 WL with Substructure Counting (SC-WL) . . . . . . . . . . . . . . . . . . . . B.4 Equivariant Subgraph Aggregation WL (DSS-WL) . . . . . . . . . . . . . . . . B.5 Generalized Distance WL (GD-WL) . . . . . . . . . . . . . . . . . . . . . . . GNNs with distance encoding . . . . . . . . . . . . . . . . . . . . . . . . . . . Preprocessing Shortest Path Distance . . . . . . . . . . . . . . . . . . . . . . . E.2 Preprocessing Resistance Distance . . . . . . . . . . . . . . . . . . . . . . . . E.3 Transformer-based implementation . . . . . . . . . . . . . . . . . . . . . . . . Synthetic Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . F.2 Real-world Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . F.3 More Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . F.4 Efficiency Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "figure_data": "AppendixTable of ContentsA Recent advances in expressive GNNsB The Weisfeiler-Lehman Algorithms and Recently Proposed VariantsB.1 1-F Experimental DetailsF.1"}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "The best computational complexity of known algorithms for solving different graph problems. Here n and m are the number of nodes and edges of a given graph, respectively.", "figure_data": "MetricComplexityReferencek-FWL\u2126(n k+1 )(Immerman & Lander, 1990)Counting/detecting trianglesO(min(n 2.376 , m 3/2 )) (Alon et al., 1997)Detecting cycles of an odd length k \u2265 3O(min(n 2.376 , m 2 ))(Alon et al., 1997)Detecting cycles of an even length k \u2265 4 O(n 2 )(Yuster & Zwick, 1997)Calculating the graph diameterO(nm)-Detecting cut vertices\u0398(n + m)(Tarjan, 1972)Detecting cut edges\u0398(n + m)"}, {"figure_label": "6", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "Efficiency Evaluation of different GNN models. We report the time per training epoch (seconds) as well as the number of model parameters.", "figure_data": "Model# Params Time (s)GCN (Kipf & Welling, 2017)505,0795.85GraphSAGE"}], "formulas": [{"formula_id": "formula_0", "formula_text": ", i.e. {{\u03c7 G (u) : u \u2208 V G }} \u0338 = {{\u03c7 H (u) : u \u2208 V H }}.", "formula_coordinates": [4.0, 218.92, 529.22, 204.96, 9.65]}, {"formula_id": "formula_1", "formula_text": "u \u2208 V G , v \u2208 V H where u is a cut vertex but v is not, their node features are different, i.e. \u03c7 G (u) \u0338 = \u03c7 H (v). Similarly, it can identify cut edges if for any {u, v} \u2208 E G and {w, x} \u2208 E H where {u, v} is a cut edge but {w, x} is not, their edge features are different, i.e. {{\u03c7 G (u), \u03c7 G (v)}} \u0338 = {{\u03c7 H (w), \u03c7 H (x)}}.", "formula_coordinates": [4.0, 108.0, 540.18, 396.0, 42.53]}, {"formula_id": "formula_2", "formula_text": "\u0338 \u2243 BCVTree(H) (or BCETree(G) \u0338 \u2243 BCETree(H)), their graph representations are different, i.e. {{\u03c7 G (u) : u \u2208 V G }} \u0338 = {{\u03c7 H (u) : u \u2208 V H }}.", "formula_coordinates": [4.0, 108.0, 594.97, 396.0, 20.61]}, {"formula_id": "formula_3", "formula_text": "Theorem 3.1. Let H = {H 1 , \u2022 \u2022 \u2022 , H k }, H i = (V i , E i )", "formula_coordinates": [5.0, 108.0, 394.87, 221.43, 9.72]}, {"formula_id": "formula_4", "formula_text": "B \u03c0 G = {{G 1 , \u2022 \u2022 \u2022 , G m }}", "formula_coordinates": [5.0, 108.0, 604.55, 96.95, 12.48]}, {"formula_id": "formula_5", "formula_text": "\u2022 For any two edges {w 1 , w 2 } \u2208 E G and {x 1 , x 2 } \u2208 E H , if {{\u03c7 G (w 1 ), \u03c7 G (w 2 )}} = {{\u03c7 H (x 1 ), \u03c7 H (x 2 )}}, then {w 1 , w 2 } is a cut edge if and only if {x 1 , x 2 } is a cut edge.", "formula_coordinates": [6.0, 129.42, 214.05, 374.58, 20.61]}, {"formula_id": "formula_6", "formula_text": "\u2208 V G , v \u2208 V H will have dif- ferent DSS-WL colors if the distance set {{dis G (u, w) : w \u2208 V G }} differs from {{dis H (v, w) : w \u2208 V H }}.", "formula_coordinates": [6.0, 108.0, 313.18, 396.0, 31.57]}, {"formula_id": "formula_7", "formula_text": "\u03c7 t G (v) := hash {{(d G (v, u), \u03c7 t\u22121 G (u)) : u \u2208 V}} ,(3)", "formula_coordinates": [7.0, 203.43, 223.69, 300.57, 13.31]}, {"formula_id": "formula_8", "formula_text": "\u03c7 t G (v) := hash \u03c7 t\u22121 G (v), {{\u03c7 t\u22121 G (u) : u \u2208 N G (v)}}, {{\u03c7 t\u22121 G (u) : dis G (v, u) = 2}}, \u2022 \u2022 \u2022 , {{\u03c7 t\u22121 G (u) : dis G (v, u) = n \u2212 1}}, {{\u03c7 t\u22121 G (u) : dis G (v, u) = \u221e}} .(4)", "formula_coordinates": [7.0, 123.5, 282.26, 380.5, 29.53]}, {"formula_id": "formula_9", "formula_text": "\u2022 If {{\u03c7 G (w) : w \u2208 V G }} = {{\u03c7 H (w) : w \u2208 V H }}, then BCETree(G) \u2243 BCETree(H).", "formula_coordinates": [7.0, 129.42, 456.83, 351.49, 9.65]}, {"formula_id": "formula_10", "formula_text": "\u2264 dis R G (u, v) \u2264 n \u2212 1, and dis R G (u, v) = dis G (u, v) if G is a tree.", "formula_coordinates": [7.0, 169.35, 709.68, 262.94, 13.03]}, {"formula_id": "formula_11", "formula_text": "\u2022 If {{\u03c7 G (w) : w \u2208 V G }} = {{\u03c7 H (w) : w \u2208 V H }}, then BCVTree(G) \u2243 BCVTree(H).", "formula_coordinates": [8.0, 129.42, 134.83, 352.88, 9.65]}, {"formula_id": "formula_12", "formula_text": "d G (u, v) := (dis G (u, v), dis R G (u, v))", "formula_coordinates": [8.0, 351.01, 240.53, 145.49, 13.03]}, {"formula_id": "formula_13", "formula_text": "Y h = \u03d5 h 1 (D) \u2299 softmax XW h Q (XW h K ) \u22a4 + \u03d5 h 2 (D) XW h V ,(5)", "formula_coordinates": [8.0, 174.86, 404.96, 329.14, 12.69]}, {"formula_id": "formula_14", "formula_text": "D uv = d G (u, v), W h Q , W h K , W h V \u2208 R d\u00d7d H", "formula_coordinates": [8.0, 148.01, 434.67, 183.98, 12.48]}, {"formula_id": "formula_15", "formula_text": "Y = h Y h W h O where W h O \u2208 R d H \u00d7d .", "formula_coordinates": [8.0, 250.11, 470.14, 166.79, 12.72]}, {"formula_id": "formula_16", "formula_text": "v \u2208 V for t \u2190 1 to T do for each v \u2208 V do \u03c7 t G (v) := hash \u03c7 t\u22121 G (v), {{\u03c7 t\u22121 G (u) : u \u2208 N G (v)}} Return: \u03c7 T G", "formula_coordinates": [19.0, 108.0, 425.98, 335.2, 64.39]}, {"formula_id": "formula_17", "formula_text": "\u223c \u03c7 t G defined to be u \u223c \u03c7 t G v \u21d0\u21d2 \u03c7 t G (u) = \u03c7 t G (v) for u, v \u2208 V.", "formula_coordinates": [19.0, 140.94, 512.17, 259.66, 13.74]}, {"formula_id": "formula_18", "formula_text": "P t G = {(\u03c7 t G ) \u22121 (c) : c \u2208 C t G } where C t G := {\u03c7 t G (v) : v \u2208 V} is the color set containing all the presented colors of vertices in G.", "formula_coordinates": [19.0, 108.0, 536.62, 396.0, 21.49]}, {"formula_id": "formula_19", "formula_text": "P t+1 G , because for any u, v \u2208 V, u \u223c \u03c7 t+1 G v implies u \u223c \u03c7 t G v.", "formula_coordinates": [19.0, 108.0, 576.37, 258.16, 15.47]}, {"formula_id": "formula_20", "formula_text": "G = P Tstable+1 G . It follows that P t G = P Tstable G", "formula_coordinates": [19.0, 108.0, 591.87, 396.0, 26.7]}, {"formula_id": "formula_21", "formula_text": "A v ij = c node if v i = v j c 0 if v i \u0338 = v j and {v i , v j } / \u2208 E c 1 if v i \u0338 = v j and {v i , v j } \u2208 E (6) for t \u2190 1 to T do for each v \u2208 V k do \u03c7 t G (v) := hash \u03c7 t\u22121 G (v), {{(\u03c7 t\u22121 G (N 1 (v, u)), \u2022 \u2022 \u2022 , \u03c7 t\u22121 G (N k (v, u))) : u \u2208 V}} where N i (v, u) = (v 1 , \u2022 \u2022 \u2022 , v i\u22121 , u, v i+1 , \u2022 \u2022 \u2022 , v k ) Return: \u03c7 T G", "formula_coordinates": [20.0, 108.0, 219.45, 381.06, 107.02]}, {"formula_id": "formula_22", "formula_text": "T = |V| k .", "formula_coordinates": [20.0, 108.0, 420.58, 40.34, 10.53]}, {"formula_id": "formula_23", "formula_text": ") := {Orb H (v) : v \u2208 V H } is called the quotient of the automorphism. Denote d H = |H\\ Aut(H)| and denote the elements in H\\ Aut(H) as {O V H,i } d H i=1 .", "formula_coordinates": [21.0, 108.0, 106.94, 396.0, 23.7]}, {"formula_id": "formula_24", "formula_text": "V H,i (v) := G[S] : S \u2282 V, G[S] \u2243 H, v \u2208 S, f G[S]\u2192V H (v) \u2208 O V H,i , i \u2208 [d H ](7)", "formula_coordinates": [21.0, 146.9, 203.29, 357.1, 12.69]}, {"formula_id": "formula_25", "formula_text": "x V (v) = [x V H1 (v) \u22a4 , \u2022 \u2022 \u2022 , x V H k (v) \u22a4 ] \u22a4 \u2208 N D + (8)", "formula_coordinates": [21.0, 217.67, 275.46, 286.33, 13.36]}, {"formula_id": "formula_26", "formula_text": "x V (v) is D = i\u2208[k] d i .", "formula_coordinates": [21.0, 204.29, 291.83, 100.19, 12.72]}, {"formula_id": "formula_27", "formula_text": "\u03c7 t G (v) := hash \u03c7 t\u22121 G (v), x V (v), {{(\u03c7 t\u22121 G (u), x V (u)) : u \u2208 N G (v)}}(9)", "formula_coordinates": [21.0, 165.57, 335.72, 338.43, 13.31]}, {"formula_id": "formula_28", "formula_text": "B \u03c0 G = {{G v : v \u2208 V}}, but each graph G v = (V, E v ) has a different edge set E v := E\\{{v, w} : w \u2208 N G (v)}.", "formula_coordinates": [21.0, 137.89, 677.65, 366.11, 33.14]}, {"formula_id": "formula_29", "formula_text": "B \u03c0 G = {{G i }} m i=1 , G i = (V, E i ) and initial coloring \u03c7 0 Gi for i \u2208 [m] according to policy \u03c0 Let \u03c7 0 G (v) := hash {{\u03c7 t Gi (v) : i \u2208 [m]}} for each v \u2208 V for t \u2190 1 to T do for each v \u2208 V do for i \u2190 1 to m do \u03c7 t Gi (v) := hash \u03c7 t\u22121 Gi (v), {{\u03c7 t\u22121 Gi (u) : u \u2208 N Gi (v)}}, \u03c7 t\u22121 G (v), {{\u03c7 t\u22121 G (u) : u \u2208 N G (v)}} \u03c7 t G (v) := hash {{\u03c7 t Gi (v) : i \u2208 [m]}} Return: \u03c7 T G \u2022 Ego network policy \u03c0 = \u03c0 EGO(k) .", "formula_coordinates": [22.0, 108.0, 122.45, 379.69, 168.53]}, {"formula_id": "formula_30", "formula_text": "B \u03c0 G = {{G v : v \u2208 V}}, G v = (V, E v ). The edge set E v is defined as E v := {{u, w} \u2208 E : dis G (u, v) \u2264 k, dis G (w, v) \u2264", "formula_coordinates": [22.0, 137.89, 279.45, 366.11, 23.24]}, {"formula_id": "formula_31", "formula_text": "(v) = c 0 for all v \u2208 V and G i \u2208 B \u03c0 G", "formula_coordinates": [22.0, 344.63, 313.38, 158.87, 12.47]}, {"formula_id": "formula_32", "formula_text": "|B \u03c0 G | = |V|.", "formula_coordinates": [22.0, 261.27, 353.29, 47.01, 12.47]}, {"formula_id": "formula_33", "formula_text": "\u03c7 t Gi (v) := hash \u03c7 t\u22121 Gi (v), {{\u03c7 t\u22121 Gi (u) : u \u2208 N G (v)}} . (10", "formula_coordinates": [22.0, 196.32, 451.85, 303.53, 13.31]}, {"formula_id": "formula_34", "formula_text": ")", "formula_coordinates": [22.0, 499.85, 454.39, 4.15, 8.64]}, {"formula_id": "formula_35", "formula_text": "Algorithm 4: The Genealized Distance Weisfeiler-Lehman Algorithm Input : Graph G = (V, E), distance metric d G : V \u00d7 V \u2192 R + ,", "formula_coordinates": [22.0, 108.0, 618.69, 280.66, 24.13]}, {"formula_id": "formula_36", "formula_text": "G (v) := c 0 for all v \u2208 V for t \u2190 1 to T do for each v \u2208 V do \u03c7 t G (v) := hash {{(d G (v, u), \u03c7 t\u22121 G (u)) : u \u2208 V}} Return: \u03c7 T G C PROOF OF THEOREMS", "formula_coordinates": [22.0, 108.0, 655.09, 335.2, 64.39]}, {"formula_id": "formula_37", "formula_text": "|N G (u) \u2229 \u03c7 \u22121 G (c)| = |N G (v) \u2229 \u03c7 \u22121 G (c)|, where \u03c7 \u22121 G is the inverse mapping of \u03c7 G . Remark C.2.", "formula_coordinates": [23.0, 108.0, 239.92, 279.69, 44.89]}, {"formula_id": "formula_38", "formula_text": "|N G (u) \u2229 \u03c7 \u22121 G (c)| = |N H (v) \u2229 \u03c7 \u22121 H (c)|. It clearly implies Definition C.1 by choosing G = H.", "formula_coordinates": [23.0, 108.0, 325.22, 280.12, 28.53]}, {"formula_id": "formula_39", "formula_text": "w \u2208 N Gi (u)}} = {{\u03c7 Hj (w) : w \u2208 N Hj (v)}}. Namely, |{w : w \u2208 N Gi (u) \u2229 \u03c7 \u22121 Gi (c)}| = |{w : w \u2208 N Hj (v) \u2229 \u03c7 \u22121", "formula_coordinates": [23.0, 108.0, 492.71, 396.0, 34.66]}, {"formula_id": "formula_40", "formula_text": "\u03c7 G (u) = \u03c7 H (v), then {{\u03c7 Gi (u) : i \u2208 [m G ]}} = {{\u03c7 Hj (v) : j \u2208 [m H ]}} (", "formula_coordinates": [23.0, 108.0, 537.97, 396.0, 20.61]}, {"formula_id": "formula_41", "formula_text": "{{(dis G (u, w), \u03c7 G (w)) : w \u2208 V}} = {{(dis G (v, w), \u03c7 G (w)) : w \u2208 V}}.", "formula_coordinates": [23.0, 164.57, 640.88, 282.87, 9.65]}, {"formula_id": "formula_42", "formula_text": "{{\u03c7 G (w) : w \u2208 N G (u)}} = {{\u03c7 G (w) : w \u2208 N G (v)}}.", "formula_coordinates": [23.0, 199.55, 675.59, 212.89, 9.65]}, {"formula_id": "formula_43", "formula_text": "w \u2208 N G (u) \u2229 \u03c7 \u22121 G (c)}| = |{w : w \u2208 N G (v) \u2229 \u03c7 \u22121 G(", "formula_coordinates": [23.0, 233.84, 692.0, 211.55, 13.31]}, {"formula_id": "formula_44", "formula_text": "Proof. Let \u03c7 G (u) = \u03c7 H (v) for some u \u2208 V G and v \u2208 V H . By the update formula (Line 4 in Algorithm 2), {{\u03c7 G (u, \u2022 \u2022 \u2022 , u, w) : w \u2208 V G }} = {{\u03c7 H (v, \u2022 \u2022 \u2022 , v, w) : w \u2208 V H }}. Note that for any nodes w 1 \u2208 V G , w 2 \u2208 V H and any x 1 \u2208 N G (w 1 ), x 2 / \u2208 N H (w 2 ), one has \u03c7 G (w 1 , \u2022 \u2022 \u2022 , w 1 , x 1 ) \u0338 = \u03c7 H (w 2 , \u2022 \u2022 \u2022 , w 2 , x 2 )", "formula_coordinates": [24.0, 108.0, 85.02, 396.0, 42.53]}, {"formula_id": "formula_45", "formula_text": "\u03c7 G refines \u03c7 0 G . Consequently, {{\u03c7 G (u, \u2022 \u2022 \u2022 , u, w) : w \u2208 N G (u)}} = {{\u03c7 G (v, \u2022 \u2022 \u2022 , v, w) : w \u2208 N H (v)}}. Next, we can use the fact that if \u03c7 G (u, \u2022 \u2022 \u2022 , u, w 1 ) = \u03c7 G (v, \u2022 \u2022 \u2022 , v, w 2 ) for some w 1 , w 2 \u2208 V, then \u03c7 G (w 1 ) = \u03c7 G (w 2 ) (see Lemma C.6). Therefore, {{\u03c7 G (w) : w \u2208 N G (u)}} = {{\u03c7 G (w) : w \u2208 N H (v)", "formula_coordinates": [24.0, 108.0, 127.28, 396.0, 44.1]}, {"formula_id": "formula_46", "formula_text": "x) := (w, \u2022 \u2022 \u2022 , w i times , x, \u2022 \u2022 \u2022 , xj times", "formula_coordinates": [24.0, 268.01, 222.39, 107.71, 23.54]}, {"formula_id": "formula_47", "formula_text": "\u2208 V G , v, x \u2208 V H , if \u03c7 G (cat k\u2212i,i (u, w)) = \u03c7 H (cat k\u2212i,i (v, x)), then \u03c7 G (cat k\u2212i\u22121,i+1 (u, w)) = \u03c7 H (cat k\u2212i\u22121,i+1 (v, x)). Consequently, \u03c7 G (w) = \u03c7 H (x).", "formula_coordinates": [24.0, 108.0, 252.44, 396.0, 31.57]}, {"formula_id": "formula_48", "formula_text": "4 in Algorithm 2), \u03c7 G (cat k\u2212i,i (u, w)) = \u03c7 H (cat k\u2212i,i (v, x)) implies that {{\u03c7 G (cat k\u2212i\u22121,1,i (u, y, w)) : y \u2208 V G }} = {{\u03c7 H (cat k\u2212i\u22121,1,i (v, y, x)) : y \u2208 V H }}. Note that for any j \u2208 [k \u2212 1] and any z \u2208 V k G , z \u2032 \u2208 V k H with z j = z j+1 but z \u2032 j \u0338 = z \u2032 j+1 , one has \u03c7 G (z) \u0338 = \u03c7 H (z \u2032 )", "formula_coordinates": [24.0, 108.0, 298.24, 396.0, 45.97]}, {"formula_id": "formula_49", "formula_text": "k\u2212i\u22121,i+1 (u, w)) = \u03c7 H (cat k\u2212i\u22121,i+1 (v, x)), as desired.", "formula_coordinates": [24.0, 108.0, 345.52, 396.0, 19.92]}, {"formula_id": "formula_50", "formula_text": "u i ) = \u03c7 G (v i ) holds for all i \u2208 [d].", "formula_coordinates": [24.0, 224.06, 429.38, 136.61, 9.65]}, {"formula_id": "formula_51", "formula_text": "\u03c7 G (u) = \u03c7 H (v)) and a color c = \u03c7 G (v 1 ) such that N G (u) \u2229 \u03c7 \u22121 G (c) \u0338 = \u2205 but N H (v) \u2229 \u03c7 \u22121 H (c) = \u2205.", "formula_coordinates": [24.0, 108.0, 472.96, 396.0, 13.3]}, {"formula_id": "formula_52", "formula_text": "(v 0 , \u2022 \u2022 \u2022 , v d\u22121 ) and (v d\u22121 , v d ). Separately using induction yields two paths (u 0 , \u2022 \u2022 \u2022 , u d\u22121 ) and (u d\u22121 , u d ) such that \u03c7 H (u i ) = \u03c7 G (v i ) for all i \u2208 [d].", "formula_coordinates": [24.0, 108.0, 497.1, 396.0, 20.61]}, {"formula_id": "formula_53", "formula_text": "Corollary C.8. For any color c \u2208 {\u03c7 G (w) : w \u2208 V G } and any two vertices u \u2208 V G , v \u2208 V H with the same color (i.e. \u03c7 G (u) = \u03c7 H (v)), dis G (u, \u03c7 \u22121 G (c)) = dis H (v, \u03c7 \u22121 H (c)).", "formula_coordinates": [24.0, 108.0, 568.65, 396.0, 23.4]}, {"formula_id": "formula_54", "formula_text": "E 1 = {{i, (i mod 2km) + 1} : i \u2208 [2km]} \u222a {{n, i} : i \u2208 [2km], i mod m = 0} , E 2 = {{i, (i mod km) + 1} : i \u2208 [km]} \u222a {{i + km, (i mod km) + km + 1} : i \u2208 [km]} \u222a {{n, i} : i \u2208 [2km], i mod m = 0} .", "formula_coordinates": [24.0, 122.46, 691.87, 367.09, 36.63]}, {"formula_id": "formula_55", "formula_text": "(i) m = 2, k = 2; (ii) m = 4, k = 1; (iii) m = 1, k = 4.", "formula_coordinates": [25.0, 108.0, 85.02, 396.0, 19.7]}, {"formula_id": "formula_56", "formula_text": "E 1 = {{i, (i mod n) + 1} : i \u2208 [n]} \u222a {{m, 2m}} , E 2 = {{i, (i mod m) + 1} : i \u2208 [m]} \u222a {{i + m, (i mod m) + m + 1} : i \u2208 [m]} \u222a {{m, 2m}} .", "formula_coordinates": [25.0, 111.95, 167.9, 388.11, 23.6]}, {"formula_id": "formula_57", "formula_text": "Let H = {H 1 , \u2022 \u2022 \u2022 , H k }, H i = (V i , E i )", "formula_coordinates": [25.0, 175.98, 231.85, 156.62, 9.65]}, {"formula_id": "formula_58", "formula_text": "n V = max i\u2208[k] |V i |.", "formula_coordinates": [25.0, 108.0, 242.81, 82.49, 9.96]}, {"formula_id": "formula_59", "formula_text": "x V G1 (n) = x V G2 (n) and x V G1 (i) = x V G2 (i) for all m < i \u2264 2m", "formula_coordinates": [25.0, 151.75, 402.28, 240.06, 12.47]}, {"formula_id": "formula_60", "formula_text": "x V G1 (v) = x V G2 (v) for v \u2208 {m + 1, \u2022 \u2022 \u2022 , 2m}.", "formula_coordinates": [25.0, 212.69, 415.4, 185.48, 12.47]}, {"formula_id": "formula_61", "formula_text": "S : S \u2192 [n], such that g S (u) = cir(u, m, 2m) if k = 1, cir(u, 0, km) if k \u2265 2.", "formula_coordinates": [25.0, 242.46, 489.96, 154.43, 35.62]}, {"formula_id": "formula_62", "formula_text": "G 1 [S] is mapped to a chain of G 2 that contains v. Concretely, denote g S (S) = {g S (u) : u \u2208 S}, then G 2 [g S (S)] \u2243 G 1 [S] \u2243 H i , and obviously the orbit of v in G 2 [g S (S)] matches the orbit of v in G 1 [S].", "formula_coordinates": [25.0, 137.89, 532.92, 366.11, 31.57]}, {"formula_id": "formula_63", "formula_text": "g S (u) = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 cir(u, m, 2m) if k = 1 and w u = w v , cir(u, 0, m) if k = 1 and w u \u0338 = w v , cir(u, 0, km)", "formula_coordinates": [25.0, 206.65, 630.77, 220.03, 39.25]}, {"formula_id": "formula_64", "formula_text": "x 1 , x 2 \u2208 S, {x 1 , x 2 } \u2208 E G1 \u21d0\u21d2 {g S (x 1 ), g S (x 2 )} \u2208 E G2 . Therefore, G 2 [g S (S)] \u2243 G 1 [S] \u2243 H i .", "formula_coordinates": [25.0, 137.89, 679.22, 366.11, 20.61]}, {"formula_id": "formula_65", "formula_text": "2 \u22121 +2 +1 2 \u22121 +1 +2 1 1 2 \u2026 \u2026 \u22121 \u2026 \u2026 2 \u22121 2 1 2 2 \u22121 2 2 \u22121 2 2 +1 1 2 \u22121 +1 +2 +2 \u2026 \u22121 +1 \u2026 \u2026 2 +1 3 \u22121 3 3 +1 \u2026 4 \u22121 4 3 \u22121 3 3 +1 4 \u22121 4 2 \u22121 1 \u22121 +1 2 +2 \u2026 \u22121 +1 +2 2 \u22121 2 2 2 \u2026 \u2026 \u2026 2 1 2 \u22121 +1 2 \u22121 2 2 +1 3 \u22121 3 3 +1 4 \u22121 4 1 \u22121 +1 +2 2 \u22121 2 2 +1 4 \u22121 4 +2 \u2026 \u2026 \u2026 \u2026 3 \u22121 3 3 +1 (a) n / \u2208 S, k = 1 (b) n / \u2208 S, k > 1 (c) n \u2208 S, k = 1 (d) n \u2208 S, k > 1", "formula_coordinates": [26.0, 109.24, 82.03, 398.54, 173.13]}, {"formula_id": "formula_66", "formula_text": "1 [S 1 ] \u2243 G 1 [S 2 ] \u2243 H i , we have g S1 (S 1 ) \u0338 = g S2 (S 2 ), which guarantees that the mapping g : {S \u2282 [n] : G 1 [S] \u2243 H i , v \u2208 S} \u2192 {S \u2282 [n] : G 2 [S] \u2243 H i , v", "formula_coordinates": [26.0, 108.0, 283.38, 396.0, 31.57]}, {"formula_id": "formula_67", "formula_text": "x V G1 (v) = x V G2 (v) for v \u2208 {m, \u2022 \u2022 \u2022 , 2m \u2212 1}. The proof for x V G1 (n) = x V G2 (n)", "formula_coordinates": [26.0, 108.0, 314.68, 396.0, 25.59]}, {"formula_id": "formula_68", "formula_text": "B \u03c0 G = {{G i }} |V| i=1", "formula_coordinates": [27.0, 425.76, 413.86, 67.83, 14.07]}, {"formula_id": "formula_69", "formula_text": "x \u2208 V in H, if \u03c7 G (w) = \u03c7 H (x), then \u03c7 G[S G (w)] (w) = \u03c7 H[S H (x)] (x). Proof. We first prove that if \u03c7 G (w) = \u03c7 H (x), then {{\u03c7 u G (w) : u \u2208 S G (w)}} = {{\u03c7 u H (x) : u \u2208 S H (x)}}. First note that for any nodes u, w in G and v, x in H, if u \u2208 S G (w) but v / \u2208 S H (x), then \u03c7 u G (w) \u0338 = \u03c7 v H (x)", "formula_coordinates": [28.0, 108.0, 172.05, 396.0, 71.03]}, {"formula_id": "formula_70", "formula_text": "\u03c7 G (w) = hash ({{\u03c7 u G (w) : u \u2208 S G (w)}} \u222a {{\u03c7 v G (w) : v / \u2208 S G (w)}}) .", "formula_coordinates": [28.0, 166.59, 264.04, 278.82, 12.69]}, {"formula_id": "formula_71", "formula_text": "\u03c7 H (x) = hash ({{\u03c7 u H (x) : u \u2208 S H (x)}} \u222a {{\u03c7 v H (x) : v / \u2208 S H (x)}}) . Since \u03c7 G (w) = \u03c7 H (x), we have {{\u03c7 u G : u \u2208 S G (w)}} = {{\u03c7 u H : u \u2208 S H (x)}}. This clearly implies {{\u03c7 u G[S G (w)] : u \u2208 S G (w)}} = {{\u03c7 u H[S H (x)] : u \u2208 S H (x)}}, and thus \u03c7 G[S G (w)] (w) = \u03c7 H[S H (x)] (x).", "formula_coordinates": [28.0, 108.0, 292.05, 396.0, 53.02]}, {"formula_id": "formula_72", "formula_text": "(a) If w = u and x \u0338 = v, then \u03c7 u G (w) \u0338 = \u03c7 v H (x); (b) If \u03c7 u G (w) = \u03c7 v H (x), then \u03c7 G (w) = \u03c7 H (x); (c) If \u03c7 u G (w) = \u03c7 v H (x), then \u03c7 G (u) = \u03c7 H (v); (d) \u03c7 G (w) = \u03c7 H (x) if and only if \u03c7 w G (w) = \u03c7 x H (x); (e) If \u03c7 u G (w) = \u03c7 v H (x), then dis G (u, w) = dis H (v, x).", "formula_coordinates": [28.0, 121.29, 464.14, 221.23, 80.22]}, {"formula_id": "formula_73", "formula_text": "\u03c7 G (w) = hash ({{\u03c7 w G (w)}} \u222a {{\u03c7 u G (w) : u \u2208 V\\{w}}}) , \u03c7 H (x) = hash ({{\u03c7 x H (x)}} \u222a {{\u03c7 v H (x) : v \u2208 V\\{x}}}) .", "formula_coordinates": [28.0, 192.67, 703.75, 226.65, 26.64]}, {"formula_id": "formula_74", "formula_text": "u G ) \u22121 (\u03c7 u G (u))) = dis H (x, (\u03c7 v H ) \u22121 (\u03c7 u G (u))).", "formula_coordinates": [29.0, 108.0, 122.3, 396.0, 23.43]}, {"formula_id": "formula_75", "formula_text": "\u2032 \u0338 = v, \u03c7 v H (v \u2032 ) \u0338 = \u03c7 v H (v", "formula_coordinates": [29.0, 108.0, 133.26, 396.0, 23.43]}, {"formula_id": "formula_76", "formula_text": "G = C d+1 H . Note that for any nodes x 1 , x 2 satisfying \u03c7 u G (x 1 ) = \u03c7 v H (x 2 ), {{\u03c7 u G (w) : w \u2208 N G (x 1 )}} = {{\u03c7 v H (w) : w \u2208 N H (x 2 )}}. Therefore, by the induction assumption C d G = C d H , x\u2208N d G (u) {{\u03c7 u G (w) : w \u2208 N G (x)}} = x\u2208N d H (v) {{\u03c7 v H (w) : w \u2208 N H (x)}}. We next claim that C d G \u2229 C d \u2032 G = \u2205 for any d \u0338 = d \u2032 .", "formula_coordinates": [29.0, 108.0, 313.27, 396.0, 87.2]}, {"formula_id": "formula_77", "formula_text": "x\u2208N d G (u) {{\u03c7 u G (w) : w \u2208 N G (x) \u2229 N d+1 G (u)}} = x\u2208N d H (v) {{\u03c7 v H (w) : w \u2208 N H (x) \u2229 N d+1 H (v)}}.", "formula_coordinates": [29.0, 116.6, 427.88, 378.8, 25.35]}, {"formula_id": "formula_78", "formula_text": "w\u2208N d+1 G (u) {{\u03c7 u G (w)}} \u00d7 |N G (w) \u2229 N d G (u)| = w\u2208N d+1 H (v) {{\u03c7 v H (w)}} \u00d7 |N H (w) \u2229 N d H (v)|.", "formula_coordinates": [29.0, 125.06, 475.77, 361.88, 26.03]}, {"formula_id": "formula_79", "formula_text": "|N G (w 1 ) \u2229 N d G (u)| = |N H (w 2 ) \u2229 N d H (v)| (because C d G \u2229 C d \u2032 G = \u2205 for any d \u0338 = d \u2032 ). Consequently, {{\u03c7 u G (w) : w \u2208 N d+1 G (u)}} = {{\u03c7 v H (w) : w \u2208 N d+1 H (v)}}, namely C d+1 G = C d+1 H .", "formula_coordinates": [29.0, 108.0, 519.11, 396.0, 38.82]}, {"formula_id": "formula_80", "formula_text": "w \u2208 \u03c7 \u22121 G (c)}} = {{\u03c7 v G (w) : w \u2208 \u03c7 \u22121 G (c)}}. Proof. First observe that if \u03c7 G (u) = \u03c7 G (v), then \u03c7 u G (u) = \u03c7 v G (v) (by Lemma C.19(d)). Con- sequently, {{\u03c7 u G (w) : w \u2208 V}} = {{\u03c7 v G (w) : w \u2208 V}} holds by Lemma C.20. If {{\u03c7 u G (w) : w \u2208 \u03c7 \u22121 G (c)}} \u0338 = {{\u03c7 v G (w) : w \u2208 \u03c7 \u22121 G (c)}}, then there must exist two nodes w 1 \u2208 \u03c7 \u22121 G (c) and w 2 / \u2208 \u03c7 \u22121 G (c), such that \u03c7 u G (w 1 ) = \u03c7 v G (w 2 )", "formula_coordinates": [29.0, 108.0, 604.4, 396.0, 73.15]}, {"formula_id": "formula_81", "formula_text": "S i satisfying S i \u2229 \u03c7 \u22121 G (\u03c7 G (u)) \u0338 = \u2205. In other words, if S i \u2229 \u03c7 \u22121 G (\u03c7 G (u)) \u0338 = \u2205 for some i \u2208 [m], then for any j \u2208 [m] and j \u0338 = i, S j \u2229 \u03c7 \u22121 G (\u03c7 G (u)) = \u2205. Proof. When |\u03c7 \u22121 G (\u03c7 G (u))| = 1, the conclusion clearly holds. If |\u03c7 \u22121 G (\u03c7 G (u))| > 1, then we can pick a node u 1 \u2208 \u03c7 \u22121 G (\u03c7 G (u)) that maximizes the shortest path distance dis G (u 1 , u). Let u 1 \u2208 S i for some i \u2208 [m].", "formula_coordinates": [30.0, 108.0, 234.23, 396.0, 74.88]}, {"formula_id": "formula_82", "formula_text": "u 2 \u2208 \u03c7 \u22121 G (\u03c7 G (u)) and u 2 / \u2208 S i . Since u 1 and u 2 are in different connected component after removing u, dis G (u 1 , u 2 ) = dis G (u 1 , u) + dis G (u 2 , u). See Figure", "formula_coordinates": [30.0, 108.0, 297.93, 396.0, 33.79]}, {"formula_id": "formula_83", "formula_text": "By Corollary C.21, {{\u03c7 u1 G (w) : w \u2208 \u03c7 \u22121 G (\u03c7 G (u))}} = {{\u03c7 u G (w) : w \u2208 \u03c7 \u22121 G (\u03c7 G (u))}}. There- fore, there must exist a node u 3 \u2208 \u03c7 \u22121 G (\u03c7 G (u)) satisfying \u03c7 u1 G (u 2 ) = \u03c7 u G (u 3 ). We thus have dis G (u 2 , u 1 ) = dis G (u 3 , u) by Lemma C.19(e). On the other hand, by definition of the node u 1 , dis G (u 1 , u) \u2265 dis G (u 3 , u). Therefore, dis G (u 2 , u 1 ) = dis G (u 1 , u) + dis G (u 2 , u) > dis G (u 3 , u).", "formula_coordinates": [30.0, 108.0, 337.9, 396.0, 46.64]}, {"formula_id": "formula_84", "formula_text": "Lemma C.23. For all u \u2032 \u2208 \u03c7 \u22121 G (\u03c7 G (u)), u \u2032 it is a cut vertex of G. Proof. When |\u03c7 \u22121 G (\u03c7 G (u))| = 1, the conclusion clearly holds. Now assume |\u03c7 \u22121 G (\u03c7 G (u))| > 1. Since u is a cut vertex in G, by Lemma C.22, there exists a set S j such that S j \u2229 \u03c7 \u22121 G (\u03c7 G (u)) = \u2205. Pick any node w \u2208 S j , then \u03c7 G (w) \u0338 = \u03c7 G (u). Let u \u2032 \u0338 = u be any node with color \u03c7 G (u) = \u03c7 G (u \u2032 ). It follows that \u03c7 u G (u) = \u03c7 u \u2032 G (u \u2032 ) by", "formula_coordinates": [30.0, 108.0, 405.58, 396.0, 75.66]}, {"formula_id": "formula_85", "formula_text": "P = (x 0 , \u2022 \u2022 \u2022 , x d ) where x 0 = w \u2032 and x d = u. It follows that \u03c7 u \u2032 G (x i ) \u0338 = \u03c7 u \u2032 G (u \u2032 ) for all i \u2208 [d] (by", "formula_coordinates": [30.0, 108.0, 520.69, 396.0, 23.13]}, {"formula_id": "formula_86", "formula_text": "\u2022 \u2022 \u2022 , y d ) satisfying y 0 = w and \u03c7 u G (y i ) = \u03c7 u \u2032 G (x i ) for all i \u2208 [d]. In particular, \u03c7 u G (y d ) = \u03c7 u \u2032 G (u), which implies \u03c7 G (y d ) = \u03c7 G (u) by using", "formula_coordinates": [30.0, 108.0, 534.87, 396.0, 33.49]}, {"formula_id": "formula_87", "formula_text": "y d \u2208 \u03c7 \u22121 G (\u03c7 G (u)) must go through node u, implying that \u03c7 u G (y i ) = \u03c7 u G (u) for some i \u2208 [d]. However, we have proved that \u03c7 u G (y i ) = \u03c7 u \u2032 G (x i ) \u0338 = \u03c7 u \u2032 G (u \u2032 ) = \u03c7 u G (u), yielding a contradiction. Therefore, u \u2032 is a cut vertex.", "formula_coordinates": [30.0, 108.0, 568.73, 396.0, 35.45]}, {"formula_id": "formula_88", "formula_text": "Observe that |\u03c7 \u22121 G (\u03c7 G (u))| = |\u03c7 \u22121 H (\u03c7 H (u))|. (A simple proof is as follows: \u03c7 G (u) = \u03c7 H (u \u2032 ) implies \u03c7 u G (u) = \u03c7 u \u2032 H (u \u2032 ) by", "formula_coordinates": [30.0, 108.0, 640.58, 396.0, 26.44]}, {"formula_id": "formula_89", "formula_text": "|\u03c7 \u22121 G (\u03c7 G (u))| = |\u03c7 \u22121 H (\u03c7 H (u))| > 1.", "formula_coordinates": [30.0, 238.88, 694.92, 151.5, 13.31]}, {"formula_id": "formula_90", "formula_text": "w \u2032 in H satisfying \u03c7 G (w) \u0338 = \u03c7 G (u) and \u03c7 u \u2032 H (w \u2032 ) = \u03c7 u G (w). Since |\u03c7 \u22121 G (\u03c7 G (u))| > 1, we can pick a node u H \u2208 \u03c7 \u22121 H (\u03c7 G (u)) in H such that u H \u0338 = u \u2032 . If u \u2032 is \u2032 \u2032 Graph Graph \u2032 \u2032 \u2032 Graph Graph(", "formula_coordinates": [30.0, 108.0, 707.23, 396.0, 26.91]}, {"formula_id": "formula_91", "formula_text": "P = (x 0 , \u2022 \u2022 \u2022 , x d ) in H where x 0 = w \u2032 and x d = u H , such that \u03c7 u \u2032 H (x i ) \u0338 = \u03c7 u \u2032 H (u \u2032 ) for all i \u2208 [d] (by", "formula_coordinates": [31.0, 108.0, 224.76, 396.0, 25.35]}, {"formula_id": "formula_92", "formula_text": "\u2022 \u2022 \u2022 , y d ) in G satisfying y 0 = w and \u03c7 u G (y i ) = \u03c7 u \u2032 H (x i ) for all i \u2208 [d]. In particular, \u03c7 u G (y d ) = \u03c7 u \u2032 H (u H ), which implies \u03c7 G (y d ) = \u03c7 G (u H ) by using Lemma C.19(b). However, any path from w to y d \u2208 \u03c7 \u22121 G (\u03c7 G (u)) must go through node u, implying that \u03c7 u G (y i ) = \u03c7 u G (u) for some i \u2208 [d]. This yields a contradiction because \u03c7 u G (y i ) = \u03c7 u \u2032 H (x i ) \u0338 = \u03c7 u \u2032 H (u \u2032 ) = \u03c7 u G(", "formula_coordinates": [31.0, 108.0, 249.12, 396.0, 53.06]}, {"formula_id": "formula_93", "formula_text": "|\u03c7 \u22121 G (\u03c7 G (u))| = |\u03c7 \u22121 H (\u03c7 H (u))| = 1.", "formula_coordinates": [31.0, 249.03, 316.96, 151.72, 13.31]}, {"formula_id": "formula_94", "formula_text": "\u03c7 G (w) \u0338 = \u03c7 G (u) and \u03c7 G (x) \u0338 = \u03c7 G (u). Since \u03c7 G (u) = \u03c7 H (u \u2032 ), by the WL-condition (Lemma C.7) there is a node w \u2032 \u2208 \u03c7 \u22121 H (\u03c7 G (w)) in H. Consequently, \u03c7 w G (w) = \u03c7 w \u2032 H (w \u2032 ) (Lemma C.19(d)). Again by the WL-condition, there is a node x \u2032 \u2208 (\u03c7 w \u2032 H ) \u22121 (\u03c7 w G (x)) in H. Clearly, w \u2032 \u0338 = u \u2032 and x \u2032 \u0338 = u \u2032 (because they have different colors). If u \u2032 is not a cut vertex, then there is path P = (y 0 , \u2022 \u2022 \u2022 , y d ) in H such that y 0 = x \u2032 , y d = w \u2032 and y i \u0338 = u \u2032 for all i \u2208 [d]. It follows that for all i \u2208 [d], \u03c7 H (y i ) \u0338 = \u03c7 H (u \u2032 )", "formula_coordinates": [31.0, 108.0, 339.52, 396.0, 72.21]}, {"formula_id": "formula_95", "formula_text": "G (z i ) = \u03c7 w \u2032 H (y i ) implies \u03c7 G (z i ) = \u03c7 H (y i ) and thus \u03c7 G (z i ) \u0338 = \u03c7 H (u \u2032 ) = \u03c7 G (u) holds for all i \u2208 [d] and thus z i \u0338 = u.", "formula_coordinates": [31.0, 108.0, 467.91, 396.0, 23.83]}, {"formula_id": "formula_96", "formula_text": "{{dis G (w, v) : v \u2208 \u03c7 \u22121 G (c)}} = {{dis G (x, v) : v \u2208 \u03c7 \u22121 G (c)}}. Proof. By Corollary C.21, we have {{\u03c7 w G (v) : v \u2208 \u03c7 \u22121 G (c)}} = {{\u03c7 x G (v) : v \u2208 \u03c7 \u22121 G (c)}}. Since for any nodes u, v, \u03c7 w G (u) = \u03c7 x G (v) implies dis G (u, w) = dis G (v, x) (by Lemma C.", "formula_coordinates": [31.0, 108.0, 585.94, 396.0, 49.47]}, {"formula_id": "formula_97", "formula_text": "{{(dis G (w, v), \u03c7 G (v)) : v \u2208 V}} = {{(dis G (x, v), \u03c7 G (v)) : v \u2208 V}}.", "formula_coordinates": [31.0, 170.11, 685.62, 271.79, 9.65]}, {"formula_id": "formula_98", "formula_text": "\u2022 For any two edges {w 1 , w 2 } \u2208 E G and {x 1 , x 2 } \u2208 E H , if {{\u03c7 G (w 1 ), \u03c7 G (w 2 )}} = {{\u03c7 H (x 1", "formula_coordinates": [32.0, 129.42, 133.54, 374.58, 20.61]}, {"formula_id": "formula_99", "formula_text": "\u03c7 G (u) \u0338 = \u03c7 G (v) (Appendix C.4.1) and \u03c7 G (u) = \u03c7 G (v) (Appendix C.4.", "formula_coordinates": [32.0, 108.0, 248.21, 286.81, 9.65]}, {"formula_id": "formula_100", "formula_text": "{u \u2032 , v \u2032 } \u2208 E H satisfying {{\u03c7 G (u), \u03c7 G (v)}} = {{\u03c7 H (u \u2032 ), \u03c7 H (v \u2032", "formula_coordinates": [32.0, 108.0, 257.6, 259.22, 11.23]}, {"formula_id": "formula_101", "formula_text": "C.4.1 THE CASE OF \u03c7 G (u) \u0338 = \u03c7 G (v) FOR CONNECTED GRAPHS", "formula_coordinates": [32.0, 108.25, 354.81, 269.78, 9.65]}, {"formula_id": "formula_102", "formula_text": "G C = (C, E G C ) where E G C = {{{\u03c7 G (w), \u03c7 G (x)}} : {w, x} \u2208 E G }.", "formula_coordinates": [32.0, 108.0, 409.48, 396.0, 22.18]}, {"formula_id": "formula_103", "formula_text": "Lemma C.27. Let S = \u03c7 \u22121 G (\u03c7 G (u)) \u222a \u03c7 \u22121 G (\u03c7 G (v)) be the set containing vertices with color \u03c7 G (u) or \u03c7 G (v). Then either S \u2229 S u = {u} or S \u2229 S v = {v}.", "formula_coordinates": [32.0, 108.0, 445.8, 396.0, 22.83]}, {"formula_id": "formula_104", "formula_text": "\u03c7 \u22121 G (\u03c7 G (u)) \u2229 S v \u0338 = \u2205 and \u03c7 \u22121 G (\u03c7 G (v)) \u2229 S u \u0338 = \u2205.", "formula_coordinates": [32.0, 108.0, 493.62, 201.46, 13.31]}, {"formula_id": "formula_105", "formula_text": "\u03c7 \u22121 G (\u03c7 G (u)) \u2229 S v = \u2205, then (\u03c7 \u22121 G (\u03c7 G (v)) \u2229 S v )\\{v} \u0338 = \u2205 (because |S \u2229 S v | > 1), and thus there exists v \u2032 \u2208 S v , v \u2032 \u0338 = v such that \u03c7 G (v \u2032 ) = \u03c7 G (v). Note that v \u2032 must connect to a node u \u2032 with \u03c7 G (u \u2032 ) = \u03c7 G (u). Since {u, v} is a cut edge in G, u \u2032 \u2208 S v . Therefore, \u03c7 \u22121 G (\u03c7 G (u)) \u2229 S v \u0338 = \u2205, yielding a contradiction.", "formula_coordinates": [32.0, 108.0, 506.3, 396.0, 45.34]}, {"formula_id": "formula_106", "formula_text": "(i) (\u03c7 \u22121 G (\u03c7 G (u)) \u2229 S u )\\{u} \u0338 = \u2205; (ii) (\u03c7 \u22121 G (\u03c7 G (v)) \u2229 S v )\\{v} \u0338 = \u2205. Based on the above paragraph, there exists v \u2032 \u2208 S u satisfying \u03c7 G (v \u2032 ) = \u03c7 G (v). Note that v \u2032 must connect to a node with color \u03c7 G (u). If condition (i) does not hold, i.e. \u03c7 \u22121 G (\u03c7 G (u)) \u2229 S u = {u}, then v \u2032 must connect to u. This means |N G (u) \u2229 \u03c7 \u22121 G (\u03c7 G (v))| \u2265 2. Again using \u03c7 \u22121 G (\u03c7 G (u)) \u2229 S v \u0338 = \u2205 (the above paragraph), we can pick such a node u \u2032 \u2208 \u03c7 \u22121 G (\u03c7 G (u)) \u2229 S v . By the WL-condition (Proposition C.4), |N G (u \u2032 ) \u2229 \u03c7 \u22121 G (\u03c7 G (v))| \u2265 2, which implies |S v \u2229 \u03c7 \u22121 G (\u03c7 G (v))| \u2265 2. Thus (\u03c7 \u22121 G (\u03c7 G (v)) \u2229 S v )\\{v} \u0338 = \u2205 holds,", "formula_coordinates": [32.0, 108.0, 559.62, 402.94, 93.4]}, {"formula_id": "formula_107", "formula_text": "\u03c7 \u22121 G (\u03c7 G (u)) \u2229 S v \u0338 = \u2205 and (\u03c7 \u22121 G (\u03c7 G (u)) \u2229 S u )\\{u} \u0338 = \u2205.", "formula_coordinates": [32.0, 108.0, 669.74, 240.12, 13.3]}, {"formula_id": "formula_108", "formula_text": "\u2022\u0169 \u2208 S u . Then by picking a node x \u2208 S v \u2229 \u03c7 \u22121 G (\u03c7 G (u)), it follows that dis G (x,\u0169) = dis G (x, v) + dis G (u,\u0169) + 1 > dis G (u,\u0169).", "formula_coordinates": [32.0, 129.42, 709.88, 374.58, 22.83]}, {"formula_id": "formula_109", "formula_text": "x \u2208 (S u \u2229 \u03c7 \u22121 G (\u03c7 G (u)))\\{u}, it follows that dis G (x,\u0169) \u2265 dis G (x, u) + dis G (u,\u0169) > dis G (u,\u0169).", "formula_coordinates": [33.0, 137.89, 273.43, 366.11, 22.83]}, {"formula_id": "formula_110", "formula_text": "w\u2208\u03c7 \u22121 G (\u03c7 G (u)) dis G (u, w) = dis G (u,\u0169) < dis G (x,\u0169) \u2264 max w\u2208\u03c7 \u22121 G (\u03c7 G (u)) dis G (x, w).", "formula_coordinates": [33.0, 142.79, 322.83, 326.42, 18.34]}, {"formula_id": "formula_111", "formula_text": "\u03c7 \u22121 G (\u03c7 G (u)) \u2229 S u = {u} and \u03c7 \u22121 G (\u03c7 G (v)) \u2229 S u = \u2205.", "formula_coordinates": [33.0, 108.0, 387.57, 215.31, 13.31]}, {"formula_id": "formula_112", "formula_text": "Lemma C.28. For any u 1 , u 2 \u2208 \u03c7 \u22121 G (\u03c7 G (u)), u 1 \u0338 = u 2 , any path from u 1 to u 2 goes through a node v \u2032 \u2208 \u03c7 \u22121 G (\u03c7 G (v)). Proof. Note that \u03c7 \u22121 G (\u03c7 G (u)) \u2229 S u = {u}. If |\u03c7 \u22121 G (\u03c7 G (u)) \u2229 S v | \u2264 1, the conclusion is clear since any path from u 1 to u 2 goes through v. Now suppose |\u03c7 \u22121 G (\u03c7 G (u)) \u2229 S v | > 1 and the lemma does not hold. Then there exist two different nodes u \u2032 1 , u \u2032 2 \u2208 \u03c7 \u22121 G (\u03c7 G (u)", "formula_coordinates": [33.0, 108.0, 404.91, 396.0, 81.38]}, {"formula_id": "formula_113", "formula_text": "1 | \u2264 |P 2 | \u2264 |P 1 | + 1 and |P 1 | + |P 2 | = |P |. Note that |P | \u2265 2 since {u 1 , u 2 } / \u2208 E G (otherwise u cannot have the same color as u 1 because \u03c7 \u22121 G (u) \u2229 S u = {u}). Therefore, w \u0338 = u 1 and w \u0338 = u 2 . Also note that \u03c7 G (w) \u0338 = \u03c7 G (u) since |P | is minimal. Since SPD-WL satisfies the WL-condition (Proposition C.4), there is a path (not necessarily simple) from u to some w \u2032 \u2208 \u03c7 \u22121 G (\u03c7 G (w)) of length |P 1 | without going through nodes in the set \u03c7 \u22121 G (\u03c7 G (v)", "formula_coordinates": [33.0, 108.0, 509.81, 396.0, 56.2]}, {"formula_id": "formula_114", "formula_text": "w \u2032 ) = |P 1 |. First, we obviously have dis G (u, w \u2032 ) \u2264 |P 1 |. Moreover, since w \u2032 , u \u2208 S u and \u03c7 \u22121 G (\u03c7 G (v)) \u2229 S u = \u2205 (Lemma C.27", "formula_coordinates": [33.0, 108.0, 581.25, 396.0, 24.9]}, {"formula_id": "formula_115", "formula_text": "3 \u2208 \u03c7 \u22121 G (\u03c7 G (u)) of length |P 3 | = dis G (u, w \u2032 ) without going through nodes in the set \u03c7 \u22121 G (\u03c7 G (v)", "formula_coordinates": [33.0, 108.0, 618.2, 396.0, 25.99]}, {"formula_id": "formula_116", "formula_text": "\u2022 If u 3 = u 1 , by the minimal length of P we have |P 1 | \u2264 |P 3 | = dis G (u, w \u2032 ) \u2264 |P 1 | and thus dis G (u, w \u2032 ) = |P 1 |.", "formula_coordinates": [33.0, 129.42, 659.43, 374.58, 22.18]}, {"formula_id": "formula_117", "formula_text": "1 | + |P 3 | from u 1 to u 3 without going through nodes in \u03c7 \u22121 G (\u03c7 G (v)). Since P has the minimal length, |P 1 | + |P 2 | \u2264 |P 1 | + |P 3 |. Therefore, |P 2 | \u2264 |P 3 | = dis G (u, w \u2032 ) and thus by definition |P 1 | \u2264 |P 2 | \u2264 dis G (u, w \u2032 ) \u2264 |P 1 |. Therefore, |P 1 | = |P 2 | = dis G (u, w \u2032 ). Now define the set D(x) := {u \u2032 : u \u2032 \u2208 \u03c7 \u22121 G (\u03c7 G (u)), dis G (x, u \u2032 ) \u2264 |P 2 |}.", "formula_coordinates": [33.0, 137.89, 688.9, 366.11, 43.81]}, {"formula_id": "formula_118", "formula_text": "u \u2032 \u2208 \u03c7 \u22121 G (\u03c7 G (u)), u \u2032 \u0338 = u, we have u \u2032 \u2208 S v and thus dis G (w \u2032 , u \u2032 ) > dis G (w \u2032 , v) = dis G (w \u2032 , u) + 1 = |P 1 | + 1 \u2265 |P 2 |.", "formula_coordinates": [34.0, 108.0, 106.0, 331.16, 30.11]}, {"formula_id": "formula_119", "formula_text": "Lemma C.29. G C has a cut edge {{\u03c7 G (u), \u03c7 G (v)}}. Proof. Suppose {{\u03c7 G (u), \u03c7 G (v)}} is not a cut edge of G C . Then there is a simple cycle (c 1 , \u2022 \u2022 \u2022 , c m ) where c 1 = \u03c7 G (u), c m = \u03c7 G (v)", "formula_coordinates": [34.0, 108.0, 205.01, 396.0, 47.07]}, {"formula_id": "formula_120", "formula_text": "i ) = c i such that {w i , w i+1 } \u2208 E G , i \u2208 [m \u2212 1]. Note that w i \u0338 = u for i = {2, \u2022 \u2022 \u2022 , m} and w 2 \u0338 = v because (c 1 , \u2022 \u2022 \u2022 , c m ) is a simple path. Therefore, w i \u2208 S u for all i \u2208 [m]. However, it contradicts |S \u2229 S u | = 1 (Lemma C.27) since \u03c7 G (w m ) = \u03c7 G (v).", "formula_coordinates": [34.0, 108.0, 264.35, 396.0, 31.57]}, {"formula_id": "formula_121", "formula_text": "Corollary C.30. For all u \u2032 \u2208 \u03c7 \u22121 G (\u03c7 G (u)) and v \u2032 \u2208 \u03c7 \u22121 G (\u03c7 G (v)), if {u \u2032 , v \u2032 } \u2208 E G , then it is a cut edge of G. Proof. If {u \u2032 , v \u2032 } is not a cut edge, there is a simple cycle going through {u \u2032 , v \u2032 }. Denote it as (w 1 , \u2022 \u2022 \u2022 , w m ) where w 1 = u \u2032 , w m = v \u2032 , m > 2. By Lemma C.27, w 2 / \u2208 \u03c7 G (v), otherwise u \u2032 will connect to at least two different nodes w 2 , w m \u2208 \u03c7 \u22121 G (\u03c7 G (v)", "formula_coordinates": [34.0, 108.0, 324.03, 396.0, 72.35]}, {"formula_id": "formula_122", "formula_text": "w i \u2208 \u03c7 \u22121 G (\u03c7 G (u)) (i \u2208 {2, \u2022 \u2022 \u2022 , j}) that does not go through nodes in the set \u03c7 \u22121 G (\u03c7 G (v)), a contradiction). Therefore, (\u03c7 G (w 1 ), \u2022 \u2022 \u2022 , \u03c7 G (w j )) is a path of length \u2265 2 in G C from \u03c7 G (u) to \u03c7 G (v) (not necessarily simple), without going through the edge {{\u03c7 G (u), \u03c7 G (v)}}. This contradicts Lemma C.29, which says that {{\u03c7 G (u), \u03c7 G (v)}} is a cut edge in G C . Based on Lemma C.29, the cut edge {{\u03c7 G (u), \u03c7 G (v)}} partitions the vertices C of the color graph G C into two classes. Denote them as {C u , C v } where \u03c7 G (u) \u2208 C u and \u03c7 G (v) \u2208 C v .", "formula_coordinates": [34.0, 108.0, 417.6, 396.0, 94.62]}, {"formula_id": "formula_123", "formula_text": "{u \u2032 , v \u2032 }, u \u2032 \u2208 \u03c7 \u22121 G (\u03c7 G (u)), v \u2032 \u2208 \u03c7 \u22121 G (\u03c7 G (v)), that partitions V into two classes S u \u2032 \u222a S v \u2032 , u \u2032 , w \u2208 S u \u2032 , v \u2032 \u2208 S v \u2032 , such that \u03c7 \u22121 G (\u03c7 G (u \u2032 )) \u222a S u \u2032 = {u \u2032 } and \u03c7 \u22121 G (\u03c7 G (v \u2032 )) \u222a S u \u2032 = \u2205. Remark C.", "formula_coordinates": [34.0, 108.0, 527.05, 396.0, 50.48]}, {"formula_id": "formula_124", "formula_text": "v \u2032 = v. Then \u03c7 \u22121 G (\u03c7 G (u \u2032 )) \u222a S u \u2032 = {u \u2032 } and \u03c7 \u22121 G (\u03c7 G (v \u2032 )) \u222a S u \u2032 = \u2205", "formula_coordinates": [34.0, 108.0, 577.38, 396.0, 22.83]}, {"formula_id": "formula_125", "formula_text": "c i = \u03c7 G (y i ), i \u2208 [m]. Then (c 1 , \u2022 \u2022 \u2022 , c m ) is a path (not necessarily simple) in the color graph G C . Now pick the index j = max{j \u2208 [m] : c j \u2208 C v } (which is well-defined because c 1 \u2208 C v ). It follows that j < m (since y m \u2208 C u ), c j = \u03c7 G (v) and c j+1 = \u03c7 G (u) (because {{\u03c7 G (u), \u03c7 G (v)", "formula_coordinates": [35.0, 108.0, 258.88, 396.0, 33.14]}, {"formula_id": "formula_126", "formula_text": "j ) = \u03c7 G (v \u2032 ) = \u03c7 G (v).", "formula_coordinates": [35.0, 412.34, 320.92, 91.66, 11.23]}, {"formula_id": "formula_127", "formula_text": "j < m \u2212 1. Then y j+1 \u0338 = u \u2032 because the path (y 1 , \u2022 \u2022 \u2022 , y m ) is simple. Howover, one has \u03c7 G (y i ) \u0338 = \u03c7 G (v) for all i \u2208 {j +1, \u2022 \u2022 \u2022", "formula_coordinates": [35.0, 137.89, 348.81, 366.11, 22.18]}, {"formula_id": "formula_128", "formula_text": "x \u2208 S u \u2032 , \u03c7 G (x) \u2208 C u . Therefore, \u03c7 \u22121 G (\u03c7 G (v \u2032 )) \u222a S u \u2032 = \u2205. We finally prove that \u03c7 \u22121 G (\u03c7 G (u)) \u222a S u \u2032 = {u \u2032 }. If not, pick u \u2032\u2032 \u2208 \u03c7 \u22121 G (\u03c7 G (u)", "formula_coordinates": [35.0, 108.0, 377.34, 384.83, 31.96]}, {"formula_id": "formula_129", "formula_text": "x 1 , x 2 in Q, dis H (x 1 , x 2 ) = dis Q (x 1 , x 2 ).", "formula_coordinates": [35.0, 240.44, 492.26, 169.92, 9.65]}, {"formula_id": "formula_130", "formula_text": "h(c) = \u03c7 H (u) if dis H C (c, \u03c7 H (u)) < dis H C (c, \u03c7 H (v)), \u03c7 H (v) if dis H C (c, \u03c7 H (u)) > dis H C (c, \u03c7 H (v)).(11)", "formula_coordinates": [36.0, 181.7, 278.88, 322.3, 21.06]}, {"formula_id": "formula_131", "formula_text": "H C (c, \u03c7 H (u)) = dis H C (c, \u03c7 H (v)) because {{\u03c7 H (u), \u03c7 H (v)}} is a cut edge of H C .", "formula_coordinates": [36.0, 108.0, 308.29, 396.0, 19.92]}, {"formula_id": "formula_132", "formula_text": "H (v)) \u2208 C v , there is a minimum index j \u2208 [m \u2212 1] such that h(\u03c7 H (w j )) \u2208 C", "formula_coordinates": [36.0, 108.0, 358.1, 396.0, 20.61]}, {"formula_id": "formula_133", "formula_text": "u \u2032 1 , u \u2032 2 with color \u03c7 G (u \u2032 1 ) = \u03c7 G (u \u2032 2 ) = \u03c7 G (u), such that dis G (w \u2032 , u \u2032 1 ) = dis H (w k , w 1 ) and dis G (w \u2032 , u \u2032 2 ) = dis H (w k , w j ). In particular, |dis G (w \u2032 , u \u2032 1 ) \u2212 dis G (w \u2032 , u \u2032 2 )| \u2264 1.", "formula_coordinates": [36.0, 108.0, 461.13, 396.0, 34.12]}, {"formula_id": "formula_134", "formula_text": "\u03c7 \u22121 H (\u03c7 H (v)), so \u03c7 H (w k ) \u2208 C u , namely \u03c7 G (w \u2032 ) \u2208 C u . By Corollary C.31, there is a cut edge {u \u2032 w , v \u2032 w } that partitions G into two vertex sets S u \u2032 w , S v \u2032 w , with w \u2032 , u \u2032 w \u2208 S u \u2032 w , v \u2032 w \u2208 S v \u2032 w . Note that u \u2032 w \u0338 = u \u2032", "formula_coordinates": [36.0, 108.0, 494.65, 396.0, 44.85]}, {"formula_id": "formula_135", "formula_text": "\u2032 , u \u2032 1 ) \u2212 dis G (w \u2032 , u \u2032", "formula_coordinates": [36.0, 108.0, 540.14, 396.0, 22.18]}, {"formula_id": "formula_136", "formula_text": "\u2032 , u \u2032 1 ) > dis G (w \u2032 , u \u2032 w ) and dis G (w \u2032 , u \u2032 2 ) > dis G (w \u2032 , u \u2032 w ).", "formula_coordinates": [36.0, 108.0, 551.1, 396.0, 23.16]}, {"formula_id": "formula_137", "formula_text": "v w \u2208 \u03c7 \u22121 H (\u03c7 H (v)) satisfying dis H (v w , w k ) = dis G (v \u2032 w , w \u2032 ).", "formula_coordinates": [36.0, 148.61, 589.31, 259.54, 13.31]}, {"formula_id": "formula_138", "formula_text": "dropmin({{dis G (w \u2032 , u G ) : u G \u2208 \u03c7 \u22121 G (\u03c7 G (u))}}) = dropmin({{dis G (w \u2032 , v \u2032 w ) + dis G (v \u2032 w , u G ) : u G \u2208 \u03c7 \u22121 G (\u03c7 G (u))}}) (by Corollary C.31) = dropmin({{dis H (w k , v w ) + dis H (v w , u H ) : u H \u2208 \u03c7 \u22121 H (\u03c7 H (u))}}) and also dropmin({{dis G (w \u2032 , u G ) : u G \u2208 \u03c7 \u22121 G (\u03c7 G (u))) = dropmin({{dis H (w k , u H ) : u H \u2208 \u03c7 \u22121 H (\u03c7 H (u)", "formula_coordinates": [36.0, 108.0, 627.88, 396.0, 78.66]}, {"formula_id": "formula_139", "formula_text": "w 1 \u2208 f \u22121 G (u, c 1 ) and w 2 \u2208 f \u22121 G (u, c 2 ) such that {w 1 , w 2 } \u2208 E G . By Lemma C.36, either \u03c7 G (w 1 ) \u0338 = \u03c7 G (u) or \u03c7 G (w 2 ) \u0338 = \u03c7 G (u). Without loss of generality, assume c 1 \u0338 = \u03c7 G (u). By Lemma C.35, there exists x 1 \u2208 f \u22121 G (v, c 1 ). Since \u03c7 G (x 1 ) = \u03c7 G (w 1 ), x 1 must also connect to a node x 2 with \u03c7 G (x 2 ) = c 2 . The edge {x 1 , x 2 } \u0338 = {u, v} because \u03c7 G (x 1 ) = c 1 \u0338 = \u03c7 G (u). Therefore, f (x 2 ) = (v, c 2 ), namely {{(v, c 1 ), (v, c 2 )}} \u2208 E A G .", "formula_coordinates": [38.0, 108.0, 147.38, 396.0, 68.52]}, {"formula_id": "formula_140", "formula_text": "w \u2032 \u2208 f \u22121 G (\u03be \u2032 ) such that dis G (w, w \u2032 ) = dis G A (\u03be, \u03be \u2032 ).", "formula_coordinates": [38.0, 137.89, 279.53, 366.11, 23.28]}, {"formula_id": "formula_141", "formula_text": "w \u2032 \u2208 f \u22121 G (\u03be \u2032 ) such that dis G (w, w \u2032 ) \u2264 dis G A (\u03be, \u03be \u2032 ),", "formula_coordinates": [38.0, 129.82, 374.01, 208.35, 13.3]}, {"formula_id": "formula_142", "formula_text": "x \u2208 f \u22121 G (\u03be) and x \u2032 \u2208 f \u22121 G (\u03be \u2032 ), such that {x, x \u2032 } \u2208 E G . Note that h G (x) = h G (x \u2032 ) because {x, x \u2032 } \u0338 = {u, v}. Since \u03c7 G (x) = \u03c7 G (w), there exists w \u2032 \u2208 \u03c7 \u22121 G (\u03c7 G (x \u2032 )", "formula_coordinates": [38.0, 108.0, 414.15, 396.0, 36.51]}, {"formula_id": "formula_143", "formula_text": "\u03be \u2032 }} = {{(u, \u03c7 G (u)), (v, \u03c7 G (v))). Therefore, h G (w \u2032 ) = h G (w) = h G (x) = h G (x \u2032 ) and thus f G (w \u2032 ) = f G (x \u2032 ), namely w \u2032 \u2208 f \u22121 G (\u03be \u2032 ).", "formula_coordinates": [38.0, 108.0, 448.96, 396.0, 24.9]}, {"formula_id": "formula_144", "formula_text": "\u2022 For any w, w \u2032 \u2208 V satisfying \u03c7 G (w) = \u03c7 G (w \u2032 ) and h G (w) = h G (w \u2032 ) (i.e. f G (w) = f G (w \u2032 )), dis G (u, w) = dis G (u, w \u2032 ) and dis G (v, w) = dis G (v, w \u2032 ); \u2022 For any w, w \u2032 \u2208 V satisfying \u03c7 G (w) = \u03c7 G (w \u2032 ) and h G (w) \u0338 = h G (w \u2032 ), dis G (u, w) = dis G (v, w \u2032 ) and dis G (v, w) = dis G (u, w \u2032 ).", "formula_coordinates": [38.0, 129.42, 518.58, 374.58, 50.08]}, {"formula_id": "formula_145", "formula_text": "u 1 , u 2 \u2208 f \u22121 G (f G (u)) such that dis G (u 1 , w) = dis G A (f G (u), f G (w)) and dis G (u 2 , w \u2032 ) = dis G A (f G (u), f G (w \u2032 )). Therefore, dis G (u 1 , w) = dis G (u 2 , w \u2032 ).", "formula_coordinates": [38.0, 108.0, 583.35, 396.0, 33.79]}, {"formula_id": "formula_146", "formula_text": "(w) = h G (w \u2032 ), it must be u 1 = u 2 = u, namely dis G (u, w) = dis G (u, w \u2032 ). The proof of dis G (v, w) = dis G (v \u2032 , w \u2032 ) is similar.", "formula_coordinates": [38.0, 108.0, 605.92, 396.0, 32.45]}, {"formula_id": "formula_147", "formula_text": "x \u2208 \u03c7 \u22121 G (c 1 ), h G (x) \u0338 = h G (w), we have dis G (w, x) = dis G (w, h(w)) + 1 + dis G (h(x), x),", "formula_coordinates": [40.0, 181.99, 106.36, 226.5, 26.56]}, {"formula_id": "formula_148", "formula_text": "v \u2208 V, \u03c7 t+1 G (v) = hash {{hash(d G (v, u), \u03c7 t G (u)) : u \u2208 V}} . Therefore, \u03c7 t+1 H (v) \u0338 = \u03c7 t+1 G (u) for all u \u2208 V G and v \u2208 V H , namely {{\u03c7 t+1 G(", "formula_coordinates": [40.0, 108.0, 355.91, 309.12, 59.14]}, {"formula_id": "formula_149", "formula_text": "x 1 , x 2 . Obviously, |S G | = |S H | due to the facts that dis G (w 1 , y) = \u221e \u0338 = dis G (w 1 , y \u2032 ) for all y / \u2208 S G , y \u2032 \u2208 S G", "formula_coordinates": [40.0, 108.0, 518.95, 396.0, 20.61]}, {"formula_id": "formula_150", "formula_text": "\u2208 S H , \u03c7 G (u G ) = \u03c7 H (u H ) implies that \u03c7 G[S G ] (u G ) = \u03c7 H[S H ] (u H ). Therefore, {w 1 , w 2 } is a cut edge of G[S G ] if and only if {x 1 , x 2 } is a cut edge of H[S H ]. By the dinifition of S G and S H , {w 1 , w 2 } is a cut edge of G if and only if {x 1 , x 2 } is a cut edge of H.", "formula_coordinates": [40.0, 108.0, 562.79, 396.0, 43.58]}, {"formula_id": "formula_151", "formula_text": "C E := {{{\u03c7 G (u), \u03c7 G (v)} : {u, v} \u2208 E G is a cut edge}} \u2022 If v", "formula_coordinates": [40.0, 196.75, 720.98, 218.5, 11.72]}, {"formula_id": "formula_152", "formula_text": "| = h G (u, v) + h G (v, w). We can similarly prove that h G (w, u) < h G (w, v) + h G (v, u).", "formula_coordinates": [42.0, 137.89, 320.99, 267.94, 56.86]}, {"formula_id": "formula_153", "formula_text": "G (u, w) = h G (u, v) + h G (v, w) and h G (w, u) = h G (w, v) + h G (v, u).", "formula_coordinates": [42.0, 143.63, 407.05, 287.9, 9.65]}, {"formula_id": "formula_154", "formula_text": "G (u) \u0338 = \u03c7 1 H (v). Namely, \u03c7 G (u) \u0338 = \u03c7 H (v)", "formula_coordinates": [50.0, 134.01, 95.48, 175.89, 12.47]}, {"formula_id": "formula_155", "formula_text": "dis R G (u, v) = r dis G (u,v) where the sequence {r d } D(G)", "formula_coordinates": [50.0, 108.0, 214.43, 396.0, 26.88]}, {"formula_id": "formula_156", "formula_text": "r d = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 0 if d = 0, r d\u22121 + 2 nk d\u22121 b d\u22121 D(G) i=d k i if d \u2208 [D(G)],(20)", "formula_coordinates": [50.0, 195.89, 250.74, 308.11, 43.41]}, {"formula_id": "formula_157", "formula_text": "\u03b9(G) = {b 0 , \u2022 \u2022 \u2022 , b D(G)\u22121 ; c 1 , \u2022 \u2022 \u2022 , c D(G) } is the intersection array of G and \u03ba(G) = (k 1 , \u2022 \u2022 \u2022 , k D(G)", "formula_coordinates": [50.0, 108.0, 303.71, 396.0, 21.97]}, {"formula_id": "formula_158", "formula_text": "R = 1 2 diag(c11 \u22a4 \u2212 R)11 \u22a4 + 11 \u22a4 diag(c11 \u22a4 \u2212 R) \u2212 c11 \u22a4 + R = R", "formula_coordinates": [50.0, 151.42, 405.25, 309.15, 22.31]}, {"formula_id": "formula_159", "formula_text": "L + 1 n 11 \u22a4 c11 \u22a4 \u2212 R = c \u2212 c 1 n 11 \u22a4 \u2212 L R.", "formula_coordinates": [50.0, 203.22, 505.25, 212.89, 22.31]}, {"formula_id": "formula_160", "formula_text": "L R = c11 \u22a4 \u2212 2I for some c \u2208 R. Let us calculate each element [L R] uv (u, v \u2208 V). We have [L R] uv = k 1 r dis G (u,v) \u2212 D(G) d=0 r d |N G (u) \u2229 N d G (v)|.(21)", "formula_coordinates": [50.0, 108.0, 538.87, 396.0, 65.88]}, {"formula_id": "formula_161", "formula_text": "D(G) d=1 r d |N G (u) \u2229 N d G (v)| = r 1 k 1 = 2(n \u2212 1) n by using b 0 = k 1 and k 0 = 0. Thus [L R] uv = \u2212 2(n\u22121) n . \u2022 u \u0338 = v and dis G (u, v) < D(G). Denote j = dis G (", "formula_coordinates": [50.0, 129.42, 651.61, 283.4, 70.14]}, {"formula_id": "formula_162", "formula_text": "N G (u) \u2229 N d G (v) \u0338 = \u2205 only when d \u2208 {j \u2212 1, j, j + 1},", "formula_coordinates": [50.0, 137.89, 721.48, 214.37, 12.48]}, {"formula_id": "formula_163", "formula_text": "{{(\u03c7 t G (u, z), \u03c7 t G (z, v)) : z \u2208 V G }} = {{(\u03c7 t H (w, z), \u03c7 t H (z, x)) : z \u2208 V H }}.(24)", "formula_coordinates": [52.0, 159.41, 104.05, 344.59, 12.69]}, {"formula_id": "formula_164", "formula_text": "{{(dis G (u, z), dis G (z, v)) : z \u2208 V G }} = {{(dis H (w, z), dis H (z, x)) : z \u2208 V H }}.", "formula_coordinates": [52.0, 147.42, 148.32, 317.17, 9.65]}], "doi": ""}