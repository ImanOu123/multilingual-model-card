{"title": "Causal Conceptions of Fairness and their Consequences", "authors": "Hamed Nilforoshan; Johann Gaebler; Ravi Shroff; Sharad Goel", "pub_date": "", "abstract": "Recent work highlights the role of causality in designing equitable decision-making algorithms. It is not immediately clear, however, how existing causal conceptions of fairness relate to one another, or what the consequences are of using these definitions as design principles. Here, we first assemble and categorize popular causal definitions of algorithmic fairness into two broad families: (1) those that constrain the effects of decisions on counterfactual disparities; and (2) those that constrain the effects of legally protected characteristics, like race and gender, on decisions. We then show, analytically and empirically, that both families of definitions almost always-in a measure theoretic sense-result in strongly Pareto dominated decision policies, meaning there is an alternative, unconstrained policy favored by every stakeholder with preferences drawn from a large, natural class. For example, in the case of college admissions decisions, policies constrained to satisfy causal fairness definitions would be disfavored by every stakeholder with neutral or positive preferences for both academic preparedness and diversity. Indeed, under a prominent definition of causal fairness, we prove the resulting policies require admitting all students with the same probability, regardless of academic qualifications or group membership. Our results highlight formal limitations and potential adverse consequences of common mathematical notions of causal fairness.", "sections": [{"heading": "Introduction", "text": "Imagine designing an algorithm to guide decisions for college admissions. To help ensure algorithms such as this are broadly equitable, a plethora of formal fairness criteria have been proposed in the machine learning community (Berk et al., 2021;Chouldechova, 2017;Chouldechova & Roth, 2020;Cleary, 1968;Corbett-Davies et al., 2017;Darlington, 1971;Dwork et al., 2012;Hardt et al., 2016;Kleinberg et al., 2017;Woodworth et al., 2017;Zafar et al., 2017a;b). For example, under the principle that fair algorithms should have comparable performance across demographic groups (Hardt et al., 2016), one might check that among applicants who were ultimately academically \"successful\" (e.g., who eventually earned a college degree, either at the institution in question or elsewhere), the algorithm would recommend admission for an equal proportion of candidates across race groups. Alternatively, following the principle that decisions should be agnostic to legally protected attributes like race and gender (cf. Corbett-Davies & Goel, 2018;Dwork et al., 2012), one might mandate that these features not be provided to the algorithm.\nRecent scholarship has argued for extending equitable algorithm design by adopting a causal perspective, leading to myriad additional formal criteria for fairness (Carey & Wu, 2022;Chiappa, 2019;Coston et al., 2020;Galhotra et al., 2022;Imai & Jiang, 2020;Imai et al., 2020;Kilbertus et al., 2017;Kusner et al., 2017;Loftus et al., 2018;Mhasawade & Chunara, 2021;Nabi & Shpitser, 2018;Wang et al., 2019;Wu et al., 2019;Zhang & Bareinboim, 2018;Zhang et al., 2017). Less attention, however, has been given to understanding the potential downstream consequences of using these causal definitions of fairness as algorithmic design principles, leaving an important gap to fill if these criteria are to responsibly inform policy choices.\nHere we synthesize and critically examine the statistical properties and concomitant consequences of popular causal approaches to fairness. We begin, in Section 2, by proposing a two-part taxonomy for causal conceptions of fairness that mirrors the illustrative, non-causal fairness principles described above. Our first category of definitions encompasses those that consider the effect of decisions on counterfactual disparities. For example, recognizing the causal effect of college admission on later success, one might demand arXiv:2207.05302v1 [cs.LG] 12 Jul 2022 that among applicants who would be academically successful if admitted to a particular college, the algorithm would recommend admission for an equal proportion of candidates across race groups. The second category of definitions encompasses those that seek to limit both the direct and indirect effects of one's group membership on decisions. For example, because one's race might impact earlier educational opportunities, and hence test scores, one might require that admissions decisions are robust to the effect of race along such causal paths.\nWe show, in Section 3, that when the distribution of causal effects is known (or can be estimated), one can efficiently compute utility-maximizing decision policies constrained to satisfy each of the causal fairness criteria we consider. However, for natural families of utility functions-for example, those that prefer both higher degree attainment and more student-body diversity-we prove in Section 4 that causal fairness constraints almost always lead to strongly Pareto dominated decision policies. To establish this result, we use the theory of prevalence (Anderson & Zame, 2001;Christensen, 1972;Hunt et al., 1992;Ott & Yorke, 2005), which extends the notion of full-measure sets to infinite-dimensional vector spaces. In particular, in our running college admissions example, adhering to any of the common conceptions of causal fairness would simultaneously result in a lower number of degrees attained and lower student-body diversity, relative to what one could achieve by explicitly tailoring admissions policies to achieve desired outcomes. In fact, under one prominent definition of causal fairness, we prove that the induced policies require simply admitting all applicants with equal probability, irrespective of one's academic qualifications or group membership. These results, we hope, elucidate the structureand limitations-of current causal approaches to equitable decision making.", "publication_ref": ["b3", "b13", "b14", "b16", "b18", "b20", "b21", "b20", "b17", "b21", "b9", "b19", "b0", "b15"], "figure_ref": [], "table_ref": []}, {"heading": "Causal Approaches to Fair Decision Making", "text": "We describe two broad classes of causal notions of fairness:\n(1) those that consider outcomes when decisions are counterfactually altered; and (2) those that consider outcomes when protected attributes are counterfactually altered. We illustrate these definitions in the context of a running example of college admissions decisions.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Problem Setup", "text": "Consider a population of individuals with observed covariates X, drawn i.i.d from a set X \u2286 R n with distribution D X . Further suppose that A \u2208 A describes one or more discrete protected attributes, such as race or gender, which can be derived from X (i.e., A = \u03b1(X) for some measurable function \u03b1). Each individual is subject to a binary decision D \u2208 {0, 1}, determined by a (randomized) rule d(x) \u2208 [0, 1], where d(x) = Pr(D = 1 | X = x) is the probability of receiving a positive decision. 1 Given a budget b with 0 < b < 1, we require the decision rule to satisfy E[D] \u2264 b, limiting the expected proportion of positive decisions.\nIn our running example, we imagine a population of applicants to a particular college, where d denotes an admissions rule and D indicates a binary admissions decision. To simplify our exposition, we assume all admitted students attend the school. In our setting, the covariates X consist of an applicant's test score and race A \u2208 {a 0 , a 1 }, where, for notational convenience, we consider two race groups. The budget b bounds the expected proportion of admitted applicants.\nAssuming there is no interference between units (Imbens & Rubin, 2015), we write Y (1) and Y (0) to denote potential outcomes of interest under each of the two possible binary decisions, where Y = Y (D) is the realized outcome. We assume that Y (1) and Y (0) are drawn from a (possibly infinite) set Y \u2286 R, where |Y| > 1. In our admissions example, Y is a binary variable that indicates college graduation (i.e., degree attainment), with Y (1) and Y (0) describing, respectively, whether an applicant would attain a college degree if admitted to or if rejected from the school we consider. Note that Y (0) is not necessarily zero, as a rejected applicant may attend-and graduate from-a different university.\nGiven this setup, our goal is to construct decision policies d that are broadly equitable, formalized in part by the causal notions of fairness described below. We focus on decisions that are made algorithmically, informed by historical data on applicants and subsequent outcomes.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Limiting the Effect of Decisions on Disparities", "text": "A popular class of non-causal fairness definitions requires that error rates (e.g., false positive and false negative rates) are equal across protected groups (Corbett-Davies & Goel, 2018;Hardt et al., 2016). Causal analogues of these definitions have recently been proposed (Coston et al., 2020;Imai & Jiang, 2020;Imai et al., 2020;Mishler et al., 2021), which require various conditional independence conditions to hold between the potential outcomes, protected attributes, and decisions. 2 Below we list three representative examples of this class of 1 That is, D = 1 U D \u2264d(X) , where UD is an independent uniform random variable. 2 In the literature on causal fairness, there is at times ambiguity between \"predictions\"\u0176 \u2208 {0, 1} of Y and \"decisions\" D \u2208 {0, 1}. Following past work (e.g., Corbett-Davies et al., 2017;Kusner et al., 2017;Wang et al., 2019), here we focus exclusively on decisions, with predictions implicitly impacting decisions but not explicitly appearing in our definitions. fairness definitions: counterfactual predictive parity (Coston et al., 2020), counterfactual equalized odds (Coston et al., 2020;Mishler et al., 2021), and conditional principal fairness (Imai & Jiang, 2020). 3 Definition 1. Counterfactual predictive parity holds when Y (1) \u22a5 \u22a5 A | D = 0.\n(1)\nIn our college admissions example, counterfactual predictive parity means that among rejected applicants, the proportion who would have attained a college degree, had they been accepted, is equal across race groups.\nDefinition 2. Counterfactual equalized odds holds when\nD \u22a5 \u22a5 A | Y (1).(2)\nIn our running example, counterfactual equalized odds is satisfied when two conditions hold: (1) among applicants who would graduate if admitted (i.e., Y (1) = 1), students are admitted at the same rate across race groups; and (2) among applicants who would not graduate if admitted (i.e., Y (1) = 0), students are again admitted at the same rate across race groups.\nDefinition 3. Conditional principal fairness holds when\nD \u22a5 \u22a5 A | Y (0), Y (1), W,(3)\nwhere, for a measurable function \u03c9 on X , W = \u03c9(X) describes a reduced set of the covariates X. When W is constant (or, equivalently, when we do not condition on W ), this condition is called principal fairness.\nIn our example, conditional principal fairness means that \"similar\" applicants-where similarity is defined by the potential outcomes and covariates W -are admitted at the same rate across race groups.", "publication_ref": ["b17", "b19", "b18", "b19", "b19"], "figure_ref": [], "table_ref": []}, {"heading": "Limiting the Effect of Attributes on Decisions", "text": "An alternative causal framework for understanding fairness considers the effects of protected attributes on decisions (Kilbertus et al., 2017;Kusner et al., 2017;Mhasawade & Chunara, 2021;Nabi & Shpitser, 2018;Wang et al., 2019;Wu et al., 2019;Zhang & Bareinboim, 2018;Zhang et al., 2017). This approach, which can be understood as codifying the legal notion of disparate treatment (Goel et al., 2017;Zafar et al., 2017a), considers a decision rule to be fair if, at a high level, decisions for individuals are the same in \"(a) the actual world and (b) a counterfactual world where the individual belonged to a different demographic group\" (Kusner et al., 2017). 4 In contrast to \"fairness through unawareness\"-in which race and other protected attributes are barred from being an explicit input to a decision rule (cf. Corbett-Davies & Goel, 2018;Dwork et al., 2012)-the causal versions of this idea consider both the direct and indirect effects of protected attributes on decisions. For example, even if decisions only directly depend on test scores, race may indirectly impact decisions through its effects on educational opportunities, which in turn influence test scores. This idea can be formalized by requiring that decisions remain the same in expectation even if one's protected characteristics are counterfactually altered, a condition known as counterfactual fairness (Kusner et al., 2017). Definition 4. Counterfactual fairness holds when\nE[D(a ) | X] = E[D | X].(4)\nwhere D(a ) denotes the decision when one's protected attributes are counterfactually altered to be any a \u2208 A.\nIn our running example, this means that for each group of observationally identical applicants (i.e., those with the same values of X, meaning identical race and test score), the proportion of students who are actually admitted is the same as the proportion who would be admitted if their race were counterfactually altered.\nCounterfactual fairness aims to limit all direct and indirect effects of protected traits on decisions. In a generalization of this criterion-termed path-specific fairness (Chiappa, 2019;Nabi & Shpitser, 2018;Wu et al., 2019;Zhang et al., 2017)-one allows protected traits to influence decisions along certain causal paths but not others. For example, one may wish to allow the direct consideration of race by an admissions committee to implement an affirmative action policy, while also guarding against any indirect influence of race on admissions decisions that may stem from cultural biases in standardized tests (Williams, 1983).\nThe formal definition of path-specific fairness requires specifying a causal DAG describing relationships between at-4 Conceptualizing a general causal effect of an immutable characteristic such as race or gender is rife with challenges, the greatest of which is expressed by the mantra, \"no causation without manipulation\" (Holland, 1986). In particular, analyzing race as a causal treatment requires one to specify what exactly is meant by \"changing an individual's race\" from, for example, white to Black (Gaebler et al., 2022;Hu & Kohler-Hausmann, 2020). Such difficulties can sometimes be addressed by considering a change in the perception of race by a decision maker (Greiner & Rubin, 2011)-for instance, by changing the name listed on an employment application (Bertrand & Mullainathan, 2004), or by masking an individual's appearance (Chohlas-Wood et al., 2021b;Goldin & Rouse, 2000;Grogger & Ridgeway, 2006;Pierson et al., 2020). A causal DAG illustrating a hypothetical process for college admissions. Under path-specific fairness, one may require, for example, that race does not affect decisions along the path highlighted in red. tributes (both observed covariates and latent variables), decisions, and outcomes. In our running example of college admissions, we imagine that each individual's observed covariates are the result of the process illustrated by the causal DAG in Figure 1. In this graph, an applicant's race A influences the educational opportunities E available to them prior to college; and educational opportunities in turn influence an applicant's level of college preparation, M , as well as their score on a standardized admissions test, T , such as the SAT. We assume the admissions committee only observes an applicant's race and test score so that X = (A, T ), and makes their decision D based on these attributes. Finally, whether or not an admitted student subsequently graduates (from any college), Y , is a function of both their preparation and whether they were admitted. 5 To define path-specific fairness, we start by defining, for the decision D, path-specific counterfactuals, a general concept in causal DAGs (cf. Pearl, 2001). Suppose G = (V, U, F) is a causal model with nodes V, exogenous variables U, and structural equations F that define the value at each node V j as a function of its parents \u2118(V j ) and its associated exogenous variable U j . (See, for example, Pearl (2009a) for further details on causal DAGs.) Let V 1 , . . . , V m be a topological ordering of the nodes, meaning that \u2118(V j ) \u2286 {V 1 , . . . , V j\u22121 } (i.e., the parents of each node appear in the ordering before the node itself). Let \u03a0 denote a collection of paths from node A to D. Now, for two possible values a and a for the variable A, the path-specific counterfactuals D \u03a0,a,a for the decision D are generated by traversing the list of nodes in topological order, propagating counterfactual values obtained by setting A = a along paths in \u03a0, and otherwise propagating values obtained by setting A = a. (In Algorithm 1 in the Appendix, we formally define pathspecific counterfactuals for an arbitrary node-or collection of nodes-in the DAG.)\nTo see this idea in action, we work out an illustrative example, computing path-specific counterfactuals for the decision D along the single path \u03a0 = {A \u2192 E \u2192 T \u2192 D} linking race to the admissions committee's decision through test score, highlighted in red in Figure 1. In the system of equations below, the first column corresponds to draws V * for each node V in the DAG, where we set A to a, and then propagate that value as usual. The second column corresponds to draws V * of path-specific counterfactuals, where we set A to a , and then propagate the counterfactuals only along the path A \u2192 E \u2192 T \u2192 D. In particular, the value for the test score T * is computed using the value of E (since the edge E \u2192 T is on the specified path) and the value of M * (since the edge M \u2192 T is not on the path).\nAs a result of this process, we obtain a draw D * from the distribution of D \u03a0,a,a .\nA * = a, A * = a , E * = f E (A * ), E * = f E (A * ), M * = f M (E * ), M * = f M (E * ), T * = f T (E * , M * ), T * = f T (E * , M * ), D * = f D (A * , T * ), D * = f D (A * , T * ).\nPath-specific fairness formalizes the intuition that the influence of a sensitive attribute on a downstream decision may, in some circumstances, be considered legitimate (i.e., it may be acceptable for the attribute to affect decisions along certain paths in the DAG). For instance, an admissions committee may believe that the effect of race A on admissions decisions D which passes through college preparation M is legitimate, whereas the effect of race along the path A \u2192 E \u2192 T \u2192 D, which may reflect access to test prep or cultural biases of the tests, rather than actual academic preparedness, is illegitimate. In that case, the admissions committee may seek to ensure that the proportion of applicants they admit from a certain race group remains unchanged if one were to counterfactually alter the race of those individuals along the path \u03a0 = {A \u2192 E \u2192 T \u2192 D}. Definition 5. Let \u03a0 be a collection of paths, and, for a measurable function w on X , let W = \u03c9(X) describe a reduced set of the covariates X. Path-specific fairness, also called \u03a0-fairness, holds when, for any a \u2208 A,\nE[D \u03a0,A,a | W ] = E[D | W ].(5)\nIn the definition above, rather than a particular counterfactual level a, the baseline level of the path-specific effect is A, i.e., an individual's actual (non-counterfactually altered) group membership (e.g., their actual race). We have implicitly assumed that the decision variable D is a descendant of the covariates X. In particular, without loss of generality, we assume D is defined by the structural equation\nf D (x, u D ) = 1 u D \u2264d(x)\n, where the exogenous variable\nu D \u223c UNIF(0, 1), so that Pr(D = 1 | X = x) = d(x).\nIf \u03a0 is the set of all paths from A to D, then D \u03a0,A,a = D(a ), in which case, for W = X, path-specific fairness is the same as counterfactual fairness.", "publication_ref": ["b18", "b17", "b21", "b9", "b22", "b4"], "figure_ref": [], "table_ref": []}, {"heading": "Constructing Causally Fair Policies", "text": "The definitions of causal fairness above constrain the set of decision policies one might adopt, but, in general, they do not yield a unique policy. For instance, a policy in which applicants are admitted randomly and independently with probability b-where b is the specified budget-satisfies counterfactual equalized odds (Def. 2), conditional principal fairness (Def. 3), counterfactual fairness (Def. 4), and pathspecific fairness (Def. 5). 6 However, such a randomized policy may be sub-optimal in the eyes of decision-makers aiming to maximize outcomes such as class diversity or degree attainment. Past work has described multiple approaches to selecting a single policy from among those satisfying any given fairness definition, including maximizing concordance of the decision with the outcome variable (Chiappa, 2019;Nabi & Shpitser, 2018) or with an existing policy (Wang et al., 2019) (e.g., in terms of binary accuracy or KL-divergence).\nHere, as we are primarily interested in the downstream consequences of various causal fairness definitions, we consider causally fair policies that maximize utility (Cai et al., 2020;Chohlas-Wood et al., 2021a;Corbett-Davies et al., 2017;Kasy & Abebe, 2021;Liu et al., 2018).\nSuppose u(x) denotes the utility of assigning a positive decision to individuals with observed covariate values x, relative to assigning them negative decisions. In our running example, we set\nu(x) = E[Y (1) | X = x] + \u03bb \u2022 1 \u03b1(x)=a1 ,(6)\nwhere E[Y (1) | X = x] denotes the likelihood the applicant would graduate if admitted, 1 \u03b1(x)=a1 indicates whether the applicant identifies as belonging to race group a 1 (e.g., a 1 may denote a group historically underrepresented in higher education), and \u03bb \u2265 0 is an arbitrary constant that balances preferences for both student graduation and racial diversity.\nWe seek decision policies that maximize expected utility, subject to satisfying a given definition of causal fairness, as well as the budget constraint. Specifically, letting C denote the family of all decision policies that satisfy one of the causal fairness definitions listed above, a utility-maximizing 6 A policy satisfying counterfactual predictive parity (Def. 1) is not guaranteed to exist. For example, if b = 0-in which case D = 0 a.s. -and E\n[Y (1) | A = a1] = E[Y (1) | A = a2], then Eq. (1) cannot hold. Similar counterexamples can be constructed for b 1.\npolicy d * is given by\nd * \u2208 arg max d\u2208C E[d(X) \u2022 u(X)] s.t. E[d(X)] \u2264 b.(7)\nConstructing optimal policies poses both statistical and computational challenges. One must, in general, estimate the joint distribution of covariates and potential outcomes-and, even more dauntingly, causal effects along designated paths for path-specific definitions of fairness. In some settings, it may be possible to obtain these estimates from observational analyses of historical data or randomized controlled trials, though both approaches typically involve substantial hurdles in practice.\nWe prove that if one has this statistical information, it is possible to efficiently compute causally fair utility-maximizing policies by solving either a single linear program or a series of linear programs (Appendix, Theorem B.1). In the case of counterfactual equalized odds, conditional principal fairness, counterfactual fairness, and path-specific fairness, we show that the definitions can be translated to linear constraints. For counterfactual predictive parity, the defining independence condition yields a quadratic constraint, which we show can be expressed as a linear constraint by further conditioning on one of the decision variables, and the optimization problem in turn can be solved through a series of linear programs.", "publication_ref": ["b9", "b7", "b10", "b18"], "figure_ref": [], "table_ref": []}, {"heading": "The Structure of Causally Fair Policies", "text": "Above, for each definition of causal fairness, we sketched how to construct utility-maximizing policies that satisfy the corresponding constraints. Now we explore the structural properties of causally fair policies. We show-both empirically and analytically, under relatively mild distributional assumptions-that policies constrained to be causally fair are disfavored by every individual in a natural class of decision makers with varying preferences for diversity.\nTo formalize these results, we start by introducing some notation and then defining the concept of (strong) Pareto dominance. To develop intuition about the structure of causally fair decision policies, we continue working through our illustrative example of college admissions. We consider a collection of decision makers with utilities U of the form in Eq. ( 6), for \u03bb \u2265 0. In this example, decision makers differ in their preferences for diversity (as determined by \u03bb), but otherwise have similar preferences. We call such a collection of utilities consistent modulo \u03b1. Definition 8. We say that a set of utilities U is consistent modulo \u03b1 if, for any u, u \u2208 U:", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Pareto Dominance and Consistent Utilities", "text": "1. For any x, sign(u(x)) = sign(u (x)); 2. For any x 1 and x 2 such that \u03b1(\nx 1 ) = \u03b1(x 2 ), u(x 1 ) > u(x 2 ) if and only if u (x 1 ) > u (x 2 ).\nFor consistent utilities, the Pareto frontier takes a particularly simple form, represented by (a subset of) groupspecific threshold policies. Proposition 1. Suppose U is a set of utilities that is consistent modulo \u03b1. Then any Pareto efficient decision policy d is a multiple threshold policy. That is, for any u \u2208 U, there exist group-specific constants t a \u2265 0 such that, a.s.:\nd(x) = 1 u(x) > t \u03b1(x) , 0 u(x) < t \u03b1(x) .(8)\nThe proof of Proposition 1 is in the Appendix. 7", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "An Empirical Example", "text": "With these preliminaries in place, we now empirically explore the structure of causally fair decision policies in the 7 In the statement of the proposition, we do not specify what happens at the thresholds u(x) = t \u03b1(x) themselves, as one can typically ignore the exact manner in which decisions are made at the threshold. Specifically, given a threshold policy d, we can construct a standardized threshold policy d that is constant within group at the threshold (i.e., d (x) = c \u03b1(x) when u(x) = t \u03b1(x) ), and for which:\n(1) E[d (X)|A] = E[d(X)|A]; and (2) u(d ) = u(d).\nIn our running example, this means we can standardize threshold policies so that applicants at the threshold are admitted with the same group-specific probability. Admitted Applicants from Target Group College Degree Attainment Figure 2. Utility-maximizing policies for various definitions of causal fairness in an illustrative example of college admissions, with the Pareto frontier depicted by the solid purple curve. For path-specific fairness, we set \u03a0 equal to the single path A \u2192 E \u2192 T \u2192 D, and set W = X. For each causal fairness definition, the depicted constrained policies are strongly Pareto dominated, meaning there is an alternative feasible policy that simultaneously achieves greater student-body diversity and higher college degree attainment. Our analytical results show, more generally, that under mild distributional assumptions, every policy constrained to satisfy these causal fairness definitions is strongly Pareto dominated. context of our stylized example of college admissions, given by the causal DAG in Figure 1. In the hypothetical pool of 100,000 applicants we consider, applicants in the target race group a 1 have, on average, fewer educational opportunities than those applicants in group a 0 , which leads to lower average academic preparedness, as well as lower average test scores. See Section C in the Appendix for additional details, including the specific structural equations we use.\nFor the utility function in Eq. (6) with \u03bb = 1 4 , we apply Theorem B.1 to compute utility-maximizing policies for each of the above causal definitions of fairness. We plot the results in Figure 2, where, for each policy, the horizontal axis shows the expected number of admitted applicants from the target race group, and the vertical axis shows the expected number of college graduates. Additionally, for the family of utilities U given by Eq. (6) for \u03bb \u2265 0, we depict the Pareto frontier by the solid purple curve, computed via Proposition 1. 8 For reference, the dashed purple line corresponds to max-utility policies constrained to satisfy 8 For all the cases we consider, the optimal policies admit the maximum proportion of students allowed under the budget b (i.e., Pr(D = 1) = b). To compute the Pareto frontier in Figure 2, it is sufficient-by Proposition 1 and Footnote 7-to sweep over (standardized) group-specific threshold policies relative to the utility u0\n(x) = E[Y (1)|X = x].\nthe level of diversity indicated on the x-axis, though these policies are not on the Pareto frontier, as they result in fewer college graduates and lower diversity than the policy that maximizes graduation alone (indicated by the \"max graduation\" point in Figure 2).\nFor each fairness definition, the depicted policies are strongly Pareto dominated, meaning that there is an alternative feasible policy favored by all decision makers with preferences in U. In particular, for each definition of causal fairness, there is an alternative feasible policy in which one simultaneously achieves more student-body diversity and more college graduates. In some instances, the efficiency gap is quite stark. Utility-maximizing policies constrained to satisfy either counterfactual fairness or path-specific fairness require one to admit each applicant independently with fixed probability b (where b is the budget), regardless of academic preparedness or group membership. 9 These results show that constraining decision-making algorithms to satisfy popular definitions of causal fairness can have unintended consequences, and may even harm the very groups they were ostensibly designed to protect.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "The Statistical Structure of Causally Fair Policies", "text": "The patterns illustrated in Figure 2 and discussed above are not idiosyncracies of our particular example, but rather hold quite generally. Indeed, Theorem 1 shows that for almost every joint distribution of X, Y (0), and Y (1) such that u(X) has a density, any decision policy satisfying counterfactual equalized odds or conditional principal fairness is Pareto dominated. Similarly, for almost every joint distribution of X and X \u03a0,A,a , we show that policies satisfying path-specific fairness (including counterfactual fairness) are Pareto dominated. (NB: The analogous statement for counterfactual predictive parity is not true, which we address in Proposition 2.)\nThe notion of almost every distribution that we use here was formalized by Christensen (1972), Hunt et al. (1992, Anderson & Zame (2001), and others (cf. Ott & Yorke, 2005, for a review). Suppose, for a moment, that combinations of covariates and outcomes take values in a finite set of size m. Then the space of joint distributions on covariates and outcomes can be represented by the unit (m \u2212 1)-simplex:\n\u2206 m\u22121 = {p \u2208 R m | p i \u2265 0 and m i=1 p i = 1}. Since \u2206 m\u22121 is a subset of an (m \u2212 1)-dimensional hyperplane in R m ,\nit inherits the usual Lebesgue measure on R m\u22121 . In this finite-dimensional setting, almost every distribution means a subset of distributions that has full Lebesgue measure on the simplex. Given a property that holds for almost every distribution in this sense, that property holds almost surely under any probability distribution on the space of distributions that is described by a density on the simplex. We use a generalization of this basic idea that extends to infinite-dimensional spaces, allowing us to consider distributions with arbitrary support. (See the Appendix for further details.)\nTo prove this result, we make relatively mild restrictions on the set of distributions and utilities we consider to exclude degenerate cases, as formalized by Definition 9 below. Definition 9. Let G be a collection of functions from Z to R d for some set Z. We say that a distribution of Z on Z is G-fine if g(Z) has a density for all g \u2208 G.\nIn particular, U-fineness ensures that the distribution of u(X) has a density. In the absence of U-fineness, corner cases can arise in which an especially large number of policies may be Pareto efficient, in particular when u(X) has large atoms and X can be used to predict the potential outcomes Y (0) and Y (1) even after conditioning on u(X). See Prop. E.7 for details. Our example of college admissions, where U is defined by Eq. (6), is U-fine.\nTheorem 1. Suppose U is a set of utilities consistent modulo \u03b1. Further suppose that for all a \u2208 A there exist a U-fine distribution of X and a utility u \u2208 U such that Pr(u(X) > 0, A = a) > 0, where A = \u03b1(X). Then,\n\u2022 For almost every U-fine distribution of X and Y (1), any decision policy satisfying counterfactual equalized odds is strongly Pareto dominated.\n\u2022 If | IMG(\u03c9)| < \u221e and there exists a U-fine distribution of X such that Pr(A = a, W = w) > 0 for all a \u2208 A and w \u2208 IMG(\u03c9), where W = \u03c9(X), then, for almost every U-fine joint distribution of X, Y (0), and Y (1), any decision policy satisfying conditional principal fairness is strongly Pareto dominated.\n\u2022 If | IMG(\u03c9)| < \u221e and there exists a U-fine distribution of X such that Pr(A = a, W = w i ) > 0 for all a \u2208 A and some distinct w 0 , w 1 \u2208 IMG(\u03c9), then, for almost every U A -fine joint distributions of A and the counterfactuals X \u03a0,A,a , any decision policy satisfying path-specific fairness is strongly Pareto dominated. 10\nThe proof of Theorem 1 is given in the Appendix. At a high-level, the proof proceed in three steps, which we outline below using the example of counterfactual equalized odds. First, we show that for almost every fixed U-fine joint distribution \u00b5 of X and Y (1) there is at most one policy d * (x) satisfying counterfactual equalized odds that is not strongly Pareto dominated. To see why, note that for any specific y 0 , since counterfactual equalized odds requires that D \u22a5 \u22a5 A | Y (1) = y 0 , setting the threshold for one group determines the thresholds for all the others; the budget constraint then can be used to fix the threshold for the original group. Second, we construct a \"slice\" around \u00b5 such that for any distribution \u03bd in the slice, d * (x) is still the only policy that can potentially lie on the Pareto frontier while satisfying counterfactual equalized odds. We create the slice by strategically perturbing \u00b5 only where Y (1) = y 1 , for some y 1 = y 0 . This perturbation moves mass from one side of the thresholds of d * (x) to the other, consequently breaking the balance requirement D \u22a5 \u22a5 A | Y (1) = y 1 for almost every \u03bd in the slice. This phenomenon is similar to the problem of infra-marginality (Ayres, 2002;Simoiu et al., 2017), which likewise afflicts non-causal notions of fairness (Corbett-Davies & Goel, 2018;Corbett-Davies et al., 2017). Finally, we appeal to the notion of prevalence to stitch the slices together, showing that for almost every distribution, any policy satisfying counterfactual equalized odds is strongly Pareto dominated. Analogous versions of this general argument apply to the cases of conditional principal fairness and path-specific fairness. 11\nIn some common settings, path-specific fairness with W = X constrains decisions so severely that the only allowable policies are constant (i.e., d(x 1 ) = d(x 2 ) for all x 1 , x 2 \u2208 X ). For instance, in our running example, pathspecific fairness requires admitting all applicants with the same probability, irrespective of academic preparation or group membership. Thus, all applicants are admitted with probability b, where b is the budget, under the optimal policy constrained to satisfy path-specific fairness.\nTo build intuition for this result, we sketch the argument for a finite covariate space X . Given a policy d that satisfies path-specific fairness, select\nx * \u2208 arg max x\u2208X d(x).\nBy the definition of path-specific fairness, for any a \u2208 A,\nd(x * ) = E[D \u03a0,A,a | X = x * ] = x\u2208\u03b1 \u22121 (a) d(x) \u2022 Pr(X \u03a0,A,a = x | X = x * ). (9)\nThat is, the probability of an individual with covariates x * receiving a positive decision must be the average probability of the individuals with covariates x in group a receiving a positive decision, weighted by the probability that an individual with covariates x * in the real world would have covariates x counterfactually.\nNext, we suppose that there exists an a \u2208 A such that Pr(X \u03a0,A,a = x | X = x * ) > 0 for all x \u2208 \u03b1 \u22121 (a ). In this case, because d(x) \u2264 d(x * ) for all x \u2208 X , Eq. (9) shows that in fact d(x) = d(x * ) for all x \u2208 \u03b1 \u22121 (a ).\n11 This argument does not depend in an essential way on the definitions being causal. In Corollary E.5, we show an analogous result for the non-counterfactual version of equalized odds. Now, let x be arbitrary. Again, by the definition of pathspecific fairness, we have that\nd(x ) = E[D \u03a0,A,a | X = x ] = x\u2208\u03b1 \u22121 (a ) d(x) \u2022 Pr(X \u03a0,A,a = x | X = x ) = x\u2208\u03b1 \u22121 (a ) d(x * ) \u2022 Pr(X \u03a0,A,a = x | X = x * ), = d(x * ),\nwhere we use in the third equality the fact d(x) = d(x * ) for all x \u2208 \u03b1 \u22121 (a ), and in the final equality the fact that X \u03a0,A,a is supported on \u03b1 \u22121 (a ).\nTheorem 2 formalizes and extends this argument to more general settings, where Pr(X \u03a0,A,a = x | X = x * ) is not necessarily positive for all x \u2208 \u03b1 \u22121 (a ). The proof of Theorem 2 is in the Appendix, along with extensions to continuous covariate spaces and a more complete characterization of \u03a0-fair policies for finite X . Theorem 2. Suppose X is finite and Pr(X = x) > 0 for all x \u2208 X . Suppose Z = \u03b6(X) is a random variable such that:\n1. Z = Z \u03a0,A,a for all a \u2208 A, 2. Pr(X \u03a0,A,a = x | X = x) > 0 for all a \u2208 A such that \u03b1(x) = a and x, x \u2208 X such that \u03b6(x) = \u03b6(x ).\nThen, for any \u03a0-fair policy d, with W = X, there exists a function f such that d(X) = f (Z), i.e., d is constant across individuals having the same value of Z.\nThe first condition of Theorem 2 holds for any reduced set of covariates Z that is not causally affected by changes in A (e.g., Z is not a descendent of A). The second condition requires that among individuals with covariates x, a positive fraction have covariates x in a counterfactual world in which they belonged to another group a . Because \u03b6(x) is the same in the real and counterfactual worlds-since Z is unaffected by A, by the first condition-we only consider x such that \u03b6(x ) = \u03b6(x) in the second condition.\nIn our running example, the only non-race covariate is test score, which is downstream of race. Further, among students with a given test score, a positive fraction achieve any other test score in the counterfactual world in which their race is altered. As such, the empty set of reduced covariates-formally encoded by setting \u03b6 to a constant function-satisfies the conditions of Theorem 2. The theorem then implies that under any \u03a0-fair policy, every applicant is admitted with equal probability.\nEven when decisions are not perfectly uniform lotteries, as in our admissions example, Theorem 2 suggests that enforcing \u03a0-fairness can lead to unexpected outcomes. For instance, suppose we modify our admissions example to additionally include age as a covariate that is causally unconnected to race-as some past work has done. In that case, \u03a0-fair policies would admit students based on their age alone, irrespective of test score or race. Although in some cases such restrictive policies might be desirable, this strong structural constraint implied by \u03a0-fairness appears to be a largely unintended consequence of the mathematical formalism.\nThe conditions of Theorem 2 are relatively mild, but do not hold in every setting. Suppose that in our admissions example it were the case that T \u03a0,A,a0 = T \u03a0,A,a1 + c for some constant c-that is, suppose the effect of intervening on race is a constant change to an applicant's test score. Then the second condition of Theorem 2 would no longer hold for a constant \u03b6. Indeed, any multiple-threshold policy in which t a0 = t a1 + c would be \u03a0-fair. In practice, though, such deterministic counterfactuals would seem to be the exception rather than the rule. For example, it seems reasonable to expect that test scores would depend on race in complex ways that induce considerable heterogeneity.\nLastly, we note that W = X in some variants of pathspecific fairness (e.g., Nabi & Shpitser, 2018;Zhang & Bareinboim, 2018), in which case Theorem 2 does not apply. Although, in that case, policies are typically still Pareto dominated in accordance with Theorem 1.\nWe conclude our analysis by investigating counterfactual predictive parity, the least demanding of the causal notions of fairness we have considered, requiring only that Y (1) \u22a5 \u22a5\nA | D = 0.\nAs such, it is in general possible to have a policy on the Pareto frontier that satisfies this condition. However, in Proposition 2, we show that this cannot happen in some common cases, including our example of college admissions.\nIn that setting, when the target group has lower average graduation rates-a pattern that often motivates efforts to actively increase diversity-decision policies constrained to satisfy counterfactual predictive parity are Pareto dominated. The proof of the proposition is in the Appendix. Proposition 2. Suppose A = {a 0 , a 1 }, and consider the family U of utility functions of the form\nu(x) = r(x) + \u03bb \u2022 1 \u03b1(x)=a1 , indexed by \u03bb \u2265 0, where r(x) = E[Y (1) | X = x]\n. Suppose the conditional distributions of r(X) given A are beta distributed, i.e., r(X\n) | A = a \u223c BETA(\u00b5 a , v),\nwith v > 2 and \u00b5 a0 > \u00b5 a1 > 1/v. 12 Then any policy 12 Here we parameterize the beta distribution in terms of its mean \u00b5 and sample size v. In terms of the common, alternative \u03b1-\u03b2 parameterization, \u00b5 = \u03b1/(\u03b1 + \u03b2) and v = \u03b1 + \u03b2.\nsatisfying counterfactual predictive parity is strongly Pareto dominated.", "publication_ref": ["b15", "b0", "b1", "b17", "b18"], "figure_ref": [], "table_ref": []}, {"heading": "Discussion", "text": "We have worked to collect, synthesize, and investigate several causal conceptions of fairness that recently have appeared in the machine learning literature. These definitions formalize intuitively desirable properties-for example, minimizing the direct and indirect effects of race on decisions. But, as we have shown both analytically and with a synthetic example, they can, perhaps surprisingly, lead to policies with unintended downstream outcomes. In contrast to prior impossibility results (Chouldechova, 2017;Kleinberg et al., 2017), in which different formal notions of fairness are shown to be in conflict with each other, we demonstrate trade-offs between formal notions of fairness and resulting social welfare. For instance, in our running example of college admissions, enforcing various causal fairness definitions can lead to a student body that is both less academically prepared and less diverse than what one could achieve under natural alternative policies, potentially harming the very groups these definitions were ostensibly designed to protect. Our results thus highlight a gap between the goals and potential consequences of popular causal approaches to fairness.\nWhat, then, is the role of causal reasoning in designing equitable algorithms? Under a consequentialist perspective to algorithm design (Cai et al., 2020;Chohlas-Wood et al., 2021a;Liang et al., 2021), one aims to construct policies with the most desirable expected outcomes, a task that inherently demands causal reasoning. Formally, this approach corresponds to solving the unconstrained optimization problem in Eq. ( 7), where preferences for diversity may be directly encoded in the utility function itself, rather than by constraining the class of policies, mitigating potentially problematic consequences. While conceptually appealing, this consequentialist approach still faces considerable practical challenges, including estimating the expected effects of decisions, and eliciting preferences over outcomes.\nOur analysis illustrates some of the limitations of mathematical formalizations of fairness, reinforcing the need to explicitly consider the consequences of actions, particularly when decisions are automated and carried out at scale. Looking forward, we hope our work clarifies the ways in which causal reasoning can aid the equitable design of algorithms.\nGrant No. DGE-1656518. J.G was supported by a Stanford Knight-Hennessy Scholarship. R.S. was supported by the NSF Program on Fairness in AI in Collaboration with Amazon under the award \"FAI: End-to-End Fairness for Algorithm-in-the-Loop Decision Making in the Public Sector,\" no. IIS-2040898. Any opinion, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation or Amazon. Code to reproduce our results is available at https://github. com/stanford-policylab/causal-fairness. Pierson, E., Simoiu, C., Overgoor, J., Corbett-Davies, S., Jenson, D., Shoemaker, A., Ramachandran, V., Barghouty, P., Phillips, C., Shroff, R., and Goel, S. A large-scale analysis of racial disparities in police stops across the United States. Nature Human Behaviour, 4( 7 ", "publication_ref": ["b13", "b7", "b10"], "figure_ref": [], "table_ref": []}, {"heading": "A. Path-specific Counterfactuals", "text": "Constructing policies which satisfy path-specific fairness requires computing path-specific counterfactual values of features. In Algorithm 1, we describe the formal construction of path-specific counterfactuals Z \u03a0,a,a , for an arbitrary variable Z (or collection of variables) in the DAG. To generate a sample Z * \u03a0,a,a from the distribution of Z \u03a0,a,a , we first sample values U * j for the exogenous variables. Then, in the first loop, we traverse the DAG in topological order, setting A to a and iteratively computing values V * j of the other nodes based on the structural equations in the usual fashion. In the second loop, we set A to a , and then iteratively compute values V j * for each node. V j * is computed using the structural equation at that node, with value V * for each of its parents that are connected to it along a path in \u03a0, and the value V * for all its other parents. Finally, we set Z * \u03a0,a,a to Z * .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B. Constructing Causally Fair Policies", "text": "In order to construct causally fair policies, we prove that the optimization problem in Eq. ( 7) can be efficiently solved as a single linear program-in the case of counterfactual equalized odds, conditional principal fairness, counterfactual fairness, and path-specific fairness-or as a series of linear programs in the case of counterfactual predictive parity.\nTheorem B.1. Consider the optimization problem given in Eq. (7).\n1. If C is the class of policies that satisfies counterfactual equalized odds or conditional principal fairness, and the distribution of (X, Y (0), Y (1)) is known and supported on a finite set of size n, then a utility-maximizing policy constrained to lie in C can be constructed via a linear program with O(n) variables and constraints.\n2. If C is the class of policies that satisfies path-specific fairness (including counterfactual fairness), and the distribution of (X, D \u03a0,A,a ) is known and supported on \nif V j = A then 4 V * j \u2190 a 5 else 6 \u2118(V j ) * \u2190 {V * | V \u2208 \u2118(V j )} 7 V * j \u2190 f Vj (\u2118(V j ) * , U * j ) 8 end 9 end\n/ * Compute counterfactuals by setting A to a and propagating values along paths in \u03a0 * / 10 for j = 1, . . . , m do\n11 if V j = A then V * j \u2190 a 13 else for V k \u2208 \u2118(V j ) do if edge (V k , V j ) lies on a path in \u03a0 then 16 V \u2020 k \u2190 V * k else 18 V \u2020 k \u2190 V * k end end \u2118(V j ) \u2020 \u2190 {V \u2020 | V \u2208 \u2118(V j )} V * j \u2190 f Vj (\u2118(V j ) \u2020 , U * j ) 23 end 24 end 25 Z * \u03a0,a,a \u2190 Z *\na finite set of size n, then a utility-maximizing policy constrained to lie in C can be constructed via a linear program with O(n) variables and constraints.\n3. Suppose C is the class of policies that satisfies counterfactual predictive parity, that the distribution of (X, Y (1)) is known and supported on a finite set of size n, and that the optimization problem in Eq. (7) has a feasible solution. Further suppose Y (1) is supported on k points, and let\n\u2206 k\u22121 = {p \u2208 R k | p i \u2265 0 and k i=1 p i = 1} be the unit (k \u2212 1)- simplex.\nThen one can construct a set of linear programs L = {L(v)} v\u2208\u2206 k , with each having O(n) variables and constraints, such that the solution to one of the LPs in L is a utility-maximizing policy constrained to lie in C.\nProof. Let X = {x 1 , . . . , x m }; then, we seek decision variables d i , i = 1, . . . , m, corresponding to the probability of making a positive decision for individuals with covariate value x i . Therefore, we require that 0 \u2264 d i \u2264 1.\nLetting p i = Pr(X = x i ) denote the mass of X at x i , note that the objective function E[d(X) \u2022 u(X)] equals m i=1 d i \u2022 u(x i ) \u2022 p i and the budget constraint m i=1 d i \u2022 p i \u2264 b are both linear in the decision variables.\nWe now show that each of the causal fairness definitions can be enforced via linear constraints. We do so in three parts as listed in theorem.\nTheorem B.1 Part 1 First, we consider counterfactual equalized odds. A decision policy satisfies counterfactual equalized odds when\nD \u22a5 \u22a5 A | Y (1). Since D is binary, this condition is equivalent to the expression E[d(X) | A = a, Y (1) = y] = E[d(X) | Y (1) = y]\nfor all a \u2208 A and y \u2208 Y such that Pr(Y (1) = y) > 0. Expanding this expression and replacing d(x j ) by the corresponding decision variable d j , we obtain that\nm i=1 d i \u2022 Pr(X = x i | A = a, Y (1) = y) = m i=1 d i \u2022 Pr(X = x i | Y (1) = y)\nfor each a \u2208 A and each of the finitely many values y \u2208 Y such that Pr(Y (1) = y) > 0. These constraints are linear in the d i by inspection.\nNext, we consider conditional principal fairness. A decision policy satisfies conditional principal fairness when D \u22a5 \u22a5 A | Y (0), Y (1), W , where W = \u03c9(X) denotes a reduced set of the covariates X. Again, since D is binary, this condition is equivalent to the expression E[d(X\n) | A = a, Y (0) = y 0 , Y (1) = y 1 , W = w] = E[d(X) | Y (0) = y 0 , Y (1) = y 1 , W = w] for all y 0 , y 1 , and w satisfying Pr(Y (0) = y 0 , Y (1) = y 1 , W = w) > 0.\nAs above, expanding this expression and replacing d(x j ) by the corresponding decision variable d j yields linear constraints of the form\nm i=1 d i \u2022 Pr(X = x i | A = a, S = s) = m j=1 d i \u2022 Pr(X = x i | S = s)\nfor each a \u2208 A and each of the finitely many values of S = (Y (0\n), Y (1), W ) such that s = (y 0 , y 1 , w) \u2208 Y \u00d7 Y \u00d7 W satisfies Pr(Y (0) = y 0 , Y (1) = y 1 , W = w) > 0.\nAgain, these constraints are linear by inspection.\nTheorem B.1 Part 2 Suppose a decision policy satisfies path-specific fairness for a given collection of paths \u03a0 and a (possibly) reduced set of covariates W = \u03c9(X), meaning that for every a\n\u2208 A, E[D \u03a0,A,a | W ] = E[D | W ].\nRecall from the definition of path-specific counterfactu-\nals that D \u03a0,A,a = f D (X \u03a0,A,a , U D ) = 1 U D \u2264d(X \u03a0,A,a ) , where U D \u22a5 \u22a5 {X \u03a0,A,a , X}. Since W = \u03c9(X), U D \u22a5 \u22a5 {X \u03a0,A,a , W }, it follows that E[D \u03a0,A,a | W = w] = m i=1 E[D \u03a0,A,a | X \u03a0,A,a = x i , W = w] \u2022 Pr(X \u03a0,A,a = x i | W = w) = m i=1 E[1 U D \u2264d(X \u03a0,A,a ) | X \u03a0,A,a = x i , W = w] \u2022 Pr(X \u03a0,A,a = x i | W = w) = m i=1 d(X \u03a0,A,a ) \u2022 Pr(X \u03a0,A,a = x i | W = w) = m i=1 d i \u2022 Pr(X \u03a0,A,a = x i | W = w).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "An analogous calculation yields that", "text": "E[D | W = w] = m i=1 d i \u2022 Pr(X = x i | W = w). Equating these expres- sions gives m i=1 d i \u2022 Pr(X = x i | W = w) = m i=1 d i \u2022 Pr(X \u03a0,A,a = x i | W = w)\nfor each a \u2208 A and each of the finitely many w \u2208 W such that Pr(W = w) > 0. Again, each of these constraints is linear by inspection.\nTheorem B.1 Part 3 A decision policy satisfies counter- factual predictive parity if Y (1) \u22a5 \u22a5 A | D = 0, or equiva- lently, Pr(Y (1) = y | A = a, D = 0) = Pr(Y (1) | D = 0) for all a \u2208 A.\nWe may rewrite this expression to obtain:\nPr(Y (1) = y, A = a, D = 0) Pr(A = a, D = 0) = C y ,where\nC y = Pr(Y (1) = y | D = 0).\nExpanding the numerator on the left-hand side of the above equation yields\nPr(Y (1) = y, A = a, D = 0) = m i=1 [1 \u2212 d i ] \u2022 Pr(Y (1) = y, A = a, X = x i )\nSimilarly, expanding the denominator yields\nPr(Y (1) = y, D = 0) = m i=1 [1 \u2212 d i ] \u2022 Pr(Y (1) = y, X = x i ).\nfor each of the finitely many y \u2208 Y. Therefore, counterfactual predictive parity corresponds to\nm i=1 [1 \u2212 d i ] \u2022 Pr(Y (1) = y, A = a, X = x i ) = C y \u2022 m i=1 [1 \u2212 d i ] \u2022 Pr(Y (1) = y, X = x i ),(10)\nfor each a \u2208 A and y \u2208 Y. Again, these constraints are linear in the d i by inspection.\nConsider the family of linear programs L = {L(v)} v\u2208\u2206 k where the linear program L(v) has the same objective function\nm i=1 d i \u2022u(x i )\u2022p i and budget constraint m i=1 d i \u2022p i \u2264 b\nas before, together with additional constraints for each a \u2208 A as in Eq. ( 10), where C yi = v i for i = 1, . . . , k.\nBy assumption, there exists a feasible solution to the optimization problem in Eq. ( 7), so the solution to at least one program in L is a utility-maximizing policy that satisfies counterfactual predictive parity.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C. A Stylized Example of College Admissions", "text": "In the example we consider in Section 2.1, the exogenous variables U = {u A , u D , u E , u M , u T , u Y } in the DAG are independently distributed as follows:\nU A , U D , U Y \u223c UNIF(0, 1), U E , U M , U T \u223c N(0, 1). For fixed constants \u00b5 A , \u03b2 E,0 , \u03b2 E,A , \u03b2 M,0 , \u03b2 M,E , \u03b2 T,0 , \u03b2 T,E , \u03b2 T,M , \u03b2 T,B , \u03b2 T,u , \u03b2 Y,0 , \u03b2 Y,D\n, we define the endogenous variables V = {A, E, M, T, D, Y } in the DAG by the following structural equations:\nf A (u A ) = a 1 if u A \u2264 \u00b5 A a 0 otherwise , f E (a, u E ) = \u03b2 E,0 + \u03b2 E,A \u2022 1(a = a 1 ) + u E , f M (e, u M ) = \u03b2 M,0 + \u03b2 M,E \u2022 e + u M , f T (e, m, u T ) = \u03b2 T,0 + \u03b2 T,E \u2022 e + \u03b2 T,M \u2022 m + \u03b2 T,B \u2022 e \u2022 m + \u03b2 T,u \u2022 u T , f D (x, u D ) = 1(u D \u2264 d(x)), f Y (m, u Y , \u03b4) = 1(u Y \u2264 logit \u22121 (\u03b2 Y,0 + m + \u03b2 Y,D \u2022 \u03b4)),\nwhere logit \u22121 (x) = (1 + exp(\u2212x)) \u22121 and d(x) is the decision policy. In our example, we use constants\n\u00b5 A = 1 3 , \u03b2 E,0 = 1, \u03b2 E,A = \u22121, \u03b2 M,0 = 0, \u03b2 M,E = 1, \u03b2 T,0 = 50, \u03b2 T,E = 4, \u03b2 T,M = 4, \u03b2 T,u = 7, \u03b2 T,B = 1, \u03b2 Y,0 = \u2212 1 2 , \u03b2 Y,D = 1 2 .\nWe also assume a budget b = 1 2 .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "D. Proof of Proposition 1", "text": "We begin by more formally defining (multiple) threshold policies. We assume, without loss of generality, that Pr(A = a) > 0 for all a \u2208 A throughout. Definition D.1. Let u(x) be a utility function. We say that a policy d(x) is a threshold policy with respect to u if there exists some t such that\nd(x) = 1 u(x) > t, 0 u(x) < t,and\nd(x) \u2208 [0, 1] is arbitrary if u(x) = t.\nWe say that d(x) is a multiple threshold policy with respect to u if there exist group-specific constants t a for a \u2208 A such that\nd(x) = 1 u(x) > t \u03b1(x) , 0 u(x) < t \u03b1(x) , and d(x) \u2208 [0, 1] is arbitrary if u(x) = t \u03b1(x) .\nRemark 1. In general, it is possible for different thresholds to produce threshold policies that are almost surely equal. For instance, if u(X) \u223c BERN( 1 2 ), then the policies 1 u(X)>p are almost surely equal for all p \u2208 [0, 1). Nevertheless, we speak in general of the threshold associated with the threshold policy d(X) unless there is ambiguity.\nWe first observe that if U is consistent modulo \u03b1, then whether a decision policy d(x) is a multiple threshold policy does not depend on our choice of u \u2208 U. Lemma D.1. Let U be a collection of utilities consistent modulo \u03b1, and suppose d :\nX \u2192 [0, 1] is a decision rule. If d(x)\nis a multiple threshold rule with respect to a utility u * \u2208 U, then d(x) is a multiple threshold rule with respect to every u \u2208 U. In particular, if d(x) can be represented by non-negative thresholds over u * , it can be represented by non-negative thresholds over any u \u2208 U.\nProof. Suppose d(x) is represented by thresholds {t * a } a\u2208A with respect to u * . We construct the thresholds {t a } a\u2208A explicitly.\nFix a \u2208 A and suppose that there exists x * \u2208 \u03b1 \u22121 (a) such that u * (x * ) = t * a . Then set t a = u(x * ). Now, if u(x) > t a = u(x * ) then, by consistency modulo \u03b1, u * (x) > u * (x * ) = t * a . Similarly if u(x) < t a then u * (x) < t * a . We also note that by consistency modulo \u03b1, sign(t a ) = sign(u(x * )) = sign(u * (x * )) = sign(t * a ). If there is no x * \u2208 \u03b1 \u22121 (a) such that u * (x * ) = t * a , then let\nt a = inf x\u2208Sa u(x)\nwhere S a = {x \u2208 \u03b1 \u22121 (a) | u * (x) > t * a }. Note that since sign(u(x)) = sign(u * (x)) for all x by consistency modulo \u03b1, if t * a \u2265 0, it follows that t a \u2265 0 as well. We need to show in this case also that if u(x) > t a then u * (x) > t * a , and if u(x) < t a then u * (x) < t * a . To do so, let x \u2208 \u03b1 \u22121 (a) be arbitrary, and suppose u(x) > t a . Then, by definition, there exists x \u2208 \u03b1 \u22121 (a) such that u(x) > u(x ) > t a and u * (x ) > t * a , whence u * (x) > u * (x ) > t * a by consistency modulo \u03b1. On the other hand, if u(x) < t a , it follows by the definition of t a that u * (x) \u2264 t * a ; since u * (x) = t * a by hypothesis, it follows that u * (x) < t * a . Therefore, it follows in both cases that for x \u2208 \u03b1 \u22121 (a), if u(x) > t a then u * (x) > t * a , and if u(x) < t a then u * (x) < t * a . Therefore\nd(x) = 1 if u(x) > t \u03b1(x) , 0 if u(x) < t \u03b1(x) ,\ni.e., d(x) is a multiple threshold policy with respect to u. Moreover, as noted above, if t * a \u2265 0 for all a \u2208 A, then t a \u2265 0 for all a \u2208 A.\nWe now prove the following strengthening of Prop. 1.\nLemma D.2. Let U be a collection of utilities consistent modulo \u03b1. Let d(x) be a feasible decision policy that is not a.s. a multiple threshold policy with non-negative thresholds with respect to U, then d(x) is strongly Pareto dominated.\nProof. We prove the claim in two parts. First, we show that any policy that is not a multiple threshold policy is strongly Pareto dominated. Then, we show that any multiple threshold policy that cannot be represented with non-negative thresholds is strongly Pareto dominated.\nIf d(x) is not a multiple threshold policy, then there exists a u \u2208 U and a * \u2208 A such that d(x) is not a threshold policy when restricted to \u03b1 \u22121 (a * ) with respect to u.\nWe will construct an alternative policy d (x) that attains strictly greater utility on \u03b1 \u22121 (a * ) and is identical elsewhere. Thus, without loss of generality, we assume there is a single group, i.e., \u03b1(x) = a * . The proof proceeds heuristically by moving some of the mass below a threshold to above a threshold to create a feasible policy with improved utility.\nLet b = E[d(X)]. Define m Lo (t) = E[d(X) \u2022 1 u(X)<t ], m Up (t) = E[(1 \u2212 d(X)) \u2022 1 u(X)>t ].\nWe show that there exists t * such that m Up (t * ) > 0 and m Lo (t * ) > 0. For, if not, consider\nt = inf{t \u2208 R : m Up (t) = 0}.\nNote that d(X) \u2022 1 u(X)>t = 1 u(X)>t a.s. Ift = \u2212\u221e, then by definition d(X) = 1 a.s., which is a threshold policy, violating our assumption on d(X). Ift > \u2212\u221e, then for any t <t, we have, by definition that m Up (t ) > 0, and so by hypothesis m Lo (t ) = 0. Therefore d(X) \u2022 1 u(X)<t = 0 a.s., and so, again, d(X) is a threshold policy, contrary to hypothesis. Now, with t * as above, for notational simplicity, let m Up = m Up (t * ) and m Lo = m Lo (t * ) and consider the alternative policy\nd (x) = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 (1 \u2212 m Up ) \u2022 d(x) u(x) < t * , d(x) u(x) = t * , 1 \u2212 (1 \u2212 m Lo ) \u2022 (1 \u2212 d(x)) u(x) > t * .\nThen it follows by construction that\nE[d (X)] = (1 \u2212 m Up ) \u2022 m Lo + E[d(X) \u2022 1 u(X)=t * ] + Pr(u(X) > t * ) \u2212 (1 \u2212 m Lo ) \u2022 m Up = m Lo + E[d(X) \u2022 1 u(X)=t * ] + Pr(u(X) > t * ) \u2212 m Up = E[d(X) \u2022 1 u(X)<t * ] + E[d(X) \u2022 1 u(X)=t * ] + E[1 u(X)>t * ] \u2212 E[(1 \u2212 d(X)) \u2022 1 u(X)>t * ] = E[d(X)] = b, so d (x) is feasible. However, d (x) \u2212 d(x) = m Lo \u2022 (1 \u2212 d(x)) \u2022 1 u(x)>t * \u2212 m Up \u2022 d(x) \u2022 1 u(x)<t * , and so E[(d (X) \u2212 d(X)) \u2022 u(X)] = m Lo \u2022 E[(1 \u2212 d(X)) \u2022 1 u(X)>t * \u2022 u(X)] \u2212 m Up \u2022 E[d(X) \u2022 1 u(X)<t * \u2022 u(X)] > m Lo \u2022 t * \u2022 E[(1 \u2212 d(X)) \u2022 1 u(X)>t * ] \u2212 m Up \u2022 t * \u2022 E[d(X) \u2022 1 u(X)<t * ] = t * \u2022 m Lo \u2022 m Up \u2212 t * \u2022 m Up \u2022 m Lo = 0. Therefore E[d(X) \u2022 u(X)] < E[d (X) \u2022 u(X)]. It remains to show that u (d ) > u (d) for arbitrary u \u2208 U. Let t = inf{u (x) : d (x) > d(x)}.\nNote that by construction for any x, x \u2208 X , if d (x) > d(x) and d (x ) < d(x ), then u(x) > t * > u(x ). It follows by consistency modulo \u03b1 that u (x) \u2265 t \u2265 u (x ), and, moreover, that at least one of the inequalities is strict. Without loss of generality, assume u (x) > t \u2265 u (x ).\nThen, we have that u(x) > t * if and only if u (x) > t . Therefore, it follows that\nE[(d (X) \u2212 d(X)) \u2022 1 u (X)>t ] = m Up > 0. Since E[d (X) \u2212 d(X)] = 0, we see that E[(d (X) \u2212 d(X)) \u2022 u (X)] = E[(d (X) \u2212 d(X)) \u2022 1 u (X)>t \u2022 u (X)] + E[(d (X) \u2212 d(X)) \u2022 1 u (X)\u2264t \u2022 u (X)] > t \u2022 E[(d (X) \u2212 d(X)) \u2022 1 u (X)>t ] + t \u2022 E[(d (X) \u2212 d(X)) \u2022 1 u (X)\u2264t ] = t \u2022 E[d (X) \u2212 d(X)] = 0,\nwhere in the inequality we have used the fact that if The following results, which draw on Lemma D.2, are useful in the proof of Theorem 1.\nd (x) > d(x), u (x) > t , and if d (x) < d(x), u (x) \u2264 t . There- fore E[d(X) \u2022 u (X)] < E[d (X) \u2022 u (X)], i.e., d(\nDefinition D.2. We say that a decision policy d(x) is budget-exhausting if min(b, Pr(u(X) > 0)) \u2264 E[d(X)] \u2264 min(b, Pr(u(X) \u2265 0)).\nRemark 2. We note that if U is consistent modulo \u03b1, then whether or not a decision policy d(x) is budget-exhausting does not depend on the choice of u \u2208 U. Further, if Pr(u(X) = 0) = 0-e.g., if the distribution of X is Ufine-then the decision policy is budget-exhausting if and only if E[d(X)] = min(b, Pr(u(X) > 0)).\nCorollary D.1. Let U be a collection of utilities consistent modulo \u03b1. If \u03c4 (x) is a feasible policy that is not a budget-exhausting multiple threshold policy with nonnegative thresholds, then \u03c4 (x) is strongly Pareto dominated.\nProof. Suppose \u03c4 (x) is not strongly Pareto dominated. By Lemma D.2, it is a multiple threshold policy with nonnegative thresholds. Now, suppose toward a contradiction that \u03c4 (x) is not budgetexhausting. Then, either E[\u03c4 (X)] > min(b, Pr(u(X) \u2265 0)) or E[\u03c4 (X)] < min(b, Pr(u(X) > 0)).\nIn the first case, since \u03c4 (x) is feasible, it follows that E[\u03c4 (X)] > Pr(u(X) \u2265 0). It follows that \u03c4 (x) \u2022 1 u(x)<0 is not almost surely zero. Therefore\nE[\u03c4 (X)] < E[\u03c4 (X) \u2022 1 u(X)>0 ],\nand, by consistency modulo \u03b1, this holds for any u \u2208 U. Therefore \u03c4 (x) is strongly Pareto dominated, contrary to hypothesis.\nIn the second case, consider\nd(x) = \u03b8 \u2022 1 u(x)>0 + (1 \u2212 \u03b8) \u2022 \u03c4 (x).\nSince E[\u03c4 (X)] < min(b, Pr(u(X) > 0)) and\nE[d(X)] = \u03b8 \u2022 Pr(u(X) > 0) + (1 \u2212 \u03b8) \u2022 E[\u03c4 (X)],\nthere exists some \u03b8 > 0 such that d(x) is feasible.\nFor that \u03b8, a similar calculation shows immediately that u(d) > u(\u03c4 ), and, by consistency modulo \u03b1, u (d) > u (\u03c4 ) for all u \u2208 U. Therefore, again, d(x) strongly Pareto dominates \u03c4 (x), contrary to hypothesis.\nLemma D.3. Given a utility u, there exists a mapping T from [0, 1] A to [\u2212\u221e, \u221e] A taking sets of quantiles {q a } a\u2208A to thresholds {t a } a\u2208A such that:\n1. T is monotonically non-increasing in each coordinate; 2. For each set of quantiles, there is a multiple threshold policy \u03c4 : X \u2192 [0, 1] with thresholds T ({q a }) with respect to u such that E[\u03c4 (X\n) | A = a] = q a .\nProof. Simply choose\nt a = inf{s \u2208 R : Pr(u(X) > s) < q a }.(11)\nThen define\np a = qa\u2212Pr(u(X)>ta|A=a) Pr(u(X)=ta|A=a) Pr(u(X) = t a , A = a) > 0 0 Pr(u(X) = t a , A = a) = 0. Note that Pr(u(X) \u2265 t a | A = a) \u2265 q a , since, by defi- nition, Pr(u(X) > t a \u2212 | A = a) \u2265 q a for all > 0. Therefore, Pr(u(X) > t a | A = a) + Pr(u(X) = t a | A = a) \u2265 q a ,\nand so p a \u2264 1. Further, since Pr(u(X) > t a | A = a) \u2264 q a , we have that p a \u2265 0.\nFinally, let\nd(x) = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 1 u(x) > t \u03b1(x) , p a u(x) = t \u03b1(x) , 0 u(x) < t \u03b1(x) ,\nand it follows immediately that E[d(X\n) | A = a] = q a .\nThat t a is a monotonically non-increasing function of q a follows immediately from Eq. (11).\nWe can further refine Cor. D.1 and Lemma D.3 as follows:\nLemma D.4. Let u be a utility. Then a feasible policy is utility maximizing if and only if it is a budget-exhausting threshold policy. Moreover, there exists at least one utility maximizing policy.\nProof. Let\u1fb1 be a constant map, i.e.,\u1fb1 : X \u2192\u0100, where |\u0100| = 1. Then U = {u} is consistent modulo\u1fb1, and so by Cor. D.1, any Pareto efficient policy is a budget exhausting multiple threshold policy relative to U. Since U contains a single element, a policy is Pareto efficient if and only if it is utility maximizing. Since\u1fb1 is constant, a policy is a multiple threshold policy relative to\u1fb1 if and only if it is a threshold policy. Therefore, a policy is utility maximizing if and only if it is a budget exhausting threshold policy. By Lemma D.3, such a policy exists, and so the maximum is attained.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "E. Prevalence and the Proof of Theorem 1", "text": "The notion of a probabilistically \"small\" set-such as the event in which an idealized dart hits the exact center of a target-is, in finite-dimensional real vector spaces, typically encoded by the idea of a Lebesgue null set.\nHere we prove that the set of distributions such that there exists a policy satisfying either counterfactual equalized odds, conditional principal fairness, or counterfactual fairness that is not strongly Pareto dominated is \"small\" in an analogous sense. The proof turns on the following intuition. Each of the fairness definitions imposes a number of constraints. By Lemma D.2, any policy that is not strongly Pareto dominated is a multiple threshold policy. By adjusting the group-specific thresholds of such a policy, one can potentially satisfy one constraint per group. If there are more constraints than groups, then one has no additional degrees of freedom that can be used to ensure that the remaining constraints are satisfied. If, by chance, those constraints are satisfied with the same threshold policy, they are not satisfied robustly-even a minor distribution shift, such as increasing the amount of mass above the threshold by any amount on the relevant subpopulation, will break them. Therefore, over a \"typical\" distribution, at most |A| of the constraints can simultaneously be satisfied by a Pareto efficient policy, meaning that typically no Pareto efficient policy fully satisfies all of the conditions of the fairness definitions.\nFormalizing this intuition, however, requires considerable care. In Section E.1, we give a brief introduction to a popular generalization of null sets to infinite-dimensional vector spaces, drawing heavily on a review article by Ott & Yorke (2005). In Section E.2 we provide a roadmap of the proof itself. In Section E.3, we establish the main hypotheses necessary to apply the notion of prevalence to a convex set-in our case, the set of U-fine distributions. In Section E.4, we establish a number of technical lemmata used in the proof of Theorem 1, and provide a proof of the theorem itself in Section E.5. In Section E.6, we show why the hypothesis of U-fineness is important and how conspiracies between atoms in the distribution of u(X) can lead to \"robust\" counterexamples.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "E.1. Shyness and Prevalence", "text": "Lebesgue measure \u03bb n on R n has a number of desirable properties:\n\u2022 Local finiteness: For any point v \u2208 R n , there exists an open set U containing x such that \u03bb n [U ] < \u221e;\n\u2022 Strict positivity: For any open set U , if \u03bb n [U ] = 0, then U = \u2205;\n\u2022 Translation invariance: For any v \u2208 R n and measurable set E, \u03bb\nn [E + v] = \u03bb n [E].\nNo measure on an infinite-dimensional, separable Banach space, such as L 1 (R), can satisfy these three properties (Ott & Yorke, 2005). However, while there is no generalization of Lebesgue measure to infinite dimensions, there is a generalization of Lebesgue null sets-called shy sets-to the infinite-dimensional context that preserves many of their desirable properties. Hunt et al. (1992)). Let V be a completely metrizable topological vector space. We say that a Borel set E \u2286 V is shy if there exists a Borel measure \u00b5 on V such that:\nDefinition E.3 (\n1. There exists compact\nC \u2286 V such that 0 < \u00b5[C] < \u221e, 2. For all v \u2208 V , \u00b5[E + v] = 0.\nAn arbitrary set F \u2286 V is shy if there exists a shy Borel set E \u2286 V containing F .\nWe say that a set is prevalent if its complement is shy.\nPrevalence generalizes the concept of Lebesgue \"full measure\" or \"co-null\" sets (i.e., sets whose complements have null Lebesgue measure) in the following sense: Hunt et al. (1992)). Let V be a completely metrizable topological vector space. Then:\nProposition E.3 (\n\u2022 Any prevalent set is dense in V ;\n\u2022 If G \u2286 L and G is prevalent, then L is prevalent;\n\u2022 A countable intersection of prevalent sets is prevalent;\n\u2022 Every translate of a prevalent set is prevalent;\n\u2022 If V = R n , then G \u2286 R n is prevalent if and only if \u03bb n [R n \\ G] = 0.\nAs is conventional for sets of full measure in finitedimensional spaces, if some property holds for every v \u2208 E, where E is prevalent, then we say that the property holds for almost every v \u2208 V or that it holds generically in V .\nPrevalence can also be generalized from vector spaces to convex subsets of vector spaces, although additional care must be taken to ensure that a relative version of Prop. E.3 holds.\nDefinition E.4 (Anderson & Zame (2001)). Let V be a topological vector space and let C \u2286 V be a convex subset completely metrizable in the subspace topology induced by V . We say that a universally measurable set E \u2286 C is shy in C at c \u2208 C if for each 1 \u2265 \u03b4 > 0, and each neighborhood U of 0 in V , there is a regular Borel measure \u00b5 with compact support such that\nSUPP(\u00b5) \u2286 (\u03b4(C \u2212 c) + c) \u2229 (U + c),and\n\u00b5[E + v] = 0 for every v \u2208 V . We say that E is shy in C or shy relative to C if E is shy in C at c for every c \u2208 C. An arbitrary set F \u2286 V is shy in C if there exists a universally measurable shy set E \u2286 C containing F . A set G is prevalent in C if C \\ G is shy in C.\nProposition E.4 (Anderson & Zame (2001)). If E is shy at some point c \u2208 C, then E is shy at every point in C and hence is shy in C.\nSets that are shy in C enjoy similar properties to sets that are shy in V .\nProposition E.5 (Anderson & Zame (2001)). Let V be a topological vector space and let C \u2286 V be a convex subset completely metrizable in the subspace topology induced by V . Then:\n\u2022 Any prevalent set in C is dense in C; \u2022 If G \u2286 L and G is prevalent in C, then L is prevalent in C; \u2022 A countable intersection of sets prevalent in C is preva- lent in C \u2022 If G is prevalent in C then G + v is prevalent in C + v for all v \u2208 V . \u2022 If V = R n and C \u2286 V is a convex subset with non- empty interior, then G \u2286 C is prevalent in C if and only if \u03bb n [C \\ G] = 0.\nSets that are shy in C can often be identified by inspecting their intersections with a finite-dimensional subspace W of V , a strategy we use to prove Theorem 1.\nDefinition E.5 (Anderson & Zame (2001)). A universally measurable set E \u2286 C, where C is convex and completely metrizable, is said to be k-shy in C if there exists a k-\ndimensional subspace W \u2286 V such that 1. A translate of the set C has positive Lebesgue measure in W , i.e., \u03bb W [C + v 0 ] > 0 for some v 0 \u2208 V ; 2. Every translate of the set E is a Lebesgue null set in W , i.e., \u03bb W [E + v] = 0 for all v \u2208 V .\nHere \u03bb W denotes k-dimensional Lebesgue measure supported on W . 13 We refer to such a W as a k-dimensional probe witnessing the k-shyness of E, and to an element w \u2208 W as a perturbation.\nThe following intuition motivates the use of probes to detect shy sets. By analogy with Fubini's theorem, one can imagine trying to determine whether a subset of a finite-dimensional vector space is large or small by looking at its cross sections parallel to some subspace\nW \u2286 V . If a set E \u2286 V is small in each cross section-i.e., if \u03bb W [E + v] = 0 for all v \u2208 V -then E itself is small in V , i.e., E has \u03bb V -measure zero. Proposition E.6 (Anderson & Zame (2001)). Every k-shy set in C is shy in C.", "publication_ref": ["b0", "b0", "b0", "b0"], "figure_ref": [], "table_ref": []}, {"heading": "E.2. Outline", "text": "To aid the reader in following the application of the theory in Section E.1 to the proof of Theorem 1, we provide the following outline of the argument.\nIn Section E.3 we establish the context to which we apply the notion of relative shyness. In particular, we introduce 13 Note that Lebesgue measure on W is only defined up to a choice of basis; however, since \u03bb[T (A)] = | det(T )| \u2022 \u03bb[A] for any linear automorphism T and Lebesgue measure \u03bb, whether a set has null measure does not depend on the choice of basis. the vector space K consisting of the totally bounded Borel measures on the state space K-where K is X \u00d7 Y, X \u00d7 Y \u00d7Y, or A\u00d7X A , depending on which notion of fairness is under consideration. We further isolate the subspace K \u2286 K of U-fine totally bounded Borel measures. Within this space, we are interested in the convex set Q \u2286 K, the set of Ufine joint probability distributions of, respectively, X and Y (1); X, Y (0), Y (1); or A and the X \u03a0,A,a . Within Q, we identify E \u2286 Q, the set of U-fine distributions on K over which there exists a policy satisfying the relevant fairness definition that is not strongly Pareto dominated. The claim of Theorem 1 is that E is shy relative to Q.\nTo ensure that relative shyness generalizes Lebesgue null measure in the expected way-i.e., that Prop. E.5 holds-Definition E.4 has three technical requirements: (1) that the ambient vector space V be a topological vector space; (2) that the convex set C be completely metrizable; and (3) that the shy set E be universally measurable. In Lemma E.7, we observe that K is a complete topological vector space under the total variation norm, and so is a Banach space. We extend this in Cor. E.2, showing that K is also a Banach space. We use this fact in Lemma E.11 to show that Q is a completely metrizable subset of K, as well as convex. Lastly, in Lemma E.13, we show that the set E is closed, and therefore universally measurable.\nIn Section E.4, we develop the machinery needed to construct a probe W for the proof of Theorem 1 and prove several lemmata simplifying the eventual proof of the theorem. To build the probe, it is necessary to construct measures \u00b5 max,a with maximal support on the utility scale. This ensures that if any two threshold policies produce different decisions on any \u00b5 \u2208 K, they will produce different decisions on typical perturbations. The construction of the \u00b5 max,a , is carried out in Lemma E.14 and Cor. E.3. Next, we introduce the basic style of argument used to show that a subset of Q is shy in Lemma E.15 and Lemma E.16, in particular, by showing that the set of \u00b5 \u2208 Q that give positive probability to an event E is either prevalent or empty. We use then use a technical lemma, Lemma E.17, to show, in effect, that a generic element of Q has support on the utility scale wherever a given fixed distribution \u00b5 \u2208 Q does. In Defn. E.12, we introduce the concept of overlapping and splitting utilities, and show in Lemma E.19 that this property is generic in Q unless there exists a \u03c9-stratum that contains no positive-utility observables x. Lastly, in Lemma E.20, we provide a mild simplification of the characterization of finitely shy sets that makes the the proof of Theorem 1 more straightforward.\nFinally, in Section E.5, we give the proof of Theorem 1. We divide the proof into three parts. In the first part, we restrict our attention to the case of counterfactual equalized odds, and show in detail how to combine the lemmata of the previous section to construct the (at most) 2 \u2022 |A|dimensional probe W. In the second part we consider two distinct cases. The argument in both cases is conceptually parallel. First, we argue that the balance conditions of counterfactual equalized odds encoded by Eq. (2) must be broken by a typical perturbation in W. In particular, we argue that for a given base distribution \u00b5, there can be at most one budget-exhausting multiple threshold policy that can-although need not necessarily-satisfy counterfactual equalized odds. We show that the form of this policy cannot be altered by an appropriate perturbation in W, but that the conditional probability of a positive decision will, in general, be altered in such a way that Eq. (2) can only hold for a \u03bb W -null set of perturbations. In the final section, we lay out modiciations that can be made to the proof given for counterfactual equalized odds in the first two parts that adapt the argument to the cases of conditional principal fairness and path-specific fairness. In particular, we show how to construct the probe W in such a way that the additional conditioning on the reduced covariates W = \u03c9(X) in Eqs. ( 3) and ( 5) does not affect the argument.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "E.3. Convexity, Complete Metrizability, and Universal Measurability", "text": "In this section, we establish the background requirements of Prop. E.6 for the setting of Theorem 1. In particular, we exhibit the U-fine distributions as a convex subset of a topological vector space, the set of totally bounded U-fine Borel measures. We show that the U-fine probability distributions form a completely metrizable subset in the topology it inherits from the space of totally bounded measures. Lastly, we show that the set of regular distributions under which there exists a Pareto efficient policy satisfying one of the three fairness criteria is closed, and therefore universally measurable.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "E.3.1. BACKGROUND AND NOTATION", "text": "We begin by establishing some notational conventions. We let K denote the underlying state space over which the distributions in Theorem 1 range. Specifically, K = X \u00d7 Y in the case of counterfactual equalized odds; K = X \u00d7 Y \u00d7 Y in the case of conditional principal fairness; and K = A \u00d7 X A in the case of path-specific fairness. We note that since X \u2286 R k for some k and Y \u2286 R, K may equivalently be considered a subset of R n for some n \u2208 N, with the subspace topology (and Borel sets) inherited from R n . 14 We recall the definition of totally bounded measures.\nDefinition E.6. Let M be a \u03c3-algebra on V , and let \u00b5 be a countably additive (V, M)-measure. Then, we define\n|\u00b5|[E] = sup \u221e i=1 |\u00b5[E i ]| (12)\nwhere the supremum is taken over all countable partitions {E i } i\u2208N , i.e., collections such that \u221e i=1 E i = E and E i \u2229 E j = \u2205 for j = i. We call |\u00b5| the total variation of \u00b5, and the total variation norm of \u00b5 is |\u00b5|[V ].\nWe say that \u00b5 is totally bounded if its total variation norm is finite, i.e., |\u00b5|[V ] < \u221e. Lemma E.5. If \u00b5 is totally bounded, then |\u00b5| is a finite positive measure on (V, M), and\n|\u00b5[E]| \u2264 |\u00b5|[E] for all E \u2208 M.\nSee Theorem 6.2 in Rudin (1987) for proof.\nWe let K denote the set of totally bounded Borel measures on K. We note that, in the case of path specific fairness, which involves the joint distributions of counterfactuals, X is not defined directly. Rather, the joint distribution of the counterfactuals X \u03a0,A,a and A defines the distribution of X through consistency, i.e., what would have happened to someone if their group membership were changed to a \u2208 A is what actually happens to them if their group membership is a . More formally, Pr(X \u2208\nE | A = a ) = Pr(X \u03a0,A,a \u2208 E | A = a ) for all Borel sets E \u2286 X . (See \u00a7 3.6.3 in Pearl (2009b).)\nFor any \u00b5 \u2208 K, we adopt the following notational conventions. If we say that a property holds \u00b5-a.s., then the subset of K on which the property fails has |\u00b5|-measure zero. If E \u2286 K is a measurable set, then we denote by \u00b5 E the restriction of \u00b5 to E, i.e., the measure defined by the map-\nping E \u2192 \u00b5[E \u2229 E ].\nWe let E \u00b5 [f ] = K f d\u00b5, and for measurable sets E, Pr \u00b5 (E) = \u00b5[E]. 15 The fairness criteria we consider involve conditional independence relations. To make sense of conditional independence relations more generally, for Borel measurable f we define E \u00b5 [f | F] to be the Radon-Nikodym derivative of the measure\nE \u2192 E \u00b5 [f \u2022 1 E ]\nwith respect to the measure \u00b5 restricted to the sub-\u03c3-algebra of Borel sets F. (See \u00a7 34 in Billingsley (1995).) Similarly, we define\nE \u00b5 [f | g] to be E \u00b5 [f | \u03c3(g)],\nwhere \u03c3(g) denotes the sub-\u03c3-algebra of the Borel sets generated by g. In cases where the condition can occur with non-zero probability, we can instead make use of the elementary definition of discrete conditional probability. Lemma E.6. Let g be a Borel function on K, and suppose Pr \u00b5 (g = c) = 0 for some constant c \u2208 R. Then, we have that \u00b5-a.s., for any Borel function f ,\nE \u00b5 [f | g] \u2022 1 g=c = E \u00b5 [f \u2022 1 g=c ] Pr \u00b5 (g = c) \u2022 1 g=c .\nSee Rao ( 2005) for proof.\nWith these notational conventions in place, we turn to establishing the background conditions of Prop. E.6.\nLemma E.7. The set of totally bounded measures on a measure space (V, M) form a complete topological vector space under the total variation norm, and hence a Banach space.\nSee, e.g., Steele (2019) for proof. It follows from this that K is a Banach space. Remark 3. Since K is a Banach space, it possesses a topology, and consequently a collection of Borel subsets. These Borel sets are to be distinguished from the Borel subsets of the underlying state space K, which the elements of K measure. The requirement that the subset E of the convex set C be universally measurable in Proposition E.6 is in reference to the Borel subsets of K; the requirement that \u00b5 \u2208 K be a Borel measure is in reference to the Borel subsets of K.\nRecall the definition of absolute continuity.\nDefinition E.7. Let \u00b5 and \u03bd be measures on a measure space (V, M). We say that a measure \u03bd is absolutely continuous with respect to \u00b5-also written \u03bd \u00ce \u00b5-if, whenever\n\u00b5[E] = 0, \u03bd[E] = 0.\nAbsolute continuity is a closed property in the topology induced by the total variation norm.\nLemma E.8. Consider the space of totally bounded measures on a measure space (V, M) and fix \u00b5. The set of \u03bd such that \u03bd \u00ce \u00b5 is closed.\nProof. Let {\u03bd i } i\u2208N be a convergent sequence of measures absolutely continuous with respect to \u00b5. Let the limit of the \u03bd i be \u03bd. We seek to show that \u03bd \u00ce \u00b5. Let E \u2208 M be an arbitrary set such that \u00b5[E] = 0. Then, we have that\n\u03bd[E] = lim n\u2192\u221e \u03bd i [E] = lim n\u2192\u221e 0 = 0, since \u03bd i \u00ce \u00b5 for all i.\nSince E was arbitrary, the result follows.\nRecall the definition of a pushforward measure.\nDefinition E.8. Let f : (V, M) \u2192 (V , M ) be a measurable function. Let \u00b5 be a measure on V . We define the pushforward measure \u00b5\n\u2022 f \u22121 on V by the map E \u2192 \u00b5[f \u22121 (E )] for E \u2208 M .\nWithin K, in the case of counterfactual equalized odds and conditional principal fairness, we define the subspace K to be the set of totally bounded measures \u00b5 on K such that the pushforward measure \u00b5 \u2022 u \u22121 is absolutely continuous with respect to the Lebesgue measure \u03bb on R for all u \u2208 U. By the Radon-Nikodym theorem, these pushforward measures arise from densities, i.e., for any \u00b5 \u2208 K, there exists a unique f \u00b5 \u2208 L 1 (R) such that for any measurable subset E of R, we have\n\u00b5 \u2022 u \u22121 [E] = E f \u00b5 d\u03bb.\nIn the case of path-specific fairness, we require the joint distributions of the counterfactual utilities to have a joint density. That is, we define the subspace K to be the set of totally bounded measures \u00b5 on K such that the pushforward measure \u00b5 \u2022 (u A ) \u22121 is absolutely continuous with respect to Lebesgue measure on R A for all u \u2208 U. Here, we recall that\nu A : (a, (x a ) a \u2208A ) \u2192 (u(x a )) a \u2208A .\nAs before, there exists a corresponding density f \u00b5 \u2208 L 1 (R A ).\nWe therefore see that K extends in a natural way the notion of a Uor U A -fine distribution, and so, by a slight abuse of notation, refer to K as the set of U-fine measures on K.\nIndeed, since Pr \u00b5 (u(X) \u2208 E, A = a) \u2264 Pr \u00b5 (u(X) \u2208 E), it also follows that, for a \u2208 A such that Pr \u00b5 (A = a) > 0, the conditional distributions of u(X) | A = a are also absolutely continuous with respect to Lebesgue measure, and so also have densities. For notational convenience, we set f \u00b5,a to be the function satisfying\nPr \u00b5 (u(X) \u2208 E, A = a) = E f \u00b5,a d\u03bb, so that f \u00b5 = a\u2208A f \u00b5,a .\nSince absolute continuity is a closed condition, it follows that K is a closed subspace of K. This leads to the following useful corollary of Lemma E.8.\nCorollary E.2. The collection of U-fine measures on K is a Banach space.\nProof. It is straightforward to see that K is a subspace of K. Since K is a closed subset of K by Lemma E.8, it is complete, and therefore a Banach space.\nWe note the following useful fact about elements of K.\nLemma E.9. Consider the mapping \u00b5 \u2192 f \u00b5 from K to L 1 (R) given by associating a measure \u00b5 with the Radon-Nikodym derivative of the pushforward measure \u00b5 \u2022 u \u22121 . This mapping is continuous. Likewise, the mapping \u00b5 \u2192 f \u00b5,a is continuous for all a \u2208 A, and, in the case of pathspecific fairness, the mapping of \u00b5 to the Radon-Nikodym derivative of \u00b5 \u2022 (u A ) \u22121 is continuous.\nProof. We show only the first case. The others follow by virtually identical arguments.\nLet > 0 be arbitrary. Choose \u00b5 \u2208 K, and suppose that |\u00b5 \u2212 \u00b5 |[K] < . Then, let\nE Up = {x \u2208 R : f \u00b5 (x) > f \u00b5 (x)} E Lo = {x \u2208 R : f \u00b5 (x) < f \u00b5 (x)}.\nThen E Up and E Lo are disjoint, so we have that\nf \u00b5 \u2212 f \u00b5 L 1 (R) = E Up f \u00b5 \u2212 f \u00b5 d\u03bb + E Lo f \u00b5 \u2212 f \u00b5 d\u03bb = |(\u00b5 \u2212 \u00b5 )[u \u22121 (E Up )]| + |(\u00b5 \u2212 \u00b5 )[u \u22121 (E Lo )]| < ,\nwhere the second equality follows by the definition of pushforward measures and the inequality follows from Lemma E.5. Since was arbitrary, the claim follows.\nFinally, we define Q. We let Q be the subset of K consisting of all U-fine probability measures, i.e., measures \u00b5 \u2208 K such that:\n1. The measure \u00b5 is U-fine;\n2. For all Borel sets E \u2286 K, \u00b5[E] \u2265 0;\n3. The measure of the whole space is unity, i.e., \u00b5[K] = 1.\nWe conclude the background and notation by observing that threshold policies are defined wholly by their thresholds for distributions in K and Q. Importantly, this observation does not hold when there are atoms on the utility scale-which measures in K lack-which can in turn lead to counterexamples to Theorem 1; see Appendix E.6. Lemma E.10. Let \u03c4 0 (x) and \u03c4 1 (x) be two multiple threshold policies. If \u03c4 0 (x) and \u03c4 1 (x) have the same thresholds, then for any \u00b5 \u2208 K, \u03c4 0 (X) = \u03c4 1 (X) \u00b5-a.s. Similarly, for\n\u00b5 \u2208 Q, if E \u00b5 [\u03c4 0 (X) | A = a] = E \u00b5 [\u03c4 1 (X) | A = a]\nfor all a \u2208 A such that Pr \u00b5 (A = a) > 0, then \u03c4 0 (X) = \u03c4 1 (X) \u00b5-a.s.\nMoreover, for \u00b5 \u2208 K in the case of path-specific fairness, if \u03c4 0 (x) and \u03c4 1 (x) have the same thresholds, then \u03c4 0 (X \u03a0,A,a ) = \u03c4 1 (X \u03a0,A,a ) \u00b5-a.s. for any a \u2208 A. Similarly, for \u00b5 \u2208 Q in the case of path-specific fairness, if\nE \u00b5 [\u03c4 0 (X \u03a0,A,a )] = E \u00b5 [\u03c4 1 (X \u03a0,A,a )]\nthen \u03c4 0 (X \u03a0,A,a ) = \u03c4 1 (X \u03a0,A,a ) \u00b5-a.s. as well.\nProof. First, we show that threshold policies with the same thresholds are equal, then we show that threshold policies that distribute positive decisions across groups in the same way are equal.\nLet {t a } a\u2208A denote the shared set of thresholds. It follows that if \u03c4 0 (x) = \u03c4 1 (x), then u(x) = t \u03b1(x) . Now,\nPr(u(X) = t a , A = a) = ta ta f \u00b5,a d\u03bb = 0, so Pr \u00b5 (\u03c4 0 (X) = \u03c4 1 (X)) = 0. Next, suppose E \u00b5 [\u03c4 0 (X) | A = a] = E \u00b5 [\u03c4 1 (X) | A = a].\nIf the thresholds of the two policies agree for all a \u2208 A such that Pr \u00b5 (A = a) > 0, then we are done by the previous paragraph. Therefore, suppose t 0 a = t 1 a for some suitable a \u2208 A, where t i a represents the threshold for group a \u2208 A under the policy \u03c4 i (x). Without loss of generality, suppose t 0 a < t 1 a . Then, it follows that\nt 1 a t 0 a f \u00b5,a d\u03bb = E \u00b5 [\u03c4 0 (X) | A = a] \u2212 E \u00b5 [\u03c4 1 (X) | A = a] = 0. Since \u00b5 \u2208 Q, \u00b5 = |\u00b5|, whence Pr |\u00b5| (t a 0 \u2264 u(X) \u2264 t 1 a | A = a) = 0.\nSince this is true for all a \u2208 A such that Pr \u00b5 (A = a) > 0, \u03c4 0 (X) = \u03c4 1 (X) \u00b5-a.s.\nThe proof in the case of path-specific fairness is almost identical.", "publication_ref": ["b5"], "figure_ref": [], "table_ref": []}, {"heading": "E.3.2. CONVEXITY, COMPLETE METRIZABILITY, AND UNIVERSAL MEASURABILITY", "text": "The set of regular U-fine probability measures Q is the set to which we wish to apply Prop. E.6. To do so, we must show that Q is a convex and completely metrizable subset of K. Lemma E.11. The set of regular probability measures Q is convex and completely metrizable.\nProof. The proof proceeds in two pieces. First, we show that the U-fine probability distributions are convex, as can be verified by direct calculation. Then, we show that Q is closed and therefore complete in the original metric of K.\nWe begin by verifying convexity. Let \u00b5, \u00b5 \u2208 Q and let E \u2286 K be an arbitrary Borel subset of K. Then, choose \u03b8 \u2208 [0, 1], and note that\n(\u03b8 \u2022 \u00b5 + [1 \u2212 \u03b8] \u2022 \u00b5 )[E] = \u03b8 \u2022 \u00b5[E] + [1 \u2212 \u03b8] \u2022 \u00b5 [E] \u2265 \u03b8 \u2022 0 + [1 \u2212 \u03b8] \u2022 0 = 0, and, likewise, that (\u03b8 \u2022 \u00b5 + [1 \u2212 \u03b8] \u2022 \u00b5 )[K] = \u03b8 \u2022 \u00b5[K] + [1 \u2212 \u03b8] \u2022 \u00b5 [K] = \u03b8 \u2022 1 + [1 \u2212 \u03b8] \u2022 1 = 1.\nIt remains only to show that Q is completely metrizable. To prove this, it suffices to show that it is closed, since closed subsets of complete spaces are complete, and K is a Banach space by Cor. E.2, and therefore complete.\nSuppose {\u00b5 i } i\u2208N is a convergent sequence of probability measures in K with limit \u00b5. Then\n\u00b5[E] = lim i\u2192\u221e \u00b5 i [E] \u2265 lim i\u2192\u221e 0 = 0 and \u00b5[K] = lim i\u2192\u221e \u00b5 i [K] = lim i\u2192\u221e 1 = 1.\nTherefore Q is closed, and therefore complete, and hence is a convex, completely metrizable subset of K.\nNext we prove that the set E of regular U-fine densities over which there exists a policy satisfying the relevant counterfactual fairness definition that is not strongly Pareto dominated is universally measurable.\nRecall the definition of universal measurability.\nDefinition E.9. Let V be a complete topological space.\nThen E \u2286 V is universally measurable if V is measurable by the completion of every finite Borel measure on V , i.e., if for every finite Borel measure \u00b5, there exist Borel sets E and S such that E E \u2286 S and \u00b5[S] = 0.\nWe note that if a set is Borel, it is by definition universally measurable. Moreover, if a set is open or closed, it is by definition Borel.\nTo show that E is closed, we show that any convergent sequence in E has a limit in E. The technical complication of the argument stems from the following fact that satisfying the fairness conditions, e.g., Eq. (4), involves conditional expectations, about which very little can be said in the absence of a density, and which are difficult to compare when taken across distinct measures.\nTo handle these difficulties, we begin with a technical lemma, Lemma E.12, which gives a coarse bound on how different the conditional expectations of the same variable can be with respect to a sub-\u03c3-algebra F over two different distributions, \u00b5 and \u00b5 , before applying the results to the proof of Lemma E.13.\nDefinition E.10. Let \u00b5 be a measure on a measure space (V, M), and let f be \u00b5-measurable. Consider the equivalence class of M-measurable functions C = {g : g = f \u00b5-a.e.}. 16 We say that any g \u2208 C is a version of f , and that g \u2208 C is a standard version if g(v) \u2264 C for some constant C and all v \u2208 V .\nRemark 4. It is straightforward to see that for f \u2208 L \u221e (\u00b5), a standard version always exists with C = f \u221e .\nRemark 5. Note that in general, the conditional expectation E \u00b5 [f | F] is defined only \u00b5 -a.e. If \u00b5 is not assumed to be absolutely continuous with respect to \u00b5 , it follows that\nE \u00b5 [f | F] \u2212 E \u00b5 [f | F] L 1 (\u00b5)(13)\nis not entirely well-defined, in that its value depends on what version of E \u00b5 [f | F] one chooses. For appropriate f , however, one can nevertheless bound Eq. ( 13) for any standard version of\nE \u00b5 [f | F].\nLemma E.12. Let \u00b5, \u00b5 be totally bounded measures on a measure space\n(V, M). Let f \u2208 L \u221e (\u00b5) \u2229 L \u221e (\u00b5 ). Let F be a sub-\u03c3-algebra of M. Let C = max( f L \u221e (\u00b5) , f L \u221e (\u00b5 ) ). Then, if g is a standard version of E \u00b5 [f | F], we have that V |E \u00b5 [f | F] \u2212 g| d\u00b5 \u2264 4C \u2022 |\u00b5 \u2212 \u00b5 |[V ].(14)\nProof. First, we note that both E \u00b5 [f | F] and g are Fmeasurable. Therefore, the sets\nE Up = {v \u2208 V : E \u00b5 [f | F](v) > g(v)} and E Lo = {v \u2208 V : E \u00b5 [f | F](v) < g(v)} are in F. Now, note that V |E \u00b5 [f | F] \u2212 g| d\u00b5 = E Up E \u00b5 [f | F] \u2212 g d\u00b5 + E Lo g \u2212 E \u00b5 [f | F] d\u00b5.\nFirst consider E Up . Then, we have that\nE Up E \u00b5 [f | F] \u2212 g d\u00b5 = E Up E \u00b5 [f | F] \u2212 g d\u00b5 + E Up g \u2212 g d\u00b5 \u2264 E Up E \u00b5 [f | F] d\u00b5 \u2212 E Up g d\u00b5 + E up g d|\u00b5 \u2212 \u00b5 | \u2264 E Up f d\u00b5 \u2212 E Up f d\u00b5 + E up C d|\u00b5 \u2212 \u00b5 |,\nwhere in the final inequality, we have used the fact that, since g is a standard version of\nE \u00b5 [f | F], g(v) \u2264 E \u00b5 [f | F] L \u221e (\u00b5 ) \u2264 C\nfor all v \u2208 V , and the fact that, by the definition of conditional expectation,\nE E \u03bd [h | F] d\u03bd = E h d\u03bd for any E \u2208 F.\nSince f is everywhere bounded by C, applying Lemma E.5 yields that this final expression is less than or equal to 2C\n\u2022 |\u00b5 \u2212 \u00b5 |[V ]. An identical argument shows that E Lo g \u2212 E \u00b5 [f | F] d\u00b5 \u2264 2C \u2022 |\u00b5 \u2212 \u00b5 |[V ],\nwhence the result follows.\nLemma E.13. Let E \u2286 Q denote the set of joint densities on K such that there exists a policy satisfying the relevant fairness definition that is not strongly Pareto dominated.\nThen, E is closed, and therefore universally measurable.\nProof. For notational simplicity, we consider the case of counterfactual equalized odds. The proofs in the other two cases are virtually identical.\nSuppose \u00b5 i \u2192 \u00b5 in K, where {\u00b5 i } i\u2208N \u2286 E. Then, by Lemma E.9, f \u00b5i,a \u2192 f \u00b5,a in L 1 (R). Moreover, by Lemma D.2, there exists a sequence of threshold policies\n{\u03c4 i (x)} i\u2208N such that both E \u00b5i [\u03c4 (X)] = min(b, Pr \u00b5i (u(X) > 0)) and E \u00b5i [\u03c4 i (X) | A, Y (1)] = E \u00b5i [\u03c4 i (X) | Y (1)].\nLet {q a,i } a\u2208A be defined by\nq a,i = E \u00b5i [\u03c4 i (X) | A = a]\nif Pr \u00b5i (A = a) > 0, and q a,i = 0 otherwise. Since [0, 1] A is compact, there exists a convergent subsequence {{q a,ni } a\u2208A } i\u2208N . Let it converge to the collection of quantiles {q a } a\u2208A defining, by Lemma D.3, a multiple threshold policy \u03c4 (x) over \u00b5.\nBecause \u00b5 i \u2192 \u00b5 and {q a,ni } a\u2208A \u2192 {q a } a\u2208A , we have that\nE \u00b5 [\u03c4 a,ni (X) | A = a] \u2192 E \u00b5 [\u03c4 (X) | A = a]\nfor all a \u2208 A such that Pr \u00b5 (A = a) > 0. Therefore, by Lemma E.9, \u03c4 ni (X) \u2192 \u03c4 (X) in L 1 (\u00b5).\nChoose > 0 arbitrarily. Then, choose N so large that for i greater than N ,\n|\u00b5 \u2212 \u00b5 ni |[K] < 10 , \u03c4 (X) \u2212 \u03c4 ni (X) L 1 (\u00b5) \u2264 10 .\nThen, observe that \u03c4 (x), \u03c4 i (x) \u2264 1, and recall that\nE \u00b5n i [\u03c4 ni (X) | A, Y (1)] = E \u00b5n i [\u03c4 ni (X) | Y (1)]. (15)\nTherefore, let g i (x) be a standard version of\nE \u00b5n i [\u03c4 ni (X) | Y (1)] over \u00b5 ni . By Eq. (15), g i (x) is also a standard version of E \u00b5n i [\u03c4 ni (X) | A, Y (1)] over \u00b5 ni .\nThen, by Lemma E.12, we have that Since > 0 was arbitrary, it follows that, \u00b5-a.e.,\nE \u00b5 [\u03c4 (X) | A, Y (1)] \u2212 E \u00b5n i [\u03c4 ni (X) | Y (1)] L 1 (\u00b5) \u2264 E \u00b5 [\u03c4 (X) | A, Y (1)] \u2212 E \u00b5 [\u03c4 ni (X) | A, Y (1)] L 1 (\u00b5) + E \u00b5 [\u03c4 ni (X) | A, Y (1)] \u2212 g i (X) L 1 (\u00b5) + g i (X) \u2212 E \u00b5 [\u03c4 ni (X) | Y (1)] L 1 (\u00b5) L 1 (\u00b5) + E \u00b5 [\u03c4 ni (X) | Y (1) \u2212 E \u00b5 [\u03c4 (X) | Y (1)] L 1 (\u00b5)\nE \u00b5 [\u03c4 (X) | A, Y (1)] = E \u00b5 [\u03c4 (X) | Y (1)].\nRecall the standard fact that for independent random variables X and U ,\nE[f (X, U ) | X] = f (X, u) dF U (u),\nwhere F U is the distribution of U . 17 Further recall that D = 1 U D \u2264\u03c4 (X) , where U D \u22a5 \u22a5 X, Y (1). It follows that\nPr \u00b5 (D = 1 | X, Y (1)) = 1 0 1 u d <\u03c4 (X) d\u03bb(u d ) = \u03c4 (X).\n17 For a proof of this fact see, e.g., Brozius (2019).\nHence, by the law of iterated expectations,\nPr \u00b5 (D = 1 | A, Y (1)) = E \u00b5 [Pr \u00b5 (D = 1 | X, Y (1)) | A, Y (1)] = E \u00b5 [\u03c4 (X) | A, Y (1)] = E \u00b5 [\u03c4 (X) | Y (1)] = E \u00b5 [Pr \u00b5 (D = 1 | X, Y (1)) | Y (1)] = Pr \u00b5 (D = 1 | Y (1)).\nTherefore D \u22a5 \u22a5 A | Y (1) over \u00b5, i.e., counterfactual equalized odds holds for the decision policy \u03c4 (x) over the distribution \u00b5. Consequently \u00b5 \u2208 E, and so E is closed and therefore universally measurable.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "E.4. Shy Sets and Probes", "text": "We require a number of additional technical lemmata for the proof of Theorem 1. The probe must be constructed carefully, so that, on the utility scale, an arbitrary element of Q is absolutely continuous with respect to a typical perturbation. In addition, it is useful to show that a number of properties are generic to simplify certain aspects of the proof of Theorem 1. For instance, Lemma E.16 is used in Theorem 1 to show that a certain conditional expectation is generically well-defined, avoiding the need to separately treat certain corner cases.\nCor. E.3 concerns the construction of the probe used in the proof of Theorem 1. Lemmata E.17 to E.20 use Cor. E.3 to provide additional simplifications to the proof of Theorem 1.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "E.4.1. MAXIMAL SUPPORT", "text": "First, to construct the probe used in the proof of Theorem 1, we require elements \u00b5 \u2208 Q such that the densities f \u00b5 have \"maximal\" support. To produce such distributions, we use the following measure-theoretic construction.\nDefinition E.11. Let {E \u03b1 } \u03b3\u2208\u0393 be an arbitrary collection of \u00b5-measurable sets for some positive measure \u00b5 on a measure space (M, M). We say that E is the measure-theoretic\nunion of {E \u03b3 } \u03b3\u2208\u0393 if \u00b5[E \u03b3 \\ E] = 0 for all \u03b3 \u2208 \u0393 and E = \u221e i=1 E \u03b3i for some countable subcollection {\u03b3 i } \u2286 N.\nWhile measure-theoretic unions themselves are known (cf. Silva (2008), Rudin (1991), for completeness, we include a proof of their existence, which, to the best of our knowledge, is not found in the literature.\nLemma E.14. Let \u00b5 be a finite positive measure on a measure space (V, M). Then an arbitrary collection {E \u03b3 } \u03b3\u2208\u0393 of \u00b5-measurable sets has a measure-theoretic union.\nProof. For each countable subcollection \u0393 \u2286 \u0393, consider the \"error term\"\nr(\u0393 ) = sup \u03b3\u2208\u0393 \u00b5 \uf8ee \uf8f0 E \u03b3 \\ \u03b3 \u2208\u0393 E \u03b3 \uf8f9 \uf8fb\nWe claim that the infimum of r(\u0393 ) over all countable subcollections \u0393 \u2286 \u0393 must be zero.\nFor, toward a contradiction, suppose it were greater than or equal to > 0. Choose any set E \u03b31 such that \u00b5[E \u03b31 ] \u2265 . Such a set must exist, since otherwise r(\u2205) < . Choose\nE \u03b32 such that \u00b5[E \u03b32 \\ E \u03b31 ] > .\nAgain, some such set must exist, since otherwise r({\u03b3 1 }) < . Continuing in this way, we construct a countable collection {E \u03b3i } i\u2208N .\nTherefore, we see that\n\u00b5[V ] \u2265 \u00b5 n i=1 E \u03b3i = n i=1 \u00b5 \uf8ee \uf8f0 E \u03b3i \\ i j=1 E \u03b3j \uf8f9 \uf8fb .\nBy construction, every term in the final sum is greater than or equal to , contradicting the fact that \u00b5[V ] < \u221e.\nTherefore, there exist countable collections\n{\u0393 n } n\u2208N such that r(\u0393 n ) < 1 n . It follows immediately that for all n r n\u2208N \u0393 n \u2264 r(\u0393 k )\nfor any fixed k \u2208 N. Consequently,\nr n\u2208N \u0393 n = 0,\nand n\u2208N \u0393 n is countable.\nThe construction of the \"maximal\" elements used to construct the probe in the proof of Theorem 1 follows as a corollary of Lemma E.14\nCorollary E.3. There are measures \u00b5 max,a \u2208 Q such that for every a \u2208 A and any \u00b5 \u2208 K,\n\u03bb[SUPP(f \u00b5,a ) \\ SUPP(f \u00b5max,a )] = 0.\nProof. Consider the collection {SUPP(f \u00b5,a )} \u00b5\u2208K . By Lemma E.14, there exists a countable collection of measures {\u00b5 i } i\u2208N such that for any \u00b5 \u2208 K,\n\u03bb SUPP(f \u00b5,a ) \\ \u221e i=1 SUPP(f \u00b5i,a ) = 0,\nwhere, without loss of generality, we may assume that \u03bb[SUPP(f \u00b5i,a )] > 0 for all i \u2208 N. Such a sequence must exist, since, by the first hypothesis of Theorem 1, for every a \u2208 A, there exists \u00b5 \u2208 Q such that Pr \u00b5 (A = a) > 0. Therefore, we can define the probability measure \u00b5 max,a , where\n\u00b5 max,a = n i=1 2 \u2212i \u2022 |\u00b5 i A=a | |\u00b5 i A=a | [K]\n.\nIt follows immediately by construction that\nSUPP(f \u00b5max,a ) = \u221e i=1 SUPP(f \u00b5i,a ),\nand that \u00b5 max,a \u2208 Q.\nFor notational simplicity, we refer to SUPP(f \u00b5max,a ) as S a throughout.\nIn the case of conditional principal fairness and path-specific fairness, we need a mild refinement of the previous result that accounts for \u03c9.\nCorollary E.4. There are measures \u00b5 max,a,w \u2208 Q defined for every w \u2208 W = IMG(\u03c9) and any a \u2208 A such that for some \u03bd \u2208 K, Pr \u03bd (W = w, A = a) > 0. These measures have the property that for any \u00b5 \u2208 K,\n\u03bb[SUPP(f \u00b5 ,a,w ) \\ SUPP(f \u00b5max,a,w )] = 0,\nwhere f \u00b5 ,a,w is the density of the pushforward measure\n(\u00b5 W =w,A=a ) \u2022 u \u22121 .\nRecalling that | IMG(\u03c9)| < \u221e, the proof is the same as Cor. E.3, and we analogously refer to SUPP(f \u00b5max,a,w ) as S a,w . Here, we have assumed without loss of generality-as we continue to assume in the sequel-that for all w \u2208 W, there is some \u00b5 \u2208 K such that Pr \u00b5 (W = w) > 0. Remark 6. Because their support is maximal, the hypotheses of Theorem 1, in addition to implying that \u00b5 max,a is welldefined for all a \u2208 A, also imply that Pr \u00b5max,a (u(X) > 0) > 0. In the case of conditional principal fairness, they further imply that Pr \u00b5max,a (W = w) > 0 for all w \u2208 W and a \u2208 A. Likewise, in the case of path-specific fairness, they further imply that Pr \u00b5max,a (W = w i ) > 0 for i = 0, 1 and some a \u2208 A.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "E.4.2. SHY SETS AND PROBES", "text": "In the following lemmata, we demonstrate that a number of useful properties are generic in Q. We also demonstrate a short technical lemma, Lemma E.20, which allows us to use these generic properties to simplify the proof of Theorem 1.\nWe begin with the following lemma, which is useful in verifying that certain subspaces of K form probes.\nLemma E.15. Let W be a non-trivial finite dimensional subspace of K such that \u03bd[K] = 0 for all \u03bd \u2208 W. Then, there exists\n\u00b5 \u2208 K such that \u03bb W [Q \u2212 \u00b5] > 0. Proof. Set \u00b5 = n i=1 |\u03bd i | |\u03bd i |[K] ,\nwhere \u03bd 1 , . . . , \u03bd n form a basis of W. Then, if\n|\u03b2 i | \u2264 1 |\u03bdi|[K] , it follows that \u00b5 + n i=1 \u03b2 i \u2022 \u03bd i \u2208 Q. Since \u03bb n n i=1 \u2212 1 |\u03bd i |[K] , 1 |\u03bd i |[K] > 0, it follows that \u03bb W [Q \u2212 \u00b5] > 0.\nNext we show that, given a \u03bd \u2208 Q, a generic element of Q \"sees\" events to which \u03bd assigns non-zero probability. While Lemma E.18 alone in principle suffices for the proof of Theorem 1, we include Lemma E.16 both for conceptual clarity and to introduce at a high level the style of argument used in the subsequent lemmata and in the proof of Theorem 1 to show that a set is shy relative to Q. Lemma E.16. For a Borel set E \u2286 K, suppose there exists\n\u03bd \u2208 Q such that \u03bd[E] > 0. Then the set of \u00b5 \u2208 Q such that \u00b5[E] > 0 is prevalent.\nProof. First, we note that the set of \u00b5 \u2208 Q such that \u00b5[E] = 0 is closed and therefore universally measurable. For, if {\u00b5 i } i\u2208N \u2286 Q is a convergent sequence with limit \u00b5, then\n\u00b5[E] = lim n\u2192\u221e \u00b5 i [E] = lim n\u2192\u221e 0 = 0. Now, if \u00b5[E] > 0 for all \u00b5 \u2208 Q,\nthere is nothing to prove. Therefore, suppose that there exists \u03bd \u2208 Q such that \u03bd [E] = 0.\nNext, consider the measure\u03bd = \u03bd \u2212 \u03bd. Then, let W = SPAN(\u03bd). Since\u03bd = 0 and\n\u03bd[K] = \u03bd [K] \u2212 \u03bd[K] = 0, it follows by Lemma E.15 that \u03bb W [Q \u2212 \u00b5] > 0 for some \u00b5. Now, for arbitrary \u00b5 \u2208 Q, note that if (\u00b5 + \u03b2 \u2022\u03bd)[E] = 0, then \u00b5[E] \u2212 \u03b2 \u2022 \u03bd[E] = 0 i.e., \u03b2 = \u00b5[E] \u03bd[E] .\nA singleton has null Lebesgue measure, and so the set of \u03bd \u2208 W such that (\u00b5 + \u03bd)[E] = 0 is \u03bb W -null. Therefore, by Prop. E.6, the set of \u00b5 \u2208 Q such that \u00b5[E] = 0 is shy relative to Q, as desired.\nWhile Lemma E.16 shows that a typical element of Q \"sees\" individual events, in the proof of Theorem 1, we require a stronger condition, namely, that a typical element of Q \"sees\" certain uncountable collections of events. To demonstrate this more complex property, we require the following technical result, which is closely related to the real analysis folk theorem that any convergent uncountable \"sum\" can contain only countably many non-zero terms. (See, e.g., Benji (2020).)\nLemma E.17. Suppose \u00b5 is a totally bounded measure on (V, M), f and g are \u00b5-measurable real-valued functions, and g = 0 \u00b5-a.e. Then the set\nZ \u03b2 = {v \u2208 V : f (v) + \u03b2 \u2022 g(v) = 0}\nhas non-zero \u00b5 measure for at most countably many \u03b2 \u2208 R.\nProof. First, we show that for any countable collection\n{\u03b2 i } i\u2208N \u2286 R, the sum \u221e i=1 \u00b5[Z \u03b2i ] converges.\nThen, we show how this implies that \u00b5[Z \u03b2 ] = 0 for all but countably many \u03b2 \u2208 R.\nFirst, we note that for distinct \u03b2, \u03b2 \u2208 R,\nZ \u03b2 \u2229 Z \u03b2 \u2286 {v \u2208 V : (\u03b2 \u2212 \u03b2 ) \u2022 g(v) = 0}. Now, by hypothesis, \u00b5[{v \u2208 V : g(v) = 0}] = 0, and since \u03b2 \u2212 \u03b2 = 0, it follows that \u00b5[{v \u2208 V : (\u03b2 \u2212 \u03b2 ) \u2022 g(v) = 0}] = 0 as well. Consequently, it follows that if {Z \u03b2i } i\u2208N is a count- able collection of distinct elements of R, then \u221e i=1 \u00b5[Z \u03b2i ] = \u00b5 \u221e i=1 Z \u03b2i \u2264 \u00b5[V ] < \u221e. To see that this implies that \u00b5[Z \u03b2 ] > 0 for only countably many \u03b2 \u2208 R, let G \u2286 R consist of those \u03b2 such that \u00b5[Z \u03b2 ] \u2265 . Then G must be finite for all > 0, since otherwise we could form a collection {\u03b2 i } i\u2208N \u2286 G , in which case \u221e i=1 \u00b5[Z \u03b2i ] \u2265 \u221e i=1 = \u221e,\ncontrary to what was just shown. Therefore,\n{\u03b2 \u2208 R : \u00b5[Z \u03b2 ] > 0} = \u221e i=1 G 1/i is countable.\nWe now apply Lemma E.17 to the proof of the following lemma, which states, informally, that, under a generic element of Q, u(X) is supported everywhere it is supported under some particular fixed element of Q. For instance, Lemma E.17 can be used to show that for a generic element of Q, the density of u(X) | A = a is positive \u03bb Sa -a.e. Lemma E.18. Let \u03bd \u2208 Q and suppose \u03bd is supported on\nE, i.e., \u03bd[K \\ E] = 0. Then the set of \u00b5 \u2208 Q such that \u03bd \u2022 u \u22121 \u00ce (\u00b5 E ) \u2022 u \u22121 is prevalent relative to Q.\nLemma E.18 states, informally, that for generic \u00b5 \u2208 Q, f \u00b5 E is supported everywhere f \u03bd is supported.\nProof. We begin by showing that the set of \u00b5 \u2208 Q such that \u03bd \u2022 u \u22121 \u00ce (\u00b5 E ) \u2022 u \u22121 is Borel, and therefore universally measurable. Then, we construct a probe W and use it to show that this collection is finitely shy.\nTo begin, let U q denote the set of \u00b5 \u2208 Q such that\n\u03bd \u2022 u \u22121 [{|f \u00b5 E | = 0}] < q.\nWe note that U q is open. For, if \u00b5 \u2208 U q , then there exists some r > 0 such that\n\u03bd \u2022 u \u22121 [{|f \u00b5 E | < r}] < q. Let = q \u2212 \u03bd \u2022 u \u22121 [{|f \u00b5 E | < r}]. Now, since \u03bd \u2022u \u22121 \u00ce \u03bb, there exists a \u03b4 such that if \u03bb[E ] < \u03b4, then \u03bd \u2022 u \u22121 [E ] < . Choose \u00b5 arbitrarily so that |\u00b5 \u2212 \u00b5 |[K] < \u03b4 \u2022 r.\nThen, by Markov's inequality, we have that\n\u03bb[{|f \u00b5 E \u2212 f \u00b5 E | > r}] < \u03b4, i.e., \u03bd \u2022 u \u22121 [{f \u00b5 E \u2212 f \u00b5 E | > r}] < .\nNow, we note that by the triangle inequality, wherever\n|f \u00b5 E | = 0, either |f \u00b5 E | < r or |f \u00b5 E \u2212 f \u00b5 E | > r. Therefore \u03bb[{|f \u00b5 E | = 0}] \u2264 \u03bd \u2022 u \u22121 [{|f \u00b5 E \u2212 f \u00b5 E | > r}] + \u00b5 \u2022 u \u22121 [{|f \u00b5 E | < r] < + \u00b5 \u2022 u \u22121 [{|f \u00b5 E | < r] < q.\nWe conclude that \u00b5 \u2208 U q , and so U q is open.\nNote that \u03bd \u2022 u \u22121 \u00ce (\u00b5 E ) \u2022 u \u22121 if and only if \u03bb[SUPP(f \u03bd ) \\ SUPP(f \u00b5 E )] = 0.\nBy the definition of the support of a function, \u03bb SUPP(f\u00b5) \u00ce \u00b5 \u2022 u \u22121 . Therefore, it follows that\n\u03bb[SUPP(f \u00b5 ) \\ SUPP(f \u03bd E )] = 0 if and only if \u00b5 \u2022 u \u22121 [SUPP(f \u00b5 ) \\ SUPP(f \u03bd E )] = 0.\nThen, it follows immediately that the set of \u03bd \u2208 Q such that \u00b5\n\u2022 u \u22121 \u00ce (\u03bd E ) \u2022 u \u22121 is n i=1 U 1/i\n, which is, by construction, Borel, and therefore universally measurable.", "publication_ref": ["b2"], "figure_ref": [], "table_ref": []}, {"heading": "Now, since", "text": "Pr\n\u03bd (u(X) < t) = t \u2212\u221e f \u03bd d\u03bb\nis a continuous function of t, by the intermediate value theorem, there exists t such that Pr \u03bd (u(X) \u2208 S 0 ) = Pr \u03bd (u(X) \u2208 S 1 ), where S 0 = SUPP(f \u03bd ) \u2229 (\u2212\u221e, t) and\nS 1 = SUPP(f \u03bd ) \u2229 [t, \u221e). Then, we let \u03bd[E ] = E 1 u \u22121 (S0) \u2212 1 u \u22121 (S1) d\u03bd. Take W = SPAN(\u03bd). Since\u03bd = 0 and\u03bd[K] = 0, we have by Lemma E.15 that \u03bb W [Q \u2212 \u00b5] > 0 for some \u00b5.\nBy the definition of a density, f\u03bd is positive (\u03bd \u2022 u \u22121 )a.e. Consequently, by the definition of\u03bd, f\u03bd is non-zero (\u00b5 \u2022 u \u22121 )-a.e. Therefore, by Lemma E.17, there exist only countably many \u03b2 \u2208 R such that the density of (\u00b5 + \u03b2 \u2022\u03bd) \u2022 u \u22121 equals zero on a set of positive \u00b5 \u2022 u \u22121 -measure. Since countable sets have \u03bb-measure zero and \u03bd is arbitrary, the set of \u00b5 \u2208 Q such that \u03bd\n\u2022 u \u22121 \u00ce (\u00b5 E ) \u2022 u \u22121 is prevalent relative to Q by Prop. E.6.\nThe following definition and technical lemma are needed to extend Theorem 1 to the cases of conditional principal fairness and path-specific fairness, which involve additional conditioning on W = \u03c9(X). In particular, one corner case we wish to avoid in the proof of Theorem 1 is when the decision policy is non-trivial (i.e., some individuals receive a positive decision and others do not) but from the perspective of each \u03c9-stratum, the policy is trivial (i.e., everyone in the stratum receives a positive or negative decision). Definition E.12 formalizes this pathology, and Lemma E.19 shows that this issue-under a mild hypothesis-does not arise for a generic element of Q. Definition E.12. We say that \u00b5 \u2208 Q overlaps utilities when, for any budget-exhausting multiple threshold policy \u03c4 (x), if\n0 < E \u00b5 [\u03c4 (X)] < 1, then there exists w \u2208 W such that 0 < E \u00b5 [\u03c4 (X) | W = w] < 1.\nIf there exists a budget-exhausting multiple threshold policy \u03c4 (x) such that\n0 < E \u00b5 [\u03c4 (X)] < 1, but for all w \u2208 W, E \u00b5 [\u03c4 (X) | W = w] \u2208 {0, 1},\nthen we say that \u03c4 (x) splits utilities over \u00b5.\nInformally, having overlapped utilities prevents a budgetexhausting threshold policy from having thresholds that fall on the utility scale exactly between the strata induced by \u03c9-i.e., a threshold policy that splits utilities. This is almost a generic condition in Q, as we shown in Lemma E.19.\nLemma E.19. Let 0 < b < 1. Suppose that for all w \u2208 W there exists \u00b5 \u2208 Q such that Pr \u00b5 (u(X) > 0, W = w) > 0.\nThen almost every \u00b5 \u2208 Q overlaps utilities.\nProof. Our goal is to show that the set E of measures \u00b5 \u2208 Q such that there exists a splitting policy \u03c4 (x) is shy.\nTo simplify the proof, we divide an conquer, showing that the set E \u0393 of measures \u00b5 \u2208 Q such that there exists a splitting policy where the thresholds fall below w \u2208 \u0393 \u2286 W and above w / \u2208 \u0393 is Borel, before constructing a probe that shows that it is shy. Then, we argue that E = \u0393\u2286W E \u0393 , which shows that E is shy.\nWe begin by considering the linear map \u03a6 :\nK \u2192 R \u00d7 R W given by \u03a6(\u00b5) = Pr \u00b5 (u(X) = 0), (Pr \u00b5 (W = w)) w\u2208W .\nFor any \u0393 \u2286 W, the sets\nF Up \u0393 = {x \u2208 R \u00d7 R W : x 0 \u2265 b, b = w\u2208\u0393 x w }, F Lo \u0393 = {x \u2208 R \u00d7 R W : x 0 \u2264 b, x 0 = w\u2208\u0393 x w },\nare closed by construction. Therefore, since \u03a6 is continuous,\nE \u0393 = Q \u2229 \u03a6 \u22121 \uf8eb \uf8ed \u0393\u2286W F Up \u0393 \u222a F Lo \u0393 \uf8f6 \uf8f8(16)\nis closed, and therefore universally measurable.\nNote that by our hypothesis and Cor. E.4, for all w \u2208 W there exists some a w \u2208 A such that Pr \u00b5max,a w ,w (u(X) > 0).\nWe use this to show that E \u0393 is shy. Pick w * \u2208 W arbitrarily, and consider the measures \u03bd w for w = w * defined by \u03bd w = \u00b5 max,aw,w u(X)>0 Pr \u00b5max,a w ,w (u(X) > 0) \u2212 \u00b5 max,a w * ,w * u(X)>0 Pr \u00b5 max,a w * ,w * (u(X) > 0) .\nWe note that \u03bd w [K] = by construction. Therefore, if W w = SPAN(\u03bd w ), then \u03bb Ww [Q \u2212 \u00b5 w ] > 0 for some \u00b5 w by Lemma E.15.\nMoreover, we have that Pr \u03bd (u(X) > 0) = 0 for all \u03bd \u2208 W w , i.e., Pr \u00b5 (u(X) > 0) = Pr \u00b5+\u03bd (u(X) > 0). Now, since 0 < b < 1 and \u03c9 partitions X , it follows that\nE W = E \u2205 = \u2205.\nSince \u03bb W [\u2205] = 0 for any subspace W, we can assume without loss of generality that \u0393 = W, \u2205.\nIn that case, there exists w \u0393 \u2208 W such that if w * \u2208 \u0393, then w \u0393 / \u2208 \u0393, and vice versa. Without loss of generality, assume w \u0393 \u2208 \u0393 and w * / \u2208 \u0393. It then follows that for arbitrary \u00b5 \u2208 Q,\n\u03a6(\u00b5 + \u03b2 \u2022 \u03bd w\u0393 ) = \u03a6(\u00b5) + \u03b2 \u2022 e w\u0393 \u2212 \u03b2 \u2022 e w * ,\nwhere e w is the basis vector corresponding to w \u2208 W. From this, it follows immediately by Eq. (E.4.2) that\n\u00b5 + \u03b2 \u2022 \u03bd w\u0393 \u2208 E \u0393 only if \u03b2 = min(b, Pr \u00b5 (u(X) > 0)) \u2212 w\u2208\u0393 Pr \u00b5 (W = w).\nThis is a measure zero subset of R, and so it follows that \u03bb Ww \u0393 [E \u0393 \u2212 \u00b5] = 0 for all \u00b5 \u2208 K. Therefore, by Prop. E.6, E \u0393 is shy in Q. Taking the union over \u0393 \u2286 W, it follows by Prop. E.5 that \u0393\u2286W E \u0393 is shy. Now, we must show that E = \u0393\u2286W E \u0393 . By construction, E \u0393 \u2286 E , since the policy \u03c4 (x) = 1 \u03c9(x)\u2208\u0393 is budgetexhausting and separates utilities. To see the reverse inclusion, suppose \u00b5 \u2208 E , i.e., that there exists a budgetexhausting multiple threshold policy \u03c4 (x) that splits utilities over \u00b5. Then, let\n\u0393 \u00b5 = {w \u2208 W : E \u00b5 [\u03c4 (X) | W = w] = 1}.\nSince \u03c4 (x) is budget-exhausting, it follows immediately that \u00b5 \u2208 E \u0393\u00b5 . Therefore, E = \u0393\u2286W E \u0393 , and so E is shy, as desired.\nWe conclude our discussion of shyness and shy sets with the following general lemma, which simplifies relative prevalence proofs by showing that one can, without loss of generality, restrict one's attention to the elements of the shy set itself in applying Prop. E.6.\nLemma E.20. Suppose E is a universally measurable subset of a convex, completely metrizable set C in a topological vector space V . Suppose that for some finite-dimensional subpace\nV , \u03bb V [C + v 0 ] > 0 for some v 0 \u2208 V . If, in addition, for all v \u2208 E, \u03bb V [{v \u2208 V : v + v \u2208 E}] = 0,(17)\nthen it follows that E is shy relative to C.\nProof. Let v be arbitrary. Then, either\n(v + V ) \u2229 E is empty or not.\nFirst, suppose it is empty. Since \u03bb V [\u2205] = 0 by definition, it follows immediately that in this case\n\u03bb V [E \u2212 v] = 0.\nNext, suppose the intersection is not empty, and let v + v * \u2208 E for some fixed v * \u2208 V . It follows that\n\u03bb V [E \u2212 v] = \u03bb V [{v \u2208 V : v + v \u2208 E}] = \u03bb V [{v \u2208 V : (v + v * ) + v \u2208 E}] = 0,\nwhere the first equality follows by definition; the second equality follows by the translation invariance of \u03bb V , and the fact that v * + V = V ; and the final inequality follows from Eq. (17).\nTherefore \u03bb V [E \u2212 v] = 0 for arbitrary v, and so E is shy.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "E.5. Proof of Theorem 1", "text": "Using the lemmata above, we can prove Theorem 1. We briefly summarize what has been established so far:\n\u2022 Lemma E.7: The set K of U-fine distributions on K is a Banach space;\n\u2022 Lemma E.11: The subset Q of U-fine probability measures on K is a convex, completely metrizable subset of K;\n\u2022 Lemma E.13: The subset E of Q is a universally measurable subset of K, where E is the set consisting of U-fine probability measures over which there exists a policy satisfying counterfactual equalized odds (resp., conditional principal fairness, or path-specific fairness) that is not strongly Pareto dominated.\nTherefore, to apply Prop. E.6, it follows that what remains is to construct a probe W and show that \u03bb W [Q + \u00b5 0 ] > 0 for some \u00b5 0 \u2208 K but \u03bb W [E + \u00b5] = 0 for all \u00b5 \u2208 K.\nProof. We divide the proof into three pieces. First, we illustrate how to construct the probe W from a particular collection of distributions {\u03bd Up a , \u03bd Lo a } a\u2208A . Second, we\nshow that \u03bb W [E + \u00b5] = for all \u00b5 \u2208 K. For notational and expository simplicity, we focus in these first two sections on the case of counterfactual equalized odds. Therefore, in the third section, we show how to generalize the argument to conditional principal fairness and path-specific fairness.\nConstruction of the probe We will construct our probe to address two different cases. We recall that, by Cor. D.1, any policy that is not strongly Pareto dominated must be a budget-exhausting multiple threshold policy with nonnegative thresholds. In the first case, we consider when the candidate budget-exhausting multiple threshold policy is 1 u(x)>0 . By perturbing the underlying distribution by \u03bd \u2208 W Lo , we will be able to break the balance requirements implied by Eq. (2). In the second case, we treat the possibility that the candidate budget-exhausting multiple threshold policy has a non-trivial positive threshold for at least one group. By perturbing the underlying distribution by \u03bd \u2208 W Up for an alternative set of perturbations W Up , we will again be able to break the balance requirements.\nMore specifically, to construct our probe W = W Up + W Lo , we want W Up and W Lo to have a number of properties. In particular, for all \u03bd \u2208 W, perturbation by \u03bd should not affect whether the underlying distribution is a probability distribution, and should not affect how much of the budget is available to budget-exhausting policies. Specifically, for all \u03bd \u2208 W,\nK 1 d\u03bd = 0,(18)\nand K 1 u(X)>0 d\u03bd = 0.\nIn fact, the amount of budget available to budget-exhausting policies will not change within group, i.e., for all a \u2208 A and \u03bd \u2208 W, K 1 u(X)>0,A=a d\u03bd = 0.\nAdditionally, for some distinguished y 0 , y 1 \u2208 Y, non-zero perturbations in \u03bd Lo \u2208 W Lo should move mass between y 0 and y 1 . That is, they should have the property that if\nPr |\u03bd Lo | (A = a) > 0, then K 1 u(X)<0,Y =yi,A=a d\u03bd Lo = 0. (21\n)\nFinally, perturbations in W Up should have the property that for any non-trivial t > 0, some mass is moved either above or below t > 0. More precisely, for any \u00b5 \u2208 Q and any t such that\n0 < Pr \u00b5 (u(X) > t | A = a) < 1, if \u03bd Up \u2208 W Up is such that Pr |\u03bd Up | (A = a) > 0, then K 1 u(X)>t,A=a d\u03bd Up = 0. (22\n)\nTo carry out the construction, choose distinct y 0 , y 1 \u2208 Y.\nThen, since\n\u00b5 max,a \u2022 u \u22121 [S a \u2229 [0, r a )] \u2212 \u00b5 max,a \u2022 u \u22121 [S a \u2229 [r a , \u221e)]\nis a continuous function of r a , it follows by the intermediate value theorem that we can partition S a into three pieces,\nS Lo a = S a \u2229 (\u2212\u221e, 0), S Up a,0 = S a \u2229 [0, r a ), S Up a,1 = S a \u2229 [r a , \u221e), so that\nPr \u00b5max,a u(X) \u2208 S Up a,0 = Pr \u00b5max,a u(X) \u2208 S Up a,1 .\nRecall that K = X \u00d7Y. Let \u03c0 X : K \u2192 X denote projection onto X , and \u03b3 y : X \u2192 K be the injection x \u2192 (x, y). We define\n\u03bd Up a [E] = \u00b5 max,a \u2022 (\u03b3 y1 \u2022 \u03c0 X ) \u22121 E \u2229 u \u22121 S Up a,1 , \u2212 \u00b5 max,a \u2022 (\u03b3 y1 \u2022 \u03c0 X ) \u22121 E \u2229 u \u22121 S Up a,0 , \u03bd Lo a [E] = \u00b5 max,a \u2022 (\u03b3 y1 \u2022 \u03c0 X ) \u22121 E \u2229 u \u22121 S Lo a \u2212 \u00b5 max,a \u2022 (\u03b3 y0 \u2022 \u03c0 X ) \u22121 E \u2229 u \u22121 S Lo a . By construction, \u03bd Up a concentrates on {y 1 } \u00d7 u \u22121 (S a \u2229 [0, \u221e)),\nwhile \u03bd Lo a concentrates on {y 0 , y 1 } \u00d7 u \u22121 (S a \u2229 (\u2212\u221e, 0)).\nMoreover, if we set\nW Up = SPAN(\u03bd Up a ) a\u2208A , W Lo = SPAN(\u03bd Lo a )\na\u2208A , then it is easy to see that Eqs. ( 18) to (21) will hold. The only non-trivial case is Eq. (22). However, by Cor. E.3, the support of f \u00b5max,a is maximal. That is, for \u00b5 \u2208 Q, if\n0 < Pr \u00b5 (u(X) > t | A = a, u(X) > 0) < 1,\nthen it follows that 0 < t < sup S a . Either t \u2264 r a or t > r a . First, assume t \u2264 r a ; then, it follows by the construction of\n\u03bd Up a that \u03bd Up a \u2022 u \u22121 [(t, \u221e)] = \u221e ra f max,a d\u03bb \u2212 ra t f max,a d\u03bb > \u221e ra f max,a d\u03bb \u2212 ra 0 f max,a d\u03bb = 0. Similarly, if t > r a , \u03bd Up a \u2022 u \u22121 [(t, \u221e)] = \u221e t f max,a d\u03bb > \u221e sup Sa f max,a d\u03bb = 0.\nTherefore Eq. ( 22) holds.\nSince W is non-trivial 18 and \u03bd[K] = 0 for all \u03bd \u2208 W, it follows by Lemma E.15 that \u03bb W [Q \u2212 \u00b5] > 0 for some \u00b5 \u2208 K.\nShyness Recall that, by Prop. E.5, a set E is shy if and only if, for an arbitrary shy set E , E \\ E is shy.\nBy Lemma E.16, a generic element of \u00b5 \u2208 Q satisfies Pr \u00b5 (u(X) > 0, Y (1) = y i , A = a) > 0 for i = 0, 1, and a \u2208 A. Likewise, by Lemma E.18, a generic \u00b5 \u2208 Q satisfies \u03bd Up a \u2022 u \u22121 \u00ce (\u00b5 X \u00d7{y1} ) \u2022 u \u22121 . Therefore, to simplify our task and recalling Remark 6, we may instead demonstrate the shyness of the set of \u00b5 \u2208 Q such that:\n\u2022 There exists a budget-exhausting multiple threshold policy \u03c4 (x) with non-negative thresholds satisfying counterfactual equalized odds over \u00b5;\n\u2022 For i = 0, 1, Pr \u00b5 (u(X) > 0, A = a, Y (1) = y i ) > 0;(23)\n\u2022 For all a \u2208 A,\n\u03bd Up a \u2022 u \u22121 \u00ce (\u00b5 \u03b1 \u22121 (a)\u00d7{y1} ) \u2022 u \u22121 . (24\n)\nBy a slight abuse of notation, we continue to refer to this set as E. We note that, by the construction of W, Eq. ( 23) is not affected by perturbation by \u03bd \u2208 W, and Eq. ( 24) is not affected by perturbation by \u03bd Lo \u2208 W.\nIn particular, by Lemma E.20, it suffices to show that\n\u03bb W [E \u2212 \u00b5] = 0 for \u00b5 \u2208 E.\nTherefore, let \u00b5 \u2208 E be arbitrary. Let the budget-exhausting multiple threshold policy satisfying counterfactual equalized odds over it be \u03c4 (x), so that E \u00b5 [\u03c4 (X)] = min(b, Pr \u00b5 (u(X) > 0)), with thresholds {t a } a\u2208A . We split into two cases based on whether \u03c4 (X) = 1 u(X)>0 \u00b5-a.s. or not. 18 In general, some or all of the \u03bd Lo may be zero depending on the \u03bb-measure of S Lo a . However, as noted in Remark 6, the \u03bd Up a,i cannot be zero, since Pr\u00b5 max,a (u(X) > 0) > 0 for all a \u2208 A.\nTherefore W = {0}.\nIn both cases, we make use of the following two useful observations.\nFirst, note that as E \u2286 Q, if \u00b5 + \u03bd is not a probability measure, then \u00b5 + \u03bd / \u2208 E. Therefore, without loss of generality, we assume throughout that \u00b5 + \u03bd is a probability measure.\nSecond, suppose \u03c4 (x) is a policy satisfying counterfactual equalized odds over some \u03bd \u2208 Q. Then, if 0 < E \u00b5 [\u03c4 (X)] < 1, it follows that for all a \u2208 A,\n0 < E \u00b5 [\u03c4 (X) | A = a] < 1. (25\n)\nFor, suppose not. Then, without loss of generality, there must be a 0 , a\n1 \u2208 A such that E \u00b5 [\u03c4 (X) | A = a 0 ] = 0 and E \u00b5 [\u03c4 (X) | A = a 1 ] > 0.\nBut then, by the law of iterated expectation, there must be some Y \u2286 Y such that \u00b5[X \u00d7 Y ] > 0 and so,\n1 X \u00d7Y \u2022 E \u00b5 [\u03c4 (X) | A = a 1 , Y (1)] > 0 = 1 X \u00d7Y \u2022 E \u00b5 [\u03c4 (X) | A = a 0 , Y (1)],\ncontradicting the fact that \u03c4 (x) satisfies counterfactual equalized odds over \u00b5. Therefore, in what follows, we can assume that Eq. (25) holds.\nOur goal is to show that \u03bb W [E \u2212 \u00b5] = 0. Case 1 (\u03c4 (X) = 1 u(X)>0 ). We argue as follows. First, we show that 1 u(X)>0 is the unique budget-exhausting multiple threshold policy with non-negative thresholds over \u00b5 + \u03bd for all \u03bd \u2208 W. Then, we show that the set of \u03bd \u2208 W such that 1 u(x)>0 satisfies counterfactual equalized odds over \u00b5 + \u03bd is a \u03bb W -null set.\nWe begin by observing that W Lo = {0}. For, if that were the case, then Eq. (25) would not hold for \u03c4 (x).\nNext, we note that by Eq. ( 19), for any \u03bd \u2208 W, Pr \u00b5+\u03bd (u(X) > 0) = Pr \u00b5 (u(X) > 0)\nand so E \u00b5+\u03bd [1 u(X)>0 ] = min(b, Pr \u00b5+\u03bd (u(X) > 0)).\nIf \u03c4 (x) is a feasible multiple threshold policy with nonnegative thresholds and \u03c4 (X) = 1 u(X)>0 (\u00b5 + \u03bd)-a.s., then, as a consequence,\nE \u00b5+\u03bd [\u03c4 (X)] < Pr \u00b5+\u03bd (u(X) > 0) \u2264 b.\nTherefore, it follows that 1 u(X)>0 is the unique budgetexhausting multiple threshold policy over \u00b5 + \u03bd with nonnegative thresholds. Now, note that if counterfactual equalized odds holds with decision policy \u03c4 (x) = 1 u(x)>0 , then, by Eq. (4) and Lemma E.6, we must have that Pr \u00b5+\u03bd (u(X) >\n0 | A = a, Y (1) = y 1 ) = Pr \u00b5+\u03bd (u(X) > 0 | A = a , Y (1) = y 1 )\nfor a, a \u2208 A. 19 Now, we will show that a typical element of W breaks this balance requirement. Choose a * such that \u03bd Lo a * = 0. Recall that \u03bd is fixed, and let \u03bd = \u03bd \u2212 \u03b2 Lo a * \u2022 \u03bd Lo a * . Let\np a = Pr \u00b5+\u03bd (u(X) > 0 | A = a , Y (1) = y 1 ).\nNote that it cannot be the case that p a = 0 for all a \u2208 A, since, by Eq. ( 23),\nPr \u00b5+\u03bd (u(X) > 0 | Y (1) = y 1 ) > 0.\nTherefore, by the foregoing discussion, either p a * > 0 or p a * = 0 and we can choose a \u2208 A such that p a > 0.\nSince the \u03bd Lo a , \u03bd Up a,i are all mutually singular, it follows that counterfactual equalized odds can only hold over \u00b5 + \u03bd if p a = Pr \u00b5+\u03bd (u(X) > 0 | A = a * , Y (1) = y 1 ). Now, we observe that by Lemma E.6, that Pr \u00b5+\u03bd (u(X) >\n0 | A = a * , Y (1) = y 1 ) = \u03b7 \u03c0 + \u03b2 Lo a * \u2022 \u03c1 where \u03b7 = Pr \u00b5 (u(X) > 0, A = a * , Y (1) = y 1 ) \u03c0 = Pr \u00b5 (A = a * , Y (1) = y 1 ), \u03c1 = K 1 A=a * ,Y (1)=y1 d\u03bd Lo a * . since 0 = K 1 u(X)>0,A=a * ,Y (1)=y1 d\u03bd Lo a * , 0 = K 1 A=a * ,Y (1)=y1 d\u03bd Lo a * .\nHere, the equality follows by the fact that \u03bd Lo is supported on S Lo a \u00d7 {y 0 , y 1 } and the inequality from Eq. (21). Therefore, if, in the first case, p a > 0, then counterfactual equalized odds only holds if , 19 To ensure that both quantities are well-defined, here and throughout the remainder of the proof we use the fact that by Eqs. ( 20) and ( 23), Pr\u00b5+\u03bd (u(X) > 0, A = a, Y (1) = y1) > 0.\n\u03b2 Lo a * = e \u2212 p a \u2022 \u03c0 p a \u2022 \u03c1\nsince, as noted above, \u03c1 = 0 by Eq. (21). In the second case, if p a = 0, then counterfactual equalized odds can only hold if e = p a * \u2022 \u03c0 = 0.\nSince we chose a so that p a * > 0 if p a = 0 and \u03c0 > 0 by Eq. ( 23), this is impossible.\nIn either case, we see that the set of \u03b2 Lo a * \u2208 R such that there a budget-exhausting threshold policy with positive thresholds satisfying counterfactual equalized odds over \u00b5 + \u03bd + \u03b2 Lo a * \u2022 \u03bd Lo a * has \u03bb-measure zero. That is\n\u03bb SPAN(\u03bd Lo a * ) [E \u2212 \u00b5 \u2212 \u03bd ] = 0.\nSince \u03bd was arbitrary, it follows by Fubini's theorem that \u03bb W [E \u2212 \u00b5] = 0.\nCase 2 (\u03c4 (X) = 1 u(X)>0 ). Our proof strategy is similar to the previous case. First, we show that, for a given fixed \u03bd Lo \u2208 W Lo , there is a unique candidate policy\u03c4 (x) for being a budget-exhausting multiple threshold policy with non-negative thresholds and satisfying counterfactual equalized odds over \u00b5 + \u03bd Lo + \u03bd Up for any \u03bd Up \u2208 W Up . Then, we show that the set of \u03bd Up such that\u03c4 (X) satisfies counterfactual equalized odds has \u03bb W Up measure zero. Finally, we argue that this in turn implies that the set of \u03bd \u2208 W such that there exists a Pareto efficient policy satisfying counterfactual equalized odds over \u00b5 + \u03bd has \u03bb W -measure zero.\nWe seek to show that \u03bb W Up [E \u2212 (\u00b5 + \u03bd Lo )] = 0. To begin, we note that since \u03bd Up a,i concentrates on {y 1 } \u00d7 X for all a \u2208 A, it follows that\nE \u00b5+\u03bd Lo [d(X) | A = a, Y (1) = y 0 ] = E \u00b5+\u03bd Lo +\u03bd Up [d(X) | A = a, Y (1) = y 0 ]\nfor any \u03bd Up \u2208 W Up . Now, suppose there exists some \u03bd Up \u2208 W Up such that there exists a budget-exhausting multiple threshold polic\u1ef9 \u03c4 (x) with non-negative thresholds such that counterfactual equalized odds is satisfied over \u00b5 + \u03bd Lo + \u03bd Up . (If not, then we are done and \u03bb W Up [E \u2212 (\u00b5 + \u03bd Lo )] = 0, as the measure of the empty set is zero.) Let\np = E \u00b5+\u03bd Lo [\u03c4 (X) | A = a, Y (1) = y 0 ].\nSuppose that\u03c4 (x) is an alternative budget-exhausting multiple threshold policy with non-negative thresholds such that counterfactual equalized odds is satisfied. We seek to show that \u03c4 (X) = \u03c4 (X) (\u00b5 + \u03bd Lo + \u03bd Up )-a.e. for any \u03bd Up \u2208 W Up . Toward a contradiction, suppose that for some a 0 \u2208 A,\nE \u00b5+\u03bd Lo [\u03c4 (X) | A = a 0 , Y (1) = y 0 ] < p.\nSince, by Eq. (23), Pr \u00b5+\u03bd Lo (A = a 0 , Y (1) = y 0 ) > 0, it follows that\nE \u00b5+\u03bd Lo [\u03c4 (X) | A = a 0 ] < E \u00b5+\u03bd Lo [\u03c4 (X) | A = a 0 ].\nTherefore, since\u03c4 (x) is budget exhausting, there must be some a 1 such that\nE \u00b5+\u03bd Lo [\u03c4 (X) | A = a 1 ] > E \u00b5+\u03bd Lo [\u03c4 (X) | A = a 1 ].\nFrom this, it follows\u03c4 (x) can be represented by a threshold greater than or equal to that of\u03c4 (x) on \u03b1 \u22121 (a 1 ), and hence\nE \u00b5+\u03bd Lo [\u03c4 (X) | A = a 1 , Y (1) = y 0 ] \u2265 E \u00b5+\u03bd Lo [\u03c4 (X) | A = a 0 , Y (1) = y 0 ] = p > E \u00b5+\u03bd Lo [\u03c4 (X) | A = a 0 , Y (1) = y 0 ],\ncontradicting the fact that\u03c4 (x) satisfies counterfactual equalized odds.\nBy the preceding discussion, Lemma E.10, and the fact that \u03bd Lo is supported on u \u22121 ((\u2212\u221e, 0]), \u03c4 (X) =\u03c4 (X) (\u00b5 X \u00d7{y0} )-a.e. By Eq. (24), it follows that\u03c4 (X) =\u03c4 (X) \u03bd Up a,i -a.e. for i = 0, 1. As a consequence, \u03c4 (X) =\u03c4 (X) (\u00b5 + \u03bd Lo + \u03bd up )-a.e. for all \u03bd Up \u2208 W Up . Therefore\u03c4 (X) is, indeed, unique, as desired. Now, we note that since \u03c4 (X) = 1 u(X)>0 , it follows that E[\u03c4 (X)] < Pr \u00b5 (u(X) > 0). It follows that E \u00b5 [\u03c4 (X)] = b, since \u03c4 (x) is budget exhausting. Therefore, by Eq. (19), it follows that for any budget-exhausting policy\u03c4 (X), E[\u03c4 (X)] = b, and so\u03c4 (X) = 1 u(X)>0 over \u00b5 + \u03bd.\nTherefore, fix \u03bd Lo and\u03c4 (X). By Eq. (25), there is some a * such that\n0 < Pr \u00b5+\u03bd Lo (u(X) >t a * | A = a * ) < 1.\nThen, it follows by Eq. ( 22\n) that K 1 u(X)>t a * d\u03bd Up a * = 0. Fix \u03bd = \u03bd \u2212 \u03b2 Up a * \u2022 \u03bd Up a * .\nThen, for some a = a * , set\np * = E \u00b5+\u03bd [\u03c4 (X) | A = a, Y (1) = y 1 ].\nSince the \u03bd Lo a , \u03bd Up a are all mutually singular, it follows that counterfactual equalized odds can only hold over \u00b5 + \u03bd if p * = Pr \u00b5+\u03bd (u(X) >t a * | A = a * , Y (1) = y 1 ). Now, we observe that by Lemma E.6, that Pr \u00b5+\u03bd (u(X) >t a\n* | A = a * , Y (1) = y 1 ) = \u03b7 + \u03b2 Up a \u2022 \u03b3 \u03c0(26)\nwhere\n\u03b7 = Pr \u00b5+\u03bd Lo (u(X) >t a * | A = a * , Y (1) = y 1 ), \u03c0 = Pr \u00b5+\u03bd Lo (A = a * , Y (1) = y 1 ), \u03b3 = K 1 u(X)>t a * ,A=a * ,Y (1)=y1 d\u03bd Up a ,\nand we note that\n0 = K 1 A=a * ,Y (1)=y1 d\u03bd Lo a .\nEq. ( 26) can be rearranged to\n(p * \u2022 \u03c0 \u2212 \u03b7) \u2212 \u03b2 \u2022 \u03b3 = 0.\nThis can only hold if\n\u03b2 = p * \u2022 \u03c0 \u2212 \u03b7 \u03b3 ,\nsince by Eq. ( 22), \u03b3 = 0. Since any countable subset of R is a \u03bb-null set,\n\u03bb SPAN(\u03bd Up a * ) [E \u2212 \u00b5 \u2212 \u03bd ] = 0.\nSince \u03bd was arbitrary, it follows by Fubini's theorem that \u03bb W Up [E \u2212 \u00b5 \u2212 \u03bd Lo ] = 0 in this case as well. Lastly, since \u03bd Lo was also arbitrary, applying Fubini's theorem a final time gives that \u03bb W [E \u2212 \u00b5] = 0.\nConditional principal fairness and path-specific fairness The extension of these results to conditional principal fairness and path-specific fairness is straightforward.\nAll that is required is a minor modification of the probe.\nIn the case of conditional principal fairness, we set\n\u03bd Up a,w [E] = \u00b5 max,a,w \u2022 (\u03b3 (y1,y1) \u2022 \u03c0 X ) \u22121 [E \u2229 u \u22121 (S Up a,1 )], \u2212 \u00b5 max,a \u2022 (\u03b3 (y1,y1) \u2022 \u03c0 X ) \u22121 [E \u2229 u \u22121 (S Up a,w )], \u03bd Lo a,w [E] = \u00b5 max,a,w \u2022 (\u03b3 (y1,y1) \u2022 \u03c0 X ) \u22121 [E \u2229 u \u22121 (S Lo a )] \u2212 \u00b5 max,a \u2022 (\u03b3 (y0,y0) \u2022 \u03c0 X ) \u22121 [E \u2229 u \u22121 (S Lo a,w )],\nwhere \u03b3 (y,y ) : X \u2192 K is the injection x \u2192 (x, y, y ). Our probe is then given by\nW Up = SPAN(\u03bd Up a,w ), W Lo = SPAN(\u03bd Lo a,w ),\nalmost as before.\nThe proof otherwise proceeds virtually identically, except for two points. First, recalling Remark 6, we use the fact that a generic element of Q satisfies Pr \u00b5 (A = a, W = w) > 0 in place of Pr \u00b5 (A = a) > 0 throughout. Second, we use the fact that \u03c9 overlaps utility in place of Eq. (25).\nIn particular, If \u03c9 does not overlap utilities for a generic \u00b5 \u2208 Q, then, by Lemma E.19, there exists w \u2208 W such that Pr \u00b5 (u(X) > 0, W = w) = 0 for all \u00b5 \u2208 Q. If this occurs, we can show that no budget-exhausting multiple threshold policy with positive thresholds satisfies conditional principal fairness, exactly as we did to show Eq. (25).\nIn the case of path-specific fairness, we instead define\nS Lo a,w = S a,w \u2229 (\u2212\u221e, r a,w ), S Up a,w = S a,w \u2229 [r a,w , \u221e),\nwhere r a,w is chosen so that Pr \u00b5max,a,w (u(X) \u2208 S Lo a,w ) = Pr \u00b5max,a,w (u(X) \u2208 S Up a,w ).\nLet \u03c0 X denote the projection from K = A \u00d7 X A given by\n(a, (x a ) a \u2208A ) \u2192 x a .\nLet \u03c0 a denote the projection from the a -th component.\n(That is, given \u00b5 \u2208 K, the distribution of X \u03a0,A,a over \u00b5 is given by \u00b5 \u2022 \u03c0 \u22121 a and the distribution of X is given by \u00b5 \u2022 \u03c0 \u22121 X .) Then, we let\u03bc max,a,w be the measure on X given b\u1ef9\n\u00b5 max,a,w [E] = \u00b5 max,a,w [E \u2229 (u \u2022 \u03c0 a ) \u22121 (s Up a,w )] \u2212 \u00b5 max,a,w [E \u2229 (u \u2022 \u03c0 a ) \u22121 (S Lo a,w )].\nFinally, let \u03c6 : A \u2192 A be a permutation of the groups with no fixed points, i.e., so that a = \u03c6(a ) for all a \u2208 A. Then, we define\n\u03bd a = \u03b4 a \u00d7\u03bc max,\u03c6(a ),w1 \u00d7 a =\u03c6(a ) \u00b5 max,a,w1 \u2022 \u03c0 \u22121 a ,\nwhere \u03b4 a is the measure on A given by \u03b4 a [{a }] = 1 a=a . Then, simply let\nW = SPAN(\u03bd a ) a \u2208A .\nSince\u03bc max,a,w [X ] = 0 for all a \u2208 A, it follows that \u03bd a,w \u2022 \u03c0 \u22121 X = 0, i.e.,\nPr \u00b5 (X \u2208 E) = Pr \u00b5+\u03bd (X \u2208 E)\nfor any \u03bd \u2208 W and \u00b5 \u2208 Q. Therefore Eqs. ( 18) and ( 19) hold. Moreover, the \u03bd a satisfy the following strengthening of Eq. ( 22). Perturbations in W have the property that for any non-trivial t-not necessarily positive-some of the mass of u(X \u03a0,A,a ) is moved either above or below t. More precisely, for any \u00b5 \u2208 Q and any t such that\n0 < Pr \u00b5 (u(X) > t | A = a) < 1, if \u03bd \u2208 W is such that Pr |\u03bd| (A = \u03c6 \u22121 (a)) > 0, then K 1 u(X \u03a0,A,a )>t d\u03bd a = 0. (27\n)\nThis stronger property means that we need not separately treat the case where \u03c4 (X) = 1 u(X)>0 \u00b5-a.e.\nOther than this difference the proof proceeds in the same way, except for two points. First, we again make use of the fact that \u03c9 can be assumed to overlap utilities in place of Eq. ( 25), as in the case of conditional principal fairness. Second, w 0 and w 1 take the place of y 0 and y 1 . In particular, to establish the uniqueness of\u03c4 (x) given \u00b5 and \u03bd Lo in the second case, instead of conditioning on y 0 , we instead condition on w 0 , where, following the discussion in Remark 6 and Lemma E.16, this conditioning is well-defined for a generic element of Q.\nWe have focused on causal definitions of fairness, but the thrust of our analysis applies to non-causal conceptions of fairness as well. Below we show that policies constrained to satisfy (non-counterfactual) equalized odds (Hardt et al., 2016) are generically strongly Pareto dominated, a result that follows immediately from our proof above.\nDefinition E.13. Equalized odds holds for a decision policy d(x) when d(X) \u22a5 \u22a5 A | Y.\nWe note that Y in Eq. (28) does not depend on our choice of d(x), but rather represents the realized value of Y , e.g., under some status quo decision making rule.\nCorollary E.5. Suppose U is a set of utilities consistent modulo \u03b1. Further suppose that for all a \u2208 A there exist a U-fine distribution of X and a utility u \u2208 U such that Pr(u(X) > 0, A = a) > 0, where A = \u03b1(X). Then, for almost every U-fine distribution of X and Y on X \u00d7 Y, any decision policy d(x) satisfying equalized odds is strongly Pareto dominated.\nProof. Consider the following maps. Distributions of X and Y (1), i.e., probability measures on X \u00d7Y, can be embedded in the space of joint distributions on X, Y (0), and Y (1) via pushing forward by the map \u03b9, where \u03b9 : (x, y) \u2192 (x, y, y). Likewise, given a fixed decision policy D = d(X), joint distributions of X, Y (0), and Y (1) can be projected onto the space of joint distributions of X and Y by pushing forward by the map \u03c0 d : (x, y 0 , y 1 ) \u2192 (x, y d(x) ). Lastly, we see that the composition of \u03b9 and \u03c0 d -regardless of our choice of d(x)-is the identity, as shown in the diagram below.\nX \u00d7 Y X \u00d7 Y \u00d7 Y X \u00d7 Y \u03b9 \u03c0 d id\nWe note also that counterfactual equalized odds holds for \u00b5 exactly when equalized odds holds for \u00b5 \u2022 (\u03c0 d \u2022 \u03b9) \u22121 . The result follows immediately from this and Theorem 1.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "E.6. General Measures on K", "text": "Theorem 1 is restricted to U-fine and U A -fine distributions on the state space. The reason for this restriction is that when the distribution of X induces atoms on the utility scale, threshold policies can possess additional-or even infinite-degrees of freedom when the threshold falls exactly on an atom. In particular circumstances, these degrees of freedom can be used to ensure causal fairness notions, such as counterfactual equalized odds, hold in a locally robust way. In particular, the generalization of Theorem 1 beyond U-fine measures to all totally bounded measures on the state space is false, as illustrated by the following proposition.\nProposition E.7. Consider the set E \u2286 K of distributionsnot necessarily U-fine-on K = X \u00d7 Y over which there exists a Pareto efficient policy satisfying counterfactual equalized odds. There exist b, X , Y, and U such that E is not relatively shy.\nProof. We adopt the notational conventions of Section E.3. We note that by Prop. E.5, a set can only be shy if it has empty interior. Therefore, we will construct an example in which an open ball of distributions on K in the total variation norm all allow for a Pareto efficient policy satisfying counterfactual equalized odds, i.e., are contained in E . Let b = 3 4 , Y = {0, 1}, A = {a 0 , a 1 }, and X = {0, 1} \u00d7 {a 0 , a 1 } \u00d7 R. Let \u03b1 : X \u2192 A be given by \u03b1 : (y, a, v) \u2192 a for arbitrary (y, a, v) \u2208 X . Likewise, let u : X \u2192 R be given by u : (y, a, v) \u2192 v. Then, if U = {u}, U is vacuously consistent modulo \u03b1. Consider the joint distribution \u00b5 on K = X \u00d7 Y where for all y, y \u2208 Y, a \u2208 A, and u \u2208 R,\nPr \u00b5 (X = (a, y, u), Y (1) = y ) = 1 4 \u2022 1 y=y \u2022 Pr \u00b5 (u(X) = u),\nwhere, over \u00b5, u(X) is distributed as a 1 2 -mixture of UNIF(1, 2) and \u03b4(1); that is, Pr(u(X) = 1) = 1 2 and Pr(a < u(X\n) < b) = b\u2212a 2 for 0 \u2264 a \u2264 b < 1.\nWe first observe that there exists a Pareto efficient threshold policy \u03c4 (x) such that counterfactual equalized odds is satisfied with respect to the decision policy \u03c4 (X). Namely, let\n\u03c4 (a, y, u) = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 1 u > 1, 1 2 u = 1, 0 u < 1.\nThen, it immediately follows that E[\u03c4 (X)] = 3 4 = b. Since \u03c4 (x) is a threshold policy and exhausts the budget, it is utility maximizing by Lemma D.4. Moreover, if\nD = 1 U D \u2264\u03c4 (X) for some U D \u223c UNIF(0, 1) independent of X and Y (1), then D \u22a5 \u22a5 A | Y (1). Since u(X) \u22a5 \u22a5 A, Y (1), it follows that Pr \u00b5 (D = 1 | A = a, Y (1) = y) = Pr(U D \u2264 \u03c4 (X) | A = a, Y (1) = y) = Pr(U D \u2264 \u03c4 (X)) = E \u00b5 [\u03c4 (X)],\nTherefore Eq. (2) is satisfied, i.e., counterfactual equalized odds holds. Now, using \u00b5, we construct an open ball of distributions over which we can construct similar threshold policies. In particular, suppose \u00b5 is any distribution such that |\u00b5 \u2212 \u00b5 |[K] < 1 64 . Then, we claim that there exists a budget-exhausting threshold policy satisfying counterfactual equalized odds over \u00b5 . For, we note that\nPr \u00b5 (U > 1) < Pr \u00b5 (U > 1) + 1 64 = 33 64 , Pr \u00b5 (U \u2265 1) > Pr \u00b5 (U \u2265 1) \u2212 1 64 = 63 64 ,\nand so any threshold policy \u03c4 (x) satisfying E[\u03c4 (X)] = b = 3 4 must have t = 1 as its threshold. We will now construct a threshold policy \u03c4 (x) satisfying counterfactual equalized odds over \u00b5 . Consider a threshold policy of the form\n\u03c4 (a, y, u) = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 1 u > 1, p a,y u = 1, 0 u < 1.\nFor notational simplicity, let\nq a,y = Pr \u00b5 (A = a, Y = y, U > 1), r a,y = Pr \u00b5 (A = a, Y = y, U = 1), \u03c0 a,y = Pr \u00b5 (A = a, Y = y).\nThen, we have that\nE \u00b5 [\u03c4 (X)] = a,y q a,y + p a,y \u2022 r a,y , E \u00b5 [\u03c4 (X) | A = a, Y = y] = q a,y + p a,y \u2022 r a,y \u03c0 a,y.\nTherefore, the policy will be budget exhausting if a,y q a,y + p a,y \u2022 r a,y = 3 4 , and it will satisfy counterfactual equalized odds if\n\u03c0 a1,0 \u2022 (q a0,0 + p a0,0 \u2022 r a0,0 ) = \u03c0 a0,0 \u2022 (q a1,0 + p a1,0 \u2022 r a1,0 ), \u03c0 a1,1 \u2022 (q a0,1 + p a0,1 \u2022 r a0,1 ) = \u03c0 a0,1 \u2022 (q a1,1 + p a1,1 \u2022 r a1,1 ),(29)\nsince, as above,\nPr(D = 1 | A = a, Y (1) = y) = E[\u03c4 (X) | A = a, Y (1) = y].\nAgain, for notational simplicity, let\nS = 3 4 \u2212 Pr \u00b5 (U > 1) Pr \u00b5 (U = 1) .\nThen, a straightforward algebraic manipulation shows that Eq. ( 29) is solved by setting p a0,y to be S \u2022 \u03c0 a0,y \u2022 (r a0,y + r a1,y ) + \u03c0 a0,y \u2022 q a1,y \u2212 \u03c0 a1,y \u2022 q a0,y r a0,y \u2022 (\u03c0 a0,y + \u03c0 a1,y ) , and p a1,y to be S \u2022 \u03c0 a1,y \u2022 (r a0,y + r a1,y ) + \u03c0 a1,y \u2022 q a0,y \u2212 \u03c0 a0,y \u2022 q a1,y r a1,y \u2022 (\u03c0 a0,y + \u03c0 a1,y ) .\nIn order for \u03c4 (x) to be a well-defined policy, we need to show that p a,y \u2208 [0, 1] for all a \u2208 A and y \u2208 Y. To that end, note that  and hence p a,y \u2208 [0, 1] for all a \u2208 A and y \u2208 Y.\nTherefore, the policy \u03c4 (x) is well-defined, and, by construction, is budget-exhausting and therefore utility-maximizing by Lemma D.4. It also satisfies counterfactual equalized odds by construction. Since \u00b5 was arbitrary, it follows that the set of distributions on K such that there exists a Pareto efficient policy satisfying counterfactual equalized odds contains an open ball, and hence is not shy.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "F. Theorem 2 and Related Results", "text": "We first prove a variant of Theorem 2 for general, continuous covariates X . Then, we extend and generalize Theorem 2 using the theory of finite Markov chains, offering a proof of the theorem different from the sketch included in the main text.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "F.1. Extension to Continuous Covariates", "text": "Here we follow the proof sketch in the main text for Theorem 2, which assumes a finite covariate-space X . In that case, we start with a point x * with maximum decision probability d(x * ), and then assume, toward a contradiction, that there exists a point with strictly lower decision probability. The general case is more involved since it is not immediately clear that the maximum value of d(x) is achieved with positive probability in X . We start with the lemma below before proving the main result. Proof. First, suppose that d(x) satisfies path-specific fairness. To show the result, we use the standard fact that for independent random variables X and U , E[f (X, U ) | X] = f (X, u) dF U (u), where the second equality follows from the fact that D \u03a0,A,a \u22a5 \u22a5 X | X \u03a0,A,a , the third from the law of iterated expectations, and the fourth from the definition of pathspecific fairness.\nNext, suppose that\nE[d(X \u03a0,A,a | X] = d(X)\nfor all a \u2208 A. Then, since W = X and X \u22a5 \u22a5 U D , using Eq. (30), we have that for all a \u2208 A,\nE[D \u03a0,A,a | X] = E[E[1 U D \u2264d(X \u03a0,A,a ) | X \u03a0,A,a , X] | X] = E[E[d(X \u03a0,A,a ) | X \u03a0,A,a , X] | X] = E[d(X \u03a0,A,a ) | X] = d(X) = E[d(X) | X] = E[D | X].\nThis is exactly Eq. (5), and so the result follows.\nWe are now ready to prove a continuous variant of Theorem 2. The technical hypotheses of the theorem ensure that the conditional probability measures Pr(E | X) are \"sufficiently\" mutually non-singular distributions on X with respect to the distribution of X-for example, the conditions ensure that the conditional distribution of X \u03a0,A,a | X does not have atoms that X itself does not have, and vice versa. For notational and conceptual simplicity, we only consider the case of trivial \u03b6, i.e., where \u03b6(x) = \u03b6(x ) for all x, x \u2208 X .\nProposition F.8. Suppose that 1. For all a \u2208 A and any event S satisfying Pr(X \u2208 S | A = a) > 0, we have, a.s., Pr(X \u03a0,A,a \u2208 S \u2228 A = a | X) > 0.\n2. For all a \u2208 A and > 0, there exists \u03b4 > 0 such that for any event S satisfying Pr(X \u2208 S | A = a) < \u03b4, we have, a.s., Pr(X \u03a0,A,a \u2208 S, A = a | X) < .\nThen, for W = X, any \u03a0-fair policy d(x) is constant a.s. (i.e., d(X) = p a.s. for some 0 \u2264 p \u2264 1).\nProof. Let d max = d(x) \u221e , the essential supremum of d. To establish the theorem statement, we show that Pr(d(X) = d max | A = a) = 1 for all a \u2208 A. To do that, we begin by showing that there exists some a \u2208 A such that Pr(d(X) = d max | A = a) > 0.\nAssume, toward a contradiction, that for all a \u2208 A,\nPr(d(X) = d max | A = a) = 0. (31\n)\nBecause A is finite, there must be some a 0 \u2208 A such that Pr(d max \u2212 d(X) < | A = a 0 ) > 0 (32) for all > 0.\nChoose a 1 = a 0 . We show that for values of x such that d(x) is close to d max , the distribution of d(X \u03a0,A,a1 ) | X = x must be concentrated near d max with high probability to satisfy the definition of path-specific fairness, in Eq. (5). But, under the assumption in Eq. (31), we also show that the concentration occurs with low probability, by the continuity hypothesis in the statement of the theorem, establishing the contradiction.\nSpecifically, by Markov's inequality, for any \u03c1 > 0, a.s.,\nPr(d max \u2212 d(X \u03a0,A,a1 ) \u2265 \u03c1 | X) \u2264 E[d max \u2212 d(X \u03a0,A,a1 ) | X] \u03c1 = d max \u2212 d(X) \u03c1 ,\nwhere the final equality follows from Lemma F.21. Rearranging, it follows that for any \u03c1 > 0, a.s.,\nPr(d max \u2212 d(X \u03a0,A,a1 ) < \u03c1 | X) \u2265 1 \u2212 d max \u2212 d(X) \u03c1 .(33)\nNow let S = {x \u2208 X : d max \u2212 d(x) < \u03c1}. By the second hypothesis of the theorem, we can choose \u03b4 sufficiently small that if Pr(X \u2208 S | A = a 1 ) < \u03b4 then, a.s., Pr(X \u03a0,A,a1 \u2208 S, A = a 1 | X) < 1 2 .\nIn other words, we can chose \u03b4 such that if Pr(d max \u2212 d(X) < \u03c1 | A = a 1 ) < \u03b4 then, a.s.,\nPr(d max \u2212 d(X \u03a0,A,a1 ) < \u03c1, A = a 1 | X) < 1 2\nBy Eq. (31), we can choose > 0 so small that Pr(d max \u2212 d(X) < | A = a 1 ) < \u03b4.\nThen, we have that Pr(d max \u2212 d(X \u03a0,A,a1 ) < , A = a 1 | X) < 1 2 a.s. Further, by the definition of the essential supremum and a 0 , and the fact that a 0 = a 1 , we have that Pr(d max \u2212 d(X) < 2 , A = a 1 ) > 0.\nTherefore, with positive probability, we have that where the first equality follows from Lemma F.21, establishing the result.\n1 \u2212 d max \u2212 d(X) > 1 \u2212 2 = 1 2 > Pr(d max \u2212 d(X \u03a0,A,a1 ) < , A = a 1 | X).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "F.2. A Markov Chain Perspective", "text": "The theory of Markov chains illuminates-and allows us to extend-the proof of Theorem 2. Suppose X = {x 1 , . . . , x n }. 20 For any a \u2208 A, let P a = [p a i,j ] where p a i,j = Pr(X \u03a0,A,a = x j | X = x i ). Then P a is a stochastic matrix.\nTo motivate the subsequent discussion, we first note that this perspective conceptually simplifies some of our earlier results. Lemma F.21 can be recast as stating that when W = X, a policy d is \u03a0-fair if and only if P a d = d-i.e., if and only if d is a 1-eigenvector of P a -for all a \u2208 A.\nThe 1-eigenvectors of Markov chains have a particularly simple structure, which we derive here for completeness. 20 Because of the technical difficulties associated with characterizing the long-run behavior of arbitrary infinite Markov chains, we restrict our attention in this section to Markov chains with finite state spaces.\nLemma F.22. Let S 1 , . . . , S m denote the recurrent classes of a finite Markov chain with transition matrix P . If d is a 1-eigenvector of P , then d takes a constant value p k on each S k , k = 1, . . . , m, and\nd i = m k=1 \uf8ee \uf8f0 lim n\u2192\u221e j\u2208S k P n ij \uf8f9 \uf8fb \u2022 p k .(34)\nRemark 7. We note that lim n\u2192\u221e j\u2208S k P n i,j always exists and is the probability that the Markov chain, beginning at state i, is eventually absorbed by the recurrent class S k .\nProof. Note that, possibly by reordering the states, we can arrange that the stochastic matrix P is in canonical form, i.e., that\nP = B R Q ,\nwhere Q is a sub-stochastic matrix, R is non-negative, and\nB = \uf8ee \uf8ef \uf8ef \uf8ef \uf8f0 P 1 P 2 . . . P m \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fb\nis a block-diagonal matrix with the stochastic matrix P i corresponding to the transition probabilities on the recurrent set S i in the i-th position along the diagonal. Now, consider a 1-eigenvector v = [v 1 v 2 ] of P . We must have that P v = v, i.e., Bv 1 = v 1 and R v 1 + Qv 2 = v 2 . Therefore v 1 is a 1-eigenvector of B. Since B is block diagonal, and each diagonal element is a positive stochastic matrix, it follows by the Perron-Frobenius theorem that the 1-eigenvectors of B are given by SPAN(1 Si ) i=1,...,m , where 1 Si is the vector which is 1 at index j if j \u2208 S i and is 0 otherwise. Now, for v 1 \u2208 SPAN(1 Si ) i=1,...,m , we must find v 2 such that R v 1 + Qv 2 = v 2 .\nNote that every finite Markov chain M can be canonically associated with an absorbing Markov chain M ABS where the set of states of M ABS is exactly the union of the transitive states of M and the recurrent sets of M . (In essence, one tracks which state of M the Markov chain is in until it is absorbed by one of the recurrent sets, at which point the entire recurrent set is treated as a single absorbent state.)\nThe transition matrix P ABS associated with M ABS is given by\nP ABS = I R Q\nwhere R = R [1 S1 . . . 1 Sm ]. In particular, it follows that v = [v 1 v 2 ] is a 1-eigenvector of P if and only if [T v 1 v 2 ] is a 1-eigenvector of P ABS , where T :\n1 Si \u2192 e i .\nNow, if v is a 1-eigenvector of P ABS , then it is a 1eigenvector of (P ABS ) k for all k. Since Q is sub-stochastic, the series Therefore, if v = [v 1 v 2 ] is a 1-eigenvector of P ABS , we must have that (I \u2212 Q) \u22121 Rv 1 = v 2 . By Theorem 3.3.7 in Kemeny & Snell (1976), the (i, k) entry of (I \u2212 Q) \u22121 R is exactly the probability that, conditional on X 0 = x i , the Markov chain is eventually absorbed by the recurrent set S k . This is, in turn, by the Chapman-Kolmogorov equations and the definition of S k , equal to lim n\u2192\u221e j\u2208S k P n i,j , and therefore the result follows.\nWe arrive at the following simple necessary condition on \u03a0-fair policies.\nCorollary F.6. Suppose X is finite, and define the stochastic matrix P = 1 |A| a \u2208A P a . If d(x) is a \u03a0-fair policy then it is constant on the recurrent classes of P .\nProof. By Lemma F.21, d is \u03a0-fair if and only if P a d = d for all a \u2208 A. Therefore,\n1 |A| a \u2208A P a d = 1 |A| a \u2208A d = d,(35)\nand so d is a 1-eigenvector of P . Therefore it is constant on the recurrent classes of P by Lemma F.22.\nWe note that Theorem 2 follows immediately from this.\nProof of Theorem 2. Note that 1 |A| a\u2208A P a decomposes into a block diagonal stochastic matrix, where each block corresponds to a single stratum of \u03b6 and is irreducible. Consequently, each stratum forms a recurrent class, and the result follows.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "G. Proof of Proposition 2", "text": "To prove the proposition, we must characterize the conditional tail risks of the beta distribution. Note that in the main text, we parameterize beta distributions in terms of their mean \u00b5 and sample size v; here, for mathematical simplicity, we parameterize them in terms of successes, \u03b1, and failures, \u03b2, where \u00b5 = \u03b1 \u03b1+\u03b2 and v = \u03b1 + \u03b2. Lemma G.23. Suppose Z i \u223c BETA(\u03b1 i , \u03b2 i ) for i = 0, 1, and that \u03b1 0 > \u03b1 1 > 1, 1 < \u03b2 0 < \u03b2 1 . Then, for all t \u2208 (0, 1], E[Z\n1 | Z 1 < t] < E[Z 0 | Z 0 < t].", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgements", "text": "We thank Guillaume Basse, Jennifer Hill, and Ravi Sojitra for helpful conversations. H.N was supported by a Stanford Knight-Hennessy Scholarship and the National Science Foundation Graduate Research Fellowship under", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "", "text": "Proof. Let Z(\u03b1, \u03b2) \u223c BETA(\u03b1, \u03b2). Then,\nSince \u03b1 > 1, we may take the partial derivative with respect to \u03b1 by differentiating under the integral sign, which yields that\nRearranging gives that this is greater than zero when\nSince all of the integrands are positive,\nTherefore, the result follows.\nWe use this lemma to prove a modest generalization of Prop. 2.\nLemma G.24. Suppose A = {a 0 , a 1 }, and consider the family U of utility functions of the form\nwith 1 < \u03b1 a1 < \u03b1 a0 and 1 < \u03b2 a0 < \u03b2 a1 . Then any policy satisfying counterfactual predictive parity is strongly Pareto dominated.\nProof. Suppose there were a Pareto efficient policy satisfying counterfactual predictive parity. Let \u03bb = 0. Then, by Prop. 1, we may without loss of generality assume that there exist thresholds t a0 , t a1 and a constant p such that a threshold policy \u03c4 (x) witnessing Pareto efficiency is given by\n(Note that by our distributional assumption, Pr(u(x) = t) = 0 for all t \u2208 [0, 1].) Since \u03bb \u2265 0, we must have that t a0 \u2265 t a1 . Since b < 1, 0 < t a0 . Therefore,\nwhere the first equality follows by the law of iterated expectation, the second from the fact that t a1 \u2264 t a0 , the third from our distributional assumption and Lemma G.23, and the final again from the law of iterated expectation. However, since counterfactual predictive parity is satisfied,\nwhich is a contradiction. Therefore, no such threshold policy exists.\nAfter accounting for the difference in parameterization, Prop. 2 follows as a corollary.\n. Therefore 1 < \u03b1 a0 < \u03b1 a1 and 1 < \u03b1 a1 < \u03b1 a0 , and so, by Lemma G.24, the proposition follows.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Genericity with infinitely many parameters", "journal": "Advances in Theoretical Economics", "year": "2001", "authors": "R M Anderson; W R Zame"}, {"ref_id": "b1", "title": "Outcome tests of racial disparities in police practices", "journal": "Justice Research and Policy", "year": "2002", "authors": "I Ayres"}, {"ref_id": "b2", "title": "The sum of an uncountable number of positive numbers. Mathematics Stack Exchange", "journal": "", "year": "2020-05-29", "authors": " Benji"}, {"ref_id": "b3", "title": "Fairness in criminal justice risk assessments: The state of the art", "journal": "Sociological Methods & Research", "year": "2021", "authors": "R Berk; H Heidari; S Jabbari; M Kearns; Roth ; A "}, {"ref_id": "b4", "title": "Are Emily and Greg more employable than Lakisha and Jamal? A field experiment on labor market discrimination", "journal": "American Economic Review", "year": "2004", "authors": "M Bertrand; S Mullainathan"}, {"ref_id": "b5", "title": "Wiley Series in Probability and Mathematical Statistics", "journal": "A Wiley-Interscience Publication", "year": "1995", "authors": "P Billingsley;  Probability;  Measure"}, {"ref_id": "b6", "title": "", "journal": "", "year": "", "authors": "H Brozius"}, {"ref_id": "b7", "title": "Fair allocation through selective information acquisition", "journal": "", "year": "2020", "authors": "W Cai; J Gaebler; N Garg; S Goel"}, {"ref_id": "b8", "title": "The causal fairness field guide: Perspectives from social and formal sciences", "journal": "Frontiers in Big Data", "year": "", "authors": "A N Carey; X Wu"}, {"ref_id": "b9", "title": "Path-specific counterfactual fairness", "journal": "", "year": "2019", "authors": "S Chiappa"}, {"ref_id": "b10", "title": "Learning to be fair: A consequentialist approach to equitable decision-making", "journal": "", "year": "2021", "authors": "A Chohlas-Wood; M Coots; E Brunskill; S Goel"}, {"ref_id": "b11", "title": "Blind justice: Algorithmically masking race in charging decisions", "journal": "", "year": "", "authors": "A Chohlas-Wood; J Nudell; K Yao; Z Lin; J Nyarko; S Goel"}, {"ref_id": "b12", "title": "AAAI/ACM Conference on AI, Ethics, and Society", "journal": "", "year": "2021", "authors": ""}, {"ref_id": "b13", "title": "Fair prediction with disparate impact: A study of bias in recidivism prediction instruments. Big data", "journal": "", "year": "2017", "authors": "A Chouldechova"}, {"ref_id": "b14", "title": "A snapshot of the frontiers of fairness in machine learning", "journal": "Communications of the ACM", "year": "2020", "authors": "A Chouldechova; A Roth"}, {"ref_id": "b15", "title": "On sets of Haar measure zero in Abelian Polish groups", "journal": "Israel Journal of Mathematics", "year": "1972", "authors": "J P R Christensen"}, {"ref_id": "b16", "title": "Test bias: Prediction of grades of Negro and white students in integrated colleges", "journal": "Journal of Educational Measurement", "year": "1968", "authors": "T A Cleary"}, {"ref_id": "b17", "title": "The measure and mismeasure of fairness: A critical review of fair machine learning", "journal": "", "year": "2018", "authors": "S Corbett-Davies; S Goel"}, {"ref_id": "b18", "title": "Algorithmic decision making and the cost of fairness", "journal": "", "year": "2017", "authors": "S Corbett-Davies; E Pierson; A Feller; S Goel; A Huq"}, {"ref_id": "b19", "title": "Counterfactual risk assessments, evaluation, and fairness", "journal": "", "year": "2020", "authors": "A Coston; A Mishler; E H Kennedy; A Chouldechova"}, {"ref_id": "b20", "title": "Another look at \"cultural fairness", "journal": "Journal of Educational Measurement", "year": "1971", "authors": "R B Darlington"}, {"ref_id": "b21", "title": "Fairness through awareness", "journal": "", "year": "2012", "authors": "C Dwork; M Hardt; T Pitassi; O Reingold; R Zemel"}, {"ref_id": "b22", "title": "A causal framework for observational studies of discrimination", "journal": "Statistics and Public Policy", "year": "2022", "authors": "J Gaebler; W Cai; G Basse; R Shroff; S Goel; J Hill"}, {"ref_id": "b23", "title": "Causal feature selection for algorithmic fairness", "journal": "", "year": "", "authors": "S Galhotra; K Shanmugam; P Sattigeri; K R Varshney"}], "figures": [{"figure_label": "", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure1. A causal DAG illustrating a hypothetical process for college admissions. Under path-specific fairness, one may require, for example, that race does not affect decisions along the path highlighted in red.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "For a real-valued utility function u and decision policy d, we write u(d) = E[d(X) \u2022 u(X)] to denote the utility of d under u. Definition 6. For a budget b, we say a decision policy d is feasible if E[d(X)] \u2264 b. Given a collection of utility functions encoding the preferences of different individuals, we say a decision policy d is Pareto dominated if there exists a feasible alternative d such that none of the decision makers prefers d over d , and at least one decision maker strictly prefers d over d, a property formalized in Definition 7. Definition 7. Suppose U is a collection of utility functions. A decision policy d is Pareto dominated if there exists a feasible alternative d such that u(d ) \u2265 u(d) for all u \u2208 U, and there exists u \u2208 U such that u (d ) > u (d). A policy d is strongly Pareto dominated if there exists a feasible alternative d such that u(d ) > u(d) for all u \u2208 U. A policy d is Pareto efficient if it is feasible and not Pareto dominated, and the Pareto frontier is the set of Pareto efficient policies.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Goel, S., Perelman, M., Shroff, R., and Sklansky, D. A.Combatting police discrimination in the age of big data. New Criminal Law Review: An International and Interdisciplinary Journal, 20(2):181-232, 2017.Goldin, C. and Rouse, C. Orchestrating impartiality: The impact of \"blind\" auditions on female musicians. American Economic Review, 90(4):715-741, 2000.Greiner, D. J. and Rubin, D. B. Causal effects of perceived immutable characteristics. Review of Economics and Statistics, 93(3):775-785, 2011. Grogger, J. and Ridgeway, G. Testing for racial profiling in traffic stops from behind a veil of darkness. Journal of the American Statistical Association, 101(475):878-887, 2006. Hardt, M., Price, E., and Srebro, N. Equality of opportunity in supervised learning. Advances in Neural Information Processing Systems, 29:3315-3323, 2016. Holland, P. W. Statistics and causal inference. Journal of the American Statistical Association, 81(396):945-960, 1986. Hu, L. and Kohler-Hausmann, I. What's sex got to do with machine learning? In Proceedings of the 2020 ACM Conference on Fairness, Accountability, and Transparency, 2020. Hunt, B. R., Sauer, T., and Yorke, J. A. Prevalence: a translation-invariant \"almost every\" on infinitedimensional spaces. Bulletin of the American Mathematical Society, 27(2):217-238, 1992. Imai, K. and Jiang, Z. Principal fairness for human and algorithmic decision-making. arXiv preprint arXiv:2005.10400, 2020. Imai, K., Jiang, Z., Greiner, J., Halen, R., and Shin, S. Experimental evaluation of algorithm-assisted human decisionmaking: Application to pretrial public safety assessment. arXiv preprint arXiv:2012.02845, 2020. Imbens, G. W. and Rubin, D. B. Causal Inference in Statistics, Social, and Biomedical Sciences. Cambridge University Press, 2015. Kasy, M. and Abebe, R. Fairness, equality, and power in algorithmic decision-making. In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, pp. 576-586, 2021. Kemeny, J. G. and Snell, J. L. Finite Markov Chains. Undergraduate Texts in Mathematics. Springer-Verlag, New York-Heidelberg, 1976. Reprinting of the 1960 original. Kilbertus, N., Rojas-Carulla, M., Parascandolo, G., Hardt, M., Janzing, D., and Sch\u00f6lkopf, B. Avoiding discrimination through causal reasoning. In Proceedings of the 31st International Conference on Neural Information Processing Systems, pp. 656-666, 2017. Kleinberg, J., Mullainathan, S., and Raghavan, M. Inherent trade-offs in the fair determination of risk scores. In 8th Innovations in Theoretical Computer Science Conference (ITCS). Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik, 2017. Kusner, M., Loftus, J., Russell, C., and Silva, R. Counterfactual fairness. In Proceedings of the 31st International Conference on Neural Information Processing Systems, pp. 4069-4079, 2017. Liang, A., Lu, J., and Mu, X. Algorithmic design: Fairness versus accuracy. arXiv preprint arXiv:2112.09975, 2021. Liu, L. T., Dean, S., Rolf, E., Simchowitz, M., and Hardt, M. Delayed impact of fair machine learning. In International Conference on Machine Learning, pp. 3150-3158. PMLR, 2018. Loftus, J. R., Russell, C., Kusner, M. J., and Silva, R. Causal reasoning for algorithmic fairness. arXiv preprint arXiv:1805.05859, 2018. Mhasawade, V. and Chunara, R. Causal multi-level fairness. In Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society, pp. 784-794, 2021. Mishler, A., Kennedy, E. H., and Chouldechova, A. Fairness in risk assessment instruments: Post-processing to achieve counterfactual equalized odds. In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, pp. 386-400, 2021. Nabi, R. and Shpitser, I. Fair inference on outcomes. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 32, 2018. Ott, W. and Yorke, J. Prevalence. Bulletin of the American Mathematical Society, 42(3):263-290, 2005. Page, S. E. Making the difference: Applying a logic of diversity. Academy of Management Perspectives, 21(4): 6-20, 2007. Pearl, J. Direct and indirect effects. In Proceedings of the Seventeenth Conference on Uncertainty and Artificial Intelligence, 2001, pp. 411-420. Morgan Kaufman, 2001. Pearl, J. Causal inference in statistics: An overview. Statistics surveys, 3:96-146, 2009a. Pearl, J. Causality. Cambridge University Press, second edition, 2009b.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "x) strongly Pareto dominates d(x). Now, we prove the second claim, namely, that a multiple threshold policy \u03c4 (x) that cannot be represented with non-negative thresholds is strongly Pareto dominated. For, if \u03c4 (x) is such a policy, then, by Lemma D.1, for any u \u2208 U, E[\u03c4 (X) \u2022 1 u(X)<0 ] > 0. It follows immediately that \u03c4 (x) = \u03c4 (x) \u2022 1 u(x)>0 satisfies u(\u03c4 ) > u(\u03c4 ). By consistency modulo \u03b1, the definition of \u03c4 (x) does not depend on our choice of u, and so u(\u03c4 ) > u(\u03c4 ) for every u \u2208 U, i.e., \u03c4 (x) strongly Pareto dominates \u03c4 (x).", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "q 3 4\u22123a,y = Pr \u00b5 (A = a, Y = y, U > 1), r a,y = Pr \u00b5 (A = a, Y = y, U = 1), \u03c0 a,y = Pr \u00b5 (A = a, Y = y), r a0,y + r a1,y = Pr \u00b5 (Y = y, U = 1), \u03c0 a0,y + \u03c0 a1,y = Pr \u00b5 (Y = y), S = Pr \u00b5 (U > 1)Pr \u00b5 (U = 1) . Now, we recall that | Pr \u00b5 (E) \u2212 Pr \u00b5 (E)| < 1 64 for any event E by hypothesis. Therefore,", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Lemma F.21. A decision policy d(x) satisfies path-specific fairness with W = X if and only if any a \u2208 A,E[d(X \u03a0,A,a ) | X] = d(X).", "figure_data": ""}, {"figure_label": "0", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "0 10where F U is the distribution of U . (For a proof of this fact see, for example,Brozius, 2019)    Now, we have thatE[D \u03a0,A,a | X \u03a0,A,a ] = E[1 U D \u2264d(X \u03a0,A,a ) | X \u03a0,A,a ] = 1 u\u2264d(X \u03a0,A,a ) du = d(X \u03a0,A,a ),where the first equality follows from the definition of D \u03a0,A,a , and the second from Eq. (30), since the exogenous variable U D \u223c UNIF(0, 1) is independent of the counterfactual covariates X \u03a0,A,a . An analogous argument shows thatE[D | X] = d(X).Finally, conditioning on X, we haveE[d(X \u03a0,A,a ) | X] = E[E[D \u03a0,A,a | X \u03a0,A,a ] | X] = E[E[D \u03a0,A,a | X \u03a0,A,a , X] | X] = E[D \u03a0,A,a | X] = E[D | X] = d(X),", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "This contradicts Eq. (33), and so it cannot be the case thatPr(d(X) = d max | A = a 0 ) = 0, meaning Pr(d(X) = d max | A = a 0 ) > 0. Now, we show that Pr(d(X) = d max | A = a 1 ) = 1. Suppose, toward a contradiction, that Pr(d(X) < d max | A = a 1 ) > 0.Then, by the first hypothesis, a.s.,Pr(d(X\u03a0,A,a1 ) < d max \u2228 A = a 1 | X) > 0 As a consequence, d max = E[d(X) | d(X) = d max , A = a 0 ] = E[E[d(X \u03a0,A,a1 ) | X] | d(X) = d max , A = a 0 ] < E[E[d max | X] | d(X) = d max , A = a 0 ] = E[d max | d(X) = d max , A = a 0 ] = d max ,where we can condition on the set {d(X) = d max , A = a 0 } since Pr(d(X) = d max | A = a 0 ) > 0; and the second equality above follows from Lemma F.21. This establishes the contradiction, and so Pr(d(X) = d max | A = a 1 ) = 1.Finally, we extend this equality to all a \u2208 A. Since, Pr(d(X) = d max | A = a 1 ) = 0, we have, by the second hypothesis of the theorem, that, a.s.,Pr(d(X \u03a0,A,a1 ) = d max , A = a 1 | X) = 0.Since, by definition, Pr(X \u03a0,A,a1 = X | A = a 1 ) = 1, and Pr(d(X) = d max | A = a 1 ) = 1, we can strengthen this toPr(d(X \u03a0,A,a1 ) = d max | X) = 0. Consequently, a.s., d(X) = E[d(X \u03a0,A,a ) | X] = E[d max | X] = d max ,", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "\u221ek=0 Q k converges to (I \u2212 Q) \u22121 . Since(P ABS ) k = I (I + Q + \u2022 \u2022 \u2022 + Q k\u22121 )R Q k , it follows that lim k\u2192\u221e (P ABS ) k = I (I \u2212 Q) \u22121 R 0 .", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "/q/3197508. (Version: 2019-04-22). Wang, Y., Sridhar, D., and Blei, D. M. Equal opportunity and affirmative action via counterfactual predictions. arXiv preprint arXiv:1905.10870, 2019. In Proceedings of the 31st International Conference on Neural Information Processing Systems, pp. 228-238, 2017b. Zhang, J. and Bareinboim, E. Fairness in decisionmaking-the causal explanation formula. In Thirty-Second AAAI Conference on Artificial Intelligence, 2018. Zhang, L., Wu, Y., and Wu, X. A causal framework for discovering and removing direct and indirect discrimination. In Proceedings of the 26th International Joint Conference on Artificial Intelligence, pp. 3929-3935, 2017.", "figure_data": "):736-745,2020.Rao, M. M. Conditional measures and applications, vol-ume 271 of Pure and Applied Mathematics (Boca Raton).Chapman & Hall/CRC, Boca Raton, FL, second edition,2005.Rudin, W. Real and Complex Analysis. McGraw-Hill BookCo., New York, third edition, 1987. ISBN 0-07-054234-1.Rudin, W. Functional Analysis. International Series in Pureand Applied Mathematics. McGraw-Hill, Inc., New York,second edition, 1991. ISBN 0-07-054236-8."}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Algorithm 1: Path-specific counterfactuals Data: G (topologically ordered), \u03a0, a, and a Result: A sample Z * \u03a0,a,a from Z \u03a0,a,a 1 Sample values {U * j } for the exogenous variables / * Compute counterfactuals by setting A to a * / 2 for j = 1, . . . , m do 3", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "D \u22a5 \u22a5 A | Y (1).(2)", "formula_coordinates": [3.0, 141.35, 251.25, 148.09, 8.96]}, {"formula_id": "formula_1", "formula_text": "D \u22a5 \u22a5 A | Y (0), Y (1), W,(3)", "formula_coordinates": [3.0, 121.99, 392.29, 167.45, 8.96]}, {"formula_id": "formula_2", "formula_text": "E[D(a ) | X] = E[D | X].(4)", "formula_coordinates": [3.0, 371.02, 290.08, 170.42, 8.96]}, {"formula_id": "formula_3", "formula_text": "A * = a, A * = a , E * = f E (A * ), E * = f E (A * ), M * = f M (E * ), M * = f M (E * ), T * = f T (E * , M * ), T * = f T (E * , M * ), D * = f D (A * , T * ), D * = f D (A * , T * ).", "formula_coordinates": [4.0, 330.41, 265.49, 188.07, 82.56]}, {"formula_id": "formula_4", "formula_text": "E[D \u03a0,A,a | W ] = E[D | W ].(5)", "formula_coordinates": [4.0, 365.25, 599.83, 176.19, 9.65]}, {"formula_id": "formula_5", "formula_text": "f D (x, u D ) = 1 u D \u2264d(x)", "formula_coordinates": [4.0, 325.25, 708.26, 93.77, 10.57]}, {"formula_id": "formula_6", "formula_text": "u D \u223c UNIF(0, 1), so that Pr(D = 1 | X = x) = d(x).", "formula_coordinates": [5.0, 55.44, 70.22, 223.72, 9.65]}, {"formula_id": "formula_7", "formula_text": "u(x) = E[Y (1) | X = x] + \u03bb \u2022 1 \u03b1(x)=a1 ,(6)", "formula_coordinates": [5.0, 89.78, 497.36, 199.66, 9.96]}, {"formula_id": "formula_8", "formula_text": "[Y (1) | A = a1] = E[Y (1) | A = a2], then Eq. (1) cannot hold. Similar counterexamples can be constructed for b 1.", "formula_coordinates": [5.0, 55.44, 689.01, 234.0, 27.99]}, {"formula_id": "formula_9", "formula_text": "d * \u2208 arg max d\u2208C E[d(X) \u2022 u(X)] s.t. E[d(X)] \u2264 b.(7)", "formula_coordinates": [5.0, 359.75, 90.61, 181.69, 31.41]}, {"formula_id": "formula_10", "formula_text": "x 1 ) = \u03b1(x 2 ), u(x 1 ) > u(x 2 ) if and only if u (x 1 ) > u (x 2 ).", "formula_coordinates": [6.0, 75.36, 368.09, 214.08, 21.61]}, {"formula_id": "formula_11", "formula_text": "d(x) = 1 u(x) > t \u03b1(x) , 0 u(x) < t \u03b1(x) .(8)", "formula_coordinates": [6.0, 116.79, 500.72, 172.65, 24.3]}, {"formula_id": "formula_12", "formula_text": "(1) E[d (X)|A] = E[d(X)|A]; and (2) u(d ) = u(d).", "formula_coordinates": [6.0, 55.44, 679.05, 234.0, 17.83]}, {"formula_id": "formula_13", "formula_text": "(x) = E[Y (1)|X = x].", "formula_coordinates": [6.0, 316.18, 708.94, 85.94, 7.86]}, {"formula_id": "formula_14", "formula_text": "\u2206 m\u22121 = {p \u2208 R m | p i \u2265 0 and m i=1 p i = 1}. Since \u2206 m\u22121 is a subset of an (m \u2212 1)-dimensional hyperplane in R m ,", "formula_coordinates": [7.0, 54.61, 589.24, 234.83, 35.83]}, {"formula_id": "formula_15", "formula_text": "x * \u2208 arg max x\u2208X d(x).", "formula_coordinates": [8.0, 169.88, 463.17, 96.55, 11.22]}, {"formula_id": "formula_16", "formula_text": "d(x * ) = E[D \u03a0,A,a | X = x * ] = x\u2208\u03b1 \u22121 (a) d(x) \u2022 Pr(X \u03a0,A,a = x | X = x * ). (9)", "formula_coordinates": [8.0, 69.58, 501.7, 219.86, 41.73]}, {"formula_id": "formula_17", "formula_text": "d(x ) = E[D \u03a0,A,a | X = x ] = x\u2208\u03b1 \u22121 (a ) d(x) \u2022 Pr(X \u03a0,A,a = x | X = x ) = x\u2208\u03b1 \u22121 (a ) d(x * ) \u2022 Pr(X \u03a0,A,a = x | X = x * ), = d(x * ),", "formula_coordinates": [8.0, 324.65, 100.54, 199.58, 85.98]}, {"formula_id": "formula_18", "formula_text": "1. Z = Z \u03a0,A,a for all a \u2208 A, 2. Pr(X \u03a0,A,a = x | X = x) > 0 for all a \u2208 A such that \u03b1(x) = a and x, x \u2208 X such that \u03b6(x) = \u03b6(x ).", "formula_coordinates": [8.0, 314.91, 359.27, 227.65, 39.2]}, {"formula_id": "formula_19", "formula_text": "A | D = 0.", "formula_coordinates": [9.0, 55.44, 434.85, 51.18, 8.74]}, {"formula_id": "formula_20", "formula_text": "u(x) = r(x) + \u03bb \u2022 1 \u03b1(x)=a1 , indexed by \u03bb \u2265 0, where r(x) = E[Y (1) | X = x]", "formula_coordinates": [9.0, 55.44, 592.23, 209.02, 26.36]}, {"formula_id": "formula_21", "formula_text": ") | A = a \u223c BETA(\u00b5 a , v),", "formula_coordinates": [9.0, 126.86, 651.39, 107.32, 9.65]}, {"formula_id": "formula_22", "formula_text": "if V j = A then 4 V * j \u2190 a 5 else 6 \u2118(V j ) * \u2190 {V * | V \u2208 \u2118(V j )} 7 V * j \u2190 f Vj (\u2118(V j ) * , U * j ) 8 end 9 end", "formula_coordinates": [13.0, 61.92, 173.2, 160.11, 84.4]}, {"formula_id": "formula_23", "formula_text": "11 if V j = A then V * j \u2190 a 13 else for V k \u2208 \u2118(V j ) do if edge (V k , V j ) lies on a path in \u03a0 then 16 V \u2020 k \u2190 V * k else 18 V \u2020 k \u2190 V * k end end \u2118(V j ) \u2020 \u2190 {V \u2020 | V \u2208 \u2118(V j )} V * j \u2190 f Vj (\u2118(V j ) \u2020 , U * j ) 23 end 24 end 25 Z * \u03a0,a,a \u2190 Z *", "formula_coordinates": [13.0, 58.43, 314.09, 216.07, 199.01]}, {"formula_id": "formula_24", "formula_text": "\u2206 k\u22121 = {p \u2208 R k | p i \u2265 0 and k i=1 p i = 1} be the unit (k \u2212 1)- simplex.", "formula_coordinates": [13.0, 75.36, 645.52, 215.73, 35.6]}, {"formula_id": "formula_25", "formula_text": "Letting p i = Pr(X = x i ) denote the mass of X at x i , note that the objective function E[d(X) \u2022 u(X)] equals m i=1 d i \u2022 u(x i ) \u2022 p i and the budget constraint m i=1 d i \u2022 p i \u2264 b are both linear in the decision variables.", "formula_coordinates": [13.0, 307.44, 148.54, 234.0, 44.82]}, {"formula_id": "formula_26", "formula_text": "D \u22a5 \u22a5 A | Y (1). Since D is binary, this condition is equivalent to the expression E[d(X) | A = a, Y (1) = y] = E[d(X) | Y (1) = y]", "formula_coordinates": [13.0, 307.44, 274.12, 235.25, 32.65]}, {"formula_id": "formula_27", "formula_text": "m i=1 d i \u2022 Pr(X = x i | A = a, Y (1) = y) = m i=1 d i \u2022 Pr(X = x i | Y (1) = y)", "formula_coordinates": [13.0, 319.81, 352.88, 211.67, 63.51]}, {"formula_id": "formula_28", "formula_text": ") | A = a, Y (0) = y 0 , Y (1) = y 1 , W = w] = E[d(X) | Y (0) = y 0 , Y (1) = y 1 , W = w] for all y 0 , y 1 , and w satisfying Pr(Y (0) = y 0 , Y (1) = y 1 , W = w) > 0.", "formula_coordinates": [13.0, 307.44, 512.81, 234.0, 45.52]}, {"formula_id": "formula_29", "formula_text": "m i=1 d i \u2022 Pr(X = x i | A = a, S = s) = m j=1 d i \u2022 Pr(X = x i | S = s)", "formula_coordinates": [13.0, 319.81, 600.77, 211.67, 63.51]}, {"formula_id": "formula_30", "formula_text": "), Y (1), W ) such that s = (y 0 , y 1 , w) \u2208 Y \u00d7 Y \u00d7 W satisfies Pr(Y (0) = y 0 , Y (1) = y 1 , W = w) > 0.", "formula_coordinates": [13.0, 307.44, 684.35, 233.18, 21.61]}, {"formula_id": "formula_31", "formula_text": "\u2208 A, E[D \u03a0,A,a | W ] = E[D | W ].", "formula_coordinates": [14.0, 122.03, 106.08, 140.45, 9.65]}, {"formula_id": "formula_32", "formula_text": "als that D \u03a0,A,a = f D (X \u03a0,A,a , U D ) = 1 U D \u2264d(X \u03a0,A,a ) , where U D \u22a5 \u22a5 {X \u03a0,A,a , X}. Since W = \u03c9(X), U D \u22a5 \u22a5 {X \u03a0,A,a , W }, it follows that E[D \u03a0,A,a | W = w] = m i=1 E[D \u03a0,A,a | X \u03a0,A,a = x i , W = w] \u2022 Pr(X \u03a0,A,a = x i | W = w) = m i=1 E[1 U D \u2264d(X \u03a0,A,a ) | X \u03a0,A,a = x i , W = w] \u2022 Pr(X \u03a0,A,a = x i | W = w) = m i=1 d(X \u03a0,A,a ) \u2022 Pr(X \u03a0,A,a = x i | W = w) = m i=1 d i \u2022 Pr(X \u03a0,A,a = x i | W = w).", "formula_coordinates": [14.0, 55.08, 135.97, 235.6, 220.43]}, {"formula_id": "formula_33", "formula_text": "E[D | W = w] = m i=1 d i \u2022 Pr(X = x i | W = w). Equating these expres- sions gives m i=1 d i \u2022 Pr(X = x i | W = w) = m i=1 d i \u2022 Pr(X \u03a0,A,a = x i | W = w)", "formula_coordinates": [14.0, 55.44, 365.78, 235.65, 107.68]}, {"formula_id": "formula_34", "formula_text": "Theorem B.1 Part 3 A decision policy satisfies counter- factual predictive parity if Y (1) \u22a5 \u22a5 A | D = 0, or equiva- lently, Pr(Y (1) = y | A = a, D = 0) = Pr(Y (1) | D = 0) for all a \u2208 A.", "formula_coordinates": [14.0, 55.44, 531.01, 235.66, 44.89]}, {"formula_id": "formula_35", "formula_text": "Pr(Y (1) = y, A = a, D = 0) Pr(A = a, D = 0) = C y ,where", "formula_coordinates": [14.0, 55.08, 585.97, 192.21, 41.56]}, {"formula_id": "formula_36", "formula_text": "C y = Pr(Y (1) = y | D = 0).", "formula_coordinates": [14.0, 81.91, 618.58, 120.46, 9.65]}, {"formula_id": "formula_37", "formula_text": "Pr(Y (1) = y, A = a, D = 0) = m i=1 [1 \u2212 d i ] \u2022 Pr(Y (1) = y, A = a, X = x i )", "formula_coordinates": [14.0, 67.06, 671.48, 212.41, 43.93]}, {"formula_id": "formula_38", "formula_text": "Pr(Y (1) = y, D = 0) = m i=1 [1 \u2212 d i ] \u2022 Pr(Y (1) = y, X = x i ).", "formula_coordinates": [14.0, 319.06, 93.7, 212.41, 43.93]}, {"formula_id": "formula_39", "formula_text": "m i=1 [1 \u2212 d i ] \u2022 Pr(Y (1) = y, A = a, X = x i ) = C y \u2022 m i=1 [1 \u2212 d i ] \u2022 Pr(Y (1) = y, X = x i ),(10)", "formula_coordinates": [14.0, 315.13, 176.5, 226.32, 63.51]}, {"formula_id": "formula_40", "formula_text": "m i=1 d i \u2022u(x i )\u2022p i and budget constraint m i=1 d i \u2022p i \u2264 b", "formula_coordinates": [14.0, 307.44, 300.02, 234.0, 23.66]}, {"formula_id": "formula_41", "formula_text": "U A , U D , U Y \u223c UNIF(0, 1), U E , U M , U T \u223c N(0, 1). For fixed constants \u00b5 A , \u03b2 E,0 , \u03b2 E,A , \u03b2 M,0 , \u03b2 M,E , \u03b2 T,0 , \u03b2 T,E , \u03b2 T,M , \u03b2 T,B , \u03b2 T,u , \u03b2 Y,0 , \u03b2 Y,D", "formula_coordinates": [14.0, 307.44, 473.03, 235.25, 57.04]}, {"formula_id": "formula_42", "formula_text": "f A (u A ) = a 1 if u A \u2264 \u00b5 A a 0 otherwise , f E (a, u E ) = \u03b2 E,0 + \u03b2 E,A \u2022 1(a = a 1 ) + u E , f M (e, u M ) = \u03b2 M,0 + \u03b2 M,E \u2022 e + u M , f T (e, m, u T ) = \u03b2 T,0 + \u03b2 T,E \u2022 e + \u03b2 T,M \u2022 m + \u03b2 T,B \u2022 e \u2022 m + \u03b2 T,u \u2022 u T , f D (x, u D ) = 1(u D \u2264 d(x)), f Y (m, u Y , \u03b4) = 1(u Y \u2264 logit \u22121 (\u03b2 Y,0 + m + \u03b2 Y,D \u2022 \u03b4)),", "formula_coordinates": [14.0, 308.51, 566.66, 231.85, 117.39]}, {"formula_id": "formula_43", "formula_text": "\u00b5 A = 1 3 , \u03b2 E,0 = 1, \u03b2 E,A = \u22121, \u03b2 M,0 = 0, \u03b2 M,E = 1, \u03b2 T,0 = 50, \u03b2 T,E = 4, \u03b2 T,M = 4, \u03b2 T,u = 7, \u03b2 T,B = 1, \u03b2 Y,0 = \u2212 1 2 , \u03b2 Y,D = 1 2 .", "formula_coordinates": [14.0, 506.26, 706.37, 36.42, 13.47]}, {"formula_id": "formula_44", "formula_text": "d(x) = 1 u(x) > t, 0 u(x) < t,and", "formula_coordinates": [15.0, 55.44, 223.36, 163.24, 43.66]}, {"formula_id": "formula_45", "formula_text": "d(x) \u2208 [0, 1] is arbitrary if u(x) = t.", "formula_coordinates": [15.0, 72.53, 258.07, 146.99, 8.96]}, {"formula_id": "formula_46", "formula_text": "d(x) = 1 u(x) > t \u03b1(x) , 0 u(x) < t \u03b1(x) , and d(x) \u2208 [0, 1] is arbitrary if u(x) = t \u03b1(x) .", "formula_coordinates": [15.0, 55.44, 302.76, 179.54, 44.66]}, {"formula_id": "formula_47", "formula_text": "X \u2192 [0, 1] is a decision rule. If d(x)", "formula_coordinates": [15.0, 55.27, 481.94, 235.91, 20.69]}, {"formula_id": "formula_48", "formula_text": "t a = inf x\u2208Sa u(x)", "formula_coordinates": [15.0, 141.62, 704.82, 61.64, 14.58]}, {"formula_id": "formula_49", "formula_text": "d(x) = 1 if u(x) > t \u03b1(x) , 0 if u(x) < t \u03b1(x) ,", "formula_coordinates": [15.0, 364.51, 261.92, 118.68, 24.3]}, {"formula_id": "formula_50", "formula_text": "Let b = E[d(X)]. Define m Lo (t) = E[d(X) \u2022 1 u(X)<t ], m Up (t) = E[(1 \u2212 d(X)) \u2022 1 u(X)>t ].", "formula_coordinates": [15.0, 307.44, 612.36, 189.95, 48.57]}, {"formula_id": "formula_51", "formula_text": "t = inf{t \u2208 R : m Up (t) = 0}.", "formula_coordinates": [15.0, 363.79, 706.18, 121.31, 10.81]}, {"formula_id": "formula_52", "formula_text": "d (x) = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 (1 \u2212 m Up ) \u2022 d(x) u(x) < t * , d(x) u(x) = t * , 1 \u2212 (1 \u2212 m Lo ) \u2022 (1 \u2212 d(x)) u(x) > t * .", "formula_coordinates": [16.0, 67.93, 203.22, 207.84, 40.47]}, {"formula_id": "formula_53", "formula_text": "E[d (X)] = (1 \u2212 m Up ) \u2022 m Lo + E[d(X) \u2022 1 u(X)=t * ] + Pr(u(X) > t * ) \u2212 (1 \u2212 m Lo ) \u2022 m Up = m Lo + E[d(X) \u2022 1 u(X)=t * ] + Pr(u(X) > t * ) \u2212 m Up = E[d(X) \u2022 1 u(X)<t * ] + E[d(X) \u2022 1 u(X)=t * ] + E[1 u(X)>t * ] \u2212 E[(1 \u2212 d(X)) \u2022 1 u(X)>t * ] = E[d(X)] = b, so d (x) is feasible. However, d (x) \u2212 d(x) = m Lo \u2022 (1 \u2212 d(x)) \u2022 1 u(x)>t * \u2212 m Up \u2022 d(x) \u2022 1 u(x)<t * , and so E[(d (X) \u2212 d(X)) \u2022 u(X)] = m Lo \u2022 E[(1 \u2212 d(X)) \u2022 1 u(X)>t * \u2022 u(X)] \u2212 m Up \u2022 E[d(X) \u2022 1 u(X)<t * \u2022 u(X)] > m Lo \u2022 t * \u2022 E[(1 \u2212 d(X)) \u2022 1 u(X)>t * ] \u2212 m Up \u2022 t * \u2022 E[d(X) \u2022 1 u(X)<t * ] = t * \u2022 m Lo \u2022 m Up \u2212 t * \u2022 m Up \u2022 m Lo = 0. Therefore E[d(X) \u2022 u(X)] < E[d (X) \u2022 u(X)]. It remains to show that u (d ) > u (d) for arbitrary u \u2208 U. Let t = inf{u (x) : d (x) > d(x)}.", "formula_coordinates": [16.0, 55.13, 275.44, 236.05, 412.08]}, {"formula_id": "formula_54", "formula_text": "E[(d (X) \u2212 d(X)) \u2022 1 u (X)>t ] = m Up > 0. Since E[d (X) \u2212 d(X)] = 0, we see that E[(d (X) \u2212 d(X)) \u2022 u (X)] = E[(d (X) \u2212 d(X)) \u2022 1 u (X)>t \u2022 u (X)] + E[(d (X) \u2212 d(X)) \u2022 1 u (X)\u2264t \u2022 u (X)] > t \u2022 E[(d (X) \u2212 d(X)) \u2022 1 u (X)>t ] + t \u2022 E[(d (X) \u2212 d(X)) \u2022 1 u (X)\u2264t ] = t \u2022 E[d (X) \u2212 d(X)] = 0,", "formula_coordinates": [16.0, 307.44, 138.75, 230.78, 146.05]}, {"formula_id": "formula_55", "formula_text": "d (x) > d(x), u (x) > t , and if d (x) < d(x), u (x) \u2264 t . There- fore E[d(X) \u2022 u (X)] < E[d (X) \u2022 u (X)], i.e., d(", "formula_coordinates": [16.0, 307.44, 298.85, 235.66, 65.36]}, {"formula_id": "formula_56", "formula_text": "Definition D.2. We say that a decision policy d(x) is budget-exhausting if min(b, Pr(u(X) > 0)) \u2264 E[d(X)] \u2264 min(b, Pr(u(X) \u2265 0)).", "formula_coordinates": [16.0, 307.44, 524.82, 234.0, 57.94]}, {"formula_id": "formula_57", "formula_text": "E[\u03c4 (X)] < E[\u03c4 (X) \u2022 1 u(X)>0 ],", "formula_coordinates": [17.0, 109.81, 198.46, 125.27, 9.96]}, {"formula_id": "formula_58", "formula_text": "d(x) = \u03b8 \u2022 1 u(x)>0 + (1 \u2212 \u03b8) \u2022 \u03c4 (x).", "formula_coordinates": [17.0, 99.11, 281.58, 146.67, 9.96]}, {"formula_id": "formula_59", "formula_text": "E[d(X)] = \u03b8 \u2022 Pr(u(X) > 0) + (1 \u2212 \u03b8) \u2022 E[\u03c4 (X)],", "formula_coordinates": [17.0, 70.39, 322.86, 204.1, 8.74]}, {"formula_id": "formula_60", "formula_text": ") | A = a] = q a .", "formula_coordinates": [17.0, 188.81, 508.22, 67.73, 9.65]}, {"formula_id": "formula_61", "formula_text": "t a = inf{s \u2208 R : Pr(u(X) > s) < q a }.(11)", "formula_coordinates": [17.0, 92.7, 553.64, 196.74, 9.65]}, {"formula_id": "formula_62", "formula_text": "p a = qa\u2212Pr(u(X)>ta|A=a) Pr(u(X)=ta|A=a) Pr(u(X) = t a , A = a) > 0 0 Pr(u(X) = t a , A = a) = 0. Note that Pr(u(X) \u2265 t a | A = a) \u2265 q a , since, by defi- nition, Pr(u(X) > t a \u2212 | A = a) \u2265 q a for all > 0. Therefore, Pr(u(X) > t a | A = a) + Pr(u(X) = t a | A = a) \u2265 q a ,", "formula_coordinates": [17.0, 55.13, 591.49, 236.05, 93.82]}, {"formula_id": "formula_63", "formula_text": "d(x) = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 1 u(x) > t \u03b1(x) , p a u(x) = t \u03b1(x) , 0 u(x) < t \u03b1(x) ,", "formula_coordinates": [17.0, 365.95, 90.5, 115.78, 41.69]}, {"formula_id": "formula_64", "formula_text": ") | A = a] = q a .", "formula_coordinates": [17.0, 466.44, 145.12, 76.75, 9.65]}, {"formula_id": "formula_65", "formula_text": "n [E + v] = \u03bb n [E].", "formula_coordinates": [18.0, 126.73, 434.55, 76.72, 9.65]}, {"formula_id": "formula_66", "formula_text": "Definition E.3 (", "formula_coordinates": [18.0, 55.44, 550.97, 65.78, 9.03]}, {"formula_id": "formula_67", "formula_text": "C \u2286 V such that 0 < \u00b5[C] < \u221e, 2. For all v \u2208 V , \u00b5[E + v] = 0.", "formula_coordinates": [18.0, 62.91, 614.76, 226.53, 44.72]}, {"formula_id": "formula_68", "formula_text": "Proposition E.3 (", "formula_coordinates": [18.0, 307.44, 109.92, 71.88, 9.03]}, {"formula_id": "formula_69", "formula_text": "\u2022 If V = R n , then G \u2286 R n is prevalent if and only if \u03bb n [R n \\ G] = 0.", "formula_coordinates": [18.0, 318.89, 225.51, 222.54, 23.18]}, {"formula_id": "formula_70", "formula_text": "SUPP(\u00b5) \u2286 (\u03b4(C \u2212 c) + c) \u2229 (U + c),and", "formula_coordinates": [18.0, 307.44, 463.76, 195.12, 30.68]}, {"formula_id": "formula_71", "formula_text": "\u00b5[E + v] = 0 for every v \u2208 V . We say that E is shy in C or shy relative to C if E is shy in C at c for every c \u2208 C. An arbitrary set F \u2286 V is shy in C if there exists a universally measurable shy set E \u2286 C containing F . A set G is prevalent in C if C \\ G is shy in C.", "formula_coordinates": [18.0, 306.97, 485.48, 234.47, 80.69]}, {"formula_id": "formula_72", "formula_text": "\u2022 Any prevalent set in C is dense in C; \u2022 If G \u2286 L and G is prevalent in C, then L is prevalent in C; \u2022 A countable intersection of sets prevalent in C is preva- lent in C \u2022 If G is prevalent in C then G + v is prevalent in C + v for all v \u2208 V . \u2022 If V = R n and C \u2286 V is a convex subset with non- empty interior, then G \u2286 C is prevalent in C if and only if \u03bb n [C \\ G] = 0.", "formula_coordinates": [18.0, 318.89, 708.26, 155.88, 8.96]}, {"formula_id": "formula_73", "formula_text": "dimensional subspace W \u2286 V such that 1. A translate of the set C has positive Lebesgue measure in W , i.e., \u03bb W [C + v 0 ] > 0 for some v 0 \u2208 V ; 2. Every translate of the set E is a Lebesgue null set in W , i.e., \u03bb W [E + v] = 0 for all v \u2208 V .", "formula_coordinates": [19.0, 55.44, 294.63, 234.0, 80.69]}, {"formula_id": "formula_74", "formula_text": "W \u2286 V . If a set E \u2286 V is small in each cross section-i.e., if \u03bb W [E + v] = 0 for all v \u2208 V -then E itself is small in V , i.e., E has \u03bb V -measure zero. Proposition E.6 (Anderson & Zame (2001)). Every k-shy set in C is shy in C.", "formula_coordinates": [19.0, 55.44, 497.82, 234.0, 72.71]}, {"formula_id": "formula_75", "formula_text": "|\u00b5|[E] = sup \u221e i=1 |\u00b5[E i ]| (12)", "formula_coordinates": [20.0, 375.07, 85.66, 166.37, 30.32]}, {"formula_id": "formula_76", "formula_text": "|\u00b5[E]| \u2264 |\u00b5|[E] for all E \u2208 M.", "formula_coordinates": [20.0, 307.44, 214.51, 234.0, 20.69]}, {"formula_id": "formula_77", "formula_text": "E | A = a ) = Pr(X \u03a0,A,a \u2208 E | A = a ) for all Borel sets E \u2286 X . (See \u00a7 3.6.3 in Pearl (2009b).)", "formula_coordinates": [20.0, 307.44, 360.33, 234.0, 32.87]}, {"formula_id": "formula_78", "formula_text": "ping E \u2192 \u00b5[E \u2229 E ].", "formula_coordinates": [20.0, 307.44, 461.95, 94.08, 8.96]}, {"formula_id": "formula_79", "formula_text": "E \u2192 E \u00b5 [f \u2022 1 E ]", "formula_coordinates": [20.0, 475.95, 521.73, 65.49, 9.65]}, {"formula_id": "formula_80", "formula_text": "E \u00b5 [f | g] to be E \u00b5 [f | \u03c3(g)],", "formula_coordinates": [20.0, 347.6, 557.59, 113.34, 9.65]}, {"formula_id": "formula_81", "formula_text": "E \u00b5 [f | g] \u2022 1 g=c = E \u00b5 [f \u2022 1 g=c ] Pr \u00b5 (g = c) \u2022 1 g=c .", "formula_coordinates": [20.0, 345.04, 660.06, 158.81, 23.23]}, {"formula_id": "formula_82", "formula_text": "\u00b5[E] = 0, \u03bd[E] = 0.", "formula_coordinates": [21.0, 55.44, 355.41, 82.49, 8.74]}, {"formula_id": "formula_83", "formula_text": "\u03bd[E] = lim n\u2192\u221e \u03bd i [E] = lim n\u2192\u221e 0 = 0, since \u03bd i \u00ce \u00b5 for all i.", "formula_coordinates": [21.0, 55.44, 512.51, 155.24, 70.35]}, {"formula_id": "formula_84", "formula_text": "\u2022 f \u22121 on V by the map E \u2192 \u00b5[f \u22121 (E )] for E \u2208 M .", "formula_coordinates": [21.0, 55.44, 648.83, 234.0, 22.49]}, {"formula_id": "formula_85", "formula_text": "\u00b5 \u2022 u \u22121 [E] = E f \u00b5 d\u03bb.", "formula_coordinates": [21.0, 375.2, 154.32, 98.48, 19.31]}, {"formula_id": "formula_86", "formula_text": "u A : (a, (x a ) a \u2208A ) \u2192 (u(x a )) a \u2208A .", "formula_coordinates": [21.0, 349.17, 265.9, 150.54, 11.72]}, {"formula_id": "formula_87", "formula_text": "Pr \u00b5 (u(X) \u2208 E, A = a) = E f \u00b5,a d\u03bb, so that f \u00b5 = a\u2208A f \u00b5,a .", "formula_coordinates": [21.0, 307.44, 445.88, 195.35, 39.09]}, {"formula_id": "formula_88", "formula_text": "E Up = {x \u2208 R : f \u00b5 (x) > f \u00b5 (x)} E Lo = {x \u2208 R : f \u00b5 (x) < f \u00b5 (x)}.", "formula_coordinates": [22.0, 102.16, 129.56, 140.56, 28.17]}, {"formula_id": "formula_89", "formula_text": "f \u00b5 \u2212 f \u00b5 L 1 (R) = E Up f \u00b5 \u2212 f \u00b5 d\u03bb + E Lo f \u00b5 \u2212 f \u00b5 d\u03bb = |(\u00b5 \u2212 \u00b5 )[u \u22121 (E Up )]| + |(\u00b5 \u2212 \u00b5 )[u \u22121 (E Lo )]| < ,", "formula_coordinates": [22.0, 80.38, 193.88, 189.09, 90.36]}, {"formula_id": "formula_90", "formula_text": "\u00b5 \u2208 Q, if E \u00b5 [\u03c4 0 (X) | A = a] = E \u00b5 [\u03c4 1 (X) | A = a]", "formula_coordinates": [22.0, 55.44, 564.19, 200.54, 29.25]}, {"formula_id": "formula_91", "formula_text": "E \u00b5 [\u03c4 0 (X \u03a0,A,a )] = E \u00b5 [\u03c4 1 (X \u03a0,A,a )]", "formula_coordinates": [22.0, 102.58, 688.69, 139.72, 9.65]}, {"formula_id": "formula_92", "formula_text": "Pr(u(X) = t a , A = a) = ta ta f \u00b5,a d\u03bb = 0, so Pr \u00b5 (\u03c4 0 (X) = \u03c4 1 (X)) = 0. Next, suppose E \u00b5 [\u03c4 0 (X) | A = a] = E \u00b5 [\u03c4 1 (X) | A = a].", "formula_coordinates": [22.0, 307.44, 153.81, 205.39, 63.14]}, {"formula_id": "formula_93", "formula_text": "t 1 a t 0 a f \u00b5,a d\u03bb = E \u00b5 [\u03c4 0 (X) | A = a] \u2212 E \u00b5 [\u03c4 1 (X) | A = a] = 0. Since \u00b5 \u2208 Q, \u00b5 = |\u00b5|, whence Pr |\u00b5| (t a 0 \u2264 u(X) \u2264 t 1 a | A = a) = 0.", "formula_coordinates": [22.0, 307.44, 303.05, 231.33, 82.57]}, {"formula_id": "formula_94", "formula_text": "(\u03b8 \u2022 \u00b5 + [1 \u2212 \u03b8] \u2022 \u00b5 )[E] = \u03b8 \u2022 \u00b5[E] + [1 \u2212 \u03b8] \u2022 \u00b5 [E] \u2265 \u03b8 \u2022 0 + [1 \u2212 \u03b8] \u2022 0 = 0, and, likewise, that (\u03b8 \u2022 \u00b5 + [1 \u2212 \u03b8] \u2022 \u00b5 )[K] = \u03b8 \u2022 \u00b5[K] + [1 \u2212 \u03b8] \u2022 \u00b5 [K] = \u03b8 \u2022 1 + [1 \u2212 \u03b8] \u2022 1 = 1.", "formula_coordinates": [22.0, 319.76, 674.78, 209.36, 38.63]}, {"formula_id": "formula_95", "formula_text": "\u00b5[E] = lim i\u2192\u221e \u00b5 i [E] \u2265 lim i\u2192\u221e 0 = 0 and \u00b5[K] = lim i\u2192\u221e \u00b5 i [K] = lim i\u2192\u221e 1 = 1.", "formula_coordinates": [23.0, 55.44, 234.46, 184.59, 53.74]}, {"formula_id": "formula_96", "formula_text": "E \u00b5 [f | F] \u2212 E \u00b5 [f | F] L 1 (\u00b5)(13)", "formula_coordinates": [23.0, 367.18, 198.74, 174.26, 9.96]}, {"formula_id": "formula_97", "formula_text": "E \u00b5 [f | F].", "formula_coordinates": [23.0, 386.15, 266.2, 44.55, 9.65]}, {"formula_id": "formula_98", "formula_text": "(V, M). Let f \u2208 L \u221e (\u00b5) \u2229 L \u221e (\u00b5 ). Let F be a sub-\u03c3-algebra of M. Let C = max( f L \u221e (\u00b5) , f L \u221e (\u00b5 ) ). Then, if g is a standard version of E \u00b5 [f | F], we have that V |E \u00b5 [f | F] \u2212 g| d\u00b5 \u2264 4C \u2022 |\u00b5 \u2212 \u00b5 |[V ].(14)", "formula_coordinates": [23.0, 306.88, 297.36, 234.56, 131.0]}, {"formula_id": "formula_99", "formula_text": "E Up = {v \u2208 V : E \u00b5 [f | F](v) > g(v)} and E Lo = {v \u2208 V : E \u00b5 [f | F](v) < g(v)} are in F. Now, note that V |E \u00b5 [f | F] \u2212 g| d\u00b5 = E Up E \u00b5 [f | F] \u2212 g d\u00b5 + E Lo g \u2212 E \u00b5 [f | F] d\u00b5.", "formula_coordinates": [23.0, 307.44, 514.55, 224.04, 175.07]}, {"formula_id": "formula_100", "formula_text": "E Up E \u00b5 [f | F] \u2212 g d\u00b5 = E Up E \u00b5 [f | F] \u2212 g d\u00b5 + E Up g \u2212 g d\u00b5 \u2264 E Up E \u00b5 [f | F] d\u00b5 \u2212 E Up g d\u00b5 + E up g d|\u00b5 \u2212 \u00b5 | \u2264 E Up f d\u00b5 \u2212 E Up f d\u00b5 + E up C d|\u00b5 \u2212 \u00b5 |,", "formula_coordinates": [24.0, 70.84, 94.65, 202.62, 179.52]}, {"formula_id": "formula_101", "formula_text": "E \u00b5 [f | F], g(v) \u2264 E \u00b5 [f | F] L \u221e (\u00b5 ) \u2264 C", "formula_coordinates": [24.0, 106.7, 294.16, 130.76, 30.35]}, {"formula_id": "formula_102", "formula_text": "E E \u03bd [h | F] d\u03bd = E h d\u03bd for any E \u2208 F.", "formula_coordinates": [24.0, 55.44, 372.05, 171.94, 34.28]}, {"formula_id": "formula_103", "formula_text": "\u2022 |\u00b5 \u2212 \u00b5 |[V ]. An identical argument shows that E Lo g \u2212 E \u00b5 [f | F] d\u00b5 \u2264 2C \u2022 |\u00b5 \u2212 \u00b5 |[V ],", "formula_coordinates": [24.0, 55.44, 427.26, 234.0, 54.67]}, {"formula_id": "formula_104", "formula_text": "{\u03c4 i (x)} i\u2208N such that both E \u00b5i [\u03c4 (X)] = min(b, Pr \u00b5i (u(X) > 0)) and E \u00b5i [\u03c4 i (X) | A, Y (1)] = E \u00b5i [\u03c4 i (X) | Y (1)].", "formula_coordinates": [24.0, 55.44, 647.07, 204.58, 70.83]}, {"formula_id": "formula_105", "formula_text": "q a,i = E \u00b5i [\u03c4 i (X) | A = a]", "formula_coordinates": [24.0, 371.12, 90.42, 106.64, 9.65]}, {"formula_id": "formula_106", "formula_text": "E \u00b5 [\u03c4 a,ni (X) | A = a] \u2192 E \u00b5 [\u03c4 (X) | A = a]", "formula_coordinates": [24.0, 336.07, 214.52, 176.75, 9.65]}, {"formula_id": "formula_107", "formula_text": "|\u00b5 \u2212 \u00b5 ni |[K] < 10 , \u03c4 (X) \u2212 \u03c4 ni (X) L 1 (\u00b5) \u2264 10 .", "formula_coordinates": [24.0, 318.98, 296.78, 210.92, 11.59]}, {"formula_id": "formula_108", "formula_text": "E \u00b5n i [\u03c4 ni (X) | A, Y (1)] = E \u00b5n i [\u03c4 ni (X) | Y (1)]. (15)", "formula_coordinates": [24.0, 318.41, 337.19, 223.03, 11.87]}, {"formula_id": "formula_109", "formula_text": "E \u00b5n i [\u03c4 ni (X) | Y (1)] over \u00b5 ni . By Eq. (15), g i (x) is also a standard version of E \u00b5n i [\u03c4 ni (X) | A, Y (1)] over \u00b5 ni .", "formula_coordinates": [24.0, 307.44, 357.39, 234.0, 35.78]}, {"formula_id": "formula_110", "formula_text": "E \u00b5 [\u03c4 (X) | A, Y (1)] \u2212 E \u00b5n i [\u03c4 ni (X) | Y (1)] L 1 (\u00b5) \u2264 E \u00b5 [\u03c4 (X) | A, Y (1)] \u2212 E \u00b5 [\u03c4 ni (X) | A, Y (1)] L 1 (\u00b5) + E \u00b5 [\u03c4 ni (X) | A, Y (1)] \u2212 g i (X) L 1 (\u00b5) + g i (X) \u2212 E \u00b5 [\u03c4 ni (X) | Y (1)] L 1 (\u00b5) L 1 (\u00b5) + E \u00b5 [\u03c4 ni (X) | Y (1) \u2212 E \u00b5 [\u03c4 (X) | Y (1)] L 1 (\u00b5)", "formula_coordinates": [24.0, 315.91, 413.46, 221.55, 86.18]}, {"formula_id": "formula_111", "formula_text": "E \u00b5 [\u03c4 (X) | A, Y (1)] = E \u00b5 [\u03c4 (X) | Y (1)].", "formula_coordinates": [24.0, 342.2, 553.46, 164.48, 9.65]}, {"formula_id": "formula_112", "formula_text": "E[f (X, U ) | X] = f (X, u) dF U (u),", "formula_coordinates": [24.0, 345.86, 615.85, 157.17, 9.65]}, {"formula_id": "formula_113", "formula_text": "Pr \u00b5 (D = 1 | X, Y (1)) = 1 0 1 u d <\u03c4 (X) d\u03bb(u d ) = \u03c4 (X).", "formula_coordinates": [24.0, 309.32, 673.29, 230.24, 26.29]}, {"formula_id": "formula_114", "formula_text": "Pr \u00b5 (D = 1 | A, Y (1)) = E \u00b5 [Pr \u00b5 (D = 1 | X, Y (1)) | A, Y (1)] = E \u00b5 [\u03c4 (X) | A, Y (1)] = E \u00b5 [\u03c4 (X) | Y (1)] = E \u00b5 [Pr \u00b5 (D = 1 | X, Y (1)) | Y (1)] = Pr \u00b5 (D = 1 | Y (1)).", "formula_coordinates": [25.0, 67.26, 95.97, 210.37, 84.37]}, {"formula_id": "formula_115", "formula_text": "union of {E \u03b3 } \u03b3\u2208\u0393 if \u00b5[E \u03b3 \\ E] = 0 for all \u03b3 \u2208 \u0393 and E = \u221e i=1 E \u03b3i for some countable subcollection {\u03b3 i } \u2286 N.", "formula_coordinates": [25.0, 55.44, 557.47, 235.73, 23.1]}, {"formula_id": "formula_116", "formula_text": "r(\u0393 ) = sup \u03b3\u2208\u0393 \u00b5 \uf8ee \uf8f0 E \u03b3 \\ \u03b3 \u2208\u0393 E \u03b3 \uf8f9 \uf8fb", "formula_coordinates": [25.0, 358.73, 88.0, 131.43, 33.68]}, {"formula_id": "formula_117", "formula_text": "E \u03b32 such that \u00b5[E \u03b32 \\ E \u03b31 ] > .", "formula_coordinates": [25.0, 307.44, 201.17, 126.97, 9.65]}, {"formula_id": "formula_118", "formula_text": "\u00b5[V ] \u2265 \u00b5 n i=1 E \u03b3i = n i=1 \u00b5 \uf8ee \uf8f0 E \u03b3i \\ i j=1 E \u03b3j \uf8f9 \uf8fb .", "formula_coordinates": [25.0, 328.24, 262.13, 192.41, 33.53]}, {"formula_id": "formula_119", "formula_text": "{\u0393 n } n\u2208N such that r(\u0393 n ) < 1 n . It follows immediately that for all n r n\u2208N \u0393 n \u2264 r(\u0393 k )", "formula_coordinates": [25.0, 307.44, 338.71, 234.0, 63.76]}, {"formula_id": "formula_120", "formula_text": "r n\u2208N \u0393 n = 0,", "formula_coordinates": [25.0, 388.23, 444.09, 72.42, 20.06]}, {"formula_id": "formula_121", "formula_text": "\u03bb[SUPP(f \u00b5,a ) \\ SUPP(f \u00b5max,a )] = 0.", "formula_coordinates": [25.0, 350.31, 574.36, 148.27, 9.65]}, {"formula_id": "formula_122", "formula_text": "\u03bb SUPP(f \u00b5,a ) \\ \u221e i=1 SUPP(f \u00b5i,a ) = 0,", "formula_coordinates": [25.0, 344.03, 643.56, 160.82, 30.32]}, {"formula_id": "formula_123", "formula_text": "\u00b5 max,a = n i=1 2 \u2212i \u2022 |\u00b5 i A=a | |\u00b5 i A=a | [K]", "formula_coordinates": [26.0, 104.13, 102.31, 132.66, 30.32]}, {"formula_id": "formula_124", "formula_text": "SUPP(f \u00b5max,a ) = \u221e i=1 SUPP(f \u00b5i,a ),", "formula_coordinates": [26.0, 102.56, 160.1, 140.01, 30.32]}, {"formula_id": "formula_125", "formula_text": "\u03bb[SUPP(f \u00b5 ,a,w ) \\ SUPP(f \u00b5max,a,w )] = 0,", "formula_coordinates": [26.0, 88.64, 357.49, 167.6, 9.65]}, {"formula_id": "formula_126", "formula_text": "(\u00b5 W =w,A=a ) \u2022 u \u22121 .", "formula_coordinates": [26.0, 54.28, 390.49, 90.58, 12.17]}, {"formula_id": "formula_127", "formula_text": "\u00b5 \u2208 K such that \u03bb W [Q \u2212 \u00b5] > 0. Proof. Set \u00b5 = n i=1 |\u03bd i | |\u03bd i |[K] ,", "formula_coordinates": [26.0, 102.46, 70.36, 355.75, 647.55]}, {"formula_id": "formula_128", "formula_text": "|\u03b2 i | \u2264 1 |\u03bdi|[K] , it follows that \u00b5 + n i=1 \u03b2 i \u2022 \u03bd i \u2208 Q. Since \u03bb n n i=1 \u2212 1 |\u03bd i |[K] , 1 |\u03bd i |[K] > 0, it follows that \u03bb W [Q \u2212 \u00b5] > 0.", "formula_coordinates": [26.0, 307.44, 115.01, 235.25, 111.34]}, {"formula_id": "formula_129", "formula_text": "\u03bd \u2208 Q such that \u03bd[E] > 0. Then the set of \u00b5 \u2208 Q such that \u00b5[E] > 0 is prevalent.", "formula_coordinates": [26.0, 307.44, 340.41, 234.0, 20.72]}, {"formula_id": "formula_130", "formula_text": "\u00b5[E] = lim n\u2192\u221e \u00b5 i [E] = lim n\u2192\u221e 0 = 0. Now, if \u00b5[E] > 0 for all \u00b5 \u2208 Q,", "formula_coordinates": [26.0, 307.44, 421.38, 156.0, 67.94]}, {"formula_id": "formula_131", "formula_text": "\u03bd[K] = \u03bd [K] \u2212 \u03bd[K] = 0, it follows by Lemma E.15 that \u03bb W [Q \u2212 \u00b5] > 0 for some \u00b5. Now, for arbitrary \u00b5 \u2208 Q, note that if (\u00b5 + \u03b2 \u2022\u03bd)[E] = 0, then \u00b5[E] \u2212 \u03b2 \u2022 \u03bd[E] = 0 i.e., \u03b2 = \u00b5[E] \u03bd[E] .", "formula_coordinates": [26.0, 307.44, 554.49, 235.74, 111.37]}, {"formula_id": "formula_132", "formula_text": "Z \u03b2 = {v \u2208 V : f (v) + \u03b2 \u2022 g(v) = 0}", "formula_coordinates": [27.0, 97.52, 226.23, 149.84, 9.65]}, {"formula_id": "formula_133", "formula_text": "{\u03b2 i } i\u2208N \u2286 R, the sum \u221e i=1 \u00b5[Z \u03b2i ] converges.", "formula_coordinates": [27.0, 55.44, 280.94, 191.97, 14.11]}, {"formula_id": "formula_134", "formula_text": "Z \u03b2 \u2229 Z \u03b2 \u2286 {v \u2208 V : (\u03b2 \u2212 \u03b2 ) \u2022 g(v) = 0}. Now, by hypothesis, \u00b5[{v \u2208 V : g(v) = 0}] = 0, and since \u03b2 \u2212 \u03b2 = 0, it follows that \u00b5[{v \u2208 V : (\u03b2 \u2212 \u03b2 ) \u2022 g(v) = 0}] = 0 as well. Consequently, it follows that if {Z \u03b2i } i\u2208N is a count- able collection of distinct elements of R, then \u221e i=1 \u00b5[Z \u03b2i ] = \u00b5 \u221e i=1 Z \u03b2i \u2264 \u00b5[V ] < \u221e. To see that this implies that \u00b5[Z \u03b2 ] > 0 for only countably many \u03b2 \u2208 R, let G \u2286 R consist of those \u03b2 such that \u00b5[Z \u03b2 ] \u2265 . Then G must be finite for all > 0, since otherwise we could form a collection {\u03b2 i } i\u2208N \u2286 G , in which case \u221e i=1 \u00b5[Z \u03b2i ] \u2265 \u221e i=1 = \u221e,", "formula_coordinates": [27.0, 55.08, 346.67, 236.01, 297.59]}, {"formula_id": "formula_135", "formula_text": "{\u03b2 \u2208 R : \u00b5[Z \u03b2 ] > 0} = \u221e i=1 G 1/i is countable.", "formula_coordinates": [27.0, 55.44, 668.38, 182.5, 48.83]}, {"formula_id": "formula_136", "formula_text": "E, i.e., \u03bd[K \\ E] = 0. Then the set of \u00b5 \u2208 Q such that \u03bd \u2022 u \u22121 \u00ce (\u00b5 E ) \u2022 u \u22121 is prevalent relative to Q.", "formula_coordinates": [27.0, 307.44, 157.46, 234.0, 22.58]}, {"formula_id": "formula_137", "formula_text": "\u03bd \u2022 u \u22121 [{|f \u00b5 E | = 0}] < q.", "formula_coordinates": [27.0, 368.29, 300.39, 112.31, 13.16]}, {"formula_id": "formula_138", "formula_text": "\u03bd \u2022 u \u22121 [{|f \u00b5 E | < r}] < q. Let = q \u2212 \u03bd \u2022 u \u22121 [{|f \u00b5 E | < r}]. Now, since \u03bd \u2022u \u22121 \u00ce \u03bb, there exists a \u03b4 such that if \u03bb[E ] < \u03b4, then \u03bd \u2022 u \u22121 [E ] < . Choose \u00b5 arbitrarily so that |\u00b5 \u2212 \u00b5 |[K] < \u03b4 \u2022 r.", "formula_coordinates": [27.0, 307.44, 354.2, 234.0, 84.94]}, {"formula_id": "formula_139", "formula_text": "\u03bb[{|f \u00b5 E \u2212 f \u00b5 E | > r}] < \u03b4, i.e., \u03bd \u2022 u \u22121 [{f \u00b5 E \u2212 f \u00b5 E | > r}] < .", "formula_coordinates": [27.0, 307.44, 454.32, 189.12, 40.38]}, {"formula_id": "formula_140", "formula_text": "|f \u00b5 E | = 0, either |f \u00b5 E | < r or |f \u00b5 E \u2212 f \u00b5 E | > r. Therefore \u03bb[{|f \u00b5 E | = 0}] \u2264 \u03bd \u2022 u \u22121 [{|f \u00b5 E \u2212 f \u00b5 E | > r}] + \u00b5 \u2022 u \u22121 [{|f \u00b5 E | < r] < + \u00b5 \u2022 u \u22121 [{|f \u00b5 E | < r] < q.", "formula_coordinates": [27.0, 307.13, 512.91, 236.05, 88.92]}, {"formula_id": "formula_141", "formula_text": "Note that \u03bd \u2022 u \u22121 \u00ce (\u00b5 E ) \u2022 u \u22121 if and only if \u03bb[SUPP(f \u03bd ) \\ SUPP(f \u00b5 E )] = 0.", "formula_coordinates": [27.0, 307.44, 630.39, 190.28, 33.59]}, {"formula_id": "formula_142", "formula_text": "\u03bb[SUPP(f \u00b5 ) \\ SUPP(f \u03bd E )] = 0 if and only if \u00b5 \u2022 u \u22121 [SUPP(f \u00b5 ) \\ SUPP(f \u03bd E )] = 0.", "formula_coordinates": [27.0, 359.74, 708.26, 129.4, 11.09]}, {"formula_id": "formula_143", "formula_text": "\u2022 u \u22121 \u00ce (\u03bd E ) \u2022 u \u22121 is n i=1 U 1/i", "formula_coordinates": [28.0, 83.01, 120.21, 148.7, 14.11]}, {"formula_id": "formula_144", "formula_text": "\u03bd (u(X) < t) = t \u2212\u221e f \u03bd d\u03bb", "formula_coordinates": [28.0, 122.75, 170.38, 110.06, 26.29]}, {"formula_id": "formula_145", "formula_text": "S 1 = SUPP(f \u03bd ) \u2229 [t, \u221e). Then, we let \u03bd[E ] = E 1 u \u22121 (S0) \u2212 1 u \u22121 (S1) d\u03bd. Take W = SPAN(\u03bd). Since\u03bd = 0 and\u03bd[K] = 0, we have by Lemma E.15 that \u03bb W [Q \u2212 \u00b5] > 0 for some \u00b5.", "formula_coordinates": [28.0, 55.13, 241.51, 241.05, 79.27]}, {"formula_id": "formula_146", "formula_text": "\u2022 u \u22121 \u00ce (\u00b5 E ) \u2022 u \u22121 is prevalent relative to Q by Prop. E.6.", "formula_coordinates": [28.0, 55.44, 399.22, 234.0, 22.49]}, {"formula_id": "formula_147", "formula_text": "0 < E \u00b5 [\u03c4 (X)] < 1, then there exists w \u2208 W such that 0 < E \u00b5 [\u03c4 (X) | W = w] < 1.", "formula_coordinates": [28.0, 55.44, 616.86, 176.15, 50.66]}, {"formula_id": "formula_148", "formula_text": "0 < E \u00b5 [\u03c4 (X)] < 1, but for all w \u2208 W, E \u00b5 [\u03c4 (X) | W = w] \u2208 {0, 1},", "formula_coordinates": [28.0, 133.18, 70.22, 350.42, 647.69]}, {"formula_id": "formula_149", "formula_text": "K \u2192 R \u00d7 R W given by \u03a6(\u00b5) = Pr \u00b5 (u(X) = 0), (Pr \u00b5 (W = w)) w\u2208W .", "formula_coordinates": [28.0, 307.44, 349.48, 232.92, 47.09]}, {"formula_id": "formula_150", "formula_text": "F Up \u0393 = {x \u2208 R \u00d7 R W : x 0 \u2265 b, b = w\u2208\u0393 x w }, F Lo \u0393 = {x \u2208 R \u00d7 R W : x 0 \u2264 b, x 0 = w\u2208\u0393 x w },", "formula_coordinates": [28.0, 329.29, 428.1, 190.31, 50.68]}, {"formula_id": "formula_151", "formula_text": "E \u0393 = Q \u2229 \u03a6 \u22121 \uf8eb \uf8ed \u0393\u2286W F Up \u0393 \u222a F Lo \u0393 \uf8f6 \uf8f8(16)", "formula_coordinates": [28.0, 348.92, 510.03, 192.52, 33.7]}, {"formula_id": "formula_152", "formula_text": "E W = E \u2205 = \u2205.", "formula_coordinates": [29.0, 140.97, 187.72, 62.95, 9.99]}, {"formula_id": "formula_153", "formula_text": "\u03a6(\u00b5 + \u03b2 \u2022 \u03bd w\u0393 ) = \u03a6(\u00b5) + \u03b2 \u2022 e w\u0393 \u2212 \u03b2 \u2022 e w * ,", "formula_coordinates": [29.0, 81.25, 295.96, 182.37, 9.68]}, {"formula_id": "formula_154", "formula_text": "\u00b5 + \u03b2 \u2022 \u03bd w\u0393 \u2208 E \u0393 only if \u03b2 = min(b, Pr \u00b5 (u(X) > 0)) \u2212 w\u2208\u0393 Pr \u00b5 (W = w).", "formula_coordinates": [29.0, 55.44, 350.4, 219.56, 64.24]}, {"formula_id": "formula_155", "formula_text": "\u0393 \u00b5 = {w \u2208 W : E \u00b5 [\u03c4 (X) | W = w] = 1}.", "formula_coordinates": [29.0, 85.74, 590.44, 173.4, 9.65]}, {"formula_id": "formula_156", "formula_text": "V , \u03bb V [C + v 0 ] > 0 for some v 0 \u2208 V . If, in addition, for all v \u2208 E, \u03bb V [{v \u2208 V : v + v \u2208 E}] = 0,(17)", "formula_coordinates": [29.0, 307.44, 106.08, 234.0, 42.69]}, {"formula_id": "formula_157", "formula_text": "(v + V ) \u2229 E is empty or not.", "formula_coordinates": [29.0, 307.44, 185.03, 234.0, 20.91]}, {"formula_id": "formula_158", "formula_text": "\u03bb V [E \u2212 v] = 0.", "formula_coordinates": [29.0, 456.07, 226.88, 67.01, 9.65]}, {"formula_id": "formula_159", "formula_text": "\u03bb V [E \u2212 v] = \u03bb V [{v \u2208 V : v + v \u2208 E}] = \u03bb V [{v \u2208 V : (v + v * ) + v \u2208 E}] = 0,", "formula_coordinates": [29.0, 322.0, 277.85, 204.88, 38.63]}, {"formula_id": "formula_160", "formula_text": "K 1 d\u03bd = 0,(18)", "formula_coordinates": [30.0, 151.7, 403.18, 137.74, 17.23]}, {"formula_id": "formula_163", "formula_text": "Pr |\u03bd Lo | (A = a) > 0, then K 1 u(X)<0,Y =yi,A=a d\u03bd Lo = 0. (21", "formula_coordinates": [30.0, 55.44, 556.13, 229.85, 42.14]}, {"formula_id": "formula_164", "formula_text": ")", "formula_coordinates": [30.0, 285.29, 581.36, 4.15, 8.64]}, {"formula_id": "formula_165", "formula_text": "0 < Pr \u00b5 (u(X) > t | A = a) < 1, if \u03bd Up \u2208 W Up is such that Pr |\u03bd Up | (A = a) > 0, then K 1 u(X)>t,A=a d\u03bd Up = 0. (22", "formula_coordinates": [30.0, 55.44, 660.64, 229.85, 60.76]}, {"formula_id": "formula_166", "formula_text": ")", "formula_coordinates": [30.0, 285.29, 704.48, 4.15, 8.64]}, {"formula_id": "formula_167", "formula_text": "\u00b5 max,a \u2022 u \u22121 [S a \u2229 [0, r a )] \u2212 \u00b5 max,a \u2022 u \u22121 [S a \u2229 [r a , \u221e)]", "formula_coordinates": [30.0, 309.26, 98.35, 230.35, 11.72]}, {"formula_id": "formula_168", "formula_text": "S Lo a = S a \u2229 (\u2212\u221e, 0), S Up a,0 = S a \u2229 [0, r a ), S Up a,1 = S a \u2229 [r a , \u221e), so that", "formula_coordinates": [30.0, 307.44, 146.79, 162.19, 63.95]}, {"formula_id": "formula_169", "formula_text": "\u03bd Up a [E] = \u00b5 max,a \u2022 (\u03b3 y1 \u2022 \u03c0 X ) \u22121 E \u2229 u \u22121 S Up a,1 , \u2212 \u00b5 max,a \u2022 (\u03b3 y1 \u2022 \u03c0 X ) \u22121 E \u2229 u \u22121 S Up a,0 , \u03bd Lo a [E] = \u00b5 max,a \u2022 (\u03b3 y1 \u2022 \u03c0 X ) \u22121 E \u2229 u \u22121 S Lo a \u2212 \u00b5 max,a \u2022 (\u03b3 y0 \u2022 \u03c0 X ) \u22121 E \u2229 u \u22121 S Lo a . By construction, \u03bd Up a concentrates on {y 1 } \u00d7 u \u22121 (S a \u2229 [0, \u221e)),", "formula_coordinates": [30.0, 307.44, 285.98, 231.86, 107.6]}, {"formula_id": "formula_170", "formula_text": "W Up = SPAN(\u03bd Up a ) a\u2208A , W Lo = SPAN(\u03bd Lo a )", "formula_coordinates": [30.0, 373.33, 454.84, 102.23, 29.14]}, {"formula_id": "formula_171", "formula_text": "0 < Pr \u00b5 (u(X) > t | A = a, u(X) > 0) < 1,", "formula_coordinates": [30.0, 333.47, 533.76, 181.94, 9.65]}, {"formula_id": "formula_172", "formula_text": "\u03bd Up a that \u03bd Up a \u2022 u \u22121 [(t, \u221e)] = \u221e ra f max,a d\u03bb \u2212 ra t f max,a d\u03bb > \u221e ra f max,a d\u03bb \u2212 ra 0 f max,a d\u03bb = 0. Similarly, if t > r a , \u03bd Up a \u2022 u \u22121 [(t, \u221e)] = \u221e t f max,a d\u03bb > \u221e sup Sa f max,a d\u03bb = 0.", "formula_coordinates": [30.0, 307.44, 574.34, 203.94, 139.07]}, {"formula_id": "formula_173", "formula_text": "\u2022 For i = 0, 1, Pr \u00b5 (u(X) > 0, A = a, Y (1) = y i ) > 0;(23)", "formula_coordinates": [31.0, 66.89, 392.3, 222.55, 32.07]}, {"formula_id": "formula_174", "formula_text": "\u03bd Up a \u2022 u \u22121 \u00ce (\u00b5 \u03b1 \u22121 (a)\u00d7{y1} ) \u2022 u \u22121 . (24", "formula_coordinates": [31.0, 98.41, 461.98, 186.89, 12.69]}, {"formula_id": "formula_175", "formula_text": ")", "formula_coordinates": [31.0, 285.29, 464.37, 4.15, 8.64]}, {"formula_id": "formula_176", "formula_text": "\u03bb W [E \u2212 \u00b5] = 0 for \u00b5 \u2208 E.", "formula_coordinates": [31.0, 55.44, 556.68, 109.96, 9.68]}, {"formula_id": "formula_177", "formula_text": "0 < E \u00b5 [\u03c4 (X) | A = a] < 1. (25", "formula_coordinates": [31.0, 366.62, 186.47, 170.68, 9.65]}, {"formula_id": "formula_178", "formula_text": ")", "formula_coordinates": [31.0, 537.29, 186.79, 4.15, 8.64]}, {"formula_id": "formula_179", "formula_text": "1 \u2208 A such that E \u00b5 [\u03c4 (X) | A = a 0 ] = 0 and E \u00b5 [\u03c4 (X) | A = a 1 ] > 0.", "formula_coordinates": [31.0, 307.44, 219.03, 167.93, 62.82]}, {"formula_id": "formula_180", "formula_text": "1 X \u00d7Y \u2022 E \u00b5 [\u03c4 (X) | A = a 1 , Y (1)] > 0 = 1 X \u00d7Y \u2022 E \u00b5 [\u03c4 (X) | A = a 0 , Y (1)],", "formula_coordinates": [31.0, 322.92, 321.91, 203.05, 39.54]}, {"formula_id": "formula_181", "formula_text": "E \u00b5+\u03bd [\u03c4 (X)] < Pr \u00b5+\u03bd (u(X) > 0) \u2264 b.", "formula_coordinates": [31.0, 343.78, 663.74, 161.31, 9.65]}, {"formula_id": "formula_182", "formula_text": "0 | A = a, Y (1) = y 1 ) = Pr \u00b5+\u03bd (u(X) > 0 | A = a , Y (1) = y 1 )", "formula_coordinates": [32.0, 108.95, 119.19, 170.53, 24.6]}, {"formula_id": "formula_183", "formula_text": "p a = Pr \u00b5+\u03bd (u(X) > 0 | A = a , Y (1) = y 1 ).", "formula_coordinates": [32.0, 78.15, 220.11, 188.59, 9.65]}, {"formula_id": "formula_184", "formula_text": "Pr \u00b5+\u03bd (u(X) > 0 | Y (1) = y 1 ) > 0.", "formula_coordinates": [32.0, 97.19, 276.21, 150.49, 9.65]}, {"formula_id": "formula_185", "formula_text": "0 | A = a * , Y (1) = y 1 ) = \u03b7 \u03c0 + \u03b2 Lo a * \u2022 \u03c1 where \u03b7 = Pr \u00b5 (u(X) > 0, A = a * , Y (1) = y 1 ) \u03c0 = Pr \u00b5 (A = a * , Y (1) = y 1 ), \u03c1 = K 1 A=a * ,Y (1)=y1 d\u03bd Lo a * . since 0 = K 1 u(X)>0,A=a * ,Y (1)=y1 d\u03bd Lo a * , 0 = K 1 A=a * ,Y (1)=y1 d\u03bd Lo a * .", "formula_coordinates": [32.0, 55.08, 395.84, 227.96, 187.9]}, {"formula_id": "formula_186", "formula_text": "\u03b2 Lo a * = e \u2212 p a \u2022 \u03c0 p a \u2022 \u03c1", "formula_coordinates": [32.0, 134.15, 655.99, 72.25, 23.23]}, {"formula_id": "formula_187", "formula_text": "\u03bb SPAN(\u03bd Lo a * ) [E \u2212 \u00b5 \u2212 \u03bd ] = 0.", "formula_coordinates": [32.0, 367.56, 213.66, 113.76, 12.86]}, {"formula_id": "formula_188", "formula_text": "E \u00b5+\u03bd Lo [d(X) | A = a, Y (1) = y 0 ] = E \u00b5+\u03bd Lo +\u03bd Up [d(X) | A = a, Y (1) = y 0 ]", "formula_coordinates": [32.0, 317.4, 465.17, 214.07, 25.05]}, {"formula_id": "formula_189", "formula_text": "p = E \u00b5+\u03bd Lo [\u03c4 (X) | A = a, Y (1) = y 0 ].", "formula_coordinates": [32.0, 343.93, 603.66, 161.01, 10.1]}, {"formula_id": "formula_190", "formula_text": "E \u00b5+\u03bd Lo [\u03c4 (X) | A = a 0 , Y (1) = y 0 ] < p.", "formula_coordinates": [32.0, 340.3, 708.26, 168.28, 10.1]}, {"formula_id": "formula_191", "formula_text": "E \u00b5+\u03bd Lo [\u03c4 (X) | A = a 0 ] < E \u00b5+\u03bd Lo [\u03c4 (X) | A = a 0 ].", "formula_coordinates": [33.0, 66.39, 103.87, 212.1, 10.1]}, {"formula_id": "formula_192", "formula_text": "E \u00b5+\u03bd Lo [\u03c4 (X) | A = a 1 ] > E \u00b5+\u03bd Lo [\u03c4 (X) | A = a 1 ].", "formula_coordinates": [33.0, 66.39, 159.21, 212.1, 10.1]}, {"formula_id": "formula_193", "formula_text": "E \u00b5+\u03bd Lo [\u03c4 (X) | A = a 1 , Y (1) = y 0 ] \u2265 E \u00b5+\u03bd Lo [\u03c4 (X) | A = a 0 , Y (1) = y 0 ] = p > E \u00b5+\u03bd Lo [\u03c4 (X) | A = a 0 , Y (1) = y 0 ],", "formula_coordinates": [33.0, 75.79, 214.55, 193.3, 54.94]}, {"formula_id": "formula_194", "formula_text": "0 < Pr \u00b5+\u03bd Lo (u(X) >t a * | A = a * ) < 1.", "formula_coordinates": [33.0, 87.98, 551.64, 168.93, 12.18]}, {"formula_id": "formula_195", "formula_text": ") that K 1 u(X)>t a * d\u03bd Up a * = 0. Fix \u03bd = \u03bd \u2212 \u03b2 Up a * \u2022 \u03bd Up a * .", "formula_coordinates": [33.0, 55.44, 575.72, 167.07, 66.13]}, {"formula_id": "formula_196", "formula_text": "p * = E \u00b5+\u03bd [\u03c4 (X) | A = a, Y (1) = y 1 ].", "formula_coordinates": [33.0, 92.31, 650.84, 160.26, 11.72]}, {"formula_id": "formula_197", "formula_text": "* | A = a * , Y (1) = y 1 ) = \u03b7 + \u03b2 Up a \u2022 \u03b3 \u03c0(26)", "formula_coordinates": [33.0, 406.83, 89.54, 134.61, 40.33]}, {"formula_id": "formula_198", "formula_text": "\u03b7 = Pr \u00b5+\u03bd Lo (u(X) >t a * | A = a * , Y (1) = y 1 ), \u03c0 = Pr \u00b5+\u03bd Lo (A = a * , Y (1) = y 1 ), \u03b3 = K 1 u(X)>t a * ,A=a * ,Y (1)=y1 d\u03bd Up a ,", "formula_coordinates": [33.0, 324.69, 158.27, 199.51, 55.38]}, {"formula_id": "formula_199", "formula_text": "0 = K 1 A=a * ,Y (1)=y1 d\u03bd Lo a .", "formula_coordinates": [33.0, 366.14, 245.33, 116.59, 19.31]}, {"formula_id": "formula_200", "formula_text": "(p * \u2022 \u03c0 \u2212 \u03b7) \u2212 \u03b2 \u2022 \u03b3 = 0.", "formula_coordinates": [33.0, 374.28, 293.61, 100.33, 10.81]}, {"formula_id": "formula_201", "formula_text": "\u03b2 = p * \u2022 \u03c0 \u2212 \u03b7 \u03b3 ,", "formula_coordinates": [33.0, 391.99, 335.57, 64.91, 23.89]}, {"formula_id": "formula_202", "formula_text": "\u03bb SPAN(\u03bd Up a * ) [E \u2212 \u00b5 \u2212 \u03bd ] = 0.", "formula_coordinates": [33.0, 367.03, 403.98, 114.82, 13.83]}, {"formula_id": "formula_203", "formula_text": "\u03bd Up a,w [E] = \u00b5 max,a,w \u2022 (\u03b3 (y1,y1) \u2022 \u03c0 X ) \u22121 [E \u2229 u \u22121 (S Up a,1 )], \u2212 \u00b5 max,a \u2022 (\u03b3 (y1,y1) \u2022 \u03c0 X ) \u22121 [E \u2229 u \u22121 (S Up a,w )], \u03bd Lo a,w [E] = \u00b5 max,a,w \u2022 (\u03b3 (y1,y1) \u2022 \u03c0 X ) \u22121 [E \u2229 u \u22121 (S Lo a )] \u2212 \u00b5 max,a \u2022 (\u03b3 (y0,y0) \u2022 \u03c0 X ) \u22121 [E \u2229 u \u22121 (S Lo a,w )],", "formula_coordinates": [33.0, 307.49, 561.52, 233.9, 63.61]}, {"formula_id": "formula_204", "formula_text": "W Up = SPAN(\u03bd Up a,w ), W Lo = SPAN(\u03bd Lo a,w ),", "formula_coordinates": [33.0, 380.76, 667.8, 87.36, 29.38]}, {"formula_id": "formula_205", "formula_text": "S Lo a,w = S a,w \u2229 (\u2212\u221e, r a,w ), S Up a,w = S a,w \u2229 [r a,w , \u221e),", "formula_coordinates": [34.0, 115.88, 228.26, 113.13, 29.38]}, {"formula_id": "formula_206", "formula_text": "(a, (x a ) a \u2208A ) \u2192 x a .", "formula_coordinates": [34.0, 129.21, 338.78, 86.46, 9.65]}, {"formula_id": "formula_207", "formula_text": "\u00b5 max,a,w [E] = \u00b5 max,a,w [E \u2229 (u \u2022 \u03c0 a ) \u22121 (s Up a,w )] \u2212 \u00b5 max,a,w [E \u2229 (u \u2022 \u03c0 a ) \u22121 (S Lo a,w )].", "formula_coordinates": [34.0, 60.06, 429.79, 224.75, 29.38]}, {"formula_id": "formula_208", "formula_text": "\u03bd a = \u03b4 a \u00d7\u03bc max,\u03c6(a ),w1 \u00d7 a =\u03c6(a ) \u00b5 max,a,w1 \u2022 \u03c0 \u22121 a ,", "formula_coordinates": [34.0, 65.15, 515.64, 214.58, 22.6]}, {"formula_id": "formula_209", "formula_text": "W = SPAN(\u03bd a ) a \u2208A .", "formula_coordinates": [34.0, 128.67, 586.54, 87.55, 10.65]}, {"formula_id": "formula_210", "formula_text": "Pr \u00b5 (X \u2208 E) = Pr \u00b5+\u03bd (X \u2208 E)", "formula_coordinates": [34.0, 107.6, 649.76, 129.69, 9.65]}, {"formula_id": "formula_211", "formula_text": "0 < Pr \u00b5 (u(X) > t | A = a) < 1, if \u03bd \u2208 W is such that Pr |\u03bd| (A = \u03c6 \u22121 (a)) > 0, then K 1 u(X \u03a0,A,a )>t d\u03bd a = 0. (27", "formula_coordinates": [34.0, 307.44, 104.74, 229.85, 68.5]}, {"formula_id": "formula_212", "formula_text": ")", "formula_coordinates": [34.0, 537.29, 156.32, 4.15, 8.64]}, {"formula_id": "formula_214", "formula_text": "X \u00d7 Y X \u00d7 Y \u00d7 Y X \u00d7 Y \u03b9 \u03c0 d id", "formula_coordinates": [35.0, 110.9, 90.88, 122.27, 71.87]}, {"formula_id": "formula_215", "formula_text": "Pr \u00b5 (X = (a, y, u), Y (1) = y ) = 1 4 \u2022 1 y=y \u2022 Pr \u00b5 (u(X) = u),", "formula_coordinates": [35.0, 67.06, 636.9, 212.41, 36.3]}, {"formula_id": "formula_216", "formula_text": ") < b) = b\u2212a 2 for 0 \u2264 a \u2264 b < 1.", "formula_coordinates": [35.0, 105.41, 706.37, 135.22, 13.47]}, {"formula_id": "formula_217", "formula_text": "\u03c4 (a, y, u) = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 1 u > 1, 1 2 u = 1, 0 u < 1.", "formula_coordinates": [35.0, 372.09, 114.18, 103.5, 40.47]}, {"formula_id": "formula_218", "formula_text": "D = 1 U D \u2264\u03c4 (X) for some U D \u223c UNIF(0, 1) independent of X and Y (1), then D \u22a5 \u22a5 A | Y (1). Since u(X) \u22a5 \u22a5 A, Y (1), it follows that Pr \u00b5 (D = 1 | A = a, Y (1) = y) = Pr(U D \u2264 \u03c4 (X) | A = a, Y (1) = y) = Pr(U D \u2264 \u03c4 (X)) = E \u00b5 [\u03c4 (X)],", "formula_coordinates": [35.0, 307.44, 200.08, 235.25, 97.98]}, {"formula_id": "formula_219", "formula_text": "Pr \u00b5 (U > 1) < Pr \u00b5 (U > 1) + 1 64 = 33 64 , Pr \u00b5 (U \u2265 1) > Pr \u00b5 (U \u2265 1) \u2212 1 64 = 63 64 ,", "formula_coordinates": [35.0, 340.06, 396.93, 168.77, 46.29]}, {"formula_id": "formula_220", "formula_text": "\u03c4 (a, y, u) = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 1 u > 1, p a,y u = 1, 0 u < 1.", "formula_coordinates": [35.0, 365.63, 522.18, 116.42, 40.47]}, {"formula_id": "formula_221", "formula_text": "q a,y = Pr \u00b5 (A = a, Y = y, U > 1), r a,y = Pr \u00b5 (A = a, Y = y, U = 1), \u03c0 a,y = Pr \u00b5 (A = a, Y = y).", "formula_coordinates": [35.0, 350.83, 599.17, 147.23, 39.54]}, {"formula_id": "formula_222", "formula_text": "E \u00b5 [\u03c4 (X)] = a,y q a,y + p a,y \u2022 r a,y , E \u00b5 [\u03c4 (X) | A = a, Y = y] = q a,y + p a,y \u2022 r a,y \u03c0 a,y.", "formula_coordinates": [35.0, 319.51, 668.23, 209.85, 46.83]}, {"formula_id": "formula_223", "formula_text": "\u03c0 a1,0 \u2022 (q a0,0 + p a0,0 \u2022 r a0,0 ) = \u03c0 a0,0 \u2022 (q a1,0 + p a1,0 \u2022 r a1,0 ), \u03c0 a1,1 \u2022 (q a0,1 + p a0,1 \u2022 r a0,1 ) = \u03c0 a0,1 \u2022 (q a1,1 + p a1,1 \u2022 r a1,1 ),(29)", "formula_coordinates": [36.0, 73.41, 162.63, 216.03, 54.48]}, {"formula_id": "formula_224", "formula_text": "Pr(D = 1 | A = a, Y (1) = y) = E[\u03c4 (X) | A = a, Y (1) = y].", "formula_coordinates": [36.0, 67.06, 264.23, 212.41, 23.68]}, {"formula_id": "formula_225", "formula_text": "S = 3 4 \u2212 Pr \u00b5 (U > 1) Pr \u00b5 (U = 1) .", "formula_coordinates": [36.0, 124.3, 337.27, 96.28, 25.69]}, {"formula_id": "formula_227", "formula_text": "E[d(X \u03a0,A,a | X] = d(X)", "formula_coordinates": [37.0, 119.62, 490.5, 105.65, 9.65]}, {"formula_id": "formula_228", "formula_text": "E[D \u03a0,A,a | X] = E[E[1 U D \u2264d(X \u03a0,A,a ) | X \u03a0,A,a , X] | X] = E[E[d(X \u03a0,A,a ) | X \u03a0,A,a , X] | X] = E[d(X \u03a0,A,a ) | X] = d(X) = E[d(X) | X] = E[D | X].", "formula_coordinates": [37.0, 56.55, 547.11, 231.79, 85.47]}, {"formula_id": "formula_229", "formula_text": "Pr(d(X) = d max | A = a) = 0. (31", "formula_coordinates": [37.0, 359.73, 439.54, 177.56, 9.65]}, {"formula_id": "formula_230", "formula_text": ")", "formula_coordinates": [37.0, 537.29, 439.86, 4.15, 8.64]}, {"formula_id": "formula_231", "formula_text": "Pr(d max \u2212 d(X \u03a0,A,a1 ) \u2265 \u03c1 | X) \u2264 E[d max \u2212 d(X \u03a0,A,a1 ) | X] \u03c1 = d max \u2212 d(X) \u03c1 ,", "formula_coordinates": [37.0, 341.25, 650.73, 165.19, 64.32]}, {"formula_id": "formula_232", "formula_text": "Pr(d max \u2212 d(X \u03a0,A,a1 ) < \u03c1 | X) \u2265 1 \u2212 d max \u2212 d(X) \u03c1 .(33)", "formula_coordinates": [38.0, 92.9, 104.07, 196.54, 37.35]}, {"formula_id": "formula_233", "formula_text": "Pr(d max \u2212 d(X \u03a0,A,a1 ) < \u03c1, A = a 1 | X) < 1 2", "formula_coordinates": [38.0, 78.53, 337.75, 186.63, 13.47]}, {"formula_id": "formula_234", "formula_text": "1 \u2212 d max \u2212 d(X) > 1 \u2212 2 = 1 2 > Pr(d max \u2212 d(X \u03a0,A,a1 ) < , A = a 1 | X).", "formula_coordinates": [38.0, 64.21, 534.84, 216.46, 84.62]}, {"formula_id": "formula_235", "formula_text": "d i = m k=1 \uf8ee \uf8f0 lim n\u2192\u221e j\u2208S k P n ij \uf8f9 \uf8fb \u2022 p k .(34)", "formula_coordinates": [39.0, 108.96, 125.97, 180.48, 34.35]}, {"formula_id": "formula_236", "formula_text": "P = B R Q ,", "formula_coordinates": [39.0, 140.3, 258.03, 64.28, 20.69]}, {"formula_id": "formula_237", "formula_text": "B = \uf8ee \uf8ef \uf8ef \uf8ef \uf8f0 P 1 P 2 . . . P m \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fb", "formula_coordinates": [39.0, 116.94, 308.04, 111.0, 53.36]}, {"formula_id": "formula_238", "formula_text": "P ABS = I R Q", "formula_coordinates": [39.0, 137.21, 654.07, 65.2, 20.69]}, {"formula_id": "formula_239", "formula_text": "1 Si \u2192 e i .", "formula_coordinates": [39.0, 207.49, 708.23, 40.83, 9.68]}, {"formula_id": "formula_240", "formula_text": "1 |A| a \u2208A P a d = 1 |A| a \u2208A d = d,(35)", "formula_coordinates": [39.0, 358.25, 413.87, 183.19, 26.8]}, {"formula_id": "formula_241", "formula_text": "1 | Z 1 < t] < E[Z 0 | Z 0 < t].", "formula_coordinates": [39.0, 364.89, 708.26, 118.81, 9.65]}], "doi": ""}