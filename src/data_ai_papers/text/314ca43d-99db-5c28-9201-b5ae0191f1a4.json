{"title": "Random Sampling from a Search Engine's Index *", "authors": "Ziv Bar-Yossef; Maxim Gurevich", "pub_date": "2008-03-04", "abstract": "We revisit a problem introduced by Bharat and Broder almost a decade ago: how to sample random pages from the corpus of documents indexed by a search engine, using only the search engine's public interface? Such a primitive is particularly useful in creating objective benchmarks for search engines. The technique of Bharat and Broder suffers from a well-recorded bias: it favors long documents. In this paper we introduce two novel sampling algorithms: a lexicon-based algorithm and a random walk algorithm. Our algorithms produce biased samples, but each sample is accompanied by a weight, which represents its bias. The samples, in conjunction with the weights, are then used to simulate near-uniform samples. To this end, we resort to four well-known Monte Carlo simulation methods: rejection sampling, importance sampling, the Metropolis-Hastings algorithm, and the Maximum Degree method. The limited access to search engines force our algorithms to use bias weights that are only \"approximate\". We characterize analytically the effect of approximate bias weights on Monte Carlo methods and conclude that our algorithms are guaranteed to produce near-uniform samples from the search engine's corpus. Our study of approximate Monte Carlo methods could be of independent interest. Experiments on a corpus of 2.4 million documents substantiate our analytical findings and show that our algorithms do not have significant bias towards long documents. We use our algorithms to collect comparative statistics about the corpora of the Google, MSN Search, and Yahoo! search engines.", "sections": [{"heading": "Introduction", "text": "Search engine size wars are almost as old as search engines themselves. Self reports of search engine sizes are frequently contradictory, leading to heated public debates. See [38,34,6,42] for\nThe Bharat-Broder approach Bharat and Broder proposed the following simple algorithm for uniformly sampling documents from a search engine's corpus. The algorithm successively formulates \"random\" queries, submits the queries to the search engine, and picks uniformly chosen documents from the result sets returned. In order to construct the random queries, the algorithm requires the availability of a lexicon of terms that appear in web documents. Each term in the lexicon should be accompanied by an estimate of its frequency on the web. Random queries are then formulated by randomly selecting a few terms from the lexicon, based on their estimated frequencies, and then taking their conjunction or disjunction. The lexicon is constructed in a pre-processing step by crawling a large corpus of documents (Bharat and Broder crawled the Yahoo! directory).\nAs Bharat and Broder noted in the original article [7] and was later confirmed by subsequent studies [13,43], the method suffers from severe biases. The most significant bias is towards long, \"content-rich\", documents, simply because these documents match many more queries than short documents. An extreme example is online dictionaries and word lists (such as the ispell dictionaries), which will be returned as the result of almost any conjunctive query composed of unrelated terms [13,43].\nAnother problem is that search engines do not allow access to the full list of results, but rather only to the top k ones (where k is usually 1,000). Therefore, the Bharat-Broder algorithm may be biased towards documents with high static rank, if the random queries it generates tend to return more than k results, which is usually the case for disjunctive queries. To alleviate this problem, Bharat and Broder used the estimated term frequencies to choose queries that are unlikely to return more than k results. As the number of pages indexed by search engines grew by orders of magnitude over the past decade, while k has not, this technique for query selection has become ineffective. It is almost impossible to find terms so that disjunctive queries composed of them will return less than k results. By focusing only on such queries, the algorithm is limited to sampling only from a small subset of the web. It is easier to construct conjunctive queries with less than k results simply by adding more random terms. This, however, also increases the fraction of dictionaries and word lists among the results.\nOur contributions We propose two novel algorithms for sampling pages from a search engine's corpus. Both algorithms use a lexicon to formulate random queries, but unlike the Bharat-Broder approach, do not need to know term frequencies. The first algorithm, like the Bharat-Broder algorithm, requires a pre-processing step to build the lexicon. The second algorithm is based on a random walk on a virtual graph defined over the documents in the corpus. This algorithm does not need to build the lexicon a priori, but rather creates it \"on the fly\", as the random walk proceeds from document to document.\nBoth algorithms share the same basic framework. The algorithm first produces biased samples. That is, some documents are more likely to be sampled than others. Yet, each sample document x is accompanied by a corresponding \"weight\" w(x), which represents the bias in the sample x. The weights allow us to apply stochastic simulation methods on the samples and consequently obtain uniform, unbiased, samples from the search engine's corpus. 1 A simulation method accepts samples taken from a trial distribution p and simulates sampling from a target distribution \u03c0. In order to carry out the simulation, the simulator needs to be able to compute a \"bias weight\" w(x) = \u03c0(x)/p(x), for any given instance x. The simulator uses these weights to \"promote\" certain samples from p, while \"demoting\" other samples, thereby eliminating the initial bias in the trial distribution. The simulation has some overhead, which depends on how far p and \u03c0 are from each other. In our case \u03c0 is the uniform distribution over the search engine's corpus, while p is some other easy-to-sample-from distribution over the corpus. 2 We employ four Monte Carlo simulation methods: rejection sampling, importance sampling, the Metropolis-Hastings algorithm, and the Maximum Degree method.\nOne technical difficulty in applying simulation methods in our setting is that the weights produced by our samplers are only approximate. To the best of our knowledge, stochastic simulation with approximate weights has not been addressed before. We are able to show that all four Monte Carlo methods still work even when provided with approximate weights. The distribution of the samples they generate is no longer identical to the target distribution \u03c0, but is rather only close to \u03c0. We provide extensive theoretical analysis of the effect of the approximate bias weights on the quality and the performance of the Monte Carlo methods. This study may be of independent interest.\nPool-based sampler A query pool, or a lexicon, is a collection of queries. Our pool-based sampler assumes knowledge of some query pool P. The terms constituting queries in the pool can be collected by crawling a large corpus, like the Yahoo! [45] or ODP [16] directories. We stress again that knowledge of the frequencies of these terms is not needed.\nThe degree of a document x in the corpus is the number of queries from the pool that it matches. The \"document degree distribution\" is a distribution over the corpus, where each document is selected proportionally to its degree. The inner subroutine of the pool-based sampler generates samples from the document degree distribution. The corresponding bias weights are inverse-proportional to the document degrees, and are thus easy to calculate. The outer subroutine of the pool-based sampler then applies a Monte Carlo method (e.g., rejection sampling) on the samples from the document degree distribution in order to simulate uniform samples.\nHow does the algorithm generate samples from the document degree distribution? The first solution that comes to mind is as follows. The algorithm picks a random query from the pool, submits the query to the search engine, and then selects a random document from the result set returned. Indeed, documents with high degree match more queries, and are thus more likely to be sampled than documents with low degree. However, the resulting sampling distribution is not exactly the document degree distribution, as the chance of a document to be selected depends also on the number of results returned on queries that this document matches. For example, if documents x and x \u2032 have both degree 1, but x matches a query q with 100 results, while x \u2032 matches a query q \u2032 with 50 results, then the probability of x \u2032 to be sampled is twice as high as the probability of x to be sampled.\nTo alleviate this problem, the algorithm does not select the query uniformly at random, but rather proportionally to its cardinality. The cardinality of a query q is the number of results it has. It can be shown that if the algorithm samples queries from the pool proportionally to their cardinalities, then by selecting random documents from their result sets, the algorithm could have obtained samples from the document degree distribution. Sampling queries according to their cardinality is tricky, though, because we do not know a priori the cardinality of queries. What we do instead is sample queries from the pool uniformly, and then simulate sampling from the cardinality distribution. To this end, we use Monte Carlo methods again. Hence, Monte Carlo methods are used twice: first to generate the random queries and then to generate the uniform documents.\nTo demonstrate how the pool-based sampler works, consider a corpus consisting of only 100 documents and a query pool with two queries q 1 and q 2 , whose cardinalities are 99 and 2, respectively. Suppose the result sets of q 1 , q 2 share a single document x. The sampler chooses one of q 1 , q 2 uniformly at random and then applies an acceptance-rejection procedure, in which q 1 is accepted with probability 99/100 and q 2 is accepted with probability 2/100. If the query is accepted, it is submitted to the search engine, and a random document is chosen from its result set. A second acceptance-rejection procedure is applied on this document. If it is the document x, it is accepted with probability 1/2, and otherwise it is accepted with probability 1. If the document is accepted, it is output as a sample. It can be verified that all 100 documents in the corpus are equally likely to be sampled.\nWe rigorously analyze the pool-based sampler and identify the important properties of the query pool that make this technique accurate and efficient. We find that using a pool of exact phrase queries of a certain length is much more preferable to using conjunctive or disjunctive queries, like the ones used by Bharat and Broder. Random walk sampler We present another sampler, which also uses a query pool, but does not need to construct it a priori. This sampler performs a random walk on a virtual graph defined over the documents in the corpus. The limit distribution of this random walk is the uniform distribution over the documents, and thus if we run the random walk for sufficiently many steps, we are guaranteed to obtain near-uniform samples from the corpus.\nThe graph is defined as follows: two documents are connected by an edge if and only if they match the same query from the pool. This means that if one submits the shared query to the search engine, both documents are guaranteed to belong to the result set. Running a random walk on this graph is simple: we start from an arbitrary document, at each step choose a random query that the current document matches, submit this query to the search engine, and move to a randomly chosen document from the query's result set.\nThe random walk as defined does not converge to the uniform distribution. In order to make it uniform, we apply either the Metropolis-Hastings algorithm or the Maximum Degree method. We provide careful analysis of the random walk sampler. Like the pool-based sampler, this sampler too is guaranteed to produce near-uniform samples. However, theoretical analysis of its performance suggests that it is less efficient than the pool-based sampler.", "publication_ref": ["b35", "b32", "b5", "b39", "b6", "b12", "b40", "b12", "b40", "b0", "b1", "b42"], "figure_ref": [], "table_ref": []}, {"heading": "Experimental results", "text": "To validate our techniques, we crawled 2.4 million English pages from the ODP hierarchy [16], and built a search engine over these pages. We used these pages to create the query pool needed for our pool-based sampler and for the Bharat-Broder sampler.\nWe ran our two samplers as well as the Bharat-Broder sampler on this search engine, and calculated bias towards long documents and towards highly ranked documents. As expected, the Bharat-Broder sampler was found to have significant bias. On the other hand, our pool-based sampler had no bias at all, while the random walk sampler only had a small negative bias towards short documents.\nWe then ran our pool-based sampler on Google [20], MSN Search [37], and Yahoo! [45]. As a query pool, we used 5-term phrases extracted from English pages at the ODP hierarchy. The samples collected enabled us to produce estimates, as of May 2006, of the relative sizes of these search engines as well as interesting statistics about their freshness, their domain name distribution, and their coverage of dynamic URLs.\nThe rest of the paper is organized as follows. In Section 2 we review some related work. Section 3 overviews some tools from probability theory and statistics used in our analysis. In Section 4 we briefly review the four Monte Carlo simulation methods we use. In Section 5 we analyze the effect of approximate bias weights on Monte Carlo simulation. In Section 6 we describe a formal framework for studying search engine samplers. In Sections 7 and 8 we outline in detail our two samplers. Section 9 includes our experimental results, and Section 10 some concluding remarks.\nIn order to avoid disturbing the flow of the paper, most proofs are postponed to the appendix.", "publication_ref": ["b18", "b42"], "figure_ref": [], "table_ref": []}, {"heading": "Related work", "text": "Apart from Bharat and Broder, several other studies used queries to search engines to collect random samples from their corpora. Queries were either manually crafted [10], collected from user query logs [29], or selected randomly using the technique of Bharat and Broder [22,13]. Assuming search engine corpora are independent and uniformly chosen subsets of the web, estimates of the sizes of search engines and of the indexable web have been derived. Due to the bias in the samples, though, these estimates lack any statistical guarantees. Dobra and Fienberg [17] showed how to avoid the unrealistic independence and uniformity assumptions, but did not address the sampling bias. We believe that their methods could be combined with ours to obtain accurate size estimates.\nSeveral studies [30,25,26,3,39] developed methods for sampling pages from the indexable web. Such methods can be used to also sample pages from a search engine's corpus. Yet, since these methods try to solve a harder problem, they also suffer from various biases, which our method does not have. It is interesting to note that the random walk approaches of Henzinger et al. [26] and Bar-Yossef et al. [3] implicitly use importance sampling and the Maximum Degree method, respectively, to make their samples near-uniform. Yet, the bias they suffer towards pages with high in-degree is significant. Anagnostopoulos,Broder,and Carmel [2] proposed an enhancement to index architecture that could support random sampling from the result sets of broad queries. This is very different from what we do in this paper: our techniques do not propose any changes to current search engine architecture and do not rely on internal data of the search engine; moreover, our goal is to sample from the whole corpus and not from the result set of a particular query.\nA recent study by Broder et al. [11] presents an algorithm for accurately estimating the absolute size of a search engine's corpus, using the engine's public interface. The cleverly crafted estimator uses our techniques to generate uniform samples from the search engine's corpus.\nThe samplers proposed in this paper, as well as in the paper of Broder et al. [11], suffer from a bias caused by inaccurate approximation of document degrees. In this paper we analyzed and quantified the resulting bias. In our subsequent work [5] we showed a method for overcoming this bias.", "publication_ref": ["b9", "b27", "b20", "b12", "b15", "b28", "b23", "b24", "b2", "b36", "b24", "b2", "b10", "b10", "b4"], "figure_ref": [], "table_ref": []}, {"heading": "Preliminaries", "text": "In this section we outline our notations and conventions and review some tools from statistics that will be handy in our analysis.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Conventions and notations", "text": "Sets are denoted by uppercase calligraphic letters: D, Q, P. Elements in sets are denoted by lowercase Roman letters: x, y, q. Random variables are denoted by uppercase Roman letters: X, Y, Q. Probability distributions are denoted by small italicized letters, Roman or Greek: p, q, \u03c0.\nAll probability spaces in this paper are discrete and finite. A probability distribution p on a finite probability space U is a function p : U \u2192 [0, 1] s.t. x\u2208U p(x) = 1. The support of p is defined as:\nsupp(p) = {x \u2208 U | p(x) > 0}.\nA subset E of the probability space U is called an event. For an event E \u2286 U, we define p(E) to be the probability of this event under p:\np(E) = x\u2208E p(x).\nA random variable with distribution p and range V is a function X : U \u2192 V. Unless stated otherwise, when we refer to a random variable with distribution p, we mean the identity random variable: V = U and X(x) = x, for all x \u2208 U.\nGiven a predicate f : V \u2192 {0, 1}, f (X) is the following event:\nf (X) = {x \u2208 U | f (X(x)) = 1}.\nThe probability of the event f (X) under p is denoted Pr p (f (X)).\nWhen the range of the random variable is V = R, we can define the expectation of X under p:\nE p (X) = x\u2208U p(x) X(x).\nThe variance of X is defined as:\nvar p (X) = E p ((X \u2212 E p (X)) 2 ) = E p (X 2 ) \u2212 (E p (X)) 2 .\nThe standard deviation of X is the square root of its variance:\n\u03c3 p (X) = var p (X).\nWe define the mean deviation of a random variable X to be its expected absolute deviation from its mean:\ndev p (X) = E p (|X \u2212 E p (x)|).\nIt follows from the Cauchy-Schwartz inequality that the mean deviation is always bounded by the standard deviation: Proposition 1. For any random variable X, dev p (X) \u2264 \u03c3 p (X).\nThe normalized mean deviation of X is the mean deviation, normalized by the mean:\nndev p (X) = dev p (X) E p (X) .\nThe covariance of two random variables (X, Y) with joint distribution p is defined as:\ncov p (X, Y) = E p (XY) \u2212 E p (X) E p (Y).\nThe average of a function g : D \u2192 R is defined as:\navg x\u2208D g(x) = 1 |D| x\u2208D g(x)\n.\nThroughout, we assume knowledge of basic probability theory. Everything we use can be found in any standard textbook on the subject.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Total variation distance", "text": "The total variation distance between two distribution p, q on the same space U is defined as:\n||p \u2212 q|| = 1 2 x\u2208U |p(x) \u2212 q(x)|.\nWe use total variation distance, because it has some nice properties described below. Yet, other statistical distance measures, like the Kullback-Leibler divergence could have been used as well.\nThe following is a standard characterization of the total variation distance:\nLemma 2. Let p, q be two distributions on the same probability space U. Then,\n||p \u2212 q|| = max E\u2286U |p(E) \u2212 q(E)|.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Wald's identity", "text": "Suppose we invoke a sampler T times, where T is a random variable, and each invocation requires n search engine queries in expectation. What is then the expected total number of search engine queries made? As T is a random variable, simple linearity of expectation cannot be used in the analysis. The following identity from statistical sequential analysis shows that the expectation equals n \u2022 E(T ).\nTheorem 3 (Wald's identity). Let X 1 , X 2 , . . . be an infinite sequence of independent and identically distributed random variables with mean \u00b5. Let T be a random variable on {0, 1, 2, . . .}, for which the event {T = k} is independent of X k+1 , X k+2 , . . . for all k (T is called a stopping time random variable). We further assume E(T) < \u221e. Then,\nE( T i=1 X i ) = \u00b5 E(T).\nA proof of Wald's identity can be found, e.g., in the textbook of Siegmund [40], Section 2.2.", "publication_ref": ["b37"], "figure_ref": [], "table_ref": []}, {"heading": "Monte Carlo methods", "text": "We briefly review the four Monte Carlo simulation methods we use in this paper. For a more elaborate overview, refer to the textbook of Liu [32].", "publication_ref": ["b30"], "figure_ref": [], "table_ref": []}, {"heading": "Basic framework", "text": "The basic question addressed in stochastic simulation is the following. There is a target distribution \u03c0 on a space U, which is hard to sample from directly. On the other hand, there is an easy-tosample-from trial distribution p on the same space U. Can we then somehow use the samples from p to simulate sampling from \u03c0? A Monte Carlo simulator is a procedure, which given samples from p generates samples from \u03c0. In order to carry out the simulation, the simulator requires access to three \"oracle procedures\", which we describe next.\nThe first procedure, getSample p (), generates samples from the trial distribution p. Each invocation returns a single sample X from p. Successive invocations generate independent and identically distributed samples X 1 , X 2 , . . ..\nThe two other oracle procedures are used to calculate unnormalized forms of the distributions \u03c0 and p:\nDefinition 4 (Unnormalized form of a distribution). Let \u03c0 be a distribution on a space U.\nAn unnormalized form of \u03c0 is a function\u03c0 : U \u2192 [0, \u221e), which equals \u03c0 up to a normalization constant Z\u03c0 > 0. That is, \u2200x \u2208 U,\u03c0(x) = \u03c0(x) \u2022 Z\u03c0.\n\u03c0(x) is a relative weight, which represents the probability of x to be chosen in the distribution \u03c0.\nFor example, if \u03c0 is the uniform distribution on U, then all elements are equally likely to be selected. Hence, the straightforward unnormalized form of \u03c0 is:\u03c0(x) = 1, for all x \u2208 U. The corresponding normalization constant is Z\u03c0 = |U |.\nA Monte Carlo simulator needs two oracle functions, getWeight\u03c0(x) and getWeightp(x), which given an instance x \u2208 U return the unnormalized weights\u03c0(x) andp(x), respectively.\u03c0 and p are any unnormalized forms of \u03c0 and p. Note that the simulator does not need to know the corresponding normalization constants Z\u03c0 and Zp.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Rejection sampling", "text": "Rejection sampling, due to John von Neumann [44], is the most classical Monte Carlo method. Rejection sampling makes two assumptions: (1) supp(\u03c0) \u2286 supp(p); and (2) there is a known envelope constant C satisfying:\nC \u2265 max x\u2208supp(p)\u03c0 (x) p(x)\n.\nThe procedure, described in Figure 1, repeatedly generates samples from the trial distribution p, until a sample is \"accepted\". To decide whether a sample X is accepted, the procedure applies an acceptance-rejection procedure. The procedure accepts the sample X with the following acceptance probability:\nr rs (X) =\u03c0 (X) Cp(X) .\nWe call r rs the acceptance function. Note that r rs (x) \u2208 [0, 1], for all x \u2208 supp(p), due to the property of the envelope constant C.  Intuitively, rejection sampling uses the acceptance-rejection procedure to bridge the gap between p and \u03c0. For example, when \u03c0 is the uniform distribution and p is some non-uniform distribution, then the procedure assigns high acceptance probabilities to instances that have low probability in p and low acceptance probabilities to instances that have high probabilities in p. Thus, the acceptance-rejection procedure smoothes the distribution p. A simple analysis shows that for any \u03c0 and p, the distribution of the accepted samples is exactly the target distribution \u03c0.\nThe expected number of samples from p needed in order to generate each sample of \u03c0 is CZp/Z\u03c0 \u2265 max x\u2208U \u03c0(x)/p(x). Hence, the efficiency of the procedure depends on two factors: (1) the similarity between the target distribution and the trial distribution: the more similar they are the smaller is max x\u2208U \u03c0(x)/p(x); and (2) the gap between the envelope constant C and max x\u2208U\u03c0 (x)/p(x).\nThe main drawback of rejection sampling is the need to know the envelope constant C. A too high value makes the procedure inefficient, while a too low value violates the envelope condition.", "publication_ref": ["b41", "b0"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Importance sampling", "text": "Importance sampling [33] does not generate samples from the target distribution \u03c0, but rather uses samples from p to directly estimate statistical parameters relative to the distribution \u03c0. For simplicity, we assume the desired statistical parameter is E \u03c0 (f (X)), where X is distributed according to \u03c0, and f is some real-valued function, although the technique is applicable to other statistical parameters as well. Unlike rejection sampling, there is no need to know an \"envelope constant\".\nIn order to estimate E \u03c0 (f (X)), the importance sampling procedure (see Figure 2) generates n independent samples X 1 , . . . , X n from the trial distribution p. If p = \u03c0, then clearly 1 n n i=1 f (X i ) is an unbiased estimator of E \u03c0 (f (X)). However, when p = \u03c0, the samples X 1 , . . . , X n are \"weighted\" and the weights have to be accounted for in the estimation. The importance ratio at x, which is defined as\nw(x) =\u03c0 (x) p(x)\n, is exactly the desired weight. Hence, 1 n n i=1 f (X i )w(X i ) is an unbiased estimator of E \u03c0 (f (X)), modulo normalization. In order to get a correct estimator, we need to estimate also the ratio between the normalization constants of\u03c0 andp. Hence, the final estimator is:\n\u00b5 = 1 n n i=1 f (X i )w(X i ) 1 n n i=1 w(X i )\n.\n1:Function ImportanceSampling(f ,n) 2: for i = 1 to n do 3:\nX i := getSample p () 4: w(X i ) :=\u03c0 (Xi) p(Xi) 5: compute f (X i ) 6: output 1 n n i=1 f (Xi)w(Xi) 1 n n i=1 w(Xi)\nFigure 2: The importance sampling procedure.\nRemark. This is one of several possible importance sampling estimators. The estimator is biased (i.e., its expectation is not necessarily E \u03c0 (f (X))), however it is guaranteed to be close to the true value with high probability, as long as n is sufficiently large. See more details in [27].\nThe efficiency of importance sampling depends on how close is the \"shape\" ofp(x) to the \"shape\" of f (x)\u03c0(x). An appropriately chosen p can lead to less samples than even sampling from \u03c0 directly. See more details in [31]. In this paper we rely on the Liu's \"rule of thumb\" [31]. It states that the number of samples from p, required to estimate E \u03c0 (f (X)) with the same confidence level (variance) as if using n independent samples from \u03c0, is at most n(1 + var p (\u03c0(X)/p(X))).\nRemark. var p (\u03c0(X)/p(X)) can be either calculated exactly on local data, or estimated from samples on real search engines (e.g., using again importance sampling).", "publication_ref": ["b31", "b25", "b29", "b29"], "figure_ref": [], "table_ref": []}, {"heading": "Markov Chain Monte Carlo methods", "text": "In some situations even generating i.i.d. samples from the trial distribution p is infeasible. Instead, we are given a random walk that converges in the limit to p. Can we then transform this random walk into a new random walk that converges to the target distribution \u03c0? This is the question addressed by Markov Chain Monte Carlo (MCMC) methods. In this paper we focus on two of these methods: the Metropolis-Hastings (MH) algorithm [36,23] and the Maximum Degree (MD) method (cf. [3,9]).\nA Markov Chain (a.k.a. random walk) on a finite state space U is a stochastic process in which states of U are visited successively. The Markov Chain is specified by a |U | \u00d7 |U | probability transition matrix P . P is a stochastic matrix, meaning that every row x of P specifies a probability distribution P x on U. P induces a directed graph G P on U with non-negative edge weights. There is an edge x \u2192 y in the graph if P (x, y) > 0 and the corresponding weight is P (x, y).\nThe Markov Chain is called ergodic, if it satisfies two conditions: (1) it is irreducible, meaning that the graph G P is strongly connected; and (2) it is aperiodic, meaning that the g.c.d. of the lengths of directed paths connecting any two nodes in G P is 1.\nA random walk process starts at some initial state x 0 \u2208 U. The initial state is chosen according to an initial state distribution p 0 on U (typically, the mass of the initial distribution is concentrated on a single fixed state of U). The random walk then successively moves between states of U. After visiting state x, the next state is chosen randomly according to the probability distribution P x . This process goes on indefinitely.\nEach step t of the random walk induces a probability distribution p t on the state space U. The initial distribution is p 0 . Successive distributions are given by the recursive formula: p t = p t\u22121 P . Therefore, p t = p 0 P t . A fundamental theorem of the theory of Markov Chains states that if a Markov Chain is ergodic, then regardless of the initial distribution p 0 , the sequence of distributions p 0 , p 1 , p 2 , . . . is guaranteed to converge to a unique limit distribution p. That is,\n||p t \u2212 p|| t\u2192\u221e \u2212\u2192 0.\nFurthermore, the unique limit distribution p is also the unique stationary distribution of P :\npP = p.\nA random walk sampler (see Figure 3) uses a Markov Chain to generate samples from a distribution which is close to p. The algorithm starts the random walk from any given initial state x 0 and runs it for B steps (B is called the \"burn-in period\"). The reached state x B is then returned as the sample. By the above, the distribution of this sample is p B , and thus if B is sufficiently large, ||p B \u2212 p|| is small. (We discuss below how to choose a sufficiently large burn-in period.) To generate more samples, the algorithm runs the random walk again and again. (There are more efficient sampling procedures, which we mention below.) 1:Function RandomWalk(P , B, x 0 ) 2: X := x 0 3: for t = 1 to B do 4: Y := sample generated according to P X 5: X := Y 6: return X MCMC methods allow us to transform a given ergodic Markov Chain P whose limit distribution is p into a new Markov Chain P mcmc whose limit distribution is \u03c0. The two MCMC methods we consider in this paper, MH and MD, use the same framework to perform the transformation. The MCMC sampler (see Figure 4) runs a random walk similarly to the random walk sampler, except that it applies an acceptance-rejection procedure at each step. The procedure is used to determine whether the \"proposed state\" Y is \"accepted\" and thus will become the next step of the random walk or not. The acceptance function r mcmc (x, y) depends on both the current state and the proposed state. MH and MD differ in the choice of the acceptance function.\n1:Function MCMC(P , B, x 0 ) 2: X := x 0 3: for t = 1 to B do 4: Y := sample generated according to P X 5: if (accept(P ,X,Y)) 6: X := Y 7: return X 1:Function accept(P , x, y) 2: compute r mcmc (x, y) from\u03c0(x),\u03c0(y),p(x),p(y), P (x, y), and P (y, x). 3: toss a coin whose heads probability is r mcmc (x, y) 4: return true if and only if coin comes up heads The acceptance-rejection procedure effectively modifies the transition probabilities of the random walk and defines a new transition matrix P mcmc . A careful choice of the acceptance function r mcmc guarantees that the limit distribution of P mcmc is the target distribution \u03c0.\nRemark. Throughout the paper, when dealing with MCMC samplers, we will assume that the target distribution \u03c0 satisfies supp(\u03c0) = U, i.e., every node in the Markov Chain's state space has positive probability under the target distribution. This assumption is made only to make the presentation simpler.", "publication_ref": ["b34", "b21", "b2", "b8"], "figure_ref": ["fig_1", "fig_2"], "table_ref": []}, {"heading": "The Metropolis-Hastings algorithm", "text": "The MH algorithm requires that the initial Markov Chain P is not only ergodic but also satisfies the following condition: for all states x, y \u2208 U, P (x, y) > 0 \u21d4 P (y, x) > 0. Also the supports of the limit distribution p and of the target distribution \u03c0 must be equal (i.e., supp(p) = supp(\u03c0)).\nThe acceptance function used by the MH algorithm is the following:\nr mh (x, y) = min \u03c0(y) P (y, x) \u03c0(x) P (x, y) , 1 .\nNote that since\u03c0 (y) \u03c0(x) = \u03c0(y) \u03c0(x) , oracle access to an unnormalized form of \u03c0 suffices for computing this acceptance function.\nThe probability transition matrix of the resulting Markov Chain is:\nP mh (x, y) = P (x, y) r mh (x, y), if x = y, P (x, x) r mh (x, x) + 1 \u2212 z\u2208U P (x, z) r mh (x, z), if x = y.\nIt can be shown (see, e.g., [15]) that the limit distribution of this Markov Chain is exactly \u03c0.", "publication_ref": ["b14"], "figure_ref": [], "table_ref": []}, {"heading": "The Maximum Degree method", "text": "The MD method applies to arbitrary ergodic Markov Chains. The supports of the limit distribution p and of the target distribution \u03c0 should satisfy supp(p) = supp(\u03c0). Similarly to rejection sampling, application of this method requires the availability of an \"envelope constant\" C. C must satisfy the following condition:\nC \u2265 max x\u2208Up (x) \u03c0(x)\n.\nThe need for an envelope constant is the major disadvantage of the Maximum Degree method relative to the Metropolis-Hastings algorithm. However, if the envelope constant is chosen sufficiently close to its lower bound, then the MD method can become significantly more efficient than the MH algorithm.\nThe acceptance function used by the MD algorithm is the following:\nr md (x) =p (x) C\u03c0(x)\n.\nRemark. Notice the reversed roles ofp(x) and\u03c0(x), comparing to the rejection sampling acceptance function. This is not accidental. Rejection sampling is similar (but not identical) to the application of the MD method on a degenerate random walk, which converges in one step to the limit distribution p (that is, all the rows of the transition matrix P equal p). The reversed roles are due to the reversed semantics of acceptance in rejection sampling versus MCMC methods. In rejection sampling, when the current state is accepted, the process stops and outputs the current state. In MCMC methods, when a proposed state is accepted, then implicitly the current state is rejected, and the process continues.\nThe probability transition matrix of the MD Markov Chain is:\nP md (x, y) = P (x, y) r md (x), if x = y, P (x, x) r md (x) + 1 \u2212 r md (x), if x = y.\nTheorem 5. The limit distribution of the Markov Chain defined by P md is \u03c0.\nRemark. To the best of our knowledge, the formulation above is the first application of the Maximum Degree method to arbitrary ergodic Markov Chains and to arbitrary target distributions. Previous studies [3,9] applied the MD method only in the special case P is a simple random walk on an undirected graph G and \u03c0 is the uniform distribution over the vertices of G. The limit distribution of the simple random walk is the degree distribution (i.e., each node is chosen proportionally to its degree). In this case C must be set as an upper bound on the maximum degree of the graph, and that is why the method is called \"Maximum Degree\".\nThe acceptance function of the MD method has the peculiar property that it depends only on the current state x and not on the proposed state y. This fact allows a more efficient implementation of the MD sampler (see Figure 5). This sampler postpones the selection of the proposed state Y to until after acceptance is achieved. Hence, rather than selecting a proposed state every time the acceptance-rejection procedure is called, the proposed state is selected only once. Since in many situations selection of a proposed state is costly, this amounts to significant savings in running time.\nA further improvement is possible. Note that the number of steps the random walk spends at each state x is a geometric random variable with a known success probability. Therefore, when the sampler moves to a new state x, it can simulate the number of steps that it is going spend at the state by generating an appropriate geometric random variable. It can then immediately select the next state. This saves the need to perform the iterative coin tosses. 1:Function MD(P , B, x 0 , C) 2: X := x 0 3: for t = 1 to B do 4: if (accept(P ,C,X)) 5:\nY := sample generated according to P X 6:\nX := Y 7: return X 1:Function accept(P , C, x) 2: r md (x) :=p (x) C\u03c0(x)\n3: toss a coin whose heads probability is r md (x) 4: return true if and only if coin comes up heads ", "publication_ref": ["b2", "b8"], "figure_ref": ["fig_3"], "table_ref": []}, {"heading": "The burn-in period", "text": "How should we set the burn-in period B of a random walk in order to guarantee that the selected sample has distribution which is close to the limit distribution? To this end, a rich pool of techniques, ranging from algebraic to geometric, is available from the theory of Markov Chains (see a survey by Diaconis and Saloff-Coste [15] for a detailed review). In this paper we focus on a popular technique, which is based on estimating the spectral gap of the Markov Chain's transition matrix.\nLet P be the transition matrix of an ergodic Markov Chain, whose limit distribution is p. For each \u03b5 > 0, we define the \u03b5-burn-in period (a.k.a. \u03b5-mixing time) of the Markov Chain as: T \u03b5 (P ) = min{t | for all initial distributions p 0 and \u2200t \u2032 \u2265 t, ||p t \u2032 \u2212 p|| < \u03b5}.\nThat is, T \u03b5 (P ) is the first step t, for which p t is guaranteed to be at most \u03b5 away from the limit distribution p.\nThe spectral gap technique for bounding the burn-in period is applicable only to reversible Markov Chains. A Markov Chain is called reversible, if for all states x, y \u2208 U, p(x)P (x, y) = p(y)P (y, x). It can be shown that a reversible Markov Chain is equivalent to a random walk on a weighted and undirected graph.\nLet n = |U | and let \u03bb 1 , . . . , \u03bb n be the eigenvalues of P , ordered from largest to smallest by absolute value (i.e., |\u03bb\n1 | \u2265 |\u03bb 2 | \u2265 \u2022 \u2022 \u2022 \u2265 |\u03bb n |).\nThe spectral gap of P is defined as the difference between its first and the second eigenvalues:\n\u03b1(P ) = |\u03bb 1 | \u2212 |\u03bb 2 | = 1 \u2212 |\u03bb 2 |.\n(For a transition matrix P , \u03bb 1 = 1 always.) Using the spectral gap, one can bound the pointwise distance between p t and p: Theorem 6 (Sinclair [41], Proposition 2.1, Page 47). Let P be the transition matrix of a reversible Markov Chain whose limit distribution is p. Then, for any initial distribution, for every t \u2265 0, and for every x \u2208 U,\n|p t (x) \u2212 p(x)| \u2264 p(x) p min \u2022 (1 \u2212 \u03b1(P )) t ,\nwhere p min = min x\u2208U p(x).\nThat is, the larger the spectral gap, the faster the convergence to the limit distribution.\nAn immediate corollary of the above theorem is the following bound on the burn-in period of a reversible Markov Chain:\nCorollary 7. Let P be the transition matrix of a reversible Markov Chain whose limit distribution is p. Then, for every \u03b5 > 0,\nT \u03b5 (P ) \u2264 1 \u03b1(P ) ln 1 p min + ln 1 \u03b5 .\nProof. We first bound the total variation distance between p and p t :\n||p \u2212 p t || = 1 2 x\u2208U |p(x) \u2212 p t (x)| \u2264 1 2 x\u2208U p(x) p min \u2022 (1 \u2212 \u03b1(P )) t (By Theorem 6) \u2264 (1 \u2212 \u03b1(P )) t 2 \u2022 \u221a p min \u2022 |U | (Cauchy-Schwartz) \u2264 (1 \u2212 \u03b1(P )) t 2 \u2022 p min (Using the fact p min \u2264 1/|U |).\nHence, in order for ||p \u2212 p t || \u2264 \u03b5, we need\nt \u2265 ln 1 \u03b5 + ln 1 p min \u2212 ln 2 ln 1 1\u2212\u03b1(P ) .\nThe corollary follows using the fact 1 \u2212 \u03b1 < e \u2212\u03b1 for 0 < \u03b1 < 1.\nIt can be shown that if P is reversible, then also P mh and P md are reversible, and thus we can use the spectral gap technique to estimate the required burn-in periods of the MH and the MD samplers.", "publication_ref": ["b14", "b38"], "figure_ref": [], "table_ref": []}, {"heading": "Efficient random walk sampling", "text": "The naive method for generating multiple independent samples from (a distribution which is close to) the limit distribution p of a Markov Chain is to run a new random walk for each desired sample. This incurs high overhead, if the required number of samples is large. It turns out that in some situations it is possible to use a single random walk to generate multiple samples.\nAldous [1] (with further improvements by Gillman [18] and Kahale [28]) proposed an efficient procedure for generating dependent samples that can be used to perform accurate density estimations.\nSuppose A \u2286 U is a subset of the state space. The density of A under a probability measure p is the quantity p(A). For example, when p is the uniform distribution on U, the density of A is the ratio |A|/|U |. Suppose that we are given an \"oracle\" procedure, which on input x \u2208 U can determine whether x \u2208 A or not, and that we would like to use this procedure to estimate the density of A. This type of estimation is very popular. One example from our domain is the estimation of the relative overlap between two search engines.\nGiven a Markov Chain P whose limit distribution is p, the most obvious method for estimating p(A) would be to run n random walks, each for T \u03b5 (P ) steps, and thereby obtain n i.i.d. samples from (a distribution which is close to) p. The estimator for p(A) would then be the fraction of the n samples that fall into A.\nAldous's procedure is more efficient. Instead of running n walks, Aldous suggests running only a single walk of length T \u03b5 (P )+n 1 \u03b1(P ) , and use the last n 1 \u03b1(P ) states visited as the samples, disregarding the first T \u03b5 (P ) steps as sample delay. As shown in [1,18,28], these n 1 \u03b1(p) dependent samples can be used to produce an estimate for p(A), which is as good as the estimate obtained from the n independent samples. Overall, the Aldous procedures saves a factor of log(1/p min ) in the number of random walk steps over the naive procedure.", "publication_ref": ["b0", "b16", "b26", "b0", "b16", "b26"], "figure_ref": [], "table_ref": []}, {"heading": "Approximate Monte Carlo methods", "text": "All Monte Carlo methods assume that the trial distribution p is known, up to normalization. This assumption turns out to be very problematic in our setting, since the trial distributions we construct depend on unknown internal data of the search engine. An approximate Monte Carlo method employs an \"approximate trial distribution\" q rather than the true trial distribution p in the acceptance function calculations. The mismatch between the trial samples (that are generated from p) and the acceptance function (which is based on q) implies that the sampling distributions of the resulting procedures are no longer guaranteed to equal the target distribution \u03c0. To the best of our knowledge, no previous study addressed this scenario before.\nWe show that the sampling distribution of approximate rejection sampling and the limit distributions of approximate Metropolis-Hastings and of approximate Maximum Degree are all identical to some distribution \u03c0 \u2032 , for which we give a closed form formula. We then prove that \u03c0 \u2032 is close to the target distribution \u03c0, as long as the trial distribution p and the approximate trial distribution q are similar. We also prove that the estimations generated by approximate importance sampling are close to the true values. All proofs are provided in Appendix B.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Approximate rejection sampling", "text": "Consider the following modified (\"approximate\") form of rejection sampling. The procedure is given the following three oracle procedures: (1) getSample p (), which generates samples from p, (2) getWeight\u03c0(x), which calculates an unnormalized form of the target distribution \u03c0; and (3) getWeightq(x), which calculates an unnormalized form of an \"approximate trial distribution\" q. \u03c0, p, q are assumed to satisfy: supp(\u03c0) \u2286 supp(p) \u2286 supp(q).\nThe approximate rejection sampling procedure works exactly like the standard procedure, except that the acceptance function it uses is the following:\nr \u2032 rs (x) =\u03c0 (x) Cq(x) ,\nwhere\nC \u2265 max x\u2208supp(p)\u03c0 (x) q(x)\nis an envelope constant. The following theorem characterizes the sampling distribution of the approximate rejection sampling procedure and analyzes its sample complexity: Theorem 8. The sampling distribution of the approximate rejection sampling procedure is:\n\u03c0 \u2032 (x) = \u03c0(x) p(x) q(x) E \u03c0 p(X) q(X)\n.\nThe expected number of samples from p needed to generate each sample from \u03c0 \u2032 is:\nCZq Z\u03c0 E \u03c0 p(X) q(X)\n.\nThe following proposition shows that as long as the trial distribution p and the approximate trial distribution q are \"similar\" relative to the target distribution \u03c0 (in the sense that the ratio p(X)/q(X) has low variance when X is chosen according to \u03c0), then the sampling distribution of approximate rejection sampling is close to the target distribution:\nProposition 9. ||\u03c0 \u2032 \u2212 \u03c0|| = 1 2 ndev \u03c0 p(X) q(X) .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Approximate Importance Sampling", "text": "The approximate importance sampling procedure assumes oracle access to the approximate trial distribution q. \u03c0, p, q are assumed to satisfy:\nsupp(\u03c0) \u2286 supp(p) \u2286 supp(q).\nThe approximate importance sampling procedure works exactly like the standard importance sampling procedure, except that the following approximate importance ratios are used:\nw \u2032 (x) =\u03c0 (x) q(x)\n.\nThe following theorem shows that as long as the ratio p(X)/q(X) is uncorrelated with the function f (X) whose expectation we need to estimate, then the estimate produced by approximate importance sampling is close to the desired parameter:\nTheorem 10. Let\u03bc \u2032 = A B = 1 n n i=1 f (X i )w \u2032 (X i ) 1 n n i=1\nw \u2032 (X i ) be the estimator produced by the approximate importance sampling procedure for the parameter E \u03c0 (f (X)). Then,\nE p (A) E p (B) = E \u03c0 (f (X)) + cov \u03c0 f (X), p(X) q(X) E \u03c0 p(X) q(X)\n.\nThe next theorem shows that as n grows to infinity, the difference between E p (\u03bc \u2032 ) and\nEp(A) Ep(B)\ndiminishes to 0.\nTheorem 11. Suppose A and B are two estimators such that E(A) E(B) = I. Let A 1 , . . . , A n and B 1 , . . . , B n be n independent instances of A and B, respectively. Then,\n| E 1 n n i=1 A i 1 n n i=1 B i \u2212 I| \u2264 1 n \u2022 C,\nwhere\nC = I \u2022 var(B) E 2 (B) + | cov(A,B)| E 2 (B) + o(1).\nThe above theorem can be proved using the Delta method in statistics. See an example proof in the full version of our subsequent paper [5].", "publication_ref": ["b4"], "figure_ref": [], "table_ref": []}, {"heading": "Approximate Metropolis-Hastings", "text": "Next, we discuss an approximate variant of the Metropolis-Hastings algorithm. Like in approximate rejection sampling, we assume oracle access to an approximate trial distribution q. We assume that supp(q) = supp(p) = supp(\u03c0) = U.\nWe also need to assume that the base Markov Chain P is reversible (i.e., p(x)P (x, y) = p(y)P (y, x), for all x, y \u2208 U). When P is reversible, the acceptance function of the standard Metropolis-Hastings algorithm can be rewritten as follows:\nr mh (x, y) = min \u03c0(y) P (y, x) \u03c0(x) P (x, y) , 1 = min \u03c0(y) p(x) \u03c0(x) p(y) , 1 .\nThe approximate Metropolis-Hastings procedure is identical to the standard procedure, except that it uses the following acceptance function:\nr \u2032 mh (x, y) = min \u03c0(y) q(x) \u03c0(x) q(y) , 1 .\nNote that since\u03c0 (y) \u03c0(x) = \u03c0(y) \u03c0(x) andq (x) q(y) = q(x) q(y) , this acceptance function can be computed using oracle access to unnormalized forms of \u03c0 and q.\nThe following theorem shows that the resulting Markov Chain is ergodic and that its unique limit distribution is \u03c0 \u2032 , where \u03c0 \u2032 is defined as in Theorem 8:\n\u03c0 \u2032 (x) = \u03c0(x) \u2022 p(x) q(x) / E \u03c0 p(X) q(X) .\nTheorem 12. Let P \u2032 mh be the transition matrix of the approximate Metropolis-Hastings algorithm. Then, P \u2032 mh forms an ergodic Markov Chain and its unique limit distribution is \u03c0 \u2032 .\nIt follows from Proposition 9 that the limit distribution of the approximate MH random walk is close to the target distribution \u03c0 as long as p and q are similar relative to \u03c0.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Approximate Maximum Degree", "text": "As before, we assume oracle access to an approximate trial distribution q and that supp(q) = supp(p) = supp(\u03c0) = U. This time we do not need to assume that the base Markov Chain P is reversible.\nApproximate MD is identical to the standard MD, except that the following modified acceptance function is used:\nr \u2032 md (x) =q (x) C\u03c0(x)\n, where\nC \u2265 max x\u2208Uq (x) \u03c0(x)\n.\nThe following theorem shows that the resulting Markov Chain is ergodic and that its unique limit distribution equals \u03c0 \u2032 , where \u03c0 \u2032 is defined as in Theorem 8:\n\u03c0 \u2032 (x) = \u03c0(x) \u2022 p(x) q(x) / E \u03c0 p(X) q(X) .\nTheorem 13. Let P \u2032 md be the transition matrix of the approximate Maximum Degree procedure. Then, P \u2032 md forms an ergodic Markov Chain. The unique limit distribution of P \u2032 md is \u03c0 \u2032 .\nIt follows from Proposition 9 that the limit distribution of the approximate MD random walk is close to the target distribution \u03c0 as long as p and q are close relative to \u03c0.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Formal framework", "text": "In this section we lay out the formal framework for the design and analysis of search engine samplers.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Search engines", "text": "Definition 14 (Search engine). A search engine is a 4-tuple D, Q, results(\u2022), k , where:\n1. D is the document corpus indexed. Documents are assumed to have been pre-processed (e.g., they may be truncated to some maximum size limit).\n2. Q is the space of queries supported by the search engine.\n3. results(\u2022) is a mapping that maps every query q \u2208 Q to an ordered sequence of documents, called results. The cardinality of q is the number of results: card(q) = |results(q)|.\n4. k is the result limit. Only the top k results are actually returned to the user via the search engine's public interface.\nA query q is said to be overflowing, if card(q) > k. It is said to be underflowing, if card(q) = 0. If q neither overflows nor underflows, it is called valid.\nA document x matches a query q, if x \u2208 results(q). The set of queries that a document x matches is denoted queries(x).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Search engine samplers", "text": "Definition 15 (Search engine sampler). Let \u03c0 be a target distribution on a document corpus D indexed by a search engine. A search engine sampler is a randomized procedure, which is given access to three \"oracle\" procedures:\n1. getWeight\u03c0(x): returns the unnormalized weight of an instance x \u2208 D under the target distribution \u03c0.\n2. getResults(q): returns the top k results from the search engine on the query q.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "getDocument(x)", "text": ": returns the HTTP header and the content of the document x.\nEach invocation of the sampler outputs a random document X from the corpus D. The distribution of the sample X is called the sampling distribution and is denoted by \u03b7. Successive invocations of the sampler produce independent samples from \u03b7.\nIf the unnormalized form of \u03c0 is independent of the corpus D (e.g., when \u03c0 is the uniform distribution and\u03c0(x) = 1 for all x), then the same sampler can be used to sample from different search engines. All that needs to be changed is the implementation of the procedure getResults(q).\nWhen the sampling distribution \u03b7 of the sampler equals exactly the target distribution \u03c0, then the sampler is said to be perfect. Otherwise, it is biased. We discuss below the two main metrics for measuring the quality of a sampler w.r.t. a given target distribution: the sampling recall and the sampling bias.\nNot all documents in D are practically reachable via the public interface of the search engine. Some pages have no text content and others have very low static rank, and thus formulating a query that returns them as one of the top k results may be impossible. Thus, search engine samplers usually generate samples only from large subsets of D and not from the whole corpus D. The sampling recall of a sampler with target \u03c0 and sampling distribution \u03b7 is defined as \u03c0(supp(\u03b7)). For instance, when \u03c0 is the uniform distribution, the sampling recall is | supp(\u03b7)|/|D|, i.e., the fraction of documents that the sampler can actually return as samples. Ideally, we would like the recall to be as close to 1 as possible. Note that even if the recall is lower than 1, but supp(\u03b7) is sufficiently representative of D, then estimators that use samples from supp(\u03b7) can produce accurate estimates of parameters of the whole corpus D.\nSince samplers sample only from large subsets of D and not from D in its entirety, it is unfair to measure the bias of a sampler directly w.r.t. the target distribution \u03c0. Rather, we measure the bias w.r.t. the distribution \u03c0 restricted to supp(\u03b7). Formally, let \u03c0 supp(\u03b7) be the following distribution on supp(\u03b7):\n\u03c0 supp(\u03b7) (x) = \u03c0(x) \u03c0(supp(\u03b7))\n, \u2200x \u2208 supp(\u03b7).\nThe sampling bias of the sampler is defined as the total variation distance between \u03b7 and \u03c0 supp(\u03b7) :\n||\u03b7 \u2212 \u03c0 supp(\u03b7) || = 1 2 x\u2208supp(\u03b7) |\u03b7(x) \u2212 \u03c0(x) \u03c0(supp(\u03b7)) |.\nFor example, if a sampler generates truly uniform samples from a subset D \u2032 of D that constitutes 80% of D, then its sampling recall is 0.8 and its sampling bias is 0.\nThe two most expensive resources of a search engine sampler are: (1) the amount of queries submitted to the search engine; and (2) the amount of additional web pages fetched. Search engine queries and web page fetches consume significant amount of time and require network bandwidth.\nIn addition, the rate at which a sampler can submit queries to the search engine is usually very restricted, since search engines impose hard daily limits on the number of queries they accept from any single user. We thus measure the complexity of search engine samplers in terms of their query cost (expected number of calls to the subroutine getResults() per sample generated) and their fetch cost (expected number of calls to the subroutine getDocument() per sample generated).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Query pools", "text": "Consider a search engine S, whose corpus is D and whose query space is Q.\nDefinition 16 (Query pool). A query pool is a fragment P \u2286 Q of the query space.\nA query pool may be specified either explicitly as a set of queries, e.g.,\nP = {[Java software], [\"Michael Jordan\" -basketball], [Car OR Automobile]},\nor implicitly, e.g., P = All single-term queries.\nNote that in the latter case in order to transform P into an explicit form, we need a list of all the terms that occur in the corpus D. All the samplers we consider in this paper fix some query pool P and use only queries from P in order to generate the sample documents from D.\nQueries-documents graph Every query pool P naturally induces a bipartite graph B P on P \u00d7 D. Its left side consists of all queries in P and its right side consists of all documents in D. A query q \u2208 P is connected to a document x \u2208 D if and only if x \u2208 results(q). 3 The cardinality of a query q, denoted card(q), is its degree in B P . This is exactly the number of documents in the result set of the query. The cardinality of a set of queries P \u2032 \u2286 P is defined as:\ncard(P \u2032 ) = q\u2208P \u2032 card(q).\nFor a document x, we denote by queries P (x) the set of its neighbors in B P . These are exactly all the queries in P that x matches. For example, if P is the pool of all single term queries, then queries P (x) is the set of all distinct terms that occur in the text of x. The degree of x is: deg P (x) = |queries P (x)|. The degree of a set of documents D \u2032 \u2286 D is defined as:\ndeg P (D \u2032 ) = x\u2208D \u2032 deg P (x).\nNote that card(P) is the sum of the degrees of all nodes on the left side of B P , while deg P (D) is the sum of the degrees of all nodes on the right side of B P . Both sums equal to the number of edges in B P , and we thus obtain the following result:\nProposition 17. Let P be any query pool. Then, card(P) = deg P (D).\nRecall We say that a query pool P covers a document x, if deg P (x) > 0. That is, at least one query in P returns x as a result. Let D P be the collection of documents covered by P. Note that a sampler that uses only queries from P can never reach documents outside D P .\nFor a distribution \u03c0 on D, the recall of P w.r.t. \u03c0, denoted recall \u03c0 (P), is the probability that a random document selected from \u03c0 is covered by P. That is, recall \u03c0 (P) = \u03c0(D P ).\nIn the case \u03c0 is the uniform distribution on D, recall \u03c0 (P) = |D P |/|D|.\nOverflow probability Recall that a query q is valid if it neither overflows nor underflows. The set of valid queries q \u2208 P is denoted P + and the set of invalid queries is denoted P \u2212 . Given a distribution \u03c6 on P, we define the overflow probability of \u03c6, denoted ovprob(\u03c6), to be the probability that a random query Q chosen from \u03c6 overflows:\novprob(\u03c6) = Pr \u03c6 (card(Q) > k).", "publication_ref": ["b2"], "figure_ref": [], "table_ref": []}, {"heading": "Incidence computation", "text": "The samplers we use in this paper require \"local accessibility\" to the queries-documents graph B P . By that we mean that the sampler needs efficient implementations of the following procedures that compute incidences in the graph:\n1. getIncidentDocs P (q): Given a query q \u2208 P, returns all documents that are incident to q in B P , i.e., results(q).\n2. getIncidentQueries P (x): Given a document x \u2208 D, returns all queries that are incident to x in B P , i.e., queries P (x).\nImplementing the above procedures efficiently is crucial since our algorithms call them over and over again. Moreover, the query and the fetch costs of our samplers are \"consumed\" only through these procedures. We first describe a simple, yet impractical, implementations of the above procedures, and then propose more realistic implementations.\nNaive implementations. The implementation of the first procedure (getIncidentDocs P (q)) is trivial: just submit q to the search engine and output all the results returned. The cost of this implementation is a single search engine query. It has one caveat, though: it is applicable only to non-overflowing queries. If the given query overflows, the procedure returns only the top k documents in the result set. The second procedure (getIncidentQueries P (x)) is implemented by submitting each query from P to the search engine and returning those that have x as their result. This implementation is usually impractical, due to a large number of queries in a typical query pool.\nEfficient implementations. The implementation of the first procedure (getIncidentDocs P (q)) is as before: submit q to the search engine and output all the results returned. To implement the second procedure (getIncidentQueries P (x)), we first fetch the content of x. Then, for a pool consisting of term/phrase queries, we can compute queries P (x) by extracting all the terms/phrases directly from the content of x, and without submitting queries to the search engine. We call the set of queries extracted from the content of x the predicted queries, and denote them by pqueries P (x). The cost of computing pqueries P (x) by the above procedure is a single page fetch. We note that not all the pools allow such an implementation. Pools that consist solely of standard term/phrase queries (e.g., [java], [\"Michael Jordan\"]) do. Pools that contain other types of queries, like complex Boolean queries or link queries (which ask for documents that contain a link to a given URL), may not allow such an implementation.\nInaccuracies in incidence calculation. Using pqueries P (x) as a substitute for queries P (x) introduces some inaccuracies in the incidence calculations. We distinguish between two types of inaccuracies: (1) incidence recall deficiency: pqueries P (x) may miss some queries that belong to queries P (x); (2) incidence precision deficiency: pqueries P (x) may contain queries that do not belong to queries P (x).\nIn the following we list several factors that cause these deficiencies:\n1. Overflowing queries. Some of the queries that x matches may be overflowing (have more than k matches) and consequently may not return x as one of their top k results.\n2. Duplicates and near-duplicates. If the search engine filters duplicate or near-duplicate documents, a query that x matches may not return x as a result, if one of the documents that are similar to x is returned as a result. Note that although we requested search engines not to eliminate duplicates from search results, duplicate elimination may be done at crawl/index time already.\n3. Host collapsing. If the search engine collapses documents belonging to the same host, a query that matches x may not return x as a result, if another document from the same host is returned as a result. Note that we requested search engines not to collapse results from the same host, so this can be a problem only if the search engine limits the number of documents it indexes per host.\n4. Indexing depth. We assumed the first d (where d is some constant, d was set to 10, 000 in our experiments) terms (and the corresponding phrases) in each document are indexed. If the search engine's indexing depth is smaller than d, queries that we find x to match may not return x as a result. While the exact indexing depth is not disclosed by search engines, and may even vary from document to document, our experiments, as well as those of [8], showed that the majority of the documents are indexed by the first d = 10, 000 terms at the least.\n5. Parsing and tokenization. Different search engines may have slightly different algorithms for parsing and tokenizing documents. For example, two words separated by a comma may or may not be indexed as a phrase. If our parser determines a sequence of terms in x to be a phrase, while the search engine's parser does not, the corresponding phrase will not return x as a result. Conversely, search engine's parser may detect a phrase that our parser does not. We designed our parser to mimic the search engines' parsers as closely as we could.\n6. Indexing by terms not appearing in document content. Search engines index documents under terms that do not occur at their text at all (e.g., anchor text terms). Our parser, obviously, will not find a document to match such terms (unless they appear in the document content too).\nOvercoming the inaccuracies. Incidence recall deficiency can be easily alleviated by discarding from B P edges corresponding to queries that belong to queries P (x) but not to pqueries P (x). To this end, we modify getIncidentDocs P (q) so that after computing results(q), it fetches all the documents in results(q) and returns only those for which q \u2208 pqueries P (x) (note that |results(q)| is at most k). Incidence precision deficiency is not as easy to handle. Theoretically, we could have submitted all the queries in pqueries P (x) to the search engine and discard the ones that do not return x as a result, but that would have required sending many (sometimes, thousands of) queries per sample document.\nTo tackle the incidence precision problem more realistically, we note that our algorithms do not really need to know the whole set of incident queries of a given document. Rather, they need:\n(1) to sample random queries from queries P (x); and (2) calculate the degree of x: deg P (x) = |queries P (x)|. Sampling random queries from queries P (x) can be done by repeatedly selecting queries from pqueries P (x) and submitting them to the search engine until hitting a query q so that x \u2208 results(q). As for the degree calculation, we do not have an accurate method of estimating document degrees. Rather, we use |pqueries P (x)| as an (over-)estimate of deg P (x). In our subsequent paper [5], we presented an efficient technique for avoiding the degree overestimation.\nIn Section 5 we provide a theoretical analysis of the effect of the inaccuracies in degree calculations on the bias of our samplers. From now on, we focus on overflowing queries as the only source of deficiency, as we believe these to be the most significant factor causing degree overestimation.", "publication_ref": ["b7", "b4"], "figure_ref": [], "table_ref": []}, {"heading": "Other assumptions", "text": "Dynamic corpora. Our algorithms assume that search engine corpora do not change during the sampling process. Obviously, this assumption does not hold in practice as search engine indices are constantly being updated. In our experiments we noticed only slight differences in the results returned for the same queries at different steps of the experiment. We note that the duration of our experiments was determined by the limited resources we used. Having more resources could have shortened this duration and drastically diminished the effect of corpus changes.\nVersioned indices. Search engines may maintain multiple non-identical versions of the index simultaneously, and serve users from different versions of the index (based on the user's profile or based on load-balancing criteria). Our algorithms assume all queries are served from a single coherent index. If all the queries are indeed served from the same version of the index, then the results produced by our algorithms reflect properties of the specific index version used. Some anomalies may occur, if the samplers work with multiple index versions simultaneously, assuming the differences among the versions are significant (which we do not believe to be the case in most search engines).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Pool-based sampler", "text": "In this section we describe our pool-based (PB) sampler. The sampler assumes knowledge of an explicit and admissible query pool P. Such a pool can be constructed by crawling a large corpus of web documents, such as the ODP directory [16], and collecting terms or phrases that occur in its pages. We can run the PB sampler with any such pool, yet the choice of the pool may affect the bias, the recall, and the query and fetch costs of the sampler. In the end of the section we provide analysis of the impact of the choice of the query pool on the performance of the PB sampler.\nLet \u03c0 be a target distribution on the corpus D. We assume our sampler is given a black box procedure getWeight\u03c0(x) that computes an unnormalized form\u03c0 of \u03c0. We denote by qcost(\u03c0) (query cost) and by fcost(\u03c0) (fetch cost) the worst-case number of search engine queries and page fetches, respectively, the procedure uses to compute the weight\u03c0(x). As a running example, we think of \u03c0 as the uniform distribution on D. The unnormalized form we use is \u2200x,\u03c0(x) = 1, and thus qcost(\u03c0) = fcost(\u03c0) = 0.\nRemark. There are natural examples of target distributions \u03c0, for which qcost(\u03c0) > 0 and/or f cost(\u03c0) > 0. For example, if \u03c0 is the distribution of documents by in-degree, then qcost(\u03c0) > 0, as we need to query a search engine in order to find the number of in-links of a given document. If \u03c0 is the distribution of documents by out-degree, then f cost(\u03c0) > 0, because we need to fetch the content of a document in order to find the number of out-links it has.\nThe PB sampler does not directly generate samples from the target distribution \u03c0. Instead, it uses another sampler-the degree distribution sampler-that generates samples from the \"document degree distribution\" (see definition below). An unnormalized form of the document degree distribution can be efficiently computed. The PB sampler therefore applies a Monte Carlo method (e.g., rejection sampling) on the samples from the degree distribution in order to generate samples from \u03c0.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "The outer procedure", "text": "Recall that the degree of a document x \u2208 D is the number of queries it matches:\ndeg P (x) = |queries P (x)| = |{q \u2208 P | x \u2208 results(q)}|.\nThe distribution of documents by degree is called the document degree distribution:\nd P (x) = deg P (x) deg P (D) .\nNote that the support of d P is exactly D P -the set of documents that are covered by P. The document degree distribution has an unnormalized form, which is easy to compute:\nd P (x) = deg P (x).\nRecall that P is an admissible query pool, and thus computing deg P (x) = |queries P (x)| can be done by fetching only x and without submitting queries to the search engine.\nAssume for the moment that we already have a sampler (DDSampler) that generates random documents sampled from the degree distribution d P (we show in the next subsection how to construct such a sampler). Figure 6 shows the outer function of the PB sampler, which uses DDSampler as a subroutine.\n1: Function PBSampler(SE,C) 2: while (true) do 3: X := random document generated by DDSampler(SE) 4:\ntoss a coin whose heads probability is\u03c0 (X)\nC deg P (X)\n5: if (coin comes up heads) 6: break 7: return X Figure 6: The outer procedure of the PB sampler.\nThe PB sampler applies rejection sampling with trial distribution d P and target distribution \u03c0. The unnormalized weights used for document x are\u03c0(x) (which is computed by calling the getWeight\u03c0(x) procedure) andd P (x) = deg P (x). Recall that the latter can be computed by a single page fetch. An envelope constant C satisfying\nC \u2265 max x\u2208D P\u03c0 (x) deg P (x)\nmust be given to the PB sampler as input. In the case \u03c0 is the uniform distribution on D,\u03c0(x) = 1 for all x \u2208 D while deg P (x) \u2265 1 for all x \u2208 supp(d P ) = D P . Therefore, in this case an envelope constant of C = 1 will do. The resulting acceptance probability (Line 4) is simply 1/ deg P (X).\nWe next analyze the recall and the bias of the PB sampler, under the assumption that DDSampler generates samples from d P : Proposition 18. Suppose the sampling distribution of DDSampler is exactly the degree distribution d P . Then, the sampling recall of the PB sampler is:\nrecall \u03c0 (P) = \u03c0(D P )\nand it is a perfect sampler, i.e., it has a sampling bias of 0.\nProof. Let \u03b7 be the sampling distribution of the PB sampler. We first show that supp(\u03b7) = D P \u2229 supp(\u03c0). Clearly, supp(\u03b7) \u2286 D P , because the PB sampler cannot output documents that are not covered by P. Also, supp(\u03b7) \u2286 supp(\u03c0), because only documents that have non-zero probability under \u03c0 can be accepted by the acceptance-rejection procedure. Therefore, supp(\u03b7) \u2286 D P \u2229supp(\u03c0).\nTo show containment in the other direction, consider any document x \u2208 D P \u2229 supp(\u03c0). This means that: (1) deg P (x) > 0; and (2)\u03c0(x) > 0. The first condition implies that x has a positive probability to be selected by DDSampler. The second condition implies that x has a positive probability to be accepted by the acceptance-rejection procedure. Therefore, x has an overall positive probability to be returned by the PB sampler and thus D P \u2229 supp(\u03c0) \u2286 supp(\u03b7).\nWe can now calculate the recall of the PB sampler:\nrecall \u03c0 (P B) = \u03c0(supp(\u03b7)) = \u03c0(D P \u2229 supp(\u03c0)) = \u03c0(D P ) = recall \u03c0 (P).\nNext, we analyze the sampling bias of the PB sampler. To this end, we need to calculate the distance between \u03b7 and the distribution obtained by restricting \u03c0 to supp(\u03b7), i.e., \u03c0 supp(\u03b7) . The main thing to observe is that the unnormalized form\u03c0 of \u03c0 also gives an unnormalized form of \u03c0 supp(\u03b7) . Let Z\u03c0 be the normalization constant of\u03c0. Define\nZ\u03c0 supp(\u03b7) = Z\u03c0 \u2022 \u03c0(D P ).\nHence, for every x \u2208 supp(\u03b7), we have:\n\u03c0 supp(\u03b7) (x) = \u03c0(x) \u03c0(supp(\u03b7)) =\u03c0 (x) Z\u03c0 \u2022 \u03c0(D P \u2229 supp(\u03c0)) =\u03c0 (x) Z\u03c0 \u2022 \u03c0(D P ) =\u03c0 (x) Z\u03c0 supp(\u03b7)\n.\nTherefore,\u03c0 is indeed an unnormalized form of \u03c0 supp(\u03b7) . So the right way to view the PB sampler is as a rejection sampling procedure with \u03c0 supp(\u03b7) (and not \u03c0) as the target distribution and with d P as the trial distribution. Note that supp(\u03c0 supp(\u03b7) ) \u2286 D P = supp(d P ) and hence the necessary pre-condition of rejection sampling is met. It now follows from the analysis of rejection sampling that \u03b7 = \u03c0 supp(\u03b7) .\nWe note that one could implement the PB sampler with other Monte Carlo methods as well. We chose to present here rejection sampling, due to its simplicity.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Degree distribution sampler", "text": "Next, we describe DDSampler-the sampler that samples documents from the degree distribution.\nTo this end, we need to sample queries from the query pool according to the query cardinality distribution. Recall that the cardinality of a query is the number of documents in its result set. The distribution of queries by cardinality is defined as:\nc P (q) = card(q) card(P) .\nIn Figure 7 we describe the degree distribution sampler. For the time being, we make two unrealistic assumptions: (1) There is a sampler QCSampler that samples queries from the cardinality distribution c P . (This seems unrealistic, because we do not know a priori the cardinalities of all the queries in P, and so it is not clear how to sample queries proportionally to their cardinalities.) (2) No query in P overflows. (This is unrealistic, because it is not clear how to create a large explicit pool of queries that does not have even a single overflowing query.) We later show how to remove these assumptions. The sampler is very similar to the Bharat-Broder sampler, except that it samples random queries proportionally to their cardinalities. Since no query overflows, all documents that match a query are included in its result set. It follows that the probability of a document to be sampled is proportional to the number of queries in P that it matches: Proposition 19. Suppose the sampling distribution of QCSampler is the query cardinality distribution and that P has no overflowing queries. Then, the sampling distribution of DDSampler is d P .\nProof. Let p be the sampling distribution of DDSampler, and let X denote a random document selected by DDSampler. Let Q denote a random query chosen from the cardinality distribution c P .\nTo calculate p(x), we expand over all choices for Q:\np(x) = Pr p (X = x) = q\u2208P Pr p,c P (X = x|Q = q) \u2022 Pr c P (Q = q).\nNote that given Q = q, the probability that X = x is 0 if x \u2208 results(q) and is 1/ card(q) otherwise. Hence, the only terms left in the sum are ones that belong to queries We next address the unrealistic assumption that none of the queries in P overflows. Rather than using P, which is likely to have overflowing queries, we use the query pool P + (recall that P + is the set of valid queries in P). P + does not have any overflowing queries by definition.\nIn the next subsection we show an efficient implementation of QCSampler that generates samples from c P + (the cardinality distribution of P + ) rather than from c P . Since P + has no overflowing queries, then by Proposition 19, the sampling distribution of DDSampler in this case equals the degree distribution d P + induced by P + .\nRecall and bias analysis. Let us now return to the outer function of the PB sampler. That function assumed DDSampler generates samples from d P . What happens if instead it generates samples from d P + ? Note that now there is a mismatch between the trial distribution used by the PB sampler (i.e., d P + ) and the unnormalized weights it uses (i.e., deg P (x)).\nOne possible solution could be to try to compute the unnormalized weights of d P + , i.e.,d P + (x) = deg P + (x). However, this is impossible to do efficiently, because P + is no longer an admissible query pool. Instead, we opt for a different solution: we leave the outer function of the PB sampler as is; that is, the trial distribution will be d P + but the unnormalized weights will remain those of d P (i.e., deg P (x)). This means that the PB sampler is in fact an approximate rejection sampling procedure, and we can thus use Theorem 8 to bound its sampling bias.\nTheorem 21 below bounds the recall and the bias of the PB sampler. The upper bound on the bias is given in terms of a property of documents, which we call the validity density: Definition 20 (Validity density). Let P be a query pool. The validity density of a document x \u2208 D P relative to P is:\nvdensity P (x) = deg P + (x) deg P (x) .\nThat is, the validity density of x is the fraction of valid queries among the queries from P that x matches. The bias of the PB sampler is bounded by half the normalized mean deviation of the validity density of documents, where documents are weighted by the target distribution. Hence, if all documents have more-or-less the same validity density, then we can expect the PB sampler to be accurate.\nTheorem 21. The sampling recall of the PB sampler is equal to:\nrecall \u03c0 (P + ) = \u03c0(D P + ).\nThe sampling bias of the PB sampler is at most:\n1 2 ndev \u03c0 P + (vdensity P (X)),\nwhere \u03c0 P + is the restriction of \u03c0 to D P + \u2229 supp(\u03c0).\nFor the proof, see Appendix C.\nAs we later show in Table 1, the normalized mean deviation of the validity density of our test pool is relatively small (0.34), implying the bias is at most 0.17.\nAnother factor that affects the variance of the validity density is the fraction of invalid queries among the queries in the pool. If invalid queries are rare, then the validity density of most documents will be close to 1, implying the variance of the validity density is small. This is formalized by Theorem 22 below.\nTo state the theorem, we first need to define a distribution over queries, induced by the distribution \u03c0 on documents, with respect to which we measure the overflow probability. For every document x \u2208 D, we define the \"weight\" of x to be its probability under the target distribution \u03c0 P + , i.e., \u03c0 P + (x). The weight of a query is the sum of all the weights it \"absorbs\" from the documents it is connected to:\nw P (q) =\nx\u2208results(q)\n\u03c0 P + (x) deg P (x) .\nNote that each document x distributes its weight \u03c0 P + (x) among all the queries it is connected to. Thus, its contribution to one query q is only \u03c0 P + (x)/ deg P (x). It follows that the sum of all query weights equals the sum of all document weights:\nw P (P) = q\u2208P w P (q) = x\u2208D \u03c0 P + (x) = 1.\nWe can thus view w P as a probability distribution over P. We call this distribution the query weight distribution.\nTheorem 22. The sampling bias of the PB sampler is at most:\novprob(w P ) 1 \u2212 ovprob(w P )\n.\nThat is, if the overflowing queries in the pool have a relatively low mass under the query weight distribution (i.e., they are few in number and they do not overflow by \"much\"), then the bias of the sampler is low. The proof of the theorem appears in Appendix C.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_3"]}, {"heading": "Cardinality distribution sampler", "text": "We are left to show how to efficiently sample queries from P according to the cardinality distribution c P + . Sampling queries uniformly from P is easy, since we have P in explicit form. But how do we sample queries from P + proportionally to their cardinalities? This seems impossible to do, because we do not know a priori which queries belong to P + and what are the cardinalities of these queries.\nOur most crucial observation is that an unnormalized form of c P + can be computed efficiently. Given a query q \u2208 P, a corresponding unnormalized weight is the following:\nc P + (q) = card(q), if card(q) \u2264 k, 0, if card(q) > k.\nc P + (q) can be computed by submitting q to the search engine and counting the number of matches it has.\nRemark. Since we need to know card(q) exactly only when q does not overflow, then we can compute card(q) by physically counting the number of results returned by the search engine on the query q.\nWe do not need to rely on the number of results reported by the search engine, which is notoriously inaccurate.\nNow, since we know c P + in unnormalized form, we can apply rejection sampling with the uniform distribution on P as the trial distribution and with c P + as the target distribution. This will give us samples from c P + .  The query cardinality sampler (QCSampler) is depicted in Figure 8. The sampler applies rejection sampling with the cardinality distribution c P + as the target distribution and with the uniform distribution on P (which we denote by u P ) as the trial distribution. The unnormalized form used for the target distribution is\u0109 P + , as described above. The unnormalized form used for the trial distribution is: \u2200q \u2208 P,\u00fb P (q) = 1.\nSince for every q \u2208 P,\u0109 P + (q) \u2264 k, then\nmax q\u2208P\u0109 P + (q) u P (q) \u2264 k,\nand thus the sampler uses the envelope constant C = k.\nThe following now follows directly from the correctness of rejection sampling:\nProposition 23. The sampling distribution of QCSampler is c P + .", "publication_ref": [], "figure_ref": ["fig_6"], "table_ref": []}, {"heading": "Cost analysis", "text": "We now analyze the query cost and the fetch cost of the PB sampler.\nTheorem 24. The query cost of the PB sampler is at most:\nC \u2022 deg P + (D P + ) Z\u03c0 \u2022 \u03c0(D P + ) \u2022 (1 \u2212 ovprob(w P )) \u2022 |P| |P + | \u2022 k avg q\u2208P + card(q) + qcost(\u03c0) .\nThe fetch cost of the PB sampler is at most:\nC \u2022 deg P + (D P + ) Z\u03c0 \u2022 \u03c0(D P + ) \u2022 (1 \u2212 ovprob(w P )) \u2022 (1 + fcost(\u03c0)).\nThe proof can be found in Appendix C.\nThe above expressions may seem hard to parse, so we would like to simplify and interpret them, at least for the case \u03c0 is the uniform distribution on D.\nWhen \u03c0 is uniform, Z\u03c0 = |D| and \u03c0(D P + ) = |D P + |/|D|. Therefore, the term Z\u03c0 \u2022 \u03c0(D P + ) is |D P + |. Also, an envelope constant C = 1 can be used in this case. It follows that\nC \u2022 deg P + (D P + ) Z\u03c0 \u2022 \u03c0(D P + ) = deg P + (D P + ) |D P + | = avg x\u2208D P + deg P + (x).\nAlso, qcost(\u03c0) = fcost(\u03c0) = 0 in this case. Therefore, the query cost is:\navg x\u2208D P + deg P + (x) \u2022 1 1 \u2212 ovprob(w P ) \u2022 |P| |P + | \u2022 k avg q\u2208P + card(q)\n.\nThus, the query cost is the product of four components: (1) The average degree of documents that are covered by the valid queries in P;\n(2) The inverse of the \"validity probability\" of queries, when selected proportionally to their weights; (3) The ratio between the total number of queries in P and the valid queries in P; and (3) The ratio between the maximum cardinality of valid queries (i.e., k) and the average cardinality of valid queries.\nSimilarly, the fetch cost in this case is:\navg x\u2208D P + deg P + (x) \u2022 1 1 \u2212 ovprob(w P )\n.", "publication_ref": ["b2", "b2"], "figure_ref": [], "table_ref": []}, {"heading": "Choosing the query pool", "text": "We next review the parameters of the query pool that impact the PB sampler.\nPool's recall The sampler's recall equals the recall of P + -the pool of valid queries among the queries in P. Therefore, we would like pools whose valid queries cover most of the documents in the corpus D. In order to guarantee such high recall, the pool must consist of enough terms/phrases that are not too popular (and thus would not overflow), but yet almost every document in D contains at least one of them. We can obtain such a collection of terms/phrases by crawling a large corpus of web documents, such as the ODP directory.\nValidity density deviation The bias of the PB sampler is bounded by the normalized mean deviation of the validity density of documents, where documents are weighted by the target distribution. That is, in order to keep the bias low, we need to make sure that all documents have roughly similar validity densities. If the query pool has few overflowing queries and the queries that do overflow do not overflow by much, then we should expect most documents to have a validity density that is close 1, implying that the variance of the validity density is small. Obtaining such a pool whose recall is still high may be tricky. A pool consisting of disjunctions of terms, for example, may be problematic, because such queries are likely to overflow. We thus opted for exact phrase queries. Our experiments indicate that phrases of length at least 5 are unlikely to overflow. If the phrases are collected from a sufficiently large and representative corpus, then the corresponding recall is still reasonable.\nAverage degree The query and fetch costs depend on the average degree of documents that are covered by the valid queries in the pool. Hence, we would like to find pools for which the degree of documents grows moderately with the document length. Exact phrase queries are a good example, because then the degree of documents grows linearly with the document length. Conjunctions or disjunctions of m terms are poor choices, because there the growth rate is exponential in m.\nOverflow and underflow probabilities High density of overflowing queries in the pool has two negative effects: (1) it potentially increases the sampling bias of the sampler; and (2) it increases the query and fetch costs. High density of underflowing queries does not impact the sampling bias, but may increase the query cost. We therefore would like to keep the overflow and underflow probabilities as small as possible.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Average cardinality", "text": "The query cost depends also on the ratio between the maximum cardinality of valid queries (k) and the average cardinality of valid queries. We would like thus the average cardinality to be as close as possible to k. Of course, this may interfere with the overflow probability: if the average cardinality is too high, many queries will simply overflow.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Random walk based sampler", "text": "We propose two variants of a random walk sampler. One is based on the Metropolis-Hastings algorithm and another on the Maximum Degree method. Both samplers perform a random walk on a virtual graph whose nodes are the documents indexed by the search engine.\nLike the pool-based sampler, this sampler too selects its queries from a fixed admissible query pool P. However, here the pool may be implicit rather than explicit, and thus does not require a pre-processing step for constructing the query pool.\nLet \u03c0 be a target distribution on the corpus D, so that supp(\u03c0) = D (recall our simplifying assumption from Section 4.4). As with the pool-based sampler, we assume access to an oracle procedure getWeight\u03c0(x) that computes an unnormalized form\u03c0 of \u03c0. qcost(\u03c0) and fcost(\u03c0) denote, respectively, the worst-case query and fetch costs of this oracle procedure.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Document graph", "text": "The random walk sampler performs a random walk on a virtual graph G P , which we call the document graph. 4 G P is obtained from the queries-documents graph B P defined in Section 6.3. G P is an undirected weighted graph whose vertex set is D-the documents indexed by the search engine. Two documents x, y are connected by an edge in G P if and only if they share a neighboring query q in the graph B P . The edge weight is the number of such shared neighbor queries, where each query is normalized by its cardinality. In other words, (x, y) is an edge if and only if queries P (x) \u2229 queries P (y) = \u2205. The weight of the edge (x, y) is: weight P (x, y) = q\u2208queries P (x)\u2229queries P (y)", "publication_ref": ["b3"], "figure_ref": [], "table_ref": []}, {"heading": "card(q)", "text": ".\nThe degree of a document x in G P is defined as:\ndeg G P (x) = y\u2208D weight P (x, y).\nWe next observe that the degree of a document x in the graph G P coincides with its degree in the graph B P :\nProposition 25. For every document x \u2208 D, deg G P (x) = |queries P (x)| = deg P (x).\nProof. For every triple (x, y, q), where x, y \u2208 D are documents and q \u2208 P is a query, define the predicate A(x, y, q) to be 1 if and only if both x and y belong to results(q). Now, we use the predicate A to rewrite the degree of a document x: If q \u2208 queries P (x), then y\u2208D A(x, y, q) = |results(q)| = card(q). However, if q \u2208 queries P (x), then y\u2208D A(x, y, q) = 0. Hence, we have:\ndeg G P (x) =\nq\u2208P 1 card(q) y\u2208D A(x, y, q) = q\u2208queries P (x) 1 card(q)\n\u2022 card(q) = |queries P (x)| = deg P (x).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Skeleton of the random walk sampler", "text": "The random walk sampler runs a random walk on the document graph G P + (like the pool-based sampler, it ignores invalid queries). The transition matrix P of a simple random walk on this graph is the following: P (x, y) = weight P + (x, y)\ndeg P + (x) .\nThat is, having visited a node x in the graph, a neighbor y is chosen proportionally to the weight of the edge connecting x and y. It can be shown that this random walk is a reversible Markov Chain whose limit distribution is the document degree distribution d P + (recall definition from Section 7.1).\nIn order to transform this simple random walk into a Markov Chain that converges to the target distribution \u03c0, an MCMC algorithm is applied. In this paper we focus on the Metropolis-Hastings and the Maximum Degree methods.\nThe skeleton of the random walk sampler is described in Figure 9. The sampler runs a simple random walk on the graph G P + augmented with an acceptance-rejection procedure. Having visited a node X in the graph, the function sampleNeighbor selects a random neighbor Y with probability P (X, Y) =\nweight P + (X,Y) deg P + (X)\n(the implementation of this function is described below). An acceptancerejection procedure is then applied on X and Y in order to determine whether Y should be accepted as the next step of the random walk. The choice of the acceptance function depends on the particular MCMC method used. The two acceptance functions we employ are: where C \u2265 max\nx\u2208D P + deg P + (x) \u03c0(x)\nis an envelope constant.\n1:Function RWSampler(SE, B, x 0 ) 2: X := x 0 3: for t = 1 to B do 4: Y := sampleNeighbor(SE, X) 5: if (accept(X,Y)) 6: X := Y 7: return X 1:Function accept(x, y) 2: compute r mcmc (x, y) 3: toss a coin whose heads probability is r mcmc (x, y) 4: return true if and only if coin comes up heads Figure 9: Skeleton of the random walk sampler.\nIn order to implement the random walk sampler, we need to address four issues: (1) how to select the start node x 0 ? (2) how to set the length of the burn-in period B? (3) how to implement the neighbor sampling procedure? and (4) how to calculate the acceptance functions r mh and r md ?", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Selecting the start node", "text": "The graph G P + is not necessarily connected. When we choose the start node x 0 from some connected component F of G P + , then the random walk will never reach nodes outside F . This implies that the Markov Chain we produce will not necessarily converge to the target distribution \u03c0, but rather to the distribution \u03c0 F obtained by restricting \u03c0 to F :\n\u03c0 F (x) = \u03c0(x) \u03c0(F ) , for all x \u2208 F .\nTherefore, the recall of the sampler in this case will be at most \u03c0(F ). In order to maximize recall, we would like the start node to belong to the component that has the highest mass under \u03c0. We do not have any rigorous technique for making such a selection. On the other hand, we speculate that for sufficiently rich query pools, G P + is expected to have a giant connected component, and thus almost any document chosen as a start node will do. Our experimental results (see Section 9.3) support this speculation, as the largest connected component of G P + in a small search engine that we built constituted close to 99% of the nodes.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Setting the burn-in period", "text": "As shown in Section 4.4.3, the main factor that determines the length of the burn-in period is the spectral gap of the underlying transition matrix. Thus, in order to set B, we need an estimate of the spectral gaps of the transition matrices P mh and P md obtained by applying the MH and the MD methods, respectively, on the simple random walk on G P + .\nWe experimentally estimated these gaps for a small search engine that we built. The results, discussed more thoroughly in Section 9.3, provide the following estimates:\n\u03b1(P md ) \u2265 1 20, 000 , \u03b1(P mh ) \u2265 1 20, 000\n.\nAs the connectivity of G P + in larger search engines is expected to be similar to the connectivity of G P + in the small search engine, we expect similar bounds to be applicable also to random walks on real search engines. See more details in Section 9.3.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Sampling neighbors", "text": "We now address the problem of sampling neighbors according to the transition matrix P (x, y).\nThe naive method to select such a random neighbor would be the following: given a document x, find all valid queries q \u2208 queries P + (x) that match x, choose one of them at random, submit the query to the search engine, and then pick one of its results at random. The only problem with this algorithm is that we do not know how to compute the set queries P + (x) efficiently, since P + is not an admissible query pool.\nThe solution to the above problem emanates from the following observation: queries P + (x) is a subset of queries P (x), which we can compute efficiently, since P is an admissible query pool. So we can simply select random queries from queries P (x) until hitting a valid query. This random valid query will be uniform in queries P + (x). The neighbor sampling procedure, described in Figure 10, implements this idea. The following proposition proves the correctness of the neighbor sampling procedure: Proposition 26. Let x be any document in D P + and let Y be the random neighbor selected by the procedure sampleNeighbor, when given x as input. Then, for every neighbor y of x in the graph\nG P + , Pr(Y = y) = weight P + (x, y) deg P + (x) .\nProof. To calculate Pr(Y = y), we expand over all possibilities for the random query Q chosen from queries P + (x). Obviously, Pr(Q = q) = 0 for all q / \u2208 queries P + (x).\nPr(Y = y) =\nq\u2208queries P + (x)\nPr(Y = y|Q = q) \u2022 Pr(Q = q).\nFor fixed q and y, Pr(Y = y|Q = q) = 1 card(q) , if q \u2208 queries P + (y), and Pr(Y = y|Q = q) = 0, otherwise. Pr(Q = q) = x) . Therefore,\n1\n|queries P + (x)| = 1 deg P + (\nq\u2208queries P + (x) Pr(Y = y|Q = q) \u2022 Pr(Q = q) = q\u2208queries P + (x)\u2229queries P + (y) 1 card(q) \u2022 1 deg P + (x) = weight P + (x, y) deg P + (x) .", "publication_ref": [], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Calculating the acceptance functions", "text": "Next, we address the issue of how to calculate the acceptance functions of the MH and the MD samplers.\nThe acceptance function of the MH algorithm is:\nr mh (x, y) = min \u03c0(y) deg P + (x) \u03c0(x) deg P + (y) , 1 .\nThe acceptance function of the MD method is:\nr md (x) = deg P + (x) C\u03c0(x)\n, where C \u2265 max\nx\u2208D P + deg P + (x) \u03c0(x) .\nThe problem is that we cannot compute the degrees deg P + (x) and deg P + (y) efficiently, since P + is not an admissible query pool. What we do instead is apply perturbed acceptance functions:\nr \u2032 mh (x, y) = min \u03c0(y) deg P (x) \u03c0(x) deg P (y) , 1 and r \u2032 md (x) = deg P (x) C \u2032\u03c0 (x)\n, where C \u2032 \u2265 max\nx\u2208D P + deg P (x) \u03c0(x) .\n(Note that when \u03c0 is the uniform distribution, C \u2032 should be an upper limit on the maximum degree of documents.) r \u2032 mh (x, y) and r \u2032 md (x) can be computed efficiently, because P is an admissible query pool. The problem is that now the acceptance functions and the base Markov Chain P on which they are applied are mismatching, and thus the limit distributions are no longer guaranteed to equal the target distribution \u03c0. This scenario is the one captured by the approximate Metropolis-Hastings and the approximate Maximum Degree procedures, described in Section 5.\nBefore we analyze the sampling bias and sampling recall of the resulting samplers, let us identify the exact form of the target distribution, trial distribution, and approximate trial distribution employed by the approximate MH and MD procedures.\nLet F be the connected component of G P + to which the start vertex x 0 of the random walk belongs. Let d F be the restriction of the degree distribution d P + to F :\nd F (x) = d P + (x) d P + (F ) , for all x \u2208 F .(1)\nAs the random walk can never reach nodes outside F , then d F , rather than d P + , is the limit distribution of the simple random walk on G P + that starts at x 0 \u2208 F . Therefore, the trial distribution is d F .\nSimilarly, as the random walk can never reach nodes outside F , the real target distribution when applying the MH and the MD samplers with x 0 \u2208 F is the restriction of \u03c0 to F , i.e., \u03c0 F . Indeed, it can be easily verified that the restriction of the unnormalized form of \u03c0 to F constitutes an unnormalized form of \u03c0 F .\nFinally, the approximate trial distribution used by the two procedures is the restriction of the degree distribution d P to F :\nq F (x) = d P (x) d P (F )\n, for all x \u2208 F .\nSince supp(\u03c0) = D, supp(d P + ) = D P + , supp(d P ) = D P , and F \u2286 D P + \u2286 D P \u2286 D, then supp(\u03c0 F ) = supp(d F ) = supp(q F ) = F . Therefore, \u03c0 F , d F , q F satisfy the requirements of the approximate MH and MD procedures. Furthermore, the simple random walk on F constitutes a reversible Markov Chain, as G P + is an undirected graph. Therefore, the necessary pre-condition of the approximate MH procedure is met.\nApplying Theorems 13 and 12, we know that the random walks performed by the approximate MH and MD procedures have the following limit distribution \u03b7:\n\u03b7(x) = \u03c0 F (x) d F (x) q F (x) E \u03c0 F d F (X) q F (X)\n.\n(\n)2\nThe following theorem bounds the sampling bias and the sampling recall of the MH and MD samplers:\nTheorem 27. Let \u03b5 > 0. Suppose we run the MH sampler (resp., the MD sampler) with a burnin period B that guarantees the approximate MH Markov Chain (resp., approximate MD Markov Chain) reaches a distribution, which is at distance of at most \u03b5 from the limit distribution. Then, the sampling bias of the MH sampler (resp., MD sampler) is at most:\n1 2 ndev \u03c0 F (vdensity P (X)) + \u03b5.\nThe sampling recall of the MH sampler (resp., MD sampler) is at least:\n\u03c0(F ) \u2022 (1 \u2212 1 2 ndev \u03c0 F (vdensity P (X)) \u2212 \u03b5).\nThe proof appears in Appendix D.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Optimized MD sampler", "text": "As discussed in Section 4.4.2, the special form of the acceptance function of the MD sampler allows for an optimized implementation. Since the acceptance function depends only on the current state x and not on the proposed state y, then rather than selecting a new proposed neighbor Y every time the acceptance-rejection procedure is invoked, we can select the neighbor only once, after acceptance is achieved. Further optimization is possible by selecting a priori the number of steps the random walk is going to spend at the state x, without actually performing the iterative coin tosses.\nIn this spirit, we describe in Figure 11 an optimized version of the MD sampler. Note that the fact the proposed neighbor is chosen only once results in significant savings in the number of search engine queries made. We analyze these savings below.\n1: Function OptimizedMDSampler(SE, B, x 0 , C \u2032 ) 2: X := x 0 3: t = 0 4: while (t < B) do 5: delay := generate a geometric random variable whose success parameter is:\ndeg P (x) C \u2032\u03c0 (x)\n6: t := t + delay 7:\nif (t \u2265 B) break 8:\nY := sampleNeighbor(SE,X) 9:\nX := Y 10:\nt := t + 1 11: return X ", "publication_ref": [], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Cost analysis for the MH and MD samplers", "text": "We now analyze the query and the fetch costs of the MH and MD samplers. We first analyze the query cost incurred by the random walk when it visits a particular node x: Proposition 28. The expected number of queries the (MH or MD) random walk sampler submits to the search engine when visiting a node x is at most 1 vdensity P (x) + qcost(\u03c0).\nProof. Search engine queries are made in two places: (1) in the sampleNeighbor procedure; and (2) (possibly) in the getWeight\u03c0 procedure in order to compute the unnormalized target weights.\nWhen sampleNeighbor is called with a document x as input, the procedure repeatedly selects random queries from queries P (x) until hitting a valid query. Therefore, the expected number of queries made in such a call is:\n|queries P (x)| |queries P + (x)| = deg P (x) deg P + (x) = 1 vdensity P (x)\n.\nThe procedure getWeight\u03c0 is called once for every candidate neighbor y. Each invocation of the procedure makes at most qcost(\u03c0) search engine queries.\nWe conclude that the expected query cost of the step is at most:\n1 vdensity P (x) + qcost(\u03c0).\nThe actual cost of the random walk at a certain step depends on the distribution of the random node X that is visited at this step. This cost may vary greatly between the early stages of the walk, where the distribution of visited nodes depends on the walk's starting point, and the later stages of the walk, where the distribution of visited nodes is close to the limit distribution. Note that the former cost is tricky to bound, because the distribution of the starting node may be arbitrary. We therefore present two bounds: (1) A bound on the worst-case cost of a step, which applies to all steps, regardless of the distribution of visited nodes; this bound is applicable in particular to the early steps of the random walk. (2) A bound on the expected cost of a step, assuming the distribution of visited nodes is close to the limit distribution; this bound is applicable mainly to the later stages of the random walk. We start with the worst-case bound:\nProposition 29. For any step of the random walk, the expected number of queries the (MH or MD) sampler submits to the search engine is at most\nmax x\u2208F deg P (x) + qcost(\u03c0).\nProof. By Proposition 28, the expected number of queries submitted to the search engine is at most:\nmax x\u2208supp(\u03b7t) 1 vdensity P (x) + qcost(\u03c0) \u2264 max x\u2208F deg P (x) deg P + (x) +qcost(\u03c0) \u2264 max x\u2208F deg P (x)+qcost(\u03c0).\nAt the later stages of the walk, where the distribution of X is known to be close to the limit distribution, we can achieve a much better bound:\nTheorem 30. For any t \u2265 0, the expected query cost of the t-th step of the random walk sampler (whether MH or MD) is at most:\n1 E \u03c0 F (vdensity P (X)) + 3\u03b5 t |F | \u2022 E u F 1 vdensity 2 P (X) + qcost(\u03c0).\nHere, \u03b5 t is an upper bound on the total variation distance between the distribution of the node visited at the t-th step and the limit distribution \u03b7 of the random walk. u F is the uniform distribution over F .\nThe proof appears in Appendix D. Using the spectral gap bound on the convergence rate of random walks (see the proof of Corollary 7), \u03b5 t can be chosen as:\n\u03b5 t = (1 \u2212 \u03b1) t \u03b7 min ,\nwhere \u03b1 is the spectral gap of the random walk's transition matrix and \u03b7 min = min x\u2208F \u03b7(x).\nThe above theorem therefore implies that for\nt \u2265 \u2126 log 1 \u03b7 min + log |F | + log E u F 1 vdensity 2 (X)\n, the query cost of the t-th step is about 1/ E \u03c0 F (vdensity P (X)). In case \u03c0 F equals the uniform distribution u F , qcost(\u03c0) = 0, and thus the query cost becomes roughly 1/ E u F (vdensity P (X)).\nThe fetch cost of the random walk sampler does not depend on the distribution of visited nodes and is quantified in the following theorem.\nTheorem 31. For any t \u2265 0, the expected fetch cost of the t-th step of the random walk sampler (whether MH or MD) is at most: 1 + fcost(\u03c0).\nProof. Page fetches are made only in the sampleNeighbor procedure and in the getWeight\u03c0 procedure. In sampleNeighbor(x) only x is fetched, in order to compute queries P (x). In getWeight\u03c0(x), at most fcost(\u03c0) pages are fetched in order to compute\u03c0(x). So the fetch cost is at most:\n1 + fcost(\u03c0).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Cost analysis for the optimized MD sampler", "text": "An optimized MD random walk can be viewed as performing a simple random walk on F and augmenting it with different \"delays\" at the different nodes visited along the walk. We call the steps of the simple random walk real steps, and the steps performed during the delay free steps.\nAs free steps incur zero query and fetch costs, the amortized query and the fetch costs of a real step are reduced by a multiplicative factor of 1 + delay compared to the unoptimized MD sampler (where all steps are real). Thus, in order to obtain upper bounds on the amortized costs of real steps of the optimized MD sampler, it will suffice to lower bound the delays associated with these steps.\nThe following proposition analyzes the expected delay when the simple random walk visits a node x.\nProposition 32. The expected delay of the optimized MD sampler when visiting a node x is\nC \u2032\u03c0 (x) deg P (x) .\nProof. According to Figure 11, when visiting a node x, the delay is a geometric random variable whose success probability is\ndeg P (x) C \u2032\u03c0 (x) .\nFor example, when \u03c0 is the uniform distribution, then\u03c0(x) = 1 and C \u2032 is an upper limit on the maximum degree. Therefore, the expected delay is the ratio between the maximum degree and the degree of x.\nLet X be a random node visited at the t-th real step of the optimized MD random walk. It follows from the above proposition that the expected delay at this step is C \u2032\u03c0 (X) deg P (X) . In order to lower bound the expectation of this delay, we need to analyze the distribution of X. When t is small, this distribution can be quite arbitrary, and therefore it is difficult to bound the corresponding expected delay. We note, however, that the delay is always non-negative, and therefore t real steps of the optimized MD sampler correspond to at least t steps of the unoptimized MD sampler. Since the upper bound on the expected query cost of the unoptimized MD sampler is monotonically non-increasing with t (see the previous subsection), we conclude that for any t, the upper bound on the expected query cost of the t-th step of the unoptimized MD random walk is applicable also to the optimized case.\nSimilarly to the unoptimized case, at the later stages of the walk, when the distribution of X is close to the limit distribution, we can achieve a much better bound.\nTheorem 33. For any t \u2265 0, the expected delay of the t-th real step of the optimized MD random walk is at least:\nC \u2032 \u2022 Z\u03c0 F \u2022 \u03c0(F ) \u2022 E \u03c0 F (vdensity P (X)) deg P + (F ) \u2212 3\u03b5 t \u2022 E u F \u03c0 2 F (X) deg 2 P (X) .\nHere, \u03b5 t is an upper bound on the total variation distance between the distribution of the node visited at the t-th real step and the degree distribution d F . u F is the uniform distribution over F .\nThe proof appears in Appendix D.\nThe real steps of the optimized MD random walk induce a simple random walk (i.e., without acceptance-rejection) on F . As we saw before, the limit distribution of this random walk is the degree distribution d F . Hence, \u03b5 t is a bound on the distance between the t-th step of the simple random walk and the limit distribution of this walk.\nUsing the spectral gap bound on the convergence rate of random walks (see the proof of Corollary 7), \u03b5 t can be chosen as:\n\u03b5 t = (1 \u2212 \u03b1) t d F min ,\nwhere \u03b1 is the spectral gap of the simple random walk's transition matrix and\nd F min = min x\u2208F d F (x).\nThe above theorem therefore implies that for\nt \u2265 \u2126 log 1 d F min + log |F | + log E u F \u03c0 2 F (X) deg 2 P (X)\n, the expected delay of the t-th real step is about\nC \u2032 \u2022 Z\u03c0 F \u2022 \u03c0(F ) \u2022 E \u03c0 F (vdensity P (X))/ deg P + (F ).\nWhen \u03c0 is the uniform distribution and assuming \u03c0(F ) = 1, this expression can be further simplified. In this case, (1) C \u2032 is an upper limit on the maximum degree max x\u2208F deg P (x); (2) Z\u03c0 F = |F |; and (3) qcost(\u03c0) = 0. For t large enough, the costs are reduced by a multiplicative factor of:\n1 + max x\u2208F deg P (x)|F | deg P + (F ) E u F (vdensity P (X)) = 1 + max x\u2208F deg P (x) avg x\u2208F deg P (x)\n\u2022 E u F (vdensity P (X)).", "publication_ref": [], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Choosing the query pool", "text": "We next review the parameters of the implicit query pool that impact the random walk based sampler.\nPool's recall The considerations here are similar to the ones for the PB sampler (see Section 7.5).\nThe main difference is that there is no need to crawl a large corpus in order to achieve satisfactory recall.\nValidity density Validity density has a direct effect on the query cost of the random walk sampler. The lower is the expected validity density (under the target distribution), the higher is the query cost of the sampler, as it needs to submit more queries before encountering a valid one. Therefore, we would like to find pools having as little invalid queries as possible.\nValidity density deviation Similarly to the PB sampler (see Section 7.5), the recall and the bias of the random walk sampler is bounded by the normalized mean deviation of the validity density of documents, where documents are weighted by the target distribution.\nAverage degree Similarly to the PB sampler (see Section 7.5), the query and the fetch costs of the optimized MD sampler depend on the average degree of documents in F .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Maximum document degree", "text": "The query cost of the optimized MD sampler depends also on the ratio between the maximum document degree and the average document degree. We would like thus to limit maximum document degree as much as possible. A possible way to achieve this is to set a threshold on the number of queries we extract from a document. Of course, this may interfere with the desire to increase the pool's recall: if we set the threshold too low, the recall may decrease significantly.\nThe burn-in period The query and the fetch costs of the random walk sampler are directly proportional to the random walk's burn-in period. The burn-in period depends on the structure of the graph induced by the query pool. Although we did not analyze the dependence of the burn-in period on the query pool, the following intuition applies. In each step of the random walk, we want to move to a document, which is as unrelated to the current document as possible. This will ensure that we need only a few steps to obtain a sufficiently random document. If we choose the query pool to be \"too specific\" (e.g., a pool of long exact phrases), we are likely to spend many consecutive steps in small subsets of related documents, and thus increase the required burn-in period. Conversely, a query pool consisting mainly of single terms is likely to result in a shorter burn-in period, as two documents sharing a single term are not necessarily related to each other. On the other hand, single-term queries are more likely to overflow, thus reducing the validity density, which in turn incurs elevated costs as discussed above.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Experimental results", "text": "We ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Experimental setup", "text": "In order to conduct the first three sets of experiments, we built a home-made search engine over a corpus of 2.4 million documents obtained from the Open Directory Project (ODP) [16]. The ODP directory crawl consisted of 3 million pages, of which we kept only the ones that we could successfully fetch and parse, that were in text, HTML, or pdf format, and that were written in English. Each page was given a serial id, stored locally, and indexed by single terms and phrases.\nOnly the first 10, 000 terms in each page were considered. We used static ranking by document id to rank query results. Different experiments used different values of the result limit k. See more details below.\nThe first three sets of experiments were performed on a dual Intel Xeon 2.8GHz processor workstation with 2GB RAM and two 160GB disks.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Pool measurements", "text": "In the first set of experiments, we wanted to measure the pool parameters that impact the quality and the efficiency of our samplers. In order to get a variety of results, we measured four different query pools: a single terms pool and three pools of exact phrases of lengths 3, 5, and 7. (We measured only four pools, because each measurement required substantial disk space and running time.)\nIn order to construct the pools, we extracted all the terms or the n-grams (with overlaps) of the corresponding length from the ODP documents. n-grams were not allowed to cross boundaries, such as paragraph boundaries. We split the ODP data set into two parts: a training set, consisting of every fifth page (when ordered by id), and a test set, consisting of the rest of the pages. The pools were built only from the training data, but the measurements were done only on the test data. In order to determine whether a query is overflowing, we set a result limit of k = 20.\nAll our measurements were made w.r.t. the uniform target distribution. We measured the following parameters: (1) the pool's size (total number of queries); (2) the fraction of overflowing queries;\n(3) the fraction of underflowing queries; (4) the average cardinality of valid queries;\n(5) the recall of valid queries (i.e., |D P + |/|D|); (6) the average degree of documents relative to valid queries (i.e., avg x\u2208D P + deg P + (x)); ( 7) the average degree of documents relative to all queries (i.e., avg x\u2208D P + deg P (x)); ( 8) the normalized mean deviation of the validity density (i.e., ndev \u03c0 P + (vdensity P (X))); ( 9) the overflow probability of the query weight distribution (i.e., ovprob(w P )). The results of our measurements are tabulated in Table 1.  The measurements show that fraction of overflowing queries, average document degree, normalized mean deviation of validity density, and overflow probability improve as phrase length increases, while fraction of underflowing queries, recall, and average cardinality get worse. The results indicate that a phrase length of 5 achieves the best tradeoff among the parameters. It has very few overflowing queries (about 0.5%), while maintaining a recall of about 89%. The overflow probability of the query weight distribution on 3-term phrases is too high (70%), while the recall of the 7-term phrases is way too low (about 64%). The fraction of overflowing queries among single terms is surprisingly small. The explanation is that many of the terms are misspellings, technical terms, or digit strings. The overflow probability of single terms, though, is very high.\nSince the ODP data set is presumably representative of the web, we expect most of these mea-surements to represent the situation on real search engines. The only exceptions are the fraction of overflowing and underflowing queries and the average cardinality of valid queries, which are distorted due to the small size of the ODP data set. We thus measured these parameters on the Yahoo! search engine. In this experiment we used real Yahoo!'s result limit k = 1, 000. The results are given in Table 2. It is encouraging to see that for 5-term phrases, the fraction of overflowing queries remains relatively low, while the fraction of underflowing queries goes down dramatically. The elevated fraction of overflowing queries among 3-term phrases is more evident here.  Assuming the above measurements represent the situation on real search engines, we can use Theorems 21 and 24 to derive estimates of the sampling bias, sampling recall, query cost, and fetch cost for the pool-based sampler. The results are given in Table 3. In the estimations we used the measurements on the Yahoo! search engine, and thus set k = 1, 000.\nParameter Single Phrases Phrases Phrases terms (  ", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_3", "tab_5", "tab_7"]}, {"heading": "Spectral gap estimations", "text": "We wanted to estimate the burn-in periods of the two random walk samplers: the MH sampler and the MD sampler. By Corollary 7, the main factor that determines the burn-in period is the spectral gap of the random walk's transition matrix. In order to obtain an accurate estimate of the spectral gaps w.r.t. a real search engine SE, we would have had to construct the adjacency matrix of the document graph G P + corresponding to SE, transform this matrix into the two transition matrices P mh and P md , and then estimate the spectral gaps of these matrices. 5 However, since we did not have full access to the corpus of real search engines, we could not explicitly construct the matrices P mh and P md .\nOur only option then was to estimate the spectral gaps of the matrices corresponding to our home-made ODP search engine. Since the ODP corpus is a diverse set of documents, presumably representing the whole web, we expect the document graph of the ODP search engine to have similar connectivity properties as the document graph of real search engines. Spectral gap is a \"structural\"\nproperty of a transition matrix, which depends only on the connectivity in the document graph, and not on the size of the graph. Therefore, estimations of the spectral gaps corresponding to the ODP search engine could be representative of the spectral gaps corresponding to real search engines.\nIn order to make the connectivity of the document graph of the ODP search engine as similar as possible to the connectivity of the document graphs in larger search engines, we set in this experiment k = 80 as the result limit and used a pool of 3-term exact phrases. These settings made the graph more dense, similarly to document graphs that are based on very large corpora.\nWe constructed the two matrices P mh and P md corresponding to the largest connected component of the document graph. This component contained 98.7% of the documents in the corpus, resulting in two matrices of dimensions 2.37 million by 2.37 million.\nSince the matrices were so large, we could not compute their eigenvalues exactly. The largest eigenvalue of any transition matrix is always 1, since the matrix is stochastic. We thus had to estimate only the second largest eigenvalue. To this end, we applied the power iteration method (cf. [19]). We obtained the following lower bounds on the two spectral gaps:\n\u03b1(P md ) \u2265 1 20, 000 , \u03b1(P mh ) \u2265 1 20, 000\n.\nWe note that the actual gaps could be larger, yet figuring them out exactly would have required many more iterations of the power method. The fact the two bounds are identical does not mean that the actual spectral gaps of the two Markov Chains are identical. In reality, one of them may be much higher than the other.\nPlugging in the above estimates in the formula for the burn-in period (Corollary 7) and assuming \u03c0 min = 1 2\u202210 10 , as in major search engines, and \u03b5 = 0.1, we obtained:\nT \u03b5 (P mh ) = T \u03b5 (P md ) \u2264 1 \u03b1(T ) ln 1 \u03c0 min + ln 1 \u03b5 \u2248 520, 000.\nWe can now use the cost analysis from Section 8.8 to estimate the query costs of the MH and the MD samplers. To this end, we: (1) assume that G P + is connected (and thus F = D P + ); (2) employ the estimates for E \u03c0 P + (vdensity P (X)) = 1 \u2212 ovprob(w P ) and for avg x\u2208D P + deg P (x) derived from our pool measurements. Plugging in the numbers into the formulae given in Section 8.8, we expect the query cost of the MH sampler to be roughly 1, 730, 300 queries per sample, while the query cost of the optimized MD sampler (executed with C \u2032 = 10, 000) to be roughly 42, 800 queries per sample.\nWe conclude that both the MH sampler and the MD sampler are significantly less efficient than the pool-based sampler. The cost of the MH sampler is prohibitive. The cost of the optimized MD sampler is much lower, and thus this sampler might be of practical use, if the desired number of samples is small. Recall the big advantage of this approach over the pool-based sampler: it does not need any pre-processing step to create an explicit query pool.\nWe stress that the above cost estimates are based on our theoretical analysis, which is pessimistic by nature. Our evaluation experiments described below indicate that in practice it may be possible to run the random walks for far fewer steps than is required by the theoretical bounds, yet obtain good samples.", "publication_ref": ["b4", "b17"], "figure_ref": [], "table_ref": []}, {"heading": "Evaluation experiments", "text": "In order to estimate the biases of our samplers and of the Bharat-Broder (BB) sampler, we ran them on the ODP search engine. In this controlled environment we could compare the sampling results against the real data.\nThe corpus of our ODP search engine consisted of the test set only. A result limit of k = 5 was used in order to have an overflow probability comparable to the one on Yahoo!.\nWe ran five samplers: (1) the PB sampler with rejection sampling; (2) the PB sampler with importance sampling; (3) the MH sampler; (4) the MD sampler; and (5) the BB sampler. All the samplers used a query pool of 5-term phrases extracted from the ODP training set. In order to have a common basis, we allowed each sampler to submit exactly 5 million queries to the search engine.\nRunning the random walk samplers with the burn-in period dictated by the spectral gap estimations would have been useless, since we would have gotten very few samples from the 5 million queries submitted. We therefore opted for a short burn-in period of 1,000 steps for the MH sampler and 10, 000 steps for the MD sampler (these settings turned out to produce a comparable number of samples to what the PB sampler produced). This enabled us to evaluate whether the shortened burn-in period actually caused the random walk samplers to produce biased samples.\nSince each sampler has a different query cost, the samplers produced varying number of samples using the 5 million queries. Table 4 shows the actual number of samples generated by each sampler. The BB sampler generated the most samples, yet these samples are highly biased.  In Figure 12, we show the distribution of samples by document size. We ordered the documents in the corpus by size, from largest to smallest, and split them into 10 equally sized deciles. Truly uniform samples should distribute evenly among the deciles. The results show the overwhelming difference between our samplers and the BB sampler. The BB sampler generated a huge number of samples at the top decile (more than 50%!). Our samplers, on the other hand, had no or little bias. The two PB samplers essentially show no bias, while the RW samplers have small negative bias towards very short documents, possibly due to the shortened burn-in period.\nFigure 13 addresses bias towards highly ranked documents. We ordered the documents in the corpus by their static rank, from highest to lowest, and split into 10 equally sized deciles. The first decile corresponds to the most highly ranked documents. The results indicate that none of our samplers had any significant bias under the ranking criterion. Surprisingly, the BB sampler had bias towards the 4th, 5th, and 6th deciles. When digging into the data, we found that documents  whose rank (i.e., id) belonged to these deciles had a higher average size than documents with lower or higher rank. Thus, the bias we see here is in fact an artifact of the bias towards long documents. A good explanation is that our 5-term exact phrases pool had a low overflow probability in the first place, so very few queries overflowed. Note that the ranking bias of the BB sampler is created only by overflowing queries.\nWe have several conclusions from the above experiments: (1) the 5-term phrases pool, which has small overflow probability, made an across-the-board improvement to all the samplers (including BB). This was evidenced by the lack of bias towards highly ranked documents. (2) The BB sampler suffers from a severe bias towards long documents, regardless of the query pool used. (3) Our poolbased samplers seem to give the best results, showing no bias in any of the experiments. (4) The random walk samplers have small negative bias towards short documents. Possibly by increasing the burn-in period of the random walk, this negative bias could be alleviated.", "publication_ref": [], "figure_ref": ["fig_0", "fig_0"], "table_ref": ["tab_9"]}, {"heading": "Exploration experiments", "text": "We used our most successful sampler, the PB sampler, to generate uniform samples from three major search engines: Google, MSN Search, and Yahoo!.\nDuring the experiments, conducted over a span of three weeks in April-May 2006, we submitted 395,000 queries to Google, 448,000 queries to MSN Search, and 370,000 queries to Yahoo!. Due to legal restrictions on automatic queries, we used the Google, MSN, and Yahoo! Web Search APIs. While automatic queries via APIs are, reportedly, served from slightly different corpora than the corpora used to serve human users, McCown et al. [35] showed that the differences are quite minor. These APIs are limited to submitting only a few thousands of queries a day, which limited the Deciles of documents ordered by rank Prcent of documents from sample . Before describing the results of the experiment, we elaborate on the assumptions made in these experiments and on the procedure we used to test whether a given URL is indexed by a given search engine.", "publication_ref": ["b33"], "figure_ref": [], "table_ref": []}, {"heading": "PB + Rejection Sampling PB + Importance Sampling RW-MH RW-MD BB", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Setup", "text": "The limit k on the number of returned results was, at the time of the experiment, 1,000 for Google and Yahoo!, and 250 for MSN Search. As a query pool, we used 5-term phrases extracted from English pages of the ODP data set. The pool contained 666,641,510 phrases (we used the whole ODP corpus, not just the training set).\nWe discarded all the results that were not in text, HTML, or pdf format. When calculating the cardinality of a query, we did not rely on the number of results reported by the search engine, since this number is notoriously inaccurate. Instead, we explicitly fetched the entire list of available results, and calculated its size.\nWhen submitting queries to the search engines, we specifically indicated not to filter out duplicate results and not to perform any other filtering (host, language, domain, date, etc. . . ). Note that duplicate results are filtered out by default, and thus our measurements do not directly reflect duplicate-free corpora but rather the complete \"raw\" corpora 6 . We choose to make our measurements against the raw corpora in order to prevent different filtering mechanisms employed by search engines from biasing our measurements. Comparing duplicate-free corpora proves even more difficult because each search engine may choose a different \"representative\" from a set of duplicate pages, thus defeating our URL membership test. Obviously, the raw corpus size should not be used as the only metric of search engine quality. Moreover, it may favor a less sophisticated search engine indexing more duplicate and near-duplicate documents. Some documents are indexed by terms that do not appear in their content, e.g., according to anchor text. Since our samplers have access only to the terms that appear in the document, we rejected samples whose content did not contain the query terms. Similarly, to avoid bias due to index depth, we rejected sampled documents for which the query terms were not found among their first 10, 000 terms.\nIn order to compute queries P (x), for a given document x, we first tried to retrieve the cached version of x from the search engine. If the cached page was not available, we downloaded the page from the web and computed queries P (x) according to the downloaded version. When any error was encountered while downloading the page, the corresponding sample was dropped.\nNote that as a result of dropping some of the samples (either due to fetching errors or due to the absence of the query terms at the first 10, 000 terms of the document), the query cardinalities, which were calculated assuming all query results are valid, were not always accurate. Since the frequency of sample drops was low, we speculate that this did not have any significant effect on our measurements.", "publication_ref": ["b5"], "figure_ref": [], "table_ref": []}, {"heading": "URL membership testing", "text": "A basic ingredient in our exploration experiments was a procedure, which given a URL u and search engine SE, determines whether SE indexes u or not. Implementing such a procedure that produces accurate results, while interacting only with the public interface of the search engine, turns out to be tricky. The procedure we employed, which combines ideas from previous studies, is described below.\nFirst, we brought the given URL into a canonical form, by converting hex-encoded characters (%XX) to a standard iso-8859-1 characters, converting double slash (//) to a single one, dropping /index.html from the URL's tail, etc.\nFor each URL tested, we submitted up to seven different queries to the search engine, in order to determine whether the URL is indexed by the search engine. The first query was the URL itself. The second query was \"inurl:URL\". The last five queries were phrases, from 8 to 14 terms long, extracted randomly from the first 10, 000 terms of the document. We sequentially submitted these seven queries to the search engine until we found the URL among the first 100 results (after canonization). If the URL was found by any of the queries, we assumed it is indexed by the search engine. Otherwise, it was assumed not to be indexed.\nObviously, this heuristic procedure is prone to some error. That is, its result is not guaranteed to correctly determine whether a URL is indexed or not.\nIf a URL was sampled from a search engine, but our procedure failed to find it in the same search engine, we dropped the sample. 5% of samples from Google, and less than 1% of samples from MSN Search and Yahoo! were dropped.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Corpus size", "text": "We used importance sampling to estimate the overlaps among Google, MSN Search, and Yahoo!. Table 5 tabulates the measured relative overlap of the Google, MSN Search, and Yahoo! corpora. We note that since our query pool consisted mostly of English language phrases, our results refer mainly to the English portions of these corpora.  Using Liu's \"rule of thumb\" (see Section 4.3) and the Chernoff bound, we estimate the overlap results stated above to be within an absolute error of 4.5% from the real values with a confidence level of 95%. There could be an additional absolute error of up to 17%, due to the sampling bias of the PB sampler.\nIn Figure 14  ). Note that due to the division, the error in these results can be higher than in the overlap estimates.", "publication_ref": [], "figure_ref": ["fig_0"], "table_ref": ["tab_11"]}, {"heading": "Top-level domain name distribution", "text": "Figure 15 shows the domain name distributions in the three corpora. Here too, the results are within an absolute error of 4.5% from the real values with a confidence level of 95%. Note that the differences between the search engines are quite minor.  ", "publication_ref": [], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Corpus freshness", "text": "We evaluated the freshness of the three corpora. First, we checked the percentage of pages indexed that are still valid. Figure 16 shows the percentage of dead pages (ones returning a 4xx HTTP return code) in the three corpora (within an absolute error in each point of 4.5% from the real values with a confidence level of 95%). Note that the Google corpus contains significantly more dead pages than Yahoo! and MSN Search.\n0.0% 0.5% 1.0% 1.5% 2.0% 2.5% Google MSN Search Yahoo!\nPercent of dead pages Next, we tried to determine to what degree each of the three corpora reflects the current content of indexed web pages. To this end, we assumed that when the cached copy of the document is up-to-date, the index is up-to-date too and vice versa. We compared the two versions of the sampled document: (1) the cached document, and (2) the actual document fetched from the web. These measurements were performed on samples of HTML documents only, for which we were able to fetch both the cached copy and the document itself. Fetching of both document versions was performed simultaneously.\nFigure 17 shows, for each value 0 \u2264 p \u2264 100, the fraction of samples, for which at most p percent of the lines in the cached version are different from the web version. The Yahoo! results look rather bad especially for low p values. After looking at the data, we found that some of the cached documents stored by Yahoo! were slightly pre-processed.\nTo provide a more objective measure of freshness, we measured text-only difference, which would ignore all formatting or other non-essential differences between the two document versions. We compared the bag-of-words representations of the two versions of each sample document. Figure 18 shows, for each value 0 \u2264 p \u2264 100, the fraction of samples, for which at most p percent of the words in the cached version are different from the web version.\nWe can see that about 55% -60% of the documents are \"fresh\" in all three search engines, while Google's freshness is the lowest and MSN's is the highest.  ", "publication_ref": [], "figure_ref": ["fig_0", "fig_0", "fig_0"], "table_ref": []}, {"heading": "Percentage of dynamic pages", "text": "In this experiment we calculated the percentage of dynamic pages in the three corpora. We deem a page \"dynamic\" if its URL contains the characters \"?\" or \"&\" or if the URL ends with one of the following filename extensions: .php, .php3, .asp, .cfm, .cgi, .pl, .jsp, .exe, .dll. Figure 19 shows substantial differences among the search engines in terms of the percentage of dynamic pages in their corpora: Google has the highest percentage, while MSN has the lowest. This may indicate Google is doing a better job in crawling \"deep web\" dynamic content. Here too, the results are within an absolute error of 4.5% from the real values with a confidence level of 95%.  ", "publication_ref": [], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Conclusions", "text": "We presented two novel search engine samplers. The first, the pool-based sampler, uses a preprepared pool of queries to generate random queries. Random documents are then selected from the results of these queries. The sampler employs a Monte Carlo method, like rejection sampling, to guarantee that the distribution of the samples is close to the target distribution. We show that the sampler works, even if the sampling \"weights\", which are needed by the Monte Carlo method, are only approximate.\nWe provided full analysis of the sampler and identified the query pool parameters that impact its bias and performance. We then estimated these parameters on real data, consisting of the English pages from the ODP hierarchy, and showed that a pool of 5-term phrases achieves the best tradeoff between accuracy and performance.\nOur second sampler runs a random walk on a graph defined over the indexed documents. Its primary advantage is that it does not need a pre-prepared query pool. This sampler employs a Markov Chain Monte Carlo method, like the Metropolis-Hastings algorithm or the Maximum Degree method, to guarantee that the random walk converges to the target distribution. Theoretical bounds on the convergence rate of the random walk are quite high, yet practical evidence suggests that the random walk produces only slightly biased samples much before reaching the theoretical bounds.\nOur experimental results bare bias towards pages in the English language, since the query pool we used consisted primarily of English phrase queries. We note that this bias is a limitation of our experimental setup and not of the techniques themselves. The bias could be eliminated by using a more comprehensive query pool.\nDuring our experiments we performed our measurements against \"raw\" corpora. Duplicate-free measurements remain an interesting open problem.\nAlthough we tested our samplers on web search engines only, we speculate that they may be applicable in a more general setting. For example, for sampling from databases, deep web sites, library records, medical data, etc.\nAs the query and fetch cost of our samplers are quite high, it remains as an open problem to design much more efficient search engine samplers.\nA Monte Carlo methods -Proofs", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A.1 Markov Chain Monte Carlo methods", "text": "Theorem 5 (restated) The limit distribution of the Markov Chain defined by P md is \u03c0.\nProof. In order to show that \u03c0 is the limit distribution of the Markov Chain defined by P md , we will show that \u03c0P md = \u03c0.\nThat is, for each x \u2208 supp(\u03c0), y\u2208supp(\u03c0) \u03c0(y)P md (y, x) = \u03c0(x).\nSubstituting P md (x, y) = P (x, y) r md (x), if x = y, P (x, x) r md (x) + 1 \u2212 r md (x), if x = y.\n, we get We know that p is the limit distribution of the Markov Chain defined by P and that supp(\u03c0) = supp(p), thus y\u2208supp(\u03c0) p(y)P (y, x) = p(x). Substituting into the above we get Theorem 8 (restated) The sampling distribution of the approximate rejection sampling procedure is:\n\u03c0 \u2032 (x) = \u03c0(x) p(x) q(x) E \u03c0 p(X) q(X)\n.\nThe expected number of samples from p needed to generate each sample from \u03c0 \u2032 is:\nCZq Z\u03c0 E \u03c0 p(X) q(X)\n.\nProof. We start by finding a closed form expression for \u03c0 \u2032 . Let X denote a random sample from p.\nLet Z be a 0-1 random variable, which is 1 with probability r \u2032 rs (X) and 0 otherwise. Z corresponds to the outcome of the coin toss in the acceptance-rejection procedure of approximate rejection sampling. The procedure returns X as a sample if and only if Z = 1. Therefore, \u03c0 \u2032 is the distribution of X conditioned on the event \"Z = 1\". In other words, for all x \u2208 supp(\u03c0), Expanding over all possibilities for X, we have:\nPr(Z = 1) = y\u2208supp(\u03c0) Pr(Z = 1|X = y) \u2022 Pr(X = y) = y\u2208supp(\u03c0) r \u2032 rs (y) p(y).\nHence,\nPr(X = x|Z = 1) = r \u2032 rs (x) p(x) y\u2208supp(\u03c0) r \u2032 rs (y) p(y)\n.\nRecalling the definition of r \u2032 rs , we have:\n\u03c0 \u2032 (x) = Pr(X = x|Z = 1) =\u03c0 (x) Cq(x) p(x) y\u2208supp(\u03c0)\u03c0 (y) Cq(y) p(y) = \u03c0(x)Z\u03c0 Cq(x)Zq p(x) y\u2208supp(\u03c0) \u03c0(y)Z\u03c0 Cq(y)Zq p(y) = \u03c0(x) p(x) q(x) y\u2208supp(\u03c0) \u03c0(y) p(y) q(y) = \u03c0(x) p(x) q(x) E \u03c0 p(X) q(X)\n.\nWe now turn to calculating the cost of the approximate rejection sampling procedure. The procedure generates samples from p until the acceptance-rejection procedure accepts. The probability of acceptance is Pr(Z = 1), and thus the number of samples generated from p is a geometric random variable whose probability of success is Pr(Z = 1). Its expectation is 1/ Pr(Z = 1). Let us then calculate this probability:\nPr(Z = 1) = y\u2208supp(\u03c0) r \u2032 rs (y) p(y) = y\u2208supp(\u03c0) \u03c0(y)Z\u03c0 Cq(y)Zq p(y) = Z\u03c0 CZq \u2022 y\u2208supp(\u03c0) \u03c0(y) p(y) q(y) = Z\u03c0 CZq \u2022 E \u03c0 p(X) q(X) .\nProposition 9 (restated)\n||\u03c0 \u2032 \u2212 \u03c0|| = 1 2 ndev \u03c0 p(X) q(X) .\nProof.\n||\u03c0 \u2032 \u2212 \u03c0|| = 1 2 x\u2208supp(\u03c0) \u03c0 \u2032 (x) \u2212 \u03c0(x) = 1 2 x\u2208supp(\u03c0) \u03c0(x) p(x) q(x) E \u03c0 p(X) q(X) \u2212 \u03c0(x) = 1 2 \u2022 1 E \u03c0 p(X) q(X) \u2022 x\u2208supp(\u03c0) \u03c0(x) p(x) q(x) \u2212 E \u03c0 p(X) q(X) = 1 2 \u2022 1 E \u03c0 p(X) q(X)\n\u2022 dev \u03c0 p(X) q(X) = 1 2 ndev \u03c0 p(X) q(X) .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B.2 Approximate importance sampling", "text": "Theorem 10 (restated) Let\u03bc\n\u2032 = A B = 1 n n i=1 f (X i )w \u2032 (X i ) 1 n n i=1\nw \u2032 (X i ) be the estimator produced by the approximate importance sampling procedure for the parameter E \u03c0 (f (X)). Then,\nE p (A) E p (B) = E \u03c0 (f (X)) + cov \u03c0 f (X), p(X) q(X) E \u03c0 p(X) q(X)\n.\nProof. Since X 1 , . . . , X n are i.i.d. random variables, it suffices to analyze the expectations of f (X)w \u2032 (X) and w \u2032 (X), where X \u223c p.\nE p (f (X)w \u2032 (X)) = x\u2208U p(x) f (x)\u03c0 (x) q(x) = Z\u03c0 Zq x\u2208U \u03c0(x) f (X) p(x) q(x) = Z\u03c0 Zq E \u03c0 f (X) p(X) q(X) . E p (w \u2032 (X)) = x\u2208U p(x)\u03c0 (x) q(x) = Z\u03c0 Zq x\u2208U \u03c0(x) p(x) q(x) = Z\u03c0 Zq E \u03c0 p(X) q(X) .\nTherefore,\nE p (A) E p (B) = E p (f (X)w \u2032 (X)) E p (w \u2032 (X)) = Z\u03c0 Zq \u2022 E \u03c0 f (X) p(X) q(X) Z\u03c0 Zq \u2022 E \u03c0 p(X) q(X) = cov \u03c0 f (X), p(X) q(X) + E \u03c0 (f (X)) E \u03c0 p(X) q(X) E \u03c0 p(X) q(X) = E \u03c0 (f (X)) + cov \u03c0 f (X), p(X) q(X) E \u03c0 p(X) q(X)\n.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B.3 Approximate Metropolis-Hastings", "text": "Theorem 12 (restated) Let P \u2032 mh be the transition matrix of the approximate Metropolis-Hastings algorithm. Then, P \u2032 mh forms an ergodic Markov Chain and its unique limit distribution is \u03c0 \u2032 .\nProof. The transition matrix of approximate MH is:\nP \u2032 mh (x, y) = P (x, y) r \u2032 mh (x, y), if x = y, P (x, x) r \u2032 mh (x, x) + 1 \u2212 z\u2208U P (x, z) r \u2032 mh (x, z), if x = y, where r \u2032 mh (x, y) = min \u03c0(y) q(x) \u03c0(x) q(y) , 1 .\nSince \u03c0(x) > 0 and q(x) > 0 for all x \u2208 U, then r \u2032 mh (x, y) > 0 for all x, y \u2208 U. It follows that whenever P (x, y) > 0, then also P \u2032 mh (x, y) > 0. This implies that the Markov Chain graph G P \u2032 mh corresponding to P \u2032 mh contains all the edges of the Markov Chain graph G P corresponding to P . Since P is ergodic, we know that G P is strongly connected and aperiodic. As strong connectedness and aperiodicity are invariant under addition of edges, it follows that also G P \u2032 mh must be strongly connected and aperiodic, and thus P \u2032 mh is ergodic. As P \u2032 mh is ergodic, the fundamental theorem of Markov Chains tell us that it has a unique limit distribution \u03b7. Furthermore, \u03b7 is the unique stationary distribution of P \u2032 mh . We use the next proposition to show that that \u03b7 = \u03c0 \u2032 . Proposition 34. If P is ergodic, and reversible with respect to \u03c0, then \u03c0 is the unique stationary distribution of P .\nProof. For every y, we have Hence \u03c0 is stationary, and by the fundamental theorem of Markov Chains it is unique.\nIn order to show that P \u2032 mh satisfies the conditions of Proposition 34, we are left to show that P \u2032 mh is reversible with respect to \u03c0 \u2032 . That is, \u03c0 \u2032 (x)P \u2032 mh (x, y) = \u03c0 \u2032 (y)P \u2032 mh (y, x). It will then follow that \u03c0 \u2032 is the unique limit distribution of P \u2032 mh . For x = y, reversibility follows trivially. When x = y,\n\u03c0 \u2032 (x)P \u2032 mh (x, y) = \u03c0 \u2032 (x)P (x, y)r \u2032 mh (x, y) = \u03c0(x) p(x) q(x) E \u03c0 p(X) q(X) P (x, y) min \u03c0(y) q(x) \u03c0(x) q(y) , 1 = 1 E \u03c0 p(X) q(X) p(x)P (x, y) \u03c0(x) q(x) min \u03c0(y) q(x) \u03c0(x) q(y) , 1 = 1 E \u03c0 p(X) q(X) p(y)P (y, x) \u03c0(x) q(x) min \u03c0(y) q(x) \u03c0(x) q(y) , 1 (Since P is reversible) = 1 E \u03c0 p(X) q(X) p(y)P (y, x) \u03c0(y) q(y) min \u03c0(y) q(x) \u03c0(x) q(y) \u03c0(x) q(y) q(x) \u03c0(y) , \u03c0(x) q(y) q(x) \u03c0(y) = \u03c0(y) p(y) q(y) E \u03c0 p(X) q(X) P (y, x) min 1, \u03c0(x) q(y) \u03c0(y) q(x)\n= \u03c0 \u2032 (y)P (y, x)r \u2032 mh (y, x) = \u03c0 \u2032 (y)P \u2032 mh (y, x).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B.4 Approximate Maximum Degree", "text": "Theorem 13 (restated) Let P \u2032 md be the transition matrix of the approximate Maximum Degree procedure. Then, P \u2032 md forms an ergodic Markov Chain. The unique limit distribution of P \u2032 md is \u03c0 \u2032 .\nProof. The transition matrix of approximate MD is:\nP \u2032 md (x, y) = P (x, y) r \u2032 md (x), if x = y, P (x, x) r \u2032 md (x) + 1 \u2212 r \u2032 md (x), if x = y.\nRecall that\nr \u2032 md (x) =q (x) C\u03c0(x)\n, where\nC \u2265 max x\u2208Uq (x) \u03c0(x)\n.\nSinceq(x) > 0 for all x \u2208 U, it can be seen from the above expression that for all x = y \u2208 U, P \u2032 md (x, y) > 0 if and only if P (x, y) > 0. Furthermore, if P \u2032 md (x, x) = 0, then also P (x, x) = 0 (the converse is not necessarily true). We conclude that the Markov Chain graph G P \u2032 md corresponding to P \u2032 md contains all the edges of the Markov Chain graph G P corresponding to P (the only possible extra edges in G P \u2032 md are self loops). As P is ergodic, and ergodicity is invariant under addition of edges to the Markov Chain graph, we conclude that also P \u2032 md is ergodic. We next prove that P \u2032 md is reversible with respect to \u03c0 \u2032 . This would imply, by Proposition 34, that \u03c0 \u2032 is also the unique limit distribution of P \u2032 md . For x = y, reversibility follows trivially. When x = y, The sampling bias of the PB sampler is at most:\n\u03c0 \u2032 (x)P \u2032 md (x, y) = \u03c0 \u2032 (x)P (x, y)r \u2032 md (x, y) = \u03c0(x) p(x) q(x) E \u03c0 p(X) q(X) P (x, y)q (x) C\u03c0(x) = 1 E \u03c0 p(X) q(X) p(x)P (x, y) Zq C Z\u03c0 = 1 E \u03c0 p(X) q(X) p(y)P (y, x) Zq C Z\u03c0 (Since P is reversible) = \u03c0(y) p(y) q(y) E \u03c0 p(X) q(X) P (y, x)q (y) C\u03c0(y) = \u03c0 \u2032 (y)P (y, x)r \u2032 md (y, x) = \u03c0 \u2032 (y)P \u2032 md (y, x).\n1 2 ndev \u03c0 P + (vdensity P (X)),\nwhere \u03c0 P + is the restriction of \u03c0 to D P + \u2229 supp(\u03c0).\nProof. The analysis of the recall of the PB sampler is identical to the recall analysis shown in the proof of Proposition 18. We therefore omit the details.\nLet \u03b7 be the sampling distribution of the PB sampler. Similarly to the proof of Proposition 18, it can be shown that: supp(\u03b7) = D P + \u2229 supp(\u03c0).\nHence, the restriction of \u03c0 to supp(\u03b7), i.e., \u03c0 supp(\u03b7) , is exactly \u03c0 P + . The sampling bias of the PB sampler is therefore the distance ||\u03b7 \u2212 \u03c0 P + ||.\nWe note that the scenario we face here is exactly the one captured by Theorem 8: we have a rejection sampling procedure whose trial distribution does not match the unnormalized trial weights. The target distribution in this case is\u03c0 P + and the trial distribution is d P + . Let us denote the distribution induced by the trial weights by q. We next calculate a closed form expression for q.\nThe support of q is the same as the support of d P + , because only documents that are sampled from d P + are assigned an unnormalized trial weight. Hence, supp(q) = supp(d P + ) = D P + . For each x \u2208 D P + the unnormalized trial weight is deg P (x). Therefore, the normalization constant is: Zq = x\u2208D P + deg P (x) = deg P (D P + ). Therefore, for every document x \u2208 D P + we have:\nq(x) = deg P (x) deg P (D P + )\n.\nApplying Proposition 9, we bound the bias of the PB sampler as follows:\n||\u03b7 \u2212 \u03c0 P + || \u2264 1 2 ndev \u03c0 P + d P + (X) q(X) .\nFor each x \u2208 D P + , we have: Therefore, ndev \u03c0 P + d P + (X) q(X) = ndev \u03c0 P + vdensity P (X) \u2022 deg P (D P + ) deg P + (D P + ) = ndev \u03c0 P + (vdensity P (X)) ,\nd P + (x) q(x) =\nwhere the latter equality follows from the fact the normalized mean deviation is invariant under multiplication by a scalar.\nTheorem 22 (restated) The sampling bias of the PB sampler is at most:\novprob(w P ) 1 \u2212 ovprob(w P )\n.\nProof. In order to prove the theorem, we prove that 1 2\n\u2022 ndev \u03c0 P + (vdensity P (X)) \u2264 ovprob(w P ) 1 \u2212 ovprob(w P ) .\nLet \u00b5 = E \u03c0 P + (vdensity P (X)). Then, 1 2\n\u2022 ndev \u03c0 P + (vdensity P (X)) = E \u03c0 P + (| vdensity P (X) \u2212 \u00b5|) 2\u00b5 .\nFor a document x \u2208 D P + , we define the invalidity density of x as:\ninvdensity P (x) = 1 \u2212 vdensity P (x).\nThen, E \u03c0 P + (| vdensity P (X) \u2212 \u00b5|)\n2\u00b5 = E \u03c0 P + (|1 \u2212 invdensity P (X) \u2212 \u00b5|) 2\u00b5 .\nBy the triangle inequality, for every x \u2208 D P + ,\n|1 \u2212 invdensity P (x) \u2212 \u00b5| \u2264 1 \u2212 \u00b5 + invdensity P (x) = 1 \u2212 \u00b5 + 1 \u2212 vdensity P (x).\nHence,\nE \u03c0 P + (|1 \u2212 invdensity P (X) \u2212 \u00b5|) 2\u00b5 \u2264 E \u03c0 P + (1 \u2212 \u00b5 + 1 \u2212 vdensity P (X)) 2\u00b5 = 1 \u2212 \u00b5 + 1 \u2212 E \u03c0 P + (vdensity P (X)) 2\u00b5 (3) = 1 \u2212 \u00b5 + 1 \u2212 \u00b5 2\u00b5 = 1 \u2212 \u00b5 \u00b5 .\nNext, we relate \u00b5 = E \u03c0 P + (vdensity P (X)) to ovprob(w P ).\nE \u03c0 P + (vdensity P (X)) = Substituting back in Equation 3, we have: 1 2\nx\u2208D P + \u03c0 P + (x) \u2022 deg P + (x) deg P (x) = x\u2208D P + \u03c0 P + (x) deg P (x)\n\u2022 ndev \u03c0 P + (vdensity P (X)) \u2264 1 \u2212 (1 \u2212 ovprob(w P )) 1 \u2212 ovprob(w P ) = ovprob(w P ) 1 \u2212 ovprob(w P ) .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C.2 Analysis of query and fetch costs", "text": "Theorem 24 (restated) The query cost of the PB sampler is at most:\nC \u2022 deg P + (D P + ) Z\u03c0 \u2022 \u03c0(D P + ) \u2022 (1 \u2212 ovprob(w P )) \u2022 |P| |P + | \u2022 k avg q\u2208P + card(q) + qcost(\u03c0) .\nThe fetch cost of the PB sampler is at most:\nC \u2022 deg P + (D P + ) Z\u03c0 \u2022 \u03c0(D P + ) \u2022 (1 \u2212 ovprob(w P ))\n\u2022 (1 + fcost(\u03c0)).\nProof. Search engine queries are made in two of the subroutines of the PB sampler: (1) In DDSampler, which selects a random document from the results of the query Q that it gets from QCSampler; and (2) In QCSampler, in order to determine the cardinality of the selected random query Q. Queries can also be possibly made in the getWeight\u03c0(x) procedure, when calculating the target weight\u03c0(x) of a document x. Note that DDSampler needs the results of a query Q only after Q has already been processed by QCSampler and thus has already been submitted to the search engine. Therefore, by careful data management, we can keep the results already returned for Q in memory, and hence avoid the additional search engine queries in DDSampler. We assume, then, from now on that DDSampler does not submit queries to the search engine.\nIn order to analyze the total number of queries made by PBSampler, we define the following random variables: (1) T is the number of iterations made in the loop of the outer procedure. Note that T determines exactly the number of calls to the getWeight\u03c0(x) procedure as well as the number of calls to the QCSampler procedure. (2) S i (for i = 1, 2, . . .) is the number of iterations made in the loop of QCSampler during its i-th invocation. The total number of queries submitted to the search engine by the PB sampler is at most T i=1 S i + T \u2022 qcost(\u03c0). The query cost of PBSampler is then E( T i=1 S i ) + E(T ) \u2022 qcost(\u03c0). In order to analyze the first term, we resort to Wald's identity. Note that the conditions of Wald's identity are met: S 1 , S 2 , . . . are i.i.d. random variables and the event {T = i} is independent of S i+1 , S i+2 , . . .. Hence, the query cost of the PB sampler is E(T ) \u2022 E(S) + E(T ) \u2022 qcost(\u03c0) = E(T ) \u2022 (E(S) + qcost(\u03c0)), where S is the random number of iterations in a single invocation of QCSampler.\nIn order to bound E(T ), we analyze the parameters of the rejection sampling applied at the outer procedure:\n1. The target distribution is \u03c0 P + . As shown in the proof of Proposition 18, the corresponding normalization constant is: Z\u03c0 P + = Z\u03c0 \u2022 \u03c0(D P + ).\n2. The trial distribution is d P + .\n3. As shown in the proof of Theorem 21, the trial weight distribution is q. Its normalization constant is: Zq = deg P (D P + ).\nAs shown in the proof of Theorem 21, E \u03c0 P + d P + (X) q(X) = deg P (D P + ) deg P + (D P + )\n\u2022 E \u03c0 P + (vdensity P (X)).\nIn Theorem 22 we showed:\nE \u03c0 P + (vdensity P (X)) = 1 \u2212 ovprob(w P ).\nTherefore, applying Theorem 8, we have: Next, we bound the expected number of iterations made in the loop of QCSampler. To this end, we analyze the parameters of the rejection sampling applied at QCSampler:\nE(T ) = C \u2022 Zq Z\u03c0 P + \u2022 E \u03c0 P + d P + (X) q(X) = C \u2022\n1. The target distribution is c P + and its normalization constant is: Z\u0109 P + = card(P + ).\n2. The trial distribution is the uniform distribution on P and its normalization constant is: Z\u00fb P = |P|. The trial weight distribution is identical to the trial distribution in this case.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "The envelope constant is", "text": "C = k.\nBy the analysis of rejection sampling, we have:\nE(S) = k \u2022 |P| card(P + ) = |P| |P + | \u2022 k avg q\u2208P + card(q) .(5)\nCombining the expressions derived at Equations 4 and 5, the total query cost of the PB sampler is at most: Next, we analyze the fetch cost of the PB sampler. Pages are fetched in two of the sampler's procedures: (1) In the outer procedure, in order to compute the degrees of documents; and (2) In the getWeight\u03c0(x) procedure, in order to compute the target weight of documents. The number of fetches is determined directly by the number of iterations in the outer procedure, which we denoted by T . Therefore, the fetch cost is at most E(T ) \u2022 (1 + fcost(\u03c0)). Using the analysis of E(T ) above, the fetch cost is at most:\nE\nC \u2022 deg P + (D P + ) Z\u03c0 \u2022 \u03c0(D P + ) \u2022 (1 \u2212 ovprob(w P ))\n\u2022 (1 + fcost(\u03c0)).", "publication_ref": ["b0"], "figure_ref": [], "table_ref": []}, {"heading": "D Random walk based sampler -Proofs", "text": "Theorem 27 (restated) Let \u03b5 > 0. Suppose we run the MH sampler (resp., the MD sampler) with a burn-in period B that guarantees the approximate MH Markov Chain (resp., approximate MD Markov Chain) reaches a distribution, which is at distance of at most \u03b5 from the limit distribution.\nThen, the sampling bias of the MH sampler (resp., MD sampler) is at most: 1 2 ndev \u03c0 F (vdensity P (X)) + \u03b5.\nThe sampling recall of the MH sampler (resp., MD sampler) is at least:\n\u03c0(F ) \u2022 (1 \u2212 1 2 ndev \u03c0 F (vdensity P (X)) \u2212 \u03b5).\nProof. By Theorems 13 and 12, the limit distributions of the MH and the MD samplers are equal to:\n\u03b7(x) = \u03c0 F (x) d F (x) q F (x) E \u03c0 F d F (X) q F (X)\n.\nBy Proposition 9, the distance between this limit distribution and the target distribution \u03c0 F is bounded as follows: Since normalized mean deviation is invariant under multiplication by scalars, we therefore have:\n||\u03b7 \u2212 \u03c0 F || \u2264 1 2 ndev \u03c0 F d F (X) q F (X) .\n||\u03b7 \u2212 \u03c0 F || \u2264 1 2 ndev \u03c0 F (vdensity P (X)).\nConsider now the distribution \u03b7 \u2032 obtained after running the approximate MH Markov Chain (resp., MD Markov Chain) for B steps. \u03b7 \u2032 is the distribution of samples generated by the procedure. Since B \u2265 T \u03b5 (P \u2032 mh ) (resp., B \u2265 T \u03b5 (P \u2032 md )), then ||\u03b7 \u2032 \u2212 \u03b7|| \u2264 \u03b5.\nTherefore, by the triangle inequality,\n||\u03b7 \u2032 \u2212 \u03c0 F || \u2264 1 2 ndev \u03c0 F (vdensity P (X)) + \u03b5.(6)\nWe next show that this gives also an upper bound on the sampling bias, i.e., on ||\u03b7 \u2032 supp(\u03b7 \u2032 ) \u2212\u03c0 supp(\u03b7 \u2032 ) ||.\n||\u03b7 \u2032 supp(\u03b7 \u2032 ) \u2212 \u03c0 supp(\u03b7 \u2032 ) || = 1 2 x\u2208supp(\u03b7 \u2032 ) \u03b7 \u2032 (x) \u2212 \u03c0(x) \u03c0(supp(\u03b7 \u2032 )) \u2264 1 2 x\u2208supp(\u03b7 \u2032 ) \u03b7 \u2032 (x) \u2212 \u03c0 F (x) + 1 2 x\u2208supp(\u03b7 \u2032 ) \u03c0 F (x) \u2212 \u03c0(x) \u03c0(supp(\u03b7 \u2032 ))(7)\nLet us bound each of the two above sums separately. To bound the first one, we resort to Equation 6: 1 2\nx\u2208supp(\u03b7 \u2032 ) \u03b7 \u2032 (x) \u2212 \u03c0 F (x) = ||\u03b7 \u2032 \u2212 \u03c0 F || \u2212 1 2 x\u2208F \\supp(\u03b7 \u2032 ) \u03c0 F (x) = ||\u03b7 \u2032 \u2212 \u03c0 F || \u2212 1 2 (1 \u2212 \u03c0 F (supp(\u03b7 \u2032 ))). (8\n)\nAs for the second sum, 1 2\nx\u2208supp(\u03b7 \u2032 ) \u03c0 F (x) \u2212 \u03c0(x) \u03c0(supp(\u03b7 \u2032 )) = 1 2 x\u2208supp(\u03b7 \u2032 ) \u03c0 F (x) \u2212 \u03c0 F (x) \u03c0 F (supp(\u03b7 \u2032 )) = 1 2 1 \u03c0 F (supp(\u03b7 \u2032 )) \u2212 1 x\u2208supp(\u03b7 \u2032 ) \u03c0 F (x) = 1 2 1 \u03c0 F (supp(\u03b7 \u2032 )) \u2212 1 \u2022 \u03c0 F (supp(\u03b7 \u2032 )) = 1 2 (1 \u2212 \u03c0 F (supp(\u03b7 \u2032 )))(9)\nCombining Equations ( 6)-( 9), we have:\n||\u03b7 \u2032 supp(\u03b7 \u2032 ) \u2212 \u03c0 supp(\u03b7 \u2032 ) || \u2264 ||\u03b7 \u2032 \u2212 \u03c0 F || \u2212 1 2 (1 \u2212 \u03c0 F (supp(\u03b7 \u2032 ))) + 1 2 (1 \u2212 \u03c0 F (supp(\u03b7 \u2032 ))) = ||\u03b7 \u2032 \u2212 \u03c0 F || \u2264 1 2 ndev \u03c0 F (vdensity P (X)) + \u03b5.\nThis gives us the desired upper bound on the sampling bias. We now turn to bounding the recall of the MH and MD samplers. Using Equation ( 6) and the characterization of total variation distance given in Lemma 2, we have:\n|\u03b7 \u2032 (supp(\u03b7 \u2032 )) \u2212 \u03c0 F (supp(\u03b7 \u2032 ))| \u2264 1 2 ndev \u03c0 F (vdensity P (X)) + \u03b5.\nSince \u03b7 \u2032 (supp(\u03b7 \u2032 )) = 1, then this implies: \u03c0(supp(\u03b7 \u2032 )) = \u03c0(F ) \u2022 \u03c0 F (supp(\u03b7 \u2032 )) \u2265 \u03c0(F ) \u2022 (1 \u2212 1 2 ndev \u03c0 F (vdensity P (X)) \u2212 \u03b5).\nThis gives us the lower bound on the recall of the MH and MD samplers.\nTheorem 30 (restated) For any t \u2265 0, the expected query cost of the t-th step of the random walk sampler (whether MH or MD) is at most:\n1 E \u03c0 F (vdensity P (X)) + 3\u03b5 t |F | \u2022 E u F 1 vdensity 2 P (X) + qcost(\u03c0).\nHere, \u03b5 t is an upper bound on the total variation distance between the distribution of the node visited at the t-th step and the limit distribution \u03b7 of the random walk. u F is the uniform distribution over F .\nProof. Let \u03b7 t be the distribution of the node visited at the t-th step of the random walk. By Proposition 28, the expected query cost of the t-th step of the random walk is:\nE \u03b7t 1 vdensity P (X) + qcost(\u03c0).\nAs the term qcost(\u03c0) is independent of X, we will focus from now on bounding the expected inverse validity density.\nOur strategy for bounding E \u03b7t (1/ vdensity P (X)) will be the following. We will first show an upper bound on E \u03b7 (1/ vdensity P (X)), where \u03b7 is the limit distribution of the random walk. We will then bound the difference between E \u03b7 (1/ vdensity P (X)) and E \u03b7t (1/ vdensity P (X)).\nThe following proposition analyzes the expected inverse validity density relative to the limit distribution:\nProposition 35.\nE \u03b7 1 vdensity P (X) = 1 E \u03c0 F vdensity P (X) .\nProof. Recall (Equation 2) that for both the MH and MD random walks,\n\u03b7(x) = \u03c0 F (x) d F (x) q F (x) E \u03c0 F d F (X) q F (X)\n.\nHere, F is the connected component on which the random walk runs, \u03c0 F is the restriction of the target distribution \u03c0 to F , d F is the restriction of the degree distribution d P + to F , and q F is the restriction of the approximate degree distribution d P to F . Therefore, = 1 E \u03c0 F (vdensity P (X))\nE \u03b7 1 vdensity P (X) = x\u2208F \u03b7(x) \u2022 1 vdensity P (x) = x\u2208F \u03c0 F (x) \u2022 d F (x) q F (x) E \u03c0 F d F (X) q F (X)\nIn order to bound the difference E \u03b7 1 vdensity P (x) \u2212 E \u03b7t 1 vdensity P (x) , we will resort to the following general lemma that bounds the difference between expectations of the same function of two random variables in terms of the distance between their distributions. We conclude from Lemma 36 that:\nE \u03b7 1 vdensity P (x) \u2212 E \u03b7t 1 vdensity P (x) \u2264 2\u03b5 t \u2022 E u F 1 vdensity P (X) + |F | \u2022 cov u F 1 vdensity P (X)\n, |\u03b7 t (X) \u2212 \u03b7(X)| .\nRecall that we use the upper bound \u03b5 t = (1 \u2212 \u03b1) t /\u03b7 min on ||\u03b7 t \u2212 \u03b7||. We next show that also the covariance term can be bounded in terms of \u03b5 t .\nLemma 37. Consider a Markov Chain on a finite space U. Let \u03b1 be the spectral gap of this Markov Chain's transition matrix, let \u03b7 be its limit distribution, and let \u03b7 t be the distribution of the node visited at the t-th step. Let f by any non-negative real-valued function f : U \u2192 R + . Then, cov u (f (X), |\u03b7 t (X) \u2212 \u03b7(X\n)|) \u2264 (1 \u2212 \u03b1) t \u221a \u03b7 min \u2022 E u (f 2 (X)),\nwhere u is the uniform distribution on U.\nProof.\ncov u (f (X), |\u03b7 t (X) \u2212 \u03b7(X)|) = E u (|\u03b7 t (X) \u2212 \u03b7(X)| \u2022 f (X)) \u2212 E u (|\u03b7 t (X) \u2212 \u03b7(X)|) \u2022 E u (f (X)).\nAccording to Theorem 6, for every x \u2208 U,\n|\u03b7 t (x) \u2212 \u03b7(x)| \u2264 \u03b7(x) \u03b7 min (1 \u2212 \u03b1) t .\nThus, cov u (f (X), |\u03b7 t (X) \u2212 \u03b7(X\n)|) \u2264 (1 \u2212 \u03b1) t \u221a \u03b7 min \u2022 E u ( \u03b7(X) \u2022 f (X)) \u2212 E u ( \u03b7(X)) \u2022 E u (f (X)) \u2264 (1 \u2212 \u03b1) t \u221a \u03b7 min \u2022 E u ( \u03b7(X) \u2022 f (X)) (Since f (x) \u2265 0, \u2200x) \u2264 (1 \u2212 \u03b1) t \u221a \u03b7 min \u2022 E u (\u03b7(X)) \u2022 E u (f 2 (X)) (Cauchy-Schwartz) = (1 \u2212 \u03b1) t \u221a \u03b7 min \u2022 E u (f 2 (X)) (Since \u03b7 is a distribution).\nWe conclude from Lemma 37 that:\n|F | \u2022 cov u F 1 vdensity P (X) , |\u03b7 t (X) \u2212 \u03b7(X)| \u2264 |F | \u2022 (1 \u2212 \u03b1) t \u221a \u03b7 min \u2022 E u F 1 vdensity 2 P (X) \u2264 |F | \u2022 (1 \u2212 \u03b1) t \u03b7 min \u2022 E u F 1 vdensity 2 P (X) (Since \u03b7 min \u2264 1/|F |) = \u03b5 t \u2022 |F | \u2022 E u F 1 vdensity 2 P (X) . (11\n)\nCombining Proposition 35, Equation 10, and Equation 11, we have:\nE \u03b7t 1 vdensity P (X) \u2264 E \u03b7 1 vdensity P (X) + E \u03b7t 1 vdensity P (X) \u2212 E \u03b7 1 vdensity P (X) \u2264 1 E \u03c0 F (vdensity P (X)) + 2\u03b5 t \u2022 E u F 1 vdensity P (X) + \u03b5 t \u2022 |F | \u2022 E u F 1 vdensity 2 P (X) \u2264 1 E \u03c0 F (vdensity P (X)) + 3\u03b5 t |F | \u2022 E u F 1 vdensity 2 P (X)\n(Since E(Z) \u2264 E(Z 2 ).)\nTheorem 33 (restated) For any t \u2265 0, the expected delay of the t-th real step of the optimized MD random walk is at least:\nC \u2032 \u2022 Z\u03c0 F \u2022 \u03c0(F ) \u2022 E \u03c0 F (vdensity P (X)) deg P + (F ) \u2212 3\u03b5 t \u2022 E u F \u03c0 2 F (X) deg 2 P (X) .\nHere, \u03b5 t is an upper bound on the total variation distance between the distribution of the node visited at the t-th real step and the degree distribution d F . u F is the uniform distribution over F .\nProof. Let d t be the distribution of the node visited at the t-th real step of the random walk. By Proposition 32, and since supp(d t ) \u2286 F , the expected delay of the t-th step is:\nE dt C \u2032\u03c0 (x) deg P (x) = C \u2032 \u2022 Z\u03c0 F \u2022 \u03c0(F ) \u2022 E dt \u03c0 F (x) deg P (x) . (12\n)\nThe structure of this proof is similar to that of Theorem 30, with the difference that here we are looking for a lower bound instead of an upper bound. We will first show a lower bound on E d F \u03c0 F (x) deg P (x) , where d F is the limit distribution of the simple random walk. We will then bound the difference between E d F \u03c0 F (x) deg P (x) and E dt \u03c0 F (x) deg P (x) .\nThe following proposition analyzes the expected delay relative to the limit distribution:\nProposition 38. E d F \u03c0 F (X) deg P (X) = E \u03c0 F (vdensity P (X)) deg P + (F ) .\nProof. Recall (Equation 1) that the limit distribution of the real steps of the random walk is the degree distribution restricted to F : \nRecall that we use the upper bound \u03b5 t = (1 \u2212 \u03b1) t /d F min on ||d t \u2212 d F ||. We next show that also the covariance term can be bounded in terms of \u03b5 t .\nFrom Lemma 37 we conclude that:\n|F | \u2022 cov u F \u03c0 F (x) deg P (x) , |d t (X) \u2212 d F (X)| \u2264 |F | \u2022 (1 \u2212 \u03b1) t \u221a d F min \u2022 E u F \u03c0 2 F (x) deg 2 P (x) , |d t (X) \u2212 d F (X)| \u2264 |F | \u2022 (1 \u2212 \u03b1) t d F min \u2022 E u F \u03c0 2 F (x) deg 2 P (x) (Since d F min \u2264 1/|F |) = \u03b5 t \u2022 |F | \u2022 E u F \u03c0 2 F (x) deg 2 P (x) .(14)\nCombining Proposition 35, Equation 13, and Equation 14, we have:\nE dt \u03c0 F (x) deg P (x) \u2265 E d F \u03c0 F (x) deg P (x) \u2212 E dt \u03c0 F (x) deg P (x) \u2212 E d F \u03c0 F (x) deg P (x)\n\u2265 E \u03c0 F (vdensity P (X))\ndeg P + (F ) \u2212 2\u03b5 t \u2022 E u F \u03c0 F (x) deg P (x) \u2212 \u03b5 t \u2022 |F | \u2022 E u F \u03c0 2 F (x) deg 2 P (x)\n\u2265 E \u03c0 F (vdensity P (X))\ndeg P + (F ) \u2212 3\u03b5 t |F | \u2022 E u F \u03c0 2 F (x) deg 2 P (x)\n(Since E(Z) \u2264 E(Z 2 )).\nSubstituting the above result into Equation 12we obtain the theorem.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgments", "text": "We thank Sara Cohen, Idit Keidar, Moshe Sidi, and the anonymous reviewers of WWW2006 and JACM for their valuable suggestions that helped to improve our paper.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "On the Markov chain simulation method for uniform combinatorial distributed and simulated annealing", "journal": "Probability in the Engineering and Informational Sciences", "year": "1987", "authors": "D Aldous"}, {"ref_id": "b1", "title": "Sampling search-engine results", "journal": "", "year": "2005", "authors": "A Anagnostopoulos; A Broder; D Carmel"}, {"ref_id": "b2", "title": "Approximating aggregate queries about Web pages via random walks", "journal": "", "year": "2000", "authors": "Z Bar-Yossef; A Berg; S Chien; J Fakcharoenphol; D Weitz"}, {"ref_id": "b3", "title": "Random sampling from a search engine's index", "journal": "", "year": "2006", "authors": "Z Bar-Yossef; M Gurevich"}, {"ref_id": "b4", "title": "Efficient search engine measurements", "journal": "", "year": "2007", "authors": "Z Bar-Yossef; M Gurevich"}, {"ref_id": "b5", "title": "John Battelle's searchblog", "journal": "", "year": "2005", "authors": "J Battelle"}, {"ref_id": "b6", "title": "A technique for measuring the relative size and overlap of public Web search engines", "journal": "", "year": "1998", "authors": "K Bharat; A Broder"}, {"ref_id": "b7", "title": "Search engine indexing limits: Where do the bots stop", "journal": "", "year": "2006", "authors": "S Bondar"}, {"ref_id": "b8", "title": "Fastest mixing markov chain on a graph", "journal": "SIAM Rev", "year": "2004", "authors": "S Boyd; P Diaconis; L Xiao"}, {"ref_id": "b9", "title": "The little engines that could: Modeling the performance of World Wide Web search engines", "journal": "Marketing Science", "year": "2000", "authors": "E T Bradlow; D C Schmittlein"}, {"ref_id": "b10", "title": "Estimating corpus size via queries", "journal": "", "year": "2006", "authors": "A Broder; M Fontoura; V Josifovski; R Kumar; R Motwani; S Nabar; R Panigrahy; A Tomkins; Y Xu"}, {"ref_id": "b11", "title": "Automatic performance evaluation of Web search engines", "journal": "Information Processing and Management", "year": "2004", "authors": "F Can; R Nuray; A B Sevdik"}, {"ref_id": "b12", "title": "A comparison of the size of the Yahoo! and Google indices", "journal": "", "year": "2005", "authors": "M Cheney; M Perry"}, {"ref_id": "b13", "title": "The potential of the metasearch engine", "journal": "", "year": "2004", "authors": "B D Davison"}, {"ref_id": "b14", "title": "What do we know about the Metropolis algorithm?", "journal": "J. of Computer and System Sciences", "year": "1998", "authors": "P Diaconis; L Saloff-Coste"}, {"ref_id": "b15", "title": "How large is the World Wide Web? Web Dynamics", "journal": "", "year": "2004", "authors": "A Dobra; S E Fienberg"}, {"ref_id": "b16", "title": "A Chernoff bound for random walks on expander graphs", "journal": "SIAM J. on Computing", "year": "1998", "authors": "D Gillman"}, {"ref_id": "b17", "title": "Matrix Computations", "journal": "The Johns Hopkins University Press", "year": "1996", "authors": "G H Golub; C F Van Loan"}, {"ref_id": "b18", "title": "", "journal": "", "year": "", "authors": "Google Inc;  Google"}, {"ref_id": "b19", "title": "Finding information on the World Wide Web: the retrieval effectiveness of search engines", "journal": "Information Processing and Management", "year": "1999", "authors": "M Gordon; P Pathak"}, {"ref_id": "b20", "title": "The indexable Web is more than 11.5 billion pages", "journal": "", "year": "2005", "authors": "A Gulli; A Signorini"}, {"ref_id": "b21", "title": "Monte Carlo sampling methods using Markov chains and their applications", "journal": "Biometrika", "year": "1970", "authors": "W K Hastings"}, {"ref_id": "b22", "title": "Measuring search engine quality. Information Retrieval", "journal": "", "year": "2001", "authors": "D Hawking; N Craswel; P Bailey; K Griffiths"}, {"ref_id": "b23", "title": "Measuring index quality using random walks on the Web", "journal": "", "year": "1999-05", "authors": "M R Henzinger; A Heydon; M Mitzenmacher; M Najork"}, {"ref_id": "b24", "title": "On near-uniform URL sampling", "journal": "", "year": "2000-05", "authors": "M R Henzinger; A Heydon; M Mitzenmacher; M Najork"}, {"ref_id": "b25", "title": "Advances in Importance Sampling", "journal": "", "year": "1988", "authors": "T C Hesterberg"}, {"ref_id": "b26", "title": "Large deviation for Markov chains", "journal": "Combinatorics, Probability and Computing", "year": "1997", "authors": "N Kahale"}, {"ref_id": "b27", "title": "Searching the World Wide Web", "journal": "Science", "year": "1998", "authors": "S Lawrence; C L Giles"}, {"ref_id": "b28", "title": "Accessibility of information on the Web", "journal": "Nature", "year": "1999", "authors": "S Lawrence; C L Giles"}, {"ref_id": "b29", "title": "Metropolized independent sampling with comparisons to rejection sampling and importance sampling", "journal": "Statistics and Computing", "year": "1996", "authors": "J S Liu"}, {"ref_id": "b30", "title": "Monte Carlo Strategies in Scientific Computing", "journal": "Springer", "year": "2001", "authors": "J S Liu"}, {"ref_id": "b31", "title": "The use of multi-stage sampling schemes in Monte Carlo computations", "journal": "Wiley", "year": "1956", "authors": "A "}, {"ref_id": "b32", "title": "Our blog is growing up -and so has our index", "journal": "", "year": "2005", "authors": "T Mayer"}, {"ref_id": "b33", "title": "Agreeing to disagree: search engines and their public interfaces", "journal": "", "year": "2007", "authors": "F Mccown; M L Nelson"}, {"ref_id": "b34", "title": "Equations of state calculations by fast computing machines", "journal": "J. of Chemical Physics", "year": "1953", "authors": "N Metropolis; A Rosenbluth; M Rosenbluth; A Teller; E Teller"}, {"ref_id": "b35", "title": "More on the total database size battle and Googlewhacking with Yahoo", "journal": "", "year": "2005", "authors": "G Price"}, {"ref_id": "b36", "title": "Methods for sampling pages uniformly from the World Wide Web", "journal": "", "year": "2001", "authors": "P Rusmevichientong; D Pennock; S Lawrence; C L Giles"}, {"ref_id": "b37", "title": "Sequential Analysis -Tests and Confidence Intervals", "journal": "Springer-Verlag", "year": "1985", "authors": "D Siegmund"}, {"ref_id": "b38", "title": "Algorithms for random generation and counting: a Markov chain approach", "journal": "Birkhauser Verlag", "year": "1993", "authors": "A Sinclair"}, {"ref_id": "b39", "title": "Search engine sizes", "journal": "", "year": "2005", "authors": "D Sullivan"}, {"ref_id": "b40", "title": "Yahoo: Missing pages", "journal": "", "year": "", "authors": "J V\u00e9ronis"}, {"ref_id": "b41", "title": "Various techniques used in connection with random digits", "journal": "", "year": "1963", "authors": "J Neumann"}, {"ref_id": "b42", "title": "", "journal": "", "year": "", "authors": "! Yahoo;  Inc"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 :1Figure 1: The rejection sampling procedure.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 3 :3Figure 3: A random walk sampler.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 4 :4Figure 4: An MCMC sampler.", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 5 :5Figure 5: The Maximum Degree sampler.", "figure_data": ""}, {"figure_label": "17", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "1 :Figure 7 :17Figure 7: The degree distribution sampler.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Since card(P) = deg P (D) (Proposition 17), then the LHS of the last expression equals deg P (x) deg P (D) = d P (x).", "figure_data": ""}, {"figure_label": "8", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Figure 8 :8Figure 8: The cardinality distribution sampler.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "rmh (x, y) = min \u03c0(y) P (y, x) \u03c0(x) P (x, y) , 1 = min \u03c0(y) deg P + (x) \u03c0(x) deg P + (y) , 1 ; and r md (x) =d P + (x) C\u03c0(x) = deg P + (x) C\u03c0(x) ,", "figure_data": ""}, {"figure_label": "110", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "1 :Figure 10 :110Figure 10: The neighbor sampling procedure.", "figure_data": ""}, {"figure_label": "11", "figure_type": "figure", "figure_id": "fig_10", "figure_caption": "Figure 11 :11Figure 11: The optimized Maximum Degree sampler.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_11", "figure_caption": "conducted four sets of experiments: (1) pool measurements: estimation of parameters of selected query pools; (2) spectral gap estimations: measurement of the spectral gaps of the transition matrices used by the random walk samplers; (3) evaluation experiments: evaluation of the bias of our samplers and the Bharat-Broder (BB) sampler; and (4) exploration experiments: measurements of real search engines.", "figure_data": ""}, {"figure_label": "12", "figure_type": "figure", "figure_id": "fig_13", "figure_caption": "Figure 12 :12Figure 12: Distribution of samples by document size.", "figure_data": ""}, {"figure_label": "13", "figure_type": "figure", "figure_id": "fig_15", "figure_caption": "Figure 13 :13Figure 13: Distribution of samples by document rank.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_16", "figure_caption": "we show the relative sizes of the English portions of the corpora of the three search engines, as derived from the relative overlap estimates (by dividing overlap[SE1][SE2] by overlap[SE2][SE1]", "figure_data": ""}, {"figure_label": "14", "figure_type": "figure", "figure_id": "fig_17", "figure_caption": "Figure 14 :14Figure 14: Relative corpus size of Google, MSN Search, and Yahoo! (English pages only).", "figure_data": ""}, {"figure_label": "15", "figure_type": "figure", "figure_id": "fig_18", "figure_caption": "Figure 15 :15Figure 15: Top-level domain name distribution of pages in Google, MSN Search, and Yahoo! corpora (English pages only).", "figure_data": ""}, {"figure_label": "16", "figure_type": "figure", "figure_id": "fig_19", "figure_caption": "Figure 16 :16Figure 16: Percentage of inaccessible pages in the Google, MSN Search, and Yahoo! corpora (English pages only).", "figure_data": ""}, {"figure_label": "18", "figure_type": "figure", "figure_id": "fig_20", "figure_caption": "Figure 18 :18Figure 18: Text freshness of the Google, MSN Search, and Yahoo! corpora (English pages only).", "figure_data": ""}, {"figure_label": "19", "figure_type": "figure", "figure_id": "fig_22", "figure_caption": "Figure 19 :19Figure 19: Percentage of dynamic pages in the Google, MSN Search, and Yahoo! corpora (English pages only).", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_23", "figure_caption": ")P md (y, x) = \u03c0(x)(P (x, x)r md (x) + 1 \u2212 r md (x)) + y =x \u03c0(y)P (y, x)r md (y) = \u03c0(x)(1 \u2212 r md (x)) + y\u2208supp(\u03c0) \u03c0(y)P (y, x)r md (y) = \u03c0(x) \u2212 \u03c0(x)r md (x) + y\u2208supp(\u03c0) \u03c0(y)P (y, x)r md (y). Substituting r md (x) =p (x) C\u03c0(x) we get \u03c0(x)r md (x) = \u03c0(x)p (x) C\u03c0(x) = Zp CZ\u03c0 p(x), so the above can be further simplified to: y\u2208supp(\u03c0) \u03c0(y)P md (y, x) = \u03c0(x) \u2212 Zp CZ\u03c0 p(x) + Zp CZ\u03c0 y\u2208supp(\u03c0) p(y)P (y, x).", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_24", "figure_caption": "y\u2208supp(\u03c0) \u03c0(y)P md (y, x) = \u03c0(x). B Approximate Monte Carlo methods -Proofs B.1 Approximate rejection sampling", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_25", "figure_caption": "\u03c0\u2032 (x) = Pr(X = x|Z = 1). By Bayes rule, Pr(X = x|Z = 1) = Pr(Z = 1|X = x) \u2022 Pr(X = x) Pr(Z = 1) = r \u2032 rs (x) p(x) Pr(Z = 1) .", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_26", "figure_caption": "[\u03c0P ](y) = x\u2208U \u03c0(x)P (x, y) = x\u2208U \u03c0(y)P (y, x) = \u03c0(y).", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_27", "figure_caption": "CPool-based sampler -Proofs C.1 Analysis of sampling recall and sampling bias Theorem 21 (restated) The sampling recall of the PB sampler is equal to: recall \u03c0 (P + ) = \u03c0(D P + ).", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_28", "figure_caption": "deg P + (x) deg P + (D P + ) deg P (x) deg P (D P + ) = vdensity P (x) deg P (D P + ) deg P + (D P + ) .", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_29", "figure_caption": "q\u2208queries P + (x) 1 =1q\u2208P + x\u2208results(q) \u03c0 P + (x) deg P (x) = q\u2208P + w P (q) = w P (P + ) Since underflowing queries in P have zero weight, then w P (P + ) = 1 \u2212 w P (P \u2212 ) = 1 \u2212 Pr w P (Q \u2208 P \u2212 ) = 1 \u2212 Pr w P (card(Q) > k) = 1 \u2212 ovprob(w P ).", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_30", "figure_caption": "deg P (D P + ) Z\u03c0 \u2022 \u03c0(D P + ) \u2022 deg P (D P + ) deg P + (D P + ) \u2022 (1 \u2212 ovprob(w P )) = C \u2022 deg P + (D P + ) Z\u03c0 \u2022 \u03c0(D P + ) \u2022 (1 \u2212 ovprob(w P ))(4)", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_31", "figure_caption": "(T ) \u2022 (E(S) + qcost(\u03c0)) = C \u2022 deg P + (D P + ) Z\u03c0 \u2022 \u03c0(D P + ) \u2022 (1 \u2212 ovprob(w P )) \u2022 |P| |P + | \u2022 k avg q\u2208P + card(q)+ qcost(\u03c0) .", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_32", "figure_caption": "Now, for everyx \u2208 F , d F (x) q F (x) =deg P + (x) deg P + (F ) deg P (x) deg P (F ) = vdensity P (x) \u2022 deg P (F ) deg P + (F ) .", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_33", "figure_caption": "F(x) \u2022 vdensity P (x) E \u03c0 F (vdensity P (X)) \u2022 1 vdensity P (x) = 1 E \u03c0 F (vdensity P (X)) x\u2208F \u03c0 F (x)", "figure_data": ""}, {"figure_label": "36", "figure_type": "figure", "figure_id": "fig_34", "figure_caption": "Lemma 36 .36Let \u03c1 and \u03c1 \u2032 be two distributions on the same finite probability space U and let f : U \u2192 R be some real-valued function. Then,| E \u03c1 \u2032 (f (X)) \u2212 E \u03c1 (f (X))| \u2264 2\u03b5 \u2022 E u (|f (X)|) + |U | \u2022 cov u (|f (X)|, |\u03c1 \u2032 (X) \u2212 \u03c1(X)|),where \u03b5 \u2265 ||\u03c1 \u2212 \u03c1 \u2032 || and u is the uniform distribution on U.Proof.| E \u03c1 \u2032 (f (X)) \u2212 E \u03c1 (f (X))| = x\u2208U \u03c1 \u2032 (x)f (x) \u2212 x\u2208U \u03c1(x)f (x) = x\u2208U f (x)(\u03c1 \u2032 (x) \u2212 \u03c1(x)) \u2264 |U | \u2022 x\u2208U 1 |U | |f (x)| \u2022 |\u03c1 \u2032 (x) \u2212 \u03c1(x)| = |U | \u2022 E u (|f (X)| \u2022 |\u03c1 \u2032 (X) \u2212 \u03c1(X)|) = |U | \u2022 (E u (|f (X)|) \u2022 E u (|\u03c1 \u2032 (X) \u2212 \u03c1(X)|) + cov u (|f (X)|, |\u03c1 \u2032 (X) \u2212 \u03c1(X)|)).It is easy to see that|U | \u2022 E u (|\u03c1 \u2032 (X) \u2212 \u03c1(X)|) = 2||\u03c1 \u2032 \u2212 \u03c1|| \u2264 2\u03b5. So, | E \u03c1 \u2032 (f (X)) \u2212 E \u03c1 (f (X))| \u2264 2\u03b5 \u2022 E u (|f (X)|) + |U | \u2022 cov u (|f (X)|, |\u03c1 \u2032 (X) \u2212 \u03c1(X)|).", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "Results of pool parameter measurements.", "figure_data": ""}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "Pool parameter measurements on Yahoo!.", "figure_data": ""}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_7", "figure_caption": "Estimated bias, recall, and cost of the pool-based sampler.", "figure_data": ""}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_9", "figure_caption": "Number of samples generated by each sampler when run over the ODP search engine with the budget of 5 million queries.", "figure_data": ""}, {"figure_label": "5", "figure_type": "table", "figure_id": "tab_11", "figure_caption": "Relative overlap of Google, MSN Search, and Yahoo! (English pages only).", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_12", "figure_caption": "Figure 17: Raw HTML freshness of the Google, MSN Search, and Yahoo! corpora (English pages only).", "figure_data": "100%Percent of samples (cumulative)10% 20% 30% 40% 50% 60% 70% 80% 90%Google MSN Search Yahoo!0%0%20%40%60%80%100%Percent of lines changed100%Percent of samples (cumulative)10% 20% 30% 40% 50% 60% 70% 80% 90%Google MSN Search Yahoo!0%0%20%40%60%80%100%Percent of words changed"}], "formulas": [{"formula_id": "formula_0", "formula_text": "supp(p) = {x \u2208 U | p(x) > 0}.", "formula_coordinates": [7.0, 235.56, 188.26, 140.67, 18.89]}, {"formula_id": "formula_1", "formula_text": "p(E) = x\u2208E p(x).", "formula_coordinates": [7.0, 268.2, 252.1, 75.51, 23.37]}, {"formula_id": "formula_2", "formula_text": "f (X) = {x \u2208 U | f (X(x)) = 1}.", "formula_coordinates": [7.0, 233.4, 358.54, 145.11, 18.89]}, {"formula_id": "formula_3", "formula_text": "E p (X) = x\u2208U p(x) X(x).", "formula_coordinates": [7.0, 250.92, 429.58, 110.07, 23.49]}, {"formula_id": "formula_4", "formula_text": "var p (X) = E p ((X \u2212 E p (X)) 2 ) = E p (X 2 ) \u2212 (E p (X)) 2 .", "formula_coordinates": [7.0, 185.52, 486.14, 240.99, 21.01]}, {"formula_id": "formula_5", "formula_text": "\u03c3 p (X) = var p (X).", "formula_coordinates": [7.0, 259.8, 540.82, 92.43, 11.58]}, {"formula_id": "formula_6", "formula_text": "dev p (X) = E p (|X \u2212 E p (x)|).", "formula_coordinates": [7.0, 240.96, 593.5, 129.99, 18.89]}, {"formula_id": "formula_7", "formula_text": "ndev p (X) = dev p (X) E p (X) .", "formula_coordinates": [8.0, 254.76, 92.62, 102.51, 26.46]}, {"formula_id": "formula_8", "formula_text": "cov p (X, Y) = E p (XY) \u2212 E p (X) E p (Y).", "formula_coordinates": [8.0, 217.32, 146.26, 177.27, 18.89]}, {"formula_id": "formula_9", "formula_text": "avg x\u2208D g(x) = 1 |D| x\u2208D g(x)", "formula_coordinates": [8.0, 240.12, 183.34, 126.92, 33.53]}, {"formula_id": "formula_10", "formula_text": "||p \u2212 q|| = 1 2 x\u2208U |p(x) \u2212 q(x)|.", "formula_coordinates": [8.0, 235.92, 321.58, 140.07, 30.81]}, {"formula_id": "formula_11", "formula_text": "||p \u2212 q|| = max E\u2286U |p(E) \u2212 q(E)|.", "formula_coordinates": [8.0, 237.72, 431.98, 136.47, 18.89]}, {"formula_id": "formula_12", "formula_text": "E( T i=1 X i ) = \u00b5 E(T).", "formula_coordinates": [8.0, 258.84, 633.67, 94.35, 34.16]}, {"formula_id": "formula_13", "formula_text": "C \u2265 max x\u2208supp(p)\u03c0 (x) p(x)", "formula_coordinates": [9.0, 261.24, 631.54, 84.77, 25.97]}, {"formula_id": "formula_14", "formula_text": "w(x) =\u03c0 (x) p(x)", "formula_coordinates": [11.0, 274.44, 97.54, 58.37, 25.79]}, {"formula_id": "formula_15", "formula_text": "\u00b5 = 1 n n i=1 f (X i )w(X i ) 1 n n i=1 w(X i )", "formula_coordinates": [11.0, 246.96, 178.47, 113.92, 32.28]}, {"formula_id": "formula_16", "formula_text": "X i := getSample p () 4: w(X i ) :=\u03c0 (Xi) p(Xi) 5: compute f (X i ) 6: output 1 n n i=1 f (Xi)w(Xi) 1 n n i=1 w(Xi)", "formula_coordinates": [11.0, 223.92, 255.33, 122.15, 68.49]}, {"formula_id": "formula_17", "formula_text": "||p t \u2212 p|| t\u2192\u221e \u2212\u2192 0.", "formula_coordinates": [12.0, 268.68, 308.31, 74.55, 22.2]}, {"formula_id": "formula_18", "formula_text": "pP = p.", "formula_coordinates": [12.0, 287.51, 360.1, 36.99, 10.91]}, {"formula_id": "formula_19", "formula_text": "r mh (x, y) = min \u03c0(y) P (y, x) \u03c0(x) P (x, y) , 1 .", "formula_coordinates": [13.0, 220.44, 521.86, 171.03, 25.67]}, {"formula_id": "formula_20", "formula_text": "P mh (x, y) = P (x, y) r mh (x, y), if x = y, P (x, x) r mh (x, x) + 1 \u2212 z\u2208U P (x, z) r mh (x, z), if x = y.", "formula_coordinates": [13.0, 129.0, 620.74, 347.93, 32.21]}, {"formula_id": "formula_21", "formula_text": "C \u2265 max x\u2208Up (x) \u03c0(x)", "formula_coordinates": [14.0, 265.68, 154.54, 76.37, 25.97]}, {"formula_id": "formula_22", "formula_text": "r md (x) =p (x) C\u03c0(x)", "formula_coordinates": [14.0, 264.24, 269.74, 79.37, 25.79]}, {"formula_id": "formula_23", "formula_text": "P md (x, y) = P (x, y) r md (x), if x = y, P (x, x) r md (x) + 1 \u2212 r md (x), if x = y.", "formula_coordinates": [14.0, 171.72, 449.5, 262.49, 32.21]}, {"formula_id": "formula_24", "formula_text": "1 | \u2265 |\u03bb 2 | \u2265 \u2022 \u2022 \u2022 \u2265 |\u03bb n |).", "formula_coordinates": [15.0, 134.88, 635.38, 108.51, 18.89]}, {"formula_id": "formula_25", "formula_text": "\u03b1(P ) = |\u03bb 1 | \u2212 |\u03bb 2 | = 1 \u2212 |\u03bb 2 |.", "formula_coordinates": [15.0, 236.16, 673.42, 139.71, 18.89]}, {"formula_id": "formula_26", "formula_text": "|p t (x) \u2212 p(x)| \u2264 p(x) p min \u2022 (1 \u2212 \u03b1(P )) t ,", "formula_coordinates": [16.0, 218.64, 154.54, 174.75, 26.61]}, {"formula_id": "formula_27", "formula_text": "T \u03b5 (P ) \u2264 1 \u03b1(P ) ln 1 p min + ln 1 \u03b5 .", "formula_coordinates": [16.0, 227.52, 301.54, 156.99, 26.73]}, {"formula_id": "formula_28", "formula_text": "||p \u2212 p t || = 1 2 x\u2208U |p(x) \u2212 p t (x)| \u2264 1 2 x\u2208U p(x) p min \u2022 (1 \u2212 \u03b1(P )) t (By Theorem 6) \u2264 (1 \u2212 \u03b1(P )) t 2 \u2022 \u221a p min \u2022 |U | (Cauchy-Schwartz) \u2264 (1 \u2212 \u03b1(P )) t 2 \u2022 p min (Using the fact p min \u2264 1/|U |).", "formula_coordinates": [16.0, 164.04, 365.14, 283.84, 139.61]}, {"formula_id": "formula_29", "formula_text": "t \u2265 ln 1 \u03b5 + ln 1 p min \u2212 ln 2 ln 1 1\u2212\u03b1(P ) .", "formula_coordinates": [16.0, 248.64, 530.3, 114.63, 34.01]}, {"formula_id": "formula_30", "formula_text": "r \u2032 rs (x) =\u03c0 (x) Cq(x) ,", "formula_coordinates": [18.0, 266.16, 226.18, 79.71, 25.79]}, {"formula_id": "formula_31", "formula_text": "C \u2265 max x\u2208supp(p)\u03c0 (x) q(x)", "formula_coordinates": [18.0, 103.56, 263.9, 100.97, 21.85]}, {"formula_id": "formula_32", "formula_text": "\u03c0 \u2032 (x) = \u03c0(x) p(x) q(x) E \u03c0 p(X) q(X)", "formula_coordinates": [18.0, 244.92, 346.47, 110.21, 38.16]}, {"formula_id": "formula_33", "formula_text": "CZq Z\u03c0 E \u03c0 p(X) q(X)", "formula_coordinates": [18.0, 271.44, 419.74, 58.37, 32.7]}, {"formula_id": "formula_34", "formula_text": "Proposition 9. ||\u03c0 \u2032 \u2212 \u03c0|| = 1 2 ndev \u03c0 p(X) q(X) .", "formula_coordinates": [18.0, 72.0, 535.66, 304.71, 37.61]}, {"formula_id": "formula_35", "formula_text": "supp(\u03c0) \u2286 supp(p) \u2286 supp(q).", "formula_coordinates": [18.0, 234.84, 662.38, 142.23, 18.89]}, {"formula_id": "formula_36", "formula_text": "w \u2032 (x) =\u03c0 (x) q(x)", "formula_coordinates": [19.0, 273.0, 110.62, 61.13, 25.79]}, {"formula_id": "formula_37", "formula_text": "Theorem 10. Let\u03bc \u2032 = A B = 1 n n i=1 f (X i )w \u2032 (X i ) 1 n n i=1", "formula_coordinates": [19.0, 72.0, 205.18, 305.56, 40.26]}, {"formula_id": "formula_38", "formula_text": "E p (A) E p (B) = E \u03c0 (f (X)) + cov \u03c0 f (X), p(X) q(X) E \u03c0 p(X) q(X)", "formula_coordinates": [19.0, 210.84, 277.59, 179.57, 39.36]}, {"formula_id": "formula_39", "formula_text": "Ep(A) Ep(B)", "formula_coordinates": [19.0, 516.24, 336.06, 22.61, 16.93]}, {"formula_id": "formula_40", "formula_text": "| E 1 n n i=1 A i 1 n n i=1 B i \u2212 I| \u2264 1 n \u2022 C,", "formula_coordinates": [19.0, 228.96, 412.23, 154.11, 32.4]}, {"formula_id": "formula_41", "formula_text": "C = I \u2022 var(B) E 2 (B) + | cov(A,B)| E 2 (B) + o(1).", "formula_coordinates": [19.0, 102.84, 456.5, 154.43, 21.85]}, {"formula_id": "formula_42", "formula_text": "r mh (x, y) = min \u03c0(y) P (y, x) \u03c0(x) P (x, y) , 1 = min \u03c0(y) p(x) \u03c0(x) p(y) , 1 .", "formula_coordinates": [19.0, 154.8, 666.46, 302.43, 25.79]}, {"formula_id": "formula_43", "formula_text": "r \u2032 mh (x, y) = min \u03c0(y) q(x) \u03c0(x) q(y) , 1 .", "formula_coordinates": [20.0, 222.84, 108.94, 166.35, 25.79]}, {"formula_id": "formula_44", "formula_text": "\u03c0 \u2032 (x) = \u03c0(x) \u2022 p(x) q(x) / E \u03c0 p(X) q(X) .", "formula_coordinates": [20.0, 337.2, 195.27, 149.55, 21.36]}, {"formula_id": "formula_45", "formula_text": "r \u2032 md (x) =q (x) C\u03c0(x)", "formula_coordinates": [20.0, 197.16, 411.58, 86.69, 25.79]}, {"formula_id": "formula_46", "formula_text": "C \u2265 max x\u2208Uq (x) \u03c0(x)", "formula_coordinates": [20.0, 343.32, 411.58, 67.25, 26.09]}, {"formula_id": "formula_47", "formula_text": "\u03c0 \u2032 (x) = \u03c0(x) \u2022 p(x) q(x) / E \u03c0 p(X) q(X) .", "formula_coordinates": [20.0, 359.28, 463.35, 149.55, 21.48]}, {"formula_id": "formula_48", "formula_text": "\u03c0 supp(\u03b7) (x) = \u03c0(x) \u03c0(supp(\u03b7))", "formula_coordinates": [22.0, 208.32, 215.86, 117.05, 25.79]}, {"formula_id": "formula_49", "formula_text": "||\u03b7 \u2212 \u03c0 supp(\u03b7) || = 1 2 x\u2208supp(\u03b7) |\u03b7(x) \u2212 \u03c0(x) \u03c0(supp(\u03b7)) |.", "formula_coordinates": [22.0, 192.0, 272.86, 228.03, 31.29]}, {"formula_id": "formula_50", "formula_text": "P = {[Java software], [\"Michael Jordan\" -basketball], [Car OR Automobile]},", "formula_coordinates": [22.0, 121.44, 587.26, 369.03, 18.89]}, {"formula_id": "formula_51", "formula_text": "card(P \u2032 ) = q\u2208P \u2032 card(q).", "formula_coordinates": [23.0, 249.0, 159.38, 114.03, 25.85]}, {"formula_id": "formula_52", "formula_text": "deg P (D \u2032 ) = x\u2208D \u2032 deg P (x).", "formula_coordinates": [23.0, 245.76, 268.94, 120.39, 25.97]}, {"formula_id": "formula_53", "formula_text": "ovprob(\u03c6) = Pr \u03c6 (card(Q) > k).", "formula_coordinates": [23.0, 234.12, 610.78, 143.67, 17.33]}, {"formula_id": "formula_54", "formula_text": "deg P (x) = |queries P (x)| = |{q \u2208 P | x \u2208 results(q)}|.", "formula_coordinates": [27.0, 183.48, 278.86, 244.83, 18.89]}, {"formula_id": "formula_55", "formula_text": "d P (x) = deg P (x) deg P (D) .", "formula_coordinates": [27.0, 262.08, 325.9, 87.75, 27.57]}, {"formula_id": "formula_56", "formula_text": "d P (x) = deg P (x).", "formula_coordinates": [27.0, 264.84, 401.02, 82.35, 12.81]}, {"formula_id": "formula_57", "formula_text": "C deg P (X)", "formula_coordinates": [27.0, 370.44, 564.77, 37.55, 7.31]}, {"formula_id": "formula_58", "formula_text": "C \u2265 max x\u2208D P\u03c0 (x) deg P (x)", "formula_coordinates": [28.0, 261.96, 106.78, 86.93, 27.69]}, {"formula_id": "formula_59", "formula_text": "recall \u03c0 (P) = \u03c0(D P )", "formula_coordinates": [28.0, 259.32, 255.94, 93.28, 11.85]}, {"formula_id": "formula_60", "formula_text": "recall \u03c0 (P B) = \u03c0(supp(\u03b7)) = \u03c0(D P \u2229 supp(\u03c0)) = \u03c0(D P ) = recall \u03c0 (P).", "formula_coordinates": [28.0, 126.0, 462.58, 359.79, 18.89]}, {"formula_id": "formula_61", "formula_text": "Z\u03c0 supp(\u03b7) = Z\u03c0 \u2022 \u03c0(D P ).", "formula_coordinates": [28.0, 252.36, 551.98, 107.31, 18.89]}, {"formula_id": "formula_62", "formula_text": "\u03c0 supp(\u03b7) (x) = \u03c0(x) \u03c0(supp(\u03b7)) =\u03c0 (x) Z\u03c0 \u2022 \u03c0(D P \u2229 supp(\u03c0)) =\u03c0 (x) Z\u03c0 \u2022 \u03c0(D P ) =\u03c0 (x) Z\u03c0 supp(\u03b7)", "formula_coordinates": [28.0, 124.44, 592.06, 357.96, 33.53]}, {"formula_id": "formula_63", "formula_text": "c P (q) = card(q) card(P) .", "formula_coordinates": [29.0, 264.24, 215.5, 83.55, 25.67]}, {"formula_id": "formula_64", "formula_text": "p(x) = Pr p (X = x) = q\u2208P Pr p,c P (X = x|Q = q) \u2022 Pr c P (Q = q).", "formula_coordinates": [29.0, 166.32, 642.34, 279.39, 23.62]}, {"formula_id": "formula_65", "formula_text": "vdensity P (x) = deg P + (x) deg P (x) .", "formula_coordinates": [30.0, 243.72, 568.18, 124.47, 29.01]}, {"formula_id": "formula_66", "formula_text": "recall \u03c0 (P + ) = \u03c0(D P + ).", "formula_coordinates": [31.0, 252.0, 99.34, 107.91, 12.44]}, {"formula_id": "formula_67", "formula_text": "1 2 ndev \u03c0 P + (vdensity P (X)),", "formula_coordinates": [31.0, 244.8, 144.94, 123.51, 25.79]}, {"formula_id": "formula_68", "formula_text": "w P (q) =", "formula_coordinates": [31.0, 235.2, 397.3, 44.25, 11.85]}, {"formula_id": "formula_69", "formula_text": "\u03c0 P + (x) deg P (x) .", "formula_coordinates": [31.0, 334.8, 389.38, 42.03, 28.17]}, {"formula_id": "formula_70", "formula_text": "w P (P) = q\u2208P w P (q) = x\u2208D \u03c0 P + (x) = 1.", "formula_coordinates": [31.0, 201.6, 482.5, 208.71, 23.37]}, {"formula_id": "formula_71", "formula_text": "ovprob(w P ) 1 \u2212 ovprob(w P )", "formula_coordinates": [31.0, 267.0, 576.22, 74.92, 33.53]}, {"formula_id": "formula_72", "formula_text": "c P + (q) = card(q), if card(q) \u2264 k, 0, if card(q) > k.", "formula_coordinates": [32.0, 215.16, 200.86, 470.34, 24.71]}, {"formula_id": "formula_73", "formula_text": "max q\u2208P\u0109 P + (q) u P (q) \u2264 k,", "formula_coordinates": [33.0, 266.16, 95.38, 79.6, 27.09]}, {"formula_id": "formula_74", "formula_text": "C \u2022 deg P + (D P + ) Z\u03c0 \u2022 \u03c0(D P + ) \u2022 (1 \u2212 ovprob(w P )) \u2022 |P| |P + | \u2022 k avg q\u2208P + card(q) + qcost(\u03c0) .", "formula_coordinates": [33.0, 136.32, 274.9, 340.47, 35.22]}, {"formula_id": "formula_75", "formula_text": "C \u2022 deg P + (D P + ) Z\u03c0 \u2022 \u03c0(D P + ) \u2022 (1 \u2212 ovprob(w P )) \u2022 (1 + fcost(\u03c0)).", "formula_coordinates": [33.0, 194.16, 340.06, 224.79, 35.09]}, {"formula_id": "formula_76", "formula_text": "C \u2022 deg P + (D P + ) Z\u03c0 \u2022 \u03c0(D P + ) = deg P + (D P + ) |D P + | = avg x\u2208D P + deg P + (x).", "formula_coordinates": [33.0, 168.6, 471.1, 275.91, 35.21]}, {"formula_id": "formula_77", "formula_text": "avg x\u2208D P + deg P + (x) \u2022 1 1 \u2212 ovprob(w P ) \u2022 |P| |P + | \u2022 k avg q\u2208P + card(q)", "formula_coordinates": [33.0, 158.04, 527.62, 291.77, 33.77]}, {"formula_id": "formula_78", "formula_text": "avg x\u2208D P + deg P + (x) \u2022 1 1 \u2212 ovprob(w P )", "formula_coordinates": [33.0, 216.6, 664.3, 174.64, 33.53]}, {"formula_id": "formula_79", "formula_text": "deg G P (x) = y\u2208D weight P (x, y).", "formula_coordinates": [35.0, 229.8, 479.26, 152.31, 23.5]}, {"formula_id": "formula_80", "formula_text": "Proposition 25. For every document x \u2208 D, deg G P (x) = |queries P (x)| = deg P (x).", "formula_coordinates": [35.0, 72.0, 550.54, 319.35, 43.37]}, {"formula_id": "formula_81", "formula_text": "deg G P (x) =", "formula_coordinates": [36.0, 191.16, 100.3, 62.61, 13.43]}, {"formula_id": "formula_82", "formula_text": "q\u2208P 1 card(q) y\u2208D A(x, y, q) = q\u2208queries P (x) 1 card(q)", "formula_coordinates": [36.0, 94.8, 278.74, 233.33, 32.75]}, {"formula_id": "formula_83", "formula_text": "deg P + (x) .", "formula_coordinates": [36.0, 306.84, 433.78, 59.91, 20.84]}, {"formula_id": "formula_84", "formula_text": "weight P + (X,Y) deg P + (X)", "formula_coordinates": [36.0, 126.6, 587.66, 57.41, 23.31]}, {"formula_id": "formula_85", "formula_text": "x\u2208D P + deg P + (x) \u03c0(x)", "formula_coordinates": [37.0, 279.6, 116.5, 72.18, 28.88]}, {"formula_id": "formula_86", "formula_text": "\u03c0 F (x) = \u03c0(x) \u03c0(F ) , for all x \u2208 F .", "formula_coordinates": [37.0, 229.2, 520.42, 153.63, 25.97]}, {"formula_id": "formula_87", "formula_text": "\u03b1(P md ) \u2265 1 20, 000 , \u03b1(P mh ) \u2265 1 20, 000", "formula_coordinates": [38.0, 211.8, 195.1, 183.89, 26.09]}, {"formula_id": "formula_88", "formula_text": "G P + , Pr(Y = y) = weight P + (x, y) deg P + (x) .", "formula_coordinates": [39.0, 72.0, 74.74, 301.59, 42.44]}, {"formula_id": "formula_89", "formula_text": "q\u2208queries P + (x)", "formula_coordinates": [39.0, 242.4, 189.26, 57.41, 11.31]}, {"formula_id": "formula_90", "formula_text": "1", "formula_coordinates": [39.0, 213.48, 226.7, 4.23, 7.97]}, {"formula_id": "formula_91", "formula_text": "|queries P + (x)| = 1 deg P + (", "formula_coordinates": [39.0, 189.48, 226.7, 97.38, 19.47]}, {"formula_id": "formula_92", "formula_text": "q\u2208queries P + (x) Pr(Y = y|Q = q) \u2022 Pr(Q = q) = q\u2208queries P + (x)\u2229queries P + (y) 1 card(q) \u2022 1 deg P + (x) = weight P + (x, y) deg P + (x) .", "formula_coordinates": [39.0, 190.32, 258.82, 230.21, 99.56]}, {"formula_id": "formula_93", "formula_text": "r mh (x, y) = min \u03c0(y) deg P + (x) \u03c0(x) deg P + (y) , 1 .", "formula_coordinates": [39.0, 209.52, 488.14, 192.99, 29.6]}, {"formula_id": "formula_94", "formula_text": "r md (x) = deg P + (x) C\u03c0(x)", "formula_coordinates": [39.0, 176.76, 548.98, 96.89, 27.23]}, {"formula_id": "formula_95", "formula_text": "x\u2208D P + deg P + (x) \u03c0(x) .", "formula_coordinates": [39.0, 356.16, 548.98, 78.99, 28.88]}, {"formula_id": "formula_96", "formula_text": "r \u2032 mh (x, y) = min \u03c0(y) deg P (x) \u03c0(x) deg P (y) , 1 and r \u2032 md (x) = deg P (x) C \u2032\u03c0 (x)", "formula_coordinates": [39.0, 72.0, 622.9, 316.61, 70.67]}, {"formula_id": "formula_97", "formula_text": "x\u2208D P + deg P (x) \u03c0(x) .", "formula_coordinates": [39.0, 357.6, 667.78, 73.59, 27.44]}, {"formula_id": "formula_98", "formula_text": "d F (x) = d P + (x) d P + (F ) , for all x \u2208 F .(1)", "formula_coordinates": [40.0, 223.68, 266.26, 316.24, 27.68]}, {"formula_id": "formula_99", "formula_text": "q F (x) = d P (x) d P (F )", "formula_coordinates": [40.0, 226.8, 443.86, 78.88, 26.73]}, {"formula_id": "formula_100", "formula_text": "\u03b7(x) = \u03c0 F (x) d F (x) q F (x) E \u03c0 F d F (X) q F (X)", "formula_coordinates": [40.0, 240.72, 586.46, 118.61, 39.3]}, {"formula_id": "formula_101", "formula_text": ")2", "formula_coordinates": [40.0, 530.69, 599.74, 9.23, 10.91]}, {"formula_id": "formula_102", "formula_text": "1 2 ndev \u03c0 F (vdensity P (X)) + \u03b5.", "formula_coordinates": [41.0, 238.44, 110.02, 136.23, 25.79]}, {"formula_id": "formula_103", "formula_text": "\u03c0(F ) \u2022 (1 \u2212 1 2 ndev \u03c0 F (vdensity P (X)) \u2212 \u03b5).", "formula_coordinates": [41.0, 207.84, 166.78, 196.23, 25.97]}, {"formula_id": "formula_104", "formula_text": "deg P (x) C \u2032\u03c0 (x)", "formula_coordinates": [41.0, 473.52, 471.77, 28.31, 15.37]}, {"formula_id": "formula_105", "formula_text": "|queries P (x)| |queries P + (x)| = deg P (x) deg P + (x) = 1 vdensity P (x)", "formula_coordinates": [42.0, 195.84, 233.74, 217.25, 33.77]}, {"formula_id": "formula_106", "formula_text": "1 vdensity P (x) + qcost(\u03c0).", "formula_coordinates": [42.0, 247.32, 326.5, 118.47, 27.57]}, {"formula_id": "formula_107", "formula_text": "max x\u2208F deg P (x) + qcost(\u03c0).", "formula_coordinates": [42.0, 247.8, 572.86, 116.43, 16.93]}, {"formula_id": "formula_108", "formula_text": "max x\u2208supp(\u03b7t) 1 vdensity P (x) + qcost(\u03c0) \u2264 max x\u2208F deg P (x) deg P + (x) +qcost(\u03c0) \u2264 max x\u2208F deg P (x)+qcost(\u03c0).", "formula_coordinates": [42.0, 72.0, 642.58, 467.91, 28.16]}, {"formula_id": "formula_109", "formula_text": "1 E \u03c0 F (vdensity P (X)) + 3\u03b5 t |F | \u2022 E u F 1 vdensity 2 P (X) + qcost(\u03c0).", "formula_coordinates": [43.0, 150.84, 150.7, 311.43, 28.65]}, {"formula_id": "formula_110", "formula_text": "\u03b5 t = (1 \u2212 \u03b1) t \u03b7 min ,", "formula_coordinates": [43.0, 272.76, 281.31, 66.51, 28.0]}, {"formula_id": "formula_111", "formula_text": "t \u2265 \u2126 log 1 \u03b7 min + log |F | + log E u F 1 vdensity 2 (X)", "formula_coordinates": [43.0, 175.56, 361.78, 238.72, 26.73]}, {"formula_id": "formula_112", "formula_text": "C \u2032\u03c0 (x) deg P (x) .", "formula_coordinates": [44.0, 285.96, 189.26, 41.31, 29.45]}, {"formula_id": "formula_113", "formula_text": "deg P (x) C \u2032\u03c0 (x) .", "formula_coordinates": [44.0, 209.28, 243.38, 34.35, 17.33]}, {"formula_id": "formula_114", "formula_text": "C \u2032 \u2022 Z\u03c0 F \u2022 \u03c0(F ) \u2022 E \u03c0 F (vdensity P (X)) deg P + (F ) \u2212 3\u03b5 t \u2022 E u F \u03c0 2 F (X) deg 2 P (X) .", "formula_coordinates": [44.0, 146.88, 538.58, 318.27, 30.53]}, {"formula_id": "formula_115", "formula_text": "\u03b5 t = (1 \u2212 \u03b1) t d F min ,", "formula_coordinates": [45.0, 272.76, 98.43, 66.51, 28.6]}, {"formula_id": "formula_116", "formula_text": "d F min = min x\u2208F d F (x).", "formula_coordinates": [45.0, 433.08, 132.58, 109.47, 12.33]}, {"formula_id": "formula_117", "formula_text": "t \u2265 \u2126 log 1 d F min + log |F | + log E u F \u03c0 2 F (X) deg 2 P (X)", "formula_coordinates": [45.0, 182.4, 174.74, 225.04, 30.53]}, {"formula_id": "formula_118", "formula_text": "C \u2032 \u2022 Z\u03c0 F \u2022 \u03c0(F ) \u2022 E \u03c0 F (vdensity P (X))/ deg P + (F ).", "formula_coordinates": [45.0, 303.96, 213.62, 224.67, 20.41]}, {"formula_id": "formula_119", "formula_text": "1 + max x\u2208F deg P (x)|F | deg P + (F ) E u F (vdensity P (X)) = 1 + max x\u2208F deg P (x) avg x\u2208F deg P (x)", "formula_coordinates": [45.0, 92.28, 285.82, 324.53, 28.52]}, {"formula_id": "formula_121", "formula_text": "\u03b1(P md ) \u2265 1 20, 000 , \u03b1(P mh ) \u2265 1 20, 000", "formula_coordinates": [49.0, 211.8, 303.22, 183.89, 26.09]}, {"formula_id": "formula_122", "formula_text": "T \u03b5 (P mh ) = T \u03b5 (P md ) \u2264 1 \u03b1(T ) ln 1 \u03c0 min + ln 1 \u03b5 \u2248 520, 000.", "formula_coordinates": [49.0, 171.24, 430.06, 269.07, 26.61]}, {"formula_id": "formula_123", "formula_text": "0.0% 0.5% 1.0% 1.5% 2.0% 2.5% Google MSN Search Yahoo!", "formula_coordinates": [56.0, 205.94, 190.57, 202.21, 136.81]}, {"formula_id": "formula_124", "formula_text": "\u03c0 \u2032 (x) = \u03c0(x) p(x) q(x) E \u03c0 p(X) q(X)", "formula_coordinates": [63.0, 244.92, 157.59, 110.21, 38.16]}, {"formula_id": "formula_125", "formula_text": "CZq Z\u03c0 E \u03c0 p(X) q(X)", "formula_coordinates": [63.0, 271.44, 225.58, 58.37, 32.7]}, {"formula_id": "formula_126", "formula_text": "Pr(Z = 1) = y\u2208supp(\u03c0) Pr(Z = 1|X = y) \u2022 Pr(X = y) = y\u2208supp(\u03c0) r \u2032 rs (y) p(y).", "formula_coordinates": [63.0, 123.12, 460.34, 365.67, 26.21]}, {"formula_id": "formula_127", "formula_text": "Pr(X = x|Z = 1) = r \u2032 rs (x) p(x) y\u2208supp(\u03c0) r \u2032 rs (y) p(y)", "formula_coordinates": [63.0, 200.88, 508.1, 205.97, 29.93]}, {"formula_id": "formula_128", "formula_text": "\u03c0 \u2032 (x) = Pr(X = x|Z = 1) =\u03c0 (x) Cq(x) p(x) y\u2208supp(\u03c0)\u03c0 (y) Cq(y) p(y) = \u03c0(x)Z\u03c0 Cq(x)Zq p(x) y\u2208supp(\u03c0) \u03c0(y)Z\u03c0 Cq(y)Zq p(y) = \u03c0(x) p(x) q(x) y\u2208supp(\u03c0) \u03c0(y) p(y) q(y) = \u03c0(x) p(x) q(x) E \u03c0 p(X) q(X)", "formula_coordinates": [63.0, 111.0, 568.11, 388.73, 80.76]}, {"formula_id": "formula_129", "formula_text": "Pr(Z = 1) = y\u2208supp(\u03c0) r \u2032 rs (y) p(y) = y\u2208supp(\u03c0) \u03c0(y)Z\u03c0 Cq(y)Zq p(y) = Z\u03c0 CZq \u2022 y\u2208supp(\u03c0) \u03c0(y) p(y) q(y) = Z\u03c0 CZq \u2022 E \u03c0 p(X) q(X) .", "formula_coordinates": [64.0, 156.72, 122.98, 298.49, 99.17]}, {"formula_id": "formula_130", "formula_text": "||\u03c0 \u2032 \u2212 \u03c0|| = 1 2 ndev \u03c0 p(X) q(X) .", "formula_coordinates": [64.0, 235.32, 276.1, 141.39, 26.09]}, {"formula_id": "formula_131", "formula_text": "||\u03c0 \u2032 \u2212 \u03c0|| = 1 2 x\u2208supp(\u03c0) \u03c0 \u2032 (x) \u2212 \u03c0(x) = 1 2 x\u2208supp(\u03c0) \u03c0(x) p(x) q(x) E \u03c0 p(X) q(X) \u2212 \u03c0(x) = 1 2 \u2022 1 E \u03c0 p(X) q(X) \u2022 x\u2208supp(\u03c0) \u03c0(x) p(x) q(x) \u2212 E \u03c0 p(X) q(X) = 1 2 \u2022 1 E \u03c0 p(X) q(X)", "formula_coordinates": [64.0, 117.12, 340.71, 372.29, 114.61]}, {"formula_id": "formula_132", "formula_text": "\u2032 = A B = 1 n n i=1 f (X i )w \u2032 (X i ) 1 n n i=1", "formula_coordinates": [64.0, 239.76, 581.55, 137.8, 32.28]}, {"formula_id": "formula_133", "formula_text": "E p (A) E p (B) = E \u03c0 (f (X)) + cov \u03c0 f (X), p(X) q(X) E \u03c0 p(X) q(X)", "formula_coordinates": [64.0, 210.84, 649.35, 179.57, 39.24]}, {"formula_id": "formula_134", "formula_text": "E p (f (X)w \u2032 (X)) = x\u2208U p(x) f (x)\u03c0 (x) q(x) = Z\u03c0 Zq x\u2208U \u03c0(x) f (X) p(x) q(x) = Z\u03c0 Zq E \u03c0 f (X) p(X) q(X) . E p (w \u2032 (X)) = x\u2208U p(x)\u03c0 (x) q(x) = Z\u03c0 Zq x\u2208U \u03c0(x) p(x) q(x) = Z\u03c0 Zq E \u03c0 p(X) q(X) .", "formula_coordinates": [65.0, 183.6, 127.66, 243.65, 185.51]}, {"formula_id": "formula_135", "formula_text": "E p (A) E p (B) = E p (f (X)w \u2032 (X)) E p (w \u2032 (X)) = Z\u03c0 Zq \u2022 E \u03c0 f (X) p(X) q(X) Z\u03c0 Zq \u2022 E \u03c0 p(X) q(X) = cov \u03c0 f (X), p(X) q(X) + E \u03c0 (f (X)) E \u03c0 p(X) q(X) E \u03c0 p(X) q(X) = E \u03c0 (f (X)) + cov \u03c0 f (X), p(X) q(X) E \u03c0 p(X) q(X)", "formula_coordinates": [65.0, 178.92, 352.83, 246.53, 132.01]}, {"formula_id": "formula_136", "formula_text": "P \u2032 mh (x, y) = P (x, y) r \u2032 mh (x, y), if x = y, P (x, x) r \u2032 mh (x, x) + 1 \u2212 z\u2208U P (x, z) r \u2032 mh (x, z), if x = y, where r \u2032 mh (x, y) = min \u03c0(y) q(x) \u03c0(x) q(y) , 1 .", "formula_coordinates": [65.0, 72.0, 622.94, 404.93, 72.55]}, {"formula_id": "formula_137", "formula_text": "\u03c0 \u2032 (x)P \u2032 mh (x, y) = \u03c0 \u2032 (x)P (x, y)r \u2032 mh (x, y) = \u03c0(x) p(x) q(x) E \u03c0 p(X) q(X) P (x, y) min \u03c0(y) q(x) \u03c0(x) q(y) , 1 = 1 E \u03c0 p(X) q(X) p(x)P (x, y) \u03c0(x) q(x) min \u03c0(y) q(x) \u03c0(x) q(y) , 1 = 1 E \u03c0 p(X) q(X) p(y)P (y, x) \u03c0(x) q(x) min \u03c0(y) q(x) \u03c0(x) q(y) , 1 (Since P is reversible) = 1 E \u03c0 p(X) q(X) p(y)P (y, x) \u03c0(y) q(y) min \u03c0(y) q(x) \u03c0(x) q(y) \u03c0(x) q(y) q(x) \u03c0(y) , \u03c0(x) q(y) q(x) \u03c0(y) = \u03c0(y) p(y) q(y) E \u03c0 p(X) q(X) P (y, x) min 1, \u03c0(x) q(y) \u03c0(y) q(x)", "formula_coordinates": [66.0, 118.8, 418.7, 374.32, 230.89]}, {"formula_id": "formula_138", "formula_text": "P \u2032 md (x, y) = P (x, y) r \u2032 md (x), if x = y, P (x, x) r \u2032 md (x) + 1 \u2212 r \u2032 md (x), if x = y.", "formula_coordinates": [67.0, 171.72, 167.66, 262.47, 33.97]}, {"formula_id": "formula_139", "formula_text": "r \u2032 md (x) =q (x) C\u03c0(x)", "formula_coordinates": [67.0, 197.16, 215.74, 86.69, 25.79]}, {"formula_id": "formula_140", "formula_text": "C \u2265 max x\u2208Uq (x) \u03c0(x)", "formula_coordinates": [67.0, 343.32, 215.74, 67.25, 25.97]}, {"formula_id": "formula_141", "formula_text": "\u03c0 \u2032 (x)P \u2032 md (x, y) = \u03c0 \u2032 (x)P (x, y)r \u2032 md (x, y) = \u03c0(x) p(x) q(x) E \u03c0 p(X) q(X) P (x, y)q (x) C\u03c0(x) = 1 E \u03c0 p(X) q(X) p(x)P (x, y) Zq C Z\u03c0 = 1 E \u03c0 p(X) q(X) p(y)P (y, x) Zq C Z\u03c0 (Since P is reversible) = \u03c0(y) p(y) q(y) E \u03c0 p(X) q(X) P (y, x)q (y) C\u03c0(y) = \u03c0 \u2032 (y)P (y, x)r \u2032 md (y, x) = \u03c0 \u2032 (y)P \u2032 md (y, x).", "formula_coordinates": [67.0, 133.2, 393.98, 345.4, 191.73]}, {"formula_id": "formula_142", "formula_text": "1 2 ndev \u03c0 P + (vdensity P (X)),", "formula_coordinates": [68.0, 244.8, 204.7, 123.51, 25.67]}, {"formula_id": "formula_143", "formula_text": "q(x) = deg P (x) deg P (D P + )", "formula_coordinates": [68.0, 256.08, 514.42, 95.56, 27.69]}, {"formula_id": "formula_144", "formula_text": "||\u03b7 \u2212 \u03c0 P + || \u2264 1 2 ndev \u03c0 P + d P + (X) q(X) .", "formula_coordinates": [68.0, 215.28, 581.86, 181.47, 26.45]}, {"formula_id": "formula_145", "formula_text": "d P + (x) q(x) =", "formula_coordinates": [68.0, 175.44, 654.1, 48.81, 26.27]}, {"formula_id": "formula_146", "formula_text": "ovprob(w P ) 1 \u2212 ovprob(w P )", "formula_coordinates": [69.0, 267.0, 198.46, 74.92, 33.53]}, {"formula_id": "formula_147", "formula_text": "invdensity P (x) = 1 \u2212 vdensity P (x).", "formula_coordinates": [69.0, 218.52, 374.62, 174.87, 18.89]}, {"formula_id": "formula_148", "formula_text": "2\u00b5 = E \u03c0 P + (|1 \u2212 invdensity P (X) \u2212 \u00b5|) 2\u00b5 .", "formula_coordinates": [69.0, 211.32, 407.5, 246.75, 28.43]}, {"formula_id": "formula_149", "formula_text": "|1 \u2212 invdensity P (x) \u2212 \u00b5| \u2264 1 \u2212 \u00b5 + invdensity P (x) = 1 \u2212 \u00b5 + 1 \u2212 vdensity P (x).", "formula_coordinates": [69.0, 111.6, 462.1, 388.83, 18.89]}, {"formula_id": "formula_150", "formula_text": "E \u03c0 P + (|1 \u2212 invdensity P (X) \u2212 \u00b5|) 2\u00b5 \u2264 E \u03c0 P + (1 \u2212 \u00b5 + 1 \u2212 vdensity P (X)) 2\u00b5 = 1 \u2212 \u00b5 + 1 \u2212 E \u03c0 P + (vdensity P (X)) 2\u00b5 (3) = 1 \u2212 \u00b5 + 1 \u2212 \u00b5 2\u00b5 = 1 \u2212 \u00b5 \u00b5 .", "formula_coordinates": [69.0, 138.48, 503.02, 401.45, 87.95]}, {"formula_id": "formula_151", "formula_text": "x\u2208D P + \u03c0 P + (x) \u2022 deg P + (x) deg P (x) = x\u2208D P + \u03c0 P + (x) deg P (x)", "formula_coordinates": [69.0, 229.68, 622.18, 209.93, 34.88]}, {"formula_id": "formula_152", "formula_text": "C \u2022 deg P + (D P + ) Z\u03c0 \u2022 \u03c0(D P + ) \u2022 (1 \u2212 ovprob(w P )) \u2022 |P| |P + | \u2022 k avg q\u2208P + card(q) + qcost(\u03c0) .", "formula_coordinates": [70.0, 136.32, 293.62, 340.47, 35.09]}, {"formula_id": "formula_153", "formula_text": "C \u2022 deg P + (D P + ) Z\u03c0 \u2022 \u03c0(D P + ) \u2022 (1 \u2212 ovprob(w P ))", "formula_coordinates": [70.0, 194.16, 363.58, 148.24, 35.21]}, {"formula_id": "formula_154", "formula_text": "E(T ) = C \u2022 Zq Z\u03c0 P + \u2022 E \u03c0 P + d P + (X) q(X) = C \u2022", "formula_coordinates": [71.0, 174.72, 351.82, 148.85, 57.95]}, {"formula_id": "formula_155", "formula_text": "C = k.", "formula_coordinates": [71.0, 220.92, 580.06, 32.19, 10.91]}, {"formula_id": "formula_156", "formula_text": "E(S) = k \u2022 |P| card(P + ) = |P| |P + | \u2022 k avg q\u2208P + card(q) .(5)", "formula_coordinates": [71.0, 193.44, 631.78, 346.48, 33.77]}, {"formula_id": "formula_157", "formula_text": "C \u2022 deg P + (D P + ) Z\u03c0 \u2022 \u03c0(D P + ) \u2022 (1 \u2212 ovprob(w P ))", "formula_coordinates": [72.0, 194.16, 256.06, 148.24, 35.21]}, {"formula_id": "formula_158", "formula_text": "\u03c0(F ) \u2022 (1 \u2212 1 2 ndev \u03c0 F (vdensity P (X)) \u2212 \u03b5).", "formula_coordinates": [72.0, 207.84, 473.14, 196.23, 25.97]}, {"formula_id": "formula_159", "formula_text": "\u03b7(x) = \u03c0 F (x) d F (x) q F (x) E \u03c0 F d F (X) q F (X)", "formula_coordinates": [72.0, 240.72, 534.86, 118.61, 39.3]}, {"formula_id": "formula_160", "formula_text": "||\u03b7 \u2212 \u03c0 F || \u2264 1 2 ndev \u03c0 F d F (X) q F (X) .", "formula_coordinates": [72.0, 223.56, 602.86, 164.91, 26.46]}, {"formula_id": "formula_161", "formula_text": "||\u03b7 \u2032 \u2212 \u03c0 F || \u2264 1 2 ndev \u03c0 F (vdensity P (X)) + \u03b5.(6)", "formula_coordinates": [73.0, 202.68, 215.98, 337.24, 25.97]}, {"formula_id": "formula_162", "formula_text": "||\u03b7 \u2032 supp(\u03b7 \u2032 ) \u2212 \u03c0 supp(\u03b7 \u2032 ) || = 1 2 x\u2208supp(\u03b7 \u2032 ) \u03b7 \u2032 (x) \u2212 \u03c0(x) \u03c0(supp(\u03b7 \u2032 )) \u2264 1 2 x\u2208supp(\u03b7 \u2032 ) \u03b7 \u2032 (x) \u2212 \u03c0 F (x) + 1 2 x\u2208supp(\u03b7 \u2032 ) \u03c0 F (x) \u2212 \u03c0(x) \u03c0(supp(\u03b7 \u2032 ))(7)", "formula_coordinates": [73.0, 93.96, 269.5, 445.96, 68.01]}, {"formula_id": "formula_163", "formula_text": "x\u2208supp(\u03b7 \u2032 ) \u03b7 \u2032 (x) \u2212 \u03c0 F (x) = ||\u03b7 \u2032 \u2212 \u03c0 F || \u2212 1 2 x\u2208F \\supp(\u03b7 \u2032 ) \u03c0 F (x) = ||\u03b7 \u2032 \u2212 \u03c0 F || \u2212 1 2 (1 \u2212 \u03c0 F (supp(\u03b7 \u2032 ))). (8", "formula_coordinates": [73.0, 159.48, 374.62, 375.83, 61.37]}, {"formula_id": "formula_164", "formula_text": ")", "formula_coordinates": [73.0, 535.31, 417.34, 4.61, 10.91]}, {"formula_id": "formula_165", "formula_text": "x\u2208supp(\u03b7 \u2032 ) \u03c0 F (x) \u2212 \u03c0(x) \u03c0(supp(\u03b7 \u2032 )) = 1 2 x\u2208supp(\u03b7 \u2032 ) \u03c0 F (x) \u2212 \u03c0 F (x) \u03c0 F (supp(\u03b7 \u2032 )) = 1 2 1 \u03c0 F (supp(\u03b7 \u2032 )) \u2212 1 x\u2208supp(\u03b7 \u2032 ) \u03c0 F (x) = 1 2 1 \u03c0 F (supp(\u03b7 \u2032 )) \u2212 1 \u2022 \u03c0 F (supp(\u03b7 \u2032 )) = 1 2 (1 \u2212 \u03c0 F (supp(\u03b7 \u2032 )))(9)", "formula_coordinates": [73.0, 211.08, 458.98, 328.84, 164.81]}, {"formula_id": "formula_166", "formula_text": "||\u03b7 \u2032 supp(\u03b7 \u2032 ) \u2212 \u03c0 supp(\u03b7 \u2032 ) || \u2264 ||\u03b7 \u2032 \u2212 \u03c0 F || \u2212 1 2 (1 \u2212 \u03c0 F (supp(\u03b7 \u2032 ))) + 1 2 (1 \u2212 \u03c0 F (supp(\u03b7 \u2032 ))) = ||\u03b7 \u2032 \u2212 \u03c0 F || \u2264 1 2 ndev \u03c0 F (vdensity P (X)) + \u03b5.", "formula_coordinates": [73.0, 108.12, 646.66, 395.69, 51.89]}, {"formula_id": "formula_167", "formula_text": "1 E \u03c0 F (vdensity P (X)) + 3\u03b5 t |F | \u2022 E u F 1 vdensity 2 P (X) + qcost(\u03c0).", "formula_coordinates": [74.0, 150.84, 287.98, 311.43, 28.77]}, {"formula_id": "formula_168", "formula_text": "\u03b7(x) = \u03c0 F (x) d F (x) q F (x) E \u03c0 F d F (X) q F (X)", "formula_coordinates": [74.0, 240.72, 651.5, 118.61, 39.42]}, {"formula_id": "formula_169", "formula_text": "E \u03b7 1 vdensity P (X) = x\u2208F \u03b7(x) \u2022 1 vdensity P (x) = x\u2208F \u03c0 F (x) \u2022 d F (x) q F (x) E \u03c0 F d F (X) q F (X)", "formula_coordinates": [75.0, 134.4, 124.42, 233.45, 73.79]}, {"formula_id": "formula_170", "formula_text": "E \u03b7 1 vdensity P (x) \u2212 E \u03b7t 1 vdensity P (x) \u2264 2\u03b5 t \u2022 E u F 1 vdensity P (X) + |F | \u2022 cov u F 1 vdensity P (X)", "formula_coordinates": [76.0, 120.96, 90.22, 287.32, 57.81]}, {"formula_id": "formula_172", "formula_text": ")|) \u2264 (1 \u2212 \u03b1) t \u221a \u03b7 min \u2022 E u (f 2 (X)),", "formula_coordinates": [76.0, 286.94, 230.79, 148.33, 28.12]}, {"formula_id": "formula_173", "formula_text": "|\u03b7 t (x) \u2212 \u03b7(x)| \u2264 \u03b7(x) \u03b7 min (1 \u2212 \u03b1) t .", "formula_coordinates": [76.0, 230.28, 355.9, 151.47, 26.73]}, {"formula_id": "formula_174", "formula_text": ")|) \u2264 (1 \u2212 \u03b1) t \u221a \u03b7 min \u2022 E u ( \u03b7(X) \u2022 f (X)) \u2212 E u ( \u03b7(X)) \u2022 E u (f (X)) \u2264 (1 \u2212 \u03b1) t \u221a \u03b7 min \u2022 E u ( \u03b7(X) \u2022 f (X)) (Since f (x) \u2265 0, \u2200x) \u2264 (1 \u2212 \u03b1) t \u221a \u03b7 min \u2022 E u (\u03b7(X)) \u2022 E u (f 2 (X)) (Cauchy-Schwartz) = (1 \u2212 \u03b1) t \u221a \u03b7 min \u2022 E u (f 2 (X)) (Since \u03b7 is a distribution).", "formula_coordinates": [76.0, 200.72, 406.83, 318.45, 122.32]}, {"formula_id": "formula_175", "formula_text": "|F | \u2022 cov u F 1 vdensity P (X) , |\u03b7 t (X) \u2212 \u03b7(X)| \u2264 |F | \u2022 (1 \u2212 \u03b1) t \u221a \u03b7 min \u2022 E u F 1 vdensity 2 P (X) \u2264 |F | \u2022 (1 \u2212 \u03b1) t \u03b7 min \u2022 E u F 1 vdensity 2 P (X) (Since \u03b7 min \u2264 1/|F |) = \u03b5 t \u2022 |F | \u2022 E u F 1 vdensity 2 P (X) . (11", "formula_coordinates": [76.0, 140.28, 558.22, 394.71, 137.49]}, {"formula_id": "formula_176", "formula_text": ")", "formula_coordinates": [76.0, 534.99, 674.38, 4.81, 10.91]}, {"formula_id": "formula_177", "formula_text": "E \u03b7t 1 vdensity P (X) \u2264 E \u03b7 1 vdensity P (X) + E \u03b7t 1 vdensity P (X) \u2212 E \u03b7 1 vdensity P (X) \u2264 1 E \u03c0 F (vdensity P (X)) + 2\u03b5 t \u2022 E u F 1 vdensity P (X) + \u03b5 t \u2022 |F | \u2022 E u F 1 vdensity 2 P (X) \u2264 1 E \u03c0 F (vdensity P (X)) + 3\u03b5 t |F | \u2022 E u F 1 vdensity 2 P (X)", "formula_coordinates": [77.0, 88.92, 97.3, 416.44, 130.53]}, {"formula_id": "formula_178", "formula_text": "C \u2032 \u2022 Z\u03c0 F \u2022 \u03c0(F ) \u2022 E \u03c0 F (vdensity P (X)) deg P + (F ) \u2212 3\u03b5 t \u2022 E u F \u03c0 2 F (X) deg 2 P (X) .", "formula_coordinates": [77.0, 146.88, 284.66, 318.27, 30.53]}, {"formula_id": "formula_179", "formula_text": "E dt C \u2032\u03c0 (x) deg P (x) = C \u2032 \u2022 Z\u03c0 F \u2022 \u03c0(F ) \u2022 E dt \u03c0 F (x) deg P (x) . (12", "formula_coordinates": [77.0, 174.0, 405.26, 360.99, 29.33]}, {"formula_id": "formula_180", "formula_text": ")", "formula_coordinates": [77.0, 534.99, 414.34, 4.81, 10.91]}, {"formula_id": "formula_181", "formula_text": "Proposition 38. E d F \u03c0 F (X) deg P (X) = E \u03c0 F (vdensity P (X)) deg P + (F ) .", "formula_coordinates": [77.0, 72.0, 543.7, 328.71, 39.8]}, {"formula_id": "formula_183", "formula_text": "|F | \u2022 cov u F \u03c0 F (x) deg P (x) , |d t (X) \u2212 d F (X)| \u2264 |F | \u2022 (1 \u2212 \u03b1) t \u221a d F min \u2022 E u F \u03c0 2 F (x) deg 2 P (x) , |d t (X) \u2212 d F (X)| \u2264 |F | \u2022 (1 \u2212 \u03b1) t d F min \u2022 E u F \u03c0 2 F (x) deg 2 P (x) (Since d F min \u2264 1/|F |) = \u03b5 t \u2022 |F | \u2022 E u F \u03c0 2 F (x) deg 2 P (x) .(14)", "formula_coordinates": [78.0, 149.52, 358.9, 390.29, 137.85]}, {"formula_id": "formula_184", "formula_text": "E dt \u03c0 F (x) deg P (x) \u2265 E d F \u03c0 F (x) deg P (x) \u2212 E dt \u03c0 F (x) deg P (x) \u2212 E d F \u03c0 F (x) deg P (x)", "formula_coordinates": [78.0, 111.48, 529.54, 275.81, 57.81]}, {"formula_id": "formula_185", "formula_text": "deg P + (F ) \u2212 2\u03b5 t \u2022 E u F \u03c0 F (x) deg P (x) \u2212 \u03b5 t \u2022 |F | \u2022 E u F \u03c0 2 F (x) deg 2 P (x)", "formula_coordinates": [78.0, 163.56, 592.7, 312.77, 30.53]}, {"formula_id": "formula_186", "formula_text": "deg P + (F ) \u2212 3\u03b5 t |F | \u2022 E u F \u03c0 2 F (x) deg 2 P (x)", "formula_coordinates": [78.0, 163.56, 629.9, 198.17, 30.53]}], "doi": ""}