{"title": "Model Counting: A New Strategy for Obtaining Good Bounds", "authors": "Carla P Gomes; Ashish Sabharwal; Bart Selman", "pub_date": "", "abstract": "Model counting is the classical problem of computing the number of solutions of a given propositional formula. It vastly generalizes the NP-complete problem of propositional satisfiability, and hence is both highly useful and extremely expensive to solve in practice. We present a new approach to model counting that is based on adding a carefully chosen number of so-called streamlining constraints to the input formula in order to cut down the size of its solution space in a controlled manner. Each of the additional constraints is a randomly chosen XOR or parity constraint on the problem variables, represented either directly or in the standard CNF form. Inspired by a related yet quite different theoretical study of the properties of XOR constraints, we provide a formal proof that with high probability, the number of XOR constraints added in order to bring the formula to the boundary of being unsatisfiable determines with high precision its model count. Experimentally, we demonstrate that this approach can be used to obtain good bounds on the model counts for formulas that are far beyond the reach of exact counting methods. In fact, we obtain the first non-trivial solution counts for very hard, highly structured combinatorial problem instances. Note that unlike other counting techniques, such as Markov Chain Monte Carlo methods, we are able to provide highconfidence guarantees on the quality of the counts obtained.", "sections": [{"heading": "Introduction", "text": "Propositional model counting is the problem of computing the number of models for a given propositional formula, i.e., the number of distinct variable assignments for which the formula evaluates to TRUE. This problem generalizes the well-known NP-complete problem of propositional satisfiability, SAT, which has played a key role in complexity theory as well as in automated reasoning. Indeed, computing the exact model count is a #P-complete problem, which means that it is no easier than solving a propositional formula with an unbounded number of \"there exist\" and \"forall\" quantifiers in its variables (Toda 1989). For comparison, recall that SAT can be thought of as a propositional formula with exactly one level of \"there exist\" quantification.\nEffective model counting procedures would open up a range of new applications. For example, various probabilistic inference problems, such as Bayesian net reasoning, can be effectively translated into model counting problems (cf. Roth;Littman, Majercik, & Pitassi;Darwiche 1996;2001;2005). Another application is in the study of hard combinatorial problems, such as combinatorial designs, where the number of solutions provides further insights into the problem. Even finding a single solution can be a challenge for such problems: counting the number of solutions is much harder yet. Using our counting method, we will obtain the first non-trivial lower bounds on the number of solutions of several complex combinatorial problems.\nThe earliest practical approach for counting models is based on an extension of systematic DPLL-based SAT solvers. By using appropriate multiplication factors and continuing the search after a single solution is found, Relsat (Bayardo Jr. & Pehoushek 2000) is able to provide incremental lower bounds on the model count as it proceeds, and finally computes the exact model count. Newer tools such as Cachet (Sang et al. 2004) often improve upon this by using techniques such as component caching.\nAll exact counting methods, including Relsat and Cachet, essentially attack a #P-complete problem \"head on\" -by searching the raw combinatorial search space. Consequently, these algorithms often have difficulty scaling up to larger problem sizes. We should point out that problems with a higher solution count are not necessarily harder to determine the model count of. In fact, Relsat can compute the exact model count of highly under-constrained problems with many \"don't care\" variables and a lot of models by exploiting big clusters in the solution space. The model counting problem is instead much harder for more intricate combinatorial problems where the solutions are spread much more finely throughout the combinatorial space. We consider examples of such problems in our experiments.\nA relatively new approach introduced by Wei & Selman (2005) is to use Markov Chain Monte Carlo sampling to compute an approximation of the exact model count. Their tool, ApproxCount, is able to solve several instances quite accurately, while scaling much better than both Relsat and Cachet as problem size increases. The drawback of ApproxCount is that one is not able to provide any hard guarantees on the model count it computes. To output a number close to the exact count, the counting strategy of Wei & Selman requires uniform sampling from the set of solutions, which is generally very difficult to achieve. Uniform sampling from the solution space is much harder than just generating a single solution. MCMC methods can provide theoretical convergence guarantees but only in the limit, generally after an exponential number of steps.\nInterestingly, the inherent strength of most state-of-the-art SAT solvers comes actually from the ability to quickly narrow down to a certain portion of the search space the solver is designed to handle best. Such solvers therefore sample solutions in a highly non-uniform manner, making them seemingly ill-suited for model counting, unless one forces the solver to explore the full combinatorial space. An interesting question is whether there is a way around this apparent limitation of the use of state-of-the-art SAT solvers for model counting. Our key contribution is a new method for model counting, which uses a state-of-the-art SAT solver \"as is\". It follows immediately that the more efficient the SAT solver used, the more powerful our counting strategy becomes.\nOur approach is inspired by recent work on so-called \"streamlining constraints\" (Gomes & Sellmann 2004), in which additional, non-redundant constraints are added to the original problem to increase constraint propagation and to focus the search on a small part of the subspace, (hopefully) still containing solutions. This strategy was shown to be successful in solving very hard combinatorial design problems, with carefully created, domain-specific streamlining constraints. In contrast, in this work, we introduce a domain-independent streamlining technique.\nStreamlining could potentially also be used to obtain an accurate estimate of the total solution count, if the solution density in the remaining (streamlined) search space was similar to that of the overall solution density. In that case, one could count the solutions remaining in the subspace and multiply this by the relative size of the subspace to the overall search space. Interestingly, there exist generic constraints that can be used to probabilistically streamline the search space sufficiently uniformly. These are so-called parity or XOR constraints, represented by logical XOR formulas.\nThe central idea of our approach is to repeatedly add randomly chosen XOR or parity constraints on the problem variables to the input formula and feed the result to a state-ofthe-art SAT solver. We will discuss the technical details below, but at a very high level, our approach works as follows. Each random XOR constraint will cut the search space approximately in half. So, intuitively, if after the addition of s XOR's the formula is still satisfiable, the original formula must have at least on the order of 2 s models. More rigorously, we will show that if we perform t experiments of adding s random XOR constraints and our formula remains satisfiable in each case, then with probability at least 1\u22122 \u2212\u03b1t , our original formula will have at least 2 s\u2212\u03b1 satisfying assignments for any \u03b1 \u2265 1. So, by repeated experiments or by weakening the claimed bound, one can arbitrarily boost the confidence in the lower bound count. We also give results for the upper bound, and formalize two variants of this approach as algorithms MBound and Hybrid-MBound.\nOf course, the above argument might raise suspicion, because it does not depend at all on the how the solutions are distributed throughout the search space. This however is the surprising feature of the approach. We rely on the very special properties of random parity constraints, which in effect provide a good hash function, randomly dividing the solutions into two near-equal sets. Such constraints were first used by Valiant & Vazirani (1986) in a randomized reduction from SAT to so-called unique SAT. They provided evidence that unique SAT problems (formulas with at most one satisfying assignment) are essentially as hard as general SAT problems. In this work, we show a different, more positive, use of XOR constraints, allowing us to count assignments of hard combinatorial problems.\nIn the theoretical section of the paper, we give much more specific details on the bounds obtained from XORstreamlining. To demonstrate that this strategy is not just of theoretical interest, we also provide experimental results. Specifically, we applied our technique to three hard combinatorial problems, the Ramsey problem, the Schur problem, and the clique coloring problem. Our technique provides the first good lower bounds on solution counts for these problems. For both problems, we compute lower bounds with 99% confidence. For the Ramsey problems, we obtained a lower bound of 2 64 \u2248 1.8 \u00d7 10 19 solutions, in under two hours of computation. By comparison, Relsat found only 194,127 models in over 12 hours (Cachet does not provide partial counts and timed out, and ApproxCount does not converge to a solution). For the Schur problem, we obtained a lower bound of 2 26 \u2248 6.7 \u00d7 10 7 solutions, in under 5 hours of computation. Relsat, Cachet, and ApproxCount could not find any solutions in over 12 hours. For the clique coloring problem, we found over 10 40 solutions in only a few minutes while other methods didn't finish in 12 hours.\nIn summary, we provide a new approach to model counting. Our method is unique in that it can use any stateof-the-art SAT solver without any modifications. Our approach uses randomized streamlining XOR constraints and gives concrete bounds with high probability (desired confidence level is under control of the user). Our experiments provide the first non-trivial lower bounds on solution counts for three highly combinatorial problems. In each case these bounds dramatically improve upon existing methods.", "publication_ref": ["b8", "b6", "b3", "b3", "b1", "b0", "b7", "b10", "b2", "b9"], "figure_ref": [], "table_ref": []}, {"heading": "Preliminaries", "text": "For the rest of this paper, fix the set of propositional variables in all formulas to be V , |V | = n. A variable assignment \u03c3 : V \u2192 {0, 1} is a function that assigns a value in {0, 1} to each variable in V . We may think of the value 0 as FALSE and the value 1 as TRUE. We will often abuse notation and write \u03c3 (i) for valuations of entities i \u2208 V when the intended meaning is either already defined or is clear from the context. In particular, \u03c3 (1) = 1 and \u03c3 (0) = 0. When \u03c3 (i) = 1, we say that \u03c3 satisfies i. For x \u2208 V , \u00acx denotes the corresponding negated variable; \u03c3 (\u00acx) = 1 \u2212 \u03c3 (x).\nLet F be a formula over the set V of variables and let \u03c3 be a variable assignment. \u03c3 (F) denotes the valuation of F under \u03c3 . If \u03c3 satisfies F, i.e., \u03c3 (F) = 1, then \u03c3 is a model, solution, or satisfying assignment for F. The model count of F, denoted MC(F), is the number of models of F. The (propositional) model counting problem is to compute MC(F) given a (propositional) formula F.\nAlthough our theoretical results hold for propositional formulas in general, we present our work in the context of formulas in the standard conjunctive normal form or CNF, on which our experimental results rely. A clause (also called a CNF constraint) C is a logical disjunction of a set of possibly negated variables; \u03c3 satisfies C if it satisfies at least one signed variable of C. A formula F is in the CNF form if it is a logical conjunction of a set of clauses; \u03c3 satisfies F if it satisfies all clauses of F.\nAn XOR constraint D over variables V is the logical \"xor\" or parity of a subset of V \u222a {1}; \u03c3 satisfies D if it satisfies an odd number of elements in D. The value 1 allows us to express even parity. For instance, Our focus will be on formulas in the CNFXOR form, i.e., a logical conjunction of clauses and XOR constraints. Note that for every two complementary XOR constraints involving the same subset of V (e.g., c \u2295 d and c \u2295 d \u2295 1), any assignment \u03c3 satisfies exactly one of them. This simple property will be crucial for our analysis.\nD = {a, b, c, 1} represents the xor constraint a \u2295 b \u2295 c \u2295 1,\nLet X denote the set of all XOR constraints over V . For 1 \u2264 k \u2264 n = |V |, let X k denote the subset of X containing only those constraints that involve exactly k variables (and possibly the element 1). For simplicity, we will assume in the rest of the paper that n is even, and will be interested only in 1 \u2264 k \u2264 n/2. This assumption can be avoided, for instance, by adding a dummy variable with a fixed TRUE/FALSE value or by defining X n/2 = X n/2 \u222a X n/2 when n is odd.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A Simple Model Counting Algorithm", "text": "Our main algorithm is MBound, described below as Algorithm 1. It provides bounds on the model count of an input formula F by adding s random XOR constraints to F, solving the resulting CNFXOR formula using an arbitrary SAT solver as a subroutine, repeating this process t times, and looking at the observed satisfiable vs. unsatisfiable (sat-unsat) distribution of the t CNFXOR formulas. If this observed distribution is biased away from half-and-half, a bound on MC(F) is reported. Specifically, for a slack factor \u03b1, if most instances are satisfiable, 2 s\u2212\u03b1 is reported as a lower bound, and if most instances are unsatisfiable, 2 s+\u03b1 is reported as an upper bound. The correctness of these bounds depends on various factors and is quantified in the next section.\nParameters: MBound has five parameters: (1) the size k of the XORs used, (2) the number s of the XORs used, (3) the number t of repetitions or trials, (4) the deviation \u03b4 \u2208 (0, 1 / 2 ] from the 50-50 sat-unsat ratio, and (5) the precision slack \u03b1 \u2265 1. s and t will be the most crucial parameters, and we will often use k n/2 for our experiments.\nOutput: MBound has three modes of termination: (1) return a lower bound on MC(F), (2) return an upper bound on\nAlgorithm 1: MBound Params: k, s,t, \u03b4 , \u03b1 : k, s,t positive integers, k \u2264 n/2, 0 < \u03b4 \u2264 1 / 2 , \u03b1 \u2265 1 Input : A CNF formula F Output : A lower or upper bound on MC(F), or Failure begin numSat \u2190 0 for i \u2190 1 to t do Q s \u2190 s random constraints from X k F k s \u2190 F \u222a Q s result \u2190 SATSolve(F k s ) if result = TRUE then numSat \u2190 numSat + 1 if numSat \u2265 t \u2022 ( 1 / 2 + \u03b4 ) then return Lower bound: MC(F) > 2 s\u2212\u03b1 else if numSat \u2264 t \u2022 ( 1 / 2 \u2212 \u03b4 )\nthen return Upper bound: MC(F) < 2 s+\u03b1 else return Failure end MC(F), or (3) return \"Failure\" without reporting any bound whatsoever. A Failure happens when the observed sat-unsat ratio is less than \u03b4 away from 50-50.\nWe say that MBound makes an error if it reports an incorrect lower or upper bound on MC(F), and that it fails if it reports Failure. We expect the probability of MBound making an error to go down as k,t, \u03b4 , and \u03b1 increase.\nMBound is based on the following central idea. As observed by Valiant & Vazirani (1986), the effect of adding a random XOR from X to F is to cut down the number of models by approximately a half. The same holds also when using X n/2 instead of X. Somewhat surprisingly, this works no matter how solutions are structured in the space of all variable assignments. This is because constraints in X and X n/2 act as pairwise-independent uniform hash functions -uniformity allowing them to accept each model with probability exactly a half, and pairwise-independence making them oblivious to their acceptance or rejection of another model.\nAs the solution space is being iteratively cut down into halves, the number of XOR constraints one expects to add to F to bring it to the boundary of being unsatisfiable is roughly s * = log 2 MC(F). This is the key property MBound uses to approximate MC(F). Of course, this is only the expected behavior. To make the algorithm robust, we give a detailed probabilistic analysis to show that MBound is unlikely to deviate significantly from its expected behavior. This analysis forms the core of the technical contribution of this paper on the theoretical side and extends to provable guarantees for our second algorithm, Hybrid-MBound, as well.\nIn practice, adding XOR constraints from X n/2 (i.e., large XORs) can make the underlying SAT solver quite inefficient, and one is forced to consider the spaces X k , k n/2, of small XORs. Such small XORs, however, do not necessarily act pairwise-independently on the solution space, resulting in an algorithm of not as high a quality as with large XORs. Interestingly, small XORs turn out to be sufficient to obtain guaranteed lower bounds. Moreover, as k increases, one provably approaches the truly pairwise-independent ran-dom behavior of large XORs. In fact, in several domains, fairly small XORs work quite well in practice. Further, our preliminary results suggest that this fact can be used to our advantage in order to provide key insights into the clustering structure of the solution space. This, however, is beyond the scope of this paper.", "publication_ref": ["b9"], "figure_ref": [], "table_ref": []}, {"heading": "Analysis of Algorithm MBound", "text": "For 1 \u2264 k \u2264 n/2, let Q k s denote a set of s XOR constraints chosen independently and uniformly at random from X k , and let F k s denote the random CNFXOR formula obtained by adding the constraints Q k s to F. In our analysis, the probability will be over the random choice of Q k s . Our technical arguments have the following flavor. We show that when one adds too many XORs, even small ones, the resulting CNFXOR formula is quite unlikely to remain satisfiable. Further, if one conducts a meta-experiment by repeating this experiment with a fixed number of (too many) XORs several times, one is extremely unlikely to see many satisfiable formulas. By focusing on a meta-experiment that produces enough satisfiable formulas, one is thus able to probabilistically conclude that the number of XORs added was indeed not too many, providing a lower bound on the model count. A similar reasoning with too few XORs provides an upper bound, though with some complications arising from the lack of pairwise-independence of small XORs.\nWe will use standard bounds on the concentration of moments of a probability distribution, namely, Markov's inequality, Chebyshev's inequality, and the Chernoff bound (cf. Motwani & Raghavan 1994).", "publication_ref": ["b4"], "figure_ref": [], "table_ref": []}, {"heading": "The Lower Bound", "text": "We begin by arguing using Markov's inequality that as more and more XOR constraints are added at random from X k for any k to a formula F, its model count, MC(F) = 2 s * , is quite likely to go down at least nearly as fast as expected. Later, in the upper bound section, we will argue that MC(F) is likely to go down at most nearly as fast as expected when k = n/2. The precision slack \u03b1 captures the notion of \"nearly\" as fast.\nLemma 1. For 1 \u2264 k \u2264 n/2 and \u03b1 \u2265 1, Pr[MC(F k s ) \u2265 MC(F)/2 s\u2212\u03b1 ] \u2264 2 \u2212\u03b1 .\nProof. Let S be the set of satisfying assignments for F; |S| = MC(F). For each \u03c3 \u2208 S, let Y \u03c3 = \u03c3 (F k s ) be a 0-1 random variable. The expected value of Y \u03c3 is the probability that \u03c3 satisfies all of the s XOR constraints in Q k s . Recall that \u03c3 satisfies exactly half the constraints in X k . Since the s constraints in Q k s are chosen uniformly and independently from X k , the probability that \u03c3 satisfies all of them is 2\n\u2212s , implying E[Y \u03c3 ] = 2 \u2212s . Let Y = \u2211 \u03c3 Y \u03c3 . The random variable Y equals MC(F k s ), and we have E[Y ] = E[\u2211 \u03c3 Y \u03c3 ] = \u2211 \u03c3 E[Y \u03c3 ] = \u2211 \u03c3 2 \u2212s = MC(F)/2 s . It follows that Pr[MC(F k s ) \u2265 MC(F)/2 s\u2212\u03b1 ] = Pr[Y \u2265 2 \u03b1 E[Y ]] \u2264 2 \u2212\u03b1 by Markov's inequality. Corollary 1. For 1 \u2264 k \u2264 n/2, \u03b1 \u2265 1, and s \u2265 s * + \u03b1, Pr[F k s is satisfiable] \u2264 2 \u2212\u03b1 . Proof. Observe that MC(F)/2 s\u2212\u03b1 = 2 s * \u2212(s\u2212\u03b1) \u2264 1. There- fore, Pr[F k s is satisfiable] = Pr[MC(F k s ) \u2265 1] \u2264 Pr[MC(F k s ) \u2265 MC(F)/2 s\u2212\u03b1 ] \u2264 2 \u2212\u03b1 .\nWe use this result along with the Chernoff bound to show that after adding s \u2265 s * + \u03b1 XOR constraints from X k s several times, the fraction of instances F k s that are satisfiable is unlikely to be much more than 2 \u2212\u03b1 . Consequently, if one does see a significantly larger fraction of satisfiable instances than 2 \u2212\u03b1 in this meta-experiment, then s is very likely to be less than (s * + \u03b1), providing a high probability lower bound of (s \u2212 \u03b1) on s * . Clearly, a weaker bound with a large \u03b1 holds with a higher probability than a stronger one with a small \u03b1.\nFormally, let F k,(i) s\n, 1 \u2264 i \u2264 t, denote t random formulas obtained by independently adding s random XOR constraints from X k to F. The probability in what follows is on the collective choice of these formulas. In particular, whether F k,(i) s is satisfiable or not is a random event of interest. For convenience, we define the following quantity related to the Chernoff bound. Definition 1. For any positive integer t, 0 < \u03b4 \u2264 1 / 2 , and\n\u03b1 \u2265 1, let \u03b2 = 2 \u03b1 ( 1 / 2 + \u03b4 ) \u2212 1 and define p(t, \u03b4 , \u03b1) = \uf8f1 \uf8f2 \uf8f3 2 \u2212\u03b1t if \u03b4 = 1 / 2 e \u03b2 (1+\u03b2 ) 1+\u03b2 t/2 \u03b1 if \u03b4 < 1 / 2 .\nWhen \u03b4 < 1 / 2 , we can simplify the above expression for \u03b1 \u2208 {1, 2} to get p(t, \u03b4 , 1) \u2264 e \u22120.77\u03b4 2 t and p(t, \u03b4 , 2) \u2264 e \u22120.07(1+4\u03b4 ) 2 t \u2264 e \u22121.12\u03b4 2 t\u22120.07t . This demonstrates that p(t, \u03b4 , \u03b1) decreases exponentially as \u03b4 and t increase, and is significantly smaller for larger \u03b1. This will help in qualitatively understanding the correctness guarantees we provide.\nLemma 2. For s \u2265 s * + \u03b1 and 0 < \u03b4 \u2264 1 / 2 , the probability that at least a ( 1 / 2 + \u03b4 ) fraction of the t formulas F\nk,(i) s , 1 \u2264 i \u2264 t, is satisfiable is at most p(t, \u03b4 , \u03b1). Proof. Let Z i , 1 \u2264 i \u2264 t, be a random variable whose value is 1 if F k,(i) s\nis satisfiable and 0 otherwise. Let Z = \u2211 i Z i be the random variable that equals the number of satisfiable formulas F k,(i) s , 1 \u2264 i \u2264 t. Note that Z is the sum of independent 0-1 random variables, and, by Chernoff bound, is highly concentrated around its expected value.\nBy Corollary 1, Pr[F\nk,(i) s is satisfiable] \u2264 2 \u2212\u03b1 . Therefore, E[Z i ] = Pr[Z i = 1] = Pr[F k,(i) s is satisfiable] \u2264 2 \u2212\u03b1 so that E[Z] = \u2211 i E[Z i ] \u2264 t2 \u2212\u03b1 .\nThe probability that at least a ( 1 / 2 + \u03b4 ) fraction of these t random formulas is satisfiable equals Pr\n[Z \u2265 t \u2022 ( 1 / 2 + \u03b4 )]. For \u03b4 = 1 / 2 , this equals Pr[Z \u2265 t] = Pr[Z i = 1 for all i] \u2264 2 \u2212\u03b1t = p(t, 1 / 2 , \u03b1) because the random variables Z i are in- dependent. For \u03b4 < 1 / 2 , Pr[Z \u2265 t \u2022 ( 1 / 2 + \u03b4 )] \u2264 Pr[Z \u2265 2 \u03b1 ( 1 / 2 + \u03b4 )E[Z]].\nUsing the Chernoff bound, this probability is bounded above by p(t, \u03b4 , \u03b1).\nRecall that p(t, \u03b4 , \u03b1) is a quantity that decreases exponentially with t and \u03b4 .\nTheorem 1 (Main Result). For 1 \u2264 k \u2264 n/2, the lower bound of 2 s\u2212\u03b1 reported by MBound with parameters (k, s,t, \u03b4 , \u03b1) is correct with probability at least 1 \u2212 p(t, \u03b4 , \u03b1).\nProof. Suppose MBound with parameters (k, s,t, \u03b4 , \u03b1) makes a lower bound error on input F. Let r denote the final value of the variable numSat in that run of MBound, i.e., r is the number of satisfiable formulas amongst the t random formulas generated by the algorithm.\nSince MBound reported a (wrong) lower bound, it must be that r \u2265 t \u2022 ( 1 / 2 + \u03b4 ). Further, since it made an error, it must be that log 2 MC(F) \u2264 s \u2212 \u03b1 in reality, i.e., s \u2265 s * + \u03b1. In this case, by Lemma 2, the probability of the algorithm encountering r \u2265 t \u2022 ( 1 / 2 + \u03b4 ) satisfiable formulas amongst the t random ones is bounded above by p(t, \u03b4 , \u03b1).\nIn particular, when all formulas encountered by MBound are satisfiable, we have a simpler correctness guarantee.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Corollary 2 (Simplified Result). When", "text": "MBound finds all t CNFXOR formulas to be satisfiable, the lower bound 2 s\u2212\u03b1 it reports is correct with probability at least 1 \u2212 2 \u2212\u03b1t . Example 1. Consider an experiment with t = 20 runs and \u03b4 set to 1/4. Then t \u2022 ( 1 / 2 + \u03b4 ) = 15, p(t, \u03b4 , 1) \u2264 0.34, and p(t, \u03b4 , 2) \u2264 0.002. It follows that if we observe at least 15 out of 20 runs to be satisfiable, the lower bound of 2 s\u22121 is correct with probability at least 0.66, and that of 2 s\u22122 is correct with probability at least 0.998. This shows that the probability of MBound making a lower-bound error indeed goes down exponentially as the number of trials t increase, making the algorithm quite robust for providing lower bounds on the model count. Further, when the precision slack \u03b1 is increased from 1 to 2, the error probability decreases dramatically.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "The Upper Bound: Ideal Case, Large XORs", "text": "For the upper bound, Markov's inequality is insufficient. We instead argue using Chebyshev's inequality that as more and more XOR constraints are added at random from X n/2 to a formula F, its model count is quite likely to go down at most nearly as fast as expected. In particular, F is quite unlikely to become unsatisfiable with too few XORs. Note that this result as such does not hold when small XORs are used.\nLemma 3. For \u03b1 \u2265 1 and s \u2264 s * , (A) Pr[MC(F n/2 s ) \u2264 MC(F)/2 s+\u03b1 ] \u2264 1/((1 \u2212 2 \u2212\u03b1 ) 2 2 s * \u2212s ) and (B) Pr[F n/2 s is unsatisfiable] \u2264 1/2 s * \u2212s .\nProof Sketch. (See Appendix for details.) As in the proof of Lemma 1, let S be the set of satisfying assignments for F.\nFor each \u03c3 \u2208 S, let Y \u03c3 = \u03c3 (F n/2 s ) be a 0-1 random variable. The expected value of Y \u03c3 is, as before, given by E[Y \u03c3 ] = 2 \u2212s . Further, its variance is Var[Y \u03c3 ] = E[Y 2 \u03c3 ] \u2212 E[Y \u03c3 ] 2 .\nIgnoring the negative term and using the fact that Y \u03c3 is a 0-1 variable,\nVar[Y \u03c3 ] \u2264 E[Y \u03c3 ].\nA key thing to observe here is that the random variables Y \u03c3 for various \u03c3 are pairwise-independent because of an argument that relies on both the fact that we are dealing with XOR constraints (as opposed to, say, CNF constraints) and that they are chosen uniformly from X n/2 rather than from X k for k < n. The result then follows from a variance computation and an application of Chebyshev's inequality.\nCorollary 3. For \u03b1 \u2265 1 and s \u2264 s * \u2212 \u03b1, Pr[F n/2 s is unsatisfiable] \u2264 2 \u2212\u03b1 .\nThe meta-experiment providing an upper bound on s * works essentially the same as Lemma 2 (see Appendix). Lemma 4. For s \u2264 s * \u2212 \u03b1 and 0 < \u03b4 \u2264 1 / 2 , the probability that at least a ( 1 / 2 +\u03b4 ) fraction of the t formulas\nF n/2,(i) s , 1 \u2264 i \u2264 t, is unsatisfiable is at most p(t, \u03b4 , \u03b1).\nFrom this follows our main upper bound result for large XORs, in a fashion very similar to the proof of Theorem 1. Theorem 2. An upper bound of 2 s+\u03b1 reported by MBound with parameters (n/2, s,t, \u03b4 , \u03b1) is correct with probability at least 1 \u2212 p(t, \u03b4 , \u03b1).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "The Upper Bound: Practical Case, Small XORs", "text": "As mentioned earlier, computation with large XORs is quite expensive in practice. While the correctness of the lower bound reported by MBound does not depend on the length of the XORs, that of the upper bound does. When the solution space is highly structured, small XORs do not act pairwiseindependently on various variable assignments.\nAfter adding s \u2264 s * \u2212 2 small random XORs to F, while one still expects 2 s * \u2212s solutions of F to survive on average, the variance in this number could be quite high. In the worst case, one could have a tiny number of resulting formulas F k,(i) s be satisfiable with an enormous number of solutions, and a huge number of such formulas be unsatisfiable. This would still maintain the expected number of surviving solutions, but would make the sat-unsat distribution of F k,(i) s highly skewed towards unsat even with too few XORs.\nOn the positive side, as k increases and approaches n/2, one expects random XORs from X k to act on different variable assignments in a more and more pairwise independent manner. This can be proved formally using a straightforward variance calculation. We omit the proof for lack of space. Proposition 1. As the length k of XORs increases, the variance in the number of satisfiable CNFXOR formulas observed by MBound decreases.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A Hybrid Model Counting Algorithm", "text": "By using a good SAT solver as a subroutine, MBound is already able to provide high quality lower bounds in practice. Its performance can be boosted even further by combining it with an exact model counting algorithm. Algorithm 2, Hybrid-MBound, that we present in this section does precisely this. The idea is to add randomly chosen XORs as before, but solve the resulting formula using an exact model counting algorithm as a subroutine instead of a SAT solver.\nTwo key factors make the hybrid approach work well in practice. First, by streamlining hard-to-count formulas with random XORs, we bring them within the reach of exact counting methods while maintaining the accuracy of the overall bound. Second, by throwing in relatively fewer XORs and relying on an exact counting method for the residual formula, the quality of the obtained bound is improved.\nHybrid-MBound has a subset of the parameters of MBound and has only a single mode of termination: return both a lower and an upper bound on MC(F), within a factor of 2 2\u03b1+1 of each other. Once Hybrid-MBound generates exact counts for t streamlined formulas, the overall bound it reports can naturally be based on the minimum, average, or maximum of the t residual counts. We call this the mode of operation. The correctness of Hybrid-MBound is captured by the following results (see Appendix for proofs). Theorem 3 (Main Hybrid Result). For 1 \u2264 k \u2264 n/2, when Hybrid-MBound is run with parameters (k, s,t, \u03b1)\n, then Pr[Conservative lower bound is correct] \u2265 1 \u2212 2 \u2212\u03b1t , Pr[Moderate lower bound is correct] \u2265 1 \u2212 2 \u2212\u03b1 , and Pr[Aggressive lower bound is correct] \u2265 (1 \u2212 2 \u2212\u03b1 ) t .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Theorem 4. The lower and upper bounds reported by", "text": "Hybrid-MBound with parameters (n/2, s,t, \u03b1) are correct with probability at least 1 \u2212 1/2 s * \u2212s\u22122 independent of t, \u03b1.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Experimental Results", "text": "To demonstrate the practical relevance of our approach, we considered the model counting problem for three hard combinatorial domains: the Ramsey problem, the Schur problem, and the clique coloring problem. All three problems deal with the question of the existence of certain intricate combinatorial objects.\nIn the Ramsey domain, one considers all possible twocolorings (red and blue) of the edges of the complete graph on n nodes. Ramsey showed that when n gets sufficiently large, certain structures of red or blue edges will be found in every coloring. In particular, R(k, l) denotes the minimum value of n such that every coloring has at least one red clique of k vertices or one blue clique of l vertices. It is known that R(4, 5) = 25. So, if we consider a complete graph of 23 vertices, we are guaranteed to have solutions that neither contain a red clique of size 4 nor a blue clique of size 5. However, this is a highly non-trivial coloring problem. We can translate this problem into a SAT formula with 253 variables and 42,504 clauses. Finding a single solution using the fastest available SAT solver for this problem (MiniSAT) takes approximately 30 seconds on a 1 GHz machine. Our challenge is to find an interesting lower bound on the number of solutions.\nWe used MBound with small XOR constraints and MiniSAT as the subsolver. The parameters were chosen so as to make the streamlined formula easy for MiniSAT. In particular, when the XORs are too large, they do not provide enough constraint propagation for MiniSAT. (Note that the XORs are converted into CNF using auxiliary variables and clauses.) We found that we could streamline with 65 random XOR constraints with 4 to 5 variables in each constraint.\nIn the Schur problem, we are given the set of integers {1, 2, . . . , n}. The question is whether this set can be divided into k sum-free subsets. A set S is sum-free if the sum of any pair of numbers in S is not in S. For each value of k, there is a certain value of n such that no partition into k sum-free subsets exists. For given values of n and k, we can again construct a SAT problem representing the formula. It is known that for k = 5 and n = 140, sum-free partitions still exist. The corresponding SAT problem has 700 variables and 51,600 clauses. This formula is already beyond the reach of current state-of-the-art SAT solvers (i.e., we could not find a single model in approximately 12 hours of CPU time). With random XOR streamlining with good parameters, we were able to solve the instance using MiniSAT by adding 27 XOR constraints containing an average of 9 variables.\nIn the clique coloring problem with parameters n, m, and k, the task is to construct a graph on n nodes such that it can be colored with m colors and also contains a clique of size k. This problem has interesting properties that make it very useful in proof complexity research on exponential lower bounds for powerful proof systems (Pudl\u00e1k 1997). We experimented with instances that had 600-750 variables and 20,000-35,000 clauses. When satisfiable, finding a single solution to these is quite easy. However, counting all solutions turns out to be extremely challenging even for approximate methods. By streamlining with XORs of size 6-8, we obtained lower bounds of 10 40 and higher within minutes.\nTable 1 summarizes the results obtained 1 on a 550 MHz 8 processor Intel Pentium III machine with 4 GB shared memory. All reported lower bounds are based on t = 7 and \u03b1 = 1 so that Corollary 2 guarantees a 1 \u2212 2 \u22127 \u2265 99% confidence. The confidence level can, of course, be boosted by simply doing more XOR streamlined runs with MiniSAT (higher t) or reducing the reported bound by a factor of 2 (higher \u03b1). We see that we obtain non-trivial lower bounds on the model counts. We also see that these counting problems are effectively beyond the reach of other state-of-the-art model counting approaches. Both Relsat and Cachet do not finish in 12 hours. Relsat gives very low partial counts while Cachet is not designed to report partial counts. ApproxCount computes a medium quality approximate count without any guarantees. These results show that counting using randomized XOR streamlining provides a powerful new approach for obtaining lower bounds on model counts of hard combinatorial problems.\nOften lower bounds obtained from MBound can be made stronger with Hybrid-MBound. With Cachet as a subsolver and 30 XORs, we could boost the lower bound model count for Schur-5-140 to 1.8 \u00d7 10 12 . Similarly, the lower bound for fclqcolor-18-14-11 was improved to 4.1 \u00d7 10 45 . Note that the ability of Hybrid-MBound to boost MBound relies partly on exact model counting technology. The latter generally lags quite a bit behind SAT solvers, which are sufficient for MBound.\nFinally, the results summarized in Table 2 confirm that, in practice, lower bounds reported by MBound and Hybrid-MBound can come quite close to exact counts even with very small XORs. The instance bitmax is a circuit synthesis problem and log a is a logistics planning problem. The exact counts for these are obtained using Relsat. The last two instances are pigeonhole-type problems, with n pigeons and k holes, n \u2264 k. Relsat timed out on these instances after 12 hours. However, the exact count can be analytically computed to be k!/(k \u2212 n)!. In all four cases, the average length of XORs used was less than 5% of the number of problem variables. Nevertheless, MBound came within a factor of 20 of the exact counts, which exceed 10 11 and sometimes even 10 28 . Hybrid-MBound typically requires shorter XORs than MBound in order to make the streamlined formula solvable using an exact counting method. Despite this, it further boosted the results to within a factor of 2 of the exact counts in three cases; in the fourth, even the streamlined problem remained hard for Relsat. Of course, one could yet further improve these bounds using somewhat larger XORs and additional computational resources.", "publication_ref": ["b5"], "figure_ref": [], "table_ref": ["tab_1", "tab_0"]}, {"heading": "Conclusion", "text": "Current techniques for model counting are based on either an exact counting paradigm or an approximate counting approach (e.g., MCMC methods), both of which have their limitations. We propose a third alternative based on randomized streamlining using XOR constraints. Our approach has two key strengths: it can generate model counts using any state-of-the-art SAT solver off-the-shelf, and it provides concrete bounds along with a high probability correctness guarantee that can be easily boosted by repetition. The model count lower bounds obtained using our algorithm MBound dramatically improve upon the results of existing techniques on three very difficult combinatorial problems. Our algorithm Hybrid-MBound combines the strength of existing exact counting methods with our XOR streamlining approach, boosting the results even further.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Appendix: Proofs", "text": "Proof of Lemma 3. As in the proof of Lemma 1, let S be the set of satisfying assignments for F; |S| = MC(F). For each \u03c3 \u2208 S, let Y \u03c3 be the 0-1 random variable whose value is \u03c3 (F n/2 s ). The expected value of Y \u03c3 is, as before, given by E[Y \u03c3 ] = 1/2 s . Further, its variance is Var\nIgnoring the negative term and using the fact that Y \u03c3 is a 0-1 variable, Var [\nA key point to observe here is that the random variables Y \u03c3 for various \u03c3 are pairwise-independent because of the following argument which relies on both the fact that we are dealing with XOR constraints (as opposed to, say, CNF constraints) and that they are chosen uniformly from X n/2 rather than from X k for k < n. Consider two random variables, Y \u03c3 1 and Y \u03c3 2 . The question we need to answer is: what can we say about the value of Y \u03c3 2 when we know the value of Y \u03c3 1 ? The answer is determined by the behavior of \u03c3 1 and \u03c3 2 on any single XOR constraint D. We will show that for D chosen uniformly from X n/2 , \u03c3 1 (D) differs from \u03c3 2 (D) with probability exactly a 1/2. This will imply that knowing the value of Y \u03c3 1 does not tell us anything about the value of Y \u03c3 2 .\nTo this end, let V \u2286 V be the non-empty set of variables on which \u03c3 1 and \u03c3 2 differ, and D be an random XOR constraint from X n/2 . Since D is an XOR constraint, the probability that \u03c3 1 (D) differs from \u03c3 2 (D) equals the probability that D involves an odd number of variables in V . Since D is chosen at random from X n/2 and exactly half the constraints in X n/2 involve an odd number of variables in any subset of V , this probability is exactly 1/2. As argued above, this implies that Y \u03c3 1 and Y \u03c3 2 are pairwise-independent.\nGetting back to the main argument, let Y = \u2211 \u03c3 Y \u03c3 . The random variable Y equals the number of models of the formula\nis unsatisfiable and 0 otherwise.\nLet Z = \u2211 i Z i be the random variable that equals the number of unsatisfiable formulas F n/2,(i) s , 1 \u2264 i \u2264 t. Note that Z is the sum of independent 0-1 random variables, and, by Chernoff bound, is highly concentrated around its expected value.\nBy Corollary 3, Pr[F\nThe probability that at least a (1/2 + \u03b4 ) fraction of these t random formulas is unsatisfiable equals Pr\nUsing the Chernoff bound separately for \u03b1 = 1, 2 as in Lemma 2, this probability is bounded above by p(t, \u03b4 , \u03b1).\nProof of Theorem 3. Suppose HybridMC makes a lower bound error in Conservative mode, that is, MC(F) \u2264 2 s\u2212\u03b1 \u2022 minModels. Equivalently, minModels \u2265 MC(F)/2 s\u2212\u03b1 so that all t of the random formulas F k,(i) s\n, 1 \u2264 i \u2264 t, have model counts at least MC(F)/2 s\u2212\u03b1 . By Lemma 1, this happens for a single such formula with probability at most 2 \u2212\u03b1 , and, by independence, for all of them with probability at most 2 \u2212\u03b1t .\nFrom the opposite perspective, the lower bound reported in Aggressive mode is correct iff all t random formulas F k,(i) s correctly have model counts less than MC(F)/2 s\u2212\u03b1 . By Lemma 1, this happens for a single such formula with probability at least 1 \u2212 2 \u2212\u03b1 , and, by independence, for all of them with probability at least (1 \u2212 2 \u2212\u03b1 ) t .\nThe result for Moderate mode can be proved using a variant of Lemma 1. Specifically, for the i th trial, we have a 0-1 random variable Y i \u03c3 instead of Y \u03c3 in the proof of Lemma 1, and now Y = \u2211 i \u2211 \u03c3 Y i \u03c3 is the total number of solutions of all t random formulas. E[Y ] = t \u2022 MC(F)/2 s and the result follows from Markov's inequality as before.\nProof of Theorem 4. We will focus on the hardest case, namely, t = \u03b1 = 1. Let F n/2 s denote the CNFXOR formula generated by HybridMC on input F, so that minModels = maxModels = avgModels = MC(F n/2 s ). Suppose the algorithm makes an error, that is, either MC(F) \u2264 2 s\u22121 MC(F n/2 s ) or MC(F) \u2265 2 s+1 MC(F n/2 s ). We will show that these events occur with a low probability.\nThe proof uses a slight generalization of Lemma 3. Assume the same setup as in the proof of that lemma, namely, a random variable Y that equals MC(F ", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Counting models using connected components", "journal": "", "year": "2000", "authors": "R J Bayardo; J D Pehoushek"}, {"ref_id": "b1", "title": "The quest for efficient probabilistic inference. Invited Talk", "journal": "", "year": "2005", "authors": "A Darwiche"}, {"ref_id": "b2", "title": "Streamlined constraint reasoning", "journal": "", "year": "2004", "authors": "C P Gomes; M Sellmann"}, {"ref_id": "b3", "title": "Stochastic boolean satisfiability", "journal": "J. Auto. Reasoning", "year": "2001", "authors": "M L Littman; S M Majercik; T Pitassi"}, {"ref_id": "b4", "title": "Randomized Algorithms", "journal": "Cambridge University Press", "year": "1994", "authors": "R Motwani; P Raghavan"}, {"ref_id": "b5", "title": "Lower bounds for resolution & cutting plane proofs & monotone computations", "journal": "J. Symb. Logic", "year": "1997", "authors": "P Pudl\u00e1k"}, {"ref_id": "b6", "title": "On the hardness of approximate reasoning", "journal": "J. AI", "year": "1996", "authors": "D Roth"}, {"ref_id": "b7", "title": "Combining component caching and clause learning for effective model counting", "journal": "", "year": "2004", "authors": "T Sang; F Bacchus; P Beame; H A Kautz; T Pitassi"}, {"ref_id": "b8", "title": "On the computational power of PP and \u2295P", "journal": "", "year": "1989", "authors": "S Toda"}, {"ref_id": "b9", "title": "NP is as easy as detecting unique solutions", "journal": "Theoretical Comput. Sci", "year": "1986", "authors": "L G Valiant; V V Vazirani"}, {"ref_id": "b10", "title": "A new approach to model counting", "journal": "", "year": "2005", "authors": "W Wei; B Selman"}], "figures": [{"figure_label": "", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "which is TRUE when an even number of a, b, c are TRUE. Note that it suffices to use only positive variables. E.g., \u00aca \u2295 b \u2295 \u00acc and \u00aca \u2295 b are equivalent to D = {a, b, c} and D = {a, b, 1}, respectively.", "figure_data": ""}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "Hybrid-MBoundParams: k, s,t, \u03b1 : k, s,t positive integers, k \u2264 n/2, \u03b1 \u2265 1 Mode : Conservative, Moderate, or Aggressive Input : A CNF formula F Output : A lower and an upper bound on MC(F)   ", "figure_data": "beginnumSeq \u2190 emptyfor i \u2190 1 to t doQ s \u2190 s random constraints from X kF s k,(i)\u2190 F \u222a Q snumModels \u2190 ExactModelCount(F s k,(i))numSeq.PushBack(numModels)minModels \u2190 Min(numSeq)maxModels \u2190 Max(numSeq)avgModels \u2190 Average(numSeq)if mode = Conservative thenreturn Lower bound: MC(F) > 2 s\u2212\u03b1 \u2022 minModels, Upper bound: MC(F) < 2 s+\u03b1 \u2022 maxModelselse if mode = Moderate thenreturn Lower bound: MC(F) > 2 s\u2212\u03b1 \u2022 avgModels, Upper bound: MC(F) < 2 s+\u03b1 \u2022 avgModelselse/* mode = Aggressive */return Lower bound: MC(F) > 2 s\u2212\u03b1 \u2022 maxModels, Upper bound: MC(F) < 2 s+\u03b1 \u2022 minModelsend"}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "MBound on problems beyond the reach of exact counting methods (99% confidence). Note that ApproxCount does not provide any guarantee on correctness or accuracy.", "figure_data": "InstanceMBound ModelsTimeRelsat ModelsTimeCachet Models TimeApproxCount Models TimeRamsey-20-4-5\u2265 1.2 \u00d7 10 30 < 2 hrs\u2265 7.1 \u00d7 10 812 hrs-12 hrs \u2248 1.8 \u00d7 10 194 hrsRamsey-23-4-5\u2265 1.8 \u00d7 10 19 < 2 hrs\u2265 1.9 \u00d7 10 512 hrs-12 hrs \u2248 7.7 \u00d7 10 125 hrsSchur-5-100\u2265 2.8 \u00d7 10 14 < 2 hrs-12 hrs-12 hrs \u2248 2.3 \u00d7 10 117 hrsSchur-5-140\u2265 6.7 \u00d7 10 7< 5 hrs-12 hrs-12 hrs-12 hrsfclqcolor-18-14-11 \u2265 2.1 \u00d7 10 403 mins \u2265 2.8 \u00d7 10 26 12 hrs-12 hrs-12 hrsfclqcolor-20-15-12 \u2265 2.2 \u00d7 10 469 mins \u2265 2.3 \u00d7 10 20 12 hrs-12 hrs-12 hrs"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Comparison of lower bounds with exact counts. The XOR size column reports the average.", "figure_data": "numexactXORHybrid-prob.varscountsizeMBoundMBoundbitmax252 21\u00d710 289 \u2265 1.9\u00d710 28 \u2265 9.2\u00d710 28log a1719 26\u00d710 1536 \u2265 1.1\u00d710 15 \u2265 11\u00d710 15php.10.20 200 6.7\u00d710 1117 \u2265 1.3\u00d710 11 \u2265 2.9\u00d710 11php.15.20 300 20\u00d710 1520 \u2265 1.1\u00d710 15-"}], "formulas": [{"formula_id": "formula_0", "formula_text": "D = {a, b, c, 1} represents the xor constraint a \u2295 b \u2295 c \u2295 1,", "formula_coordinates": [3.0, 54.0, 222.55, 238.5, 19.97]}, {"formula_id": "formula_1", "formula_text": "Algorithm 1: MBound Params: k, s,t, \u03b4 , \u03b1 : k, s,t positive integers, k \u2264 n/2, 0 < \u03b4 \u2264 1 / 2 , \u03b1 \u2265 1 Input : A CNF formula F Output : A lower or upper bound on MC(F), or Failure begin numSat \u2190 0 for i \u2190 1 to t do Q s \u2190 s random constraints from X k F k s \u2190 F \u222a Q s result \u2190 SATSolve(F k s ) if result = TRUE then numSat \u2190 numSat + 1 if numSat \u2265 t \u2022 ( 1 / 2 + \u03b4 ) then return Lower bound: MC(F) > 2 s\u2212\u03b1 else if numSat \u2264 t \u2022 ( 1 / 2 \u2212 \u03b4 )", "formula_coordinates": [3.0, 324.48, 59.84, 204.6, 163.53]}, {"formula_id": "formula_2", "formula_text": "Lemma 1. For 1 \u2264 k \u2264 n/2 and \u03b1 \u2265 1, Pr[MC(F k s ) \u2265 MC(F)/2 s\u2212\u03b1 ] \u2264 2 \u2212\u03b1 .", "formula_coordinates": [4.0, 54.0, 501.29, 238.51, 21.77]}, {"formula_id": "formula_3", "formula_text": "\u2212s , implying E[Y \u03c3 ] = 2 \u2212s . Let Y = \u2211 \u03c3 Y \u03c3 . The random variable Y equals MC(F k s ), and we have E[Y ] = E[\u2211 \u03c3 Y \u03c3 ] = \u2211 \u03c3 E[Y \u03c3 ] = \u2211 \u03c3 2 \u2212s = MC(F)/2 s . It follows that Pr[MC(F k s ) \u2265 MC(F)/2 s\u2212\u03b1 ] = Pr[Y \u2265 2 \u03b1 E[Y ]] \u2264 2 \u2212\u03b1 by Markov's inequality. Corollary 1. For 1 \u2264 k \u2264 n/2, \u03b1 \u2265 1, and s \u2265 s * + \u03b1, Pr[F k s is satisfiable] \u2264 2 \u2212\u03b1 . Proof. Observe that MC(F)/2 s\u2212\u03b1 = 2 s * \u2212(s\u2212\u03b1) \u2264 1. There- fore, Pr[F k s is satisfiable] = Pr[MC(F k s ) \u2265 1] \u2264 Pr[MC(F k s ) \u2265 MC(F)/2 s\u2212\u03b1 ] \u2264 2 \u2212\u03b1 .", "formula_coordinates": [4.0, 54.0, 53.59, 504.01, 649.93]}, {"formula_id": "formula_4", "formula_text": "\u03b1 \u2265 1, let \u03b2 = 2 \u03b1 ( 1 / 2 + \u03b4 ) \u2212 1 and define p(t, \u03b4 , \u03b1) = \uf8f1 \uf8f2 \uf8f3 2 \u2212\u03b1t if \u03b4 = 1 / 2 e \u03b2 (1+\u03b2 ) 1+\u03b2 t/2 \u03b1 if \u03b4 < 1 / 2 .", "formula_coordinates": [4.0, 319.5, 296.58, 204.69, 53.87]}, {"formula_id": "formula_5", "formula_text": "k,(i) s , 1 \u2264 i \u2264 t, is satisfiable is at most p(t, \u03b4 , \u03b1). Proof. Let Z i , 1 \u2264 i \u2264 t, be a random variable whose value is 1 if F k,(i) s", "formula_coordinates": [4.0, 319.5, 448.39, 238.51, 57.24]}, {"formula_id": "formula_6", "formula_text": "k,(i) s is satisfiable] \u2264 2 \u2212\u03b1 . Therefore, E[Z i ] = Pr[Z i = 1] = Pr[F k,(i) s is satisfiable] \u2264 2 \u2212\u03b1 so that E[Z] = \u2211 i E[Z i ] \u2264 t2 \u2212\u03b1 .", "formula_coordinates": [4.0, 319.5, 553.22, 238.5, 39.29]}, {"formula_id": "formula_7", "formula_text": "[Z \u2265 t \u2022 ( 1 / 2 + \u03b4 )]. For \u03b4 = 1 / 2 , this equals Pr[Z \u2265 t] = Pr[Z i = 1 for all i] \u2264 2 \u2212\u03b1t = p(t, 1 / 2 , \u03b1) because the random variables Z i are in- dependent. For \u03b4 < 1 / 2 , Pr[Z \u2265 t \u2022 ( 1 / 2 + \u03b4 )] \u2264 Pr[Z \u2265 2 \u03b1 ( 1 / 2 + \u03b4 )E[Z]].", "formula_coordinates": [4.0, 319.5, 604.33, 238.51, 59.9]}, {"formula_id": "formula_8", "formula_text": "Lemma 3. For \u03b1 \u2265 1 and s \u2264 s * , (A) Pr[MC(F n/2 s ) \u2264 MC(F)/2 s+\u03b1 ] \u2264 1/((1 \u2212 2 \u2212\u03b1 ) 2 2 s * \u2212s ) and (B) Pr[F n/2 s is unsatisfiable] \u2264 1/2 s * \u2212s .", "formula_coordinates": [5.0, 54.0, 542.65, 238.51, 40.13]}, {"formula_id": "formula_9", "formula_text": "For each \u03c3 \u2208 S, let Y \u03c3 = \u03c3 (F n/2 s ) be a 0-1 random variable. The expected value of Y \u03c3 is, as before, given by E[Y \u03c3 ] = 2 \u2212s . Further, its variance is Var[Y \u03c3 ] = E[Y 2 \u03c3 ] \u2212 E[Y \u03c3 ] 2 .", "formula_coordinates": [5.0, 54.0, 613.73, 238.5, 37.52]}, {"formula_id": "formula_10", "formula_text": "Var[Y \u03c3 ] \u2264 E[Y \u03c3 ].", "formula_coordinates": [5.0, 54.0, 662.15, 66.73, 10.05]}, {"formula_id": "formula_11", "formula_text": "Corollary 3. For \u03b1 \u2265 1 and s \u2264 s * \u2212 \u03b1, Pr[F n/2 s is unsatisfiable] \u2264 2 \u2212\u03b1 .", "formula_coordinates": [5.0, 319.5, 107.33, 238.5, 25.46]}, {"formula_id": "formula_12", "formula_text": "F n/2,(i) s , 1 \u2264 i \u2264 t, is unsatisfiable is at most p(t, \u03b4 , \u03b1).", "formula_coordinates": [5.0, 319.5, 173.88, 238.51, 23.64]}, {"formula_id": "formula_13", "formula_text": ", then Pr[Conservative lower bound is correct] \u2265 1 \u2212 2 \u2212\u03b1t , Pr[Moderate lower bound is correct] \u2265 1 \u2212 2 \u2212\u03b1 , and Pr[Aggressive lower bound is correct] \u2265 (1 \u2212 2 \u2212\u03b1 ) t .", "formula_coordinates": [6.0, 59.04, 512.4, 220.38, 41.84]}], "doi": ""}