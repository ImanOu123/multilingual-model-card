{"title": "Sparse coding for multitask and transfer learning", "authors": "Andreas Maurer", "pub_date": "2014-06-16", "abstract": "We investigate the use of sparse coding and dictionary learning in the context of multitask and transfer learning. The central assumption of our learning method is that the tasks parameters are well approximated by sparse linear combinations of the atoms of a dictionary on a high or infinite dimensional space. This assumption, together with the large quantity of available data in the multitask and transfer learning settings, allows a principled choice of the dictionary. We provide bounds on the generalization error of this approach, for both settings. Numerical experiments on one synthetic and two real datasets show the advantage of our method over single task learning, a previous method based on orthogonal and dense representation of the tasks and a related method learning task grouping.", "sections": [{"heading": "Introduction", "text": "The last decade has witnessed many efforts of the machine learning community to exploit assumptions of sparsity in the design of algorithms. A central development in this respect is the Lasso (Tibshirani, 1996), which estimates a linear predictor in a high dimensional space under a regularizing \u2113 1 -penalty. Theoretical results guarantee a good performance of this method under the assumption that the vector corresponding to the underlying predictor is sparse, or at least has a small \u2113 1 -norm, see e.g. (B\u00fchlmann & van de Geer, 2011) and references therein.\nIn this work we consider the case where the predictors are Proceedings of the 30 th International Conference on Machine Learning, Atlanta, Georgia, USA, 2013. JMLR: W&CP volume 28. Copyright 2013 by the author(s). linear combinations of the atoms of a dictionary of linear functions on a high or infinite dimensional space, and we assume that we are free to choose the dictionary. We will show that a principled choice is possible, if there are many learning problems, or \"tasks\", and there exists a dictionary allowing sparse, or nearly sparse representations of all or most of the underlying predictors. In such a case we can exploit the larger quantity of available data to estimate the \"good\" dictionary and still reap the benefits of the Lasso for the individual tasks. This paper gives theoretical and experimental justification of this claim, both in the domain of multitask learning, where the new representation is applied to the tasks from which it was generated, and in the domain of learning to learn, where the dictionary is applied to new tasks of the same environment.\nOur work combines ideas from sparse coding (Olshausen & Field, 1996), multitask learning (Ando & Zhang, 2005;Argyriou, Evgeniou, Pontil, 2008;Argyriou, Maurer, Pontil, 2008;Ben-David & Schuller, 2003;Caruana, 1997;Evgeniou, Micchelli, Pontil, 2005;Maurer, 2009) and learning to learn (Baxter, 2000;Thrun & Pratt, 1998). There is a vast literature on these subjects and the list of papers provided here is necessarily incomplete. Learning to learn (also called inductive bias learning or transfer learning) has been proposed by Baxter (2000) and an error analysis is provided therein, showing that a common representation which performs well on the training tasks will also generalize to new tasks obtained from the same \"environment\". The precursors of the analysis presented here are (Maurer & Pontil, 2010) and (Maurer, 2009). The first paper provides a bound on the reconstruction error of sparse coding and may be seen as a special case of the ideas presented here when the sample size is infinite. The second paper provides a learning to learn analysis of the multitask feature learning method in (Argyriou, Evgeniou, Pontil, 2008).\nWe note that a method similar to the one presented in this paper has been recently proposed within the multitask learning setting (Kumar & Daum\u00e9 III, 2012). Here we highlight the connection between sparse coding and multitask learning and present a probabilistic analysis which complements well with the practical insights in the above work. We also address the different problem of learning to learn, demonstrating the utility of our approach in this setting by means of both learning bounds and numerical experiments. A further novelty of our approach is that it applies to a Hilbert spaces setting, thereby providing the possibility of learning nonlinear predictors using reproducing kernel Hilbert spaces.\nThe paper is organized in the following manner. In Section 2, we set up our notation and introduce the learning problem. In Section 3, we present our learning bounds for multitask learning and learning to learn. In Section 4 we report on numerical experiments. Section 5 contains concluding remarks.", "publication_ref": ["b7", "b0", "b1", "b2", "b6", "b8", "b10", "b17", "b4", "b4", "b18", "b17", "b1", "b13"], "figure_ref": [], "table_ref": []}, {"heading": "Method", "text": "In this section, we turn to a technical exposition of the proposed method, introducing some necessary notation on the way.\nLet H be a finite or infinite dimensional Hilbert space with inner product \u2022, \u2022 , norm \u2022 , and fix an integer K. We study the problem\nmin D\u2208DK 1 T T t=1 min \u03b3\u2208C\u03b1 1 m m i=1 \u2113 ( D\u03b3, x ti , y ti ) ,(1)\nwhere \u2022 D K is the set of K-dimensional dictionaries (or simply dictionaries), which means that every D \u2208 D K is a linear map D : R K \u2192 H, such that De k \u2264 1 for every one of the canonical basis vectors e k of R K . The number K can be regarded as one of the regularization parameters of our method.\n\u2022 C \u03b1 is the set of code vectors \u03b3 in R K satisfying \u03b3 1 \u2264 \u03b1. The \u2113 1 -norm constraint implements the assumption of sparsity and \u03b1 is the other regularization parameter. Different sets C \u03b1 could be readily used in our method, such as those associated with \u2113 p -norms.\n\u2022 Z = ((x ti , y ti ) : 1 \u2264 i \u2264 m, 1 \u2264 t \u2264 T ) is a dataset\non which our algorithm operates. Each x ti \u2208 H represents an input vector, and y ti is a corresponding real valued label. We also write Z = (X, Y) = (z 1 , . . . , z T ) = ((x 1 , y 1 ) , . . . , (x T , y T )) with x t = (x t1 , . . . , x tm ) and y t = (y t1 , . . . , y tm ). The index t identifies a learning task, and z t are the corresponding training points, so the algorithm operates on T tasks, each of which is represented by m example pairs.\n\u2022 \u2113 is a loss function where \u2113 (y, y \u2032 ) measures the loss incurred by predicting y when the true label is y \u2032 . We assume that \u2113 has values in [0, 1] and has Lipschitz constant L in the first argument for all values of the second argument.\nThe minimum in ( 1) is zero if the data is generated according to a noise-less model which postulates that there is a \"true\" dictionary D * \u2208 D K * with K * atoms and vectors \u03b3 * 1 , . . . , \u03b3 * T satisfying \u03b3 * t 1 \u2264 \u03b1 * , such that an input x \u2208 H generates the label y = D * \u03b3 * t , x in the context of task t. If K \u2265 K * and \u03b1 \u2265 \u03b1 * then the minimum in (1) is zero. In Section 4, we will present experiments with such a generative model, when noise is added to the labels, that is y = D * \u03b3 * t , x + \u03b6 with \u03b6 \u223c N (0, \u03c3), the standard normal distribution.\nThe method (1) should output a minimizing D (Z) \u2208 D K as well as a minimizing \u03b3 1 (Z) , . . . , \u03b3 T (Z) corresponding to the different tasks. Our implementation, described in Section 4.1, does not guarantee exact minimization, because of the non-convexity of the problem. Below predictors are always linear, specified by a vector w \u2208 H, predicting the label w, x for an input x \u2208 H, and a learning algorithm is a rule which assigns a predictor A (z) to a given data set z = ((x i , y\ni ) : 1 \u2264 i \u2264 m) \u2208 (H \u00d7 R) m .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Learning bounds", "text": "In this section, we present learning bounds for method (1), both in the multitask learning and learning to learn settings, and discuss the special case of sparse coding.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Multitask learning", "text": "Let \u00b5 1 , . . . , \u00b5 T be probability measures on H \u00d7 R. We interpret \u00b5 t (x, y) as the probability of observing the input/output pair (x, y) in the context of task t. For each of these tasks an i\n.i.d. training sample z t = ((x ti , y ti ) : 1 \u2264 i \u2264 m) is drawn from (\u00b5 t ) m and the en- semble Z \u223c T t=1 \u00b5 m\nt is input to algorithm (1). Upon returning of a minimizing D (Z) and \u03b3 1 (Z) , . . . , \u03b3 T (Z), we will use the predictor D (Z) \u03b3 t (Z) on the t-th task. The average over all tasks of the expected error incurred by these predictors is\n1 T T t=1 E (x,y)\u223c\u00b5 t [\u2113 ( D (Z) \u03b3 t (Z) , x , y)] .\nWe compare this task-average risk to the minimal analogous risk obtainable by any dictionary D \u2208 D K and any set of vectors \u03b3 1 , . . . , \u03b3 T \u2208 C \u03b1 . Our first result is a bound on the excess risk.\nTheorem 1. Let \u03b4 > 0 and let \u00b5 1 , . . . , \u00b5 T be probability measures on H \u00d7 R. With probability at least 1 \u2212 \u03b4 in the draw of Z \u223c T t=1 \u00b5 m t we have\n1 T T t=1 E (x,y)\u223c\u00b5 t [\u2113 ( D (Z) \u03b3 t (Z) , x , y)] \u2212 inf D\u2208DK 1 T T t=1 inf \u03b3\u2208C\u03b1 E (x,y)\u223c\u00b5 t [\u2113 ( D\u03b3, x , y)] \u2264 L\u03b1 2S 1 (X) (K + 12) mT + L\u03b1 8S \u221e (X) ln (2K) m + 8 ln 4/\u03b4 mT ,\nwhere\nS 1 (X) = 1 T T t=1 tr \u03a3 (x t ) and S \u221e (X) = 1 T T t=1 \u03bb max \u03a3 (x t ) . Here\u03a3 (x t )\nis the empirical covariance of the input data for the t-th task, tr (\u2022) denotes the trace and \u03bb max (\u2022) the largest eigenvalue.\nWe state several implications of this theorem.\n1. The quantity S 1 (X) appearing in the bound is just the average square norm of the input data points, while S \u221e (X) is roughly the average inverse of the observed dimension of the data for each task. Suppose that H = R d and that the data-distribution is uniform on the surface of the unit ball. Then S 1 (X) = 1 and for m \u226a d it follows from Levy's isoperimetric inequality (see e.g. (Ledoux & Talagrand, 1991)) that S \u221e (X) \u2248 1/m, so the corresponding term behaves like \u221a ln K/m. If the minimum in (1) is small and T is large enough for this term to become dominant then there is a significant advantage of the method over learning the tasks independently. If the data is essentially low dimensional, then S \u221e (X) will be large, and in the extreme case, if the data is one-dimensional for all tasks then S \u221e (X) = S 1 (X) and our bound will always be worse by a factor of ln K than standard bounds for independent single task learning as in (Bartlett & Mendelson, 2002). This makes sense, because for low dimensional data there can be little advantage to multitask learning.\n2. In the regime T < K the bound is dominated by the term of order S 1 (X) K/mT > S 1 (X) /m. This is easy to understand, because the dictionary atoms De k can be chosen independently, separately for each task, so we could at best recover the usual bound for linear models and there is no benefit from multitask learning.\n3. Consider the noiseless generative model mentioned in Section 2. If K \u2265 K * and \u03b1 \u2265 \u03b1 * then the min-imum in (1) is zero. In the bound the overestimation of K * can be compensated by a proportional increase in the number of tasks considered and an only very minor increase of the sample size m, namely m \u2192 (ln K * / ln K) m.\n4. Suppose that we concatenate two sets of tasks. If the tasks are generated by the model described in Section 2 then the resulting set of tasks is also generated by such a model, obtained by concatenating the lists of atoms of the two true dictionaries D * 1 and D * 2 to obtain the new dictionary D * of length K * = K * 1 + K * 2 and taking the union of the set of generating vectors \u03b3 * 1 t T t=1 and \u03b3 * 2 t T t=1 , extending them to R K * 1 +K * 2 so that the supports of the first group are disjoint from the supports of the second group. If T 1 = T 2 , K * 1 = K * 2 and we train with the correct parameters, then the excess risk for the total task set increases only by the order of 1/ \u221a m, independent of K, despite the fact that the tasks in the second group are in no way related to those in the first group. Our method has the property of finding the right clusters of mutually related tasks.\n5. Consider the alternative method of subspace learning (SL) where C \u03b1 is replaced by an euclidean ball of radius \u03b1. With similar methods one can prove a bound for SL where, apart from slightly different constants, \u221a ln K above is replaced by K. SL will be successful and outperform the proposed method, whenever K can be chosen small, with K < m and the vector \u03b3 * t utilize the entire span of the dictionary. For large values of K, a correspondingly large number of tasks and sparse \u03b3 * t the proposed method will be superior.\nThe proof of Theorem 1, which is given in Section B.1 of the supplementary appendix, uses standard methods of empirical process theory, but also employs a concentration result related to Talagrand's convex distance inequality to obtain the crucial dependence on S \u221e (X). At the end of Section B.1 we sketch applications of the proof method to other regularization schemes, such as the one presented in (Kumar & Daum\u00e9 III, 2012), in which the Frobenius norm on the dictionary D is used in place of the \u2113 2 /\u2113 \u221e -norm employed here and the \u2113 1 /\u2113 1 norm on the coefficient matrix [\u03b3 1 , . . . , \u03b3 T ] is used in place of the \u2113 1 /\u2113 \u221e .", "publication_ref": ["b14", "b3", "b13"], "figure_ref": [], "table_ref": []}, {"heading": "Learning to learn", "text": "There is no absolute way to assess the quality of a learning algorithm. Algorithms may perform well on one kind of task, but poorly on another kind. It is important that an algorithm performs well on those tasks which it is likely to be applied to. To formalize this, Baxter (2000) introduced the notion of an environment, which is a probability mea-sure E on the set of tasks. Thus E (\u03c4 ) is the probability of encountering the task \u03c4 in the environment E, and \u00b5 \u03c4 (x, y) is the probability of finding the pair (x, y) in the context of the task \u03c4 .\nGiven E, the transfer risk (or simply risk) of a learning algorithm A is defined as follows. We draw a task from the environment, \u03c4 \u223c E, which fixes a corresponding distribution \u00b5 \u03c4 on H \u00d7R. Then we draw a training sample z \u223c \u00b5 m \u03c4 and use the algorithm to compute the predictor A (z). Finally we measure the performance of this predictor on test points (x, y) \u223c \u00b5 \u03c4 . The corresponding definition of the transfer risk of A reads as\nR E (A) = E \u03c4 \u223cE E z\u223c\u00b5 m \u03c4 E (x,y)\u223c\u00b5 \u03c4 [\u2113 ( A (z) , x , y)]\n(2) which is simply the expected loss incurred by the use of the algorithm A on tasks drawn from the environment E.\nFor any given dictionary D \u2208 D K we consider the learning algorithm A D , which for z \u2208 Z m computes the predictor\nA D (z) = D arg min \u03b3\u2208C\u03b1 1 m m i=1 \u2113 ( D\u03b3, x i , y i ) .\n(3)\nEquivalently, we can regard A D as the Lasso operating on data preprocessed by the linear map D \u22a4 , the adjoint of D.\nWe can make a single observation of the environment E in the following way: one first draws a task \u03c4 \u223c E. This task and the corresponding distribution \u00b5 \u03c4 are then observed by drawing an i.i.d. sample z from \u00b5 \u03c4 , that is z \u223c \u00b5 m \u03c4 . For simplicity the sample size m will be fixed. Such an observation corresponds to the draw of a sample z from a probability distribution \u03c1 E on (H \u00d7 R) m which is defined by\n\u03c1 E (z) := E \u03c4 \u223cE [(\u00b5 \u03c4 ) m (z)] .(4)\nTo estimate an environment a large number T of independent observations is needed, corresponding to a vector\nZ = (z 1 , . . . , z T ) \u2208 ((H \u00d7 R) m ) T drawn i.i.d. from \u03c1 E , that is Z \u223c (\u03c1 E ) T .\nWe now propose to solve the problem (1) with the data Z, ignore the resulting \u03b3 i (Z), but retain the dictionary D (Z) and use the algorithm A D(Z) on future tasks drawn from the same environment. The performance of this method can be quantified as the transfer risk R E A D(Z) as defined in equation ( 2) and again we are interested in comparing this to the risk of an ideal solution based on complete knowledge of the environment. For any fixed dictionary D and task \u03c4 the best we can do is to choose \u03b3 \u2208 C so as to minimize E (x,y)\u223c\u00b5 \u03c4 [\u2113 ( D\u03b3, x , y)], so the best is to choose D so as to minimize the average of this over \u03c4 \u223c E. The quantity\nR opt = min D\u2208DK E \u03c4 \u223cE min \u03b3\u2208C\u03b1 E (x,y)\u223c\u00b5 \u03c4 \u2113 [( D\u03b3, x , y)]\nthus describes the optimal performance achievable under the given constraint. Our second result is Theorem 2. With probability at least 1 \u2212 \u03b4 in the multisample Z = (X, Y) \u223c \u03c1 T E we have\nR E A D(Z) \u2212 R opt \u2264 L\u03b1K 2\u03c0S 1 (X) T +4L\u03b1 S \u221e (E) (2 + ln K) m + 8 ln 4/\u03b4 T ,\nwhere S 1 (X) is as in Theorem 1 and S \u221e (E) :=\nE \u03c4 \u223cE E (x,y)\u223c\u00b5 m \u03c4 \u03bb max \u03a3 (x) .\nWe discuss some implications of the above theorem. 1.\n1. The interpretation of S \u221e (E) is analogous to that of S \u221e (X) in the bound for Theorem 1. The same applies to Remark 6 following Theorem 1.\n2. In the regime T \u2264 K 2 the result does not imply any useful behaviour. On the other and, if T \u226b K 2 the dominant term in the bound is of order S \u221e (E) /m.", "publication_ref": ["b4"], "figure_ref": [], "table_ref": []}, {"heading": "3.", "text": "There is an important difference with the multitask learning bound, namely in Theorem 2 we have \u221a T in the denominator of the first term of the excess risk, and not \u221a mT as in Theorem 1. This is because in the setting of learning to learn there is always a possibility of being misled by the draw of the training tasks. This possibility can only decrease as T increases -increasing m does not help.\nThe proof of Theorem 2 is given in Section B.2 of the supplementary appendix and follows the method outlined in (Maurer, 2009): one first bounds the estimation error for the expected empirical risk on future tasks, and then combines this with a bound of the expected true risk by said expected empirical risk. The term K/ \u221a T may be an artefact of our method of proof and the conjecture that it can be replaced by K/T seems plausible.", "publication_ref": ["b17"], "figure_ref": [], "table_ref": []}, {"heading": "Connection to sparse coding", "text": "We discuss a special case of Theorem 2 in the limit m \u2192 \u221e, showing that it subsumes the sparse coding result in (Maurer & Pontil, 2010). To this end, we assume the noiseless generative model y ti = w t , x ti described in Section 2, that is \u00b5(x, y) = p(x)\u03b4(y, w, x ), where p is the uniform distribution on the sphere in R d (i.e. the Haar measure). In this case the environment of tasks is fully specified by a measure \u03c1 on the unit ball in R d from which a task w \u2208 R d is drawn and the measure \u00b5 is identified with the vector w. Note that we do not assume that these tasks are obtained as sparse combinations of some dictionary. Under the above assumptions and choosing \u2113 to be the square loss, we have that E (x,y)\u223c\u00b5 t \u2113( w, x , y) = w t \u2212 w 2 . Consequently, in the limit of m \u2192 \u221e method (1) reduces to a constrained version of sparse coding (Olshausen & Field, 1996), namely\nmin D\u2208DK 1 T T t=1 min \u03b3\u2208C\u03b1 D\u03b3 \u2212 w t 2 .\nIn turn, the transfer error of a dictionary D is given by the quantity R(D) := min \u03b3\u2208C\u03b1 D\u03b3 \u2212 w 2 and R opt = min D\u2208DK E w\u223c\u03c1 min \u03b3\u2208C\u03b1 D\u03b3 \u2212 w 2 . Given the constraints D \u2208 D K , \u03b3 \u2208 C \u03b1 and x \u2264 1, the square loss \u2113 (y, y \u2032 ) = (y \u2212 y \u2032 ) 2 , evaluated at y = D\u03b3, x , can be restricted to the interval y \u2208 [\u2212\u03b1, \u03b1], where it has the Lipschitz constant 2 (1 + \u03b1) for any y \u2032 \u2208 [\u22121, 1], as is easily verified. Since S 1 (X) = 1 and S \u221e (E) < \u221e, the bound in Theorem 2 becomes\nR(D) \u2212 R opt \u2264 2\u03b1(1 + \u03b1)K 2\u03c0 T + 8 ln 4/\u03b4 T (5)\nin the limit m \u2192 \u221e. The typical choice for \u03b1 is \u03b1 \u2264 1, which ensures that D\u03b3 \u2264 1. In this case inequality ( 5) provides an improvement over the sparse coding bound in (Maurer & Pontil, 2010) (cf. Theorem 2 and Section 2.4 therein), which contains an additional term of the order of (ln T )/T and the same leading term in K as in ( 5) but with slightly worse constant (14 instead of 4 \u221a 2\u03c0). The connection of our method to sparse coding is experimentally demonstrated in Section 4.4 and illustrated in Figure 6.", "publication_ref": ["b18", "b18"], "figure_ref": ["fig_5"], "table_ref": []}, {"heading": "Experiments", "text": "In this section, we present experiments on a synthetic and two real datasets. The aim of the experiments is to study the statistical performance of the proposed method, in both settings of multitask learning and learning to learn. We compare our method, denoted as Sparse Coding Multi Task Learning (SC-MTL), with independent ridge regression (RR) as a base line and multitask feature learning (MTFL) (Argyriou, Evgeniou, Pontil, 2008) and GO-MTL (Kumar & Daum\u00e9 III, 2012). We also report on sensitivity analysis of the proposed method versus different number of parameters involved.", "publication_ref": ["b1", "b13"], "figure_ref": [], "table_ref": []}, {"heading": "Optimization algorithm", "text": "We solve problem (1) by alternating minimization over the dictionary matrix D and the code vectors \u03b3. The techniques we use are very similar to standard methods for sparse coding and dictionary learning, see e.g. (Jenatton et al., 2011) and references therein for more information. Briefly, assuming that the loss function \u2113 is convex and has Lipschitz continuous gradient, either minimization problem is convex and can be solved efficiently by proximal gradient methods, see e.g. (Beck & Teboulle, 2009;Combettes & Wajs, 2006). The key ingredient in each step is the computation of the proximity operator, which in either problem has a closed form expression.", "publication_ref": ["b11", "b5", "b9"], "figure_ref": [], "table_ref": []}, {"heading": "Toy experiment", "text": "We generated a synthetic environment of tasks as follows. We choose a d\u00d7K matrix D by sampling its columns independently from the uniform distribution on the unit sphere in R d . Once D is created, a generic task in the environment is given by w = D\u03b3, where \u03b3 is an s-sparse vector obtained as follows. First, we generate a set J \u2286 {1, . . . , K} of cardinality s, whose elements (indices) are sampled uniformly without replacement from the set {1, . . . , K}. We then set \u03b3 j = 0 if j / \u2208 J and otherwise sample \u03b3 j \u223c N (0, 0.1). Finally, we normalize \u03b3 so that it has \u2113 1 -norm equal to some prescribed value \u03b1. Using the above procedure we generated T tasks w t = D\u03b3 t , t = 1, . . . , T . Further, for each task t we generated a training set z t = {(x ti , y ti )} m i=1 , sampling x ti i.i.d. from the uniform distribution on the unit sphere in R d . We then set y ti = w t , x ti + \u03be ti , with \u03be ti \u223c N (0, \u03c3 2 ), where \u03c3 is the variance of the noise. This procedure also defines the generation of new tasks in the transfer learning experiments below.  The above model depends on seven parameters: the number K and the dimension d of the atoms, the sparsity s and the \u2113 1 -norm \u03b1 of the codes, the noise level \u03c3, the sample size per task m and the number of training tasks T . In all experiments we report both the multitask learning (MTL) and learning to learn (LTL) performance of the methods. For MTL, we measure performance by the estimation error 1/T T t=1 w t \u2212\u0175 t 2 , where\u0175 1 , . . . ,\u0175 T are the estimated task vectors (in the case of SC-MTL, w t = D(Z)\u03b3(Z) t -see the discussion in Section 2. For LTL, we use the same quantity but with a new set of tasks generated by the environment (in the experiment below we generate 100 new tasks). The regularization parameter of each method is chosen by cross validation. Finally, all experiments are repeated 50 times, and the average performance results are reported in the plots below.\nIn the first experiment, we fix K = 10, d = 20, s = 2, \u03b1 = 10, m = 10, \u03c3 = 0.1 and study the statistical performance of the methods as a function of the number of tasks. The results, shown in Figure 1, clearly indicate that the proposed method outperforms the remaining approaches. In this experiment the number of atoms used by dictionarybased approaches, which here we denote by K \u2032 to avoid confusion with the number of atoms K of the target dictionary, was equal to K = 10. This gives an advantage to both GO-MTL and SC-MTL. We therefore also studied the performance of those methods in dependence on K \u2032 . Figure 2, reporting this result, is in qualitative agreement with our theoretical analysis: the performance of SC-MTL is not too sensitive to K \u2032 if K \u2032 \u2265 K, and the method still outperforms independent RR and MTFL if K \u2032 = 4K. On the other hand if K \u2032 < K the performance of the method quickly degrades. In the last experiment we study performance vs. the sparsity ratio s/K. Intuitively we would expect our method to have greater advantage over MTL if s \u226a K. The results, shown in Figure 3, confirm this fact, also indicating that SC-MTL is outperformed by both GO-MTL and MTFL as sparsity becomes less pronounced (s/K > 0.6).", "publication_ref": [], "figure_ref": ["fig_0", "fig_1", "fig_2"], "table_ref": []}, {"heading": "Learning to learn optical character recognition", "text": "We have conducted experiments on real data to study the performance of our method in a learning to learn / transfer learning setting. To this end, we employed the NIST dataset 1 , which is composed of a set of 14 \u00d7 14 pixels images of handwritten characters (digits and lower and capital case letters, for a total of 52 characters).\nWe considered the following experimental protocol. First, a set of 20 characters are chosen randomly as well as n instances for each character. These are used to learn all possibilities of 1-vs-1 train tasks, which makes T = 190,  each of which having m = 2n instances. The knowledge learned in this stage is employed to learn another set of target tasks. In our approach, the assumption that is made is that some of the components in the dictionary learned from the training tasks, can also be useful for representing the target tasks. In order to create the target tasks, another set of 10 characters are chosen among the remaining set of characters in the dataset, inducing a set of 45 1-vs-1 classification tasks. Since we are interested in the case where the training set size of the target tasks is small, we sample only 3 instances for each character, hence 6 examples per task.\nIn order to tune the hyperparameters of all compared approaches, we have also created another set of 45 validation tasks by following the process previously described, simulating the target set of tasks. Note that there is not overlapping between the digits associated to the train, target and validation tasks.\nWe have run 50 trials of the above process for different values of m and the average multiclass accuracy on the target tasks is reported in Figure 4.", "publication_ref": [], "figure_ref": ["fig_3"], "table_ref": []}, {"heading": "Sparse coding of images with missing pixels", "text": "In the last experiment we consider a sparse coding problem (Olshausen & Field, 1996) of optical character images, with missing pixels. We employ the Binary Alphadigits dataset 2 , which is composed of a set of binary 20 \u00d7 16 images of all digits and capital letters (39 images for each character). In the following experiment only the digits are used. We regard each image as a task, hence the input space is the set of 320 possible pixels indices, while the output space is the real interval [0, 1], representing the gray level. We sample T = 100, 130, 160, 190, 220, 250 images, equally divided among the 10 possible digits. For each of these, a corresponding random set of m = 160 pixel values are sampled (so the set of sample pixels varies 2 Available at http://www.cs.nyu.edu/ roweis/data.html. from one image to another).\nWe test the performance of the dictionary learned by method (1) in a learning to learn setting, by choosing 100 new images. The regularization parameter for each approach is tuned using cross validation. The results, shown in Figure 5, indicate some advantage of the proposed method over trace norm regularization. A similar trend, not reported here due to space constraints, is obtained in the multitask setting. Ridge regression performed significantly worse and is not shown in the figure. We also show as a reference the performance of sparse coding (SC) applied when all pixels are known.\nWith the aim of analyzing the atoms learned by the algorithm, we have carried out another experiment where we assume that there are 10 underlying atoms (one for each digit). We compare the resultant dictionary to that obtained by sparse coding, where all pixels are known. The results are shown in Figure 6. ", "publication_ref": [], "figure_ref": ["fig_4", "fig_5"], "table_ref": []}, {"heading": "Summary", "text": "In this paper, we have explored an application of sparse coding, which has been widely used in unsupervised learning and signal processing, to the domains of multitask learning and learning to learn. Our learning bounds provide a justification of this method and offer insights into its advantage over independent task learning and learning dense representation of the tasks. The bounds, which hold in a Hilbert space setting, depend on data dependent quantities which measure the intrinsic dimensionality of the data. Numerical simulations presented here indicate that sparse coding is a promising approach to multitask learning and can lead to significant improvements over competing methods.\nIn the future, it would be valuable to study extensions of our analysis to more general classes of code vectors. For example, we could use code sets C \u03b1 which arise from structured sparsity norms, such as the group Lasso, see e.g. (Jenatton et al., 2011;Lounici et al., 2011) or other families of regularizers. A concrete example which comes to mind is to choose K = Qr, Q, r \u2208 N and a partition J = {{(q \u2212 1)r + 1, . . . , qr} : q = 1, . . . , Q} of the index set {1, . . . , K} into contiguous index sets of size r. Then using a norm of the type \u03b3 = \u03b3 1 + J\u2208J \u03b3 J 2 will encourage codes which are sparse and use only few of the groups in J . Using the ball associated with this norm as our set of codes would allow to model sets of tasks which are divided into groups. A further natural extension of our method is nonlinear dictionary learning in which the dictionary columns correspond to functions in a reproducing kernel Hilbert space and the tasks are expressed as sparse linear combinations of such functions. ", "publication_ref": ["b11", "b15"], "figure_ref": [], "table_ref": []}, {"heading": "A. Notation and tools", "text": "Issues of measurability will be ignored throughout, in particular, if F is a class of real valued functions on a domain X and X a random variable with values in X then we will always write E sup f \u2208F f (X) to mean sup {E max f \u2208F0 f (X) : F 0 \u2286 F , F 0 finite}.\nIn the sequel H denotes a finite or infinite dimensional Hilbert space with inner product \u2022, \u2022 and norm \u2022 . If T is a bounded linear operator on H its operator norm is written A multisample is a vector Z = (z 1 , . . . , z T ) composed of samples. We also write Z = (X, Y) with X = (x 1 , . . . , x T ).\nT \u221e = sup { T x : x = 1}.\nFor members of R K we use the greek letters \u03b3 or \u03b2. Depending on context the inner product and euclidean norm on R K will also be denoted with \u2022, \u2022 and . . The \u2113 1norm \u2022 1 on R K is defined by \u03b2 1 = K k=1 |\u03b2 k |. In the sequel we denote with C \u03b1 the set \u03b2 \u2208 R K : \u03b2 1 \u2264 \u03b1 , abbreviate C for the \u2113 1 -unit ball C 1 . The canonical basis of R K is denoted e 1 , . . . , e K . Unless otherwise specified the summation over the index i will always run from 1 to m, t will run from 1 to T , and k will run from 1 to K.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A.1. Covariances", "text": "For x \u2208H m the empirical covariance operator\u03a3 (x) is specified by\n\u03a3 (x) v, w = 1 m i v, x i x i , w , v, w \u2208 H.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "The definition implies the inequality", "text": "i v, x i 2 = m \u03a3 (x) v, v \u2264 m \u03a3 (x) \u221e v 2 . (6\n)\nIt also follows that tr \u03a3 (x) = (1/m) i x i 2 .\nFor a multisample X \u2208 H mT we will consider two quantities defined in terms of the empirical covariances.\nS 1 (X) = 1 T t \u03a3 (x t ) 1 := 1 T t tr \u03a3 (x t ) S \u221e (X) = 1 T t \u03a3 (x t ) \u221e := 1 T t \u03bb max \u03a3 (x t )\nwhere \u03bb max is the largest eigenvalue. If all data points x ti lie in the unit ball of H then S 1 (X) \u2264 1. Of course S 1 (X) can also be written as the trace of the total covariance (1/T ) t\u03a3 (x t ), while S \u221e (X) will always be at least as large as the largest eigenvalue of the total covariance. We always have S \u221e (X) \u2264 S 1 (X), with equality only if the data is one-dimensional for all tasks. The quotient S 1 (X) /S \u221e (X) can be regarded as a crude measure of the effective dimensionality of the data. If the data have a high dimensional distribution for each task then S \u221e (X) can be considerably smaller than S 1 (X).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A.2. Concentration inequalities", "text": "Let X be any space. For x \u2208 X n , 1 \u2264 k \u2264 n and y \u2208 X we use x k\u2190y to denote the object obtained from x by replacing the k-th coordinate of x with y. That is\nx k\u2190y = (x 1 , . . . , x k\u22121 , y, x k+1 , . . . , x n ) .\nThe concentration inequality in part (i) of the following theorem, known as the bounded difference inequality is given in (McDiarmid, 1998). A proof of inequality (ii) is given in (Maurer, 2006).\nTheorem 3. Let F : X n \u2192 R and define A and B by\nA 2 = sup x\u2208X n n k=1 sup y1,y2\u2208X (F (x k\u2190y1 ) \u2212 F (x k\u2190y2 )) 2 B 2 = sup x\u2208X n n k=1 F (x) \u2212 inf y\u2208X F (x k\u2190y ) 2 .\nLet X = (X 1 , . . . , X n ) be a vector of independent random variables with values in X , and let X \u2032 be i.i.d. to X. Then for any s > 0\n(i) Pr {F (X) > EF (X \u2032 ) + s} \u2264 e \u22122s 2 /A 2 ; (ii) Pr {F (X) > EF (X \u2032 ) + s} \u2264 e \u2212s 2 /(2B 2 ) .", "publication_ref": ["b16"], "figure_ref": [], "table_ref": []}, {"heading": "A.3. Rademacher and Gaussian averages", "text": "We will use the term Rademacher variables for any set of independent random variables, uniformly distributed on {\u22121, 1}, and reserve the symbol \u03c3 for Rademacher variables. A set of random variables is called orthogaussian if the members are independent N (0, 1)-distributed (standard normal) variables and reserve the letter \u03b6 for standard normal variables. Thus \u03c3 1 , \u03c3 2 , . . . , \u03c3 i , . . . , \u03c3 11 , . . . , \u03c3 ij etc. will always be independent Rademacher variables and \u03b6 1 , \u03b6 2 , . . . , \u03b6 i , . . . , \u03b6 11 , . . . , \u03b6 ij will always be orthogaussian.\nFor A \u2286 R n we define the Rademacher and Gaussian averages of A (Ledoux & Talagrand, 1991;Bartlett & Mendelson, 2002) as\nR (A) = E \u03c3 sup (x1,...,xn)\u2208A 2 n n i=1 \u03c3 i x i , G (A) = E \u03b6 sup (x1,...,xn)\u2208A 2 n n i=1 \u03b6 i x i .\nIf F is a class of real valued functions on a space X and x = (x 1 , . . . , x n ) \u2208 X n we write\nF (x) = F (x 1 , . . . , x n ) = {(f (x 1 ) , . . . , f (x n )) : f \u2208 F } \u2286 R n .\nThe empirical Rademacher and Gaussian complexities of F on x are respectively R (F (x)) and G (F (x)).\nThe utility of these concepts for learning theory comes from the following key-result (see (Bartlett & Mendelson, 2002;Koltchinskii & Panchenko, 2002)), stated here in two portions for convenience in the sequel.\nTheorem 4. Let F be a real-valued function class on a space X and \u00b5 1 , . . . , \u00b5 m be probability measures on X with product measure\n\u00b5 = i \u00b5 i on X m . For x \u2208 X m define \u03a6 (x) = sup f \u2208F 1 m m i=1 E x\u223c\u00b5 i [f (x)] \u2212 f (x i ) . Then E x\u223c\u00b5 [\u03a6 (x)] \u2264 E x\u223c\u00b5 R (F (x)).\nProof. For any realization \u03c3 = \u03c3 1 , . . . , \u03c3 m of the Rademacher variables\nE x\u223c\u00b5 [\u03a6 (x)] = E x\u223c\u00b5 sup f \u2208F 1 m E x \u2032 \u223c\u00b5 m i=1 (f (x \u2032 i ) \u2212 f (x i )) \u2264 E x,x \u2032 \u223c\u00b5\u00d7\u00b5 sup f \u2208F 1 m m i=1 \u03c3 i (f (x \u2032 i ) \u2212 f (x i )) ,\nbecause of the symmetry of the measure\n\u00b5 \u00d7 \u00b5 (x, x \u2032 ) = i \u00b5 i \u00d7 i \u00b5 i (x, x \u2032 )under the in- terchange x i \u2194 x \u2032 i .\nTaking the expectation in \u03c3 and applying the triangle inequality gives the result.\nTheorem 5. Let F be a [0, 1]-valued function class on a space X , and \u00b5 as above. For \u03b4 > 0 we have with probability greater than 1 \u2212 \u03b4 in the sample x \u223c \u00b5 that for all f \u2208 F\nE x\u223c\u00b5 [f (x)] \u2264 1 m m i=1 f (x i )+E x\u223c\u00b5 R (F (x))+ ln (1/\u03b4) 2m .\nTo prove this we apply the bounded-difference inequality ( part (i) of Theorem 3) to the function \u03a6 of the previous theorem (see e.g. (Bartlett & Mendelson, 2002)). Under the conditions of this result, changing one of the x i will not change R (F (x)) by more than 2, so again by the bounded difference inequality applied to R (F (x)) and a union bound we obtain the data dependent version Corollary 6. Let F and \u00b5 be as above. For \u03b4 > 0 we have with probability greater than 1 \u2212 \u03b4 in the sample x \u223c \u00b5 that for all f \u2208 F\nE x\u223c\u00b5 [f (x)] \u2264 1 m m i=1 f (x i ) + R (F (x)) + 9 ln (2/\u03b4) 2m .\nTo bound Rademacher averages the following result is very useful (Bartlett & Mendelson, 2002;Ando & Zhang, 2005;Ledoux & Talagrand, 1991) Lemma 7. Let A \u2286 R n , and let \u03c8 1 , . . . , \u03c8 n be real functions such that \u03c8 i (s) \u2212 \u03c8 i (t) \u2264 L |s \u2212 t|,\u2200i, and s, t \u2208 R.\nDefine\n\u03c8 (A) = {\u03c8 1 (x 1 ) , . . . , \u03c8 n (x n ) : (x 1 , . . . , x n ) \u2208 A}. Then R (\u03c8 (A)) \u2264 LR (A) .\nSometimes it is more convenient to work with gaussian averages which can be used instead, by virtue of the next lemma. For a proof see e.g. (Ledoux & Talagrand, 1991) ", "publication_ref": ["b14", "b3", "b3", "b12", "b3", "b3", "b0", "b14", "b14"], "figure_ref": [], "table_ref": []}, {"heading": "Lemma 8. For", "text": "A \u2286 R k we have R (A) \u2264 \u03c0/2 G (A).\nThe next result is known as Slepian's lemma ((Slepian, 1962), (Ledoux & Talagrand, 1991)).", "publication_ref": ["b14"], "figure_ref": [], "table_ref": []}, {"heading": "Theorem 9.", "text": "Let \u2126 and \u039e be mean zero, separable Gaussian processes indexed by a common set S, such that\nE (\u2126 s1 \u2212 \u2126 s2 ) 2 \u2264 E (\u039e s1 \u2212 \u039e s2 ) 2 for all s 1 , s 2 \u2208 S. Then E sup s\u2208S \u2126 s \u2264 E sup s\u2208S \u039e s .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B. Proofs", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B.1. Multitask learning", "text": "In this section we prove Theorem 1. It is an immediate consequence of Hoeffding's inequality and the following uniform bound on the estimation error.\nTheorem 10. Let \u03b4 > 0, fix K and let \u00b5 1 , . . . , \u00b5 T be probability measures on H \u00d7 R. With probability at least 1 \u2212 \u03b4 in the draw of Z \u223c T t=1 \u00b5 t we have for all D \u2208 D K and all \u03b3 \u2208 C T \u03b1 that\n1 T T t=1 E (x,y)\u223c\u00b5 t [\u2113 ( D\u03b3 t , x , y)] \u2212 1 mT T t=1 m i=1 \u2113 ( D\u03b3 t , x ti , y ti ) \u2264 L\u03b1 2S 1 (X) (K + 12) mT + L\u03b1 8S \u221e (X) ln (2K) m + 9 ln 2/\u03b4 2mT .\nThe proof of this theorem requires auxiliary results. Fix X \u2208 H mT and for \u03b3 = (\u03b3 1 , . . . , \u03b3 T ) \u2208 R K T define the random variable\nF \u03b3 = F \u03b3 (\u03c3) = sup D\u2208DK t,i \u03c3 ti D\u03b3 t , x ti . (7\n)\nLemma 11. (i) If \u03b3 = (\u03b3 1 , . . . , \u03b3 T ) satisfies \u03b3 t \u2264 1 for all t, then EF \u03b3 \u2264 mT K S 1 (X).\n(ii) If \u03b3 satisfies \u03b3 t 1 \u2264 1 for all t, then for any s \u2265 0\nPr {F \u03b3 \u2265 E [F \u03b3 ] + s} \u2264 exp \u2212s 2 8mT S \u221e (X)\n.\nProof. (i) We observe that\nEF \u03b3 = E sup D k De k , t,i \u03c3 ti \u03b3 tk x ti \u2264 sup D k De k 2 1/2 E \uf8eb \uf8ec \uf8ed k t,i \u03c3 ti \u03b3 tk x ti 2 \uf8f6 \uf8f7 \uf8f8 1/2 \u2264 \u221a K \uf8eb \uf8ec \uf8ed k E t,i \u03c3 ti \u03b3 tk x ti 2 \uf8f6 \uf8f7 \uf8f8 1/2 = \u221a K \uf8eb \uf8ed k,t,i |\u03b3 tk | 2 x ti 2 \uf8f6 \uf8f8 1/2 = \u221a K t k |\u03b3 tk | 2 i x ti 2 1/2 \u2264 K t,i\nx ti 2 = mT K S 1 (X).\n(ii) For any configuration \u03c3 of the Rademacher variables let D (\u03c3) be the maximizer in the definition of F \u03b3 (\u03c3). Then for any s \u2208 {1, . . . , T }, j \u2208 {1, . . . , m} and any \u03c3 \u2032 \u2208 {\u22121, 1} to replace \u03c3 sj we have\nF \u03b3 (\u03c3) \u2212 F \u03b3 \u03c3 (sj)\u2190\u03c3 \u2032 \u2264 2 | D (\u03c3) \u03b3 s , x sj | .\nUsing the inequality ( 6) we then obtain\nsj F \u03b3 (\u03c3) \u2212 inf \u03c3 \u2032 \u2208{\u22121,1} F \u03b3 \u03c3 (sj)\u2190\u03c3 \u2032 2 \u2264 4 t,i D (\u03c3) \u03b3 t , x ti 2 \u2264 4m t \u03a3 (x t ) \u221e D (\u03c3) \u03b3 t 2 \u2264 4m t \u03a3 (x t ) \u221e .\nIn the last inequality we used the fact that for any D \u2208 D K we have\nD\u03b3 t \u2264 k |\u03b3 tk | De k \u2264 \u03b3 t 1 \u2264 1.\nThe conclusion now follows from part (ii) of Theorem 3. Proposition 12. For every fixed Z = (X, Y) \u2208 (H \u00d7 R) mT we have E \u03c3 sup D\u2208D,\u03b3\u2208(C\u03b1) T t,i \u03c3 it \u2113 ( D\u03b3 t , x ti , y ti ) \u2264 L\u03b1 2mT S 1 (X) (K + 12)+L\u03b1T 8mS \u221e (X) ln (2K).\nProof. It suffices to prove the result for \u03b1 = 1, the general result being a consequence of rescaling. By Lemma 7 and the Lipschitz properties of the loss function \u2113 we have\nE \u03c3 sup D\u2208DK ,\u03b3\u2208(C) T , t,i \u03c3 it \u2113 ( D\u03b3 t , x ti , y ti ) \u2264 LE \u03c3 sup D\u2208DK ,\u03b3\u2208(C) T , t,i \u03c3 it D\u03b3 t , x ti . (8\n)\nSince linear functions on a compact convex set attain their maxima at the extreme points, we have\nE sup D\u2208DK ,\u03b3\u2208(C) T , T t=1 m i=1 \u03c3 it D\u03b3 t , x ti = E max \u03b3\u2208ext(C) T F \u03b3 ,(9)\nwhere F \u03b3 is defined as in (7). Let c = mKT S 1 (X). Now for any \u03b4 \u2265 0 we have, since\nF \u03b3 \u2265 0, E max \u03b3\u2208ext(C) T F \u03b3 = \u221e 0 Pr max \u03b3\u2208ext(C) T F \u03b3 > s ds \u2264 c + \u03b4 + \u03b3\u2208(ext(C)) T \u221e \u221a mKT S1(X)+\u03b4 Pr {F \u03b3 > s} ds \u2264 c + \u03b4 + \u03b3\u2208(ext(C)) T \u221e \u03b4 Pr {F \u03b3 > EF \u03b3 + s} ds \u2264 c + \u03b4 + (2K) T \u221e \u03b4 exp \u2212s 2 8mT S \u221e (X) ds \u2264 c + \u03b4 + 4mT S \u221e (X) (2K) T \u03b4 exp \u2212\u03b4 2 8mT S \u221e (X)\n.\nHere the first inequality follows from the fact that probabilities never exceed 1 and a union bound. The second inequality follows from Lemma 11, part (i), since EF k \u2264 mKT S 1 (X). The third inequality follows from Lemma 11, part (ii), and the fact that the cardinality of ext(C) is 2K, and the last inequality follows from a well known estimate on Gaussian random variables. Setting\n\u03b4 = 8mT S \u221e (X) ln e (2K)\nT we obtain with some easy simplifying estimates\nE max \u03b3\u2208ext(C) T F \u03b3 \u2264 2mT (K + 12) S 1 (X) +T 8mS \u221e (X) ln (2K),\nwhich together with ( 8) and ( 9) gives the result.\nTheorem 10 now follows from Corollary 6.\nIf the set C \u03b1 is replaced by any other subset C \u2032 of the \u2113 2ball of radius \u03b1, a similar proof strategy can be employed.\nThe denominator in the exponent of Lemma 11-(ii) then obtains another factor of \u221a K. The union bound over the extreme points in ext(C) in the previous proposition can be replaced by a union bound over a cover C \u2032 . This leads to the alternative result mentioned in Remark 5 following the statement of Theorem 1.\nAnother modification leads to a bound for the method presented in (Kumar & Daum\u00e9 III, 2012), where the constraint De k \u2264 1 is replaced by D 2 \u2264 \u221a K (here \u2022 2 is the Frobenius or Hilbert Schmidt norm) and the constraint \u03b3 t 1 \u2264 \u03b1, \u2200t is replaced by \u03b3 t 1 \u2264 \u03b1T . To explain the modification we set \u03b1 = 1. Part (i) of Lemma 11 is easily verified. The union bound over (ext (C)) T in the previous proposition is replaced by a union bound over the 2T K extreme points of the \u2113 1 -Ball of radius T in R T K . For part (ii) we use the fact that the concentration result is only needed for \u03b3 being an extreme point (so that it involves only a single task) and obtain the bound\nt \u03a3 (x t ) \u221e D\u03b3 t 2 \u2264 T KS \u2032 \u221e (X), leading to Pr {F \u03b3 \u2265 E [F \u03b3 ] + s} \u2264 exp \u2212s 2 8mT K S \u2032 \u221e (X)\n.\nProceeding as above we obtain the excess risk bound\nL\u03b1 2S1(X)(K+12) mT + L\u03b1 8KS \u2032 \u221e (X) ln(2KT ) m + 8 ln 4/\u03b4 mT ,\nto replace the bound in Theorem 1. The factor \u221a K in the second term seems quite weak, but it must be borne in mind that the constraint D 2 \u2264 \u221a K is much weaker than De k \u2264 1, and allows for a smaller approximation error. If we retain De k \u2264 1 and only modify the \u03b3-constraint to \u03b3 t 1 \u2264 \u03b1T the \u221a K in the second term disappears and by comparison to Theorem 1 there is only and additional ln T and the switch from S \u221e (X) to S \u2032 \u221e (X), reflecting the fact that \u03b3 t 1 \u2264 \u03b1T is a much weaker constraint than \u03b3 t 1 \u2264 \u03b1, \u2200t, so that, again, a smaller minimum in (1) is possible for the modified method.", "publication_ref": ["b13"], "figure_ref": [], "table_ref": []}, {"heading": "B.2. Learning to learn", "text": "In this section we prove Theorem 2. The basic strategy is as follows. Recall the definition (4) of the measure \u03c1 E , which governs the generation of a training sample in the environment E. On a given training sample z \u223c\u03c1 E the algorithm A D as defined in (3) incurs the empirical risk\nR D (z) = min \u03b3\u2208C\u03b1 1 m m i=1 \u2113 ( D\u03b3, x i , y i ) .\nThe algorithm A D , essentially being the Lasso, has very good estimation properties, soR D (z) will be close to the true risk of A D in the corresponding task. This means that we only really need to estimate the expected empirical risk E z\u223c\u03c1 ER D (z) of A D on future tasks. On the other hand the minimization problem (1) can be written as\nmin D\u2208DK 1 T T t=1R D (z t ) with Z = (z 1 , . . . , z T ) \u223c (\u03c1 E ) T ,\nwith dictionary D (Z) being the minimizer. If D K is not too large this should be similar to E z\u223c\u03c1 ER D(Z) (z). In the sequel we make this precise.\nLemma 13. For v \u2208 H with v \u2264 1 and x \u2208 H m let F be the random variable\nF = v, i \u03c3 i x i . Then (i) EF \u2264 \u221a m \u03a3 (x) 1/2 \u221e and (ii) for t \u2265 0 Pr {F > EF + s} \u2264 exp \uf8eb \uf8ed \u2212s 2 2m \u03a3 (x) \u221e \uf8f6 \uf8f8 .\nProof. (i). Using Jensen's inequality and ( 6) we get\nEF \u2264 \uf8eb \uf8ed E v, i \u03c3 i x i 2 \uf8f6 \uf8f8 1/2 = i v, x i 2 1/2 \u2264 m \u03a3 (x) \u221e .\n(ii) Let \u03c3 be any configuration of the Rademacher variables. For any \u03c3 \u2032 , \u03c3 \u2032\u2032 \u2208 {\u22121, 1} to replace \u03c3 sj we have\nF \u03c3 (sj)\u2190\u03c3 \u2032 \u2212 F \u03c3 (sj)\u2190\u03c3 \u2032\u2032 \u2264 2 | v, x j | ,\nso the conclusion follows from the bounded difference inequality, Theorem 3 (i).\nLemma 14. For v 1 , . . . , v K \u2208 H satisfying v k \u2264 1, x \u2208 H m we have E max k v k , i \u03c3 i x i \u2264 2m \u03a3 (x) \u221e 2 + \u221a ln K . Proof. Let F k = | v k , i \u03c3 i x i |. Setting c = m \u03a3 (x)\n\u221e and using integration by parts we have for\n\u03b4 \u2265 0 E max k F k \u2264 c + \u03b4 + \u221e m \u03a3 (x) \u221e +\u03b4 max k Pr {F k \u2265 s} ds \u2264 c + \u03b4 + k \u221e \u03b4 Pr {F k \u2265 EF k + s} ds \u2264 c + \u03b4 + k \u221e \u03b4 exp \uf8eb \uf8ed \u2212s 2 2m \u03a3 (x) \u221e \uf8f6 \uf8f8 ds \u2264 c + \u03b4 + mK \u03a3 (x) \u221e \u03b4 exp \uf8eb \uf8ed \u2212\u03b4 2 2m \u03a3 (x) \u221e \uf8f6 \uf8f8 .\nAbove the first inequality is trivial, the second follows from Lemma 13 (i) and a union bound, the third inequality follows from Lemma 13 (ii) and the last from a well known approximation. The conclusion follows from substitution of \u03b4 = 2m \u03a3 (x)\n\u221e ln (eK).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Proposition", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "15.", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Let", "text": "S \u221e (E) := E \u03c4 \u223cE E (x,y)\u223c\u00b5 m \u03c4 \u03a3 (x) \u221e . With probability at least 1 \u2212 \u03b4 in the multisample Z \u223c \u03c1 T E sup D\u2208DK R E (A D ) \u2212 1 T T t=1R D (z t ) (10) \u2264 L\u03b1K 2\u03c0S 1 (X) T + 4L\u03b1 S \u221e (E) (2 + ln K) m + 9 ln 2/\u03b4 2T .\nProof. Following our strategy we write (abbreviating \u03c1 = \u03c1 E ) and proceed by bounding each of the two terms in turn.\nsup D\u2208DK R E (A D ) \u2212 1 T\nFor any fixed dictionary D and any measure \u00b5 on Z we have valid for every measure \u00b5 on H \u00d7 R and every D \u2208 D K . Replacing \u00b5 by \u00b5 \u03c4 , taking the expectation as \u03c4 \u223c E and using Jensen's inequality bounds the first term on the right hand side of ( 11) by the second term on the right hand side of (10).\nWe proceed to bound the second term. From Corollary 6 and Lemma 8 we get that with probability at least 1 \u2212 \u03b4 in Z \u223c (\u03c1 E ) \n\u2264 L\u03b1 \u221a m sup D\u2208DK k De k 2 1/2 E \uf8eb \uf8ec \uf8ed k t,i \u03b6 tki x ti 2 \uf8f6 \uf8f7 \uf8f8 1/2 \u2264 L\u03b1 \u221a K \u221a m \uf8eb \uf8ec \uf8ed k E t,i \u03b6 tki x ti 2 \uf8f6 \uf8f7 \uf8f8 1/2 \u2264 L\u03b1 \u221a K \u221a m \uf8eb \uf8ed k t,i x ti 2 \uf8f6 \uf8f8 1/2 \u2264 L\u03b1K T S 1 (X).\nWe therefore have that with probability at least 1 \u2212 \u03b4 in the draw of the multi sample Z \u223c\u03c1 T The term ( 17) above is therefore non-positive. By Hoeffding's inequality the term ( 16) is less than ln (2/\u03b4) /2T with probability at least 1 \u2212 \u03b4/2. The term ( 15) is nonpositive by the definition of D (Z). Finally we use Proposition 15 to obtain with probability at least 1 \u2212 \u03b4/2 that\nR E A D(Z) \u2212 1 T T t=1R D(Z) (z t ) \u2264 sup D\u2208DK R E (A D ) \u2212 1 T T t=1R D (z t ) \u2264 L\u03b1K 2\u03c0S 1 (X) T + 4L\u03b1 S \u221e (E) (2 + ln K) m + 9 ln 4/\u03b4 2T .\nCombining these estimates on ( 14), ( 15), ( 16) and ( 17) in a union bound gives the conclusion.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgments", "text": "This work was supported in part by EPSRC Grant EP/H027203/1 and Royal Society International Joint Project Grant 2012/R2.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Appendix", "text": "In this appendix, we present the proof of Theorems 1 and 2. We begin by introducing some more notation and auxiliary results.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "A framework for learning predictive structures from multiple tasks and unlabeled data", "journal": "J. of Machine Learning Research", "year": "2005", "authors": "R K Ando; T Zhang"}, {"ref_id": "b1", "title": "Convex multitask feature learning", "journal": "", "year": "2008", "authors": "A Argyriou; T Evgeniou; M Pontil"}, {"ref_id": "b2", "title": "An algorithm for transfer learning in a heterogeneous environment", "journal": "", "year": "2008", "authors": "A Argyriou; A Maurer; M Pontil"}, {"ref_id": "b3", "title": "Rademacher and gaussian complexities: risk bounds and structural results", "journal": "J. of Machine Learning Research", "year": "2002", "authors": "P L Bartlett; S Mendelson"}, {"ref_id": "b4", "title": "A model for inductive bias learning", "journal": "J. of Artificial Intelligence Research", "year": "2000", "authors": "J Baxter"}, {"ref_id": "b5", "title": "A fast iterative shrinkagethresholding algorithm for linear inverse problems", "journal": "SIAM Journal of Imaging Sciences", "year": "2009", "authors": "A Beck; M Teboulle"}, {"ref_id": "b6", "title": "Exploiting task relatedness for multiple task learning", "journal": "", "year": "2003", "authors": "S Ben-David; R Schuller"}, {"ref_id": "b7", "title": "Statistics for High-Dimensional Data: Methods, Theory and Applications", "journal": "Springer", "year": "2011", "authors": "P B\u00fchlmann; S Van De Geer"}, {"ref_id": "b8", "title": "Multi-task learning", "journal": "", "year": "1997", "authors": "R Caruana"}, {"ref_id": "b9", "title": "Signal recovery by proximal forward-backward splitting", "journal": "Multiscale Modeling and Simulation", "year": "2006", "authors": "P L Combettes; V R Wajs"}, {"ref_id": "b10", "title": "Learning multiple tasks with kernel methods", "journal": "J. of Machine Learning Research", "year": "2005", "authors": "T Evgeniou; C A Micchelli; M Pontil"}, {"ref_id": "b11", "title": "Proximal methods for hierarchical sparse coding", "journal": "J. of Machine Learning Research", "year": "2011", "authors": "R Jenatton; J Mairal; G Obozinski; F Bach"}, {"ref_id": "b12", "title": "Empirical margin distributions and bounding the generalization error of combined classifiers", "journal": "Annals of Statistics", "year": "2002", "authors": "V Koltchinskii; D Panchenko"}, {"ref_id": "b13", "title": "Learning task grouping and overlap in multitask learning. International Conference on Machine Learning (ICML)", "journal": "", "year": "2012", "authors": "A Kumar; Iii Daum\u00e9; H "}, {"ref_id": "b14", "title": "Probability in Banach Spaces", "journal": "Springer", "year": "1991", "authors": "M Ledoux; M Talagrand"}, {"ref_id": "b15", "title": "Oracle inequalities and optimal inference under group sparsity", "journal": "Annals of Statistics", "year": "2011", "authors": "K Lounici; M Pontil; A B Tsybakov; S Van De Geer"}, {"ref_id": "b16", "title": "Concentration inequalities for functions of independent variables. Random Structures and Algorithms", "journal": "", "year": "2006", "authors": "A Maurer"}, {"ref_id": "b17", "title": "Transfer bounds for linear feature learning", "journal": "", "year": "2009", "authors": "A Maurer"}, {"ref_id": "b18", "title": "K-dimensional coding schemes in Hilbert spaces", "journal": "IEEE Transactions on Information Theory", "year": "2010", "authors": "A Maurer; M Pontil"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 .1Figure 1. Multitask error (Top) and Transfer error (Bottom) vs. number of training tasks T .", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 2 .2Figure 2. Multitask error (Top) and Transfer error (Bottom) vs. number of atoms K \u2032 used by dictionary-based methods.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 3 .3Figure 3. Multitask error (Top) and Transfer error (Bottom) vs. sparsity ratio s/K.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 4 .4Figure 4. Multiclassification accuracy of RR, MTFL GO-MTL and SC-MTL vs. the number of training instances in the transfer tasks, m.", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 5 .5Figure5. Transfer error vs. number of tasks T (Top) and vs. number of atoms K (Bottom) on the Binary Alphadigits dataset.", "figure_data": ""}, {"figure_label": "6", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Figure 6 .6Figure 6. Dictionaries found by SC-MTL using m = 240 pixels (missing 25% pixels) per image (top) and by Sparse Coding employing all pixels (bottom).", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "McDiarmid, C. Probabilistic Methods of Algorithmic Discrete Mathematics. Springer, 1998. Olshausen, B.A. and Field, D.J. Emergence of simple-cell receptive field properties by learning a sparse code for natural images. Nature, 381:607-609, 1996. Slepian, D. The one-sided barrier problem for gaussian noise. Bell System Tech. J., 41:463-501, 1962. Thrun, S. and Pratt, L. Learning to Learn. Springer, 1998. Tibshirani, R. Regression shrinkage and selection via the lasso. J. R. Statist. Soc. B, 58(1):267-288, 1996.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "Members of H are denoted with lower case italics such as x, v, w, vectors composed of such vectors are in bold lower case, i.e.x = (x 1 , . . . , x m ) or v = (v 1 , . . . , v n ),where m or n are explained in the context. Let B be the unit ball in H. An example is a pair z = (x, y) \u2208 B \u00d7 R =: Z, a sample is a vector of such pairs z = (z 1 , . . . , z m ) = ((x 1 , y 1 ) , . . . , (x m , y m )). Here we also write z = (x, y), with x = (x 1 , . . . , x m ) \u2208 H m and y = (y 1 , . . . , y m ) \u2208 R m .", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "E(x,y)\u223c\u00b5 \u03c4 [\u2113 ( A D (z) , x , y)] \u2212R D (z) + sup D\u2208DK E z\u223c\u03c1 R D (z)", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "E\u03c3Ez\u223c\u00b5 m E (x,y)\u223c\u00b5 [\u2113 ( A D (z) , x , y)] \u2212R D (z) \u2264 E z\u223c\u00b5 m sup \u03b3\u2208C\u03b1 E (x,y)\u223c\u00b5 [\u2113 ( D\u03b3, x , y)] i \u2113 ( D\u03b3, x i , y i ) [Theorem 4] z\u223c\u00b5 m E (x,y)\u223c\u00b5 [\u2113 ( A D (z) , x , y)] \u2212R D (z) \u2264 4L\u03b1 E z\u223c\u00b5 m \u03bb max \u03a3 (x) (2 + ln K) m(12)   ", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_10", "figure_caption": "TR(sup D\u2208DK E z\u223c\u03c1 R D (z) \u03b6 t is an orthogaussian sequence. Define two Gaussian processes \u2126 and \u039e indexed by D K as\u2126 D = T t=1 \u03b6 tRD (z t ) and \u039e De k , x ti , where the \u03b6 ijk are also orthogaussian. Then for D 1 , D 2 \u2208 D K E (\u2126 D1 \u2212 \u2126 D2 ) D1 (z t ) \u2212R D2 (z t ) 1 \u03b3, x ti , y ti ) \u2212\u2113 ( D 2 \u03b3, x ti , y ti ) D 1 e k , x ti \u2212 D 2 e k , x ti ) 2 = E (\u039e D1 \u2212 \u039e D2 ) 2 .", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_11", "figure_caption": "sup D\u2208DK E z\u223c\u03c1 R D (z) 11) combines with (12) to give the conclusion.Proof of Theorem 2. Let D opt and \u03b3 \u03c4 the minimizers in the definition of R opt , so thatR opt = E \u03c4 \u223cE E (x,y)\u223c\u00b5 \u03c4 \u2113 [( D opt \u03b3 \u03c4 , x , y)] . R E A D(Z) \u2212 R opt can be decomposed as the sum of four terms, t ) \u2212 E z\u223c\u03c1RDopt (z) (16)+E \u03c4 \u223cE E z\u223c\u00b5 m \u03c4R Dopt (z) \u2212E (x,y)\u223c\u00b5 \u03c4 [\u2113 ( D opt \u03b3 \u03c4 , x , y)] .(17)By definition ofR we have for every \u03c4 that D opt \u03b3 \u03c4 , x i , y i )]= E (x,y)\u223c\u00b5 \u03c4 \u2113 [( D opt \u03b3 \u03c4 , x , y)] .", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "min D\u2208DK 1 T T t=1 min \u03b3\u2208C\u03b1 1 m m i=1 \u2113 ( D\u03b3, x ti , y ti ) ,(1)", "formula_coordinates": [2.0, 83.76, 424.25, 205.76, 31.21]}, {"formula_id": "formula_1", "formula_text": "\u2022 Z = ((x ti , y ti ) : 1 \u2264 i \u2264 m, 1 \u2264 t \u2264 T ) is a dataset", "formula_coordinates": [2.0, 65.4, 635.6, 224.05, 17.29]}, {"formula_id": "formula_2", "formula_text": "i ) : 1 \u2264 i \u2264 m) \u2208 (H \u00d7 R) m .", "formula_coordinates": [2.0, 408.84, 389.93, 121.41, 19.72]}, {"formula_id": "formula_3", "formula_text": ".i.d. training sample z t = ((x ti , y ti ) : 1 \u2264 i \u2264 m) is drawn from (\u00b5 t ) m and the en- semble Z \u223c T t=1 \u00b5 m", "formula_coordinates": [2.0, 307.44, 544.17, 234.08, 42.24]}, {"formula_id": "formula_4", "formula_text": "1 T T t=1 E (x,y)\u223c\u00b5 t [\u2113 ( D (Z) \u03b3 t (Z) , x , y)] .", "formula_coordinates": [2.0, 338.4, 634.73, 173.28, 30.97]}, {"formula_id": "formula_5", "formula_text": "1 T T t=1 E (x,y)\u223c\u00b5 t [\u2113 ( D (Z) \u03b3 t (Z) , x , y)] \u2212 inf D\u2208DK 1 T T t=1 inf \u03b3\u2208C\u03b1 E (x,y)\u223c\u00b5 t [\u2113 ( D\u03b3, x , y)] \u2264 L\u03b1 2S 1 (X) (K + 12) mT + L\u03b1 8S \u221e (X) ln (2K) m + 8 ln 4/\u03b4 mT ,", "formula_coordinates": [3.0, 66.6, 117.29, 212.88, 123.64]}, {"formula_id": "formula_6", "formula_text": "S 1 (X) = 1 T T t=1 tr \u03a3 (x t ) and S \u221e (X) = 1 T T t=1 \u03bb max \u03a3 (x t ) . Here\u03a3 (x t )", "formula_coordinates": [3.0, 56.64, 250.01, 232.74, 34.33]}, {"formula_id": "formula_7", "formula_text": "R E (A) = E \u03c4 \u223cE E z\u223c\u00b5 m \u03c4 E (x,y)\u223c\u00b5 \u03c4 [\u2113 ( A (z) , x , y)]", "formula_coordinates": [4.0, 62.4, 228.45, 208.44, 15.54]}, {"formula_id": "formula_8", "formula_text": "A D (z) = D arg min \u03b3\u2208C\u03b1 1 m m i=1 \u2113 ( D\u03b3, x i , y i ) .", "formula_coordinates": [4.0, 72.48, 310.73, 188.28, 31.21]}, {"formula_id": "formula_9", "formula_text": "\u03c1 E (z) := E \u03c4 \u223cE [(\u00b5 \u03c4 ) m (z)] .(4)", "formula_coordinates": [4.0, 114.36, 473.81, 175.16, 19.3]}, {"formula_id": "formula_10", "formula_text": "Z = (z 1 , . . . , z T ) \u2208 ((H \u00d7 R) m ) T drawn i.i.d. from \u03c1 E , that is Z \u223c (\u03c1 E ) T .", "formula_coordinates": [4.0, 55.44, 516.29, 233.97, 33.63]}, {"formula_id": "formula_11", "formula_text": "R opt = min D\u2208DK E \u03c4 \u223cE min \u03b3\u2208C\u03b1 E (x,y)\u223c\u00b5 \u03c4 \u2113 [( D\u03b3, x , y)]", "formula_coordinates": [4.0, 68.76, 703.77, 207.36, 15.69]}, {"formula_id": "formula_12", "formula_text": "R E A D(Z) \u2212 R opt \u2264 L\u03b1K 2\u03c0S 1 (X) T +4L\u03b1 S \u221e (E) (2 + ln K) m + 8 ln 4/\u03b4 T ,", "formula_coordinates": [4.0, 338.04, 133.17, 172.8, 58.56]}, {"formula_id": "formula_13", "formula_text": "E \u03c4 \u223cE E (x,y)\u223c\u00b5 m \u03c4 \u03bb max \u03a3 (x) .", "formula_coordinates": [4.0, 307.44, 209.13, 125.49, 18.06]}, {"formula_id": "formula_14", "formula_text": "min D\u2208DK 1 T T t=1 min \u03b3\u2208C\u03b1 D\u03b3 \u2212 w t 2 .", "formula_coordinates": [5.0, 107.88, 138.05, 129.12, 31.09]}, {"formula_id": "formula_15", "formula_text": "R(D) \u2212 R opt \u2264 2\u03b1(1 + \u03b1)K 2\u03c0 T + 8 ln 4/\u03b4 T (5)", "formula_coordinates": [5.0, 67.44, 295.89, 222.08, 23.76]}, {"formula_id": "formula_16", "formula_text": "T \u221e = sup { T x : x = 1}.", "formula_coordinates": [10.0, 60.48, 264.2, 128.01, 17.35]}, {"formula_id": "formula_17", "formula_text": "\u03a3 (x) v, w = 1 m i v, x i x i , w , v, w \u2208 H.", "formula_coordinates": [10.0, 78.84, 631.05, 194.49, 27.69]}, {"formula_id": "formula_18", "formula_text": "i v, x i 2 = m \u03a3 (x) v, v \u2264 m \u03a3 (x) \u221e v 2 . (6", "formula_coordinates": [10.0, 71.64, 684.29, 213.97, 32.95]}, {"formula_id": "formula_19", "formula_text": ")", "formula_coordinates": [10.0, 285.61, 708.28, 3.91, 8.97]}, {"formula_id": "formula_20", "formula_text": "S 1 (X) = 1 T t \u03a3 (x t ) 1 := 1 T t tr \u03a3 (x t ) S \u221e (X) = 1 T t \u03a3 (x t ) \u221e := 1 T t \u03bb max \u03a3 (x t )", "formula_coordinates": [10.0, 307.44, 123.93, 231.39, 57.42]}, {"formula_id": "formula_21", "formula_text": "x k\u2190y = (x 1 , . . . , x k\u22121 , y, x k+1 , . . . , x n ) .", "formula_coordinates": [10.0, 339.72, 398.97, 169.41, 10.66]}, {"formula_id": "formula_22", "formula_text": "A 2 = sup x\u2208X n n k=1 sup y1,y2\u2208X (F (x k\u2190y1 ) \u2212 F (x k\u2190y2 )) 2 B 2 = sup x\u2208X n n k=1 F (x) \u2212 inf y\u2208X F (x k\u2190y ) 2 .", "formula_coordinates": [10.0, 311.52, 490.97, 223.69, 64.81]}, {"formula_id": "formula_23", "formula_text": "(i) Pr {F (X) > EF (X \u2032 ) + s} \u2264 e \u22122s 2 /A 2 ; (ii) Pr {F (X) > EF (X \u2032 ) + s} \u2264 e \u2212s 2 /(2B 2 ) .", "formula_coordinates": [10.0, 307.44, 604.96, 189.36, 40.0]}, {"formula_id": "formula_24", "formula_text": "R (A) = E \u03c3 sup (x1,...,xn)\u2208A 2 n n i=1 \u03c3 i x i , G (A) = E \u03b6 sup (x1,...,xn)\u2208A 2 n n i=1 \u03b6 i x i .", "formula_coordinates": [11.0, 90.0, 191.09, 162.45, 64.33]}, {"formula_id": "formula_25", "formula_text": "F (x) = F (x 1 , . . . , x n ) = {(f (x 1 ) , . . . , f (x n )) : f \u2208 F } \u2286 R n .", "formula_coordinates": [11.0, 88.8, 300.44, 167.31, 32.29]}, {"formula_id": "formula_26", "formula_text": "\u00b5 = i \u00b5 i on X m . For x \u2208 X m define \u03a6 (x) = sup f \u2208F 1 m m i=1 E x\u223c\u00b5 i [f (x)] \u2212 f (x i ) . Then E x\u223c\u00b5 [\u03a6 (x)] \u2264 E x\u223c\u00b5 R (F (x)).", "formula_coordinates": [11.0, 55.44, 443.21, 233.5, 92.79]}, {"formula_id": "formula_27", "formula_text": "E x\u223c\u00b5 [\u03a6 (x)] = E x\u223c\u00b5 sup f \u2208F 1 m E x \u2032 \u223c\u00b5 m i=1 (f (x \u2032 i ) \u2212 f (x i )) \u2264 E x,x \u2032 \u223c\u00b5\u00d7\u00b5 sup f \u2208F 1 m m i=1 \u03c3 i (f (x \u2032 i ) \u2212 f (x i )) ,", "formula_coordinates": [11.0, 68.16, 581.61, 188.64, 79.02]}, {"formula_id": "formula_28", "formula_text": "\u00b5 \u00d7 \u00b5 (x, x \u2032 ) = i \u00b5 i \u00d7 i \u00b5 i (x, x \u2032 )under the in- terchange x i \u2194 x \u2032 i .", "formula_coordinates": [11.0, 55.44, 680.09, 234.08, 30.4]}, {"formula_id": "formula_29", "formula_text": "E x\u223c\u00b5 [f (x)] \u2264 1 m m i=1 f (x i )+E x\u223c\u00b5 R (F (x))+ ln (1/\u03b4) 2m .", "formula_coordinates": [11.0, 307.44, 123.05, 246.48, 31.09]}, {"formula_id": "formula_30", "formula_text": "E x\u223c\u00b5 [f (x)] \u2264 1 m m i=1 f (x i ) + R (F (x)) + 9 ln (2/\u03b4) 2m .", "formula_coordinates": [11.0, 307.44, 296.09, 234.0, 31.09]}, {"formula_id": "formula_31", "formula_text": "\u03c8 (A) = {\u03c8 1 (x 1 ) , . . . , \u03c8 n (x n ) : (x 1 , . . . , x n ) \u2208 A}. Then R (\u03c8 (A)) \u2264 LR (A) .", "formula_coordinates": [11.0, 307.44, 403.53, 233.94, 48.84]}, {"formula_id": "formula_32", "formula_text": "A \u2286 R k we have R (A) \u2264 \u03c0/2 G (A).", "formula_coordinates": [11.0, 371.4, 498.77, 163.17, 18.52]}, {"formula_id": "formula_33", "formula_text": "E (\u2126 s1 \u2212 \u2126 s2 ) 2 \u2264 E (\u039e s1 \u2212 \u039e s2 ) 2 for all s 1 , s 2 \u2208 S. Then E sup s\u2208S \u2126 s \u2264 E sup s\u2208S \u039e s .", "formula_coordinates": [11.0, 307.44, 577.37, 224.13, 52.09]}, {"formula_id": "formula_34", "formula_text": "1 T T t=1 E (x,y)\u223c\u00b5 t [\u2113 ( D\u03b3 t , x , y)] \u2212 1 mT T t=1 m i=1 \u2113 ( D\u03b3 t , x ti , y ti ) \u2264 L\u03b1 2S 1 (X) (K + 12) mT + L\u03b1 8S \u221e (X) ln (2K) m + 9 ln 2/\u03b4 2mT .", "formula_coordinates": [12.0, 66.6, 129.17, 212.88, 123.76]}, {"formula_id": "formula_35", "formula_text": "F \u03b3 = F \u03b3 (\u03c3) = sup D\u2208DK t,i \u03c3 ti D\u03b3 t , x ti . (7", "formula_coordinates": [12.0, 87.36, 313.65, 198.25, 20.97]}, {"formula_id": "formula_36", "formula_text": ")", "formula_coordinates": [12.0, 285.61, 314.32, 3.91, 8.97]}, {"formula_id": "formula_37", "formula_text": "Pr {F \u03b3 \u2265 E [F \u03b3 ] + s} \u2264 exp \u2212s 2 8mT S \u221e (X)", "formula_coordinates": [12.0, 73.44, 406.97, 185.07, 30.46]}, {"formula_id": "formula_38", "formula_text": "EF \u03b3 = E sup D k De k , t,i \u03c3 ti \u03b3 tk x ti \u2264 sup D k De k 2 1/2 E \uf8eb \uf8ec \uf8ed k t,i \u03c3 ti \u03b3 tk x ti 2 \uf8f6 \uf8f7 \uf8f8 1/2 \u2264 \u221a K \uf8eb \uf8ec \uf8ed k E t,i \u03c3 ti \u03b3 tk x ti 2 \uf8f6 \uf8f7 \uf8f8 1/2 = \u221a K \uf8eb \uf8ed k,t,i |\u03b3 tk | 2 x ti 2 \uf8f6 \uf8f8 1/2 = \u221a K t k |\u03b3 tk | 2 i x ti 2 1/2 \u2264 K t,i", "formula_coordinates": [12.0, 55.44, 481.53, 246.25, 236.14]}, {"formula_id": "formula_39", "formula_text": "F \u03b3 (\u03c3) \u2212 F \u03b3 \u03c3 (sj)\u2190\u03c3 \u2032 \u2264 2 | D (\u03c3) \u03b3 s , x sj | .", "formula_coordinates": [12.0, 327.96, 133.4, 192.96, 17.29]}, {"formula_id": "formula_40", "formula_text": "sj F \u03b3 (\u03c3) \u2212 inf \u03c3 \u2032 \u2208{\u22121,1} F \u03b3 \u03c3 (sj)\u2190\u03c3 \u2032 2 \u2264 4 t,i D (\u03c3) \u03b3 t , x ti 2 \u2264 4m t \u03a3 (x t ) \u221e D (\u03c3) \u03b3 t 2 \u2264 4m t \u03a3 (x t ) \u221e .", "formula_coordinates": [12.0, 318.0, 177.65, 183.61, 114.34]}, {"formula_id": "formula_41", "formula_text": "D\u03b3 t \u2264 k |\u03b3 tk | De k \u2264 \u03b3 t 1 \u2264 1.", "formula_coordinates": [12.0, 349.44, 319.16, 170.49, 17.29]}, {"formula_id": "formula_42", "formula_text": "E \u03c3 sup D\u2208DK ,\u03b3\u2208(C) T , t,i \u03c3 it \u2113 ( D\u03b3 t , x ti , y ti ) \u2264 LE \u03c3 sup D\u2208DK ,\u03b3\u2208(C) T , t,i \u03c3 it D\u03b3 t , x ti . (8", "formula_coordinates": [12.0, 307.44, 520.53, 230.17, 53.13]}, {"formula_id": "formula_43", "formula_text": ")", "formula_coordinates": [12.0, 537.61, 553.36, 3.91, 8.97]}, {"formula_id": "formula_44", "formula_text": "E sup D\u2208DK ,\u03b3\u2208(C) T , T t=1 m i=1 \u03c3 it D\u03b3 t , x ti = E max \u03b3\u2208ext(C) T F \u03b3 ,(9)", "formula_coordinates": [12.0, 310.44, 630.17, 231.08, 40.39]}, {"formula_id": "formula_45", "formula_text": "F \u03b3 \u2265 0, E max \u03b3\u2208ext(C) T F \u03b3 = \u221e 0 Pr max \u03b3\u2208ext(C) T F \u03b3 > s ds \u2264 c + \u03b4 + \u03b3\u2208(ext(C)) T \u221e \u221a mKT S1(X)+\u03b4 Pr {F \u03b3 > s} ds \u2264 c + \u03b4 + \u03b3\u2208(ext(C)) T \u221e \u03b4 Pr {F \u03b3 > EF \u03b3 + s} ds \u2264 c + \u03b4 + (2K) T \u221e \u03b4 exp \u2212s 2 8mT S \u221e (X) ds \u2264 c + \u03b4 + 4mT S \u221e (X) (2K) T \u03b4 exp \u2212\u03b4 2 8mT S \u221e (X)", "formula_coordinates": [12.0, 307.44, 684.56, 229.54, 34.3]}, {"formula_id": "formula_46", "formula_text": "\u03b4 = 8mT S \u221e (X) ln e (2K)", "formula_coordinates": [13.0, 55.44, 305.85, 131.91, 15.54]}, {"formula_id": "formula_47", "formula_text": "E max \u03b3\u2208ext(C) T F \u03b3 \u2264 2mT (K + 12) S 1 (X) +T 8mS \u221e (X) ln (2K),", "formula_coordinates": [13.0, 55.44, 340.28, 191.54, 38.47]}, {"formula_id": "formula_48", "formula_text": "t \u03a3 (x t ) \u221e D\u03b3 t 2 \u2264 T KS \u2032 \u221e (X), leading to Pr {F \u03b3 \u2265 E [F \u03b3 ] + s} \u2264 exp \u2212s 2 8mT K S \u2032 \u221e (X)", "formula_coordinates": [13.0, 66.0, 670.13, 197.66, 56.38]}, {"formula_id": "formula_49", "formula_text": "L\u03b1 2S1(X)(K+12) mT + L\u03b1 8KS \u2032 \u221e (X) ln(2KT ) m + 8 ln 4/\u03b4 mT ,", "formula_coordinates": [13.0, 307.44, 88.77, 182.75, 51.72]}, {"formula_id": "formula_50", "formula_text": "R D (z) = min \u03b3\u2208C\u03b1 1 m m i=1 \u2113 ( D\u03b3, x i , y i ) .", "formula_coordinates": [13.0, 344.4, 379.13, 160.08, 31.21]}, {"formula_id": "formula_51", "formula_text": "min D\u2208DK 1 T T t=1R D (z t ) with Z = (z 1 , . . . , z T ) \u223c (\u03c1 E ) T ,", "formula_coordinates": [13.0, 313.32, 498.17, 222.24, 30.97]}, {"formula_id": "formula_52", "formula_text": "F = v, i \u03c3 i x i . Then (i) EF \u2264 \u221a m \u03a3 (x) 1/2 \u221e and (ii) for t \u2265 0 Pr {F > EF + s} \u2264 exp \uf8eb \uf8ed \u2212s 2 2m \u03a3 (x) \u221e \uf8f6 \uf8f8 .", "formula_coordinates": [13.0, 307.44, 616.65, 210.36, 105.06]}, {"formula_id": "formula_53", "formula_text": "EF \u2264 \uf8eb \uf8ed E v, i \u03c3 i x i 2 \uf8f6 \uf8f8 1/2 = i v, x i 2 1/2 \u2264 m \u03a3 (x) \u221e .", "formula_coordinates": [14.0, 74.52, 92.93, 195.84, 76.42]}, {"formula_id": "formula_54", "formula_text": "F \u03c3 (sj)\u2190\u03c3 \u2032 \u2212 F \u03c3 (sj)\u2190\u03c3 \u2032\u2032 \u2264 2 | v, x j | ,", "formula_coordinates": [14.0, 81.24, 217.88, 182.4, 17.29]}, {"formula_id": "formula_55", "formula_text": "Lemma 14. For v 1 , . . . , v K \u2208 H satisfying v k \u2264 1, x \u2208 H m we have E max k v k , i \u03c3 i x i \u2264 2m \u03a3 (x) \u221e 2 + \u221a ln K . Proof. Let F k = | v k , i \u03c3 i x i |. Setting c = m \u03a3 (x)", "formula_coordinates": [14.0, 55.44, 282.32, 243.12, 115.81]}, {"formula_id": "formula_56", "formula_text": "\u03b4 \u2265 0 E max k F k \u2264 c + \u03b4 + \u221e m \u03a3 (x) \u221e +\u03b4 max k Pr {F k \u2265 s} ds \u2264 c + \u03b4 + k \u221e \u03b4 Pr {F k \u2265 EF k + s} ds \u2264 c + \u03b4 + k \u221e \u03b4 exp \uf8eb \uf8ed \u2212s 2 2m \u03a3 (x) \u221e \uf8f6 \uf8f8 ds \u2264 c + \u03b4 + mK \u03a3 (x) \u221e \u03b4 exp \uf8eb \uf8ed \u2212\u03b4 2 2m \u03a3 (x) \u221e \uf8f6 \uf8f8 .", "formula_coordinates": [14.0, 55.44, 405.08, 229.8, 191.47]}, {"formula_id": "formula_57", "formula_text": "S \u221e (E) := E \u03c4 \u223cE E (x,y)\u223c\u00b5 m \u03c4 \u03a3 (x) \u221e . With probability at least 1 \u2212 \u03b4 in the multisample Z \u223c \u03c1 T E sup D\u2208DK R E (A D ) \u2212 1 T T t=1R D (z t ) (10) \u2264 L\u03b1K 2\u03c0S 1 (X) T + 4L\u03b1 S \u221e (E) (2 + ln K) m + 9 ln 2/\u03b4 2T .", "formula_coordinates": [14.0, 55.44, 68.21, 486.2, 658.42]}, {"formula_id": "formula_58", "formula_text": "sup D\u2208DK R E (A D ) \u2212 1 T", "formula_coordinates": [14.0, 351.6, 223.53, 82.98, 24.33]}, {"formula_id": "formula_59", "formula_text": "\u2264 L\u03b1 \u221a m sup D\u2208DK k De k 2 1/2 E \uf8eb \uf8ec \uf8ed k t,i \u03b6 tki x ti 2 \uf8f6 \uf8f7 \uf8f8 1/2 \u2264 L\u03b1 \u221a K \u221a m \uf8eb \uf8ec \uf8ed k E t,i \u03b6 tki x ti 2 \uf8f6 \uf8f7 \uf8f8 1/2 \u2264 L\u03b1 \u221a K \u221a m \uf8eb \uf8ed k t,i x ti 2 \uf8f6 \uf8f8 1/2 \u2264 L\u03b1K T S 1 (X).", "formula_coordinates": [15.0, 318.96, 180.65, 220.92, 171.37]}, {"formula_id": "formula_60", "formula_text": "R E A D(Z) \u2212 1 T T t=1R D(Z) (z t ) \u2264 sup D\u2208DK R E (A D ) \u2212 1 T T t=1R D (z t ) \u2264 L\u03b1K 2\u03c0S 1 (X) T + 4L\u03b1 S \u221e (E) (2 + ln K) m + 9 ln 4/\u03b4 2T .", "formula_coordinates": [16.0, 55.44, 262.01, 213.36, 114.16]}], "doi": ""}