{"title": "Feuding Families and Former Friends: Unsupervised Learning for Dynamic Fictional Relationships", "authors": "Mohit Iyyer; Anupam Guha; Snigdha Chaturvedi; Jordan Boyd-Graber; Hal Daum\u00e9", "pub_date": "", "abstract": "Understanding how a fictional relationship between two characters changes over time (e.g., from best friends to sworn enemies) is a key challenge in digital humanities scholarship. We present a novel unsupervised neural network for this task that incorporates dictionary learning to generate interpretable, accurate relationship trajectories. While previous work on characterizing literary relationships relies on plot summaries annotated with predefined labels, our model jointly learns a set of global relationship descriptors as well as a trajectory over these descriptors for each relationship in a dataset of raw text from novels. We find that our model learns descriptors of events (e.g., marriage or murder) as well as interpersonal states (love, sadness). Our model outperforms topic model baselines on two crowdsourced tasks, and we also find interesting correlations to annotations in an existing dataset.", "sections": [{"heading": "Describing Character Relationships", "text": "When two characters in a book break bread, is their meal just a result of biological needs or does it mean more? Cognard-Black et al. (2014) argue that this simple interaction reflects the diversity and background of the characters, while Foster (2009) suggests that the tone of a meal can portend either good or ill for the rest of the book. To support such theories, scholars use their literary expertise to draw connections between disparate books: Gabriel Conroy's dissonance from his family at a sumptuous feast in Joyce's The Dead, the frustration of Tyler's mother in Dinner at the Homesick Restaurant, and the grudging I love him more than ever. We are to be married on 28 September. I feel so weak and worn out \u2026 looked quite grieved \u2026 I hadn't the spirit poor girl, there is peace for her at last. It is the end! Arthur placed the stake over her heart \u2026 he struck with all his might. The Thing in the coffin writhed \u2026 Each column describes the relationship state at a particular time by weights over a set of descriptors (larger weights shown as bigger boxes). Our goal is to learn-without supervision-both the descriptors and the trajectories from raw fictional texts. respect for a blind man eating meatloaf in Carver's Cathedral.\nHowever, these insights do not come cheap. It takes years of careful reading and internalization to make connections across books, which means that relationship symmetries and archetypes are likely to remain hidden in the millions of books published every year unless literary scholars are actively searching for them.\nNatural language processing techniques have been increasingly used to assist in these literary investigations by discovering patterns in texts (Jockers, 2013). In Section 6 we review existing techniques that classify or cluster relationships between characters in books using a fixed set of labels (e.g., friend or en-emy). However, such approaches ignore interactions between characters that lie outside of the established lexicon and cannot account for the dynamic nature of relationships that evolve through the course of a book, such as the vampiric downfall of Lucy and Arthur's engagement in Dracula (Figure 1) or Winston Smith's rat-induced betrayal of Julia in 1984.\nTo address these issues, we propose the task of unsupervised relationship modeling, in which a model jointly learns a set of relationship descriptors as well as relationship trajectories for pairs of literary characters. Instead of assigning a single descriptor to a particular relationship, the trajectories learned by the model are sequences of descriptors as in Figure 1.\nThe Bayesian hidden topic Markov model (HTMM) of Gruber et al. (2007) emerges as a natural choice for our task because it is capable of computing relationship descriptors (in the form of topics) and has an additional temporal component. However, our experiments show that the descriptors learned by the HTMM are not coherent and focus more on events or environments (e.g., meals, outdoors) than interpersonal states like happiness and sadness.\nMotivated by recent advances in deep learning, we propose the relationship modeling network (RMN), which is a novel variant of a deep recurrent autoencoder that incorporates dictionary learning to learn relationship descriptors. We show that the RMN achieves better descriptor coherence and trajectory accuracy than the HTMM and other topic model baselines in two crowdsourced evaluations described in Section 4. In Section 5 we show qualitative results and make connections to existing literary scholarship.", "publication_ref": ["b10", "b26", "b22"], "figure_ref": ["fig_1", "fig_1"], "table_ref": []}, {"heading": "A Dataset of Character Interactions", "text": "Our dataset consists of 1,383 fictional works pulled from Project Gutenberg and other Internet sources. Project Gutenberg has a limited selection (outside of science fiction) of mostly classic literature, so we add more contemporary novels from various genres such as mystery, romance, and fantasy to our dataset.\nTo identify character mentions, we run the Book-NLP pipeline of Bamman et al. (2014), which includes character name clustering, quoted speaker identification, and coreference resolution. 1 For ev-ery detected character mention, we define a span as beginning 100 tokens before the mention and ending 100 tokens after the mention. We do not use sentence or paragraph boundaries because they vary considerably depending on the author (e.g., William Faulkner routinely wrote single sentences longer than many of Hemingway's paragraphs). All spans in our dataset contain mentions to exactly two characters. This is a rather strict requirement that forces a reduction in data size, but spans in which more than two characters are mentioned are generally noisier.\nOnce we have identified usable spans in the dataset, we apply a second filtering step that removes relationships containing fewer than five spans. Without this filter, our dataset is dominated by fleeting interactions between minor characters; this is undesirable since our focus is on longer, mutable relationships. Finally, we filter our vocabulary by removing the 500 most frequently occurring words, as well as all words that occur in fewer than 100 books. The latter step helps correct for variation in time period and genre (e.g., \"thou\" and \"thy\" found in older works like the Canterbury Tales). Our final dataset contains 20,013 relationships and 380,408 spans, while our vocabulary contains 16,223 words. 2", "publication_ref": ["b2"], "figure_ref": [], "table_ref": []}, {"heading": "Relationship Modeling Networks", "text": "This section mathematically describes how we apply the RMN to relationship modeling on our dataset. Our model is similar in spirit to topic models: for an input dataset, the output of the RMN is a set of relationship descriptors (topics) and-for each relationship in the dataset-a trajectory, or a sequence of probability distributions over these descriptors (document-topic assignments). However, the RMN uses recent advances in deep learning to achieve better control over descriptor coherence and trajectory smoothness (Section 4).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Formalizing the Problem", "text": "Assume we have two characters c 1 and c 2 in book b. We define S c 1 ,c 2 as a sequence of token spans where each span s t \u2208 S c 1 ,c 2 is itself a set of tokens   {w 1 , w 2 , . . . , w l } of fixed size l that contains mentions (either directly or by coreference) to both c 1 and c 2 . In other words, S c 1 ,c 2 includes the text of every scene, chronologically ordered, in which c 1 and c 2 are present together.\nh t = f (W h \u2022 [v st ; v c1 ; v c2 ; v b ]) v st v c1 v c2 v b d t 1 R d t = \u21b5 \u2022 softmax(W d \u2022 [h t ; d t 1 ])+ (1 \u21b5) \u2022 d", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Model Description", "text": "As in other neural network models for natural language processing, we begin by associating each word type w in our vocabulary with a real-valued embedding v w \u2208 R d . These embeddings are rows of a V \u00d7 d matrix L, where V is the vocabulary size. Similarly, characters and books have their own embeddings in rows of matrices C and B. We want B to capture global context information (e.g., \"Moby Dick\" takes place at sea) and C to capture immutable aspects of characters not related to their relationships (e.g., Javert is a police officer). Finally, the RMN learns embeddings for relationship descriptors, which requires a second matrix R of size K \u00d7 d where K is the number of descriptors, analogous to the number of topics in topic models.\nEach input to the RMN is a tuple that contains identifiers for a book and two characters, as well as the spans corresponding to their relationship: (b, c 1 , c 2 , S c 1 ,c 2 ). Given one such input, our objective is to reconstruct S c 1 ,c 2 using a linear combination of relationship descriptors from R as shown in Figure 2; we now describe this process formally.", "publication_ref": [], "figure_ref": ["fig_2"], "table_ref": []}, {"heading": "Modeling Spans with Vector Averages", "text": "We compute a vector representation for each span s t in S c 1 ,c 2 by averaging the embeddings of the words in that span,\nv st = 1 l w\u2208st v w .(1)\nThen, we concatenate v st with the character embeddings v c 1 and v c 2 as well as the book embedding v b and feed the resulting vector into a standard feedforward layer to obtain a hidden state h t ,\nh t = f (W h \u2022 [v st ; v c 1 ; v c 2 ; v b ]).(2)\nIn all experiments, the transformation matrix W h is d \u00d7 4d, and we set f to the ReLu function, ReLu(x) = max(0, x).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Approximating Spans with Relationship", "text": "Descriptors Now that we can obtain representations of spans, we move on to learning descriptors using a variant of dictionary learning (Olshausen and Field, 1997; Elad and Aharon, 2006), where our descriptor matrix R is the dictionary and we are trying to approximate input spans as a linear combination of items from this dictionary.\nSuppose we compute a hidden state for every span s t in S c 1 ,c 2 (Equation 2). Now, given an h t , we compute a weight vector d t over K relationship descriptors with some composition function g, which is fully specified in the next section. Conceptually, each d t is a relationship state, and a relationship trajectory is a sequence of chronologically-ordered relationship states as shown in Figure 1. After computing d t , we use it to compute a reconstruction vector r t by taking a weighted average over relationship descriptors, r t = R T d t .\n(3)\nOur goal is to make r t similar to v st . We use a contrastive max-margin objective function similar to previous work (Weston et al., 2011;. We randomly sample spans from our dataset and compute the vector average v sn for each sampled span as in Equation 1. This subset of span vectors is N . The unregularized objective J is a hinge loss that minimizes the inner product between r t and the negative samples while simultaneously maximizing the inner product between r t and v st ,\nJ(\u03b8) = |Sc 1 ,c 2 | t=0 n\u2208N max(0, 1 \u2212 r t v st + r t v sn ), (4\n)\nwhere \u03b8 represents the model parameters.", "publication_ref": ["b12", "b42"], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "Computing Weights over Descriptors", "text": "What function should we choose for our composition function g to represent a relationship state at a given time step? On the face of it, this seems trivial; we can project h t to K dimensions and then apply a softmax or some other nonlinearity that yields nonnegative weights. 3 However, this method ignores the relationship states at previous time steps. To model the temporal aspect of relationships, we can add a recurrent connection,\nd t = softmax(W d \u2022 [h t ; d t\u22121 ])(5)\nwhere W d is of size K \u00d7 (d + K) and softmax(q) = exp q / k j=1 exp q j . Our hope is that this recurrent connection will carry some of the previous relationship state over to the current time step. It should be unlikely for two characters in love at time t to fall out of love at time t + 1 even if s t+1 does not include any love-related words. However, because the objective function in Equation 4 maximizes similarity with the current time step's input, the model is not forced to learn a smooth interpolation between the previous state and the current one. A natural remedy is to have the model predict the next time step's input instead, but this proves hard to optimize.\nWe instead force the model to use the previous relationship state by modifying Equation 5 to include a linear interpolation between d t and d t\u22121 ,\nd t = \u03b1 \u2022 softmax(W d \u2022 [h t ; d t\u22121 ])+ (1 \u2212 \u03b1) \u2022 d t\u22121 . (6)\nHere, \u03b1 is a scalar between 0 and 1. We experiment with setting \u03b1 to a fixed value of 0.5 as well as allowing the model to learn \u03b1 as in\n\u03b1 = \u03c3(v T \u03b1 \u2022 [h t ; d t\u22121 ; v st ]),(7)\nwhere \u03c3 is the sigmoid function and v \u03b1 is a vector of dimensionality 2d + K. Fixing \u03b1 = 0.5 initially and then tuning it after other parameters have converged improves training stability; for the specific hyperparameters we use see Section 4. 4", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Interpreting Descriptors and Enforcing Uniqueness", "text": "Recall that each descriptor is a d-dimensional row of R. Because our objective function J forces these descriptors to be in the same vector space as that of the word embeddings L, we can interpret them by looking at nearest neighbors in L using cosine distance as the similarity metric.\nTo discourage learning descriptors that are too similar to each other, we add another penalty term X to our objective function,\nX(\u03b8) = RR T \u2212 I , (8\n)\nwhere I is the identity matrix. This term comes from the component orthogonality constraint in independent component analysis (Hyv\u00e4rinen and Oja, 2000). We add J and X together to obtain our final training objective L,\nL(\u03b8) = J(\u03b8) + \u03bbX(\u03b8),(9)\nwhere \u03bb is a hyperparameter that controls the magnitude of the uniqueness penalty.", "publication_ref": ["b23"], "figure_ref": [], "table_ref": []}, {"heading": "Evaluating Descriptors and Trajectories", "text": "Because no previous work explores the interpretability of unsupervised relationship modeling over time, evaluating the RMN is tricky. Further compounding the problem is the subjective nature of the task; for example, is a trajectory that ignores a key event better than one that hallucinates episodes absent from source text?\nWith these issues in mind, we conduct three evaluations to show that our output is reasonable. First, we conduct a crowdsourced interpretability experiment that shows RMNs produce significantly more coherent descriptors than three topic model baselines. A second crowdsourced task indicates that our model produces trajectories that match plot summaries more accurately than topic models. Finally, we qualitatively compare the RMN's output to existing static annotations of literary relationships and find both expected and surprising results.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Topic Model Baselines", "text": "Before moving onto the evaluations, we briefly describe three baseline models, all of which are Bayesian generative models. Latent Dirichlet allocation (Blei et al., 2003, LDA) learns a single document-topic distribution per document; we can apply LDA to our dataset by concatenating all spans from a relationship into a single document. Similarly, NUBBI (Chang et al., 2009a) learns separate sets of topics for relationships and individual characters. 5 LDA and NUBBI are incapable of taking into account the chronological ordering of the spans because they view all relationships tokens as exchangeable. While we can compare the descriptors learned by these models to those of the RMN, we cannot evaluate their trajectories. We turn instead to the hidden topic Markov model (Gruber et al., 2007, HTMM), which foregoes the bag-of-words assumption of LDA and NUBBI in favor of modeling topic segments within a document as a Markov chain. This model outputs a smooth sequence of topic assignments over a document, so we can compare the trajectories it learns on our dataset to those of the RMN.", "publication_ref": ["b7"], "figure_ref": [], "table_ref": []}, {"heading": "Experimental Settings", "text": "In our descriptor interpretability experiments, we vary the number of descriptors (topics) for all models (K = 10, 30, 50). We train LDA and NUBBI for 100 iterations with a collapsed Gibbs sampler, and the HTMM uses the default setting of 100 EM iterations.\nFor the RMN, we initialize the word embedding matrix L with 300-dimensional GloVe embeddings trained on the Common Crawl (Pennington et al., 5 NUBBI requires additional spans that mention only a single character to differentiate character topics from relationship topics. None of the other models receives these extra data. The RMN learns more interpretable descriptors than three topic model baselines.\n2014). The character and book embeddings (C and B) are initialized randomly. We fix \u03b1 to 0.5 for the first 15 epochs of training; after the descriptor matrix R has converged, we fix R and tune \u03b1 using Equation 6for 15 more epochs. 6 Since the topic model baselines do not have access to character and book metadata, for fair comparison we also train a \"generic\" version of the RMN (GRMN) where the metadata embeddings are removed from Equation 2. The uniqueness penalty \u03bb is set to 10 \u22124 . All of the RMN model parameters except L are optimized using Adam (Kingma and Ba, 2014) with a learning rate of 0.001 for 30 epochs; the word embeddings are not fine-tuned during training. 7 We also apply word dropout (Iyyer et al., 2015) to the input spans, removing words from the vector average computation in Equation 1 with probability 0.5.", "publication_ref": ["b27", "b25"], "figure_ref": [], "table_ref": []}, {"heading": "Do Descriptors Make Sense?", "text": "The goal of our first experiment is to compare the descriptors R learned by the RMN to the topics learned by the topic model baselines. We conduct a word intrusion experiment (Chang et al., 2009b): workers identify an \"intruder\" word from a set of words thatother than the intruder-come from the same topic. For the topic models, the five most probable words are joined by a highly-probable word from a different topic as the intruder. We use the same procedure for the RMN   descriptor embeddings replaces topic-word probability. To control for randomness in the training process, we train three of each model, so the final experiment consists of 1,350 tasks (K = 10, 30, 50 descriptors per trial, three trials per model).\nWe collect judgments from ten different workers for each task using the Crowdflower platform. 8 Our evaluation metric, model precision (MP), is the fraction of workers that select the correct intruder word for a descriptor k. Low model precision signals descriptors that lack cohesive themes.\nOn average, the RMN's descriptors are much more interpretable than those of the baselines, as it achieves a mean model precision of 0.73 (Figure 3) across all values of K. There is little difference between the model precision of the three topic model baselines, which hover around 0.5. There is also little difference between the GRMN and RMN; however, visualizing the learned character and book embeddings as in Figure 6 may be insightful for literary scholars. We show example high and low precision descriptors for the RMN and HTMM in Table 1; a full list is included in the supplementary material.", "publication_ref": ["b8"], "figure_ref": ["fig_3", "fig_5"], "table_ref": ["tab_3"]}, {"heading": "Do Trajectories Make Sense?", "text": "While the previous evaluation focused only on descriptor quality, our next experiment compares the trajectories learned by the best RMN model from the intrusion experiment (measured by highest mean model precision) to those learned by the best HTMM model, which is the only baseline capable of learning relationship trajectories. Workers read a plot sum-mary and choose which model's trajectory best represents the relationship in question. We use the K = 30 setting because it provides the best balance between descriptor variety and trajectory interpretability.\nFor this evaluation, we crawl Wikipedia, Goodreads, and SparkNotes for plot summaries associated with our 1,383 books. We then remove all relationships where each involved character is not mentioned at least five times in the summary, which results in a final evaluation set of 125 relationships. 9 We present workers with two characters, a plot summary, and a visualization of trajectories learned by the RMN and the HTMM (Figure 4). The workers then select the trajectory that best matches the relationship described by the summary.\nTo generate the visualizations, we first have an external annotator label each descriptor from both models with a single word as in Table 1. For fairness, the annotator is unaware of the underlying models. For the RMN, we visualize trajectories by displaying the label of the argmax over descriptor weights d t at each time step t. Similarly, for the HTMM, we display the most probable topic at each time step. 10 The results of this task with seven workers per comparison favor the RMN: for 87 out of the 125 evaluated relationships (69.6%), the workers choose the RMN's trajectory over the HTMM's. We compute the Fleiss \u03ba value (Fleiss, 1971) to correct our inter-annotator agreement for chance and find that Summary: Govinda is Siddhartha's best friend and sometimes his follower. Like Siddhartha, Govinda devotes his life to the quest for understanding and enlightenment. He leaves his village with Siddhartha to join the Samanas, then leaves the Samanas to follow Gotama. He searches for enlightenment independently of Siddhartha but persists in looking for teachers who can show him the way. In the end, he is able to achieve enlightenment only because of Siddhartha's love for him.", "publication_ref": ["b16"], "figure_ref": [], "table_ref": ["tab_3"]}, {"heading": "A B TIME", "text": "Siddhartha and Govinda Figure 4: An example from the Crowdflower summary matching task; workers are asked to choose the trajectory (here, \"A\" is generated by the RMN and \"B\" by the HTMM) that best matches a provided summary that describes the relationship between Siddartha and Govinda (from Siddartha by Hesse).\n\u03ba = 0.32, indicating fair agreement among the workers. Furthermore, thirty-four relationships had unanimous agreement among the seven workers; of these, twenty-six were unanimous in favor of the RMN compared to only eight for the HTMM.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "What Makes a Relationship Positive?", "text": "While the previous two experiments show that the RMN is more interpretable and accurate than baseline models, we have not yet shown that its insights can aid in drawing connections across various books and genres. As a first step in this direction, we investigate what makes a relationship positive or negative by comparing trajectories from the RMN and HTMM to static affinity annotations from a recently-released dataset (Massey et al., 2015) of fictional relationships. Expected correlations (e.g., murder and sadness are strongly negative descriptors) emerge alongside surprising ones (politics is negative, religion is positive). The affinity labeling task of Massey et al. (2015) requires workers to describe a given relationship as positive, negative, or neutral. We consider only nonneutral relationships for which two annotators agree  on the affinity label and remove all books not present in our own dataset. This filtering step results in 120 relationships, 78% of which are positive and the remaining 22% negative.\nSince the annotations are static, we first aggregate our trajectories across all time steps. We compute K-dimensional \"average positive\" and \"average negative\" weight vectors a p and a n by averaging the relationship states d t for the RMN and the documenttopic distributions for the HTMM across all time steps for relationships labeled with a particular affinity. Then, we compute the vector difference a p \u2212 a n and sort it to produce a ranked list of descriptors, where descriptors with positive differences occur more frequently in positive relationships. Table 2 shows the most positive and most negative descriptors; of particular interest is the large negative weight associated with political relationships from both models.", "publication_ref": ["b32", "b32"], "figure_ref": [], "table_ref": ["tab_5"]}, {"heading": "Qualitative Analysis", "text": "Our experiments show the superiority of the RMN over various topic model baselines in both descriptor interpretability and trajectory accuracy, but what causes the improved performance? In this section, we analyze similarities between the RMN and HTMM and look at qualitative examples where the RMN succeeds and fails. We also connect the findings of our affinity experiment to existing literary scholarship.\nBoth models are equally proficient at learning and assigning event-based descriptors (e.g., crime, violence, food). More specifically, the RMN and HTMM agree on environmental descriptions (e.g., boats, outdoors) and graphic sexual scenes (Figure 5, middle).\nHowever, the RMN is more sophisticated with in-  2, one love descriptor is highly positive while a duplicate is strongly negative. 11 The RMN circumvents this problem with its uniqueness penalty (Equation 8).\nWhile the increased descriptor variety is a positive, sometimes it leads the RMN astray. The model largely ignores the love between Charles Darnay and Lucie Manette in Dickens' A Tale of Two Cities due to book's sad tone; meanwhile, the HTMM's trajectory, while vastly simplified, does pick up on the romance (Figure 5, right). While the RMN's learnable book and character embeddings should help, the signal in a span cannot lead to the \"proper\" descriptor.\nBoth the RMN and HTMM learn that politics is strongly negative (Table 2). Existing scholarship supports this finding: Victorian-era authors, for example, are \"obsessed with otherness . . . of antiquated social and legal institutions, and of autocratic and/or dictatorial abusive government\" (Zarifopol-Johnston, 1995), while in science fiction, \"dystopia--precisely because it is so much more common (than utopia)-bears the aspect of lived experience\" (Gordin et al., 2010). Our affinity data comes primarily from Victorian novels (e.g., by Dickens and George Eliot), leading us to believe that that the models are behaving reasonably. Finally, returning to the \"extra\" meaning of meals discussed in Section 1, food occurs slightly more frequently in positive relationships.", "publication_ref": ["b20"], "figure_ref": ["fig_4", "fig_4"], "table_ref": ["tab_5", "tab_5"]}, {"heading": "Related Work", "text": "There are two major areas upon which our work builds: computational literary analysis and deep neural networks for natural language processing.\nMost previous work in computational literary analysis has focused either on characters or events. In the former category, graphical models and classifiers have been proposed for learning character personas from novels (Bamman et al., 2014;Flekova and Gurevych, 2015) and film summaries (Bamman et al., 2013). The NUBBI model of Chang et al. (2009a) learns topics that statically describe characters and their relationships. Because these models lack temporal components (the focus of our task), we compare instead against the HTMM of Gruber et al. (2007).\nClosest to our own work is the supervised structured prediction problem of , in which features are designed to predict dynamic sequences of positive and negative interactions between two characters in plot summaries. Other research in this area includes social network construction from novels (Elson et al., 2010; and film (Krishnan and Eisenstein, 2015), as well as attempts to summarize and generate stories (Elsner, 2012).\nWhile some of the relationship descriptors learned by our model are character-centric, others are more events-based, depicting actions rather than feelings; such descriptors have been the focus of much previous work (Schank and Abelson, 1977;Chambers and Jurafsky, 2008;Chambers and Jurafsky, 2009;Orr et al., 2014). Our model is more closely related to the plot units framework (Lehnert, 1981;Goyal et al., 2013), which annotates events with emotional states.\nThe RMN builds on deep recurrent autoencoders such as the hierarchical LSTM autoencoder of ; however, it is more efficient because of the span-level vector averaging. It is also similar to recent neural topic model architectures (Cao et al., 2015;Das et al., 2015), although these models are limited to static document representations. We hope to apply the RMN to nonfictional datasets as well; in this vein, Iyyer et al. (2014) apply a neural network to sentences from nonfiction political books for ideology prediction.\nMore generally, topic models and related generative models are a central tool for understanding large corpora from science (Talley et al., 2011) to politics (Nguyen et al., 2014. We show representation learning models like RMN can be just as interpretable as LDA-based models. Other applications for which researchers have prioritized interpretable vector representations include text-to-vision mappings (Lazaridou et al., 2014) and word embeddings (Fyshe et al., 2015;Faruqui et al., 2015).", "publication_ref": ["b2", "b17", "b1", "b7", "b22", "b14", "b28", "b13", "b37", "b5", "b6", "b35", "b30", "b21", "b4", "b11", "b24", "b40", "b29", "b19", "b15"], "figure_ref": [], "table_ref": []}, {"heading": "Conclusion", "text": "We formalize the task of unsupervised relationship modeling, which involves learning a set of relationship descriptors as well as a trajectory over these descriptors for each relationship in an input dataset. We present the RMN, a novel neural network architecture for this task that generates more interpretable descriptors and trajectories than topic model baselines. Finally, we show that the output of our model can lead to interesting insights when combined with annotations in an existing dataset.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgments", "text": "We thank Jonathan Chang and Amit Gruber for providing baseline code, Thang Nguyen for helpful discussions about our model, and the anonymous reviewers for their insightful comments. This work was supported by NSF grant IIS-1320538. Boyd-Graber is also partially supported by NSF grants CCF-1409287 and NCSE-1422492. Any opinions, findings, conclusions, or recommendations expressed here are those of the authors and do not necessarily reflect the view of the sponsor.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Learning sparsely used overcomplete dictionaries", "journal": "", "year": "2014", "authors": "Alekh Agarwal; Animashree Anandkumar; Prateek Jain; Praneeth Netrapalli; Rashish Tandon"}, {"ref_id": "b1", "title": "Learning latent personas of film characters", "journal": "", "year": "2013", "authors": "David Bamman; O' Brendan; Noah A Connor;  Smith"}, {"ref_id": "b2", "title": "A bayesian mixed effects model of literary character", "journal": "", "year": "2014", "authors": "David Bamman; Ted Underwood; Noah A Smith"}, {"ref_id": "b3", "title": "Latent dirichlet allocation", "journal": "Journal of Machine Learning Research", "year": "2003", "authors": "M David;  Blei; Y Andrew; Michael I Jordan Ng"}, {"ref_id": "b4", "title": "A novel neural topic model and its supervised extension", "journal": "", "year": "2015", "authors": "Ziqiang Cao; Sujian Li; Yang Liu; Wenjie Li; Heng Ji"}, {"ref_id": "b5", "title": "Unsupervised learning of narrative event chains", "journal": "", "year": "2008", "authors": "Nathanael Chambers; Daniel Jurafsky"}, {"ref_id": "b6", "title": "Unsupervised learning of narrative schemas and their participants", "journal": "", "year": "2009", "authors": "Nathanael Chambers; Dan Jurafsky"}, {"ref_id": "b7", "title": "Connections between the lines: augmenting social networks with text", "journal": "", "year": "2009", "authors": "Jonathan Chang; Jordan Boyd-Graber; David M Blei"}, {"ref_id": "b8", "title": "Reading tea leaves: How humans interpret topic models", "journal": "", "year": "2009", "authors": "Jonathan Chang; Sean Gerrish; Chong Wang; Jordan L Boyd-Graber; David M Blei"}, {"ref_id": "b9", "title": "Modeling dynamic relationships between characters in literary novels", "journal": "", "year": "2016", "authors": "Snigdha Chaturvedi; Shashank Srivastava; Hal Daum\u00e9; Iii ; Chris Dyer"}, {"ref_id": "b10", "title": "Books That Cook: The Making of a Literary Meal", "journal": "NYU Press", "year": "2014", "authors": "J Cognard-Black; M Goldthwaite; M Nestle"}, {"ref_id": "b11", "title": "Gaussian lda for topic models with word embeddings", "journal": "", "year": "2015", "authors": "Rajarshi Das; Manzil Zaheer; Chris Dyer"}, {"ref_id": "b12", "title": "Image denoising via sparse and redundant representations over learned dictionaries", "journal": "IEEE Transactions on Image Processing", "year": "2006", "authors": "Michael Elad; Michal Aharon"}, {"ref_id": "b13", "title": "Character-based kernels for novelistic plot structure", "journal": "", "year": "2012", "authors": "Micha Elsner"}, {"ref_id": "b14", "title": "Extracting social networks from literary fiction", "journal": "", "year": "2010", "authors": "Nicholas David K Elson; Kathleen R Dames;  Mckeown"}, {"ref_id": "b15", "title": "Sparse overcomplete word vector representations", "journal": "", "year": "2015", "authors": "Manaal Faruqui; Yulia Tsvetkov; Dani Yogatama; Chris Dyer; Noah Smith"}, {"ref_id": "b16", "title": "Measuring nominal scale agreement among many raters", "journal": "Psychological bulletin", "year": "1971", "authors": "L Joseph;  Fleiss"}, {"ref_id": "b17", "title": "Personality profiling of fictional characters using sense-level links between lexical resources", "journal": "", "year": "2015", "authors": "Lucie Flekova; Iryna Gurevych"}, {"ref_id": "b18", "title": "How to Read Literature Like a Professor", "journal": "HarperCollins", "year": "2009", "authors": ""}, {"ref_id": "b19", "title": "A compositional and interpretable semantic space", "journal": "", "year": "2015", "authors": "Alona Fyshe; Leila Wehbe; Partha P Talukdar; Brian Murphy; Tom M Mitchell"}, {"ref_id": "b20", "title": "Utopia/dystopia: conditions of historical possibility", "journal": "Princeton University Press", "year": "2010", "authors": "Helen Michael D Gordin; Gyan Tilley;  Prakash"}, {"ref_id": "b21", "title": "A computational model for plot units", "journal": "Computational Intelligence Journal", "year": "2013", "authors": "Amit Goyal; Ellen Riloff; Hal Daum\u00e9; Iii "}, {"ref_id": "b22", "title": "Hidden topic markov models", "journal": "", "year": "2007", "authors": "Amit Gruber; Yair Weiss; Michal Rosen-Zvi"}, {"ref_id": "b23", "title": "Independent component analysis: algorithms and applications", "journal": "Neural networks", "year": "2000", "authors": "Aapo Hyv\u00e4rinen; Erkki Oja"}, {"ref_id": "b24", "title": "Political ideology detection using recursive neural networks", "journal": "In Proceedings of the Association for Computational Linguistics", "year": "2014", "authors": "Mohit Iyyer; Peter Enns; Jordan Boyd-Graber; Philip Resnik"}, {"ref_id": "b25", "title": "Deep unordered composition rivals syntactic methods for text classification", "journal": "", "year": "2015", "authors": "Mohit Iyyer; Varun Manjunatha; Jordan Boyd-Graber; Hal Daum\u00e9; Iii "}, {"ref_id": "b26", "title": "Macroanalysis: Digital Methods and Literary History. Topics in the Digital Humanities", "journal": "University of Illinois Press", "year": "2013", "authors": "Matt L Jockers"}, {"ref_id": "b27", "title": "Adam: A method for stochastic optimization", "journal": "", "year": "2014", "authors": "Diederik Kingma; Jimmy Ba"}, {"ref_id": "b28", "title": "You're Mr. Lebowski, I'm The Dude\": Inducing address term formality in signed social networks", "journal": "Association for Computational Linguistics", "year": "2015", "authors": "Vinodh Krishnan; Jacob Eisenstein"}, {"ref_id": "b29", "title": "Is this a wampimuk? cross-modal mapping between distributional semantics and the visual world", "journal": "", "year": "2014", "authors": "Angeliki Lazaridou; Elia Bruni; Marco Baroni"}, {"ref_id": "b30", "title": "Plot units and narrative summarization", "journal": "Cognitive Science", "year": "1981", "authors": "G Wendy;  Lehnert"}, {"ref_id": "b31", "title": "A hierarchical neural autoencoder for paragraphs and documents", "journal": "", "year": "2015", "authors": "Jiwei Li; Minh-Thang Luong; Dan Jurafsky"}, {"ref_id": "b32", "title": "Annotating character relationships in literary texts", "journal": "", "year": "2015", "authors": "Philip Massey; Patrick Xia; David Bamman; Noah A Smith"}, {"ref_id": "b33", "title": "Modeling topic control to detect influence in conversations using nonparametric topic models", "journal": "", "year": "2014", "authors": " Viet-An; Jordan Nguyen; Philip Boyd-Graber; Deborah Resnik; Jennifer Cai; Yuanxin Midberry;  Wang"}, {"ref_id": "b34", "title": "Sparse coding with an overcomplete basis set: A strategy employed by v1? Vision research", "journal": "", "year": "1997", "authors": "A Bruno; David J Olshausen;  Field"}, {"ref_id": "b35", "title": "Learning scripts as hidden markov models", "journal": "", "year": "2014", "authors": "J Walker Orr; Prasad Tadepalli; Janardhan Rao Doppa; Xiaoli Fern; Thomas G Dietterich"}, {"ref_id": "b36", "title": "Glove: Global vectors for word representation", "journal": "", "year": "2014", "authors": "Jeffrey Pennington; Richard Socher; Christopher Manning"}, {"ref_id": "b37", "title": "Scripts, Plans, Goals and Understanding: an Inquiry into Human Knowledge Structures", "journal": "", "year": "1977", "authors": "Roger Schank; Robert Abelson"}, {"ref_id": "b38", "title": "Grounded compositional semantics for finding and describing images with sentences", "journal": "Transactions of the Association for Computational Linguistics", "year": "2014", "authors": "Richard Socher; V Quoc; Christopher D Le; Andrew Y Manning;  Ng"}, {"ref_id": "b39", "title": "Inferring interpersonal relations in narrative summaries", "journal": "", "year": "2016", "authors": "Shashank Srivastava; Snigdha Chaturvedi; Tom Mitchell"}, {"ref_id": "b40", "title": "Database of NIH grants using machine-learned categories and graphical clustering", "journal": "Nature Methods", "year": "2011-05", "authors": "Edmund M Talley; David Newman; David Mimno; Bruce W Herr; Hanna M Wallach; A P C Gully; A G Burns; Andrew Miriam Leenders;  Mccallum"}, {"ref_id": "b41", "title": "Mr. bennet, his coachman, and the archbishop walk into a bar but only one of them gets recognized: On the difficulty of detecting characters in literary texts", "journal": "", "year": "2015", "authors": "Hardik Vala; David Jurgens; Andrew Piper; Derek Ruths"}, {"ref_id": "b42", "title": "Wsabie: Scaling up to large vocabulary image annotation", "journal": "", "year": "2011", "authors": "Jason Weston; Samy Bengio; Nicolas Usunier"}, {"ref_id": "b43", "title": "To kill a text: the dialogic fiction of Hugo, Dickens, and Zola", "journal": "University of Delaware Press", "year": "1995", "authors": "Ilinca Zarifopol-Johnston"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 1 :1Figure 1: An example trajectory depicting the dynamic relationship between Lucy and Arthur in Bram Stoker's Dracula, which starts with love and ends with Arthur killing the vampiric Lucy.", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 2 :2Figure 2: An example of the RMN's computations at a single time step. The model approximates the vector average of an input span (vs t ) as a linear combination of descriptors from R. The descriptor weights dt define the relationship state at each time step and-when viewed as a sequence-form a relationship trajectory.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 3 :3Figure 3: Model precision results from our word intrusion task.", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 5 :5Figure 5: Left: the RMN is able to model Arthur and Lucy's trajectory reasonably well compared to our manually-created version in Figure 1. Middle: both models agree on event-based descriptors such as food and sex. Right: a failure case for the RMN in which it is unable to learn that Lucie Manette and Charles Darnay are in love.", "figure_data": ""}, {"figure_label": "6", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Figure 6 :6Figure6: Clusters from PCA visualizations of the RMN's learned book (left) and character (right) embeddings. We see a cluster of books about war and violence (many of which are authored by Tom Clancy) as well as a cluster of lead female characters from primarily romance novels. These visualizations show that the RMN can recover useful static representations of characters and books in addition to the dynamic relationship trajectories.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "r t = R T d t", "figure_data": "Mrs. ReillyIgnatius\"A Confederacyof Dunces\"Mrs. Reilly looked at her son slyly and asked,\"Ignatius, you sure you not a communiss?\"\"Oh, my God!\" Ignatius bellowed. \"Everyday I am subjected to a McCarthyitewitchhunt in this crumbling building. No!\""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "and GRMN, except that cosine similarity to", "figure_data": "RMNHTMMLabelMP Nearest NeighborsLabelMP Most Probable Wordssadness1.0 regretful rueful pity pained despondent violence 1.0 sword shot blood shouted swunglove1.0 love delightful happiness enjoyedboats1.0 ship boat captain deck crewmurder1.0 autopsy arrested homicide murderedfood1.0 kitchen mouth glass food breadworship0.1 toil pray devote yourselves gathersci-fi0.0 suppose earth robots computer certainmoodiness 0.3 glumly snickered quizzically guiltilyfantasy0.0 agreed magician dragon castle talentinformal0.4 kinda damn heck guess shittymilitary 0.1 ship captain lucky hour general"}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "Three high-precision (top)  and three low-precision (bottom) descriptors for the RMN and HTMM, along with labels from an external evaluator and model precision (MP) computed via word intrusion experiments. The RMN is able to learn a variety of interpersonal states (e.g., love, sadness), while the HTMM's most coherent topics are about concrete objects or events.", "figure_data": ""}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "Descriptors most characteristic of positive and negative relationships, computed using existing annotations. Compared to the RMN, the HTMM struggles to coherently characterize negative relationships. Interestingly, both models show negative predispositions for political relationships, perhaps due to genre bias or class differences.", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "h t = f (W h \u2022 [v st ; v c1 ; v c2 ; v b ]) v st v c1 v c2 v b d t 1 R d t = \u21b5 \u2022 softmax(W d \u2022 [h t ; d t 1 ])+ (1 \u21b5) \u2022 d", "formula_coordinates": [3.0, 100.09, 145.36, 192.16, 102.03]}, {"formula_id": "formula_1", "formula_text": "v st = 1 l w\u2208st v w .(1)", "formula_coordinates": [3.0, 389.92, 219.06, 150.08, 30.1]}, {"formula_id": "formula_2", "formula_text": "h t = f (W h \u2022 [v st ; v c 1 ; v c 2 ; v b ]).(2)", "formula_coordinates": [3.0, 355.89, 320.47, 184.11, 12.42]}, {"formula_id": "formula_3", "formula_text": "J(\u03b8) = |Sc 1 ,c 2 | t=0 n\u2208N max(0, 1 \u2212 r t v st + r t v sn ), (4", "formula_coordinates": [4.0, 77.46, 177.83, 217.11, 36.69]}, {"formula_id": "formula_4", "formula_text": ")", "formula_coordinates": [4.0, 294.56, 191.08, 4.24, 10.91]}, {"formula_id": "formula_5", "formula_text": "d t = softmax(W d \u2022 [h t ; d t\u22121 ])(5)", "formula_coordinates": [4.0, 118.0, 385.96, 180.8, 11.95]}, {"formula_id": "formula_6", "formula_text": "d t = \u03b1 \u2022 softmax(W d \u2022 [h t ; d t\u22121 ])+ (1 \u2212 \u03b1) \u2022 d t\u22121 . (6)", "formula_coordinates": [4.0, 106.31, 642.54, 192.49, 28.35]}, {"formula_id": "formula_7", "formula_text": "\u03b1 = \u03c3(v T \u03b1 \u2022 [h t ; d t\u22121 ; v st ]),(7)", "formula_coordinates": [4.0, 365.59, 112.91, 174.41, 15.17]}, {"formula_id": "formula_8", "formula_text": "X(\u03b8) = RR T \u2212 I , (8", "formula_coordinates": [4.0, 379.14, 378.01, 156.62, 13.21]}, {"formula_id": "formula_9", "formula_text": ")", "formula_coordinates": [4.0, 535.76, 380.31, 4.24, 10.91]}, {"formula_id": "formula_10", "formula_text": "L(\u03b8) = J(\u03b8) + \u03bbX(\u03b8),(9)", "formula_coordinates": [4.0, 374.89, 485.89, 165.11, 10.91]}], "doi": ""}