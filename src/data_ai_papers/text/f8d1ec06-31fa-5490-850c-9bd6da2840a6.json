{"title": "The Space of All Stereo Images", "authors": "Steven M Seitz; Jiwon Kim", "pub_date": "", "abstract": "A theory of stereo image formation is presented that enables a complete classification of all possible stereo views, including non-perspective varieties. Towards this end, the notion of epipolar geometry is generalized to apply to multiperspective images. It is shown that any stereo pair must consist of rays lying on one of three varieties of quadric surfaces. A unified representation is developed to model all classes of stereo views, based on the concept of a quadric view. The benefits include a unified treatment of projection and triangulation operations for all stereo views. The framework is applied to derive new types of stereo image representations with unusual and useful properties. Experimental examples of these images are constructed and used to obtain 3D binocular object reconstructions.", "sections": [{"heading": "Introduction", "text": "A stereo pair consists of two images with purely horizontal parallax, that is, every scene point visible in one image projects to a point in the same row of the other. We seek to characterize the space of all stereo images. In particular, suppose that you could construct two sensors that each measure light along an arbitrary two-parameter set of viewing rays and place the resulting measurements in an image. What is the range of light rays and sensor designs that produce a stereo pair?\nWhile the geometric properties of perspective images are well understood, relatively little is known about other types of stereo images. Non-perspective image representations have received renewed interest in recent years due to the development of practical panoramic sensors [1,2] and a host of applications in vision and graphics. Furthermore, recent results [3] have demonstrated the existence of stereo panoramas [4] that enable an observer to achieve a \u00bf \u00bc AE depth perception. Processing such images with stereo algorithms enables a panoramic scene reconstruction from a single image pair [3,5], a key capability that is not possible with perspective images.\nInspired by this previous work in multiperspective imaging, we seek to identify all of the ways in which stereo images may be formed. Towards this end, this paper makes the following contributions: Epipolar geometry is extended to multiperspective images. The main result is that three varieties of epipolar geometry exist, corresponding to families of planes, hyperboloids, and hyperbolic-paraboloids.\nIt is shown that all stereo images represent rays lying on quadric surfaces. Based on this analysis, a complete classification of stereo images is derived.\nA unified representation is introduced to model all classes of stereo images, based on the concept of a quadric view. The benefits include a unified treatment of projection and triangulation operations for all stereo image varieties.\nA recipe book for generating stereo images is provided. In order to demonstrate the power of this framework, we show how all previous stereo images can be systematically constructed, and present three new varieties with interesting properties. Real examples of one of these representations, which we call stereo cyclographs, are shown.\nIt is shown that the only three-view epipolar geometry that exists is the planar variety.\nThese results are perhaps counter-intuitive in two respects. On one hand, they demonstrate that we can potentially fuse images that have multiple centers of projection. This is surprising, in that our visual system is clearly designed for processing two single-perspective images. On the other hand, it is surprising that so few varieties of stereo views exist. Out of all possible 2D subsets of the 5D set of rays, only three varieties satisfy the stereo constraint! Concurrent with this research, Pajdla [6] independently obtained a similar classification of epipolar surfaces (the first bullet in the above list), but specialized for the case of cameras that capture lines rather than rays.\nThe remainder of the paper is structured as follows. Section 2 introduces a generalized model of image formation and defines the stereo constraint geometrically. Section 3 presents our classification of stereo images and their associated epipolar geometries. Section 4 introduces the concept of a quadric view and a unified mathematics for stereo imaging. The stereo cyclograph is introduced in Section 5 and used experimentally to produce stereo object visualizations and 3D reconstructions.", "publication_ref": ["b0", "b1", "b2", "b3", "b2", "b4", "b5"], "figure_ref": [], "table_ref": []}, {"heading": "Stereo Imaging 2.1 A Generalized Imaging Model", "text": "Light in any environment flows along straight lines in space 1 . From the viewer's perspective, it is convenient to model light flow in terms of the distribution of light that is received at each point and from each direction in the environment, i.e., along each light ray \u00ca\u00b4\u00dc \u00dd \u00de \u00b5. We represent a light ray as a function \u00ca mapping the ray origin\u00b4\u00dc \u00dd \u00de\u00b5 and direction\u00b4 \u00b5 to the set of all points along that ray. The set of all light rays defines a five-dimensional set that we call ray space and denote \u00c8. The light energy flowing along these rays can be represented as a function \u00c8 \u00c8 , where represents light energy 2 .\n\u00c8 is known as the plenoptic function [7].\nWe use the term view to denote any two-dimensional subset of light rays:\nA view is any function \u00ce \u00c8 on a surface that maps image coordinates\u00b4\u00d9 \u00da\u00b5 to light rays. We adopt the convention that \u00d9 varies horizontally and \u00da vertically.\nAn image \u00c1 measures the light observed for a view, i.e., \u00c1 \u00c8 AE \u00ce .\nConceptually, a view encodes imaging geometry-the distribution of light rays measured by a camera, whereas an image represents photometry-light energy radiated from the environment toward the camera. The domain determines a view's parameterization. Cylindrical [8], spherical [1], toroidal [5], and other non-planar image representations may be represented by choosing a domain with the appropriate topology. In this paper, it is implicit that every image \u00c1 has a corresponding view \u00ce . Accordingly, any terms that we define for views, e.g., field of view, stereo pair, etc., will also apply to images.\nThese definitions are very broad, encompassing most projection models used in the computer vision literature, including single point perspective, orthographic, weak perspective, and affine models [9]. In addition, non-perspective mosaic representations fit this definition, including single-perspective panoramas [1], multiperspective panoramas [10], manifold mosaics [11], multiple-center-of-projection images [12], stereo panoramas [4], concentric mosaics [13], omnivergent images [5], and [2]. Note that this definition of an image requires that every image point corresponds to a unique light ray; point spread functions, for instance, are not modeled.\n\u00bf \u00bc \u00a2 \u00bf \u00bc panoramas\nThe following terminology and notation will be useful. We use the notation \u00d9 to denote the restriction of the domain to a column \u00d9 in a view, i.e., \u00d9 \u00b4 \u00b5 \u00be \u00d9 . Similarly, \u00da denotes the restriction of to row \u00da. The shorthand \u00ca denotes the set of points along a ray whose parameters are unspecified. Accordingly, we write \u00be \u00ca when a 3D point lies along a ray \u00ca. In this paper, rays are defined to be open, i.e.,\u00b4\u00dc \u00dd \u00de\u00b5 \u00be \u00ca\u00b4\u00dc \u00dd \u00de \u00b5. This definition is natural in the context of scene visibility-a camera cannot see its own optical center\u00b4\u00dc \u00dd \u00de\u00b5. The intersection of two rays \u00ca \u00bd and \u00ca \u00be is written \u00ca \u00bd \u00ca \u00be . In general, this intersection can be a point, ray, open line segment, or be empty.\nThe projection of a point to a view \u00ce is defined to be the set of tuples\u00b4\u00d9 \u00da\u00b5 \u00be such that \u00be \u00ce\u00b4\u00d9 \u00da\u00b5. The projection of a set of points is defined to be the union of the projections of points in .\nThe field of view of a view \u00ce , denoted \u00c7 \u00ce\u00ce \u00b5 is defined to be the range of \u00ce , i.e., \u00c7 \u00ce\u00ce \u00b5 \u00ce\u00b4\u00d9 \u00da\u00b5 \u00b4\u00d9 \u00da\u00b5 \u00be . We say a point is within the field of view of \u00ce , written \u00be \u00c7 \u00ce\u00ce \u00b5 (with some abuse of notation), if lies along some ray in \u00c7 \u00ce\u00ce \u00b5.", "publication_ref": ["b0", "b6", "b7", "b0", "b4", "b8", "b0", "b9", "b10", "b11", "b3", "b12", "b4", "b1"], "figure_ref": [], "table_ref": []}, {"heading": "Multiperspective Imaging", "text": "Central (pin-hole) camera models have the property that all rays pass through a single point in 3D space, known as the center of projection. Driven by applications in graphics [10,12,13] and stereo matching [3,5], several researchers have proposed view representations that do not have a single distinguished center of projection. Rather, these multiperspective views capture rays that emanate from different points in space. We define the generator of a view to be the set of \"camera centers\" for that view:\nThe generator of a view \u00ce is defined to be \u00b4\u00dc \u00dd \u00de \u00b5 \u00b4\u00dc \u00dd \u00de \u00b5 \u00be \u00c7 \u00ce\u00ce \u00b5 .", "publication_ref": ["b9", "b11", "b12", "b2", "b4"], "figure_ref": [], "table_ref": []}, {"heading": "The Stereo Constraint", "text": "A stereo pair consists of two views with purely horizontal parallax, that is, every scene point visible in one view projects to a point in the same row of the other view. Images satisfying this property can be fused by human observers to produce a depth effect and are amenable to processing by computational stereo algorithms.\nVirtually all image representations exhibit some form of continuity, i.e., nearby points in the scene project to nearby points in the image. More formally, we say a view \u00ce is u-continuous if, for every value of \u00da, \u00ce\u00b4\u00d9 \u00da\u00b5 is a continuous function of \u00d9 and connected sets of points in \u00c7 \u00ce\u00ce \u00b5 project to connected subsets of \u00da . v-continuity is defined analogously. While most stereo views of interest exhibit both u-and v-continuity, our definition of stereo pair requires only the former, allowing for the distribution of rays to vary arbitrarily between rows.\nWe say that two \u00d9-continuous views \u00ce \u00bd and \u00ce \u00be satisfy the stereo constraint if the following property holds:\nThe rays \u00ce \u00bd\u00b4\u00d9\u00bd \u00da \u00bd \u00b5 and \u00ce \u00be\u00b4\u00d9\u00be \u00da \u00be \u00b5 intersect only if \u00da \u00bd \u00da \u00be .\nAny two such views are referred to as stereo views or a stereo pair.\nIt is often the case that views in a stereo pair will overlap only partially, i.e., there are points in the scene that lie within the field of view of one view but not the other. Such points cannot be \"fused\" and we therefore limit our analysis to regions of the scene within the field of view of both views. We also ignore points that are imaged with the same ray in both views, since such points do not provide stereo depth cues. For instance, two identical images from the same perspective camera viewpoint satisfy our definition of a stereo pair 3 , but yet do not provide parallax cues that can be used to infer depth. Accordingly, we define the stereo viewable region as follows A point in 3D space is stereo viewable from \u00ce \u00bd and \u00ce \u00be if there exist rays \u00ca \u00bd \u00be \u00c7 \u00ce\u00ce \u00bd \u00b5 and \u00ca \u00be \u00be \u00c7 \u00ce\u00ce \u00be \u00b5 such that \u00ca \u00bd \u00ca \u00be .\nThe set of all points that are stereo viewable from two views \u00ce \u00bd and \u00ce \u00be is referred to as the stereo viewable space, denoted \u00ce \u00be \u00bd . Note that there are generally points in the stereo viewable space that are occluded in one or both images. Occlusions will not affect our analysis, however, since the stereo constraint is defined by the distribution of rays, independent of visibility.", "publication_ref": ["b2"], "figure_ref": [], "table_ref": []}, {"heading": "Generalized Stereo", "text": "It is well-known that any pair of perspective views \u00ce \u00bd and \u00ce \u00be can be converted into a stereo pair by reparameterization of the respective view domains \u00bd and \u00be . While typically performed using homographies [14], other rectification transforms may be used to avoid certain types of singularities [15]. Our definition of stereo pair is easily generalized to included any pair of views that can be converted into a stereo pair by some rectification transformation:  This definition reduces the problem of characterizing generalized stereo pairs to that of characterizing (non-generalized) stereo pairs. Note that view geometry, i.e., the distribution of rays in space, is invariant with respect to rectification transformations. Rather, rectification affects only the parameterization of the view domain. By ignoring the specifics of the rectification transforms \u00d6 \u00bd and \u00d6 \u00be , we may focus on the simpler case of stereo pairs with horizontal geometry, but ensure that all of our results apply also to the generalized case, which includes views such as catadioptrics with curved epipolar lines [16].", "publication_ref": ["b13", "b14", "b15"], "figure_ref": [], "table_ref": []}, {"heading": "Central Perspective Stereo", "text": "The classical example of a stereo pair consists of two planar perspective views where the second view has been translated horizontally from the first 4 . The fact that two such images have horizontal parallax is important both for human perception and computational stereo vision.\nIt has long been known that a perspective stereo pair (\u00ce \u00bd , \u00ce \u00be ) obeys a very special geometric constraint: the rays in both views all lie on a pencil of planes, as shown in Fig. 1(a). In particular, the rays in row \u00da of \u00ce \u00bd sweep out a surface that lies on a plane in the scene, denoted \u00c8 \u00da . Similarly, row \u00da of \u00ce \u00be sweeps out a second surface that also lies on \u00c8 \u00da . \u00c8 \u00da is known as the epipolar plane of row \u00da of the image.\nNote that any pair of perspective images defines a pencil of epipolar planes, i.e., epipolar geometry applies to all perspective images, not just to stereo pairs. In fact, it has been shown that epipolar geometry applies to panoramic views that are defined on cylindrical [8] or spherical image domains [16]. In general, it can be seen that any pair of central views, i.e., views that are each generated by a single point, can be partitioned into rays that lie on epipolar planes-as shown in Fig. 1(a), this condition is independent of the shape of the imaging surface and depends only on the positions of the generators (camera centers). Consequently, any pair of perspective images satisfies the generalized stereo constraint.", "publication_ref": ["b3", "b7", "b15"], "figure_ref": ["fig_0", "fig_0"], "table_ref": []}, {"heading": "Multiperspective Stereo", "text": "While the epipolar condition (referred to as epipolar geometry) is well-understood for perspective views, it is not clear what it means for two multiperspective views to have epipolar geometry. In particular, can stereo pairs be created from views that do not have a single center of projection? Recent work has shown that multiperspective stereo pairs do indeed exist. For instance, Ishiguro et al. [3] and Peleg et al. [4] described how stereo panoramas could be produced by capturing a set of viewing rays passing through a circle. Interestingly, stereo panoramas can be shown to have purely horizontal parallax [5], but, unlike perspective views, allow for a \u00bf \u00bc AE field of view. Do stereo panoramas have epipolar geometry? Clearly, the rays from stereo panoramas do not all lie on a pencil of planes.\nNote that each scanline of the left view is formed by rotating a single ray around a circle, sweeping out a hyperboloid \u00cb \u00bd as shown in Fig. 1(b 1: Any quadric may be generated by moving a sensor along a conic path. This table shows the doubly-ruled quadrics for each conic generating path.\nensuring that the left and right scanlines correspond to the same subset of the scene. In the same way that perspective rays lie on epipolar planes, rays from stereo panoramas can be shown to lie on \"epipolar hyperboloids.\" Note that Rademacher and Bishop [12] previously explored ways of defining epipolar geometry for a broad class of multiperspective images called multiple-center-of-projection (MCOP) images. Their formulation is quite general, but removes most of the benefits that epipolar geometry provides for stereo processing, in particular: (1) there is generally not a oneto-one correspondence between epipolar curves in two MCOP images, (2) an MCOP image may have a two-rather than a one-dimensional set of epipolar curves, (3) there is no natural extension of epipolar planes to MCOP images, and (4) two MCOP's cannot always be rectified to produce a stereo pair. We seek a more natural generalization of epipolar geometry to multiperspective images that retains its benefits for stereo processing.", "publication_ref": ["b2", "b3", "b4", "b11"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "A Classification of Stereo Views", "text": "What is the space of all stereo views? In this section we derive a complete classification of pairs of views that satisfy the stereo constraint.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Epipolar Surfaces", "text": "Let \u00ce \u00bd and \u00ce \u00be be two stereo views, and consider a specific row \u00da. Since both views are \u00d9-continuous, the light rays \u00ce \u00b4\u00d9 \u00da\u00b5, for fixed \u00da, sweep out a ruled surface \u00cb . We are interested in the subset of \u00cb \u00bd and \u00cb \u00be that is stereo viewable. In particular, define the epipolar surface for row \u00da to be \u00cb \u00be \u00bd\u00b4\u00da \u00b5 \u00cb \u00bd \u00cb \u00be \u00ce \u00be \u00bd . In the case of perspective or any other type of central views, for example, \u00cb \u00be \u00bd\u00b4\u00da \u00b5 is planar for all \u00da.\nIn the general case, observe that \u00cb \u00be \u00bd\u00b4\u00da \u00b5 contains two families of straight lines, one from \u00ce \u00bd and the other from \u00ce \u00be . Hence, \u00cb \u00be \u00bd\u00b4\u00da \u00b5 lies on a doubly-ruled surface (see Fig. 1). We may therefore characterize the space of stereo views by classifying the set of all doubly-ruled epipolar surfaces. Fortunately, the latter set can be explicitly characterized. In particular, the only doubly-ruled surfaces are the plane, hyperboloid, and hyperbolic paraboloid [17]. While this classical result applies to algebraic surfaces ruled by lines, with some care it can be extended to the case of arbitrary surfaces ruled by rays or line segments. A proof is presented in Appendix A.\nWe therefore have the following result:\nStereo Classification Theorem: \u00ce \u00bd and \u00ce \u00be are stereo views only if for every row \u00da, \u00cb \u00be \u00bd\u00b4\u00da \u00b5 lies on a plane, hyperboloid, or hyperbolic paraboloid.\nThis result demonstrates that we can potentially fuse images that have multiple centers of projection, a result that may seem counter-intuitive. Also surprising is that so few varieties of stereo views exist-out of all possible 2D subsets of the 5D set of rays, only three varieties satisfy the stereo constraint.\nNote that this theorem concerns the distribution of rays in space, but does not specify the exact parameterization. The generalized stereo constraint in Section 2.4 further broadens the space of stereo images by allowing any parameterization of rays so that epipolar surfaces map to arbitrary curves (or 1D point sets) rather than horizontal lines. Regardless of parameterization, however, the plane, hyperboloid, and hyperbolic paraboloid are the only types of epipolar surfaces.\nWe use the term quadric view to denote a view having the property that all rays in each row lie on a quadric surface.\nimage representation generator epipolar surfaces perspective point pencil of planes stereo panorama [3,4,5] circle hyperboloids\n\u00bf \u00bc \u00a2 \u00bf \u00bc [5, 2]\ncircle hyperboloids spherical omnivergent [5] sphere pencil of planes pushbroom panorama line pencil of planes stereo cyclograph ellipse hyperboloids parabolic panorama parabola hyperbolic paraboloids ", "publication_ref": ["b16", "b2", "b3", "b4", "b4"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Three-and N-View Stereo", "text": "The stereo constraint is easily generalized to three or more views by requiring that the two-view stereo constraint be satisfied for every pair of views. A direct consequence of this condition is that all three views must share the same set of epipolar surfaces. In particular, each row must sweep out a triply-ruled surface. Since every triply-ruled surface is also doubly-ruled, the epipolar surfaces must lie on planes, hyperboloids, or hyperbolic paraboloids, by the Stereo Classification Theorem. Of these, only the plane is a triply-ruled surface (it has an infinite number of rulings). It follows that the only epipolar geometry for three or more views is the planar variety. The pushbroom panorama described in Section 3.3 is an example of an image representation that can be used to form stereo triplets, quadruplets, etc.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Generating Stereo Views", "text": "We now turn to the problem of how stereo views may be captured. Whereas perspective views can be imaged with a small CCD array, the same is not necessarily true for multiperspective views. In general, multiperspective views require placing sensors on a generating path or surface. In principle, this generator could be arbitrarily complex. Due to their restrictive form, however, stereo views are generated with relative ease. In particular, any quadric view may be generated by capturing rays from one or more conic path. For instance, a hyperboloid is generated by a line, ellipse, or hyperbola. Conversely, any conic is the generator for some quadric surface. Table 1 summarizes the doubly-ruled quadrics corresponding to each conic generator. This table may be used as a recipe book for generating stereo pairs. For instance, suppose you wish to generate a stereo pair with hyperbolic paraboloid epipolar geometry. Table 1 indicates that you could capture the appropriate rays by moving a camera or placing sensors on a line, parabola, or hyperbola. All of the specific quadric view varieties discussed in this paper are generated from a single conic path. It is possible, however, to define quadric views where each row has a different generating path, and these latter views are also subsumed by our framework.\nBecause our classification is comprehensive, we can characterize all previously proposed varieties of stereo images in terms of their generators and corresponding families of quadric epipolar surfaces (Table 2). In addition, the classification suggests new varieties of interest, three of which are listed in the table. The pushbroom panorama and parabolic panorama are described briefly in this section, and the stereo cyclograph is presented in detail in Section 5.\nA pushbroom panorama is generated by translating a camera to create a sequence of images with purely horizontal parallax. Suppose we translate a perspective camera parallel to the image-plane \u00d9-axis, and extract column of pixels from every input image. Placing these columns into successive columns of a new image \u00c1 creates a new image representation which we call a pushbroom panorama. Selecting different subsets of rays from each view produces other varieties of pushbroom panoramas. For instance, capturing a cone of rays symmetric about the translation direction generates the omnidirectional pushbroom panorama shown in Fig. 2(a). This image representation is a generalization of pushbroom cameras [18] that relaxes the assumption that the sensors be oriented perpendicular to the direction of motion and allows for a 360 degree field of view about the axis of translation.\nAny two pushbroom panoramas \u00c1 and \u00c1 from the same generating path form a stereo pair with rays lying on a pencil of epipolar planes, as shown in Fig. 2(a). These images are a hybrid between orthographic and perspective images, since rays within each row are parallel but every column of rays meets at a point. They also have the interesting property that disparity is a linear function of depth, in contrast to perspective stereo images. Note that pushbroom panoramas are not the same as EPI images [19], although their construction is similar. An example use of pushbroom panoramas is to create a stereo panorama of an entire city street, as shown in Fig. 3. The second new variety of stereo pair proposed in this paper is generated by moving a camera on a parabolic path. As indicated in Table 1, this strategy can be used to create views whose rows lie on hyperbolic paraboloids, as shown in Fig. 2(b).\nAn example of such an image, which we call a parabolic panorama is shown in Fig. 4. Two parabolic panoramas that share the same set of hyperbolic paraboloids form a stereo pair. While of theoretical interest, this variety of stereo pair has a rather limited stereo viewable region with the wedge shape shown in Fig. 2(b). Consequently, a stereo effect is achieved only for objects near the generator, making this image representation less attractive compared with the alternatives in Table 2.\nSince all stereo pairs are made up of rays lying on quadric surfaces, it is convenient to cast our formulation in the framework of projective geometry.", "publication_ref": ["b17", "b18"], "figure_ref": ["fig_1", "fig_1", "fig_1", "fig_1"], "table_ref": ["tab_2", "tab_2"]}, {"heading": "Terminology", "text": "We denote points in the scene as 4D homogeneous column vectors \u00dc \u00dd \u00de \u00bd \u00cc and planes as 4D homogeneous row vectors \u00c8\n. Point is on plane \u00c8 if and only if\n\u00c8 \u00bc (1)\nAny quadric surface \u00c9 is represented as the set of solutions to a quadratic equation:\n\u00c9 \u00cc \u00c9 \u00bc (2\n)\nwhere \u00c9 is a symmetric \u00a2 matrix.  ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Quadric Representation", "text": "Let \u00ce be a \u00d9-continuous view. Each row of \u00ce defines a ruled surface \u00cb swept out by the rays in that row. If every row of \u00ce sweeps out a quadric surface, \u00ce is a quadric view. Suppose further that \u00ce is also \u00da-continuous with the property that every column also defines a quadric surface. We use the term bi-quadric view to denote such a view \u00ce . We will devote special attention to bi-quadric views since all of the stereo image varieties considered in this paper fit into this category.\nAny bi-quadric view is defined by a two parameter family of quadric surfaces. Let \u00c9 \u00d9 denote the quadric surface corresponding to column \u00d9 and \u00c9 \u00da the quadric surface corresponding to row \u00da of \u00ce . The ray \u00ce\u00b4\u00d9 \u00da\u00b5 is represented as the space of solutions to the following equations:\n\u00cc \u00c9 \u00d9 \u00bc (3) \u00cc \u00c9 \u00da \u00bc (4)\nwhere \u00c9 \u00d9 is a matrix representing the quadric corresponding to \u00c9 \u00d9 , and similarly for \u00c9 \u00da and \u00c9 \u00da . In addition, any number of field of view constraints of the following form may be enforced:\n\u00cc \u00c9 \u00bc (5)\nThe solutions to Eqs. (3)(4)(5) correspond to the set of all points \u00be \u00c7 \u00ce\u00ce \u00b5. For the special case that \u00c9 \u00d9 is a plane for every value of \u00d9, Eq. (3) may be more conveniently written:\n\u00c8 \u00d9 \u00bc (6)\nand similarly for Eqs. (4) and (5).\nFor example, consider the case of a planar perspective view \u00ce . The perspective projection equations may be written:\n\u00d9 \u00a5 , where \u00a5 is the \u00bf \u00a2 projection matrix for that view, and \u00d9 \u00d7\u00d9 \u00d7\u00da \u00d7 \u00cc . Using the notation that \u00a5 is the \u00d8 row of \u00a5, we can rewrite these equations as follow\u015b\n\u00a5 \u00bd \u00d9\u00a5 \u00bf \u00b5 \u00bc (7) \u00a5 \u00be \u00da\u00a5 \u00bf \u00b5 \u00bc (8) plus field of view constraints\u00b4\u00a5 \u00bd \u00d9 \u00d1 \u00d2 \u00a5 \u00bf \u00b5 \u00bc (9\n)\n\u00b4\u00a5 \u00bd \u00d9 \u00d1 \u00dc \u00a5 \u00bf \u00b5 \u00bc (10) \u00a5 \u00be \u00da \u00d1 \u00d2 \u00a5 \u00bf \u00b5 \u00bc (11\n)\n\u00b4\u00a5 \u00be \u00da \u00d1 \u00dc \u00a5 \u00bf \u00b5 \u00bc(12)\nEqs. (7)(8)(9)(10)(11)(12) represent the ray \u00ce\u00b4\u00d9 \u00da\u00b5 as the intersection of two planes and the viewing frustum, as shown in Fig. 5.\n\u00a5 \u00bd \u00d9\u00a5 \u00bf is the vector corresponding to the plane passing through the camera center and column \u00d9 of the image plane.\nSimilarly, \u00a5 \u00be \u00da\u00a5 \u00bf represents the plane from the camera center through row \u00da of the image plane.\nAs another example, consider the case of a \u00bf \u00bc \u00a2 \u00bf \u00bc panorama [2]. As originally described in [5], this variety of stereo view is generated by moving a camera along a circle and capturing a planar strip of rays that is normal to the circle radius.\nThe result is a panoramic image with a \u00bf \u00bc AE horizontal and vertical field of view. Since opposite edges of the image are identified, the domain of the view is a torus.\n\u00bc \u00bc \u00bd \u00bc \u00bc (15)\nThe field of view (inequality) constraints specify which set of rays are captured along the generating circle for a given image.\nIn particular, this view captures only \"forward\" rays in the direction of motion around the circle, from the top half of the hyperboloid. The corresponding image generates the top half of a \u00bf \u00bc \u00a2 \u00bf \u00bc panorama. The bottom half may be generated with a similar set of constraints.", "publication_ref": ["b2", "b3", "b4", "b4", "b6", "b7", "b8", "b9", "b10", "b11", "b1", "b4"], "figure_ref": ["fig_3"], "table_ref": []}, {"heading": "Quadric Projection", "text": "The camera projection operator maps 3D points into view coordinates\u00b4\u00d9 \u00da\u00b5. In the case of bi-quadric views, the projection operation maps 3D points onto two families of quadric surfaces, indexed by \u00d9 and \u00da. Given , \u00d9 and \u00da are computed by first checking that satisfies the field of view constraints, and then solving Eqs. ( 3) and ( 4) for \u00c9 \u00d9 and \u00c9 \u00da respectively. Note that these equations are linear in the elements of \u00c9 \u00d9 and \u00c9 \u00da . If \u00c9 \u00d9 and \u00c9 \u00da depend linearly on \u00d9 and \u00da then the solutions of \u00d9 and \u00da are also linear.\nIn the case of a \u00bf \u00bc \u00a2 \u00bf \u00bc panorama, for example, substituting Eqs. ( 13) and ( 14) into Eqs. ( 6) and ( 4) yields\n\u00d9 \u00a6 \u00d6 \u00d3\u00d7\u00b4\u00dc \u00a6 \u00dd \u00d4 \u00dc \u00be \u2022 \u00dd \u00be \u00bd \u00dc \u00be \u2022 \u00dd \u00be \u00b5 (16) \u00da \u00dc \u00be \u2022 \u00dd \u00be \u00bd \u00de \u00be(17)\nA unique value of \u00d9 may be obtained by enforcing the field of view constraints (Eqs. ( 15)).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Quadric Triangulation", "text": "Let\u00b4\u00d9 \u00bd \u00da \u00b5 in \u00ce \u00bd and\u00b4\u00d9 \u00be \u00da \u00b5 in \u00ce \u00be be projections of the same scene point . The problem of computing from its projections in two images is known as triangulation. The triangulation of\u00b4\u00d9 \u00bd \u00da \u00b5 and\u00b4\u00d9 \u00be \u00da \u00b5 is computed by solving the following equations for :\n\u00cc \u00c9 \u00d9\u00bd \u00bc (18) \u00cc \u00c9 \u00d9\u00be \u00bc (19) \u00cc \u00c9 \u00da \u00bc (20)\nWhen \u00c9 \u00d9\u00bd and \u00c9 \u00d9\u00be are planar, Eqs. ( 18) and ( 19) may be replaced with \u00c8 \u00d9\u00bd \u00bc and \u00c8 \u00d9\u00be \u00bc , respectively.\nFor the case of a \u00bf \u00bc \u00a2 \u00bf \u00bc panorama, the triangulation of image points\u00b4\u00d9 \u00bd \u00da \u00b5 and\u00b4\u00d9 \u00be \u00da \u00b5 is obtained by substituting Eqs. ( 13) and ( 14) into Eqs. (18)(19)(20). After applying the field of view constraints (Eqs. (15)) and simplifying, the following expression for is obtained:\n\u00d7 \u00d2\u00b4\u00d9 \u00be \u00b5 \u00d7 \u00d2\u00b4\u00d9 \u00bd \u00b5 \u00d7 \u00d2\u00b4\u00d9 \u00be \u00d9 \u00bd \u00b5 \u00d3\u00d7\u00b4\u00d9 \u00bd \u00b5 \u00d3\u00d7\u00b4\u00d9 \u00be \u00b5 \u00d7 \u00d2\u00b4\u00d9 \u00be \u00d9 \u00bd \u00b5 \u00bd \u00d4 \u00da \u00d8 \u00d2\u00b4\u00d9 \u00bd \u00d9 \u00be \u00be \u00b5 \u00bd \u00cc (21)", "publication_ref": ["b17", "b18", "b19", "b14"], "figure_ref": [], "table_ref": []}, {"heading": "The Quadric Fundamental Matrix", "text": "Let \u00ce \u00bd and \u00ce \u00be be a stereo pair. By definition, for two points\u00b4\u00d9 \u00bd \u00da \u00bd \u00b5 in \u00ce \u00bd and\u00b4\u00d9 \u00be \u00da \u00be \u00b5 in \u00ce \u00be to be in correspondence, \u00da \u00bd and \u00da \u00be must be identical. This constraint is easily encoded in terms of the fundamental matrix equation which has a very simple form for all (rectified) stereo views:\n\u00d9 \u00bd \u00da \u00bd \u00bd \u00be \u00bc \u00bc \u00bc \u00bc \u00bc \u00bd \u00bc \u00bd \u00bc \u00bf \u00be \u00d9 \u00be \u00da \u00be \u00bd \u00bf \u00bc (22)", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Stereo Cyclographs", "text": "An interesting type of panorama may be created by moving an inward-facing camera \u00bf \u00bc AE on an ellipse around an object of interest, capturing a column of pixels from each image, and stacking these columns side by side into a new panorama. This construction resembles an approach used by archaeologists to create unwrapped \"cyclograph\" 5 images of ancient pottery. Traditional cyclographs are produced by photographing a rotating object through a narrow slit placed in front of a length of moving film, a technique that dates back to the late 19th century [20].", "publication_ref": ["b19"], "figure_ref": [], "table_ref": []}, {"heading": "Generating Stereo Cyclographs", "text": "Using the concepts developed in this paper, it can be seen that the cyclograph construction generates a bi-quadric image, where the rows of the image sweep out hyperboloids and the columns define planes. In a traditional cyclograph image, all of these planes intersect at the axis of rotation and the quadrics degenerate to (singly-ruled) cones. If instead the slit is moved off-axis, the hyperboloids are not degenerate and are doubly-ruled. In addition, the planes corresponding to each column are all tangent to a cylinder, as shown in Fig. 6(b). Consequently, a stereo pair may be formed. Furthermore, our construction can be generalized to allow the strip to move on any ellipse, rather than a circle. The quadric representation of cyclographs, together with equations for projection and triangulation, are derived in Appendix B.\nIn order to create stereo cyclograph images of a person's head, we placed a video camera on a rotating platform and captured a sequence of images while the camera rotated in a circle around the subject. The camera was pointed inward towards the center of rotation. The entire image sequence contains just over 24 seconds of video. If the frames are stacked one on top of the other, they define an \u00dc-\u00ddvolume, similar to the \u00dc-\u00dd-\u00d8 volumes introduced by Bolles et al. [19] 6 The input images each correspond to an \u00dc-\u00dd slice through the volume for a fixed value of . Cyclograph images correspond to \u00ddslices through the volume, as shown in Fig. 6(a). In particular, a stereo cyclograph is formed from any two \u00ddslices that are symmetric about the slice \u00dc \u00dc \u00bc of rays that pass through the axis of rotation. Fig. 7 shows stereo cyclograph pairs constructed in this manner. Since all rays in a cyclograph are tangent to a cylinder, the interior of the cylinder is not visible. Hence, only the subject's nose, glasses, and pony-tail are visible in the top row of Fig. 7(b) and the rest of the object is seamlessly removed. As the radius of the cylinder is decreased, more of the subject's face comes into the field of view (second row), until the head is fully visible (third row), creating an interesting effect. The bottom pair is an anaglyph that is viewable with red-blue stereo glasses, with red over the left eye.\nLike traditional cyclographs, stereo cyclographs provide a simple and effective means for rendering the appearance of 3D objects for print or display. While traditional cyclographs represent only object appearance, however, stereo cyclographs allow the 3D structure of the object to be retained in the visualization. For instance, surface relief patterns are preserved and readily visualized in the stereo cyclograph images. Since the effective baseline can be varied at display time by choosing different \u00ddslices, the stereo pair is easily recalibrated to the eye separation of any observer.", "publication_ref": ["b18", "b5"], "figure_ref": ["fig_4", "fig_4", "fig_5", "fig_5"], "table_ref": []}, {"heading": "Shape from Cyclographs", "text": "In addition to visualization, cyclographs also have potential benefits for the purposes of shape reconstruction. For instance, the images in the bottom row of Fig. 7(b) could be provided as input to almost any stereo correspondence algorithm, yielding a nearly complete 3D head model from a single image pair. The stereo baseline could be controlled to best suit the stereo algorithm, potentially on a scanline-by-scanline basis. The entire set of cyclographs could be used for structure-from-motion or multi-baseline stereo processing, perhaps using new algorithms that exploit the unique structure of cyclograph sequences. In this section, we demonstrate the use of stereo matching techniques to reconstruct a 3D object model from a single cyclograph image pair. Cyclographs were generated by placing an object on top of a computer-controlled rotary turntable, and imaging the rotating object from a camera fixed at a certain distance from the table. A cyclograph stereo pair for a fixed baseline was chosen and used as input to a stereo matching technique. We used an (unaltered) implementation of Zitnick and Kanade's technique [21].\nFor the results shown here, the background portion of the cyclograph was manually specified and excluded from the reconstruction. Also excluded are pixels that matched with low confidence and points that lie beyond a certain distance from the center of rotation.\nFig. 8 shows stereo cyclographs of a toy horse and the resulting binocular stereo reconstructions. An interesting property of cyclograph stereo pairs is that scene points in the cyclograph that are imaged in front of the rotation axis, i.e., between the axis and the camera, have positive disparity, whereas points behind the rotation axis have negative disparity. For instance, in the cyclograph stereo pair of the horse, the front side of the head has positive disparity whereas the back side has negative disparity. This phenomenon is analogous to vergent stereo pairs, in which disparity is positive in front of the vergence point and negative behind it.\nThe horse reconstruction demonstrates the ability to obtain a true \"object model\" from a single stereo pair. In contrast, obtaining a model of this sort using traditional stereo images requires stitching together several stereo reconstructions acquired from different viewpoints. The advantage of using cyclographs is that a very reasonable object model may be obtained by running the stereo matching procedure only once, greatly simplifying reconstruction. Note that a reconstruction obtained in this manner may still contain holes-in particular, the top of the horse does not appear in the cyclograph and is thus omitted from the reconstruction. Note also that the head and neck of the horse lack geometric detail in comparison to the rest of the body. This lack of detail is primarily due to the fact that the neck is imaged at an oblique angle in this particular cyclograph pair. In addition, the head moves more quickly in the input sequence since it is closer to the camera path, thus resulting in a lower sampling rate in the cyclographs. As can be seen in Fig. 8(c), however, the shape of the horse is very well reconstructed.", "publication_ref": ["b20"], "figure_ref": ["fig_5", "fig_6", "fig_6"], "table_ref": []}, {"heading": "Conclusion", "text": "A theory of stereo image formation was presented that provides a complete classification of all possible stereo views. A main result is that only three varieties of epipolar surfaces exist, corresponding to rays lying on doubly-ruled quadrics. A second contribution is a novel representation called a quadric view that provides a unified mathematical treatment of all stereo views. This framework was used to derive projection and triangulation operations that apply equally to both perspective and multiperspective image representations. The framework was shown to subsume all previous stereo image representations and also enabled deriving three new types of stereo image representations with unusual and useful properties. One of these representations, the stereo cyclograph, was experimentally demonstrated and offers compelling advantages for visualization and 3D reconstruction tasks.\nWhile this paper addresses several research questions relating to stereo images, other avenues for future work in this area remain open. In particular, our definition of stereo image could be considered over-restrictive in certain respects. In particular, we have not considered cases in which multiple viewing rays map to the same pixel, as is the case with lens systems. Extending the theory to cope with multiple-valued views would be desirable and could potentially lead to more  In addition, it is possible to fuse some image pairs in which the parallax is not perfectly horizontal. Allowing such deviations could also lead to a broader class of images that give a stereo effect, and new approximate 3-view and N-view epipolar geometries may be possible [22]. Lastly, our analysis was independent of image irradiance information. Taking into account image irradiance might identify images that appear to have horizontal parallax, due to special surface texture or shading.\nFurther exploration of the space of stereo views will be necessary to determine which varieties are useful in practice. The topics of optics and multiperspective camera design are also important areas of future work in which promising initial progress has been made [2,23]. \u00bd\u00b4\u00da \u00b5\u00b5 is itself connected, a condition satisfied by most representations of interest including all varieties described in this paper, it lies entirely on a plane, hyperboloid, or hyperbolic paraboloid.\nX L 2 L 2 '' L 2 ' L 1 S 1 2 (v) l 1 V 1", "publication_ref": ["b21", "b1", "b22"], "figure_ref": [], "table_ref": []}, {"heading": "B Cyclograph Representation and Equations", "text": "This appendix presents the quadric representation of a stereo cyclograph and derives the equations for projection and triangulation. We present the equations for the case of a circular generator, but they may be generalized to the more general case of cyclographs generated by elliptical camera paths. We introduce the following terminology (see Fig. 10 \n\u00d6 \u00d8 \u00d2\u00b4 \u00be \u03bc \u00da \u00d6 \u00d8 \u00d2\u00b4\u00d8 \u00d8 \u00d5 \u00be \u2022 \u00be \u00b5 \u00d6 \u00d8 \u00d2\u00b4\u00da \u00d8 \u00d5 \u00be \u2022 \u00be \u00b5\nThe quadric representation of a stereo cyclograph is specified as follows:\n\u00c8 \u2022 \u00d9 \u00a2 \u00d7 \u00d2\u00b4\u00d9 \u2022 \u00b5 \u00d3\u00d7\u00b4\u00d9 \u2022 \u00b5 \u00bc \u00d6 \u00d7 \u00d2 \u00a3 (23) \u00c8 \u00d9 \u00a2 \u00d7 \u00d2\u00b4\u00d9 \u00b5 \u00d3\u00d7\u00b4\u00d9 \u00b5 \u00bc \u00d6 \u00d7 \u00d2 \u00bc \u00bd \u00bc \u00bc \u00bc \u00bc \u00bd \u00d8 \u00d2 \u00be \u00da \u00d6 \u00d3\u00d7 \u00d8 \u00d2 \u00da \u00bc \u00bc \u00d6 \u00d3\u00d7 \u00d8 \u00d2 \u00da \u00d6 \u00be \u00bf (25)\nwith the following field of view constraints:   27), specify that this view captures only the \"forward\" rays in front of the camera. The last field of view constraint Eq. (28) enforces the viewing ray to pass through the camera center, and is used to determine a unique solution for triangulation.\n\u00a2 \u00d3\u00d7\u00b4\u00d9 \u2022 \u00b5 \u00d7 \u00d2\u00b4\u00d9 \u2022 \u00b5 \u00bc \u00d6 \u00d3\u00d7 \u00a3 \u00bc (26)\n\u00a2 \u00d3\u00d7\u00b4\u00d9 \u00b5 \u00d7 \u00d2\u00b4\u00d9 \u00b5 \u00bc \u00d6 \u00d3\u00d7 \u00a3 \u00bc (27) \u00cc \u00be \u00bd \u00bc \u00bc \u00d6 \u00d3\u00d7\u00b4\u00d9 \u00b5 \u00bc \u00bd \u00bc \u00d6 \u00d7 \u00d2\u00b4\u00d9 \u00b5 \u00bc \u00bc \u00bd \u00d8 \u00d2 \u00be \u00da \u00bc \u00d6 \u00d3\u00d7\u00b4\u00d9 \u00b5 \u00d6 \u00d7 \u00d2\u00b4\u00d9 \u00b5 \u00bc \u00d6 \u00be \u00bf \u00bc (28", "publication_ref": [], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "B.1 Derivation", "text": "Rays from a column of a cyclograph rule out a plane.  As shown in Fig. 11(c), rays from a row of a cyclograph rule out a hyperboloid. In general, a hyperboloid can be expressed by an equation of the form \u00dc \u00be \u00be \u2022 \u00dd \u00be \u00be \u2022 \u00de \u00be \u00be \u00bd . Since the camera path is circular and the center of the hyperboloid is translated along the \u00de axis, the hyperboloid equation can be written as\n\u00dc \u00be \u2022 \u00dd \u00be \u00b4\u00de \u00de \u00bc \u00b5 \u00be \u00d6 \u00be \u00bc\nAs illustrated in Fig. 11(b), \u00de \u00bc corresponds to the \u00de coordinate of the translated center of the hyperboloid, and \u00d6 \u00bc corresponds to the minimum radius of the \u00dc \u00dd cross section of the hyperboloid occurring at \u00de \u00de \u00bc .\nWe need to solve for three coefficients , \u00de \u00bc and \u00d6 \u00bc . As shown in Fig. 10(a), \u00de \u00be increases by \u00d8 \u00d2 \u00be \u00da whenever \u00dc \u00be \u2022 \u00dd \u00be increases by 1. Therefore, \u00d8 \u00d2 \u00be \u00da .\nTo compute \u00de \u00bc and \u00d6 \u00bc , without loss of generality, consider a viewing ray \u00d0 which passes through a camera center at\n\u00bc \u00d6 \u00bc \u00bc\u00b5.\nFrom the illustration in Fig. 10(a), an arbitrary point on \u00d0 can be expressed as\u00b4 \u00d8 \u2022 \u00d6 \u00be \u00a1 \u00d8 \u00b4\u00da \u00d8 \u00b5\u00d8\u00b5.\nWe need to find \u00d8 that minimizes \u00dc \u00be \u2022 \u00dd \u00be , i.e., the distance from the \u00de axis.  27) are field of view constraints stating that this view contains only the subset of rays that point toward the inside of the circle. As shown in Fig. 11(a), for to lie on the \"forward\" portion of the viewing ray, the dot product between vector and must be nonnegative, where is a point on the line which is the intersection of the plane \u00c8 \u00d9 \u00bc and the plane containing the camera path.  Eq. ( 28) is a second field of view constraint enforcing to lie on the viewing ray from the camera center . Since the angle of with respect to \u00dc \u00dd plane is \u00da , \u00de \u00be \u00d8 \u00d2 \u00be \u00da \u00bc which yields Eq. (28). This constraint is necessary to obtain a unique solution for triangulation, as described in the following subsection.", "publication_ref": [], "figure_ref": ["fig_0", "fig_0", "fig_0", "fig_0", "fig_0"], "table_ref": []}, {"heading": "B.2 Projection and Triangulation", "text": "Without loss of generality, we assume that the camera rotates around the object in the counter-clockwise direction, and the cyclograph is generated by concatenating columns from left to right.\nThe 2D projection\u00b4\u00d9 \u00da\u00b5 of a 3D point into the left image of the stereo pair is computed by solving \u00c8 \u00d9 \u00bc and \u00cc \u00c9 \u00da \u00bc , which yields: \nIn fact, Eqs. (30) and (32) turn out to be the same, implying that identical solutions for \u00da are obtained for the left and right image.\nThe triangulation of\u00b4\u00d9 \u00bd \u00da \u00b5 and\u00b4\u00d9 \u00be \u00da \u00b5 corresponds to solving the following equations for :\n\u00c8 \u2022 \u00d9\u00bd \u00bc (33) \u00c8 \u00d9\u00be \u00bc (34) \u00cc \u00c9 \u00da \u00bc (35)\nEnforcing the field of view constraints, Eqs. (26), ( 27) and (28), yields the following expression for X:\n\u00d6 \u00d7 \u00d2 \u00d3\u00d7\u00b4\u00d9 \u00bd \u2022\u00d9 \u00be \u00be \u00b5 \u00d7 \u00d2\u00b4\u00d9 \u00bd \u00d9 \u00be \u00be \u2022 \u00b5 \u00d6 \u00d7 \u00d2 \u00d7 \u00d2\u00b4\u00d9 \u00bd \u2022\u00d9 \u00be \u00be \u00b5 \u00d7 \u00d2\u00b4\u00d9 \u00bd \u00d9 \u00be \u00be \u2022 \u00b5 \u00d6 \u00d8 \u00d2 \u00da \u00d7 \u00d2\u00b4\u00d9 \u00bd \u00d9 \u00be \u00be \u00b5 \u00d7 \u00d2\u00b4\u00d9 \u00bd \u00d9 \u00be \u00be \u2022 \u00b5 \u00bd \u00cc (36\n)\nThe second field of view constraint (Eq. (28)) eliminates a false solution that does not originate from the camera centers given by \u00d9 \u00bd and \u00d9 \u00be , as illustrated by Fig. 12(b). Each plane intersects the hyperboloid along two lines, and the intersection of these lines produces two triangulation points. However, only one of these two points is the true solution that corresponds to the intersection of two rays that originate from the correct camera centers \u00bd and \u00be .", "publication_ref": [], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Acknowledgements", "text": "We would like to thank Microsoft Research for providing access to their Cyberscan platform, and Sashi Raghupathy, Zicheng Liu, and Eric Hanson for their assistance in acquiring images. The stereo matching algorithm for the horse reconstruction was provided by Charles Zitnick and is available via the web: (http://www.cs.cmu.edu/ clz/stereo.html). The authors would like to thank Shai Avidan for helpful discussions in the early stages of this work, and also the anonymous reviewers of this paper for several useful comments and suggestions. The support of Intel Corporation, Microsoft Corporation, and the National Science Foundation under grants IIS-9984672 and IIS-0049095 is gratefully acknowledged.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A Proof of the Stereo Classification Theorem", "text": "We now derive the proof of the Stereo Classification Theorem presented in Section 3. The essence of the proof is to demonstrate that the result hold locally, i.e., that every interior point on \u00cb \u00be \u00bd\u00b4\u00da \u00b5 has a finite neighborhood that lies on a plane, hyperboloid, or hyperbolic paraboloid. Denote as\u00b4 \u00b5 the interior of a surface , i.e., the surface minus its boundary.\nSuppose that \u00ce \u00bd and \u00ce \u00be are a stereo pair of views. Let be a point on\u00b4\u00cb \u00be \u00bd\u00b4\u00da \u00b5\u00b5 and\u00b4\u00d9 \u00da \u00b5 the projection of in \u00ce for \u00bd \u00be. Let \u00c4 be the connected component of \u00ce \u00b4\u00d9 \u00da \u00b5 \u00b4\u00cb \u00be \u00bd\u00b4\u00da \u00b5\u00b5 containing , as shown in Fig. 9. By u-continuity, the projection of \u00c4 \u00be in \u00ce \u00bd spans an interval \u00d0 \u00bd of row \u00da that \"straddles\" \u00d9 \u00bd . We say an interval \u00d0 straddles \u00d9 if there exists an open set \u00d3 such that \u00d9 \u00be \u00d3 \u00d0. Observe that the same condition is true if we replace with any point on \u00c4 \u00bd , i.e., any point", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "A theory of single-viewpoint catadioptric image formation", "journal": "Int. J. of Computer Vision", "year": "1999", "authors": "S Baker; S Nayar"}, {"ref_id": "b1", "title": "360 x 360 mosaics", "journal": "", "year": "2000", "authors": "S K Nayar; A Karmarkar"}, {"ref_id": "b2", "title": "Omni-directional stereo", "journal": "PAMI", "year": "1992-02", "authors": "H Ishiguro; M Yamamoto; S Tsuji"}, {"ref_id": "b3", "title": "Stereo panorama with a single camera", "journal": "", "year": "1999", "authors": "S Peleg; M Ben-Ezra"}, {"ref_id": "b4", "title": "Omnivergent stereo", "journal": "", "year": "1999", "authors": "H.-Y Shum; A Kalai; S M Seitz"}, {"ref_id": "b5", "title": "Epipolar geometry of some non-classical cameras", "journal": "Slovenian Pattern Recognition Society", "year": "2001", "authors": "T Pajdla"}, {"ref_id": "b6", "title": "The Plenoptic Function and the Elements of Early Vision", "journal": "MIT Press", "year": "1991", "authors": "E H Adelson; J R Bergen"}, {"ref_id": "b7", "title": "Plenoptic modeling: An image-based rendering system", "journal": "", "year": "1995", "authors": "L Mcmillan; G Bishop"}, {"ref_id": "b8", "title": "Affine structure from motion", "journal": "J. Opt. Soc. Am. A", "year": "1991", "authors": "J J Koenderink; A J Van Doorn"}, {"ref_id": "b9", "title": "Multiperspective panoramas for cel animation", "journal": "", "year": "1997", "authors": "D N Wood; A Finkelstein; J F Hughes; C E Thayer; D H Salesin"}, {"ref_id": "b10", "title": "Panoramic mosaics by manifold projection", "journal": "", "year": "1997", "authors": "S Peleg; J Herman"}, {"ref_id": "b11", "title": "Multiple-center-of-projection images", "journal": "", "year": "1998-07", "authors": "P Rademacher; G Bishop"}, {"ref_id": "b12", "title": "Rendering with concentric mosaics", "journal": "", "year": "1999", "authors": "H.-Y Shum; L.-W He"}, {"ref_id": "b13", "title": "Computing rectifying homographies for stereo vision", "journal": "", "year": "1999", "authors": "C Loop; Z Zhang"}, {"ref_id": "b14", "title": "Cylindrical rectification to minimize epipolar distortion", "journal": "", "year": "1997", "authors": "S Roy; J Meunier; I Cox"}, {"ref_id": "b15", "title": "Epipolar geometry for panoramic cameras", "journal": "", "year": "1998", "authors": "T Svoboda; T Pajdla; V Hlavac"}, {"ref_id": "b16", "title": "Geometry and the Imagination", "journal": "AMS Chelsea", "year": "1991", "authors": "D Hilbert; S Cohn-Vossen"}, {"ref_id": "b17", "title": "Linear pushbroom cameras", "journal": "IEEE Trans. Pattern Analysis and Machine Intell", "year": "1997", "authors": "R Gupta; R I Hartley"}, {"ref_id": "b18", "title": "Epipolar-plane image analysis: An approach to determining structure from motion", "journal": "Int. J. of Computer Vision", "year": "1987", "authors": "R C Bolles; H H Baker; D H Marimont"}, {"ref_id": "b19", "title": "Principles of peripheral photography", "journal": "", "year": "1987-01", "authors": "A Davidhazy"}, {"ref_id": "b20", "title": "A cooperative algorithm for stereo matching and occlusion detection", "journal": "IEEE Trans. on Pattern Analysis and Machine Intelligence", "year": "2000", "authors": "C L Zitnick; T Kanade"}, {"ref_id": "b21", "title": "Stereo reconstruction from multiperspective panoramas", "journal": "", "year": "1999", "authors": "H.-Y Shum; R Szeliski"}, {"ref_id": "b22", "title": "Cameras for stereo panoramic imaging", "journal": "", "year": "2000", "authors": "S Peleg; Y Pritch; M Ben-Ezra"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 :1Figure 1: Epipolar Geometry. (a) Rays in two perspective views lie on a pencil of epipolar planes. (b) Rays in stereo panoramas and \u00bf \u00bc \u00a2 \u00bf \u00bc panoramas lie on a family of epipolar hyperboloids.", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 2 :2Figure 2: Epipolar geometry of a pushbroom panorama (a) and a parabolic panorama (b). For any row of a pushbroom panorama stereo pair, the pixels from both images lie in a plane. Rays from a given row of a parabolic panorama stereo pair trace out a hyperbolic paraboloid.", "figure_data": ""}, {"figure_label": "34", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 3 :Figure 4 :34Figure 3: Pushbroom Panorama generated from a car driving along a street, with the camera pointing out of the side window. (a) Selected input images. (b) Pushbroom stereo pairs with a baseline of 6, i.e., formed from two columns spaced 6 pixels apart. (c) Red-blue anaglyph generated by taking the blue and green channels from the first image and the red channel from the second image. It should be viewed with red-blue glasses with red over the left eye.", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 5 :5Figure 5: Bi-quadric Image Representation. A perspective view is represented by two families of planes (quadrics, more generally) \u00c8 \u00d9 and \u00c8 \u00da and field of view constraints. Each ray in the field of view is specified by the intersection of two of these planes.", "figure_data": ""}, {"figure_label": "6", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 6 :6Figure6: A cyclograph is generated by moving an inward-looking camera on an ellipse and stacking the sequence of images into an \u00dc-\u00ddvolume (a). \u00ddslices of the volume form cyclograph images. All of the rays in each cyclograph are tangent to a sheared cylinder (each cross section is an ellipse) (b). A stereo cyclograph pair consists of two views that are both tangent to the same sheared cylinder (b-c), but with tangent rays oriented in opposite directions.", "figure_data": ""}, {"figure_label": "7", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Figure 7 :7Figure 7: Stereo Cyclograph Images. (a) Four of 732 images captured by moving a camera on a circle around a person's head. (b) Cyclograph stereo pairs formed from these input images, corresponding to different slices of the \u00dc-\u00ddvolume. (c) Anaglyph viewable with red-blue stereo glasses (red over left eye).", "figure_data": ""}, {"figure_label": "8", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Figure 8 :8Figure 8: Cyclograph-based reconstruction of a toy horse. (a) Input images. (b) Cyclograph stereo pairs with baseline = 6. (c) Screen shots of reconstructed 3D mesh, shaded (top) and textured (bottom).", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "-Input view:\u00b4\u00d7 \u00d8\u00b5 whose origin is bottom-left corner of the image plane -World space:\u00b4\u00dc \u00dd \u00de\u00b5 whose origin is the intersection of the rotation axis and the camera motion plane -Cyclograph:\u00b4\u00d9 \u00da\u00b5 whose origin is bottom-left corner of the imag\u0113 : amount of rotation between frames in radians : baseline in pixels, i.e., distance between the two columns from which the stereo cyclograph pair is generated : camera's focal length in pixels \u00d8 : \u00d8 coordinate of the camera's principal point \u00d6: radius of the circular camera path", "figure_data": ""}, {"figure_label": "1011", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "Figure 10 :Figure 11 :1011Figure 10: (a) Geometry of a perspective view (note: the dotted line denotes the length of the corresponding line segment). (b) Camera moving along a circular path around the object.denotes the position of the camera center at frame .", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": ") Eqs. (23) and (26) correspond to the right image, and Eqs. (24) and (27) correspond to the left image of the stereo pair. The field of view constraints, Eqs. (26) and (", "figure_data": ""}, {"figure_label": "11", "figure_type": "figure", "figure_id": "fig_10", "figure_caption": "Fig. 11 (11a) shows the plane ruled out by rays of column \u00d9 of the left image of the stereo pair, which is generated by taking a column to the right of the principle point from each input frame. The right image is analogously formed by taking from each frame a column offset by the same distance to the left of the principal point. Although this might seem counter-intuitive, it is similar to the perspective vergent stereo where the same scene point is imaged by a right column of the left image and a left column of the right image, as illustrated by Fig.11(b).Eqs. (23) and (24) represent the plane ruled out by rays of column \u00d9. Since the angle of the plane from the \u00dc \u00de plane is \u00d9 \u00a6 (\u00d9 for the left image of stereo pair as shown in Fig.11(a), and \u00d9 \u2022 for the right image), and it passes through the camera center \u00d6 \u00d3\u00d7\u00b4\u00d9 \u00b5 \u00d6 \u00d7 \u00d2\u00b4\u00d9 \u00b5 \u00bc\u00b5, its equation is given as follows:", "figure_data": ""}, {"figure_label": "12", "figure_type": "figure", "figure_id": "fig_11", "figure_caption": "Figure 12 :12Figure 12: (a) A scene point projects twice into the same cyclograph. (b) Solving the triangulation equation produces two solutions \u00cc and \u00cc \u00bc , and \u00cc \u00bc is a false solution that is eliminated by enforcing the second field of view constraint.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "AE \u00d6 \u00bd and \u00ce \u00be AE \u00d6 \u00be satisfy the stereo constraint.", "figure_data": "Two views \u00ce \u00bd \u00d6 \u00bd \u00bc \u00bd \u00bd and \u00d6 \u00be \u00bd\u00c8 and \u00ce \u00be \u00be \u00c8 satisfy the generalized stereo constraint if there exist bijections \u00bc \u00be \u00be such that \u00ce \u00bd"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Classification of known stereo view varieties. The last three variants are introduced in this paper.", "figure_data": ""}, {"figure_label": "9", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "Proof of the Stereo Classification Theorem. There is an open interval \u00d0 \u00bd of row \u00da of \u00ce \u00bd such that every ray in this interval intersects all three line segments \u00c4 \u00be , \u00c4 \u00bc \u00be , and \u00c4 \u00bc\u00bc \u00be . This condition implies that the rays in \u00d0 \u00bd must lie on a plane, hyperboloid, or hyperbolic paraboloid. \u00be \u00c4 \u00bd determines a line segment \u00c4 \u00bc \u00be \u00b4\u00cb \u00be \u00bd\u00b4\u00da \u00b5\u00b5 whose projection straddles \u00d9 \u00bd . Let \u00c4 \u00bc \u00be and \u00c4 \u00bc\u00bc \u00be be two such line segments. . By construction, \u00d0 \u00bd is an interval that straddles \u00d9 \u00bd . Furthermore, \u00ce \u00bd\u00b4\u00d9 \u00da\u00b5 intersects \u00c4 \u00be , \u00c4 \u00bc for all \u00d9 \u00be \u00d0 \u00bd . We therefore have an infinite family of rays AE \u00ce \u00bd\u00b4\u00d9 \u00da\u00b5 \u00d9 \u00be \u00d0 \u00bd that all intersect three distinct lines, through \u00c4 \u00be , \u00c4 \u00bc \u00be , and, \u00c4 \u00bc\u00bc \u00be . Interestingly, this condition uniquely defines the surface in the neighborhood of [17]. In particular, if two of \u00c4 \u00be , \u00c4 \u00bc \u00be , and \u00c4 \u00bc\u00bc \u00be are co-planar then AE must lie on a plane. If the line segments are not co-planar but do lie on parallel planes, AE lies on a hyperbolic paraboloid. Otherwise, AE lies on a hyperboloid. \u00bd\u00b4\u00da \u00b5\u00b5 has an open neighborhood that lies on a quadric surface, more specifically, a plane, hyperboloid, or hyperbolic paraboloid. It follows that every connected component of\u00b4\u00cb \u00be \u00bd\u00b4\u00da \u00b5\u00b5 lies on the same quadric. In particular, if\u00b4\u00cb \u00be", "figure_data": "Define \u00d0 \u00bc \u00bd and \u00d0 \u00bc\u00bc \u00bd to be the respective projections of \u00c4 \u00bc \u00be and \u00c4 \u00bc\u00bc \u00be in \u00ce \u00bd . Consider \u00d0 \u00bd \u00d0 \u00bd \u00d0 \u00bc \u00bd \u00d0 \u00bc\u00bc and \u00c4 \u00bc\u00bc\u00be ,We have shown that every\u00be\u00b4\u00cb \u00be"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "\u00dd \u00d6 \u00d7 \u00d2\u00b4\u00d9 \u00b5 \u00d8 \u00d2\u00b4\u00d9 \u00a6 \u00b5 \u00a1\u00b4\u00dc \u00d6 \u00d3\u00d7\u00b4\u00d9 \u00b5\u00b5 Rearranging the above equation yields \u00dc \u00d7 \u00d2\u00b4\u00d9 \u00a6 \u00b5 \u00dd \u00d3\u00d7\u00b4\u00d9 \u00a6 \u00b5 \u2022 \u00d6\u00b4\u00d7 \u00d2\u00b4\u00d9 \u00b5 \u00d3 \u00d7\u00d9 \u00a6 \u00b5 \u00d3\u00d7\u00b4\u00d9 \u00b5 \u00d7 \u00d2 \u00d9 \u00a6 \u00b5\u00b5 1 \u00b5 \u00dc \u00d7 \u00d2\u00b4\u00d9 \u00a6 \u00b5 \u00dd \u00d3\u00d7\u00b4\u00d9 \u00a6 \u00b5 \u00a7 \u00d6 \u00d7 \u00d2 1", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "The minimum value of \u00dc \u00be \u2022 \u00dd \u00be is \u00d6 \u00be \u00d7 \u00d2 \u00be , which corresponds to \u00d6 \u00be \u00bc . Also, since the minimum occurs at \u00d8\u00d6 \u00d3\u00d7 \u00d5 \u00be \u2022 \u00be , \u00de \u00bc isobtained by substituting \u00d8 into the \u00de coordinate of .", "figure_data": "\u00dc \u00be \u2022 \u00dd \u00be \u00b4 \u00d8 \u2022 \u00d6\u00b5 \u00be \u2022\u00be \u00a1 \u00d8 \u00be\u00b4\u00be \u2022\u00be\u00b5\u00b4\u00d8\u00d6 \u00be \u2022\u00be \u00b5 \u00be \u2022\u00d6 \u00be \u00a1 \u00be \u00be \u2022 \u00be\u00b4\u00be \u2022\u00be\u00b5\u00b4\u00d8\u00d6 \u00d3\u00d7 \u00d5 \u00be \u2022\u00be\u00b5 \u00be \u2022 \u00d6 \u00be \u00d7 \u00d2 \u00be\u00de \u00bc \u00da\u00d8 \u00b5 \u00a1 \u00d6 \u00d3\u00d7 \u00d5 \u00be \u2022\u00be\u00d6 \u00d3\u00d7 \u00d8 \u00d2 \u00daTherefore, the equation of the hyperboloid finally reduces to\u00dc \u00be \u2022 \u00dd \u00be\u00bd \u00d8 \u00d2 \u00be \u00da\u00b4\u00de\u00d6 \u00d3\u00d7 \u00d8 \u00d2 \u00da \u00b5 \u00be \u00d6 \u00be \u00d7 \u00d2 \u00be1\u00b5\u00cc \u00c9 \u00da \u00bcEqs. (26) and ("}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_8", "figure_caption": "Analogously, the projection into the right image of the stereo pair is obtained by solving the equations \u00c8 \u2022", "figure_data": "\u00d9 \u00da\u00bd \u00a1\u00b4 \u00d6 \u00d3\u00d7\u00b4 \u00de \u00a1 \u00d6 \u00d3\u00d7 \u00a6 \u00d4 \u00d5 \u00dd\u00d6\u00d7 \u00d2 \u00a6 \u00dc \u00a1 \u00be \u2022 \u00be \u00dc \u00be \u2022 \u00dd \u00be \u00d6 \u00be \u00d7 \u00d2 \u00be \u00d5 \u00dc \u00be \u2022 \u00dd \u00be \u00dc \u00be \u2022 \u00dd \u00be \u00d6 \u00be \u00d7 \u00d2 \u00be \u00b5 \u2022 \u00d8\u00b5 \u2022 \u00b5(29) (30)\u00cc \u00c9 \u00da \u00bc , which yields:\u00d9\u00bc and\u00d9 \u00da\u00bd \u00a1\u00b4 \u00d6 \u00d3\u00d7\u00b4\u00dd \u00d5 \u00d6\u00d7 \u00d2 \u00a6 \u00dc \u00a1 \u00be \u2022 \u00be \u00de \u00a1 \u00d6 \u00d3\u00d7 \u00a6 \u00d4 \u00dc \u00be \u2022 \u00dd \u00be \u00d6 \u00be \u00d7 \u00d2 \u00be \u00d5 \u00dc \u00be \u2022 \u00dd \u00be \u00d6 \u00be \u00d7 \u00d2 \u00be \u00b5 \u00dc \u00be \u2022 \u00dd \u00be \u2022 \u00d8\u00b5\u00b5(31)"}], "formulas": [{"formula_id": "formula_0", "formula_text": "\u00bf \u00bc \u00a2 \u00bf \u00bc panoramas", "formula_coordinates": [2.0, 58.56, 511.53, 87.44, 15.6]}, {"formula_id": "formula_1", "formula_text": "\u00bf \u00bc \u00a2 \u00bf \u00bc [5, 2]", "formula_coordinates": [6.0, 194.52, 105.33, 65.89, 15.6]}, {"formula_id": "formula_2", "formula_text": "\u00c8 \u00bc (1)", "formula_coordinates": [7.0, 288.6, 613.05, 264.94, 18.0]}, {"formula_id": "formula_3", "formula_text": "\u00c9 \u00cc \u00c9 \u00bc (2", "formula_coordinates": [7.0, 256.92, 656.85, 292.74, 18.0]}, {"formula_id": "formula_4", "formula_text": ")", "formula_coordinates": [7.0, 549.66, 663.55, 3.87, 8.97]}, {"formula_id": "formula_5", "formula_text": "\u00cc \u00c9 \u00d9 \u00bc (3) \u00cc \u00c9 \u00da \u00bc (4)", "formula_coordinates": [9.0, 279.6, 351.81, 273.94, 33.0]}, {"formula_id": "formula_6", "formula_text": "\u00cc \u00c9 \u00bc (5)", "formula_coordinates": [9.0, 287.76, 420.33, 265.78, 18.0]}, {"formula_id": "formula_7", "formula_text": "\u00c8 \u00d9 \u00bc (6)", "formula_coordinates": [9.0, 285.96, 473.97, 267.58, 18.0]}, {"formula_id": "formula_8", "formula_text": "\u00a5 \u00bd \u00d9\u00a5 \u00bf \u00b5 \u00bc (7) \u00a5 \u00be \u00da\u00a5 \u00bf \u00b5 \u00bc (8) plus field of view constraints\u00b4\u00a5 \u00bd \u00d9 \u00d1 \u00d2 \u00a5 \u00bf \u00b5 \u00bc (9", "formula_coordinates": [9.0, 58.56, 551.37, 761.88, 74.64]}, {"formula_id": "formula_9", "formula_text": ")", "formula_coordinates": [9.0, 549.66, 614.71, 3.87, 8.97]}, {"formula_id": "formula_10", "formula_text": "\u00b4\u00a5 \u00bd \u00d9 \u00d1 \u00dc \u00a5 \u00bf \u00b5 \u00bc (10) \u00a5 \u00be \u00da \u00d1 \u00d2 \u00a5 \u00bf \u00b5 \u00bc (11", "formula_coordinates": [9.0, 254.76, 622.89, 558.48, 33.0]}, {"formula_id": "formula_11", "formula_text": ")", "formula_coordinates": [9.0, 549.33, 644.59, 4.15, 8.97]}, {"formula_id": "formula_12", "formula_text": "\u00b4\u00a5 \u00be \u00da \u00d1 \u00dc \u00a5 \u00bf \u00b5 \u00bc(12)", "formula_coordinates": [9.0, 255.72, 652.77, 297.76, 18.0]}, {"formula_id": "formula_13", "formula_text": "\u00bc \u00bc \u00bd \u00bc \u00bc (15)", "formula_coordinates": [10.0, 244.56, 227.59, 308.92, 14.6]}, {"formula_id": "formula_14", "formula_text": "\u00d9 \u00a6 \u00d6 \u00d3\u00d7\u00b4\u00dc \u00a6 \u00dd \u00d4 \u00dc \u00be \u2022 \u00dd \u00be \u00bd \u00dc \u00be \u2022 \u00dd \u00be \u00b5 (16) \u00da \u00dc \u00be \u2022 \u00dd \u00be \u00bd \u00de \u00be(17)", "formula_coordinates": [10.0, 225.12, 408.09, 328.36, 58.56]}, {"formula_id": "formula_15", "formula_text": "\u00cc \u00c9 \u00d9\u00bd \u00bc (18) \u00cc \u00c9 \u00d9\u00be \u00bc (19) \u00cc \u00c9 \u00da \u00bc (20)", "formula_coordinates": [10.0, 277.68, 561.57, 275.8, 47.88]}, {"formula_id": "formula_16", "formula_text": "\u00d7 \u00d2\u00b4\u00d9 \u00be \u00b5 \u00d7 \u00d2\u00b4\u00d9 \u00bd \u00b5 \u00d7 \u00d2\u00b4\u00d9 \u00be \u00d9 \u00bd \u00b5 \u00d3\u00d7\u00b4\u00d9 \u00bd \u00b5 \u00d3\u00d7\u00b4\u00d9 \u00be \u00b5 \u00d7 \u00d2\u00b4\u00d9 \u00be \u00d9 \u00bd \u00b5 \u00bd \u00d4 \u00da \u00d8 \u00d2\u00b4\u00d9 \u00bd \u00d9 \u00be \u00be \u00b5 \u00bd \u00cc (21)", "formula_coordinates": [10.0, 180.6, 674.79, 372.88, 27.48]}, {"formula_id": "formula_17", "formula_text": "\u00d9 \u00bd \u00da \u00bd \u00bd \u00be \u00bc \u00bc \u00bc \u00bc \u00bc \u00bd \u00bc \u00bd \u00bc \u00bf \u00be \u00d9 \u00be \u00da \u00be \u00bd \u00bf \u00bc (22)", "formula_coordinates": [11.0, 230.88, 121.41, 322.6, 40.14]}, {"formula_id": "formula_18", "formula_text": "X L 2 L 2 '' L 2 ' L 1 S 1 2 (v) l 1 V 1", "formula_coordinates": [16.0, 253.83, 128.16, 84.48, 87.05]}, {"formula_id": "formula_19", "formula_text": "\u00d6 \u00d8 \u00d2\u00b4 \u00be \u03bc \u00da \u00d6 \u00d8 \u00d2\u00b4\u00d8 \u00d8 \u00d5 \u00be \u2022 \u00be \u00b5 \u00d6 \u00d8 \u00d2\u00b4\u00da \u00d8 \u00d5 \u00be \u2022 \u00be \u00b5", "formula_coordinates": [17.0, 88.08, 480.27, 170.88, 40.8]}, {"formula_id": "formula_20", "formula_text": "\u00c8 \u2022 \u00d9 \u00a2 \u00d7 \u00d2\u00b4\u00d9 \u2022 \u00b5 \u00d3\u00d7\u00b4\u00d9 \u2022 \u00b5 \u00bc \u00d6 \u00d7 \u00d2 \u00a3 (23) \u00c8 \u00d9 \u00a2 \u00d7 \u00d2\u00b4\u00d9 \u00b5 \u00d3\u00d7\u00b4\u00d9 \u00b5 \u00bc \u00d6 \u00d7 \u00d2 \u00bc \u00bd \u00bc \u00bc \u00bc \u00bc \u00bd \u00d8 \u00d2 \u00be \u00da \u00d6 \u00d3\u00d7 \u00d8 \u00d2 \u00da \u00bc \u00bc \u00d6 \u00d3\u00d7 \u00d8 \u00d2 \u00da \u00d6 \u00be \u00bf (25)", "formula_coordinates": [17.0, 195.72, 548.25, 357.76, 115.02]}, {"formula_id": "formula_21", "formula_text": "\u00a2 \u00d3\u00d7\u00b4\u00d9 \u2022 \u00b5 \u00d7 \u00d2\u00b4\u00d9 \u2022 \u00b5 \u00bc \u00d6 \u00d3\u00d7 \u00a3 \u00bc (26)", "formula_coordinates": [17.0, 193.92, 685.05, 359.56, 16.68]}, {"formula_id": "formula_22", "formula_text": "\u00a2 \u00d3\u00d7\u00b4\u00d9 \u00b5 \u00d7 \u00d2\u00b4\u00d9 \u00b5 \u00bc \u00d6 \u00d3\u00d7 \u00a3 \u00bc (27) \u00cc \u00be \u00bd \u00bc \u00bc \u00d6 \u00d3\u00d7\u00b4\u00d9 \u00b5 \u00bc \u00bd \u00bc \u00d6 \u00d7 \u00d2\u00b4\u00d9 \u00b5 \u00bc \u00bc \u00bd \u00d8 \u00d2 \u00be \u00da \u00bc \u00d6 \u00d3\u00d7\u00b4\u00d9 \u00b5 \u00d6 \u00d7 \u00d2\u00b4\u00d9 \u00b5 \u00bc \u00d6 \u00be \u00bf \u00bc (28", "formula_coordinates": [18.0, 179.16, 418.89, 374.32, 80.76]}, {"formula_id": "formula_23", "formula_text": "\u00dc \u00be \u2022 \u00dd \u00be \u00b4\u00de \u00de \u00bc \u00b5 \u00be \u00d6 \u00be \u00bc", "formula_coordinates": [19.0, 252.12, 197.91, 107.16, 19.08]}, {"formula_id": "formula_24", "formula_text": "\u00bc \u00d6 \u00bc \u00bc\u00b5.", "formula_coordinates": [19.0, 66.84, 297.03, 51.81, 8.76]}, {"formula_id": "formula_26", "formula_text": "\u00c8 \u2022 \u00d9\u00bd \u00bc (33) \u00c8 \u00d9\u00be \u00bc (34) \u00cc \u00c9 \u00da \u00bc (35)", "formula_coordinates": [21.0, 279.84, 102.33, 273.64, 49.32]}, {"formula_id": "formula_27", "formula_text": "\u00d6 \u00d7 \u00d2 \u00d3\u00d7\u00b4\u00d9 \u00bd \u2022\u00d9 \u00be \u00be \u00b5 \u00d7 \u00d2\u00b4\u00d9 \u00bd \u00d9 \u00be \u00be \u2022 \u00b5 \u00d6 \u00d7 \u00d2 \u00d7 \u00d2\u00b4\u00d9 \u00bd \u2022\u00d9 \u00be \u00be \u00b5 \u00d7 \u00d2\u00b4\u00d9 \u00bd \u00d9 \u00be \u00be \u2022 \u00b5 \u00d6 \u00d8 \u00d2 \u00da \u00d7 \u00d2\u00b4\u00d9 \u00bd \u00d9 \u00be \u00be \u00b5 \u00d7 \u00d2\u00b4\u00d9 \u00bd \u00d9 \u00be \u00be \u2022 \u00b5 \u00bd \u00cc (36", "formula_coordinates": [21.0, 191.76, 180.99, 357.57, 27.9]}, {"formula_id": "formula_28", "formula_text": ")", "formula_coordinates": [21.0, 549.33, 191.95, 4.15, 8.97]}], "doi": ""}