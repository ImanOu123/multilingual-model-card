{"title": "Separating Reflective and Fluorescent Components of an Image", "authors": "Cherry Zhang; Imari Sato", "pub_date": "", "abstract": "Traditionally researchers tend to exclude fluorescence from color appearance algorithms in computer vision and image processing because of its complexity. In reality, fluorescence is a very common phenomenon observed in many objects, from gems and corals, to different kinds of writing paper, and to our clothes. In this paper, we provide detailed theories of fluorescence phenomenon. In particular, we show that the color appearance of fluorescence is unaffected by illumination in which it differs from ordinary reflectance. Moreover, we show that the color appearance of objects with reflective and fluorescent components can be represented as a linear combination of the two components. A linear model allows us to separate the two components using images taken under two unknown illuminants using independent component analysis(ICA). The effectiveness of the proposed method is demonstrated using digital images of various fluorescent objects.", "sections": [{"heading": "Introduction", "text": "In the field of computer vision, recognizing objects and patterns by their color has always been a difficult problem because the color appearance of objects varies dramatically with surrounding illumination. Researchers in computational color constancy proposed many algorithms and models to discount the effect of illumination and recover the true color of objects [1,8,4]. Researchers in image reproduction and realistic rendering strive to accurately predict the color of objects under arbitrary illuminants [11]. While the algorithms and techniques compute color appearance differently, they share one common assumption: none of the objects in the scene exhibit fluorescence. In reality, fluorescence is a very common phenomenon observed in many objects, from gems and corals, to different kinds of writing paper, and to our clothes(Figure 1). Therefore, computer vision techniques or image synthesis algorithms concerned with exact object color must take fluorescence into account.\nBy experimentation, we discovered that a composite object with both ordinary reflective and fluorescent component has the color appearance that is the sum of the two components interact with illuminants differently. To handle the two components correctly, it is necessary to separate them first. This motivates us to develop a method for separating fluorescence and reflectance. In essence, if we assume an ordinary color camera has narrowband RGB responses, we can show that the intensity of a pixel p c on the captured image can be expressed as a linear contribution that represent how they affect the color appearance of these components. Since we do not know the illumination under which p is taken, we need to solve for R and F from the only known variable p. To make this hard problem solvable, we assume that reflective and fluorescent components seen in an image are statistically independent. The assumption is reasonable because in the absence of image interpretation, the spacial distribution of fluorescent component is uncorrelated with the spatial distribution of the reflective component. Based on the linear contribution model, we show that given p for two images taken under different illuminants, R and F can be effectively recovered using independent component analysis (ICA).\nThe contributions of our paper are\n\u2022 providing a theory of fluorescent phenomenon,\n\u2022 showing that the color of fluorescent component is not affected by the color of its illuminant, in which it differs from that of ordinary reflective component, and\n\u2022 proposing a method for separating reflective and fluorescent components using only two images taken under different illuminants.\nAs far as we know, this is the first attempt to separate reflective and fluorescent components of an image taken under unknown illumination. The rest of the paper is structured as follows. Section 2 summarizes earlier research in color constancy, color appearance and rendering algorithms for fluorescent surfaces, as well as research in image separation. Section 3 presents the theories and experimental results explaining how fluorescent surfaces interact with illuminants. Our algorithm and the results for separating ordinary reflective and fluorescent components of an image are presented in Section 4 and 5. In the conclusion, we discuss issues and future directions of our research.", "publication_ref": ["b0", "b7", "b3", "b10"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Related Work", "text": "The color appearance of non-fluorescent surfaces has always been the main focus of color-related computer vision algorithms. For example, in computational color constancy, researchers attempt to recover the \"true color\" of objects under a reference illuminant [1,8]. The true color is then modified to predict the appearance of objects under other illuminants. Barnard et al. studied and compared existing color constancy algorithms by evaluating their performance with a large set of test images [4]. Some of the test images contain fluorescent objects, but all of the evaluated color constancy algorithms treat them as ordinary objects.\nLater on, researchers realized that assuming all objects are non-fluorescent greatly limits on the accuracy of color algorithms, because many objects around us exhibit fluorescence. In Johnson and Fairchild's research, they provided brief explanations of fluorescence, and extended spectral rendering algorithms to take fluorescence into account [11]. Hullin et al. proposed new ways to model and render fluorescent objects by acquiring their bispectral bidirectional reflectance and reradiation distribution functions (BRRDF) and the results showed significant improvement in fluorescent object modeling [9]. Furthermore, Barnard proposed ways to improve color constancy algorithms to include spectral data of several fluorescent materials [3]. Although Barnard solved some problems of including fluorescent objects in color constancy algorithms, his work was mainly based on experimental measurements. His paper did not provide comprehensive models for fluorescent surfaces. In our paper, we extend Barnard's research by providing more detailed theories and accurate models for fluorescence.\nTo accurately predict the appearance of composite objects with both reflective and fluorescent components, it is important to separate the two components. Research in natural science [15] shows necessary procedures for measuring color of fluorescent materials in the spectral domain using optical devices. For example, Haneishi and Kamimura used spectral data taken under multiple light sources under known spectral distributions, for characterizing fluorescent samples [12]. Alterman et al. separated the appearance of each fluorescent dye from a mixture by unmixing multiplexed images [2]. Nakajima and Tominaga used statistics of fluorescent materials for estimating fluorescent components of a real material using multi-spectral images seen under sunlight [13]. In the early stage of our research, we successfully separated the components of fluorescent sheets using spectral data captured by a spectrometer. The successful results motivated us to develop a more practical system for doing the separation using images taken by an ordinary digital camera.\nThe computer vision community has several methods for separating components of an image [14,17]. Some algorithms separate specular reflections from diffuse reflections. Some algorithms separate non-correlated components of images. For example, Farid and Adelson proposed a method for separating a painting from the reflection of an observer on the glass in front of the painting, using two images [7]. We found that Farid and Adelson's problem closely resembles the fluorescence-separation problem we are interested in. Therefore, a similar approach based on independent component analysis is used in our case for separating reflective and fluorescent components.  let (UV) range from 200 nm to 380 nm, and re-emit visible light in 380 nm to 720 nm. Some material absorbs shortwavelength visible light and re-emit longer-wavelength visible light. The first type of special UV lights are not required to observe fluorescence because many natural lighting conditions, such as daylight and cool fluorescent light, have strong UV components (Figure 2). After decades of studies, researchers can explain fluorescence phenomenon and two unique properties of fluorescent materials with concepts in quantum theory [6,15]: fluorescent material always emits light at longer wavelength than the absorbed light, and the emission spectra of each fluorescent material always have the same frequency distribution (e.g. shape) regardless of the spectra of incident light.", "publication_ref": ["b0", "b7", "b3", "b10", "b8", "b2", "b14", "b11", "b1", "b12", "b13", "b16", "b6", "b5", "b14"], "figure_ref": ["fig_3"], "table_ref": []}, {"heading": "Properties of Fluorescent Surfaces", "text": "Due to their unique properties, the appearance of fluorescent surfaces must be computed differently than reflective surfaces. The color of a reflective surface depends only on the illuminant and its reflectance. For example, the observed spectrum of an ordinary reflective surface with reflectance R under illuminant I is\nP (\u03bb) = I(\u03bb)R(\u03bb),\nwhere I(\u03bb) is the intensity of the illuminant at wavelength \u03bb and R(\u03bb) is the reflectance of the material at wavelength \u03bb. If we capture the object with a charge-coupled device (CCD) camera with three channels R,G and B, then the color of each pixel for each channel is\np = c(\u03bb)I(\u03bb)R(\u03bb) d\u03bb,(1)\nintegrated over visible spectrum (380 nm to 720 nm), wher\u0113 c(\u03bb) = {r(\u03bb),\u1e21(\u03bb),b(\u03bb)} are the camera response curves for each channel [16]. For a pure fluorescent surface, the observed spectrum depends on the illuminant, the material's excitation spectrum and emission spectrum. Excitation spectrum shows how much energy from the illuminant is absorbed at each wavelength. Thus it is a function of the wavelength of the illuminant. For each wavelength in an excitation spectrum, there is a corresponding emission spectrum that shows the frequency distribution and intensity of the emitted light. Usually the emission spectrum is a function of wavelength covering the visible range. The frequency distribution of all emission spectra is constant, but the intensity varies. Figure 3(Top) shows the measured emission spectra of a red-orange fluorescent sheet. Each colored spectrum corresponds to the illuminant at a different wavelength, and have the same frequency distribution as one another. Figure 3(Middle) shows the normalized 1 excitation and emission spectra of the sheet. From the emission spectrum we can see that the sheet appears reddish orange when it is illuminated with light in the range of 380 nm to 650 nm.\nTo obtain the observed spectrum of a pure fluorescent surface, we must consider the sum of the contribution from illuminant, excitation, and emission. Suppose the illuminant is I and its intensity at wavelength \u03bb i is I(\u03bb i ). Let Ex and Em represent the normalized excitation and emission spectrum, respectively. Then the observed spectrum, P (\u03bb, \u03bb i ), resulting from the illuminant at \u03bb i is\nP (\u03bb, \u03bb i ) = I(\u03bb i )Ex (\u03bb i )Em(\u03bb),\nwhere Ex (\u03bb i ) \u2261 Ex(\u03bbi) Ex(\u03bbi) d\u03bbi is the relative intensity of the excitation caused by the illuminant at wavelength \u03bb i . Since I(\u03bb i )Ex (\u03bb i ) is a scalar, all P (\u03bb, \u03bb i )'s have the same shape as Em(\u03bb). Considering illumination at all wavelengths, the overall observed spectrum is computed by summing up P (\u03bb, \u03bb i )'s for all wavelength \u03bb i . i.e.\nP (\u03bb) = I(\u03bb i )Ex (\u03bb i ) d\u03bb i Em(\u03bb).\nThe range of \u03bb i depends on the illuminant, and the range of \u03bb is the range of the observed light we wish to measure. Referring back to the example of red-orange fluorescent sheet, Figure 3(Top) is the plot for P (\u03bb, \u03bb i )'s.\nIf we capture the pure fluorescent surface with a CCD camera, the color of the pixel for each channel is\np = I(\u03bb i )Ex (\u03bb i ) d\u03bb i c(\u03bb)Em(\u03bb) d\u03bb.(2)\nMany objects we see every day are neither pure reflective nor pure fluorescent; they are composites of ordinary reflective and fluorescent components. Clearly, an object's reflective and fluorescent components behave significantly differently. In the next section, we will show a unique property of fluorescent component, and present our findings on how it interacts with illuminants differently from reflective component.", "publication_ref": ["b15"], "figure_ref": ["fig_4", "fig_4", "fig_4"], "table_ref": []}, {"heading": "Constant Chromaticity", "text": "The most intriguing property of fluorescence we discovered is that it has constant color, or chromaticity, under most illuminants. The proof of this property follows naturally from Equation 2 in the previous section.\nBy replacing the camera response functionsc(\u03bb), we can compute the CIE tristimulus values of the fluorescent mate-  \nX = I(\u03bb i )Ex (\u03bb i ) d\u03bb i x(\u03bb)Em(\u03bb) d\u03bb, (3) Y = I(\u03bb i )Ex (\u03bb i ) d\u03bb i \u0233(\u03bb)Em(\u03bb) d\u03bb, (4) Z = I(\u03bb i )Ex (\u03bb i ) d\u03bb i z(\u03bb)Em(\u03bb) d\u03bb,(5)\nwherex(\u03bb),\u0233(\u03bb),z(\u03bb) are the CIE color matching functions. \u03bb is integrated over visible light range 380 nm to 720 nm. Let\nX 0 = x(\u03bb)Em(\u03bb) d\u03bb, Y 0 = \u0233(\u03bb)Em(\u03bb) d\u03bb, Z 0 = z(\u03bb)Em(\u03bb) d\u03bb\nbe the reference tristimulus values of the normalized emission spectrum Em. Substituting X 0 , Y 0 and Z 0 into Equations 3 to 5, we have X = kX 0 , Y = kY 0 , and Z = kZ 0 with k = I(\u03bb i )Ex (\u03bb i ) d\u03bb i . Note that k is a scalar and its value depends on the intensity of the illuminant and the excitation spectrum of the material. Now define reference chromaticity as\nx 0 = X 0 X 0 + Y 0 + Z 0 and y 0 = Y 0 X 0 + Y 0 + Z 0 .\nThen the chromaticity of the object under an arbitrary illuminant becomes\nx = X X + Y + Z = kX 0 kX 0 + kY 0 + kZ 0 = x 0 .\nSimilarly, y = y 0 . Thus the chromaticity of the fluorescent material is independent of both the illuminant and excitation spectrum; it only depends on the emission spectrum. We verified our findings with carefully designed experiments. The results are shown in APPENDIX. In summary, the color appearance of reflective component varies with illumination dramatically, whereas the appearance of fluorescent component stays constant except for intensity. In the next section, we propose a method for separating ordinary reflective and fluorescent components, in which the only inputs required are two images of objects taken under two illuminants.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Separating Reflective and Fluorescent Components of an Image", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "The Model", "text": "When we take an image of composite objects with both ordinary reflective and fluorescent components using a CCD camera, the color of each pixel p on the final image for each channel c = {R, G, B} is the sum of the pixel color for reflective component p O and fluorescent component p F . i.e. p = p O + p F . Substitute in Equation 1 and 2 for p O and p F , we have\np = c(\u03bb)I(\u03bb)R(\u03bb) d\u03bb + I(\u03bb i )Ex (\u03bb i ) d\u03bb i c(\u03bb)Em(\u03bb) d\u03bb (6)\nWe assume that the responses of a CCD camera have fairly narrow bandwidth, that is, light goes through the camera at a particular wavelength to reach the sensor [5]. The narrowband assumption is often used in color constancy algorithms, so we can simplify Equation 6 as\np n =c(\u03bb n )I(\u03bb n )R(\u03bb n ) + I(\u03bb i )Ex (\u03bb i ) d\u03bb i c(\u03bb n )Em(\u03bb n ), (7)\nwhere \u03bb n for n = {R, G, B} is set to be the wavelength of each R,G,B channel of the camera. Now for each channel, p is represented as a linear combination of the reflective component R and fluorescent component Em. Both R and Em are unknown to us. The spectral distribution of the illuminant under which p is taken, is also unknown. To tackle the problem of blindly separating R and Em from the only known variable p, we make the assumption that the two components are independent. This assumption is reasonable since in our case, the spatial distribution of fluorescent component provides no prediction of the spacial distribution of the ordinary reflective components; we expect no correlation between images of the two components. Based on this assumption and Equation 7, we solve the blind separation problem by applying independent component analysis (ICA) [10] to images of the objects taken under different illuminants.\nSince ICA requires the number of measurements to be greater than or equal to the number of independent components, we take images p 1 and p 2 of a fluorescent object under two distinct illuminants I 1 and I 2 . Formulate the problem based on Equation 7for each n = {R, G, B} channel as\np j 1 (\u03bb n ) p j 2 (\u03bb n ) = r 1 (\u03bb n ) f 1 (\u03bb n ) r 2 (\u03bb n ) f 2 (\u03bb n ) R j (\u03bb n ) Em j (\u03bb n ) ,\nwhere p j i is the j th pixel value for i th illumination, R j and Em j are the ordinary reflectance and fluorescence at the j th pixel, r i (\u03bb n ) =c(\u03bb n )I i (\u03bb n ), and f i (\u03bb n ) = c(\u03bb n ) I i (\u03bb i )Ex (\u03bb i ) d\u03bb i . Let P n = M n S n be the short form of the matrix equation above. We call P n the input matrix, M n the mixing matrix, and S n the signal matrix. If we input P n to ICA 2 , ICA will first estimate M n , and S n is computed as M \u22121 n P n . To obtain the image with only reflective component, we combine R j (\u03bb n ) in S n for n = {R, G, B}. Similarly to obtain the image with only fluorescent component, we combine Em j (\u03bb n ) in S n .", "publication_ref": ["b4", "b9"], "figure_ref": [], "table_ref": []}, {"heading": "Ambiguities of ICA", "text": "Even though ICA works well for solving our problem, it imposes two ambiguities. First, we cannot determine the \"order\" of the independent components R and Em. In other words, we do not know which resulting component is for fluorescence and which is for reflectance. The reason is that both mixing matrix and signal matrix are unknown; for the same set of data P n , ICA could recover the pair M n and S n as either  \nM n = r 1 f 1 r 2 f 2 , S n = R j Em j ,\nM n = r 2 f 2 r 1 f 1 , S n = Em j R j .\nThe second ambiguity is \"scaling\". ICA recovers the mixing matrix within a scale factor of the true mixing matrix.\nIn other words, we cannot compute the absolute intensity of the pixels for each component. Again, the reason is that both M n and S n are unknown; any multipliers in M n can be canceled out by dividing the same scalars in S n . i.e.\nr 1 f 1 r 2 f 2 R j Em j = r 1 /\u03b1 f 1 /\u03b2 r 2 /\u03b1 f 2 /\u03b2 \u03b1R j \u03b2Em j", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Solving the \"ordering\" ambiguity", "text": "We solve the ordering ambiguity by using the unique property of fluorescent component. Let x j i and y j i represent the x,y-chromaticity of the j th pixel in the i th image. Compute the chromaticity difference at the j th pixel between two in-put images as\nd j = (x j 1 \u2212 x j 2 ) 2 + (y j 1 \u2212 y j 2 ) 2 .\nIn Section 3, we showed that d j is very small if j shows the brightness of fluorescent component. Let s j 1 and s j 2 be the recovered intensities at the j th pixel in the two images computed by ICA. Normalize them as\ns j 1 = (s j 1 ) 2 i (s i 1 ) 2 , s j 2 = (s j 2 ) 2 i (s i 2 ) 2 .\nThen multiply the relative intensities by the chromaticity difference d j , and sum over all pixels\nt 1 = j s j 1 d j , t 2 = j s j 2 d j .\nIf t 1 is smaller than t 2 , then the image represented by s 1 is the fluorescent component. Otherwise the image represented by s 1 is the fluorescent component. Intuitively, if the j th pixel contains the fluorescent component, s j will be big but d j is small. Therefore, the overall t value for image with fluorescent component is always smaller. This technique assumes that the objects have much stronger fluorescent component than ordinary reflective component.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Solving the \"scaling\" problem", "text": "In the mixing matrix, the integral part of scalar f 1 (\u03bb n ) = c(\u03bb n ) I i (\u03bb i )Ex (\u03bb i ) d\u03bb i depends only on the spectral distribution of the illuminant and excitation of the fluorescent component and thus must be the same among all RGB channels. This fact can be used for solving the scaling ambiguity of fluorescent component ifc(\u03bb n ) are known. For each n = {R, G, B}, we scale the computed s n by f 1 /c(\u03bb n ). i.e.\nEm j (\u03bb n ) = s n * c(\u03bb n )/f 1 .\nEm j (\u03bb n )'s estimate the relative intensities in RGB channels and provide the necessary color balance in the final image for fluorescent component. While in theory, this solution works for a scene consists of one type of fluorescent surface where f 1 is uniform for the entire image, it works fine for scenes with multiple types of fluorescent surfaces in our experiments shown in Figure 6. In the case of multiple types of fluorescent surfaces, we may have better solutions, and we will investigate the issue more in the future.\nTo achieve correct color balance for the reflective components, we look for or include a reference patch with white reflectance in the input images. The recovered images for RGB channels are combined in a way such that the white patch remains white in the reflectance-only image. If we have a material of known fluorescence such as white paper with bluish fluorescence, we can utilize the known fluorescence for achieving correct color balance of fluorescent component.", "publication_ref": [], "figure_ref": ["fig_9"], "table_ref": []}, {"heading": "Results and Analysis", "text": "We tested our method with images taken with an ordinary CCD camera. The first scene is an image made with color sheets. The sheets contain different amount of fluorescence and reflectance (Figure 5 Top). The top two flowers are made of fluorescent sheets that appear bright yellow and bright red-orange under white light. The flower in the middle and the leaves are made of dark red and dark green non-fluorescent sheets. The background is made of nonreflective light purple sheet.\nWe first recovered fluorescent and reflective components using images taken under a green illuminant and a pink illuminant (Figure 5 Middle). The recovered fluorescent component (Figure 6 Left) shows that the color of fluorescent component of the yellow fluorescent sheet is in fact green. In Section 3, we showed the measured emission spectrum of the sheet (Figure 3 Bottom), which suggests that the color of the fluorescent component is green. Furthermore, we took images of the fluorescent flowers under UV light, which provided \"ground truth\" for the color of the fluorescent components (Figure 5 Bottom). Our recovered appearance agrees with experimental results, as well as the \"ground truth\". The dark red and dark green sheets used in making the scene have ordinary reflectance only since the color of the middle flower and the leaves in the recovered reflective component (Figure 6 Right) is the same as the color seen under white light. It is also worth noting that the yellow fluorescent flower appears to be orange in the recovered image for reflective component. Combining the orange color with the green color in the fluorescent component gives the flower its final yellow appearance. Moreover, the red-orange fluorescent sheet has much stronger fluorescence compare to the yellow fluorescent sheet. Therefore, its color appearance is almost all contributed by the fluorescent component.\nOur method is effective on scenes with complex color patterns, and scenes consist of objects as well.      ", "publication_ref": [], "figure_ref": ["fig_8", "fig_8", "fig_9", "fig_4", "fig_8", "fig_9"], "table_ref": []}, {"heading": "Discussions and Conclusions", "text": "We explained the difference in appearance between fluorescence and reflectance and proposed a method for separating fluorescent and reflective components of objects using images captured under two illuminants. Three issues are worth further attention. First, the intensity of fluorescence varies proportionally to the illuminant; we may be able to use this property to infer information about the illuminant. Secondly, we assume that for an image, there is no correlation between the spatial distributions of reflective and fluorescent components. In the future, we will explore   statistical evidence to support the assumption. Thirdly, the proposed separation method assumes that a CCD camera has narrowband responses. Even though this assumption is made by many color constancy algorithms, it remains controversial. It is worth studying the effectiveness of the proposed method without making the narrowband assumption.\nOverall, this paper presented ideas pioneering a new direction of research in computer vision and image processing.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "APPENDIX: Appearance of Ordinary Reflectance and Fluorescence under Various Illuminants", "text": "The changes in color of eight fluorescent and nonfluorescent surfaces (Figure 9) were examined under standard daylight and indoor illumination. Figure 10 shows the spectra of the illuminant, which cover a wide range of illumination conditions. The x,y-chromaticity vs illuminants plots (Figure 11) clearly show that surfaces with strong a fluorescent component are more prone to illumination changes. The x-chromaticity of fluorescent yellow sheet varies more because it contains a stronger reflective component compare to fluorescent red-orange sheet. The appearance of surfaces with only reflective component varies greatly with illumination.", "publication_ref": [], "figure_ref": ["fig_16", "fig_0", "fig_0"], "table_ref": []}], "references": [{"ref_id": "b0", "title": "An overview of color constancy algorithms", "journal": "Journal of Pattern Recognition Research", "year": "2006", "authors": "V Agarwal; B R Abidi"}, {"ref_id": "b1", "title": "Multiplexed fluorescence unmixing", "journal": "", "year": "2010", "authors": "M Alterman; Y Schechner; A Weiss"}, {"ref_id": "b2", "title": "Color constancy with fluorescent surfaces", "journal": "", "year": "1999", "authors": "K Barnard"}, {"ref_id": "b3", "title": "A comparison of computational color constancy algorithms", "journal": "IEEE Transactions on Image Processing", "year": "2002", "authors": "K Barnard; V Cardei; B Funt"}, {"ref_id": "b4", "title": "Color Constancy", "journal": "Wiley Publishing", "year": "2007", "authors": "M Ebner"}, {"ref_id": "b5", "title": "Spectral colour prediction model for a transparent fluorescent ink on paper", "journal": "", "year": "1998", "authors": "P Emmel; R D Hersch"}, {"ref_id": "b6", "title": "Separating reflections and lighting using independent components analysis", "journal": "", "year": "1999", "authors": "H Farid; E Adelson"}, {"ref_id": "b7", "title": "A novel algorithm for color constancy", "journal": "International Journal of Computer Vision", "year": "1990", "authors": "D A Forsyth"}, {"ref_id": "b8", "title": "Acquisition and analysis of bispectral bidirectional reflectance and reradiation distribution functions", "journal": "ACM Trans. Graph", "year": "2010-07", "authors": "M B Hullin; J Hanika; B Ajdin; H.-P Seidel; J Kautz; H P A Lensch"}, {"ref_id": "b9", "title": "Independent component analysis: Algorithms and applications", "journal": "The Official Journal of the International Neural Network Society", "year": "2000", "authors": "A Hyv\u00e4rinen; E Oja"}, {"ref_id": "b10", "title": "Full-spectral color calculations in realistic image synthesis", "journal": "IEEE Computer Graphics and Applications", "year": "1999", "authors": "G M Johnson; M D Fairchild"}, {"ref_id": "b11", "title": "Modeling and estimation spectral reflectance of fluorescent object", "journal": "Japan Hardcopy", "year": "2002", "authors": "H Kaneishi; R Kamimura"}, {"ref_id": "b12", "title": "Spectral reflectance estimation of fluorescent materials by using camera images", "journal": "", "year": "2010", "authors": "T Nakajima; S Tominaga"}, {"ref_id": "b13", "title": "Removal of specularities using color and polarization", "journal": "", "year": "1993", "authors": "S Nayar; X.-S Fang; T Boult"}, {"ref_id": "b14", "title": "Introduction to measurement of color of fluorescent materials", "journal": "Analytica Chimica Acta", "year": "1999", "authors": "A Springsteen"}, {"ref_id": "b15", "title": "Spectral image processing by a multi-channel camera", "journal": "", "year": "1999", "authors": "S Tominaga; E Takahashi"}, {"ref_id": "b16", "title": "Imagebased skin color and texture analysis/synthesis by extracting hemoglobin and melanin information in the skin. SIG-GRAPH 03", "journal": "ACM", "year": "2003", "authors": "N Tsumura; N Ojima; K Sato; M Shiraishi; H Shimizu; H Nabeshima; S Akazaki; K Hori; Y Miyake"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 .1Figure 1. Examples of fluorescent objects: gems and corals, clothes, banana peel and fluorescent sheets.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "p c = a c R c + b c F c , where c = {R, G, B}, R c and F c represent ordinary reflective and fluorescent components at p c . a c and b c are coefficients computed from camera responses and illumination", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "3. 11. FluorescenceWe start by looking at what is fluorescence. Most typical fluorescent material absorbs light in the near ultravio-", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 2 .2Figure 2. Natural daylight and fluorescent lamp both have strong UV and short-wavelength components.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 3 .3Figure 3. Measured excitation and emission spectra of fluorescent sheets. Top: Emission spectra for light source at different wavelength. Middle: Excitation(dotted) and emission(solid) spectra for red-orange sheet. Bottom: Excitation(dotted) and emission(solid) spectra for yellow sheet.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Figure 4 (4a) shows the overall change in the observed spectrum of such object. Each colored line represents the observed spectrum corresponding to the illuminant at a particular wavelength. When the wavelength of the illuminant falls in the UV range, or the high-energy range of the object's excitation spectrum, fluorescent component dominates, thus we observe fluorescence only (Figure 4(b)). When the wavelength of the illuminant falls in the visible light range, we observe mixture of fluorescence and reflectance (Figure 4(c)). When the illuminant is in the low-energy range of visible light and falls outside of the excitation spectrum, fluorescence diminishes and we only observe reflectance (Figure 4(d)).", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "(a) Measured spectra of the red-orange fluorescent sheet under illuminations at different wavelength. (b) Illumination in the UV range: observe fluorescence only. (c) Illumination in visible range: observe both fluorescence and reflectance. (d) Illumination in visible range and outside of excitation range: observe reflectance only.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "Figure 4 .4Figure 4. Observed spectra of fluorescent sheet containing both reflective and fluorescent components.", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "Figure 5 .5Figure 5. Top: colored sheets under white illuminant. Middle: colored sheets under green and pink illuminants. Bottom: fluorescent sheets seen under UV light.", "figure_data": ""}, {"figure_label": "6", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "Figure 6 .6Figure 6. Recovered fluorescent and reflective components using images taken under green and pink illuminants", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_10", "figure_caption": "Figure 7 consists of two fluorescent sheets on top of a nonfluorescent background image with complex color patterns. Our method succeeded in identifying the green and redorange color of the fluorescent sheets. The recovered image for fluorescent component (Figure 7(b) Left) does not show the background image at all, which clearly demonstrates the correctness and effectiveness of our method.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_11", "figure_caption": "Figure 8 are the recovered results for a scene consists of objects. The fluorescent sticks and non-fluorescent jar are separated into two images. The color of the sticks (Figure 8(b)) matches with the ground truth (Figure 8(c)).", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_12", "figure_caption": "(a) Ground truth (seen under white light) and input images. (b) Recovered images.", "figure_data": ""}, {"figure_label": "7", "figure_type": "figure", "figure_id": "fig_13", "figure_caption": "Figure 7 .7Figure 7. Fluorescent objects on top of reflective image with complex color patterns.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_14", "figure_caption": "(a) Ground truth (seen under white light) and input images. (b) Recovered images. (c) Fluorescent sticks seen under UV light.", "figure_data": ""}, {"figure_label": "8", "figure_type": "figure", "figure_id": "fig_15", "figure_caption": "Figure 8 .8Figure 8. Examples of real fluorescent objects.", "figure_data": ""}, {"figure_label": "9", "figure_type": "figure", "figure_id": "fig_16", "figure_caption": "Figure 9 .9Figure 9. Surfaces with ordinary reflectance and fluorescence.", "figure_data": ""}, {"figure_label": "10", "figure_type": "figure", "figure_id": "fig_17", "figure_caption": "Figure 10 .10Figure 10. Illuminants used in the experiments.", "figure_data": ""}, {"figure_label": "11", "figure_type": "figure", "figure_id": "fig_18", "figure_caption": "Figure 11 .11Figure 11. x-chromaticity(top) and y-chromaticity(bottom) of fluorescent and ordinary reflective surfaces under various illuminants. Left: fluorescent surfaces vs illuminants. Right: reflective surfaces vs. illuminants.", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "P (\u03bb) = I(\u03bb)R(\u03bb),", "formula_coordinates": [3.0, 119.62, 475.24, 77.31, 8.74]}, {"formula_id": "formula_1", "formula_text": "p = c(\u03bb)I(\u03bb)R(\u03bb) d\u03bb,(1)", "formula_coordinates": [3.0, 106.53, 570.73, 179.83, 8.96]}, {"formula_id": "formula_2", "formula_text": "P (\u03bb, \u03bb i ) = I(\u03bb i )Ex (\u03bb i )Em(\u03bb),", "formula_coordinates": [4.0, 92.78, 99.82, 150.91, 9.65]}, {"formula_id": "formula_3", "formula_text": "P (\u03bb) = I(\u03bb i )Ex (\u03bb i ) d\u03bb i Em(\u03bb).", "formula_coordinates": [4.0, 74.66, 218.31, 167.23, 9.65]}, {"formula_id": "formula_4", "formula_text": "p = I(\u03bb i )Ex (\u03bb i ) d\u03bb i c(\u03bb)Em(\u03bb) d\u03bb.(2)", "formula_coordinates": [4.0, 61.57, 339.85, 224.79, 9.65]}, {"formula_id": "formula_5", "formula_text": "X = I(\u03bb i )Ex (\u03bb i ) d\u03bb i x(\u03bb)Em(\u03bb) d\u03bb, (3) Y = I(\u03bb i )Ex (\u03bb i ) d\u03bb i \u0233(\u03bb)Em(\u03bb) d\u03bb, (4) Z = I(\u03bb i )Ex (\u03bb i ) d\u03bb i z(\u03bb)Em(\u03bb) d\u03bb,(5)", "formula_coordinates": [4.0, 334.91, 511.51, 210.2, 61.9]}, {"formula_id": "formula_6", "formula_text": "X 0 = x(\u03bb)Em(\u03bb) d\u03bb, Y 0 = \u0233(\u03bb)Em(\u03bb) d\u03bb, Z 0 = z(\u03bb)Em(\u03bb) d\u03bb", "formula_coordinates": [4.0, 375.54, 643.37, 102.89, 61.9]}, {"formula_id": "formula_7", "formula_text": "x 0 = X 0 X 0 + Y 0 + Z 0 and y 0 = Y 0 X 0 + Y 0 + Z 0 .", "formula_coordinates": [5.0, 62.07, 166.54, 192.42, 23.22]}, {"formula_id": "formula_8", "formula_text": "x = X X + Y + Z = kX 0 kX 0 + kY 0 + kZ 0 = x 0 .", "formula_coordinates": [5.0, 64.65, 228.95, 187.26, 23.22]}, {"formula_id": "formula_9", "formula_text": "p = c(\u03bb)I(\u03bb)R(\u03bb) d\u03bb + I(\u03bb i )Ex (\u03bb i ) d\u03bb i c(\u03bb)Em(\u03bb) d\u03bb (6)", "formula_coordinates": [5.0, 85.52, 565.77, 200.84, 52.36]}, {"formula_id": "formula_10", "formula_text": "p n =c(\u03bb n )I(\u03bb n )R(\u03bb n ) + I(\u03bb i )Ex (\u03bb i ) d\u03bb i c(\u03bb n )Em(\u03bb n ), (7)", "formula_coordinates": [5.0, 112.15, 79.64, 432.96, 634.2]}, {"formula_id": "formula_11", "formula_text": "p j 1 (\u03bb n ) p j 2 (\u03bb n ) = r 1 (\u03bb n ) f 1 (\u03bb n ) r 2 (\u03bb n ) f 2 (\u03bb n ) R j (\u03bb n ) Em j (\u03bb n ) ,", "formula_coordinates": [5.0, 329.54, 381.74, 205.13, 26.55]}, {"formula_id": "formula_12", "formula_text": "M n = r 1 f 1 r 2 f 2 , S n = R j Em j ,", "formula_coordinates": [5.0, 340.12, 672.53, 153.81, 23.18]}, {"formula_id": "formula_13", "formula_text": "M n = r 2 f 2 r 1 f 1 , S n = Em j R j .", "formula_coordinates": [6.0, 81.37, 487.69, 153.81, 23.18]}, {"formula_id": "formula_14", "formula_text": "r 1 f 1 r 2 f 2 R j Em j = r 1 /\u03b1 f 1 /\u03b2 r 2 /\u03b1 f 2 /\u03b2 \u03b1R j \u03b2Em j", "formula_coordinates": [6.0, 60.35, 605.0, 204.13, 23.18]}, {"formula_id": "formula_15", "formula_text": "d j = (x j 1 \u2212 x j 2 ) 2 + (y j 1 \u2212 y j 2 ) 2 .", "formula_coordinates": [6.0, 349.24, 99.49, 135.57, 13.56]}, {"formula_id": "formula_16", "formula_text": "s j 1 = (s j 1 ) 2 i (s i 1 ) 2 , s j 2 = (s j 2 ) 2 i (s i 2 ) 2 .", "formula_coordinates": [6.0, 350.63, 182.3, 132.79, 27.58]}, {"formula_id": "formula_17", "formula_text": "t 1 = j s j 1 d j , t 2 = j s j 2 d j .", "formula_coordinates": [6.0, 353.05, 252.1, 127.95, 23.4]}, {"formula_id": "formula_18", "formula_text": "Em j (\u03bb n ) = s n * c(\u03bb n )/f 1 .", "formula_coordinates": [6.0, 359.11, 521.77, 115.83, 13.14]}], "doi": ""}