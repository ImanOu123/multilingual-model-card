{"title": "A Theory of Multiclass Boosting", "authors": "Indraneel Mukherjee; Robert E Schapire", "pub_date": "", "abstract": "Boosting combines weak classifiers to form highly accurate predictors. Although the case of binary classification is well understood, in the multiclass setting, the \"correct\" requirements on the weak classifier, or the notion of the most efficient boosting algorithms are missing. In this paper, we create a broad and general framework, within which we make precise and identify the optimal requirements on the weak-classifier, as well as design the most effective, in a certain sense, boosting algorithms that assume such requirements.", "sections": [{"heading": "Introduction", "text": "Boosting (Schapire and Freund, 2012) refers to a general technique of combining rules of thumb, or weak classifiers, to form highly accurate combined classifiers. Minimal demands are placed on the weak classifiers, so that a variety of learning algorithms, also called weak-learners, can be employed to discover these simple rules, making the algorithm widely applicable. The theory of boosting is well-developed for the case of binary classification. In particular, the exact requirements on the weak classifiers in this setting are known: any algorithm that predicts better than random on any distribution over the training set is said to satisfy the weak learning assumption. Further, boosting algorithms that minimize loss as efficiently as possible have been designed. Specifically, it is known that the Boost-by-majority (Freund, 1995) algorithm is optimal in a certain sense, and that AdaBoost (Freund and Schapire, 1997) is a practical approximation.\nSuch an understanding would be desirable in the multiclass setting as well, since many natural classification problems involve more than two labels, for example, recognizing a digit from its image, natural language processing tasks such as part-of-speech tagging, and object recognition in vision. However, for such multiclass problems, a complete theoretical understanding of boosting is lacking. In particular, we do not know the \"correct\" way to define the requirements on the weak classifiers, nor has the notion of optimal boosting been explored in the multiclass setting.\nStraightforward extensions of the binary weak-learning condition to multiclass do not work. Requiring less error than random guessing on every distribution, as in the binary case, turns out to be too weak for boosting to be possible when there are more than two labels. On the other hand, requiring more than 50% accuracy even when the number of labels is much larger than two is too stringent, and simple weak classifiers like decision stumps fail to meet this criterion, even though they often can be combined to produce highly accurate classifiers (Freund and Schapire, 1996a). The most common approaches so far have relied on reductions to binary classification (Allwein et al., 2000), but it is hardly clear that the weak-learning conditions implicitly assumed by such reductions are the most appropriate.\nThe purpose of a weak-learning condition is to clarify the goal of the weak-learner, thus aiding in its design, while providing a specific minimal guarantee on performance that can be exploited by a boosting algorithm. These considerations may significantly impact learning and generalization because knowing the correct weak-learning conditions might allow the use of simpler weak classifiers, which in turn can help prevent overfitting. Furthermore, boosting algorithms that more efficiently and effectively minimize training error may prevent underfitting, which can also be important.\nIn this paper, we create a broad and general framework for studying multiclass boosting that formalizes the interaction between the boosting algorithm and the weak-learner. Unlike much, but not all, of the previous work on multiclass boosting, we focus specifically on the most natural, and perhaps weakest, case in which the weak classifiers are genuine classifiers in the sense of predicting a single multiclass label for each instance. Our new framework allows us to express a range of weak-learning conditions, both new ones and most of the ones that had previously been assumed (often only implicitly). Within this formalism, we can also now finally make precise what is meant by correct weak-learning conditions that are neither too weak nor too strong.\nWe focus particularly on a family of novel weak-learning conditions that have an especially appealing form: like the binary conditions, they require performance that is only slightly better than random guessing, though with respect to performance measures that are more general than ordinary classification error. We introduce a whole family of such conditions since there are many ways of randomly guessing on more than two labels, a key difference between the binary and multiclass settings. Although these conditions impose seemingly mild demands on the weak-learner, we show that each one of them is powerful enough to guarantee boostability, meaning that some combination of the weak classifiers has high accuracy. And while no individual member of the family is necessary for boostability, we also show that the entire family taken together is necessary in the sense that for every boostable learning problem, there exists one member of the family that is satisfied. Thus, we have identified a family of conditions which, as a whole, is necessary and sufficient for multiclass boosting. Moreover, we can combine the entire family into a single weak-learning condition that is necessary and sufficient by taking a kind of union, or logical OR, of all the members. This combined condition can also be expressed in our framework.\nWith this understanding, we are able to characterize previously studied weak-learning conditions. In particular, the condition implicitly used by AdaBoost.MH (Schapire and Singer, 1999), which is based on a one-against-all reduction to binary, turns out to be strictly stronger than necessary for boostability. This also applies to AdaBoost.M1 (Freund and Schapire, 1996a), the most direct generalization of AdaBoost to multiclass, whose conditions can be shown to be equivalent to those of AdaBoost.MH in our setting. On the other hand, the condition implicit to the SAMME algorithm by Zhu et al. (2009) is too weak in the sense that even when the condition is satisfied, no boosting algorithm can guarantee to drive down the training error. Finally, the condition implicit to AdaBoost.MR (Schapire and Singer, 1999;Freund and Schapire, 1996a) (also called AdaBoost.M2) turns out to be exactly necessary and sufficient for boostability.\nEmploying proper weak-learning conditions is important, but we also need boosting algorithms that can exploit these conditions to effectively drive down error. For a given weak-learning condition, the boosting algorithm that drives down training error most efficiently in our framework can be understood as the optimal strategy for playing a certain two-player game. These games are nontrivial to analyze. However, using the powerful machinery of drifting games (Freund and Opper, 2002;Schapire, 2001), we are able to compute the optimal strategy for the games arising out of each weak-learning condition in the family described above. Compared to earlier work, our optimality results hold more generally and also achieve tighter bounds. These optimal strategies have a natural interpretation in terms of random walks, a phenomenon that has been observed in other settings (Abernethy et al., 2008;Freund, 1995).\nWe also analyze the optimal boosting strategy when using the minimal weak learning condition, and this poses additional challenges. Firstly, the minimal weak learning condition has multiple natural formulations-for example, as the union of all the conditions in the family described above, or the formulation used in AdaBoost.MR-and each formulation leading to a different game specification. A priori, it is not clear which game would lead to the best strategy. We resolve this dilemma by proving that the optimal strategies arising out of different formulations of the same weak learning condition lead to algorithms that are essentially equally good, and therefore we are free to choose whichever formulation leads to an easier analysis without fear of suffering in performance. We choose the union of conditions formulation, since it leads to strategies that share the same interpretation in terms of random walks as before. However, even with this choice, the resulting games are hard to analyze, and although we can explicitly compute the optimum strategies in general, the computational complexity is usually exponential in the number of classes. Nevertheless, we identify key situations under which efficient computation is possible.\nThe game-theoretic strategies are non-adaptive in that they presume prior knowledge about the edge, that is, how much better than random are the weak classifiers. Algorithms that are adaptive, such as AdaBoost, are much more practical because they do not require such prior information. We show therefore how to derive an adaptive boosting algorithm by modifying the game-theoretic strategy based on the minimal condition. This algorithm enjoys a number of theoretical guarantees. Unlike some of the non-adaptive strategies, it is efficiently computable, and since it is based on the minimal weak learning condition, it makes minimal assumptions. In fact, whenever presented with a boostable learning problem, this algorithm can approach zero training error at an exponential rate. More importantly, the algorithm is effective even beyond the boostability framework. In particular, we show empirical consistency, that is, the algorithm always converges to the minimum of a certain exponential loss over the training data, whether or not the data set is boostable. Furthermore, using the results in Mukherjee et al. (2011) we can show that this convergence occurs rapidly.\nOur focus in this paper is only on minimizing training error, which, for the algorithms we derive, provably decreases exponentially fast with the number of rounds of boosting under boostability assumptions. Such results can be used in turn to derive bounds on the generalization error using standard techniques that have been applied to other boosting algorithms (Schapire et al., 1998;Freund and Schapire, 1997;Koltchinskii and Panchenko, 2002). Consistency in the multiclass classification setting has been studied by Tewari and Bartlett (2007) and has been shown to be trickier than binary classification consistency. Nonetheless, by following the approach in Bartlett and Traskin (2007) for showing consistency in the binary setting, we are able to extend the empirical consistency guarantees to general consistency guarantees in the multiclass setting: we show that under certain conditions and with sufficient data, our adaptive algorithm approaches the Bayesoptimum error on the test data set.\nWe present experiments aimed at testing the efficacy of the adaptive algorithm when working with a very weak weak-learner to check that the conditions we have identified are indeed weaker than others that had previously been used. We find that our new adaptive strategy achieves low test error compared to other multiclass boosting algorithms which usually heavily underfit. This validates the potential practical benefit of a better theoretical understanding of multiclass boosting.", "publication_ref": ["b23", "b7", "b12", "b10", "b1", "b24", "b10", "b29", "b24", "b10", "b9", "b22", "b0", "b7", "b18", "b26", "b12", "b14", "b27", "b2"], "figure_ref": [], "table_ref": []}, {"heading": "Previous Work", "text": "The first boosting algorithms were given by Schapire (1990) and Freund (1995), followed by their AdaBoost algorithm (Freund and Schapire, 1997). Multiclass boosting techniques include Ada-Boost.M1 and AdaBoost.M2 (Freund and Schapire, 1997), as well as AdaBoost.MH and Ada-Boost.MR (Schapire and Singer, 1999). Other approaches include the work by Eibl and Pfeiffer (2005) and Zhu et al. (2009). There are also more general approaches that can be applied to boosting including Allwein et al. (2000), Beygelzimer et al. (2009), Dietterich and Bakiri (1995), Hastie and Tibshirani (1998) and Li (2010). Two game-theoretic perspectives have been applied to boosting. The first one (Freund and Schapire, 1996b;R\u00e4tsch and Warmuth, 2005) views the weak-learning condition as a minimax game, while drifting games (Schapire, 2001;Freund, 1995) were designed to analyze the most efficient boosting algorithms. These games have been further analyzed in the multiclass and continuous time setting in Freund and Opper (2002).", "publication_ref": ["b21", "b7", "b12", "b12", "b24", "b6", "b29", "b1", "b4", "b13", "b15", "b11", "b19", "b22", "b7", "b9"], "figure_ref": [], "table_ref": []}, {"heading": "Framework", "text": "We introduce some notation. Unless otherwise stated, matrices will be denoted by bold capital letters like M, and vectors by bold small letters like v. Entries of a matrix and vector will be denoted as M(i, j) or v(i), while M(i) will denote the ith row of a matrix. The inner product of two vectors u, v is denoted by u, v . The Frobenius inner product Tr (AB \u2032 ) of two matrices A, B will be denoted by A \u2022 B \u2032 , where B \u2032 is the transpose of B. The indicator function is denoted by 1 [\u2022]. The set of all distributions over the set {1, . . . , k} will be denoted by \u2206 {1, . . . , k}, and in general, the set of all distributions over any set S will be denoted by \u2206(S).\nIn multiclass classification, we want to predict the labels of examples lying in some set X. We are provided a training set of labeled examples {(x 1 , y 1 ), . . . , (x m , y m )}, where each example x i \u2208 X has a label y i in the set {1, . . . , k}.\nBoosting combines several mildly powerful predictors, called weak classifiers, to form a highly accurate combined classifier, and has been previously applied for multiclass classification. In this paper, we only allow weak classifiers that predict a single class for each example. This is appealing, since the combined classifier has the same form, although it differs from what has been used in much previous work. Later we will expand our framework to include multilabel weak classifiers, that may predict multiple labels per example.\nWe adopt a game-theoretic view of boosting. A game is played between two players, Booster and Weak-Learner, for a fixed number of rounds T . With binary labels, Booster outputs a distribution in each round, and Weak-Learner returns a weak classifier achieving more than 50% accuracy on that distribution. The multiclass game is an extension of the binary game. In particular, in each round t:\n\u2022 Booster creates a cost-matrix C t \u2208 R m\u00d7k , specifying to Weak-Learner that the cost of classifying example x i as l is C t (i, l). The cost-matrix may not be arbitrary, but should conform to certain restrictions as discussed below.\n\u2022 Weak-Learner returns some weak classifier h t : X \u2192 {1, . . . , k} from a fixed space h t \u2208 H so that the cost incurred is\nC t \u2022 1 h t = m \u2211 i=1 C t (i, h t (x i )),\nis \"small enough\", according to some conditions discussed below. Here by 1 h we mean the m \u00d7 k matrix whose (i, j)-th entry is 1 [h(i) = j].\n\u2022 Booster computes a weight \u03b1 t for the current weak classifier based on how much cost was incurred in this round.\nAt the end, Booster predicts according to the weighted plurality vote of the classifiers returned in each round:\nH(x) \u25b3 = argmax l\u2208{1,...,k} f T (x, l), where f T (x, l) \u25b3 = T \u2211 t=1 1 [h t (x) = l] \u03b1 t .\n(1)\nBy carefully choosing the cost matrices in each round, Booster aims to minimize the training error of the final classifier H, even when Weak-Learner is adversarial. The restrictions on cost-matrices created by Booster, and the maximum cost Weak-Learner can suffer in each round, together define the weak-learning condition being used. For binary labels, the traditional weak-learning condition states: for any non-negative weights w(1), . . . , w(m) on the training set, the error of the weak classifier returned is at most (1/2 \u2212 \u03b3/2) \u2211 i w i . Here \u03b3 parametrizes the condition. There are many ways to translate this condition into our language. The one with fewest restrictions on the cost-matrices requires labeling correctly should be less costly than labeling incorrectly:\n\u2200i : C(i, y i ) \u2264 C(i,\u0233 i ) (here\u0233 i = y i is the other binary label),\nwhile the restriction on the returned weak classifier h requires less cost than predicting randomly:\n\u2211 i C(i, h(x i )) \u2264 \u2211 i 1 2 \u2212 \u03b3 2 C(i,\u0233 i ) + 1 2 + \u03b3 2 C(i, y i ) .\nBy the correspondence w(i) = C(i,\u0233 i ) \u2212C(i, y i ), we may verify the two conditions are the same. We will rewrite this condition after making some simplifying assumptions. Henceforth, without loss of generality, we assume that the true label is always 1. Let C bin \u2286 R m\u00d72 consist of matrices C which satisfy C(i, 1) \u2264 C(i, 2). Further, let U bin \u03b3 \u2208 R m\u00d72 be the matrix whose each row is\n(1/2 + \u03b3/2, 1/2 \u2212 \u03b3/2).\nThen, Weak-Learner searching space H satisfies the binary weak-learning condition if:\n\u2200C \u2208 C bin , \u2203h \u2208 H : C \u2022 1 h \u2212 U bin \u03b3 \u2264 0.\nThere are two main benefits to this reformulation. With linear homogeneous constraints, the mathematics is simplified, as will be apparent later. More importantly, by varying the restrictions C bin on the cost vectors and the matrix U bin , we can generate a vast variety of weak-learning conditions for the multiclass setting k \u2265 2 as we now show.\nLet C \u2286 R m\u00d7k and let B \u2208 R m\u00d7k be a matrix which we call the baseline. We say a weak classifier space H satisfies the condition (C , B) if\n\u2200C \u2208 C , \u2203h \u2208 H : C \u2022 (1 h \u2212 B) \u2264 0, i.e., m \u2211 i=1 C(i, h(i)) \u2264 m \u2211 i=1 C(i), B(i) .\n(2)\nIn (2), the variable matrix C specifies how costly each misclassification is, while the baseline B specifies a weight for each misclassification. The condition therefore states that a weak classifier should not exceed the average cost when weighted according to baseline B. This large class of weak-learning conditions captures many previously used conditions, such as the ones used by AdaBoost.M1 (Freund and Schapire, 1996a), AdaBoost.MH (Schapire and Singer, 1999) and Ada-Boost.MR (Freund and Schapire, 1996a;Schapire and Singer, 1999) (see below), as well as novel conditions introduced in the next section. By studying this vast class of weak-learning conditions, we hope to find the one that will serve the main purpose of the boosting game: finding a convex combination of weak classifiers that has zero training error. For this to be possible, at the minimum the weak classifiers should be sufficiently rich for such a perfect combination to exist. Formally, a collection H of weak classifiers is boostable if it is eligible for boosting in the sense that there exists a weighting \u03bb on the votes forming a distribution that linearly separates the data:\n\u2200i : argmax l\u2208{1,...,k} \u2211 h\u2208H \u03bb(h)1 [h(x i ) = l] = y i .\nThe weak-learning condition plays two roles. It rejects spaces that are not boostable, and provides an algorithmic means of searching for the right combination. Ideally, the second factor will not cause the weak-learning condition to impose additional restrictions on the weak classifiers; in that case, the weak-learning condition is merely a reformulation of being boostable that is more appropriate for deriving an algorithm. In general, it could be too strong, that is, certain boostable spaces will fail to satisfy the conditions. Or it could be too weak, that is, non-boostable spaces might satisfy such a condition. Booster strategies relying on either of these conditions will fail to drive down error, the former due to underfitting, and the latter due to overfitting. Later we will describe conditions captured by our framework that avoid being too weak or too strong. But before that, we show in the next section how our flexible framework captures weak learning conditions that have appeared previously in the literature.", "publication_ref": ["b10", "b24", "b10", "b24"], "figure_ref": [], "table_ref": []}, {"heading": "Old Conditions", "text": "In this section, we rewrite, in the language of our framework, the weak learning conditions explicitly or implicitly employed in the multiclass boosting algorithms SAMME (Zhu et al., 2009), AdaBoost.M1 (Freund and Schapire, 1996a), and AdaBoost.MH and AdaBoost.MR (Schapire and Singer, 1999). This will be useful later on for comparing the strengths and weaknesses of the various conditions. We will end this section with a curious equivalence between the conditions of AdaBoost.MH and AdaBoost.M1.\nRecall that we have assumed the correct label is 1 for every example. Nevertheless, we continue to use y i to denote the correct label in this section.", "publication_ref": ["b29", "b10", "b24"], "figure_ref": [], "table_ref": []}, {"heading": "Old Conditions in the New Framework", "text": "Here we restate, in the language of our new framework, the weak learning conditions of four algorithms that have earlier appeared in the literature.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "SAMME", "text": "The SAMME algorithm (Zhu et al., 2009) requires less error than random guessing on any distribution on the examples. Formally, a space H satisfies the condition if there is a \u03b3 \u2032 > 0 such that,\n\u2200d(1), . . . , d(m) \u2265 0, \u2203h \u2208 H : m \u2211 i=1 d(i)1 [h(x i ) = y i ] \u2264 (1 \u2212 1/k \u2212 \u03b3 \u2032 ) m \u2211 i=1 d(i).\n(3) Define a cost matrix C whose entries are given by\nC(i, j) = d(i) if j = y i , 0 if j = y i .\nThen the left hand side of ( 3) can be written as\nm \u2211 i=1 C(i, h(x i )) = C \u2022 1 h .\nNext let \u03b3 = (k/(k \u2212 1))\u03b3 \u2032 and define baseline U \u03b3 to be the multiclass extension of U bin ,\nU \u03b3 (i, l) = (1\u2212\u03b3) k + \u03b3 if l = y i , (1\u2212\u03b3) k if l = y i .\nThen notice that for each i, we have\nC(i), U \u03b3 (i) = \u2211 l =y i C(i, l)U \u03b3 (i, l) = (k \u2212 1) (1 \u2212 \u03b3) k d(i) = 1 \u2212 1 k \u2212 1 \u2212 1 k \u03b3 d(i) = 1 \u2212 1 k \u2212 \u03b3 \u2032 d(i).\nTherefore, the right hand side of (3) can be written as\nm \u2211 i=1 \u2211 l =y i C(i, l)U \u03b3 (i, l) = C \u2022 U \u03b3 ,\nsince C(i, y i ) = 0 for every example i. Define C SAM to be the following collection of cost matrices:\nC SAM \u25b3 = C : C(i, l) = 0 if l = y i , t i if l = y i , for non-negative t 1 , . . . ,t m .\nUsing the last two equations, (3) is equivalent to\n\u2200C \u2208 C SAM , \u2203h \u2208 H : C \u2022 1 h \u2212 U \u03b3 \u2264 0.\nTherefore, the weak-learning condition of SAMME is given by (C SAM , U \u03b3 ).", "publication_ref": ["b29"], "figure_ref": [], "table_ref": []}, {"heading": "ADABOOST.M1", "text": "AdaBoost.M1 (Freund and Schapire, 1997) measures the performance of weak classifiers using ordinary error. It requires 1/2 + \u03b3/2 accuracy with respect to any non-negative weights d(1), . . . , d(m) on the training set:\nm \u2211 i=1 d(i)1 [h(x i ) = y i ] \u2264 (1/2 \u2212 \u03b3/2) m \u2211 i=1 d(i),(4)\ni.e.,\nm \u2211 i=1 d(i) h(x i ) = y i \u2264 \u2212\u03b3 m \u2211 i=1 d(i).\nwhere \u2022 is the \u00b11 indicator function, taking value +1 when its argument is true, and \u22121 when false. Using the transformation\nC(i, l) = l = y i d(i)\nwe may rewrite (4) as\n\u2200C \u2208 R m\u00d7k satisfying 0 \u2264 \u2212C(i, y i ) = C(i, l) for l = y i ,(5)\n\u2203h \u2208 H :\nm \u2211 i=1 C(i, h(x i )) \u2264 \u03b3 m \u2211 i=1 C(i, y i ) i.e., \u2200C \u2208 C M1 , \u2203h \u2208 H : C \u2022 1 h \u2212 B M1 \u03b3 \u2264 0, where B M1 \u03b3 (i, l) = \u03b31 [l = y i ]\n, and C M1 \u2286 R m\u00d7k consists of matrices satisfying the constraints in (5).", "publication_ref": ["b12"], "figure_ref": [], "table_ref": []}, {"heading": "ADABOOST.MH", "text": "AdaBoost.MH (Schapire and Singer, 1999) is a popular multiclass boosting algorithm that is based on the one-against-all reduction, and was originally designed to use weak-hypotheses that return a prediction for every example and every label. The implicit weak learning condition requires that for any matrix with non-negative entries d(i, l), the weak-hypothesis should achieve 1/2 + \u03b3 accuracy\nm \u2211 i=1 1 [h(x i ) = y i ] d(i, y i ) + \u2211 l =y i 1 [h(x i ) = l] d(i, l) \u2264 1 2 \u2212 \u03b3 2 m \u2211 i=1 k \u2211 l=1 d(i, l).(6)\nThis can be rewritten as\nm \u2211 i=1 \u22121 [h(x i ) = y i ] d(i, y i ) + \u2211 l =y i 1 [h(x i ) = l] d(i, l) \u2264 m \u2211 i=1 1 2 \u2212 \u03b3 2 \u2211 l =y i d(i, l) \u2212 1 2 + \u03b3 2 d(i, y i ) .\nUsing the mapping\nC(i, l) = d(i, l) if l = y i \u2212d(i, l) if l = y i ,\ntheir weak-learning condition may be rewritten as follows\n\u2200C \u2208 R m\u00d7k satisfying C(i, y i ) \u2264 0,C(i, l) \u2265 0 for l = y i ,(7)\n\u2203h \u2208 H :\nsum m i=1 C(i, h(x i )) \u2264 m \u2211 i=1 1 2 + \u03b3 2 C(i, y i ) + 1 2 \u2212 \u03b3 2 \u2211 l =y i C(i, l) .\nDefining C MH to be the space of all cost matrices satisfying the constraints in (7), the above condition is the same as\n\u2200C \u2208 C MH , \u2203h \u2208 H : C \u2022 1 h \u2212 B MH \u03b3 \u2264 0, where B MH \u03b3 (i, l) = (1/2 + \u03b3 l = y i /2).", "publication_ref": ["b24"], "figure_ref": [], "table_ref": []}, {"heading": "ADABOOST.MR", "text": "AdaBoost.MR (Schapire and Singer, 1999) is based on the all-pairs multiclass to binary reduction. Like AdaBoost.MH, it was originally designed to use weak-hypotheses that return a prediction for every example and every label. The weak learning condition for AdaBoost.MR requires that for any non-negative cost-vectors {d(i, l)} l =y i , the weak-hypothesis returned should satisfy the following:\nm \u2211 i=1 \u2211 l =y i (1 [h(x i ) = l] \u2212 1 [h(x i ) = y i ]) d(i, l) \u2264 \u2212\u03b3 m \u2211 i=1 \u2211 l =y i d(i, l) i.e., m \u2211 i=1 \u22121 [h(x i ) = y i ] \u2211 l =y i d(i, l) + \u2211 l =y i 1 [h(x i ) = l] d(i, l) \u2264 \u2212\u03b3 m \u2211 i=1 \u2211 l =y i d(i, l). Substituting C(i, l) = d(i, l) l = y i \u2212 \u2211 l =y i d(i, l) l = y i ,\nwe may rewrite AdaBoost.MR's weak-learning condition as\n\u2200C \u2208 R m\u00d7k satisfying C(i, l) \u2265 0 for l = y i ,C(i, y i ) = \u2212 \u2211 l =y i C(i, l),(8)\n\u2203h \u2208 H :\nm \u2211 i=1 C(i, h(x i )) \u2264 \u2212 \u03b3 2 m \u2211 i=1 \u2212C(i, y i ) + \u2211 l =y i C(i, l) .\nDefining C MR to be the collection of cost matrices satisfying the constraints in (8), the above condition is the same as\n\u2200C \u2208 C MR , \u2203h \u2208 H : C \u2022 1 h \u2212 B MR \u03b3 \u2264 0, where B MR \u03b3 (i, l) = l = y i \u03b3/2.", "publication_ref": ["b24"], "figure_ref": [], "table_ref": []}, {"heading": "A Curious Equivalence", "text": "We show that the weak learning conditions of AdaBoost.MH and AdaBoost.M1 are identical in our framework. This is surprising because the original motivations behind these algorithms were completely different. AdaBoost.M1 is a direct extension of binary AdaBoost to the multiclass setting, whereas AdaBoost.MH is based on the one-against-all multiclass to binary reduction. This equivalence is a sort of degeneracy, and arises because the weak classifiers being used predict single labels per example. With multilabel weak classifiers, for which AdaBoost.MH was originally designed, the equivalence no longer holds. The proofs in this and later sections will make use of the following minimax result, that is a weaker version of Corollary 37.3.2 of Rockafellar (1970).\nTheorem 1 (Minimax Theorem) Let C, D be non-empty closed convex subsets of R m , R n respectively, and let K be a linear function on C \u00d7 D. If either C or D is bounded, then  Step (i): If H satisfies MH, then it also satisfies M1. This follows since any constraint (4) imposed by M1 on H can be reproduced by MH by plugging the following values of d(i, l) in ( 6)\nd(i, l) = d(i) if l = y i 0 if l = y i .\nStep (ii): If H satisfies M1, then there is a convex combination H \u03bb * of the matrices 1 h \u2208 H , defined as\nH \u03bb * \u25b3 = \u2211 h\u2208H \u03bb * (h)1 h , such that \u2200i : H \u03bb * \u2212 B M1 \u03b3 (i, l) \u2265 0 if l = y i \u2264 0 if l = y i .(9)\nIndeed, Theorem 1 yields\nmin \u03bb\u2208\u2206(H ) max C\u2208C M1 C \u2022 H \u03bb \u2212 B M1 \u03b3 = max C\u2208C M1 min h\u2208H C \u2022 1 h \u2212 B M1 \u03b3 \u2264 0,(10)\nwhere the inequality is a restatement of our assumption that H satisfies M1. If \u03bb * is a minimizer of the minimax expression, then H \u03bb * must satisfy\n\u2200i : H \u03bb * (i, l) \u2265 1 2 + \u03b3 2 if l = y i \u2264 1 2 \u2212 \u03b3 2 if l = y i ,(11)\nor else some choice of\nC \u2208 C M1 can cause C\u2022 H \u03bb * \u2212 B M1 \u03b3 to exceed 0. In particular, if H \u03bb * (i 0 , l) < 1/2 + \u03b3/2, then H \u03bb * \u2212 B M1 \u03b3 (i 0 , y i 0 ) < \u2211 l =y i 0 H \u03bb * \u2212 B M1 \u03b3 (i 0 , l). Now, if we choose C \u2208 C M1 as C(i, l) = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 0 if i = i 0 1 if i = i 0 , l = y i 0 \u22121 if i = i 0 , l = y i 0 , then, C \u2022 H \u03bb * \u2212 B M1 \u03b3 = \u2212 H \u03bb * \u2212 B M1 \u03b3 (i 0 , y i 0 ) + \u2211 l =y i 0 H \u03bb * \u2212 B M1 \u03b3 (i 0 , l) > 0,\ncontradicting the inequality in (10). Therefore (11) holds. Equation ( 9), and thus Step (ii), now follows by observing that B MH \u03b3 , by definition, satisfies\n\u2200i : B MH \u03b3 (i, l) = 1 2 + \u03b3 2 if l = y i 1 2 \u2212 \u03b3 2 if l = y i .\nStep (iii) If there is some convex combination H \u03bb * satisfying (9), then H satisfies MH. Recall that B MH consists of entries that are non-positive on the correct labels and non-negative for incorrect labels. Therefore, (9) implies 0 \u2265 max\nC\u2208C MH C \u2022 H \u03bb * \u2212 B MH \u03b3 \u2265 min \u03bb\u2208\u2206(H ) max C\u2208C MH C \u2022 H \u03bb \u2212 B MH \u03b3 .\nOn the other hand, using Theorem 1 we have\nmin \u03bb\u2208\u2206(H ) max C\u2208C MH C \u2022 H \u03bb \u2212 B MH \u03b3 = max C\u2208C MH min h\u2208H C \u2022 1 h \u2212 B MH \u03b3 .\nCombining the two, we get 0 \u2265 max\nC\u2208C MH min h\u2208H C \u2022 1 h \u2212 B MH \u03b3 ,\nwhich is the same as saying that H satisfies MH's condition.\nSteps (ii) and (iii) together imply that if H satisfies M1, then it also satisfies MH. Along with\nStep (i), this concludes the proof.", "publication_ref": ["b20"], "figure_ref": [], "table_ref": []}, {"heading": "Necessary and Sufficient Weak-learning Conditions", "text": "The binary weak-learning condition has an appealing form: for any distribution over the examples, the weak classifier needs to achieve error not greater than that of a random player who guesses the correct answer with probability 1/2 + \u03b3/2. Further, this is the weakest condition under which boosting is possible as follows from a game-theoretic perspective (Freund and Schapire, 1996b;R\u00e4tsch and Warmuth, 2005) . Multiclass weak-learning conditions with similar properties are missing in the literature. In this section we show how our framework captures such conditions.", "publication_ref": ["b11", "b19"], "figure_ref": [], "table_ref": []}, {"heading": "Edge-over-random Conditions", "text": "In the multiclass setting, we model a random player as a baseline predictor B \u2208 R m\u00d7k whose rows are distributions over the labels, B(i) \u2208 \u2206 {1, . . . , k}. The prediction on example i is a sample from B(i). We only consider the space of edge-over-random baselines B eor \u03b3 \u2286 R m\u00d7k who have a faint clue about the correct answer. More precisely, any baseline B \u2208 B eor \u03b3 in this space is \u03b3 more likely to predict the correct label than an incorrect one on every example i: \u2200l = 1, B(i, 1) \u2265 B(i, l) + \u03b3, with equality holding for some l, that is:\nB(i, 1) = max {B(i, l) + \u03b3 : l = 1} .\nNotice that the edge-over-random baselines are different from the baselines used by earlier weak learning conditions discussed in the previous section.\nWhen k = 2, the space B eor \u03b3 consists of the unique player U bin \u03b3 , and the binary weak-learning condition is given by (C bin , U bin \u03b3 ). The new conditions generalize this to k > 2. In particular, define C eor to be the multiclass extension of C bin : any cost-matrix in C eor should put the least cost on the correct label, that is, the rows of the cost-matrices should come from the set c \u2208 R k : \u2200l, c(1) \u2264 c(l) .\nThen, for every baseline B \u2208 B eor \u03b3 , we introduce the condition (C eor , B), which we call an edgeover-random weak-learning condition. Since C \u2022 B is the expected cost of the edge-over-random baseline B on matrix C, the constraints (2) imposed by the new condition essentially require better than random performance.\nAlso recall that we have assumed that the true label y i of example i in our training set is always 1. Nevertheless, we may occasionally continue to refer to the true labels as y i .\nWe now present the central results of this section. The seemingly mild edge-over-random conditions guarantee boostability, meaning weak classifiers that satisfy any one such condition can be combined to form a highly accurate combined classifier.\nTheorem 3 (Sufficiency) If a weak classifier space H satisfies a weak-learning condition (C eor , B), for some B \u2208 B eor \u03b3 , then H is boostable.\nProof The proof is in the spirit of the ones in Freund and Schapire (1996b). Applying Theorem 1 yields 0 \u2265 max\nC\u2208C eor min h\u2208H C \u2022 (1 h \u2212 B) = min \u03bb\u2208\u2206(H ) max C\u2208C eor C \u2022 (H \u03bb \u2212 B) ,\nwhere the first inequality follows from the definition (2) of the weak-learning condition. Let \u03bb * be a minimizer of the min-max expression. Unless the first entry of each row of (H \u03bb * \u2212 B) is the largest, the right hand side of the min-max expression can be made arbitrarily large by choosing C \u2208 C eor appropriately. For example, if in some row i, the j th 0 element is strictly larger than the first element, by choosing\nC(i, j) = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 \u22121 if j = 1 1 if j = j 0 0\notherwise, we get a matrix in C eor which causes C \u2022 (H \u03bb * \u2212 B) to be equal to C(i, j 0 ) \u2212C(i, 1) > 0, an impossibility by the first inequality. Therefore, the convex combination of the weak classifiers, obtained by choosing each weak classifier with weight given by \u03bb * , perfectly classifies the training data, in fact with a margin \u03b3.\nOn the other hand, the family of such conditions, taken as a whole, is necessary for boostability in the sense that every eligible space of weak classifiers satisfies some edge-over-random condition.\nTheorem 4 (Relaxed necessity) For every boostable weak classifier space H , there exists a \u03b3 > 0 and B \u2208 B eor \u03b3 such that H satisfies the weak-learning condition (C eor , B).\nProof The proof shows existence through non-constructive averaging arguments. We will reuse notation from the proof of Theorem 3 above. H is boostable implies there exists some distribution\n\u03bb * \u2208 \u2206(H ) such that \u2200 j = 1, i : H \u03bb * (i, 1) \u2212 H \u03bb * (i, j) > 0.\nLet \u03b3 > 0 be the minimum of the above expression over all possible (i, j), and let B = H \u03bb * . Then B \u2208 B eor \u03b3 , and\nmax C\u2208C eor min h\u2208H C \u2022 (1 h \u2212 B) \u2264 min \u03bb\u2208\u2206(H ) max C\u2208C eor C \u2022 (H \u03bb \u2212 B) \u2264 max C\u2208C eor C \u2022 (H \u03bb * \u2212 B) = 0,\nwhere the equality follows since by definition H \u03bb * \u2212 B = 0. The max-min expression is at most zero is another way of saying that H satisfies the weak-learning condition (C eor , B) as in (2).\nTheorem 4 states that any boostable weak classifier space will satisfy some condition in our family, but it does not help us choose the right condition. Experiments in Section 10 suggest C eor , U \u03b3 is effective with very simple weak-learners compared to popular boosting algorithms. (Recall U \u03b3 \u2208 B eor \u03b3 is the edge-over-random baseline closest to uniform; it has weight (1 \u2212 \u03b3)/k on incorrect labels and (1 \u2212 \u03b3)/k + \u03b3 on the correct label.) However, there are theoretical examples showing each condition in our family is too strong.\nTheorem 5 For any B \u2208 B eor \u03b3 , there exists a boostable space H that fails to satisfy the condition (C eor , B).\nProof We provide, for any \u03b3 > 0 and edge-over-random baseline B \u2208 B eor \u03b3 , a data set and weak classifier space that is boostable but fails to satisfy the condition (C eor , B).\nPick \u03b3 \u2032 = \u03b3/k and set m > 1/\u03b3 \u2032 so that \u230am(1/2 + \u03b3 \u2032 )\u230b > m/2. Our data set will have m labeled examples {(0, y 0 ), . . . , (m \u2212 1, y m\u22121 )}, and m weak classifiers. We want the following symmetries in our weak classifiers:\n\u2022 Each weak classifier correctly classifies \u230am(1/2 + \u03b3 \u2032 )\u230b examples and misclassifies the rest.\n\u2022 On each example, \u230am(1/2 + \u03b3 \u2032 )\u230b weak classifiers predict correctly.\nNote the second property implies boostability, since the uniform convex combination of all the weak classifiers is a perfect predictor.\nThe two properties can be satisfied by the following design. A window is a contiguous sequence of examples that may wrap around; for example {i, (i + 1) mod m, . . . , (i + k) mod m} is a window containing k elements, which may wrap around if i + k \u2265 m. For each window of length \u230am(1/2 + \u03b3 \u2032 )\u230b create a hypothesis that correctly classifies within the window, and misclassifies outside. This weak-hypothesis space has size m, and has the required properties.\nWe still have flexibility as to how the misclassifications occur, and which cost-matrix to use, which brings us to the next two choices:\n\u2022 Whenever a hypothesis misclassifies on example i, it predicts label\ny i \u25b3 = argmin {B(i, l) : l = y i } .\n(12)\n\u2022 A cost-matrix is chosen so that the cost of predicting\u0177 i on example i is 1, but for any other prediction the cost is zero. Observe this cost-matrix belongs to C eor .\nTherefore, every time a weak classifier predicts incorrectly, it also suffers cost 1. Since each weak classifier predicts correctly only within a window of length \u230am(1/2 + \u03b3 \u2032 )\u230b, it suffers cost \u2308m(1/2 \u2212 \u03b3 \u2032 )\u2309. On the other hand, by the choice of\u0177 i in (12), and by our assumption that y i = 1, we have\nB(i,\u0177 i ) = min {B(i, 1) \u2212 \u03b3, B(i, 2), . . . , B(i, k)} \u2264 1 k (B(i, 1) \u2212 \u03b3 + B(i, 2) + B(i, 3) + . . . + B(i, k)) = 1/k \u2212 \u03b3/k.\nSo the cost of B on the chosen cost-matrix is at most m(1/k \u2212 \u03b3/k), which is less than the cost\n\u2308m(1/2 \u2212 \u03b3 \u2032 )\u2309 \u2265 m(1/2 \u2212 \u03b3/k)\nof any weak classifier whenever the number of labels k is more than two. Hence our boostable space of weak classifiers fails to satisfy (C eor , B).\nTheorems 4 and 5 can be interpreted as follows. While a boostable space will satisfy some edgeover-random condition, without further information about the data set it is not possible to know which particular condition will be satisfied. The kind of prior knowledge required to make this guess correctly is provided by Theorem 3: the appropriate weak learning condition is determined by the distribution of votes on the labels for each example that a target weak classifier combination might be able to get. Even with domain expertise, such knowledge may or may not be obtainable in practice before running boosting. We therefore need conditions that assume less.", "publication_ref": ["b11"], "figure_ref": [], "table_ref": []}, {"heading": "The Minimal Weak Learning Condition", "text": "A perhaps extreme way of weakening the condition is by requiring the performance on a cost matrix to be competitive not with a fixed baseline B \u2208 B eor \u03b3 , but with the worst of them:\n\u2200C \u2208 C eor , \u2203h \u2208 H : C \u2022 1 h \u2264 max B\u2208B eor \u03b3 C \u2022 B.(13)\nCondition ( 13) states that during the course of the same boosting game, Weak-Learner may choose to beat any edge-over-random baseline B \u2208 B eor \u03b3 , possibly a different one for every round and every cost-matrix. This may superficially seem much too weak. On the contrary, this condition turns out to be equivalent to boostability. In other words, according to our criterion, it is neither too weak nor too strong as a weak-learning condition. However, unlike the edge-over-random conditions, it also turns out to be more difficult to work with algorithmically.\nFurthermore, this condition can be shown to be equivalent to the one used by AdaBoost.MR (Schapire and Singer, 1999;Freund and Schapire, 1996a). This is perhaps remarkable since the latter is based on the apparently completely unrelated all-pairs multiclass to binary reduction. In Section 3 we saw that the MR condition is given by (C MR , B MR \u03b3 ), where C MR consists of costmatrices that put non-negative costs on incorrect labels and whose rows sum up to zero, while B MR \u03b3 \u2208 R m\u00d7k is the matrix that has \u03b3 on the first column and \u2212\u03b3 on all other columns. Further, the MR condition, and hence (13), can be shown to be neither too weak nor too strong.\nTheorem 6 (MR) A weak classifier space H satisfies AdaBoost.MR's weak-learning condition (C MR , B MR \u03b3 ) if and only if it satisfies (13). Moreover, this condition is equivalent to being boostable.\nProof We will show the following three conditions are equivalent:\n(A) H is boostable (B) \u2203\u03b3 > 0 such that \u2200C \u2208 C eor , \u2203h \u2208 H : C \u2022 1 h \u2264 max B\u2208B eor \u03b3 C \u2022 B (C) \u2203\u03b3 > 0 such that \u2200C \u2208 C MR , \u2203h \u2208 H : C \u2022 1 h \u2264 C \u2022 B MR .\nWe will show (A) implies (B), (B) implies (C), and (C) implies (A) to achieve the above. (A) implies (B): Immediate from Theorem 4.\n(B) implies (C): Suppose (B) is satisfied with 2\u03b3. We will show that this implies H satisfies\n(C MR , B MR \u03b3 ). Notice C MR \u2282 C eor . Therefore it suffices to show that \u2200C \u2208 C MR , B \u2208 B eor 2\u03b3 : C \u2022 B \u2212 B MR \u03b3 \u2264 0. Notice that B \u2208 B eor 2\u03b3 implies B \u2032 = B \u2212 B MR \u03b3\nis a matrix whose largest entry in each row is in the first column of that row. Then, for any C \u2208 C MR , C \u2022 B \u2032 can be written as\nC \u2022 B \u2032 = m \u2211 i=1 k \u2211 j=2 C(i, j) B \u2032 (i, j) \u2212 B \u2032 (i, 1) .\nSince C(i, j) \u2265 0 for j > 1, and B \u2032 (i, j) \u2212 B \u2032 (i, 1) \u2264 0, we have our result.\n(C) implies (A): Applying Theorem 1 0 \u2265 max\nC\u2208C MR min h\u2208H C \u2022 1 h \u2212 B MR \u03b3 \u2265 max C\u2208C MR min \u03bb\u2208\u2206(H ) C \u2022 H \u03bb \u2212 B MR \u03b3 = min \u03bb\u2208\u2206(H ) max C\u2208C MR C \u2022 H \u03bb \u2212 B MR \u03b3 .\nFor any i 0 and l 0 = 1, the following cost-matrix C satisfies C \u2208 C MR ,\nC(i, l) = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 0 if i = i 0 or l \u2208 {1, l 0 } 1 if i = i 0 , l = l 0 \u22121 if i = i 0 , l = 1.\nLet \u03bb belong to the argmin of the min max expression. Then\nC\u2022 H \u03bb \u2212 B MR \u03b3 \u2264 0 implies H \u03bb (i 0 , 1)\u2212 H \u03bb (i 0 , l 0 ) \u2265 2\u03b3.\nSince this is true for all i 0 and l 0 = 1, we conclude that the (C MR , B MR \u03b3 ) condition implies boostability.\nThis concludes the proof of equivalence.\nNext, we illustrate the strengths of our minimal weak-learning condition through concrete comparisons with previous algorithms.\nh 1 h 2 a 1 2 b 1 2\nFigure 1: A weak classifier space which satisfies SAMME's weak learning condition but is not boostable.", "publication_ref": ["b24", "b10"], "figure_ref": ["fig_7"], "table_ref": []}, {"heading": "COMPARISON WITH SAMME", "text": "The SAMME algorithm of Zhu et al. (2009) requires the weak classifiers to achieve less error than uniform random guessing for multiple labels; in our language, their weak-learning condition is (C SAM , U \u03b3 ), as shown in Section 3, where C SAM consists of cost matrices whose rows are of the form (0,t,t, . . .) for some non-negative t. As is well-known, this condition is not sufficient for boosting to be possible. In particular, consider the data set {(a, 1), (b, 2)} with k = 3, m = 2, and a weak classifier space consisting of h 1 , h 2 which always predict 1, 2, respectively (Figure 1). Since neither classifier distinguishes between a, b we cannot achieve perfect accuracy by combining them in any way. Yet, due to the constraints on the cost-matrix, one of h 1 , h 2 will always manage non-positive cost while random always suffers positive cost. On the other hand our weak-learning condition allows the Booster to choose far richer cost matrices. In particular, when the cost matrix\nC \u2208 C eor is given by 1 2 3 a \u22121 +1 0 b +1 \u22121 0,\nboth classifiers in the above example suffer more loss than the random player U \u03b3 , and fail to satisfy our condition.", "publication_ref": ["b29"], "figure_ref": ["fig_7"], "table_ref": []}, {"heading": "COMPARISON WITH ADABOOST.MH", "text": "AdaBoost.MH (Schapire and Singer, 1999) was designed for use with weak hypotheses that on each example return a prediction for every label. When used in our framework, where the weak classifiers return only a single multiclass prediction per example, the implicit demands made by AdaBoost.MH on the weak classifier space turn out to be too strong. We cannot use Theorem 5 to demonstrate this, since it applies to only fixed edge-over-random conditions. Instead, we construct a classifier space that satisfies the condition (C eor , U \u03b3 ) in our family, but cannot satisfy AdaBoost.MH's weaklearning condition. Note that this does not imply that the conditions are too strong when used with more powerful weak classifiers that return multilabel multiclass predictions.\nConsider a space H that has, for every (1/k + \u03b3)m element subset of the examples, a classifier that predicts correctly on exactly those elements. The expected loss of a randomly chosen classifier from this space is the same as that of the random player U \u03b3 . Hence H satisfies this weak-learning condition. On the other hand, it was shown in Section 3 that AdaBoost.MH's weak-learning condition is the pair (C MH , B MH \u03b3 ), where C MH consists of cost matrices with non-negative entries on incorrect labels and non-positive entries on real labels, and where each row of the matrix B MH \u03b3 is the vector (1/2 + \u03b3/2, 1/2 \u2212 \u03b3/2, . . . , 1/2 \u2212 \u03b3/2). A quick calculation shows that for any h \u2208 H , and C \u2208 C MH with \u22121 in the first column and zeroes elsewhere, C \u2022 1 h \u2212 B MH \u03b3 = 1/2 \u2212 1/k. This is positive when k > 2, so that H fails to satisfy AdaBoost.MH's condition.\nWe have seen how our framework allows us to capture the strengths and weaknesses of old conditions, describe a whole new family of conditions and also identify the condition making minimal assumptions. In the next few sections, we show how to design boosting algorithms that employ these new conditions and enjoy strong theoretical guarantees.", "publication_ref": ["b24"], "figure_ref": [], "table_ref": []}, {"heading": "Algorithms", "text": "In this section we devise algorithms by analyzing the boosting games that employ weak-learning conditions in our framework. We compute the optimum Booster strategy against a completely adversarial Weak-Learner, which here is permitted to choose weak classifiers without restriction, that is, the entire space H all of all possible functions mapping examples to labels. By modeling Weak-Learner adversarially, we make absolutely no assumptions on the algorithm it might use. Hence, error guarantees enjoyed in this situation will be universally applicable. Our algorithms are derived from the very general drifting games framework (Schapire, 2001) for solving boosting games, which in turn was inspired by Freund's Boost-by-majority algorithm (Freund, 1995), which we review next.", "publication_ref": ["b22", "b7"], "figure_ref": [], "table_ref": []}, {"heading": "The OS Algorithm", "text": "Fix the number of rounds T and a weak-learning condition (C , B). We will only consider conditions that are not vacuous, that is, at least some classifier space satisfies the condition, or equivalently, the space H all satisfies (C , B). Additionally, we assume the constraints placed by C are on individual rows. In other words, there is some subset C 0 \u2286 R k of all possible rows, such that a cost matrix C belongs to the collection C if and only if each of its rows belongs to this subset:\nC \u2208 C \u21d0\u21d2 \u2200i : C(i) \u2208 C 0 . (14)\nFurther, we assume C 0 forms a convex cone, that is, c, c \u2032 \u2208 C 0 implies tc + t \u2032 c \u2032 \u2208 C 0 for any nonnegative t,t \u2032 . This also implies that C is a convex cone. This is a very natural restriction, and is satisfied by the space C used by the weak learning conditions of AdaBoost.MH, AdaBoost.M1, AdaBoost.MR, SAMME as well as every edge-over-random condition. 1 For simplicity of presentation we fix the weights \u03b1 t = 1 in each round. With f T defined as in (1), whether the final hypotheses output by Booster makes a prediction error on an example i is decided by whether an incorrect label received the maximum number of votes, f T (i, 1) \u2264 max k l=2 f T (i, l). Therefore, the optimum Booster payoff can be written as\nmin C 1 \u2208C max h 1 \u2208H all : C 1 \u2022(1 h 1 \u2212B)\u22640 . . . min C T \u2208C max h T \u2208H all : C T \u2022(1 h T \u2212B)\u22640 1 m m \u2211 i=1 L err ( f T (x i , 1), . . . , f T (x i , k)). (15\n)\nwhere the function\nL err : R k \u2192 R encodes 0-1 error L err (s) = 1 s(1) \u2264 max l>1 s(l) .(16)\nIn general, we will also consider other loss functions L : R k \u2192 R such as exponential loss, hinge loss, etc. that upper-bound error and are proper: that is, L(s) is increasing in the weight of the correct label s(1), and decreasing in the weights of the incorrect labels s(l), l = 1. Directly analyzing the optimal payoff is hard. However, Schapire (2001) observed that the payoffs can be very well approximated by certain potential functions. Indeed, for any b \u2208 R k define the potential function \u03c6 b t : R k \u2192 R by the following recurrence:\n\u03c6 b 0 (s) = L(s) \u03c6 b t (s) = min c\u2208C 0 max p\u2208\u2206{1,...,k} E l\u223cp \u03c6 b t\u22121 (s + e l ) s.t. E l\u223cp [c(l)] \u2264 b, c ,(17)\nwhere l \u223c p denotes that label l is sampled from the distribution p, and e l \u2208 R k is the unit-vector whose lth coordinate is 1 and the remaining coordinates zero. Notice the recurrence uses the collection of rows C 0 instead of the collection of cost matrices C . When there are T \u2212t rounds remaining (that is, after t rounds of boosting), these potential functions compute an estimate \u03c6 b T \u2212t (s t ) of whether an example x will be misclassified, based on its current state s t consisting of counts of votes received so far on various classes:\ns t (l) = t\u22121 \u2211 t \u2032 =1 1 [h t \u2032 (x) = l] .(18)\nNotice this definition of state assumes that \u03b1 t = 1 in each round. Sometimes, we will choose the weights differently. In such cases, a more appropriate definition is the weighted state f t \u2208 R k , tracking the weighted counts of votes received so far:\nf t (l) = t\u22121 \u2211 t \u2032 =1 \u03b1 t \u2032 1 [h t \u2032 (x) = l] .(19)\nHowever, unless otherwise noted, we will assume \u03b1 t = 1, and so the definition in (18) will suffice. The recurrence in (17) requires the max player's response p to satisfy the constraint that the expected cost under the distribution p is at most the inner-product c, b . If there is no distribution satisfying this requirement, then the value of the max expression is \u2212\u221e. The existence of a valid distribution depends on both b and c and is captured by the following:\n\u2203p \u2208 \u2206 {1, . . . , k} : E l\u223cp [c(l)] \u2264 c, b \u21d0\u21d2 min l c(l) \u2264 b, c .(20)\nIn this paper, the vector b will always correspond to some row B(i) of the baseline used in the weak learning condition. In such a situation, the next lemma shows that a distribution satisfying the required constraints will always exist.\nLemma 7 If C 0 is a cone and (14) holds, then for any row b = B(i) of the baseline and any cost vector c \u2208 C 0 , (20) holds unless the condition (C , B) is vacuous.\nProof We show that if (20) does not hold, then the condition is vacuous. Assume that for row b = B(i 0 ) of the baseline, and some choice of cost vector c \u2208 C 0 , (20) does not hold. We pick a costmatrix C \u2208 C , such that no weak classifier h can satisfy the requirement (2), implying the condition must be vacuous. The i th 0 row of the cost matrix is c, and the remaining rows are 0. Since C 0 is a cone, 0 \u2208 C 0 and hence the cost matrix lies in C . With this choice for C, the condition (2) becomes\nc(h(x i )) = C (i, h(x i )) \u2264 C(i), B(i) = c, b < min l c(l),\nwhere the last inequality holds since, by assumption, ( 20) is not true for this choice of c, b. The previous equation is an impossibility, and hence no such weak classifier h exists, showing the condition is vacuous.\nLemma 7 shows that the expression in ( 17) is well defined, and takes on finite values. We next record an alternate dual form for the same recurrence which will be useful later.", "publication_ref": ["b22"], "figure_ref": [], "table_ref": []}, {"heading": "Lemma 8", "text": "The recurrence in (17) is equivalent to\n\u03c6 b t (s) = min c\u2208C 0 k max l=1 \u03c6 b t\u22121 (s + e l ) \u2212 (c(l) \u2212 c, b ) . (21\n)\nProof Using Lagrangean multipliers, we may convert ( 17) to an unconstrained expression as follows:\n\u03c6 b t (s) = min c\u2208C 0 max p\u2208\u2206{1,...,k} min \u03bb\u22650 E l\u223cp \u03c6 b t\u22121 (s + e l ) \u2212 \u03bb (E l\u223cp [c(l)] \u2212 c, b ) .\nApplying Theorem 1 to the inner min-max expression we get\n\u03c6 b t (s) = min c\u2208C 0 min \u03bb\u22650 max p\u2208\u2206{1,...,k} E l\u223cp \u03c6 b t\u22121 (s + e l ) \u2212 (E l\u223cp [\u03bbc(l)] \u2212 \u03bbc, b ) .\nSince C 0 is a cone, c \u2208 C 0 implies \u03bbc \u2208 C 0 . Therefore we may absorb the Lagrange multiplier into the cost vector:\n\u03c6 b t (s) = min c\u2208C 0 max p\u2208\u2206{1,...,k} E l\u223cp \u03c6 b t\u22121 (s + e l ) \u2212 (c(l) \u2212 c, b ) .\nFor a fixed choice of c, the expectation is maximized when the distribution p is concentrated on a single label that maximizes the inner expression, which completes our proof.\nThe dual form of the recurrence is useful for optimally choosing the cost matrix in each round. When the weak learning condition being used is (C , B), Schapire (2001) proposed a Booster strategy, called the OS strategy, which always chooses the weight \u03b1 t = 1, and uses the potential functions to construct a cost matrix C t as follows. Each row C t (i) of the matrix achieves the minimum of the right hand side of ( 21) with b replaced by B(i), t replaced by T \u2212 t, and s replaced by current state s t (i):\nC t (i) = argmin c\u2208C 0 k max l=1 \u03c6 B(i) T \u2212t\u22121 (s + e l ) \u2212 (c(l) \u2212 c, B(i) ) . (22\n)\nThe following theorem, proved in the appendix, provides a guarantee for the loss suffered by the OS algorithm, and also shows that it is the game-theoretically optimum strategy when the number of examples is large. Similar results have been proved by Schapire (2001), but our theorem holds much more generally, and also achieves tighter lower bounds.\nTheorem 9 (Extension of results in Schapire ( 2001)) Suppose the weak-learning condition is not vacuous and is given by (C , B), where C is such that, for some convex cone C 0 \u2286 R k , the condition (14) holds. Let the potential functions \u03c6 b t be defined as in (17), and assume the Booster employs the OS algorithm, choosing \u03b1 t = 1 and C t as in ( 22) in each round t. Then the average potential of the states,\n1 m m \u2211 i=1 \u03c6 B(i) T \u2212t (s t (i)) ,\nnever increases in any round. In particular, the loss suffered after T rounds of play is at most\n1 m m \u2211 i=1 \u03c6 B(i) T (0).(23)\nFurther, under certain conditions, this bound is nearly tight. In particular, assume the loss function does not vary too much but satisfies\nsup s,s \u2032 \u2208S T |L(s) \u2212 L(s \u2032 )| \u2264 (L, T ),(24)\nwhere S T , a subset of s \u2208 R k : s \u221e \u2264 T , is the set of all states reachable in T iterations, and\n(L, T ) is an upper bound on the discrepancy of losses between any two reachable states when the loss function is L and the total number of iterations is T . Then, for any \u03b5 > 0, when the number of examples m is sufficiently large,\nm \u2265 T (L, T ) \u03b5 ,(25)\nno Booster strategy can guarantee to achieve in T rounds a loss that is \u03b5 less than the bound (23).\nIn order to implement the nearly optimal OS strategy, we need to solve (22). This is computationally only as hard as evaluating the potentials, which in turn reduces to computing the recurrences in (17). In the next few sections, we study how to do this when using various losses and weak learning conditions.", "publication_ref": ["b22", "b22"], "figure_ref": [], "table_ref": []}, {"heading": "Solving for Any Fixed Edge-over-random Condition", "text": "In this section we show how to implement the OS strategy when the weak learning condition is any fixed edge-over-random condition: (C , B) for some B \u2208 B eor \u03b3 . By our previous discussions, this is equivalent to computing the potential \u03c6 b t by solving the recurrence in (17), where the vector b corresponds to some row of the baseline B. Let \u2206 k \u03b3 \u2286 \u2206 {1, . . . , k} denote the set of all edge-overrandom distributions on {1, . . . , k} with \u03b3 more weight on the first coordinate:\n\u2206 k \u03b3 = {b \u2208 \u2206 {1, . . . , k} : b(1) \u2212 \u03b3 = max {b(2), . . . , b(k)}} .(26)\nNote, that B eor \u03b3 consists of all matrices whose rows belong to the set \u2206 k \u03b3 . Therefore we are interested in computing \u03c6 b , where b is an arbitrary edge-over-random distribution: b \u2208 \u2206 k \u03b3 . We begin by simplifying the recurrence ( 17) satisfied by such potentials, and show how to compute the optimal cost matrix in terms of the potentials.\nLemma 10 Assume L is proper, and b \u2208 \u2206 k \u03b3 is an edge-over-random distribution. Then the recurrence (17) may be simplified as\n\u03c6 b t (s) = E l\u223cb [\u03c6 t\u22121 (s + e l )] .(27)\nFurther, if the cost matrix C t is chosen as follows\nC t (i, l) = \u03c6 b T \u2212t\u22121 (s t (i) + e l ),(28)\nthen C t satisfies the condition in ( 22), and hence is the optimal choice.\nProof Let C eor 0 \u2286 R k denote all vectors c satisfying \u2200l : c(1) \u2264 c(l). Then, we have\n\u03c6 b t (s) = min c\u2208C eor 0 max p\u2208\u2206{1,...,k} E l\u223cp [\u03c6 t\u22121 (s + e l )] s.t. E l\u223cp [c(l)] \u2264 E l\u223cb [c(l)] , ( by (17) ) = min c\u2208C eor 0 max p\u2208\u2206 min \u03bb\u22650 E l\u223cp \u03c6 b t\u22121 (s + e l ) + \u03bb (E l\u223cb [c(l)] \u2212 E l\u223cp [c(l)]) (Lagrangean) = min c\u2208C eor 0 min \u03bb\u22650 max p\u2208\u2206 E l\u223cp \u03c6 b t\u22121 (s + e l ) + \u03bb b \u2212 p, c (Theorem 1) = min c\u2208C eor 0 max p\u2208\u2206 E l\u223cp \u03c6 b t\u22121 (s + e l ) + b \u2212 p, c (absorb \u03bb into c) = max p\u2208\u2206 min c\u2208C eor 0 E l\u223cp \u03c6 b t\u22121 (s + e l ) + b \u2212 p, c (Theorem 1) .\nUnless b(1) \u2212 p(1) \u2264 0 and b(l) \u2212 p(l) \u2265 0 for each l > 1, the quantity b \u2212 p, c can be made arbitrarily small for appropriate choices of c \u2208 C eor 0 . The max-player is therefore forced to constrain its choices of p, and the above expression becomes\nmax p\u2208\u2206 E l\u223cp \u03c6 b t\u22121 (s + e l ) s.t. b(l) \u2212 q(l) \u2265 0 if l = 1, \u2264 0 if l > 1.\nLemma 6 of Schapire (2001) states that if L is proper (as defined here), so is \u03c6 b t ; the same result can be extended to our drifting games. This implies the optimal choice of p in the above expression is in fact the distribution that puts as small weight as possible in the first coordinate, namely b. Therefore the optimum choice of p is b, and the potential is the same as in ( 27).\nWe end the proof by showing that the choice of cost matrix in ( 28) is optimum. Theorem 9 states that a cost matrix C t is the optimum choice if it satisfies (22), that is, if the expression\nk max l=1 \u03c6 B(i) T \u2212t\u22121 (s + e l ) \u2212 (C t (i, l) \u2212 C t (i), B(i) ) (29) is equal to min c\u2208C 0 k max l=1 \u03c6 B(i) T \u2212t\u22121 (s + e l ) \u2212 (c(l) \u2212 c, B(i) ) = \u03c6 B(i) T \u2212t (s) ,(30)\nwhere the equality in (30) follows from ( 21). If C t (i) is chosen as in ( 28), then, for any label l, the expression within max in (29) evaluates to\n\u03c6 B(i) T \u2212t\u22121 (s + e l ) \u2212 \u03c6 B(i) T \u2212t\u22121 (s + e l ) \u2212 C t (i), B(i) = B(i), C t (i) = E l\u223cB(i) [C t (i, l)] = E l\u223cB(i) \u03c6 B(i) T \u2212t\u22121 (s + e l ) = \u03c6 B(i) T \u2212t (s),\nwhere the last equality follows from ( 27). Therefore the max expression in ( 29) is also equal to \u03c6\nB(i) T \u2212t (s),\nwhich is what we needed to show. Equation ( 28) in Lemma 10 implies the cost matrix chosen by the OS strategy can be expressed in terms of the potentials, which is the only thing left to calculate. Fortunately, the simplification (27) of the drifting games recurrence, allows the potentials to be solved completely in terms of a random-walk R t b (x). This random variable denotes the position of a particle after t time steps, that starts at location x \u2208 R k , and in each step moves in direction e l with probability b(l).\nCorollary 11 The recurrence in (27) can be solved as follows:\n\u03c6 b t (s) = E L R t b (s) . (31\n)\nProof Inductively assuming \u03c6 b t\u22121 (x) = E L(R t\u22121 b (x)) , \u03c6 t (s) = E l\u223cb L(R t\u22121 b (s) + e l ) = E L(R t b (s)) .\nThe last equality follows by observing that the random position R t\u22121 b (s) + e l is distributed as R t b (s) when l is sampled from b.", "publication_ref": ["b22"], "figure_ref": [], "table_ref": []}, {"heading": "Lemma 10 and Corollary 11 together imply:", "text": "Theorem 12 Assume L is proper and b \u2208 \u2206 k \u03b3 is an edge-over-random distribution. Then the potential \u03c6 b t , defined by the recurrence in (17), has the solution given in (31) in terms of random walks.\nBefore we can compute (31), we need to choose a loss function L. We next consider two options for the loss-the non-convex 0-1 error, and exponential loss.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Exponential Loss", "text": "The exponential loss serves as a smooth convex proxy for discontinuous non-convex 0-1 error (16) that we would ultimately like to bound, and is given by\nL exp \u03b7 (s) = k \u2211 l=2 e \u03b7(s l \u2212s 1 ) . (32\n)\nThe parameter \u03b7 can be thought of as the weight in each round, that is, \u03b1 t = \u03b7 in each round. Then notice that the weighted state f t of the examples, defined in ( 19), is related to the unweighted states s t as f t (l) = \u03b7s t (l). Therefore the exponential loss function in (32) directly measures the loss of the weighted state as\nL exp (f t ) = k \u2211 l=2 e f t (l)\u2212 f t (1) . (33\n)\nBecause of this correspondence, the optimal strategy with the loss function L exp and \u03b1 t = \u03b7 is the same as that using loss L exp \u03b7 and \u03b1 t = 1. We study the latter setting so that we may use the results derived earlier. With the choice of the exponential loss L exp \u03b7 , the potentials are easily computed, and in fact have a closed form solution. The proof by induction is straightforward. By tuning the weight \u03b7, each a l can be always made less than 1. This ensures the exponential loss decays exponentially with rounds. In particular, when B = U \u03b3 (so that the condition is (C eor , U \u03b3 )), the relevant potential \u03c6 t (s) or \u03c6 t (f) is given by\n\u03c6 t (s) = \u03c6 t ( f ) = \u03ba(\u03b3, \u03b7) t k \u2211 l=2 e \u03b7(s l \u2212s 1 ) = \u03ba(\u03b3, \u03b7) t k \u2211 l=2 e f l \u2212 f 1 (34\n)\nwhere\n\u03ba(\u03b3, \u03b7) = 1 + (1 \u2212 \u03b3) k e \u03b7 + e \u2212\u03b7 \u2212 2 \u2212 1 \u2212 e \u2212\u03b7 \u03b3. (35\n)\nThe cost-matrix output by the OS algorithm can be simplified by rescaling, or adding the same number to each coordinate of a cost vector, without affecting the constraints it imposes on a weak classifier, to the following form\nC(i, l) = (e \u03b7 \u2212 1) e \u03b7(s l \u2212s 1 ) if l > 1, (e \u2212\u03b7 \u2212 1) \u2211 k l=2 e \u03b7(s l \u2212s 1 ) if l = 1.\nUsing the correspondence between unweighted and weighted states, the above may also be rewritten as:\nC(i, l) = (e \u03b7 \u2212 1) e f l \u2212 f 1 if l > 1, (e \u2212\u03b7 \u2212 1) \u2211 k l=2 e f l \u2212 f 1 if l = 1. (36\n)\nWith such a choice, Theorem 9 and the form of the potential guarantee that the average loss\n1 m m \u2211 i=1 L exp \u03b7 (s t (i)) = 1 m m \u2211 i=1 L exp (f t (i))(37)\nof the states changes by a factor of at most \u03ba (\u03b3, \u03b7) every round. Therefore the final loss, which upper bounds the error, that is, the fraction of misclassified training examples, is at most (k \u2212 1)\u03ba (\u03b3, \u03b7) T . Since this upper bound holds for any value of \u03b7, we may tune it to optimize the bound. Setting \u03b7 = ln (1 + \u03b3), the error can be upper bounded by (k \u2212 1)e \u2212T \u03b3 2 /2 .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Zero-one Loss", "text": "There is no simple closed form solution for the potential when using the zero-one loss L err (16). However, we may compute the potentials efficiently as follows. To compute \u03c6 b t (s), we need to find the probability that a random walk (making steps according to b) of length t in Z k , starting at s will end up in a region where the loss function is 1. Any such random walk will consist of x l steps in direction e l where the non-negative \u2211 l x l = t. The probability of each such path is \u220f l b x l l . Further, there are exactly t x 1 ,...,x k such paths. Starting at state s, such a path will lead to a correct answer only if s 1 + x 1 > s l + x l for each l > 1. Hence we may write the potential \u03c6 b t (s) as\n\u03c6 b t (s) = 1 \u2212 t \u2211 x 1 ,...,x k t x 1 ,...,x k \u220f k l=1 b x l l s.t. x 1 + . . . + x k = t \u2200l : x l \u2265 0 \u2200l : x l + s l \u2264 x 1 + s 1 .\nSince the x l 's are restricted to be integers, this problem is presumably hard. In particular, the only algorithms known to the authors that take time logarithmic in t is also exponential in k. However, by using dynamic programming, we can compute the summation in time polynomial in |s l |, t and k.\nIn fact, the run time is always O(t 3 k), and at least \u2126(tk).\nThe bounds on error we achieve, although not in closed form, are much tighter than those obtainable using exponential loss. The exponential loss analysis yields an error upper bound of (k \u2212 1)e \u2212T \u03b3 2 /2 . Using a different initial distribution, Schapire and Singer (1999) achieve the slightly better bound (k \u2212 1)e \u2212T \u03b3 2 /2 . However, when the edge \u03b3 is small and the number of rounds are few, each bound is greater than 1 and hence trivial. On the other hand, the bounds computed by the above dynamic program are sensible for all values of k, \u03b3 and T . When b is the \u03b3-biased uniform distribution\nb = ( 1\u2212\u03b3 k +\u03b3, 1\u2212\u03b3 k , 1\u2212\u03b3 k , . . . , 1\u2212\u03b3 k )\na table containing the error upper bound \u03c6 b T (0) for k = 6, \u03b3 = 0 and small values for the number of rounds T is shown in Figure 2(a); note that with the exponential loss, the bound is always 1 if the edge \u03b3 is 0. Further, the bounds due to the exponential loss analyses seem to imply that the dependence of the error on the number of labels is monotonic. However, a plot of the tighter bounds with edge \u03b3 = 0.1, number of rounds T = 10 against various values of k, shown in Figure 2(b), indicates that the true dependence is more complicated. Therefore the tighter analysis also provides qualitative insights not obtainable via the exponential loss bound.", "publication_ref": ["b24"], "figure_ref": ["fig_2", "fig_2"], "table_ref": []}, {"heading": "Solving for the Minimal Weak Learning Condition", "text": "In the previous section we saw how to find the optimal boosting strategy when using any fixed edge-over-random condition. However as we have seen before, these conditions can be stronger than necessary, and therefore lead to boosting algorithms that require additional assumptions. Here we show how to compute the optimal algorithm while using the weakest weak learning condition, provided by (13), or equivalently the condition used by AdaBoost.MR, (C MR , B MR \u03b3 ). Since there are two possible formulations for the minimal condition, it is not immediately clear which to use to compute the optimal boosting strategy. To resolve this, we first show that the optimal boosting strategy based on any formulation of a necessary and sufficient weak learning condition is the same. Having resolved this ambiguity, we show how to compute this strategy for the exponential loss and 0-1 error using the first formulation. \nb = ( 1\u2212\u03b3 k + \u03b3, 1\u2212\u03b3 k , 1\u2212\u03b3 k , . . . , 1\u2212\u03b3 k ). (a)\n: Potential values (rounded to two decimal places) for different number of rounds T using \u03b3 = 0 and k = 6. These are bounds on the error, and less than 1 even when the edge and number of rounds are small. (b): Potential values for different number of classes k, with \u03b3 = 0.1, and T = 10. These are tight estimates for the optimal error, and yet not monotonic in the number of classes.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Game-theoretic Equivalence of Necessary and Sufficient Weak-learning Conditions", "text": "In this section we study the effect of the weak learning condition on the game-theoretically optimal boosting strategy. We introduce the notion of game-theoretic equivalence between two weak learning conditions, that determines if the payoffs (15) of the optimal boosting strategies based on the two conditions are identical. This should hold whenever both games last for the same number of iterations T , for any value of T . This is different from the usual notion of equivalence between two conditions, which holds if any weak classifier space satisfies both conditions or neither condition. In fact we prove that game-theoretic equivalence is a broader notion; in other words, equivalence implies game-theoretic equivalence. A special case of this general result is that any two weak learning conditions that are necessary and sufficient, and hence equivalent to boostability, are also game-theoretically equivalent. In particular, so are the conditions of AdaBoost.MR and (13), and the resulting optimal Booster strategies enjoy equally good payoffs. We conclude that in order to derive the optimal boosting strategy that uses the minimal weak-learning condition, it is sound to use either of these two formulations.\nThe purpose of a weak learning condition (C , B) is to impose restrictions on the Weak-Learner's responses in each round. These restrictions are captured by subsets of the weak classifier space as follows. If Booster chooses cost-matrix C \u2208 C in a round, the Weak-Learner's response h is restricted to the subset S C \u2286 H all defined as\nS C = h \u2208 H all : C \u2022 1 h \u2264 C \u2022 B .\nThus, a weak learning condition is essentially a family of subsets of the weak classifier space. Further, smaller subsets mean fewer options for Weak-Learner, and hence better payoffs for the optimal boosting strategy. Based on this idea, we may define when a weak learning condition (C 1 , B 1 ) is game-theoretically stronger than another condition (C 2 , B 2 ) if the following holds: For every subset S C 2 in the second condition (that is C 2 \u2208 C 2 ), there is a subset S C 1 in the first condition (that is C 1 \u2208 C 1 ), such that S C 1 \u2286 S C 2 . Mathematically, this may be written as follows:\n\u2200C 1 \u2208 C 1 , \u2203C 2 \u2208 C 2 : S C 1 \u2286 S C 2 .\nIntuitively, a game theoretically stronger condition will allow Booster to place similar or stricter restrictions on Weak-Learner in each round. Therefore, the optimal Booster payoff using a gametheoretically stronger condition is at least equally good, if not better. It therefore follows that if two conditions are both game-theoretically stronger than each other, the corresponding Booster payoffs must be equal, that is they must be game-theoretically equivalent.\nNote that game-theoretic equivalence of two conditions does not mean that they are identical as families of subsets, for we may arbitrarily add large and \"useless\" subsets to the two conditions without affecting the Booster payoffs, since these subsets will never be used by an optimal Booster strategy. In fact we next show that game-theoretic equivalence is a broader notion than just equivalence.\nTheorem 14 Suppose (C 1 , B 1 ) and (C 2 , B 2 ) are two equivalent weak learning conditions, that is, every space H satisfies both or neither condition. Then each condition is game-theoretically stronger than the other, and hence game-theoretically equivalent.\nProof We argue by contradiction. Assume that despite equivalence, the first condition (without loss of generality) includes a particularly hard subset S C 1 \u2286 H all , C 1 \u2208 C 1 which is not smaller than any subset in the second condition. In particular, for every subset S C 2 , C 2 \u2208 C 2 in the second condition is satisfied by some weak classifier h C 2 not satisfying the hard subset in the first condition:\nh C 2 \u2208 S C 2 \\ S C 1 . Therefore, the space H = {h C 2 : C 2 \u2208 C 2 } ,\nformed by just these classifiers satisfies the second condition, but has an empty intersection with S C 1 . In other words, H satisfies the second but not the first condition, a contradiction to their equivalence.\nAn immediate corollary is the game theoretic equivalence of necessary and equivalent conditions. Therefore, in deriving the optimal Booster strategy, it is sound to work with either AdaBoost.MR's condition or (13). In the next section, we actually compute the optimal strategy using the latter formulation.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Optimal Strategy with the Minimal Conditions", "text": "In this section we compute the optimal Booster strategy that uses the minimum weak learning condition provided in (13). We choose this instead of AdaBoost.MR's condition because this description is more closely related to the edge-over-random conditions, and the resulting algorithm has a close relationship to the ones derived for fixed edge-over-random conditions, and therefore more insightful. However, this formulation does not state the condition as a single pair (C, B), and therefore we cannot directly use the result of Theorem 9. Instead, we define new potentials and a modified OS strategy that is still nearly optimal, and this constitutes the first part of this section. In the second part, we show how to compute these new potentials and the resulting OS strategy.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "MODIFIED POTENTIALS AND OS STRATEGY", "text": "The condition in ( 13) is not stated as a single pair (C eor , B), but uses all possible edge-over-random baselines B \u2208 B eor \u03b3 . Therefore, we modify the definitions (17) of the potentials accordingly to extract an optimal Booster strategy. Recall that \u2206 k \u03b3 is defined in (26) as the set of all edge-over-random distributions which constitute the rows of edge-over-random baselines B \u2208 B eor \u03b3 . Using these, define new potentials \u03c6 t (s) as follows:\n\u03c6 t (s) = min c\u2208C eor 0 max b\u2208\u2206 k \u03b3 max p\u2208\u2206{1,...,k} E l\u223cp [\u03c6 t\u22121 (s + e l )] s.t. E l\u223cp [c(l)] \u2264 b, c .(38)\nThe main difference between ( 38) and ( 17) is that while the older potentials were defined using a fixed vector b corresponding to some row in the fixed baseline B, the new definition takes the maximum over all possible rows b \u2208 \u2206 k \u03b3 that an edge-over-random baseline B \u2208 B eor \u03b3 may have. As before, we may write the recurrence in (38) in its dual form\n\u03c6 t (s) = min c\u2208C eor 0 max b\u2208\u2206 k \u03b3 k max l=1 {\u03c6 t\u22121 (s + e l ) \u2212 (c(l) \u2212 c, b )} .\nThe proof is very similar to that of Lemma 8 and is omitted. We may now define a new OS strategy that chooses a cost-matrix in round t analogously:\nC t (i) \u2208 argmin c\u2208C eor 0 max b\u2208\u2206 k \u03b3 k max l=1 {\u03c6 t\u22121 (s + e l ) \u2212 (c(l) \u2212 c, b )} . (39\n)\nwhere recall that s t (i) denotes the state vector (defined in (18)) of example i. With this strategy, we can show an optimality result very similar to Theorem 9.\nTheorem 16 Suppose the weak-learning condition is given by (13). Let the potential functions \u03c6 b t be defined as in (38), and assume the Booster employs the modified OS strategy, choosing \u03b1 t = 1 and C t as in (39) in each round t. Then the average potential of the states,\n1 m m \u2211 i=1 \u03c6 T \u2212t (s t (i)) ,\nnever increases in any round. In particular, the loss suffered after T rounds of play is at most \u03c6 T (0). Further, for any \u03b5 > 0, when the loss function satisfies (24) and the number of examples m is as large as in (25), no Booster strategy can guarantee to achieve less than \u03c6 T (0) \u2212 \u03b5 loss in T rounds.\nThe proof is very similar to that of Theorem 9 and is omitted.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "COMPUTING THE NEW POTENTIALS", "text": "Here we show how to compute the new potentials. The resulting algorithms will require exponential time, and we provide some empirical evidence showing that this might be necessary. Finally, we show how to carry out the computations efficiently in certain special situations. An Exponential Time Algorithm. Here we show how the potentials may be computed as the expected loss of some random walk, just as we did for the potentials arising with fixed edge-over-random conditions. The main difference is there will be several random walks to choose from.\nWe first begin by simplifying the recurrence (38), and expressing the optimal cost matrix in (39) in terms of the potentials, just as we did in Lemma 10 for the case of fixed edge-over-random conditions.\nLemma 17 Assume L is proper. Then the recurrence (38) may be simplified as\n\u03c6 t (s) = max b\u2208\u2206 k \u03b3 E l\u223cb [\u03c6 t\u22121 (s + e l )] .(40)\nFurther, if the cost matrix C t is chosen as follows:\nC t (i, l) = \u03c6 T \u2212t\u22121 (s t (i) + e l ),(41)\nthen C t satisfies the condition in (39).\nThe proof is very similar to that of Lemma 10 and is omitted. Equation ( 41) implies that, as before, computing the optimal Booster strategy reduces to computing the new potentials. One computational difficulty created by the new definitions (38) or ( 40) is that they require infinitely many possible distributions b \u2208 \u2206 k \u03b3 to be considered. We show that we may in fact restrict our attention to only finitely many of such distributions described next.\nAt any state s and number of remaining iterations t, let \u03c0 be a permutation of the coordinates {2, . . . , k} that sorts the potential values:\n\u03c6 t\u22121 s + e \u03c0(k) \u2265 \u03c6 t\u22121 s + e \u03c0(k\u22121) \u2265 . . . \u2265 \u03c6 t\u22121 s + e \u03c0(2) .(42)\nFor any permutation \u03c0 of the coordinates {2, . . . , k}, let b \u03c0 a denote the \u03b3-biased uniform distribution on the\na coordinates {1, \u03c0 k , \u03c0 k\u22121 , . . . , \u03c0 k\u2212a+2 }: b \u03c0 a (l) = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 1\u2212\u03b3 a + \u03b3 if l = 1 1\u2212\u03b3 a if l \u2208 {\u03c0 k , . . . , \u03c0 k\u2212a+2 } 0 otherwise. (43\n)\nThen, the next lemma shows that we may restrict our attention to only the distributions b \u03c0 2 , . . . , b \u03c0 k when evaluating the recurrence in (40).\nLemma 18 Fix a state s and remaining rounds of boosting t. Let \u03c0 be a permutation of the coordinates {2, . . . , k} satisfying (42), and define b \u03c0 a as in (43). Then the recurrence (40) may be simplified as follows:\n\u03c6 t (s) = max b\u2208\u2206 k \u03b3 E l\u223cb [\u03c6 t\u22121 (s + e l )] = max 2\u2264a\u2264k E l\u223cb \u03c0 a [\u03c6 t\u22121 (s + e l )] .(44)\nProof Assume (by relabeling the coordinates if necessary) that \u03c0 is the identity permutation, that is, \u03c0(2) = 2, . . . , \u03c0(k) = k. Observe that the right hand side of ( 40) is at least as much the right hand side of ( 44) since the former considers more distributions. We complete the proof by showing that the former is also at most the latter. By (40), we may assume that some optimal b satisfies\nb(k) = \u2022 \u2022 \u2022 = b(k \u2212 a + 2) = b(1) \u2212 \u03b3, b(k \u2212 a + 1) \u2264 b(1) \u2212 \u03b3, b(k \u2212 a) = \u2022 \u2022 \u2022 = b(2) = 0.\nTherefore, b is a distribution supported on a + 1 elements, with the minimum weight placed on element\nk \u2212 a + 1. This implies b(k \u2212 a + 1) \u2208 [0, 1/(a + 1)]. Now, E l\u223cb [\u03c6 t\u22121 (s + e l )\n] may be written as\n\u03b3 \u2022 \u03c6 t\u22121 (s + e 1 ) + b(k \u2212 a + 1)\u03c6 t\u22121 (s + e k\u2212a+1 ) + (1 \u2212 \u03b3 \u2212 b(k \u2212 a + 1)) \u03c6 t\u22121 (s + e 1 ) + \u03c6 t\u22121 (s + e k\u2212a+2 ) + . . . \u03c6 t\u22121 (s + e k ) a = \u03b3 \u2022 \u03c6 t\u22121 (s + e 1 ) + b(k \u2212 a + 1) 1 \u2212 \u03b3 \u03c6 t\u22121 (s + e k\u2212a+1 ) + (1 \u2212 \u03b3) 1 \u2212 b(k \u2212 a + 1) 1 \u2212 \u03b3 \u03c6 t\u22121 (s + e 1 ) + \u03c6 t\u22121 (s + e k\u2212a+2 ) + . . . \u03c6 t\u22121 (s + e k ) a\nReplacing b(k \u2212 a + 1) by x in the above expression, we get a linear function of x. When restricted to [0, 1/(a + 1)] the maximum value is attained at a boundary point. For x = 0, the expression becomes \u03b3 \u2022 \u03c6 t\u22121 (s + e 1 ) + (1 \u2212 \u03b3) \u03c6 t\u22121 (s + e 1 ) + \u03c6 t\u22121 (s + e k\u2212a+2 ) + . . . \u03c6 t\u22121 (s + e k ) a .\nFor x = 1/(a + 1), the expression becomes\n\u03b3 \u2022 \u03c6 t\u22121 (s + e 1 ) + (1 \u2212 \u03b3) \u03c6 t\u22121 (s + e 1 ) + \u03c6 t\u22121 (s + e k\u2212a+1 ) + . . . \u03c6 t\u22121 (s + e k ) a + 1 . Since b(k \u2212 a + 1) lies in [0, 1/(a + 1)]\n, the optimal value is at most the maximum of the two. However each of these last two expressions is at most the right hand side of (44), completing the proof.\nUnraveling (44), we find that \u03c6 t (s) is the expected loss of the final state reached by some random walk of t steps starting at state s. However, the number of possibilities for the random-walk is huge; indeed, the distribution at each step can be any of the k \u2212 1 possibilities b \u03c0 a for a \u2208 {2, . . . , k}, where the parameter a denotes the size of the support of the \u03b3-biased uniform distribution chosen at each step. In other words, at a given state s with t rounds of boosting remaining, the parameter a determines the number of directions the optimal random walk will consider taking; we will therefore refer to a as the degree of the random walk given (s,t). Now, the total number of states reachable in T steps is O T k\u22121 . If the degree assignment every such state, for every value of t \u2264 T is fixed in advance, a = {a(s,t) : t \u2264 T, s reachable}, we may identify a unique random walk R a,t (s) of length t starting at step s. Therefore the potential may be computed as \u03c6 t (s) = max a E R a,t (s) . A dynamic programming approach for computing (45) requires time and memory linear in the number of different states reachable by a random walk that takes T coordinate steps: O(T k\u22121 ). This is exponential in the data set size, and hence impractical. In the next two sections we show that perhaps there may not be any way of computing these efficiently in general, but provide efficient algorithms in certain special cases.\nHardness of Evaluating the Potentials. Here we provide empirical evidence for the hardness of computing the new potentials. We first identify a computationally easier problem, and show that even that is probably hard to compute. Equation ( 44) implies that if the potentials were efficiently computable, the correct value of the degree a could be determined efficiently. The problem of determining the degree a given the state s and remaining rounds t is therefore easier than evaluating the potentials. However, a plot of the degrees against states and remaining rounds, henceforth called a degree map, reveals very little structure that might be captured by a computationally efficient function.\nWe include three such degree maps in Figure 3. Only three classes k = 3 are used, and the loss function is 0-1 error. We also fix the number T of remaining rounds of boosting and the value of the edge \u03b3 for each plot. For ease of presentation, the 3-dimensional states s\n= (s 1 , s 2 , s 3 ) are compressed into 2-dimensional pixel coordinates (u = s 2 \u2212 s 1 , v = s 3 \u2212 s 2 ).\nIt can be shown that this does not take away information required to evaluate the potentials or the degree at any pixel (u, v). Further, only those states are considered whose compressed coordinates u, v lie in the range [\u2212T, T ]; in T rounds, these account for all the reachable states. The degrees are indicated on the plot by colors. Our discussion in the previous sections implies that the possible values of the degree is 2 or 3. When the degree at a pixel (u, v) is 3, the pixel is colored green, and when the degree is 2, it is colored black.\nNote that a random walk over the space s \u2208 R 3 consisting of distributions over coordinate steps {(1, 0, 0), (0, 1, 0), (0, 0, 1)} translates to a random walk over (u, v) \u2208 R 2 where each step lies in the set {(\u22121, \u22121), (1, 0), (0, 1)}. In Figure 3, these correspond to the directions diagonally down, up or right. Therefore at a black pixel, the random walk either chooses between diagonally down and up, or between diagonally down and right, with probabilities {1/2 + \u03b3/2, 1/2 \u2212 \u03b3/2}. On the other hand, at a green pixel, the random walk chooses among diagonally down, up and right with probabilities (\u03b3 + (1 \u2212 \u03b3)/3, (1 \u2212 \u03b3)/3, (1 \u2212 \u03b3)/3). The degree maps are shown for varying values of T and the edge \u03b3. While some patterns emerge for the degrees, such as black or green depending on the parity of u or v, the authors found the region near the line u = v still too complex to admit any solution apart from a brute-force computation.\nWe also plot the potential values themselves in Figure 4 against different states. In each plot, the number of iterations remaining, T , is held constant, the number of classes is chosen to be 3, and the edge \u03b3 = 0. The states are compressed into pixels as before, and the potential is plotted against each pixel, resulting in a 3-dimensional surface. We include two plots, with different values for T . The surface is irregular for T = 3 rounds, but smoother for 20 rounds, admitting some hope for approximation.\nAn alternative approach would be to approximate the potential \u03c6 t by the potential \u03c6 b t for some fixed b \u2208 \u2206 k \u03b3 corresponding to some particular edge-over-random condition. Since \u03c6 t \u2265 \u03c6 b t for all edge-over-random distributions b, it is natural to approximate by choosing b that maximizes the fixed edge-over-random potential. (It can be shown that this b corresponds to the \u03b3-biased uniform distribution.) Two plots of comparing the potential values at 0, \u03c6 T (0) and max b \u03c6 b T (0), which correspond to the respective error upper bounds, is shown in Figure 5. In the first plot, the number of classes k is held fixed at 6, and the values are plotted for different values of iterations T . In the second plot, the number of classes vary, and the number of iterations is held at 10. Both plots show that the difference in the values is significant, and hence max b \u03c6 b T (0) would be a rather optimistic upper bound on the error when using the minimal weak learning condition.\nIf we use exponential loss (32), the situation is not much better. The degree maps for varying values of the weight parameter \u03b7 against fixed values of edge \u03b3 = 0.1, rounds remaining T = 20 and number of classes k = 3 are plotted in Figure 6. Although the patterns are simple, with the degree 3 pixels forming a diagonal band, we found it hard to prove this fact formally, or compute the exact boundary of the band. However the plots suggest that when \u03b7 is small, all pixels have degree 3. We next find conditions under which this opportunity for tractable computation exists. Efficient Computation in Special Cases. Here we show that when using the exponential loss, if the edge \u03b3 is very small, then the potentials can be computed efficiently. We first show an intermediate result. We already observed empirically that when the weight parameter \u03b7 is small, the degrees all become equal to k. Indeed, we can prove this fact.\nLemma 19 If the loss function being used is exponential loss (32) and the weight parameter \u03b7 is small compared to the number of rounds\n\u03b7 \u2264 1 4 min 1 k \u2212 1 , 1 T ,(46)\nthen the optimal value of the degree a in (44) is always k. Therefore, in this situation, the potential \u03c6 t using the minimal weak learning condition is the same as the potential \u03c6 u t using the \u03b3-biased uniform distribution u,\nu = 1 \u2212 \u03b3 k + \u03b3, 1 \u2212 \u03b3 k , . . . , 1 \u2212 \u03b3 k ,(47)\nand hence can be efficiently computed.\nProof We show \u03c6 t = \u03c6 u t by induction on the remaining number t of boosting iterations. The base case holds since, by definition,\n\u03c6 0 = \u03c6 u 0 = L exp \u03b7 . Assume, inductively that \u03c6 t\u22121 (s) = \u03c6 u t\u22121 (s) = \u03ba(\u03b3, \u03b7) t\u22121 k \u2211 l=2 e \u03b7(s l \u2212s 1 ) ,(48)\nwhere the second equality follows from (34). We show that\n\u03c6 t (s) = E l\u223cu [\u03c6 t\u22121 (s + e l )] .(49)\nBy the inductive hypothesis and ( 27), the right hand side of ( 49) is in fact equal to \u03c6 u t , and we will have shown \u03c6 t = \u03c6 u t . The proof will then follow by induction. In order to show (49), by Lemma 18, it suffices to show that the optimal degree a maximizing the right hand side of ( 44) is always k:\nE l\u223cb \u03c0 a [\u03c6 t\u22121 (s + e l )] \u2264 E l\u223cb \u03c0 k [\u03c6 t\u22121 (s + e l )] .(50)\nBy ( 48), \u03c6 t\u22121 (s + e l 0 ) may be written as \u03c6 t\u22121 (s) + \u03ba(\u03b3, \u03b7) t\u22121 \u2022 \u03be l 0 , where the term \u03be l 0 is:\n\u03be l 0 = (e \u03b7 \u2212 1)e \u03b7(s l 0 \u2212s 1 ) if l 0 = 1, (e \u2212\u03b7 \u2212 1) \u2211 k l=2 e \u03b7(s l \u2212s 1 ) if l 0 = 1.\nTherefore (50) is the same as:\nE l\u223cb \u03c0 a [\u03be l ] \u2264 E l\u223cb \u03c0 k [\u03be l ]\n. Assume (by relabeling if necessary) that \u03c0 is the identity permutation on coordinates {2, . . . , k}. Then the expression E l\u223cb \u03c0 a [\u03be l ] can be written as\nE l\u223cb \u03c0 a [\u03be l ] = 1 \u2212 \u03b3 a + \u03b3 \u03be 1 + k \u2211 l=k\u2212a+2 1 \u2212 \u03b3 a \u03be l = \u03b3\u03be 1 + (1 \u2212 \u03b3) \u03be 1 + \u2211 k l=k\u2212a+2 \u03be l a .\nIt suffices to show that the term in curly brackets is maximized when a = k. We will in fact show that the numerator of the term is negative if a < k, and non-negative for a = k, which will complete our proof. Notice that the numerator can be written as\n(e \u03b7 \u2212 1) k \u2211 l=k\u2212a+2 e \u03b7(s l \u2212s 1 ) \u2212 (1 \u2212 e \u2212\u03b7 ) k \u2211 l=2 e \u03b7(s l \u2212s 1 ) = (e \u03b7 \u2212 1) k \u2211 l=k\u2212a+2 e \u03b7(s l \u2212s 1 ) \u2212 k \u2211 l=2 e \u03b7(s l \u2212s 1 ) + (e \u03b7 \u2212 1) \u2212 (1 \u2212 e \u2212\u03b7 ) k \u2211 l=2 e \u03b7(s l \u2212s 1 ) = e \u03b7 + e \u2212\u03b7 \u2212 2 k \u2211 l=2 e \u03b7(s l \u2212s 1 ) \u2212 (e \u03b7 \u2212 1) k\u2212a+1 \u2211 l=2 e \u03b7(s l \u2212s 1 ) .\nWhen a = k, the second summation disappears, and we are left with a non-negative expression. However when a < k, the second summation is at least e \u03b7(s 2 \u2212s 1 ) . Since t \u2264 T , and in t iterations the absolute value of any state coordinate |s t (l)| is at most T , the first summation is at most (k \u2212 1)e 2\u03b7T and the second summation is at least e \u22122\u03b7T . Therefore the previous expression is at most\n(k \u2212 1) e \u03b7 + e \u2212\u03b7 \u2212 2 e 2\u03b7T \u2212 (e \u03b7 \u2212 1)e \u22122\u03b7T = (e \u03b7 \u2212 1)e \u22122\u03b7T (k \u2212 1)(1 \u2212 e \u2212\u03b7 )e 4\u03b7T \u2212 1 .\nWe show that the term in curly brackets is negative. Firstly, using e x \u2265 1 + x, we have 1 \u2212 e \u2212\u03b7 \u2264 \u03b7 \u2264 1/(4(k \u2212 1)) by choice of \u03b7. Therefore it suffices to show that e 4\u03b7T < 4. By choice of \u03b7 again, e 4\u03b7T \u2264 e 1 < 4. This completes our proof.\nThe above lemma seems to suggest that under certain conditions, a sort of degeneracy occurs, and the optimal Booster payoff ( 15) is nearly unaffected by whether we use the minimal weak learning condition, or the condition (C eor , U \u03b3 ). Indeed, we next prove this fact.\nTheorem 20 Suppose the loss function is as in Lemma 19, and for some parameter \u03b5 > 0, the number of examples m is large enough\nm \u2265 Te 1/4 \u03b5 . (51\n)\nConsider the minimal weak learning condition (13), and the fixed edge-over-random condition (C eor , U \u03b3 ) corresponding to the \u03b3-biased uniform baseline U \u03b3 . Then the optimal booster payoffs using either condition is within \u03b5 of each other.\nProof We show that the OS strategies arising out of either condition is the same. In other words, at any iteration t and state s t , both strategies play the same cost matrix and enforce the same constraints on the response of Weak-Learner. The theorem will then follow if we can invoke Theorems 9 and 16. For that, the number of examples needs to be as large as in ( 25). The required largeness would follow from (51) if the loss function satisfied ( 24) with (L, T ) at most exp(1/4). Since the largest discrepancy in losses between two states reachable in T iterations is at most e \u03b7T \u2212 0, the bound follows from the choice of \u03b7 in (46). Therefore, it suffices to show the equivalence of the OS strategies corresponding to the two weak learning conditions. We first show both strategies play the same cost-matrix. Lemma 19 states that the potential function using the minimal weak learning condition is the same as when using the fixed condition (C eor , U \u03b3 ): \u03c6 t = \u03c6 u t , where u is as in (47). Since, according to ( 28) and ( 41), given a state s t and iteration t, the two strategies choose cost matrices that are identical functions of the respective potentials, by the equivalence of the potential functions, the resulting cost matrices must be the same.\nEven with the same cost matrix, the two different conditions could be imposing different constraints on Weak-Learner, which might affect the final payoff. For instance, with the baseline U \u03b3 , Weak-Learner has to return a weak classifier h satisfying\nC t \u2022 1 h \u2264 C t \u2022 U \u03b3 ,\nwhereas with the minimal condition, the constraint on h is\nC t \u2022 1 h \u2264 max B\u2208B eor \u03b3 C t \u2022 B.\nIn order to show that the constraints are the same we therefore need to show that for the common cost matrix C t chosen, the right hand side of the two previous expressions are the same:\nC t \u2022 U \u03b3 = max B\u2208B eor \u03b3 C t \u2022 B eor \u03b3 . (52\n)\nWe will in fact show the stronger fact that the equality holds for every row separately:\n\u2200i : C t (i), u = max b\u2208\u2206 k \u03b3 C t (i), b .(53)\nTo see this, first observe that the choice of the optimal cost matrix C t in (41) implies the following identity\nC t (i), b = E l\u223cb [\u03c6 T \u2212t\u22121 (s t (i) + e l )] .\nOn the other hand, (44) and Lemma 19 together imply that the distribution b maximizing the right hand side of the above is the \u03b3-biased uniform distribution, from which (53) follows. Therefore, the constraints placed on Weak-Learner by the cost-matrix C t is the same whether we use minimum weak learning condition or the fixed condition (C eor , U \u03b3 ).\nOne may wonder why \u03b7 would be chosen so small, especially since the previous theorem indicates that such choices for \u03b7 lead to degeneracies. To understand this, recall that \u03b7 represents the size of the weights \u03b1 t chosen in every round, and was introduced as a tunable parameter to help achieve the best possible upper bound on zero-one error. More precisely, recall that the exponential loss L exp \u03b7 (s) of the unweighted state, defined in (32), is equal to the exponential loss L exp (f) on the weighted state, defined in (33), which in turn is an upper bound on the error L err (f T ) of the final weighted state f T . Therefore the potential value \u03c6 T (0) based on the exponential loss L exp \u03b7 is an upper bound on the minimum error attainable after T rounds of boosting. At the same time, \u03c6 T (0) is a function of \u03b7. Therefore, we may tune this parameter to attain the best bound possible. Even with this motivation, it may seem that a properly tuned \u03b7 will not be as small as in Lemma 19, especially since it can be shown that the resulting loss bound \u03c6 T (0) will always be larger than a fixed constant (depending on \u03b3, k), no matter how many rounds T of boosting is used. However, the next result identifies conditions under which the tuned value of \u03b7 is indeed as small as in Lemma 19. This happens when the edge \u03b3 is very small, as is described in the next theorem. Intuitively, a weak classifier achieving small edge has low accuracy, and a low weight reflects Booster's lack of confidence in this classifier.\nTheorem 21 When using the exponential loss function (32), and the minimal weak learning condition (13), the loss upper bound \u03c6 T (0) provided by Theorem 16 is more than 1 and hence trivial unless the parameter \u03b7 is chosen sufficiently small compared to the edge \u03b3:\n\u03b7 \u2264 k\u03b3 1 \u2212 \u03b3 . (54\n)\nIn particular, when the edge is very small:\n\u03b3 \u2264 min 1 2 , 1 8k min 1 k , 1 T , (55\n)\nthe value of \u03b7 needs to be as small as in (46).\nProof Comparing solutions ( 45) and ( 31) to the potentials corresponding to the minimal weak learning condition and a fixed edge-over-random condition, we may conclude that the loss bound \u03c6 T (0) is in the former case is larger than \u03c6 b T (0), for any edge-over-random distribution b \u2208 \u2206 k \u03b3 . In particular, when b is set to be the \u03b3-biased uniform distribution u, as defined in ( 47), we get \u03c6 T (0) \u2265 \u03c6 u T (0). Now the latter bound, according to (34), is \u03ba(\u03b3, \u03b7) T , where \u03ba is defined as in (35). Therefore, to get non-trivial loss bounds which are at most 1, we need to choose \u03b7 such that \u03ba(\u03b3, \u03b7) \u2264 1. By ( 35), this happens when\n1 \u2212 e \u2212\u03b7 \u03b3 \u2265 e \u03b7 + e \u2212\u03b7 \u2212 2 1 \u2212 \u03b3 k i.e., k\u03b3 1 \u2212 \u03b3 \u2265 e \u03b7 + e \u2212\u03b7 \u2212 2 1 \u2212 e \u2212\u03b7 = e \u03b7 \u2212 1 \u2265 \u03b7.\nTherefore (54) holds. When \u03b3 is as small as in ( 55), then 1 \u2212 \u03b3 \u2264 1 2 , and therefore, by (54), the bound on \u03b7 becomes identical to that in (55).\nThe condition in the previous theorem, that of the existence of only a very small edge, is the most we can assume for most practical data sets. Therefore, in such situations, we can compute the optimal Booster strategy that uses the minimal weak learning conditions. More importantly, using this result, we derive, in the next section, a highly efficient and practical adaptive algorithm, that is, one that does not require any prior knowledge about the edge \u03b3, and will therefore work with any data set.", "publication_ref": [], "figure_ref": ["fig_4", "fig_4", "fig_5"], "table_ref": []}, {"heading": "Variable Edges", "text": "So far we have required Weak-Learner to beat random by at least a fixed amount \u03b3 > 0 in each round of the boosting game. In reality, the edge over random is larger initially, and gets smaller as the OS algorithm creates harder cost matrices. Therefore requiring a fixed edge is either unduly pessimistic or overly optimistic. If the fixed edge is too small, not enough progress is made in the initial rounds, and if the edge is too large, Weak-Learner fails to meet the weak-learning condition in latter rounds. We fix this by not making any assumption about the edges, but instead adaptively responding to the edges returned by Weak-Learner. In the rest of the section we describe the adaptive procedure, and the resulting loss bounds guaranteed by it.\nThe philosophy behind the adaptive algorithm is a boosting game where Booster and Weak Learner no longer have opposite goals, but cooperate to reduce error as fast as possible. However, in order to create a clean abstraction and separate implementations of the boosting algorithms and the weak learning procedures as much as possible, we assume neither of the players has any knowledge of the details of the algorithm employed by the other player. In particular Booster may only assume that Weak Learner's strategy is barely strong enough to guarantee boosting. Therefore, Booster's demands on the weak classifiers returned by Weak Learner should be minimal, and it should send the weak learning algorithm the \"easiest\" cost matrices that will ensure boostability. In turn, Weak Learner may only assume a very weak Booster strategy, and therefore return a weak classifier that performs as well as possible with respect to the cost matrix sent by Booster.\nAt a high level, the adaptive strategy proceeds as follows. At any iteration, based on the states of the examples and number of remaining rounds of boosting, Booster chooses the game-theoretically optimal cost matrix assuming only infinitesimal edges in the remaining rounds. Intuitively, Booster has no high expectations of Weak Learner, and supplies it the easiest cost matrices with which it may be able to boost. However, in the adaptive setting, Weak-Learner is no longer adversarial. Therefore, although only infinitesimal edges are anticipated by Booster, Weak Learner cooperates in returning weak classifiers that achieve as large edges as possible, which will be more than just inifinitesimal. Based on the exact edge received in each round, Booster chooses the weight \u03b1 t adaptively to reach the most favourable state possible. Therefore, Booster plays game theoretically assuming an adversarial Weak Learner and expecting only the smallest edges in the future rounds, although Weak Learner actually cooperates, and Booster adaptively exploits this favorable behavior as much as possible. This way the boosting algorithm remains robust to a poorly performing Weak Learner, and yet can make use of a powerful weak learning algorithm whenever possible.\nWe next describe the details of the adaptive procedure. With variable weights we need to work with the weighted state f t (i) of each example i, defined in (19). To keep the computations tractable, we will only be working with the exponential loss L exp (f) on the weighted states. We first describe how Booster chooses the cost-matrix in each round. Following that we describe how it adaptively computes the weights in each round based on the edge of the weak classifier received.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Choosing the Cost-matrix", "text": "As discussed before, at any iteration t and state f t Booster assumes that it will receive an infinitesimal edge \u03b3 in each of the remaining rounds. Since the step size is a function of the edge, which in turn is expected to be the same tiny value in each round, we may assume that the step size in each round will also be some fixed value \u03b7. We are therefore in the setting of Theorem 21, which states that the parameter \u03b7 in the exponential loss function (32) should also be tiny to get any non-trivial bound. But then the loss function satisfies the conditions in Lemma 19, and by Theorem 20, the game theoretically optimal strategy remains the same whether we use the minimal condition or (C eor , U \u03b3 ). When using the latter condition, the optimal choice of the cost-matrix at iteration t and state f t , according to (36), is\nC t (i, l) = (e \u03b7 \u2212 1) e f t\u22121 (i, j)\u2212 f t\u22121 (i,1) if l > 1, (e \u2212\u03b7 \u2212 1) \u2211 k j=2 e f t\u22121 (i, j)\u2212 f t\u22121 (i,1) if l = 1.\nFurther, when using the condition (C eor , U \u03b3 ), the average potential of the states f t (i), according to (34), is given by the average loss (37) of the state times \u03ba(\u03b3, \u03b7) T \u2212t , where the function \u03ba is defined in (35). Our goal is to choose \u03b7 as a function of \u03b3 so that \u03ba(\u03b3, \u03b7) is as small as possible. Now, there is no lower bound on how small the edge \u03b3 may get, and, anticipating the worst, it makes sense to choose an infinitesimal \u03b3, in the spirit of Freund (2001). Equation ( 35) then implies that the choice of \u03b7 should also be infinitesimal. Then the above choice of the cost matrix becomes the following (after some rescaling):\nC t (i, l) = lim \u03b7\u21920 C \u03b7 (i, l) \u25b3 = 1 \u03b7 (e \u03b7 \u2212 1) e f t\u22121 (i, j)\u2212 f t\u22121 (i,1) if l > 1, (e \u2212\u03b7 \u2212 1) \u2211 k j=2 e f t\u22121 (i, j)\u2212 f t\u22121 (i,1) if l = 1. = e f t\u22121 (i, j)\u2212 f t\u22121 (i,1) if l > 1, \u2212 \u2211 k j=2 e f t\u22121 (i, j)\u2212 f t\u22121 (i,1) if l = 1. (56\n)\nWe have therefore derived the optimal cost matrix played by the adaptive boosting strategy, and we record this fact.\nLemma 22 Consider the boosting game using the minimal weak learning condition (13). Then, in iteration t at state f t , the game-theoretically optimal Booster strategy chooses the cost matrix C t given in (56).\nWe next show how to adaptively choose the weights \u03b1 t .", "publication_ref": ["b8"], "figure_ref": [], "table_ref": []}, {"heading": "Adaptively Choosing Weights", "text": "Once Weak Learner returns a weak classifier h t , Booster chooses the optimum weight \u03b1 t so that the resulting states f t = f t\u22121 + \u03b1 t 1 ht are as favorable as possible, that is, minimizes the total potential of its states. By our previous discussions, these are proportional to the total loss given by Z t = \u2211 m i=1 \u2211 k l=2 e f t (i,l)\u2212 f t (i,1) . For any choice of \u03b1 t , the difference Z t \u2212 Z t\u22121 between the total loss in rounds t \u2212 1 and t is given by\n(e \u03b1 t \u2212 1) \u2211 i\u2208S \u2212 e f t\u22121 (i,h t (i))\u2212 f t\u22121 (i,1) \u2212 1 \u2212 e \u2212\u03b1 t \u2211 i\u2208S + L exp (f t\u22121 (i)) = (e \u03b1 t \u2212 1) A t \u2212 \u2212 1 \u2212 e \u2212\u03b1 t A t + = A t + e \u2212\u03b1 t + A t \u2212 e \u03b1 t \u2212 A t + + A t \u2212 ,\nwhere S + denotes the set of examples that h t classifies correctly, S \u2212 the incorrectly classified examples, and A t \u2212 , A t + denote the first and second summations, respectively. Therefore, the task of choosing \u03b1 t can be cast as a simple optimization problem minimizing the previous expression. In fact, the optimal value of \u03b1 t is given by the following closed form expression\n\u03b1 t = 1 2 ln A t + A t \u2212 .(57)\nWith this choice of weight, one can show (with some straightforward algebra) that the total loss of the state falls by a factor less than 1. In fact the factor is exactly\n(1 \u2212 c t ) \u2212 c 2 t \u2212 \u03b4 2 t ,(58)\nwhere\nc t = (A t + + A t \u2212 )/Z t\u22121 ,\nand \u03b4 t is the edge of the returned classifier h t on the supplied cost-matrix C t . Notice that the quantity c t is at most 1, and hence the factor (58) can be upper bounded by 1 \u2212 \u03b4 2 t . We next show how to compute the edge \u03b4 t . The definition of the edge depends on the weak learning condition being used, and in this case we are using the minimal condition (13). Therefore the edge \u03b4 t is the largest \u03b3 such that the following still holds\nC t \u2022 1 h \u2264 max B\u2208B eor \u03b3 C t \u2022 B.\nHowever, since C t is the optimal cost matrix when using exponential loss with a tiny value of \u03b7, we can use arguments in the proof of Theorem 20 to simplify the computation. In particular, eq. ( 52) implies that the edge \u03b4 t may be computed as the largest \u03b3 satisfying the following simpler inequality\n\u03b4 t = sup \u03b3 : C t \u2022 1 h t \u2264 C t \u2022 U \u03b3 = sup \u03b3 : C t \u2022 1 h t \u2264 \u2212\u03b3 m \u2211 i=1 k \u2211 l=2 e f t\u22121 (i,l)\u2212 f t\u22121 (i,1) =\u21d2 \u03b4 t = \u03b3 : C t \u2022 1 h t = \u2212\u03b3 m \u2211 i=1 k \u2211 l=2 e f t\u22121 (i,l)\u2212 f t\u22121 (i,1) =\u21d2 \u03b4 t = \u2212C t \u2022 1 h t \u2211 m i=1 \u2211 k l=2 e f t\u22121 (i,l)\u2212 f t\u22121 (i,1) = \u2212C t \u2022 1 h t Z t ,(59)\nwhere the first step follows by expanding C t \u2022 U \u03b3 . We have therefore an adaptive strategy which efficiently reduces error. We record our results.\nLemma 23 If the weight \u03b1 t in each round is chosen as in (57), and the edge \u03b4 t is given by (59), then the total loss Z t falls by the factor given in (58), which is at most 1 \u2212 \u03b4 2 t .\nThe choice of \u03b1 t in ( 57) is optimal, but depends on quantities other than just the edge \u03b4 t . We next show a way of choosing \u03b1 t based only on \u03b4 t that still causes the total loss to drop by a factor of 1 \u2212 \u03b4 2 t .\nLemma 24 Suppose cost matrix C t is chosen as in (56), and the returned weak classifier h t has edge \u03b4 t , that is,\nC t \u2022 1 h t \u2264 C t \u2022 U \u03b4 t .\nThen choosing any weight \u03b1 t > 0 for h t makes the loss Z t at most a factor\n1 \u2212 1 2 (e \u03b1 t \u2212 e \u2212\u03b1 t )\u03b4 t + 1 2 (e \u03b1 t + e \u2212\u03b1 t \u2212 2)\nof the previous loss Z t\u22121 . In particular by choosing\n\u03b1 t = 1 2 ln 1 + \u03b4 t 1 \u2212 \u03b4 t ,(60)\nthe drop factor is at most 1 \u2212 \u03b4 2 t .\nProof We borrow notation from earlier discussions. The edge-condition implies\nA t \u2212 \u2212 A t + = C t \u2022 1 h t \u2264 C t \u2022 U \u03b4 t = \u2212\u03b4 t Z t\u22121 =\u21d2 A t + \u2212 A t \u2212 \u2265 \u03b4 t Z t\u22121 .\nOn the other hand, the drop in loss after choosing h t with weight \u03b1 t is 1 \u2212 e \u2212\u03b1 t A t + \u2212 (e \u03b1 t \u2212 1)\nA t \u2212 = e \u03b1 t \u2212 e \u2212\u03b1 t 2 A t + \u2212 A t \u2212 \u2212 e \u03b1 t + e \u2212\u03b1 t \u2212 2 2 A t + + A t \u2212 .\nWe have already shown that A t + \u2212 A t \u2212 \u2265 \u03b4 t Z t\u22121 . Further, A t + + A t \u2212 is at most Z t\u22121 . Therefore the loss drops by a factor of at least\n1 \u2212 1 2 (e \u03b1 t \u2212 e \u2212\u03b1 t )\u03b4 t + 1 2 (e \u03b1 t + e \u2212\u03b1 t \u2212 2) = 1 2 (1 \u2212 \u03b4 t )e \u03b1 t + (1 + \u03b4 t )e \u2212\u03b1 t .\nTuning \u03b1 t as in ( 60) causes the drop factor to be at least 1 \u2212 \u03b4 2 t . Algorithm 1 contains pseudocode for the adaptive algorithm, and includes both ways of choosing \u03b1 t . We call both versions of this algorithm AdaBoost.MM. With the approximate way of choosing the step length in (61), AdaBoost.MM turns out to be identical to AdaBoost.M2 (Freund and Schapire, 1997) or AdaBoost.MR (Schapire and Singer, 1999), provided the weak classifier space is transformed in an appropriate way to be acceptable by AdaBoost.M2 or AdaBoost.MR. We emphasize that AdaBoost.MM and AdaBoost.M2 are products of very different theoretical considerations, and this similarity should be viewed as a coincidence arising because of the particular choice of loss function, infinitesimal edge and approximate step size. For instance, when the step sizes are chosen instead as in ( 62), the training error falls more rapidly, and the resulting algorithm is different.\nAs a summary of all the discussions in the section, we record the following theorem.\nTheorem 25 The boosting algorithm AdaBoost.MM, shown in Algorithm 1, is the optimal strategy for playing the adaptive boosting game, and is based on the minimal weak learning condition. Further if the edges returned in each round are \u03b4 1 , . . . , \u03b4 T , then the error after T rounds is\n(k \u2212 1) \u220f T t=1 1 \u2212 \u03b4 2 t \u2264 (k \u2212 1) exp \u2212(1/2) \u2211 T t=1 \u03b4 2 t .\nIn particular, if a weak hypothesis space is used that satisfies the optimal weak learning condition (13), for some \u03b3, then the edge in each round is large, \u03b4 t \u2265 \u03b3, and therefore the error after T rounds is exponentially small, (k \u2212 1)e \u2212T \u03b3 2 /2 . The theorem above states that as long as the minimal weak learning condition is satisfied, the error will decrease exponentially fast. Even if the condition is not satisfied, the error rate will keep falling rapidly provided the edges achieved by the weak classifiers are relatively high. However, our theory so far can provide no guarantees on these edges, and therefore it is not clear what is the best error rate achievable in this case, and how quickly it is achieved. The assumptions of boostability, and hence our minimal weak learning condition does not hold for the vast majority of practical data sets, and as such it is important to know what happens in such settings. In particular, an important requirement is empirical consistency, where we want that for any given weak classifier space, the algorithm converge, if allowed to run forever, to the weighted combination of classifiers that minimizes error on the training set. Another important criterion is universal consistency, which requires that the algorithm converge, when provided sufficient training data, to the classifier combination that minimizes error on the test data set. In the next section, we show that AdaBoost.MM satisfies such consistency requirements. Both the choice of the minimal weak learning condition as well as the setup of the adaptive game framework will play crucial roles in ensuring consistency. These results therefore provide evidence that game theoretic considerations can have strong statistical implications. \u2022 Initialize m \u00d7 k matrix f 0 (i, l) = 0 for i = 1, . . . , m, and l = 1, . . . , k. for t = 1 to T do \u2022 Choose cost matrix C t as follows:\nC t (i, l) = e f t\u22121 (i,l)\u2212 f t\u22121 (i,y i ) if l = y i , \u2212 \u2211 l =y i e f t\u22121 (i, j)\u2212 f t\u22121 (i,y i ) if l = 1.\n\u2022 Receive weak classifier h t : X \u2192 {1, . . . , k} from weak learning algorithm \u2022 Compute edge \u03b4 t as follows:\n\u03b4 t = \u2212 \u2211 m i=1 C t (i, h t (x i )) \u2211 m\ni=1 \u2211 l =y i e f t\u22121 (i,l)\u2212 f t\u22121 (i,y i )\n\u2022 Choose \u03b1 t either as\n\u03b1 t = 1 2 ln 1 + \u03b4 t 1 \u2212 \u03b4 t ,(61)\nor, for a slightly bigger drop in the loss, as\n\u03b1 t = 1 2 ln \u2211 i:h t (x i )=y i \u2211 l =y i e f t\u22121 (i,l)\u2212 f t\u22121 (i,y i ) \u2211 i:h t (x i ) =y i e f t\u22121 (i,h t (x i ))\u2212 f t\u22121 (i,y i )(62)\n\u2022 Compute f t as:\nf t (i, l) = f t\u22121 (i, l) + \u03b1 t 1 [h t (x i ) = l] .\nend for \u2022 Output weighted combination of weak classifiers F T : X \u00d7 {1, . . . , k} \u2192 R defined as:\nF T (x, l) = T \u2211 t=1 \u03b1 t 1 [h t (x) = l] .(63)\n\u2022 Based on F T , output a classifier H T : X \u2192 {1, . . . , k} that predicts as\nH T (x) = k argmax l=1 F T (x, l).", "publication_ref": ["b12", "b24"], "figure_ref": [], "table_ref": []}, {"heading": "Consistency of the Adaptive Algorithm", "text": "The goal in a classification task is to design a classifier that predicts with high accuracy on unobserved or test data. This is usually carried out by ensuring the classifier fits training data well without being overly complex. Assuming the training and test data are reasonably similar, one can show that the above procedure achieves high test accuracy, or is consistent. Here we work in a probabilistic setting that connects training and test data by assuming both consist of examples and labels drawn from a common, unknown distribution. Consistency for multiclass classification in the probabilistic setting has been studied by Tewari and Bartlett (2007), who show that, unlike in the binary setting, many natural approaches fail to achieve consistency. In this section, we show that AdaBoost.MM described in the previous section avoids such pitfalls and enjoys various consistency results. We begin by laying down some standard assumptions and setting up some notation. Then we prove our first result showing that our algorithm minimizes a certain exponential loss function on the training data at a fast rate. Next, we build upon this result and improve along two fronts: firstly we change our metric from exponential loss to the more relevant classification error metric, and secondly we show fast convergence on not just training data, but also the test set. For the proofs, we heavily reuse existing machinery in the literature.\nThroughout the rest of this section we consider the version of AdaBoost.MM that picks weights according to the approximate rule in (61). All our results most probably hold with the other rule for picking weights in (62) as well, but we did not verify that. These results hold without any boostability requirements on the space H of weak classifiers, and are therefore widely applicable in practice. While we do not assume any weak learning condition, we will require a fully cooperating Weak Learner. In particular, we will require that in each round Weak Learner picks the weak classifier suffering minimum cost with respect to the cost matrix provided by the boosting algorithm, or equivalently achieves the highest edge as defined in (59). Such assumptions are both necessary and standard in the literature, and are frequently met in practice.\nIn order to state our results, we will need to setup some notation. The space of examples will be denoted by X , and the set of labels by Y = {1, . . . , k}. We also fix a finite weak classifier space H consisting of classifiers h : X \u2192 Y . We will be interested in functions F : X \u00d7 Y \u2192 R that assign a score to every example and label pair. Important examples of such functions are the weighted majority combinations (63) output by the adaptive algorithm. In general, any such combination of the weak classifiers in space H is specified by some weight function \u03b1 : H \u2192 R; the resulting function is denoted by F \u03b1 : X \u00d7 Y \u2192 R, and satisfies:\nF \u03b1 (x, l) = \u2211 h\u2208H \u03b1(h)1 [h(x) = l] .\nWe will be interested in measuring the average exponential loss of such functions. To measure this, we introduce the risk operator:\nrisk(F) \u25b3 = 1 m m \u2211 i=1 \u2211 l =y i e F(x i ,l)\u2212F(x i ,y i ) .\nWith this setup, we can now state our simplest consistency result, which ensures that the algorithm converges to a weighted combination of classifiers in the space H that achieves the minimum exponential loss over the training set at an efficient rate.\nLemma 26 The risk of the predictions F T , as defined in (63), converges to that of the optimal predictions of any combination of the weak classifiers in H at the rate O(1/T ):\nrisk(F T ) \u2212 inf \u03b1:H \u2192R risk(F \u03b1 ) \u2264 C T ,\nwhere C is a constant depending only on the data set.\nA slightly stronger result would state that the average exponential loss when measured with respect to the test set, and not just the empirical set, also converges. The test set is generated by some target distribution D over example label pairs, and we introduce the risk D operator to measure the exponential loss for any function F : X \u00d7 Y \u2192 R with respect to D:\nrisk D (F) = E (x,y)\u223cD \u2211\nl =y e F(x,l)\u2212F(x,y) .\nWe show this stronger result holds if the function F T is modified to the functionF T : X \u00d7 Y \u2192 R that takes values in the range [0, \u2212C], for some large constant C:\nF T (x, l) \u25b3 = max \u2212C, F T (x, l) \u2212 max l \u2032 F T (x, l \u2032 ) . (64\n)\nLemma 27 IfF T is as in (64), and the number of rounds T is set to T m = \u221a m, then its risk D converges to the optimal value as m \u2192 \u221e with high probability:\nPr risk D (F T m ) \u2264 inf F:X \u00d7Y \u2192R risk D (F) + O m \u2212c \u2265 1 \u2212 1 m 2 ,\nwhere c > 0 is some absolute constant, and the probability is over the draw of training examples.\nWe prove Lemmas 26 and 27 by demonstrating a strong correspondence between AdaBoost.MM and binary AdaBoost, and then leveraging almost identical known consistency results for AdaBoost (Bartlett and Traskin, 2007). Our proofs will closely follow the exposition in Chapter 12 of Schapire and Freund (2012) on the consistency of AdaBoost, and are deferred to the appendix. So far we have focused on risk D , but a more desirable consistency result would state that the test error of the final classifier output by AdaBoost.MM converges to the Bayes optimal error. The test error is measured by the err D operator, and is given by\nerr D (H) = Pr (x,y)\u223cD [H(x) = y] .\nThe Bayes optimal classifier H opt is a classifier achieving the minimum error among all possible classifying functions err D (H opt ) = inf\nH:X \u2192Y err D (H),\nand we want our algorithm to output a classifier whose err D approaches err D (H opt ). In designing the algorithm, our main focus was on reducing the exponential loss, captured by risk D and risk. Unless these loss functions are aligned properly with classification error, we cannot hope to achieve optimal error. The next result shows that our loss functions are correctly aligned, or more technically Bayes consistent. In other words, if a scoring function F : X \u00d7 Y \u2192 R is close to achieving optimal risk D , then the classifier H : X \u2192 Y derived from it as follows:\nH(x) \u2208 argmax l\u2208Y F(x, y),(65)\nalso approaches the Bayes optimal error.\nLemma 28 Suppose F is a scoring function achieving close to optimal risk risk D (F) \u2264 inf\nF \u2032 :X \u00d7Y \u2192R risk D (F \u2032 ) + \u03b5,(66)\nfor some \u03b5 \u2265 0. If H is the classifier derived from it as in (65), then it achieves close to the Bayes optimal error err D (H) \u2264 err D (H opt ) + \u221a 2\u03b5.\nProof The proof is similar to that of Theorem 12.1 in Schapire and Freund (2012), which in turn is based on the work by Zhang (2004) and Bartlett et al. (2006). Let p(x) = Pr (x \u2032 ,y \u2032 )\u223cD (x \u2032 = x) denote the the marginalized probability of drawing example x from D, and let p x y = Pr (x \u2032 ,y \u2032 )\u223cD [y \u2032 = y|x \u2032 = x] denote the conditional probability of drawing label y given we have drawn example x. We first rewrite the difference in errors between H and H opt using these probabilities. Firstly note that the accuracy of any classifier H \u2032 is given by\n\u2211 x\u2208X D(x, H \u2032 (x)) = \u2211 x\u2208X p(x)p x H \u2032 (x) .\nIf X \u2032 is the set of examples where the predictions of H and H opt differ, X \u2032 = x \u2208 X : H(x) = H opt (x) , then we may bound the error differences as\nerr D (H) \u2212 err D (H opt ) = \u2211 x\u2208X \u2032 p(x) p x H opt (x) \u2212 p x H(x) .(67)\nWe next relate this expression to the difference of the losses. Notice that for any scoring function F \u2032 , the risk D can be rewritten as follows :\nrisk D (F \u2032 ) = \u2211 x\u2208X p(x) \u2211 l<l \u2032\np x l e F \u2032 (x,l \u2032 )\u2212F \u2032 (x,l) + p x l \u2032 e F \u2032 (x,l)\u2212F \u2032 (x,l \u2032 ) .\nDenote the inner summation in curly brackets by L l,l \u2032 F \u2032 (x), and notice this quantity is minimized if e F \u2032 (x,l)\u2212F \u2032 (x,l \u2032 ) = p x l /p x l \u2032 , i.e., if\nF \u2032 (x, l) \u2212 F \u2032 (x, l \u2032 ) = 1 2 ln p x l \u2212 1 2 ln p x l \u2032 .\nTherefore, defining F * (x, l) = 1 2 ln p x l leads to a risk D minimizing function F * . Furthermore, for any example and pair of labels l, l \u2032 , the quantity L l,l \u2032 F * (x) is at most L l,l \u2032 F (x), and therefore the difference in losses of F * and F may be lower bounded as follows:\n\u03b5 \u2265 risk D (F) \u2212 risk D (F * ) = \u2211 x\u2208X p(x) \u2211 l =l \u2032 L l,l \u2032 F \u2212 L l,l \u2032 F * \u2265 \u2211 x\u2208X \u2032 p(x) L H(x),H opt (x) F \u2212 L H(x),H opt (x) F * . (68\n)\nWe next study the term in the curly brackets for a fixed x. Let A and B denote H(x) and H opt (x), respectively. We have already seen that L A,B F * = 2 p x A p x B . Further, by definition of Bayes optimality, the adaptive algorithm. Further, Lemma 27 seems to suggest thatF T satisfies the condition in (66), which, combined with our previous observation err D (H) = err D (H T ), would imply H T approaches the optimal error. However, the condition (66) requires achieving optimal risk over all scoring functions, and not just ones achievable as a combination of weak classifiers in H . Therefore, in order to use Lemma 28, we require the weak classifier space to be sufficiently rich, so that some combination of the weak classifiers in H attains risk D arbitrarily close to the minimum attainable by any function:\ninf \u03b1:H \u2192R risk D (F \u03b1 ) = inf F:X \u00d7Y \u2192R risk D (F). (72\n)\nThe richness condition, along with our previous arguments and Lemma 27, immediately imply the following result.\nTheorem 29 If the weak classifier space H satisfies the richness condition (72), and the number of rounds T is set to \u221a m, then the error of the final classifier H T approaches the Bayes optimal error:\nPr err D H \u221a m \u2264 err D (H opt ) + O m \u2212c \u2265 1 \u2212 1 m 2 ,\nwhere c > 0 is some positive constant, and the probability is over the draw of training examples.\nA consequence of the theorem is our strongest consistency result:\nCorollary 30 Let H opt be the Bayes optimal classifier, and let the weak classifier space H satisfy the richness condition (72). Suppose m example and label pairs {(x 1 , y 1 ), . . . , (x m , y m )} are sampled from the distribution D, the number of rounds T is set to be \u221a m, and these are supplied to Ada-Boost.MM. Then, in the limit m \u2192 \u221e, the final classifier H \u221a m output by AdaBoost.MM achieves the Bayes optimal error almost surely:\nPr lim m\u2192\u221e err D (H \u221a m ) = err D (H opt ) = 1,\nwhere the probability is over the randomness due to the draw of training examples.\nThe proof of Corollary 30, based on the Borel-Cantelli Lemma, is very similar to that of Corollary 12.3 in Schapire and Freund (2012), and so we omit it. When k = 2, AdaBoost.MM is identical to AdaBoost. For Theorem 29 to hold for AdaBoost, the richness assumption ( 72) is necessary, since there are examples due to Long and Servedio (2010) showing that the theorem may not hold when that assumption is violated.\nAlthough we have seen that technically AdaBoost.MM is consistent under broad assumptions, intuitively perhaps it is not clear what properties were responsible for this desirable behavior. We next briefly study the high level ingredients necessary for consistency in boosting algorithms.", "publication_ref": ["b27", "b2", "b23", "b23", "b28", "b3", "b23", "b16"], "figure_ref": [], "table_ref": []}, {"heading": "Key Ingredients for Consistency", "text": "We show here how both the choice of the loss function as well as the weak learning condition play crucial roles in ensuring consistency. If the loss function were not Bayes consistent as in Lemma 28, driving it down arbitrarily could still lead to high test error. For example, the loss employed by SAMME (Zhu et al., 2009) does not upper bound the error, and therefore although it can manage to drive down its loss arbitrarily when supplied by the data set discussed in Figure 1, although its error remains high.\nEqually important is the weak learning condition. Even if the loss function is chosen to be error, so that it is trivially Bayes consistent, choosing the wrong weak learning condition could lead to inconsistency. In particular, if the weak learning condition is stronger than necessary, then, even on a boostable data set where the error can be driven to zero, the boosting algorithm may get stuck prematurely because its stronger than necessary demands cannot be met by the weak classifier space. We have already seen theoretical examples of such data sets, and we will see some practical instances of this phenomenon in the next section.\nOn the other hand, if the weak learning condition is too weak, then a lazy Weak Learner may satisfy the Booster's demands by returning weak classifiers belonging only to a non-boostable subset of the available weak classifier space. For instance, consider again the data set in Figure 1, and assume that this time the weak classifier space is much richer, and consists of all possible classifying functions. However, in any round, Weak Learner searches through the space, first trying hypotheses h 1 and h 2 shown in the figure, and only if neither satisfy the Booster, search for additional weak classifiers. In that case, any algorithm using SAMME's weak learning condition, which is known to be too weak and satisfiable by just the two hypotheses {h 1 , h 2 }, would only receive h 1 or h 2 in each round, and therefore be unable to reach the optimum accuracy. Of course, if the Weak Learner is extremely generous and helpful, then it may return the right collection of weak classifiers even with a null weak learning condition that places no demands on it. However, in practice, many Weak Learners used are similar to the lazy weak learner described since these are computationally efficient.\nTo see the effect of inconsistency arising from too weak learning conditions in practice, we need to test boosting algorithms relying on such data sets on significantly hard data sets, where only the strictest Booster strategy can extract the necessary service from Weak Learner for creating an optimal classifier. We did not include such experiments, and it will be an interesting empirical conjecture to be tested in the future. However, we did include experiments that illustrate the consequence of using too strong conditions, and we discuss those in the next section.", "publication_ref": ["b29"], "figure_ref": ["fig_7", "fig_7"], "table_ref": []}, {"heading": "Experiments", "text": "In the final section of this paper, we report preliminary experimental results on 13 UCI data sets: letter, nursery, pendigits, satimage, segmentation, vowel, car, chess, connect4, forest, magic04, poker, abalone. These data sets are all multiclass except for magic04, have a wide range of sizes, contain all combinations of real and categorical features, have different number of examples to number of features per example ratios, and are drawn from a variety of real-life situations. A summary of each data set is provided in Figure 7. Most sets come with prespecified train and test splits which we use; if not, we picked a random 4 : 1 split. Sometimes the prespecified test set was too large compared to the training set, and we restricted ourselves to the first ten thousand examples of the specified test set. Throughout this section by MM we refer to the version of AdaBoost.MM studied in the consistency section, which uses the approximate step size (61).\nThere were two kinds of experiments. In the first, we took a standard implementation M1 of AdaBoost.M1 with C4.5 as weak learner, and the Boostexter implementation MH of AdaBoost.MH using stumps , and compared it against our method MM with a naive greedy tree-searching weak-learner Greedy. We will refer to the number of leaves as the size of the tree. Note that since the trees are full binary trees, with each internal node having exactly two children, the total number of nodes in the tree is one less than twice the number of leaves. When C4.5 is run as the weak learner, it grows the tree till a desired accuracy is reached in each round, and thereby automatically picks the tree sizes. Those sizes were used to pick the maximum size of the trees that Greedy was allowed to return when run as a weak learner by MM, so that both M1 and MM output ensembles of trees of roughly similar sizes. The test-errors after 500 rounds of boosting for each algorithm and data set are shown in Figure 8. The performance is comparable with M1 and far better than MH (understandably since stumps are far weaker than trees), even though our weaklearner is very naive. The convergence rates of error with rounds of M1 and MM are also comparable, as shown in Figure 9 (we omitted the curve for MH since it lay far above both M1 and MM).\nWe next investigated how each algorithm performs with less powerful weak-learners. We modified MH so that it uses a tree returning a single multiclass prediction on each example. For MH and MM we used the Greedy weak learner, while for M1 we used a more powerful-variant Greedy-Info whose greedy criterion was information gain rather than error or cost (we also ran M1 on top of Greedy but Greedy-Info consistently gave better results so we only report the latter). The reason for using weak learners that optimize different cost functions with the different boosting algorithms is as follows. M1 is based on the error-metric, where every example incurs a penalty of 0 when classified correctly and 1 when classified incorrectly. Information gain, measuring how \"impure\" the nodes resulting from a particular split are, is well aligned with the error metric. However, MH and MM use more general cost functions, and we could not come up with appropriate generalizations of information gain for these setting. So we just used the cost itself in deciding how to grow the de-  , 20, 50, 100, 200, 500, 1000, 2000, 4000} up to the tree-size used by M1 on C4.5 for each data-set. We plotted the error of each algorithm against tree size for each data-set in Figure 10. As predicted by our theory, our algorithm succeeds in boosting the accuracy even when the tree size is too small to meet the stronger weak learning assumptions of the other algorithms. More insight is provided by plots in Figure 11 of the rate of convergence of error with rounds when the tree size allowed is very small (5). Both M1 and MH drive down the error for a few rounds. But since boosting keeps creating harder distributions, very soon the small-tree learning algorithms Greedy and Greedy-Info are no longer able to meet the excessive requirements of M1 and MH respectively. However, our algorithm makes more reasonable demands that are easily met by Greedy.", "publication_ref": [], "figure_ref": ["fig_7", "fig_7"], "table_ref": []}, {"heading": "Conclusion and Discussion", "text": "In summary, we create a new framework for studying multiclass boosting. This framework is very general and captures the weak learning conditions implicitly used by many earlier multiclass boosting algorithms as well as novel conditions, including the minimal condition under which boosting is possible. We also show how to design boosting algorithms relying on these weak learning conditions that drive down training error rapidly. These algorithms are the optimal strategies for playing certain two player games. Based on this game-theoretic approach, we also design a multiclass boosting algorithm that is consistent, that is, approaches the minimum empirical risk, and under some basic assumptions, the Bayes optimal test error. Preliminary experiments show that this algorithm can achieve much lower error compared to existing algorithms when used with very weak classifiers.\nFigure 9: Plots of the rates at which M1(black,dashed) and MM(red,solid) drive down test-error on different data-sets when using trees of comparable sizes as weak classifiers. M1 called C4.5, and MM called Greedy, respectively, as weak-learner. The tree sizes returned by C4.5 were used as a bound on the size of the trees that Greedy was allowed to return. This bound on the tree-size depended on the data set, and are shown next to the data set labels.\nThe notion of game-theoretic equivalence in Section 7.1 is based upon a weak learner that may return any weak hypothesis, which is absurd from a practical viewpoint. However, designing optimal boosting algorithms separately for different kinds of weak learners, which we leave as an open problem, will lead to a much more complex theory. Further, it is not clear what the additional gain (in terms of improvement in loss bounds) may be. Our philosophy here was to take the ultra-conservative approach, so that the resulting boosting algorithm enjoys bounds that hold under all settings. Theorem 14 then says, that in that ultra-conservative framework, the best algorithm remains the same if you change the weak-learning condition to another \"equivalent\" condition.\nAlthough we can efficiently compute the game-theoretically optimal strategies under most conditions, when using the minimal weak learning condition, and non-convex 0-1 error as loss function, Figure 10: For this figure, M1(black, dashed), MH(blue, dotted) and MM(red,solid) were designed to boost decision trees of restricted sizes. The final test-errors of the three algorithms after 500 rounds of boosting are plotted against the maximum tree-sizes allowed for the weak classifiers. MM achieves much lower error when the weak classifiers are very weak, that is, with smaller trees.\nwe require exponential computational time to solve the corresponding boosting games. Boosting algorithms based on error are potentially far more noise tolerant than those based on convex loss functions, and finding efficiently computable near-optimal strategies in this situation is an important problem left for future work. Further, we primarily work with weak classifiers that output a single multiclass prediction per example, whereas weak hypotheses that make multilabel multiclass predictions are typically more powerful. We believe that multilabel predictions do not increase the power of the weak learner in our framework, and our theory can be extended without much work to include such hypotheses, but we do not address this here. Finally, it will be interesting to see if the notion of minimal weak learning condition can be extended to boosting settings beyond classification, such as ranking.\nFigure 11: A plot of how fast the test-errors of the three algorithms drop with rounds when the weak classifiers are trees with a size of at most 5. Algorithms M1 and MH make strong demands which cannot be met by the extremely weak classifiers after a few rounds, whereas MM makes gentler demands, and is hence able to drive down error through all the rounds of boosting.\nWe will choose each label l i from the set l \u2212 i , l + i . In fact, we will choose a partition S + , S \u2212 of the examples 1, . . . , m and choose the label depending on which side S \u03be , for \u03be \u2208 {\u2212, +}, of the partition element i belongs to:\nl i = l \u03be i if i \u2208 S \u03be .\nIn order to guide our choice for the partition, we introduce parameters a i , b i as follows:\na i = C(i, l \u2212 i ) \u2212C(i, l + i ), b i = \u03c6 B(i) T \u2212t\u22121 s t (i) + e l \u2212 i \u2212 \u03c6 B(i)\nT \u2212t\u22121 s t (i) + e l + i . Notice that for each example i and each sign-bit \u03be \u2208 {\u22121, +1}, we have the following relations:\nC(i, l \u03be i ) = E l\u223cp i [C(i, l)] \u2212 \u03be(1 \u2212 p \u03be i )a i (79\n)\n\u03c6 B(i) T \u2212t\u22121 s t (i) + e l \u03be i = E l\u223cp i \u03c6 B(i) T \u2212t (i, l) \u2212 \u03be(1 \u2212 p \u03be i )b i . (80\n)\nThen the cost incurred by the choice of labels can be expressed in terms of the parameters a i , b i as follows:\n\u2211 i\u2208S + C(i, l + i ) + \u2211 i\u2208S \u2212 C(i, l \u2212 i ) = \u2211 i\u2208S + E l\u223cp i [C(i, l)] \u2212 a i + p + i a i + \u2211 i\u2208S \u2212 E l\u223cp i [C(i, l)] + p + i a i = m \u2211 i=1 E l\u223cp i [C(i, l)] + m \u2211 i=1 p + i a i \u2212 \u2211 i\u2208S + a i \u2264 m \u2211 i=1 C(i), B(i) + m \u2211 i=1 p + i a i \u2212 \u2211 i\u2208S + a i ,(81)\nwhere the first equality follows from (79), and the inequality follows from the constraint on p i in (77). Similarly, the potential of the new states is given by\n\u2211 i\u2208S + \u03c6 B(i) T \u2212t\u22121 s t (i) + e l + i + \u2211 i\u2208S \u2212 \u03c6 B(i) T \u2212t\u22121 s t (i) + e l \u2212 i = \u2211 i\u2208S + E l\u223cp i \u03c6 B(i) T \u2212t\u22121 (s t (i) + e l ) \u2212 b i + p + i b i + \u2211 i\u2208S \u2212 E l\u223cp i \u03c6 B(i) T \u2212t\u22121 (s t (i) + e l ) + p + i b i = m \u2211 i=1 E l\u223cp i \u03c6 B(i) T \u2212t\u22121 (s t (i) + e l ) + m \u2211 i=1 p + i b i \u2212 \u2211 i\u2208S + b i = m \u2211 i=1 \u03c6 B(i) T \u2212t (s t (i)) + m \u2211 i=1 p + i b i \u2212 \u2211 i\u2208S + b i ,(82)\nwhere the first equality follows from (80), and the last equality from an optimal choice of p i satisfying (75). Now, ( 81) and ( 82) imply that in order to satisfy ( 73) and ( 74), it suffices to choose a subset S + satisfying\n\u2211 i\u2208S + a i \u2265 m \u2211 i=1 p + i a i , \u2211 i\u2208S + b i \u2264 m\u03b5 T + m \u2211 i=1 p + i b i .(83)\nWe simplify the required conditions. Notice the first constraint tries to ensure that S + is big, while the second constraint forces it to be small, provided the b i are non-negative. However, if b i < 0 for any example i, then adding this example to S + only helps both inequalities. In other words, if we can always construct a set S + satisfying (83) in the case where the b i are non-negative, then we may handle the more general situation by just adding the examples i with negative b i to the set S + that would be constructed by considering only the examples {i : b i \u2265 0}. Therefore we may assume without loss of generality that the b i are non-negative. Further, assume (by relabeling if necessary) that a 1 , . . . , a m \u2032 are positive and a m \u2032 +1 , . . . a m = 0, for some m \u2032 \u2264 m. By (78), we have p + i = 0 for i > m \u2032 . Therefore, by assigning the examples m \u2032 + 1, . . . , m to the opposite partition S \u2212 , we can ensure that (83) holds if the following is true:\n\u2211 i\u2208S + a i \u2265 m \u2032 \u2211 i=1 p + i a i ,(84)\n\u2211 i\u2208S + b i \u2264 m \u2032 max i=1 |b i | + m \u2032 \u2211 i=1 p + i b i ,(85)\nwhere, for (85), we additionally used that, by the choice of m (25) and the bound on loss variation (24), we have m\u03b5 T \u2265 (L, T ) \u2265 b i for i = 1, . . . , m.\nThe next lemma shows how to construct such a subset S + , and concludes our lower bound proof.\nLemma 32 Suppose a 1 , . . . , a m \u2032 are positive and b 1 , . . . , b m \u2032 are non-negative reals, and p + 1 , . . . , p + m \u2032 \u2208 [0, 1] are probabilities. Then there exists a subset S + \u2286 {1, . . . , m \u2032 } such that (84) and (85) hold.\nProof Assume, by relabeling if necessary, that the following ordering holds:\na(1) \u2212 b(1) a(1) \u2265 \u2022 \u2022 \u2022 \u2265 a(m \u2032 ) \u2212 b(m \u2032 ) a(m \u2032 ) . (86\n)\nLet I \u2264 m \u2032 be the largest integer such that\na 1 + a 2 + \u2022 \u2022 \u2022 + a I < m \u2032 \u2211 i=1 p + i a i .(87)\nSince the p + i are at most 1, I is in fact at most m \u2032 \u22121. We will choose S + to be the first I +1 examples S + = {1, . . . , I + 1}. Observe that (84) follows immediately from the definition of I. Further, (85) will hold if the following is true\nb 1 + b 2 + \u2022 \u2022 \u2022 + b I \u2264 m \u2032 \u2211 i=1 p + i b i ,(88)\nsince the addition of one more example I + 1 can exceed this bound by at most b I+1 \u2264 max m \u2032 i=1 |b i |. We prove (88) by showing that the left hand side of this equation is not much more than the left hand side of (87). We first rewrite the latter summation differently. The inequality in (87) implies we can pickp + 1 , . . . ,p + m \u2032 \u2208 [0, 1] (e.g., by simply scaling the p + i 's appropriately) such that\na 1 + . . . + a I = m \u2032 \u2211 i=1p + i a i (89\n) for i = 1, . . . , m \u2032 :p + i \u2264 p i . (90\n)\nBy subtracting off the first I terms in the right hand side of ( 89) from both sides we get\n(1 \u2212p + 1 )a 1 + \u2022 \u2022 \u2022 + (1 \u2212p + I )a I =p + I+1 a I+1 + \u2022 \u2022 \u2022 +p + m \u2032 a m \u2032 .\nSince the terms in the summations are non-negative, we may combine the above with the ordering property in (86) to get\n(1 \u2212p + 1 )a 1 a 1 \u2212 b 1 a 1 + \u2022 \u2022 \u2022 + (1 \u2212p + I )a I a I \u2212 b I a I \u2265p + I+1 a I+1 a I+1 \u2212 b I+1 a I+1 + \u2022 \u2022 \u2022 +p + m \u2032 a m \u2032 a m \u2032 \u2212 b m \u2032 a m \u2032 .(91)\nAdding the expressionp \nb i \u2265 m \u2032 \u2211 i=1p + i a i \u2212 m \u2032 \u2211 i=1p + i b i i.e., I \u2211 i=1 b i \u2264 m \u2032 \u2211 i=1p + i b i ,(92)\nwhere the last inequality follows from (89). Now (88) follows from ( 92) using ( 90) and the fact that the b i 's are non-negative.\nThis completes the proof of the lower bound.", "publication_ref": [], "figure_ref": ["fig_7", "fig_7"], "table_ref": []}, {"heading": "A.2 Consistency Proofs", "text": "Here we sketch the proofs of Lemmas 26 and 27. Our approach will be to relate our algorithm to AdaBoost and then use relevant known results on the consistency of AdaBoost. We first describe the correspondence between the two algorithms, and then state and connect the relevant results on AdaBoost to the ones in this section. For any given multiclass data set and weak classifier space, we will obtain a transformed binary data set and weak classifier space, such that the run of AdaBoost.MM on the original data set will be in perfect correspondence with the run of AdaBoost on the transformed data set. In particular, the loss and error on both the training and test set of the combined classifiers produced by our algorithm will be exactly equal to those produced by AdaBoost, while the space of functions and classifiers on the two data sets will be in correspondence.\nIntuitively, we transform our multiclass classification problem into a single binary classification problem in a way similar to the all-pairs multiclass to binary reduction. A very similar reduction was carried out by Freund and Schapire (1997). Borrowing their terminology, the transformed data set roughly consists of mislabel triples (x, y, l) where y is the true label of the example and l is an incorrect example. The new binary label of a mislabel triple is always \u22121, signifying that l is not the true label. A multiclass classifier becomes a binary classifier that predict \u00b11 on the mislabel triple (x, y, l) depending on whether the prediction on x matches label l; therefore error on the transformed binary data set is low whenever the multiclass accuracy is high. The details of the transformation are provided in Figure 12.\nSome of the properties between the functions and their transformed counterparts are described in the next lemma, showing that we are essentially dealing with similar objects.", "publication_ref": ["b12"], "figure_ref": ["fig_2"], "table_ref": []}, {"heading": "Lemma 33", "text": "The following are identities for any scoring function F : X \u00d7 Y \u2192 R and weight function \u03b1 : H \u2192 R:\nrisk (F \u03b1 ) = risk F \u03b1 (93) risk D (F) = risk D \u00af F .(94)\nThe proofs involve doing straightforward algebraic manipulations to verify the identities and are omitted.\nThe next lemma connects the two algorithms. We show that the scoring function output by AdaBoost when run on the transformed data set is the transformation of the function output by our algorithm. The proof again involves tedious but straightforward checking of details and is omitted.\nLemma 34 If AdaBoost.MM produces scoring function F \u03b1 when run for T rounds with the training set S and weak classifier space H , then AdaBoost produces the scoring function F \u03b1 when run for T rounds with the training set S and space H . We assume that for both the algorithms, Weak Learner returns the weak classifier in each round that achieves the maximum edge. Further we consider the version of AdaBoost.MM that chooses weights according to the approximate rule (61).\nWe next state the result for AdaBoost corresponding to Lemma 26 , which appears in Mukherjee et al. (2011). The previous lemma, along with (93) immediately proves Lemma 26. The result for AdaBoost corresponding to Lemma 27 appears in Schapire and Freund (2012). Pr risk D \u00af F \u2264 inf\nF \u2032 : X \u2192R risk D ( F \u2032 ) + O m \u2212c \u2265 1 \u2212 1 m 2 ,\nwhere the constant C depends only on the data set.", "publication_ref": ["b18", "b23"], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgments", "text": "This research was funded by the National Science Foundation under grants IIS-0325500 and IIS-1016029.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "p x", "text": "A \u2265 p x B . On the other hand, since x \u2208 X \u2032 , we know that B = A, and hence, F(x, A) \u2265 F(x, B). Let e F(x,B)\u2212F(x,A) = 1 + \u03b7, for some \u03b7 \u2265 0. The quantity L A,B F may be lower bounded as:\nA e F(x,B)\u2212F(x,A) + p x B e F(x,A)\u2212F(x,B) = (1 + \u03b7)p\nCombining we get\n.\nPlugging back into (68) we get\nNow we connect (67) to the previous expression as follows\nwhere ( 70) holds since\nand (71) holds since\nNote that the classifierH T , derived from the truncated scoring functionF T in the manner provided in (65), makes identical predictions to, and hence has the same err D as, the classifier H T output by Appendix A. Omitted Proofs\nWe include proofs and details that were omitted earlier in the paper.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A.1 Optimality of the OS Strategy", "text": "Here we prove Theorem 9. The proof of the upper bound on the loss is very similar to the proof of Theorem 2 in Schapire (2001). For the lower bound, a similar result is proved in Theorem 3 in Schapire (2001). However, the proof relies on certain assumptions that may not hold in our setting, and we instead follow the more direct lower bounding techniques in Section 5 of Mukherjee and Schapire (2010). We first show that the average potential of states does not increase in any round. The dual form of the recurrence ( 21) and the choice of the cost matrix C t in ( 22) together ensure that for each example i,", "publication_ref": ["b22", "b22", "b17"], "figure_ref": [], "table_ref": []}, {"heading": "Summing up the inequalities over all examples, we get", "text": "The first two summations are the total potentials in round t + 1 and t, respectively, and the third summation is the difference in the costs incurred by the weak-classifier h t returned in iteration t and the baseline B. By the weak learning condition, this difference is non-positive, implying that the average potential does not increase.\nNext we show that the bound is tight. In particular choose any accuracy parameter \u03b5 > 0, and total number of iterations T , and let m be as large as in (25). We show that in any iteration t \u2264 T , based on Booster's choice of cost-matrix C, an adversary can choose a weak classifier h t \u2208 H all such that the weak learning condition is satisfied, and the average potential does not fall by more than an amount \u03b5/T . In fact, we show how to choose labels l 1 , . . . , l m such that the following hold simultaneously:\nThis will imply that the final potential or loss is at least \u03b5 less than the bound in (23).\nWe first construct, for each example i, a distribution p i \u2208 \u2206 {1, . . . , k} such that the size of the support of p i is either 1 or 2, and\nTo satisfy (75), by (17), we may choose p i as any optimal response of the max player in the minimax recurrence when the min player chooses C(i):\nwhere\nThe existence of p i is guaranteed, since, by Lemma 7, the polytope P i is non-empty for each i. The\nnext result shows that we may choose p i to have a support of size 1 or 2.\nLemma 31 There is a p i satisfying (76) with either 1 or 2 non-zero coordinates.\nProof Let p * satisfy (76), and let its support set be S. Let \u00b5 i denote the mean cost under this distribution:\nIf the support has size at most 2, then we are done. Further, if each non-zero coordinate l \u2208 S of p * satisfies C(i, l) = \u00b5 i , then the distribution p i that concentrates all its weight on the label l min \u2208 S minimizing \u03c6\nt\u22121 (s + e l min ) is an optimum solution with support of size 1. Otherwise, we can pick labels l min 1 , l min 2 \u2208 S such that C(i, l min 1 ) < \u00b5 i < C(i, l min 2 ). Then we may choose a distribution q supported on these two labels with mean \u00b5 i :\nChoose \u03bb as follows:\n, and write p * = \u03bbq + (1 \u2212 \u03bb)p. Then both p, q belong to the polytope P i , and have strictly fewer nonzero coordinates than p * . Further, by linearity, one of q, p is also optimal. We repeat the process on the new optimal distribution till we find one which has only 1 or 2 non-zero entries.\nWe next show how to choose the labels l 1 , . . . , l m using the distributions p i . For each i, let l + i , l \u2212 i be the support of p i so that\n(When p i has only one non-zero element, then l + i = l \u2212 i .) For brevity, we use p + i and p \u2212 i to denote p i l + i and p i l \u2212 i , respectively. If the costs of both labels are equal, we assume without loss of generality that p i is concentrated on label l \u2212 i : (78) ", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Optimal stragies and minimax lower bounds for online convex games", "journal": "", "year": "2008", "authors": "Jacob Abernethy; Peter L Bartlett; Alexander Rakhlin; Ambuj Tewari"}, {"ref_id": "b1", "title": "Reducing multiclass to binary: A unifying approach for margin classifiers", "journal": "Journal of Machine Learning Research", "year": "2000", "authors": "Erin L Allwein; Robert E Schapire; Yoram Singer"}, {"ref_id": "b2", "title": "AdaBoost is consistent", "journal": "Journal of Machine Learning Research", "year": "2007", "authors": "L Peter; Mikhail Bartlett;  Traskin"}, {"ref_id": "b3", "title": "Convexity, classification, and risk bounds", "journal": "Journal of the American Statistical Association", "year": "2006-03", "authors": "L Peter; Michael I Bartlett; Jon D Jordan;  Mcauliffe"}, {"ref_id": "b4", "title": "Error-correcting tournaments", "journal": "", "year": "2009", "authors": "Alina Beygelzimer; John Langford; Pradeep Ravikumar"}, {"ref_id": "b5", "title": "Solving multiclass learning problems via error-correcting output codes", "journal": "Journal of Artificial Intelligence Research", "year": "1995-01", "authors": "G Thomas; Ghulum Dietterich;  Bakiri"}, {"ref_id": "b6", "title": "Multiclass boosting for weak classifiers", "journal": "Journal of Machine Learning Research", "year": "2005", "authors": "G\u00fcnther Eibl; Karl-Peter Pfeiffer"}, {"ref_id": "b7", "title": "Boosting a weak learning algorithm by majority", "journal": "Information and Computation", "year": "1995", "authors": "Yoav Freund"}, {"ref_id": "b8", "title": "An adaptive version of the boost by majority algorithm", "journal": "", "year": "2001-06", "authors": "Yoav Freund"}, {"ref_id": "b9", "title": "Continuous drifting games", "journal": "Journal of Computer and System Sciences", "year": "2002", "authors": "Yoav Freund; Manfred Opper"}, {"ref_id": "b10", "title": "Experiments with a new boosting algorithm", "journal": "", "year": "1996", "authors": "Yoav Freund; Robert E Schapire"}, {"ref_id": "b11", "title": "Game theory, on-line prediction and boosting", "journal": "", "year": "1996", "authors": "Yoav Freund; Robert E Schapire"}, {"ref_id": "b12", "title": "A decision-theoretic generalization of on-line learning and an application to boosting", "journal": "Journal of Computer and System Sciences", "year": "1997-08", "authors": "Yoav Freund; Robert E Schapire"}, {"ref_id": "b13", "title": "Classification by pairwise coupling", "journal": "Annals of Statistics", "year": "1998", "authors": "Trevor Hastie; Robert Tibshirani"}, {"ref_id": "b14", "title": "Empirical margin distributions and bounding the generalization error of combined classifiers", "journal": "Annals of Statistics", "year": "2002-02", "authors": "Vladimir Koltchinskii; Dmitriy Panchenko"}, {"ref_id": "b15", "title": "Robust logitboost and adaptive base class (abc) logitboost", "journal": "", "year": "2010", "authors": "Ping Li"}, {"ref_id": "b16", "title": "Random classification noise defeats all convex potential boosters", "journal": "", "year": "2010", "authors": "M Philip; Rocco A Long;  Servedio"}, {"ref_id": "b17", "title": "Learning with continuous experts using drifting games", "journal": "Theoretical Computer Science", "year": "2010-06", "authors": "Indraneel Mukherjee; Robert E Schapire"}, {"ref_id": "b18", "title": "The rate of convergence of AdaBoost", "journal": "", "year": "2011", "authors": "Indraneel Mukherjee; Cynthia Rudin; Robert E Schapire"}, {"ref_id": "b19", "title": "Efficient margin maximizing with boosting", "journal": "Journal of Machine Learning Research", "year": "2005", "authors": "Gunnar R\u00e4tsch; Manfred K Warmuth"}, {"ref_id": "b20", "title": "Convex Analysis", "journal": "Princeton University Press", "year": "1970", "authors": "R Tyrrell Rockafellar"}, {"ref_id": "b21", "title": "The strength of weak learnability", "journal": "", "year": "1990", "authors": "Robert E Schapire"}, {"ref_id": "b22", "title": "Drifting games", "journal": "", "year": "2001-06", "authors": "Robert E Schapire"}, {"ref_id": "b23", "title": "Boosting: Foundations and Algorithms", "journal": "MIT Press", "year": "2012", "authors": "Robert E Schapire; Yoav Freund"}, {"ref_id": "b24", "title": "Improved boosting algorithms using confidence-rated predictions", "journal": "", "year": "1999-12", "authors": "Robert E Schapire; Yoram Singer"}, {"ref_id": "b25", "title": "BoosTexter: A boosting-based system for text categorization", "journal": "", "year": "2000-06", "authors": "Robert E Schapire; Yoram Singer"}, {"ref_id": "b26", "title": "Boosting the margin: A new explanation for the effectiveness of voting methods", "journal": "Annals of Statistics", "year": "1998-10", "authors": "Robert E Schapire; Yoav Freund; Peter Bartlett; Wee Sun Lee"}, {"ref_id": "b27", "title": "On the Consistency of Multiclass Classification Methods", "journal": "Journal of Machine Learning Research", "year": "2007-05", "authors": "Ambuj Tewari; Peter L Bartlett"}, {"ref_id": "b28", "title": "Statistical behavior and consistency of classification methods based on convex risk minimization", "journal": "Annals of Statistics", "year": "2004", "authors": "Tong Zhang"}, {"ref_id": "b29", "title": "Multi-class AdaBoost", "journal": "Statistics and Its Interface", "year": "2009", "authors": "Ji Zhu; Hui Zou; Saharon Rosset; Trevor Hastie"}], "figures": [{"figure_label": "", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Theorem 13 If L exp \u03b7 is as in (32), where \u03b7 is non-negative, then the solution in Theorem 12 evaluates to \u03c6 b t (s) = \u2211 k l=2 (a l ) t e \u03b7 l (s l \u2212s 1 ) , where a l = 1 \u2212 (b 1 + b l ) + e \u03b7 b l + e \u2212\u03b7 b 1 .", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 2 :2Figure 2: Plot of potential value \u03c6 b T (0) where b is the \u03b3-biased uniform distribution:b = ( 1\u2212\u03b3 k + \u03b3, 1\u2212\u03b3 k , 1\u2212\u03b3 k , . . . , 1\u2212\u03b3 k ). (a): Potential values (rounded to two decimal places) for different number of rounds T using \u03b3 = 0 and k = 6. These are bounds on the error, and less than 1 even when the edge and number of rounds are small. (b): Potential values for different number of classes k, with \u03b3 = 0.1, and T = 10. These are tight estimates for the optimal error, and yet not monotonic in the number of classes.", "figure_data": ""}, {"figure_label": "15", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Corollary 1515Any two necessary and sufficient weak learning conditions are game-theoretically equivalent. In particular the optimum Booster strategies based on AdaBoost.MR's condition (C MR , B MR \u03b3 ) and (13) have equal payoffs.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 3 :3Figure 3: Green pixels (crosses) have degree 3, black pixels (solid squares) have degree 2. Each step is diagonally down (left), and up (if x < y) and right (if x > y) and both when degree is 3. The rightmost figure uses \u03b3 = 0.4, and the other two \u03b3 = 0. The loss function is 0-1.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Figure 4 :4Figure4: Optimum recurrence value. We set \u03b3 = 0. Surface is irregular for smaller values of T , but smoother for larger values, admitting hope for approximation.", "figure_data": ""}, {"figure_label": "56", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Figure 5 :Figure 6 :56Figure 5: Comparison of \u03c6 t (0) (blue, dashed) with max q \u03c6 q t (0) (red, solid) over different rounds t and different number of classes k. We set \u03b3 = 0 in both.", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "Algorithm 11AdaBoost.MM Require: Number of classes k, number of examples m. Require: Training set {(x 1 , y 1 ), . . . , (x m , y m )} with y i \u2208 {1, . . . , k} and x i \u2208 X.", "figure_data": ""}, {"figure_label": "35", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "Lemma 35 (35Theorem 8 inMukherjee et al. (2011)) Suppose AdaBoost produces the scoring function F \u03b1 when run for T rounds with the training set S and space H . Thenrisk F \u03b1 \u2264 inf \u03b2: H \u2192R risk F \u03b2 +C/T,where the constant C depends only on the data set.", "figure_data": ""}, {"figure_label": "12", "figure_type": "figure", "figure_id": "fig_10", "figure_caption": "Figure 12 :12Figure 12: Details of transformation between AdaBoost.MM and AdaBoost.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "Lemma 2 A weak classifier space H satisfies (C M1 , B M1 \u03b3 ) if and only if it satisfies (C MH , B MH \u03b3 ).", "figure_data": "Note that C M1 and C MH depend implicitly on the training set. This lemma is valid for all trainingsets.Proof We will refer to (C M1 , B M1 \u03b3 ) by M1 and (C MH , B MH \u03b3 ) by MH for brevity. The proof is in threesteps."}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "Summaries of the data sets used in the experiments. Each row contains the name of data set, number of labels, number of test examples, and training examples, and number of discrete and real features, in that order. The data sets that come with prespecified training-test splits are marked with an asterisk. When the prespecified test set was too large compared to the training set, only the first ten thousand examples were used. These test set sizes are marked with an asterisk.", "figure_data": "data setclassestesttrain discrete realabalone*281044313317car4345138360chess27992397360connect4313511 54046420forest*7 10000* 151204410letter264000 16000016magic0423804 15216010nursery52591 1036980pendigits*1034987494016poker*10 10000* 2501055satimage*620004435036segmentation*72100210019vowel*11462528010Figure 7:"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "This is a table of the final test-errors of standard implementations of MH, M1 and MM after 500 rounds of boosting on different data sets. Both M1 and MM achieve comparable error, which is often smaller than that achieved by MH. This is because M1 and MM used trees of comparable sizes which were often much larger and powerful than the decision stumps that MH boosted. cision tree. We tried all tree-sizes in the set {10", "figure_data": "data setMHM1MMabalone0.732 0.751 0.750car0.264 0.336 0.159chess0.025 0.003 0.005connect40.321 0.306 0.282forest0.326 0.238 0.239letter0.146 0.031 0.027magic040.148 0.117 0.118nursery0.081 0.164 0.196pendigits0.046 0.026 0.095poker0.497 0.341 0.228satimage0.121 0.088 0.093segmentation 0.050 0.053 0.149vowel0.569 0.485 0.567Figure 8:"}], "formulas": [{"formula_id": "formula_0", "formula_text": "C t \u2022 1 h t = m \u2211 i=1 C t (i, h t (x i )),", "formula_coordinates": [5.0, 263.89, 168.33, 111.51, 29.93]}, {"formula_id": "formula_1", "formula_text": "H(x) \u25b3 = argmax l\u2208{1,...,k} f T (x, l), where f T (x, l) \u25b3 = T \u2211 t=1 1 [h t (x) = l] \u03b1 t .", "formula_coordinates": [5.0, 173.76, 317.79, 264.47, 29.93]}, {"formula_id": "formula_2", "formula_text": "\u2200i : C(i, y i ) \u2264 C(i,\u0233 i ) (here\u0233 i = y i is the other binary label),", "formula_coordinates": [5.0, 176.39, 481.33, 259.22, 18.65]}, {"formula_id": "formula_3", "formula_text": "\u2211 i C(i, h(x i )) \u2264 \u2211 i 1 2 \u2212 \u03b3 2 C(i,\u0233 i ) + 1 2 + \u03b3 2 C(i, y i ) .", "formula_coordinates": [5.0, 174.06, 531.07, 263.88, 28.43]}, {"formula_id": "formula_4", "formula_text": "(1/2 + \u03b3/2, 1/2 \u2212 \u03b3/2).", "formula_coordinates": [5.0, 90.0, 626.76, 101.95, 18.83]}, {"formula_id": "formula_5", "formula_text": "\u2200C \u2208 C bin , \u2203h \u2208 H : C \u2022 1 h \u2212 U bin \u03b3 \u2264 0.", "formula_coordinates": [5.0, 149.7, 639.32, 183.72, 19.82]}, {"formula_id": "formula_6", "formula_text": "\u2200C \u2208 C , \u2203h \u2208 H : C \u2022 (1 h \u2212 B) \u2264 0, i.e., m \u2211 i=1 C(i, h(i)) \u2264 m \u2211 i=1 C(i), B(i) .", "formula_coordinates": [6.0, 141.81, 130.54, 328.38, 29.94]}, {"formula_id": "formula_7", "formula_text": "\u2200i : argmax l\u2208{1,...,k} \u2211 h\u2208H \u03bb(h)1 [h(x i ) = l] = y i .", "formula_coordinates": [6.0, 288.93, 335.53, 209.47, 18.83]}, {"formula_id": "formula_8", "formula_text": "\u2200d(1), . . . , d(m) \u2265 0, \u2203h \u2208 H : m \u2211 i=1 d(i)1 [h(x i ) = y i ] \u2264 (1 \u2212 1/k \u2212 \u03b3 \u2032 ) m \u2211 i=1 d(i).", "formula_coordinates": [7.0, 141.14, 146.85, 329.74, 29.94]}, {"formula_id": "formula_9", "formula_text": "C(i, j) = d(i) if j = y i , 0 if j = y i .", "formula_coordinates": [7.0, 245.28, 210.66, 119.7, 27.75]}, {"formula_id": "formula_10", "formula_text": "m \u2211 i=1 C(i, h(x i )) = C \u2022 1 h .", "formula_coordinates": [7.0, 255.79, 269.76, 100.43, 29.94]}, {"formula_id": "formula_11", "formula_text": "U \u03b3 (i, l) = (1\u2212\u03b3) k + \u03b3 if l = y i , (1\u2212\u03b3) k if l = y i .", "formula_coordinates": [7.0, 234.45, 334.42, 141.35, 33.04]}, {"formula_id": "formula_12", "formula_text": "C(i), U \u03b3 (i) = \u2211 l =y i C(i, l)U \u03b3 (i, l) = (k \u2212 1) (1 \u2212 \u03b3) k d(i) = 1 \u2212 1 k \u2212 1 \u2212 1 k \u03b3 d(i) = 1 \u2212 1 k \u2212 \u03b3 \u2032 d(i).", "formula_coordinates": [7.0, 209.59, 398.48, 197.98, 111.44]}, {"formula_id": "formula_13", "formula_text": "m \u2211 i=1 \u2211 l =y i C(i, l)U \u03b3 (i, l) = C \u2022 U \u03b3 ,", "formula_coordinates": [7.0, 240.93, 539.91, 130.14, 30.98]}, {"formula_id": "formula_14", "formula_text": "C SAM \u25b3 = C : C(i, l) = 0 if l = y i , t i if l = y i , for non-negative t 1 , . . . ,t m .", "formula_coordinates": [7.0, 157.71, 607.78, 287.81, 27.75]}, {"formula_id": "formula_15", "formula_text": "\u2200C \u2208 C SAM , \u2203h \u2208 H : C \u2022 1 h \u2212 U \u03b3 \u2264 0.", "formula_coordinates": [7.0, 216.36, 668.49, 179.28, 20.36]}, {"formula_id": "formula_16", "formula_text": "m \u2211 i=1 d(i)1 [h(x i ) = y i ] \u2264 (1/2 \u2212 \u03b3/2) m \u2211 i=1 d(i),(4)", "formula_coordinates": [8.0, 212.59, 162.69, 309.42, 29.93]}, {"formula_id": "formula_17", "formula_text": "m \u2211 i=1 d(i) h(x i ) = y i \u2264 \u2212\u03b3 m \u2211 i=1 d(i).", "formula_coordinates": [8.0, 216.51, 195.24, 159.0, 29.94]}, {"formula_id": "formula_18", "formula_text": "C(i, l) = l = y i d(i)", "formula_coordinates": [8.0, 260.25, 265.3, 90.95, 11.49]}, {"formula_id": "formula_19", "formula_text": "\u2200C \u2208 R m\u00d7k satisfying 0 \u2264 \u2212C(i, y i ) = C(i, l) for l = y i ,(5)", "formula_coordinates": [8.0, 196.51, 309.75, 325.5, 20.42]}, {"formula_id": "formula_20", "formula_text": "m \u2211 i=1 C(i, h(x i )) \u2264 \u03b3 m \u2211 i=1 C(i, y i ) i.e., \u2200C \u2208 C M1 , \u2203h \u2208 H : C \u2022 1 h \u2212 B M1 \u03b3 \u2264 0, where B M1 \u03b3 (i, l) = \u03b31 [l = y i ]", "formula_coordinates": [8.0, 90.0, 325.52, 325.49, 74.51]}, {"formula_id": "formula_21", "formula_text": "m \u2211 i=1 1 [h(x i ) = y i ] d(i, y i ) + \u2211 l =y i 1 [h(x i ) = l] d(i, l) \u2264 1 2 \u2212 \u03b3 2 m \u2211 i=1 k \u2211 l=1 d(i, l).(6)", "formula_coordinates": [8.0, 130.75, 500.0, 391.25, 45.06]}, {"formula_id": "formula_22", "formula_text": "m \u2211 i=1 \u22121 [h(x i ) = y i ] d(i, y i ) + \u2211 l =y i 1 [h(x i ) = l] d(i, l) \u2264 m \u2211 i=1 1 2 \u2212 \u03b3 2 \u2211 l =y i d(i, l) \u2212 1 2 + \u03b3 2 d(i, y i ) .", "formula_coordinates": [8.0, 188.69, 582.84, 234.63, 68.21]}, {"formula_id": "formula_23", "formula_text": "C(i, l) = d(i, l) if l = y i \u2212d(i, l) if l = y i ,", "formula_coordinates": [8.0, 238.48, 678.92, 133.29, 34.92]}, {"formula_id": "formula_24", "formula_text": "\u2200C \u2208 R m\u00d7k satisfying C(i, y i ) \u2264 0,C(i, l) \u2265 0 for l = y i ,(7)", "formula_coordinates": [9.0, 148.0, 115.45, 374.01, 20.43]}, {"formula_id": "formula_25", "formula_text": "sum m i=1 C(i, h(x i )) \u2264 m \u2211 i=1 1 2 + \u03b3 2 C(i, y i ) + 1 2 \u2212 \u03b3 2 \u2211 l =y i C(i, l) .", "formula_coordinates": [9.0, 167.91, 148.41, 296.1, 30.98]}, {"formula_id": "formula_26", "formula_text": "\u2200C \u2208 C MH , \u2203h \u2208 H : C \u2022 1 h \u2212 B MH \u03b3 \u2264 0, where B MH \u03b3 (i, l) = (1/2 + \u03b3 l = y i /2).", "formula_coordinates": [9.0, 90.0, 217.19, 307.91, 35.14]}, {"formula_id": "formula_27", "formula_text": "m \u2211 i=1 \u2211 l =y i (1 [h(x i ) = l] \u2212 1 [h(x i ) = y i ]) d(i, l) \u2264 \u2212\u03b3 m \u2211 i=1 \u2211 l =y i d(i, l) i.e., m \u2211 i=1 \u22121 [h(x i ) = y i ] \u2211 l =y i d(i, l) + \u2211 l =y i 1 [h(x i ) = l] d(i, l) \u2264 \u2212\u03b3 m \u2211 i=1 \u2211 l =y i d(i, l). Substituting C(i, l) = d(i, l) l = y i \u2212 \u2211 l =y i d(i, l) l = y i ,", "formula_coordinates": [9.0, 90.0, 347.87, 397.1, 128.52]}, {"formula_id": "formula_28", "formula_text": "\u2200C \u2208 R m\u00d7k satisfying C(i, l) \u2265 0 for l = y i ,C(i, y i ) = \u2212 \u2211 l =y i C(i, l),(8)", "formula_coordinates": [9.0, 166.75, 498.98, 355.25, 23.83]}, {"formula_id": "formula_29", "formula_text": "m \u2211 i=1 C(i, h(x i )) \u2264 \u2212 \u03b3 2 m \u2211 i=1 \u2212C(i, y i ) + \u2211 l =y i C(i, l) .", "formula_coordinates": [9.0, 228.94, 529.05, 216.3, 30.99]}, {"formula_id": "formula_30", "formula_text": "\u2200C \u2208 C MR , \u2203h \u2208 H : C \u2022 1 h \u2212 B MR \u03b3 \u2264 0, where B MR \u03b3 (i, l) = l = y i \u03b3/2.", "formula_coordinates": [9.0, 90.0, 597.83, 307.46, 35.14]}, {"formula_id": "formula_31", "formula_text": "d(i, l) = d(i) if l = y i 0 if l = y i .", "formula_coordinates": [10.0, 247.66, 374.77, 115.49, 27.75]}, {"formula_id": "formula_32", "formula_text": "H \u03bb * \u25b3 = \u2211 h\u2208H \u03bb * (h)1 h , such that \u2200i : H \u03bb * \u2212 B M1 \u03b3 (i, l) \u2265 0 if l = y i \u2264 0 if l = y i .(9)", "formula_coordinates": [10.0, 90.0, 440.86, 432.0, 78.52]}, {"formula_id": "formula_33", "formula_text": "min \u03bb\u2208\u2206(H ) max C\u2208C M1 C \u2022 H \u03bb \u2212 B M1 \u03b3 = max C\u2208C M1 min h\u2208H C \u2022 1 h \u2212 B M1 \u03b3 \u2264 0,(10)", "formula_coordinates": [10.0, 167.96, 542.83, 354.05, 20.36]}, {"formula_id": "formula_34", "formula_text": "\u2200i : H \u03bb * (i, l) \u2265 1 2 + \u03b3 2 if l = y i \u2264 1 2 \u2212 \u03b3 2 if l = y i ,(11)", "formula_coordinates": [10.0, 230.34, 612.04, 291.67, 38.02]}, {"formula_id": "formula_35", "formula_text": "C \u2208 C M1 can cause C\u2022 H \u03bb * \u2212 B M1 \u03b3 to exceed 0. In particular, if H \u03bb * (i 0 , l) < 1/2 + \u03b3/2, then H \u03bb * \u2212 B M1 \u03b3 (i 0 , y i 0 ) < \u2211 l =y i 0 H \u03bb * \u2212 B M1 \u03b3 (i 0 , l). Now, if we choose C \u2208 C M1 as C(i, l) = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 0 if i = i 0 1 if i = i 0 , l = y i 0 \u22121 if i = i 0 , l = y i 0 , then, C \u2022 H \u03bb * \u2212 B M1 \u03b3 = \u2212 H \u03bb * \u2212 B M1 \u03b3 (i 0 , y i 0 ) + \u2211 l =y i 0 H \u03bb * \u2212 B M1 \u03b3 (i 0 , l) > 0,", "formula_coordinates": [10.0, 90.0, 656.18, 432.0, 52.29]}, {"formula_id": "formula_36", "formula_text": "\u2200i : B MH \u03b3 (i, l) = 1 2 + \u03b3 2 if l = y i 1 2 \u2212 \u03b3 2 if l = y i .", "formula_coordinates": [11.0, 228.51, 276.28, 153.79, 38.02]}, {"formula_id": "formula_37", "formula_text": "C\u2208C MH C \u2022 H \u03bb * \u2212 B MH \u03b3 \u2265 min \u03bb\u2208\u2206(H ) max C\u2208C MH C \u2022 H \u03bb \u2212 B MH \u03b3 .", "formula_coordinates": [11.0, 188.1, 379.54, 254.58, 20.37]}, {"formula_id": "formula_38", "formula_text": "min \u03bb\u2208\u2206(H ) max C\u2208C MH C \u2022 H \u03bb \u2212 B MH \u03b3 = max C\u2208C MH min h\u2208H C \u2022 1 h \u2212 B MH \u03b3 .", "formula_coordinates": [11.0, 173.65, 441.89, 264.71, 20.37]}, {"formula_id": "formula_39", "formula_text": "C\u2208C MH min h\u2208H C \u2022 1 h \u2212 B MH \u03b3 ,", "formula_coordinates": [11.0, 255.86, 493.27, 119.06, 20.37]}, {"formula_id": "formula_40", "formula_text": "B(i, 1) = max {B(i, l) + \u03b3 : l = 1} .", "formula_coordinates": [12.0, 231.73, 204.57, 148.54, 18.8]}, {"formula_id": "formula_41", "formula_text": "C\u2208C eor min h\u2208H C \u2022 (1 h \u2212 B) = min \u03bb\u2208\u2206(H ) max C\u2208C eor C \u2022 (H \u03bb \u2212 B) ,", "formula_coordinates": [12.0, 199.89, 506.07, 230.99, 18.65]}, {"formula_id": "formula_42", "formula_text": "C(i, j) = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 \u22121 if j = 1 1 if j = j 0 0", "formula_coordinates": [12.0, 243.03, 591.07, 115.08, 53.23]}, {"formula_id": "formula_43", "formula_text": "\u03bb * \u2208 \u2206(H ) such that \u2200 j = 1, i : H \u03bb * (i, 1) \u2212 H \u03bb * (i, j) > 0.", "formula_coordinates": [13.0, 90.0, 186.82, 294.21, 33.96]}, {"formula_id": "formula_44", "formula_text": "max C\u2208C eor min h\u2208H C \u2022 (1 h \u2212 B) \u2264 min \u03bb\u2208\u2206(H ) max C\u2208C eor C \u2022 (H \u03bb \u2212 B) \u2264 max C\u2208C eor C \u2022 (H \u03bb * \u2212 B) = 0,", "formula_coordinates": [13.0, 131.15, 256.36, 349.7, 18.65]}, {"formula_id": "formula_45", "formula_text": "y i \u25b3 = argmin {B(i, l) : l = y i } .", "formula_coordinates": [14.0, 256.49, 115.06, 126.29, 21.21]}, {"formula_id": "formula_46", "formula_text": "B(i,\u0177 i ) = min {B(i, 1) \u2212 \u03b3, B(i, 2), . . . , B(i, k)} \u2264 1 k (B(i, 1) \u2212 \u03b3 + B(i, 2) + B(i, 3) + . . . + B(i, k)) = 1/k \u2212 \u03b3/k.", "formula_coordinates": [14.0, 175.21, 228.25, 260.41, 59.93]}, {"formula_id": "formula_47", "formula_text": "\u2308m(1/2 \u2212 \u03b3 \u2032 )\u2309 \u2265 m(1/2 \u2212 \u03b3/k)", "formula_coordinates": [14.0, 90.0, 303.87, 133.53, 20.41]}, {"formula_id": "formula_48", "formula_text": "\u2200C \u2208 C eor , \u2203h \u2208 H : C \u2022 1 h \u2264 max B\u2208B eor \u03b3 C \u2022 B.(13)", "formula_coordinates": [14.0, 214.39, 501.34, 307.62, 20.39]}, {"formula_id": "formula_49", "formula_text": "(A) H is boostable (B) \u2203\u03b3 > 0 such that \u2200C \u2208 C eor , \u2203h \u2208 H : C \u2022 1 h \u2264 max B\u2208B eor \u03b3 C \u2022 B (C) \u2203\u03b3 > 0 such that \u2200C \u2208 C MR , \u2203h \u2208 H : C \u2022 1 h \u2264 C \u2022 B MR .", "formula_coordinates": [15.0, 90.0, 165.66, 274.65, 72.17]}, {"formula_id": "formula_50", "formula_text": "(C MR , B MR \u03b3 ). Notice C MR \u2282 C eor . Therefore it suffices to show that \u2200C \u2208 C MR , B \u2208 B eor 2\u03b3 : C \u2022 B \u2212 B MR \u03b3 \u2264 0. Notice that B \u2208 B eor 2\u03b3 implies B \u2032 = B \u2212 B MR \u03b3", "formula_coordinates": [15.0, 90.0, 281.19, 308.11, 71.84]}, {"formula_id": "formula_51", "formula_text": "C \u2022 B \u2032 = m \u2211 i=1 k \u2211 j=2 C(i, j) B \u2032 (i, j) \u2212 B \u2032 (i, 1) .", "formula_coordinates": [15.0, 214.29, 373.3, 183.42, 29.93]}, {"formula_id": "formula_52", "formula_text": "C\u2208C MR min h\u2208H C \u2022 1 h \u2212 B MR \u03b3 \u2265 max C\u2208C MR min \u03bb\u2208\u2206(H ) C \u2022 H \u03bb \u2212 B MR \u03b3 = min \u03bb\u2208\u2206(H ) max C\u2208C MR C \u2022 H \u03bb \u2212 B MR \u03b3 .", "formula_coordinates": [15.0, 236.59, 452.78, 154.24, 69.01]}, {"formula_id": "formula_53", "formula_text": "C(i, l) = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 0 if i = i 0 or l \u2208 {1, l 0 } 1 if i = i 0 , l = l 0 \u22121 if i = i 0 , l = 1.", "formula_coordinates": [15.0, 220.61, 551.25, 169.04, 61.32]}, {"formula_id": "formula_54", "formula_text": "C\u2022 H \u03bb \u2212 B MR \u03b3 \u2264 0 implies H \u03bb (i 0 , 1)\u2212 H \u03bb (i 0 , l 0 ) \u2265 2\u03b3.", "formula_coordinates": [15.0, 90.0, 618.87, 434.1, 34.6]}, {"formula_id": "formula_55", "formula_text": "h 1 h 2 a 1 2 b 1 2", "formula_coordinates": [16.0, 281.38, 92.9, 48.74, 37.32]}, {"formula_id": "formula_56", "formula_text": "C \u2208 C eor is given by 1 2 3 a \u22121 +1 0 b +1 \u22121 0,", "formula_coordinates": [16.0, 90.0, 367.47, 254.68, 71.2]}, {"formula_id": "formula_57", "formula_text": "C \u2208 C \u21d0\u21d2 \u2200i : C(i) \u2208 C 0 . (14)", "formula_coordinates": [17.0, 246.13, 442.86, 275.87, 18.79]}, {"formula_id": "formula_58", "formula_text": "min C 1 \u2208C max h 1 \u2208H all : C 1 \u2022(1 h 1 \u2212B)\u22640 . . . min C T \u2208C max h T \u2208H all : C T \u2022(1 h T \u2212B)\u22640 1 m m \u2211 i=1 L err ( f T (x i , 1), . . . , f T (x i , k)). (15", "formula_coordinates": [17.0, 148.09, 574.49, 369.38, 43.28]}, {"formula_id": "formula_59", "formula_text": ")", "formula_coordinates": [17.0, 517.46, 584.21, 4.54, 9.75]}, {"formula_id": "formula_60", "formula_text": "L err : R k \u2192 R encodes 0-1 error L err (s) = 1 s(1) \u2264 max l>1 s(l) .(16)", "formula_coordinates": [17.0, 174.52, 621.94, 347.49, 43.06]}, {"formula_id": "formula_61", "formula_text": "\u03c6 b 0 (s) = L(s) \u03c6 b t (s) = min c\u2208C 0 max p\u2208\u2206{1,...,k} E l\u223cp \u03c6 b t\u22121 (s + e l ) s.t. E l\u223cp [c(l)] \u2264 b, c ,(17)", "formula_coordinates": [18.0, 192.89, 184.64, 329.12, 57.23]}, {"formula_id": "formula_62", "formula_text": "s t (l) = t\u22121 \u2211 t \u2032 =1 1 [h t \u2032 (x) = l] .(18)", "formula_coordinates": [18.0, 252.69, 338.56, 269.31, 31.95]}, {"formula_id": "formula_63", "formula_text": "f t (l) = t\u22121 \u2211 t \u2032 =1 \u03b1 t \u2032 1 [h t \u2032 (x) = l] .(19)", "formula_coordinates": [18.0, 247.94, 430.91, 274.07, 31.95]}, {"formula_id": "formula_64", "formula_text": "\u2203p \u2208 \u2206 {1, . . . , k} : E l\u223cp [c(l)] \u2264 c, b \u21d0\u21d2 min l c(l) \u2264 b, c .(20)", "formula_coordinates": [18.0, 170.7, 550.72, 351.31, 19.47]}, {"formula_id": "formula_65", "formula_text": "c(h(x i )) = C (i, h(x i )) \u2264 C(i), B(i) = c, b < min l c(l),", "formula_coordinates": [19.0, 182.98, 134.01, 246.05, 18.65]}, {"formula_id": "formula_66", "formula_text": "\u03c6 b t (s) = min c\u2208C 0 k max l=1 \u03c6 b t\u22121 (s + e l ) \u2212 (c(l) \u2212 c, b ) . (21", "formula_coordinates": [19.0, 197.96, 276.27, 319.51, 23.06]}, {"formula_id": "formula_67", "formula_text": ")", "formula_coordinates": [19.0, 517.46, 281.49, 4.54, 9.75]}, {"formula_id": "formula_68", "formula_text": "\u03c6 b t (s) = min c\u2208C 0 max p\u2208\u2206{1,...,k} min \u03bb\u22650 E l\u223cp \u03c6 b t\u22121 (s + e l ) \u2212 \u03bb (E l\u223cp [c(l)] \u2212 c, b ) .", "formula_coordinates": [19.0, 144.22, 340.48, 323.55, 20.49]}, {"formula_id": "formula_69", "formula_text": "\u03c6 b t (s) = min c\u2208C 0 min \u03bb\u22650 max p\u2208\u2206{1,...,k} E l\u223cp \u03c6 b t\u22121 (s + e l ) \u2212 (E l\u223cp [\u03bbc(l)] \u2212 \u03bbc, b ) .", "formula_coordinates": [19.0, 141.83, 395.88, 328.34, 20.5]}, {"formula_id": "formula_70", "formula_text": "\u03c6 b t (s) = min c\u2208C 0 max p\u2208\u2206{1,...,k} E l\u223cp \u03c6 b t\u22121 (s + e l ) \u2212 (c(l) \u2212 c, b ) .", "formula_coordinates": [19.0, 177.42, 469.6, 257.17, 20.5]}, {"formula_id": "formula_71", "formula_text": "C t (i) = argmin c\u2208C 0 k max l=1 \u03c6 B(i) T \u2212t\u22121 (s + e l ) \u2212 (c(l) \u2212 c, B(i) ) . (22", "formula_coordinates": [19.0, 178.46, 619.98, 339.0, 24.74]}, {"formula_id": "formula_72", "formula_text": ")", "formula_coordinates": [19.0, 517.46, 625.2, 4.54, 9.75]}, {"formula_id": "formula_73", "formula_text": "1 m m \u2211 i=1 \u03c6 B(i) T \u2212t (s t (i)) ,", "formula_coordinates": [20.0, 268.11, 159.25, 76.97, 29.94]}, {"formula_id": "formula_74", "formula_text": "1 m m \u2211 i=1 \u03c6 B(i) T (0).(23)", "formula_coordinates": [20.0, 276.24, 220.69, 245.77, 29.93]}, {"formula_id": "formula_75", "formula_text": "sup s,s \u2032 \u2208S T |L(s) \u2212 L(s \u2032 )| \u2264 (L, T ),(24)", "formula_coordinates": [20.0, 239.24, 301.15, 282.77, 27.89]}, {"formula_id": "formula_76", "formula_text": "m \u2265 T (L, T ) \u03b5 ,(25)", "formula_coordinates": [20.0, 271.58, 392.77, 250.42, 26.03]}, {"formula_id": "formula_77", "formula_text": "\u2206 k \u03b3 = {b \u2208 \u2206 {1, . . . , k} : b(1) \u2212 \u03b3 = max {b(2), . . . , b(k)}} .(26)", "formula_coordinates": [20.0, 178.54, 623.26, 343.46, 20.43]}, {"formula_id": "formula_78", "formula_text": "\u03c6 b t (s) = E l\u223cb [\u03c6 t\u22121 (s + e l )] .(27)", "formula_coordinates": [21.0, 237.74, 132.83, 284.27, 14.38]}, {"formula_id": "formula_79", "formula_text": "C t (i, l) = \u03c6 b T \u2212t\u22121 (s t (i) + e l ),(28)", "formula_coordinates": [21.0, 244.22, 187.8, 277.79, 20.37]}, {"formula_id": "formula_80", "formula_text": "\u03c6 b t (s) = min c\u2208C eor 0 max p\u2208\u2206{1,...,k} E l\u223cp [\u03c6 t\u22121 (s + e l )] s.t. E l\u223cp [c(l)] \u2264 E l\u223cb [c(l)] , ( by (17) ) = min c\u2208C eor 0 max p\u2208\u2206 min \u03bb\u22650 E l\u223cp \u03c6 b t\u22121 (s + e l ) + \u03bb (E l\u223cb [c(l)] \u2212 E l\u223cp [c(l)]) (Lagrangean) = min c\u2208C eor 0 min \u03bb\u22650 max p\u2208\u2206 E l\u223cp \u03c6 b t\u22121 (s + e l ) + \u03bb b \u2212 p, c (Theorem 1) = min c\u2208C eor 0 max p\u2208\u2206 E l\u223cp \u03c6 b t\u22121 (s + e l ) + b \u2212 p, c (absorb \u03bb into c) = max p\u2208\u2206 min c\u2208C eor 0 E l\u223cp \u03c6 b t\u22121 (s + e l ) + b \u2212 p, c (Theorem 1) .", "formula_coordinates": [21.0, 105.87, 270.53, 399.05, 133.41]}, {"formula_id": "formula_81", "formula_text": "max p\u2208\u2206 E l\u223cp \u03c6 b t\u22121 (s + e l ) s.t. b(l) \u2212 q(l) \u2265 0 if l = 1, \u2264 0 if l > 1.", "formula_coordinates": [21.0, 230.38, 471.33, 150.04, 57.79]}, {"formula_id": "formula_82", "formula_text": "k max l=1 \u03c6 B(i) T \u2212t\u22121 (s + e l ) \u2212 (C t (i, l) \u2212 C t (i), B(i) ) (29) is equal to min c\u2208C 0 k max l=1 \u03c6 B(i) T \u2212t\u22121 (s + e l ) \u2212 (c(l) \u2212 c, B(i) ) = \u03c6 B(i) T \u2212t (s) ,(30)", "formula_coordinates": [21.0, 90.0, 635.04, 432.0, 74.54]}, {"formula_id": "formula_83", "formula_text": "\u03c6 B(i) T \u2212t\u22121 (s + e l ) \u2212 \u03c6 B(i) T \u2212t\u22121 (s + e l ) \u2212 C t (i), B(i) = B(i), C t (i) = E l\u223cB(i) [C t (i, l)] = E l\u223cB(i) \u03c6 B(i) T \u2212t\u22121 (s + e l ) = \u03c6 B(i) T \u2212t (s),", "formula_coordinates": [22.0, 188.03, 130.83, 224.01, 101.4]}, {"formula_id": "formula_84", "formula_text": "B(i) T \u2212t (s),", "formula_coordinates": [22.0, 95.69, 249.74, 30.14, 22.08]}, {"formula_id": "formula_85", "formula_text": "\u03c6 b t (s) = E L R t b (s) . (31", "formula_coordinates": [22.0, 255.31, 371.37, 262.15, 14.38]}, {"formula_id": "formula_86", "formula_text": ")", "formula_coordinates": [22.0, 517.46, 374.02, 4.54, 9.75]}, {"formula_id": "formula_87", "formula_text": "Proof Inductively assuming \u03c6 b t\u22121 (x) = E L(R t\u22121 b (x)) , \u03c6 t (s) = E l\u223cb L(R t\u22121 b (s) + e l ) = E L(R t b (s)) .", "formula_coordinates": [22.0, 90.0, 396.98, 311.65, 40.54]}, {"formula_id": "formula_88", "formula_text": "L exp \u03b7 (s) = k \u2211 l=2 e \u03b7(s l \u2212s 1 ) . (32", "formula_coordinates": [22.0, 258.14, 640.38, 259.32, 30.1]}, {"formula_id": "formula_89", "formula_text": ")", "formula_coordinates": [22.0, 517.46, 650.1, 4.54, 9.75]}, {"formula_id": "formula_90", "formula_text": "L exp (f t ) = k \u2211 l=2 e f t (l)\u2212 f t (1) . (33", "formula_coordinates": [23.0, 252.97, 122.88, 264.49, 30.1]}, {"formula_id": "formula_91", "formula_text": ")", "formula_coordinates": [23.0, 517.46, 132.6, 4.54, 9.75]}, {"formula_id": "formula_92", "formula_text": "\u03c6 t (s) = \u03c6 t ( f ) = \u03ba(\u03b3, \u03b7) t k \u2211 l=2 e \u03b7(s l \u2212s 1 ) = \u03ba(\u03b3, \u03b7) t k \u2211 l=2 e f l \u2212 f 1 (34", "formula_coordinates": [23.0, 185.83, 327.02, 331.63, 30.1]}, {"formula_id": "formula_93", "formula_text": ")", "formula_coordinates": [23.0, 517.46, 336.74, 4.54, 9.75]}, {"formula_id": "formula_94", "formula_text": "\u03ba(\u03b3, \u03b7) = 1 + (1 \u2212 \u03b3) k e \u03b7 + e \u2212\u03b7 \u2212 2 \u2212 1 \u2212 e \u2212\u03b7 \u03b3. (35", "formula_coordinates": [23.0, 194.99, 383.02, 322.47, 26.22]}, {"formula_id": "formula_95", "formula_text": ")", "formula_coordinates": [23.0, 517.46, 391.39, 4.54, 9.75]}, {"formula_id": "formula_96", "formula_text": "C(i, l) = (e \u03b7 \u2212 1) e \u03b7(s l \u2212s 1 ) if l > 1, (e \u2212\u03b7 \u2212 1) \u2211 k l=2 e \u03b7(s l \u2212s 1 ) if l = 1.", "formula_coordinates": [23.0, 206.47, 470.63, 197.31, 36.8]}, {"formula_id": "formula_97", "formula_text": "C(i, l) = (e \u03b7 \u2212 1) e f l \u2212 f 1 if l > 1, (e \u2212\u03b7 \u2212 1) \u2211 k l=2 e f l \u2212 f 1 if l = 1. (36", "formula_coordinates": [23.0, 211.45, 543.44, 306.01, 36.8]}, {"formula_id": "formula_98", "formula_text": ")", "formula_coordinates": [23.0, 517.46, 553.74, 4.54, 9.75]}, {"formula_id": "formula_99", "formula_text": "1 m m \u2211 i=1 L exp \u03b7 (s t (i)) = 1 m m \u2211 i=1 L exp (f t (i))(37)", "formula_coordinates": [23.0, 230.51, 609.62, 291.5, 29.93]}, {"formula_id": "formula_100", "formula_text": "\u03c6 b t (s) = 1 \u2212 t \u2211 x 1 ,...,x k t x 1 ,...,x k \u220f k l=1 b x l l s.t. x 1 + . . . + x k = t \u2200l : x l \u2265 0 \u2200l : x l + s l \u2264 x 1 + s 1 .", "formula_coordinates": [24.0, 199.31, 216.06, 213.37, 84.17]}, {"formula_id": "formula_101", "formula_text": "b = ( 1\u2212\u03b3 k +\u03b3, 1\u2212\u03b3 k , 1\u2212\u03b3 k , . . . , 1\u2212\u03b3 k )", "formula_coordinates": [24.0, 142.31, 437.08, 134.96, 16.0]}, {"formula_id": "formula_102", "formula_text": "b = ( 1\u2212\u03b3 k + \u03b3, 1\u2212\u03b3 k , 1\u2212\u03b3 k , . . . , 1\u2212\u03b3 k ). (a)", "formula_coordinates": [25.0, 135.15, 291.0, 386.85, 31.35]}, {"formula_id": "formula_103", "formula_text": "S C = h \u2208 H all : C \u2022 1 h \u2264 C \u2022 B .", "formula_coordinates": [25.0, 231.04, 692.97, 149.92, 20.37]}, {"formula_id": "formula_104", "formula_text": "\u2200C 1 \u2208 C 1 , \u2203C 2 \u2208 C 2 : S C 1 \u2286 S C 2 .", "formula_coordinates": [26.0, 235.2, 189.78, 141.61, 18.79]}, {"formula_id": "formula_105", "formula_text": "h C 2 \u2208 S C 2 \\ S C 1 . Therefore, the space H = {h C 2 : C 2 \u2208 C 2 } ,", "formula_coordinates": [26.0, 90.0, 480.06, 264.81, 47.18]}, {"formula_id": "formula_106", "formula_text": "\u03c6 t (s) = min c\u2208C eor 0 max b\u2208\u2206 k \u03b3 max p\u2208\u2206{1,...,k} E l\u223cp [\u03c6 t\u22121 (s + e l )] s.t. E l\u223cp [c(l)] \u2264 b, c .(38)", "formula_coordinates": [27.0, 189.15, 328.81, 332.85, 41.75]}, {"formula_id": "formula_107", "formula_text": "\u03c6 t (s) = min c\u2208C eor 0 max b\u2208\u2206 k \u03b3 k max l=1 {\u03c6 t\u22121 (s + e l ) \u2212 (c(l) \u2212 c, b )} .", "formula_coordinates": [27.0, 186.98, 432.16, 238.03, 24.27]}, {"formula_id": "formula_108", "formula_text": "C t (i) \u2208 argmin c\u2208C eor 0 max b\u2208\u2206 k \u03b3 k max l=1 {\u03c6 t\u22121 (s + e l ) \u2212 (c(l) \u2212 c, b )} . (39", "formula_coordinates": [27.0, 183.05, 498.47, 334.41, 26.13]}, {"formula_id": "formula_109", "formula_text": ")", "formula_coordinates": [27.0, 517.46, 503.68, 4.54, 9.75]}, {"formula_id": "formula_110", "formula_text": "1 m m \u2211 i=1 \u03c6 T \u2212t (s t (i)) ,", "formula_coordinates": [27.0, 268.11, 610.51, 76.97, 29.94]}, {"formula_id": "formula_111", "formula_text": "\u03c6 t (s) = max b\u2208\u2206 k \u03b3 E l\u223cb [\u03c6 t\u22121 (s + e l )] .(40)", "formula_coordinates": [28.0, 228.67, 266.52, 293.33, 20.68]}, {"formula_id": "formula_112", "formula_text": "C t (i, l) = \u03c6 T \u2212t\u22121 (s t (i) + e l ),(41)", "formula_coordinates": [28.0, 244.22, 322.81, 277.79, 17.65]}, {"formula_id": "formula_113", "formula_text": "\u03c6 t\u22121 s + e \u03c0(k) \u2265 \u03c6 t\u22121 s + e \u03c0(k\u22121) \u2265 . . . \u2265 \u03c6 t\u22121 s + e \u03c0(2) .(42)", "formula_coordinates": [28.0, 174.74, 474.04, 347.27, 18.83]}, {"formula_id": "formula_114", "formula_text": "a coordinates {1, \u03c0 k , \u03c0 k\u22121 , . . . , \u03c0 k\u2212a+2 }: b \u03c0 a (l) = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 1\u2212\u03b3 a + \u03b3 if l = 1 1\u2212\u03b3 a if l \u2208 {\u03c0 k , . . . , \u03c0 k\u2212a+2 } 0 otherwise. (43", "formula_coordinates": [28.0, 119.69, 511.54, 397.77, 68.73]}, {"formula_id": "formula_115", "formula_text": ")", "formula_coordinates": [28.0, 517.46, 553.73, 4.54, 9.75]}, {"formula_id": "formula_116", "formula_text": "\u03c6 t (s) = max b\u2208\u2206 k \u03b3 E l\u223cb [\u03c6 t\u22121 (s + e l )] = max 2\u2264a\u2264k E l\u223cb \u03c0 a [\u03c6 t\u22121 (s + e l )] .(44)", "formula_coordinates": [28.0, 164.78, 681.07, 357.22, 20.69]}, {"formula_id": "formula_117", "formula_text": "b(k) = \u2022 \u2022 \u2022 = b(k \u2212 a + 2) = b(1) \u2212 \u03b3, b(k \u2212 a + 1) \u2264 b(1) \u2212 \u03b3, b(k \u2212 a) = \u2022 \u2022 \u2022 = b(2) = 0.", "formula_coordinates": [29.0, 217.02, 169.73, 176.77, 51.9]}, {"formula_id": "formula_118", "formula_text": "k \u2212 a + 1. This implies b(k \u2212 a + 1) \u2208 [0, 1/(a + 1)]. Now, E l\u223cb [\u03c6 t\u22121 (s + e l )", "formula_coordinates": [29.0, 106.94, 238.59, 247.64, 25.07]}, {"formula_id": "formula_119", "formula_text": "\u03b3 \u2022 \u03c6 t\u22121 (s + e 1 ) + b(k \u2212 a + 1)\u03c6 t\u22121 (s + e k\u2212a+1 ) + (1 \u2212 \u03b3 \u2212 b(k \u2212 a + 1)) \u03c6 t\u22121 (s + e 1 ) + \u03c6 t\u22121 (s + e k\u2212a+2 ) + . . . \u03c6 t\u22121 (s + e k ) a = \u03b3 \u2022 \u03c6 t\u22121 (s + e 1 ) + b(k \u2212 a + 1) 1 \u2212 \u03b3 \u03c6 t\u22121 (s + e k\u2212a+1 ) + (1 \u2212 \u03b3) 1 \u2212 b(k \u2212 a + 1) 1 \u2212 \u03b3 \u03c6 t\u22121 (s + e 1 ) + \u03c6 t\u22121 (s + e k\u2212a+2 ) + . . . \u03c6 t\u22121 (s + e k ) a", "formula_coordinates": [29.0, 126.58, 274.03, 360.34, 105.49]}, {"formula_id": "formula_120", "formula_text": "\u03b3 \u2022 \u03c6 t\u22121 (s + e 1 ) + (1 \u2212 \u03b3) \u03c6 t\u22121 (s + e 1 ) + \u03c6 t\u22121 (s + e k\u2212a+1 ) + . . . \u03c6 t\u22121 (s + e k ) a + 1 . Since b(k \u2212 a + 1) lies in [0, 1/(a + 1)]", "formula_coordinates": [29.0, 90.0, 468.34, 377.32, 52.28]}, {"formula_id": "formula_121", "formula_text": "= (s 1 , s 2 , s 3 ) are compressed into 2-dimensional pixel coordinates (u = s 2 \u2212 s 1 , v = s 3 \u2212 s 2 ).", "formula_coordinates": [30.0, 90.0, 530.01, 432.0, 32.2]}, {"formula_id": "formula_122", "formula_text": "\u03b7 \u2264 1 4 min 1 k \u2212 1 , 1 T ,(46)", "formula_coordinates": [33.0, 252.9, 131.65, 269.11, 32.72]}, {"formula_id": "formula_123", "formula_text": "u = 1 \u2212 \u03b3 k + \u03b3, 1 \u2212 \u03b3 k , . . . , 1 \u2212 \u03b3 k ,(47)", "formula_coordinates": [33.0, 229.71, 208.7, 292.3, 25.5]}, {"formula_id": "formula_124", "formula_text": "\u03c6 0 = \u03c6 u 0 = L exp \u03b7 . Assume, inductively that \u03c6 t\u22121 (s) = \u03c6 u t\u22121 (s) = \u03ba(\u03b3, \u03b7) t\u22121 k \u2211 l=2 e \u03b7(s l \u2212s 1 ) ,(48)", "formula_coordinates": [33.0, 213.09, 277.42, 308.91, 58.73]}, {"formula_id": "formula_125", "formula_text": "\u03c6 t (s) = E l\u223cu [\u03c6 t\u22121 (s + e l )] .(49)", "formula_coordinates": [33.0, 246.82, 372.62, 275.19, 12.33]}, {"formula_id": "formula_126", "formula_text": "E l\u223cb \u03c0 a [\u03c6 t\u22121 (s + e l )] \u2264 E l\u223cb \u03c0 k [\u03c6 t\u22121 (s + e l )] .(50)", "formula_coordinates": [33.0, 212.86, 464.66, 309.15, 19.47]}, {"formula_id": "formula_127", "formula_text": "\u03be l 0 = (e \u03b7 \u2212 1)e \u03b7(s l 0 \u2212s 1 ) if l 0 = 1, (e \u2212\u03b7 \u2212 1) \u2211 k l=2 e \u03b7(s l \u2212s 1 ) if l 0 = 1.", "formula_coordinates": [33.0, 212.42, 517.42, 185.97, 37.35]}, {"formula_id": "formula_128", "formula_text": "E l\u223cb \u03c0 a [\u03be l ] \u2264 E l\u223cb \u03c0 k [\u03be l ]", "formula_coordinates": [33.0, 224.65, 561.55, 94.49, 19.47]}, {"formula_id": "formula_129", "formula_text": "E l\u223cb \u03c0 a [\u03be l ] = 1 \u2212 \u03b3 a + \u03b3 \u03be 1 + k \u2211 l=k\u2212a+2 1 \u2212 \u03b3 a \u03be l = \u03b3\u03be 1 + (1 \u2212 \u03b3) \u03be 1 + \u2211 k l=k\u2212a+2 \u03be l a .", "formula_coordinates": [33.0, 190.46, 601.91, 230.18, 63.75]}, {"formula_id": "formula_130", "formula_text": "(e \u03b7 \u2212 1) k \u2211 l=k\u2212a+2 e \u03b7(s l \u2212s 1 ) \u2212 (1 \u2212 e \u2212\u03b7 ) k \u2211 l=2 e \u03b7(s l \u2212s 1 ) = (e \u03b7 \u2212 1) k \u2211 l=k\u2212a+2 e \u03b7(s l \u2212s 1 ) \u2212 k \u2211 l=2 e \u03b7(s l \u2212s 1 ) + (e \u03b7 \u2212 1) \u2212 (1 \u2212 e \u2212\u03b7 ) k \u2211 l=2 e \u03b7(s l \u2212s 1 ) = e \u03b7 + e \u2212\u03b7 \u2212 2 k \u2211 l=2 e \u03b7(s l \u2212s 1 ) \u2212 (e \u03b7 \u2212 1) k\u2212a+1 \u2211 l=2 e \u03b7(s l \u2212s 1 ) .", "formula_coordinates": [34.0, 128.64, 118.4, 364.19, 103.49]}, {"formula_id": "formula_131", "formula_text": "(k \u2212 1) e \u03b7 + e \u2212\u03b7 \u2212 2 e 2\u03b7T \u2212 (e \u03b7 \u2212 1)e \u22122\u03b7T = (e \u03b7 \u2212 1)e \u22122\u03b7T (k \u2212 1)(1 \u2212 e \u2212\u03b7 )e 4\u03b7T \u2212 1 .", "formula_coordinates": [34.0, 206.64, 297.08, 207.2, 38.72]}, {"formula_id": "formula_132", "formula_text": "m \u2265 Te 1/4 \u03b5 . (51", "formula_coordinates": [34.0, 280.82, 464.1, 236.64, 27.21]}, {"formula_id": "formula_133", "formula_text": ")", "formula_coordinates": [34.0, 517.46, 473.46, 4.54, 9.75]}, {"formula_id": "formula_134", "formula_text": "C t \u2022 1 h \u2264 C t \u2022 U \u03b3 ,", "formula_coordinates": [35.0, 267.61, 171.49, 76.77, 18.65]}, {"formula_id": "formula_135", "formula_text": "C t \u2022 1 h \u2264 max B\u2208B eor \u03b3 C t \u2022 B.", "formula_coordinates": [35.0, 256.81, 218.79, 98.39, 18.67]}, {"formula_id": "formula_136", "formula_text": "C t \u2022 U \u03b3 = max B\u2208B eor \u03b3 C t \u2022 B eor \u03b3 . (52", "formula_coordinates": [35.0, 250.12, 284.42, 267.34, 20.39]}, {"formula_id": "formula_137", "formula_text": ")", "formula_coordinates": [35.0, 517.46, 286.94, 4.54, 9.75]}, {"formula_id": "formula_138", "formula_text": "\u2200i : C t (i), u = max b\u2208\u2206 k \u03b3 C t (i), b .(53)", "formula_coordinates": [35.0, 237.55, 339.93, 284.46, 19.86]}, {"formula_id": "formula_139", "formula_text": "C t (i), b = E l\u223cb [\u03c6 T \u2212t\u22121 (s t (i) + e l )] .", "formula_coordinates": [35.0, 228.08, 397.61, 160.08, 18.29]}, {"formula_id": "formula_140", "formula_text": "\u03b7 \u2264 k\u03b3 1 \u2212 \u03b3 . (54", "formula_coordinates": [36.0, 282.62, 141.17, 234.84, 32.79]}, {"formula_id": "formula_141", "formula_text": ")", "formula_coordinates": [36.0, 517.46, 148.64, 4.54, 9.75]}, {"formula_id": "formula_142", "formula_text": "\u03b3 \u2264 min 1 2 , 1 8k min 1 k , 1 T , (55", "formula_coordinates": [36.0, 236.38, 196.21, 281.08, 25.23]}, {"formula_id": "formula_143", "formula_text": ")", "formula_coordinates": [36.0, 517.46, 203.59, 4.54, 9.75]}, {"formula_id": "formula_144", "formula_text": "1 \u2212 e \u2212\u03b7 \u03b3 \u2265 e \u03b7 + e \u2212\u03b7 \u2212 2 1 \u2212 \u03b3 k i.e., k\u03b3 1 \u2212 \u03b3 \u2265 e \u03b7 + e \u2212\u03b7 \u2212 2 1 \u2212 e \u2212\u03b7 = e \u03b7 \u2212 1 \u2265 \u03b7.", "formula_coordinates": [36.0, 211.95, 353.04, 193.1, 64.04]}, {"formula_id": "formula_145", "formula_text": "C t (i, l) = (e \u03b7 \u2212 1) e f t\u22121 (i, j)\u2212 f t\u22121 (i,1) if l > 1, (e \u2212\u03b7 \u2212 1) \u2211 k j=2 e f t\u22121 (i, j)\u2212 f t\u22121 (i,1) if l = 1.", "formula_coordinates": [37.0, 188.22, 610.82, 233.83, 36.8]}, {"formula_id": "formula_146", "formula_text": "C t (i, l) = lim \u03b7\u21920 C \u03b7 (i, l) \u25b3 = 1 \u03b7 (e \u03b7 \u2212 1) e f t\u22121 (i, j)\u2212 f t\u22121 (i,1) if l > 1, (e \u2212\u03b7 \u2212 1) \u2211 k j=2 e f t\u22121 (i, j)\u2212 f t\u22121 (i,1) if l = 1. = e f t\u22121 (i, j)\u2212 f t\u22121 (i,1) if l > 1, \u2212 \u2211 k j=2 e f t\u22121 (i, j)\u2212 f t\u22121 (i,1) if l = 1. (56", "formula_coordinates": [38.0, 143.78, 145.38, 373.68, 73.5]}, {"formula_id": "formula_147", "formula_text": ")", "formula_coordinates": [38.0, 517.46, 192.38, 4.54, 9.75]}, {"formula_id": "formula_148", "formula_text": "(e \u03b1 t \u2212 1) \u2211 i\u2208S \u2212 e f t\u22121 (i,h t (i))\u2212 f t\u22121 (i,1) \u2212 1 \u2212 e \u2212\u03b1 t \u2211 i\u2208S + L exp (f t\u22121 (i)) = (e \u03b1 t \u2212 1) A t \u2212 \u2212 1 \u2212 e \u2212\u03b1 t A t + = A t + e \u2212\u03b1 t + A t \u2212 e \u03b1 t \u2212 A t + + A t \u2212 ,", "formula_coordinates": [38.0, 168.02, 437.96, 285.93, 64.88]}, {"formula_id": "formula_149", "formula_text": "\u03b1 t = 1 2 ln A t + A t \u2212 .(57)", "formula_coordinates": [38.0, 266.96, 572.19, 255.04, 34.7]}, {"formula_id": "formula_150", "formula_text": "(1 \u2212 c t ) \u2212 c 2 t \u2212 \u03b4 2 t ,(58)", "formula_coordinates": [38.0, 261.27, 654.13, 260.73, 19.68]}, {"formula_id": "formula_151", "formula_text": "c t = (A t + + A t \u2212 )/Z t\u22121 ,", "formula_coordinates": [38.0, 258.16, 692.91, 95.69, 20.29]}, {"formula_id": "formula_152", "formula_text": "C t \u2022 1 h \u2264 max B\u2208B eor \u03b3 C t \u2022 B.", "formula_coordinates": [39.0, 256.81, 163.31, 98.39, 18.68]}, {"formula_id": "formula_153", "formula_text": "\u03b4 t = sup \u03b3 : C t \u2022 1 h t \u2264 C t \u2022 U \u03b3 = sup \u03b3 : C t \u2022 1 h t \u2264 \u2212\u03b3 m \u2211 i=1 k \u2211 l=2 e f t\u22121 (i,l)\u2212 f t\u22121 (i,1) =\u21d2 \u03b4 t = \u03b3 : C t \u2022 1 h t = \u2212\u03b3 m \u2211 i=1 k \u2211 l=2 e f t\u22121 (i,l)\u2212 f t\u22121 (i,1) =\u21d2 \u03b4 t = \u2212C t \u2022 1 h t \u2211 m i=1 \u2211 k l=2 e f t\u22121 (i,l)\u2212 f t\u22121 (i,1) = \u2212C t \u2022 1 h t Z t ,(59)", "formula_coordinates": [39.0, 177.05, 245.52, 344.96, 116.44]}, {"formula_id": "formula_154", "formula_text": "C t \u2022 1 h t \u2264 C t \u2022 U \u03b4 t .", "formula_coordinates": [39.0, 162.83, 517.92, 83.85, 18.65]}, {"formula_id": "formula_155", "formula_text": "1 \u2212 1 2 (e \u03b1 t \u2212 e \u2212\u03b1 t )\u03b4 t + 1 2 (e \u03b1 t + e \u2212\u03b1 t \u2212 2)", "formula_coordinates": [39.0, 219.47, 544.76, 173.05, 25.23]}, {"formula_id": "formula_156", "formula_text": "\u03b1 t = 1 2 ln 1 + \u03b4 t 1 \u2212 \u03b4 t ,(60)", "formula_coordinates": [39.0, 260.95, 600.48, 261.06, 33.7]}, {"formula_id": "formula_157", "formula_text": "A t \u2212 \u2212 A t + = C t \u2022 1 h t \u2264 C t \u2022 U \u03b4 t = \u2212\u03b4 t Z t\u22121 =\u21d2 A t + \u2212 A t \u2212 \u2265 \u03b4 t Z t\u22121 .", "formula_coordinates": [39.0, 151.08, 692.91, 289.91, 20.43]}, {"formula_id": "formula_158", "formula_text": "A t \u2212 = e \u03b1 t \u2212 e \u2212\u03b1 t 2 A t + \u2212 A t \u2212 \u2212 e \u03b1 t + e \u2212\u03b1 t \u2212 2 2 A t + + A t \u2212 .", "formula_coordinates": [40.0, 174.27, 112.41, 273.44, 44.21]}, {"formula_id": "formula_159", "formula_text": "1 \u2212 1 2 (e \u03b1 t \u2212 e \u2212\u03b1 t )\u03b4 t + 1 2 (e \u03b1 t + e \u2212\u03b1 t \u2212 2) = 1 2 (1 \u2212 \u03b4 t )e \u03b1 t + (1 + \u03b4 t )e \u2212\u03b1 t .", "formula_coordinates": [40.0, 144.3, 196.61, 323.4, 25.24]}, {"formula_id": "formula_160", "formula_text": "(k \u2212 1) \u220f T t=1 1 \u2212 \u03b4 2 t \u2264 (k \u2212 1) exp \u2212(1/2) \u2211 T t=1 \u03b4 2 t .", "formula_coordinates": [40.0, 90.0, 417.0, 432.0, 33.24]}, {"formula_id": "formula_161", "formula_text": "\u03b4 t = \u2212 \u2211 m i=1 C t (i, h t (x i )) \u2211 m", "formula_coordinates": [41.0, 247.69, 268.25, 120.78, 28.34]}, {"formula_id": "formula_162", "formula_text": "\u03b1 t = 1 2 ln 1 + \u03b4 t 1 \u2212 \u03b4 t ,(61)", "formula_coordinates": [41.0, 271.85, 319.52, 250.15, 33.7]}, {"formula_id": "formula_163", "formula_text": "\u03b1 t = 1 2 ln \u2211 i:h t (x i )=y i \u2211 l =y i e f t\u22121 (i,l)\u2212 f t\u22121 (i,y i ) \u2211 i:h t (x i ) =y i e f t\u22121 (i,h t (x i ))\u2212 f t\u22121 (i,y i )(62)", "formula_coordinates": [41.0, 217.83, 375.41, 304.18, 31.28]}, {"formula_id": "formula_164", "formula_text": "f t (i, l) = f t\u22121 (i, l) + \u03b1 t 1 [h t (x i ) = l] .", "formula_coordinates": [41.0, 239.56, 432.23, 156.34, 11.66]}, {"formula_id": "formula_165", "formula_text": "F T (x, l) = T \u2211 t=1 \u03b1 t 1 [h t (x) = l] .(63)", "formula_coordinates": [41.0, 248.65, 489.64, 273.35, 29.93]}, {"formula_id": "formula_166", "formula_text": "H T (x) = k argmax l=1 F T (x, l).", "formula_coordinates": [41.0, 256.64, 554.99, 109.67, 23.92]}, {"formula_id": "formula_167", "formula_text": "F \u03b1 (x, l) = \u2211 h\u2208H \u03b1(h)1 [h(x) = l] .", "formula_coordinates": [42.0, 237.29, 467.75, 137.41, 23.62]}, {"formula_id": "formula_168", "formula_text": "risk(F) \u25b3 = 1 m m \u2211 i=1 \u2211 l =y i e F(x i ,l)\u2212F(x i ,y i ) .", "formula_coordinates": [42.0, 231.66, 535.21, 148.68, 30.98]}, {"formula_id": "formula_169", "formula_text": "risk(F T ) \u2212 inf \u03b1:H \u2192R risk(F \u03b1 ) \u2264 C T ,", "formula_coordinates": [42.0, 236.0, 660.3, 140.01, 30.72]}, {"formula_id": "formula_170", "formula_text": "risk D (F) = E (x,y)\u223cD \u2211", "formula_coordinates": [43.0, 220.19, 166.6, 106.56, 15.52]}, {"formula_id": "formula_171", "formula_text": "F T (x, l) \u25b3 = max \u2212C, F T (x, l) \u2212 max l \u2032 F T (x, l \u2032 ) . (64", "formula_coordinates": [43.0, 203.08, 245.29, 314.38, 21.72]}, {"formula_id": "formula_172", "formula_text": ")", "formula_coordinates": [43.0, 517.46, 248.68, 4.54, 9.75]}, {"formula_id": "formula_173", "formula_text": "Pr risk D (F T m ) \u2264 inf F:X \u00d7Y \u2192R risk D (F) + O m \u2212c \u2265 1 \u2212 1 m 2 ,", "formula_coordinates": [43.0, 175.89, 316.91, 260.22, 30.02]}, {"formula_id": "formula_174", "formula_text": "err D (H) = Pr (x,y)\u223cD [H(x) = y] .", "formula_coordinates": [43.0, 242.06, 483.17, 127.87, 17.98]}, {"formula_id": "formula_175", "formula_text": "H:X \u2192Y err D (H),", "formula_coordinates": [43.0, 300.53, 541.42, 69.4, 23.44]}, {"formula_id": "formula_176", "formula_text": "H(x) \u2208 argmax l\u2208Y F(x, y),(65)", "formula_coordinates": [43.0, 255.57, 662.26, 266.43, 19.81]}, {"formula_id": "formula_177", "formula_text": "F \u2032 :X \u00d7Y \u2192R risk D (F \u2032 ) + \u03b5,(66)", "formula_coordinates": [44.0, 279.56, 117.84, 242.45, 25.74]}, {"formula_id": "formula_178", "formula_text": "\u2211 x\u2208X D(x, H \u2032 (x)) = \u2211 x\u2208X p(x)p x H \u2032 (x) .", "formula_coordinates": [44.0, 234.13, 297.99, 143.73, 23.44]}, {"formula_id": "formula_179", "formula_text": "err D (H) \u2212 err D (H opt ) = \u2211 x\u2208X \u2032 p(x) p x H opt (x) \u2212 p x H(x) .(67)", "formula_coordinates": [44.0, 192.73, 376.88, 329.27, 24.8]}, {"formula_id": "formula_180", "formula_text": "risk D (F \u2032 ) = \u2211 x\u2208X p(x) \u2211 l<l \u2032", "formula_coordinates": [44.0, 168.42, 453.66, 104.94, 25.33]}, {"formula_id": "formula_181", "formula_text": "F \u2032 (x, l) \u2212 F \u2032 (x, l \u2032 ) = 1 2 ln p x l \u2212 1 2 ln p x l \u2032 .", "formula_coordinates": [44.0, 295.79, 523.47, 161.36, 20.41]}, {"formula_id": "formula_182", "formula_text": "\u03b5 \u2265 risk D (F) \u2212 risk D (F * ) = \u2211 x\u2208X p(x) \u2211 l =l \u2032 L l,l \u2032 F \u2212 L l,l \u2032 F * \u2265 \u2211 x\u2208X \u2032 p(x) L H(x),H opt (x) F \u2212 L H(x),H opt (x) F * . (68", "formula_coordinates": [44.0, 152.99, 609.44, 364.47, 58.19]}, {"formula_id": "formula_183", "formula_text": ")", "formula_coordinates": [44.0, 517.46, 645.4, 4.54, 9.75]}, {"formula_id": "formula_184", "formula_text": "inf \u03b1:H \u2192R risk D (F \u03b1 ) = inf F:X \u00d7Y \u2192R risk D (F). (72", "formula_coordinates": [46.0, 211.38, 199.54, 306.08, 24.06]}, {"formula_id": "formula_185", "formula_text": ")", "formula_coordinates": [46.0, 517.46, 200.35, 4.54, 9.75]}, {"formula_id": "formula_186", "formula_text": "Pr err D H \u221a m \u2264 err D (H opt ) + O m \u2212c \u2265 1 \u2212 1 m 2 ,", "formula_coordinates": [46.0, 193.38, 301.87, 225.23, 25.23]}, {"formula_id": "formula_187", "formula_text": "Pr lim m\u2192\u221e err D (H \u221a m ) = err D (H opt ) = 1,", "formula_coordinates": [46.0, 214.04, 460.94, 183.92, 17.39]}, {"formula_id": "formula_188", "formula_text": "l i = l \u03be i if i \u2208 S \u03be .", "formula_coordinates": [55.0, 272.38, 132.23, 67.25, 22.2]}, {"formula_id": "formula_189", "formula_text": "a i = C(i, l \u2212 i ) \u2212C(i, l + i ), b i = \u03c6 B(i) T \u2212t\u22121 s t (i) + e l \u2212 i \u2212 \u03c6 B(i)", "formula_coordinates": [55.0, 191.65, 177.81, 155.7, 41.11]}, {"formula_id": "formula_190", "formula_text": "C(i, l \u03be i ) = E l\u223cp i [C(i, l)] \u2212 \u03be(1 \u2212 p \u03be i )a i (79", "formula_coordinates": [55.0, 234.49, 249.72, 282.97, 22.2]}, {"formula_id": "formula_191", "formula_text": ")", "formula_coordinates": [55.0, 517.46, 254.08, 4.54, 9.75]}, {"formula_id": "formula_192", "formula_text": "\u03c6 B(i) T \u2212t\u22121 s t (i) + e l \u03be i = E l\u223cp i \u03c6 B(i) T \u2212t (i, l) \u2212 \u03be(1 \u2212 p \u03be i )b i . (80", "formula_coordinates": [55.0, 179.25, 269.54, 338.21, 22.63]}, {"formula_id": "formula_193", "formula_text": ")", "formula_coordinates": [55.0, 517.46, 273.88, 4.54, 9.75]}, {"formula_id": "formula_194", "formula_text": "\u2211 i\u2208S + C(i, l + i ) + \u2211 i\u2208S \u2212 C(i, l \u2212 i ) = \u2211 i\u2208S + E l\u223cp i [C(i, l)] \u2212 a i + p + i a i + \u2211 i\u2208S \u2212 E l\u223cp i [C(i, l)] + p + i a i = m \u2211 i=1 E l\u223cp i [C(i, l)] + m \u2211 i=1 p + i a i \u2212 \u2211 i\u2208S + a i \u2264 m \u2211 i=1 C(i), B(i) + m \u2211 i=1 p + i a i \u2212 \u2211 i\u2208S + a i ,(81)", "formula_coordinates": [55.0, 148.91, 335.34, 373.09, 125.96]}, {"formula_id": "formula_195", "formula_text": "\u2211 i\u2208S + \u03c6 B(i) T \u2212t\u22121 s t (i) + e l + i + \u2211 i\u2208S \u2212 \u03c6 B(i) T \u2212t\u22121 s t (i) + e l \u2212 i = \u2211 i\u2208S + E l\u223cp i \u03c6 B(i) T \u2212t\u22121 (s t (i) + e l ) \u2212 b i + p + i b i + \u2211 i\u2208S \u2212 E l\u223cp i \u03c6 B(i) T \u2212t\u22121 (s t (i) + e l ) + p + i b i = m \u2211 i=1 E l\u223cp i \u03c6 B(i) T \u2212t\u22121 (s t (i) + e l ) + m \u2211 i=1 p + i b i \u2212 \u2211 i\u2208S + b i = m \u2211 i=1 \u03c6 B(i) T \u2212t (s t (i)) + m \u2211 i=1 p + i b i \u2212 \u2211 i\u2208S + b i ,(82)", "formula_coordinates": [55.0, 177.28, 509.6, 344.72, 160.36]}, {"formula_id": "formula_196", "formula_text": "\u2211 i\u2208S + a i \u2265 m \u2211 i=1 p + i a i , \u2211 i\u2208S + b i \u2264 m\u03b5 T + m \u2211 i=1 p + i b i .(83)", "formula_coordinates": [56.0, 173.74, 115.74, 348.27, 30.99]}, {"formula_id": "formula_197", "formula_text": "\u2211 i\u2208S + a i \u2265 m \u2032 \u2211 i=1 p + i a i ,(84)", "formula_coordinates": [56.0, 237.65, 303.33, 284.35, 32.92]}, {"formula_id": "formula_198", "formula_text": "\u2211 i\u2208S + b i \u2264 m \u2032 max i=1 |b i | + m \u2032 \u2211 i=1 p + i b i ,(85)", "formula_coordinates": [56.0, 237.66, 340.21, 284.35, 32.92]}, {"formula_id": "formula_199", "formula_text": "a(1) \u2212 b(1) a(1) \u2265 \u2022 \u2022 \u2022 \u2265 a(m \u2032 ) \u2212 b(m \u2032 ) a(m \u2032 ) . (86", "formula_coordinates": [56.0, 228.86, 519.24, 288.6, 29.31]}, {"formula_id": "formula_200", "formula_text": ")", "formula_coordinates": [56.0, 517.46, 529.19, 4.54, 9.75]}, {"formula_id": "formula_201", "formula_text": "a 1 + a 2 + \u2022 \u2022 \u2022 + a I < m \u2032 \u2211 i=1 p + i a i .(87)", "formula_coordinates": [56.0, 243.01, 582.23, 279.0, 31.87]}, {"formula_id": "formula_202", "formula_text": "b 1 + b 2 + \u2022 \u2022 \u2022 + b I \u2264 m \u2032 \u2211 i=1 p + i b i ,(88)", "formula_coordinates": [56.0, 243.01, 676.96, 279.0, 31.87]}, {"formula_id": "formula_203", "formula_text": "a 1 + . . . + a I = m \u2032 \u2211 i=1p + i a i (89", "formula_coordinates": [57.0, 266.53, 157.37, 250.94, 31.87]}, {"formula_id": "formula_204", "formula_text": ") for i = 1, . . . , m \u2032 :p + i \u2264 p i . (90", "formula_coordinates": [57.0, 231.61, 169.03, 290.4, 43.32]}, {"formula_id": "formula_205", "formula_text": ")", "formula_coordinates": [57.0, 517.46, 194.5, 4.54, 9.75]}, {"formula_id": "formula_206", "formula_text": "(1 \u2212p + 1 )a 1 + \u2022 \u2022 \u2022 + (1 \u2212p + I )a I =p + I+1 a I+1 + \u2022 \u2022 \u2022 +p + m \u2032 a m \u2032 .", "formula_coordinates": [57.0, 181.6, 239.4, 248.79, 20.96]}, {"formula_id": "formula_207", "formula_text": "(1 \u2212p + 1 )a 1 a 1 \u2212 b 1 a 1 + \u2022 \u2022 \u2022 + (1 \u2212p + I )a I a I \u2212 b I a I \u2265p + I+1 a I+1 a I+1 \u2212 b I+1 a I+1 + \u2022 \u2022 \u2022 +p + m \u2032 a m \u2032 a m \u2032 \u2212 b m \u2032 a m \u2032 .(91)", "formula_coordinates": [57.0, 174.37, 301.48, 347.64, 58.4]}, {"formula_id": "formula_208", "formula_text": "b i \u2265 m \u2032 \u2211 i=1p + i a i \u2212 m \u2032 \u2211 i=1p + i b i i.e., I \u2211 i=1 b i \u2264 m \u2032 \u2211 i=1p + i b i ,(92)", "formula_coordinates": [57.0, 245.83, 469.57, 276.18, 67.12]}, {"formula_id": "formula_209", "formula_text": "risk (F \u03b1 ) = risk F \u03b1 (93) risk D (F) = risk D \u00af F .(94)", "formula_coordinates": [58.0, 247.53, 344.64, 274.48, 35.09]}, {"formula_id": "formula_210", "formula_text": "F \u2032 : X \u2192R risk D ( F \u2032 ) + O m \u2212c \u2265 1 \u2212 1 m 2 ,", "formula_coordinates": [59.0, 255.74, 660.4, 174.95, 32.13]}], "doi": ""}