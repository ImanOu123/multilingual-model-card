{"title": "What Energy Functions Can Be Minimized via Graph Cuts?", "authors": "Vladimir Kolmogorov; Ramin Zabih; M A T Figueiredo; E R Hancock; M Pelillo; J Zerubia", "pub_date": "", "abstract": "In the last few years, several new algorithms based on graph cuts have been developed to solve energy minimization problems in computer vision. Each of these techniques constructs a graph such that the minimum cut on the graph also minimizes the energy. Yet, because these graph constructions are complex and highly specific to a particular energy function, graph cuts have seen limited application to date. In this paper, we give a characterization of the energy functions that can be minimized by graph cuts. Our results are restricted to functions of binary variables. However, our work generalizes many previous constructions and is easily applicable to vision problems that involve large numbers of labels, such as stereo, motion, image restoration, and scene reconstruction. We give a precise characterization of what energy functions can be minimized using graph cuts, among the energy functions that can be written as a sum of terms containing three or fewer binary variables. We also provide a general-purpose construction to minimize such an energy function. Finally, we give a necessary condition for any energy function of binary variables to be minimized by graph cuts. Researchers who are considering the use of graph cuts to optimize a particular energy function can use our results to determine if this is possible and then follow our construction to create the appropriate graph. A software implementation is freely available.", "sections": [{"heading": "INTRODUCTION AND OVERVIEW", "text": "M ANY of the problems that arise in early vision can be naturally expressed in terms of energy minimization. The computational task of minimizing the energy is usually quite difficult as it generally requires minimizing a nonconvex function in a space with thousands of dimensions. If the functions have a very restricted form, they can be solved efficiently using dynamic programming [2]. However, researchers typically have needed to rely on general purpose optimization techniques such as simulated annealing [3], [16], which requires exponential time in theory and is extremely slow in practice.\nIn the last few years, however, a new approach has been developed based on graph cuts. The basic technique is to construct a specialized graph for the energy function to be minimized such that the minimum cut on the graph also minimizes the energy (either globally or locally). The minimum cut, in turn, can be computed very efficiently by max flow algorithms. These methods have been successfully used for a wide variety of vision problems, including image restoration [9], [10], [18], [21], stereo and motion [4], [9], [10], [20], [24], [27], [32], [35], [36], image synthesis [29], image segmentation [8], voxel occupancy [39], multicamera scene reconstruction [28], and medical imaging [5], [6], [25], [26]. The output of these algorithms is generally a solution with some interesting theoretical quality guarantee. In some cases [9], [18], [20], [21], [35], it is the global minimum, in other cases, a local minimum in a strong sense [10] that is within a known factor of the global minimum. The experimental results produced by these algorithms are also quite good. For example, two recent evaluations of stereo algorithms using real imagery with dense ground truth [37], [41] found that the best overall performance was due to algorithms based on graph cuts.\nMinimizing an energy function via graph cuts, however, remains a technically difficult problem. Each paper constructs its own graph specifically for its individual energy function and, in some of these cases (especially [10], [27], [28]), the construction is fairly complex. One consequence is that researchers sometimes use heuristic methods for optimization, even in situations where the exact global minimum can be computed via graph cuts. The goal of this paper is to precisely characterize the class of energy functions that can be minimized via graph cuts and to give a general-purpose graph construction that minimizes any energy function in this class. Our results play a key role in [28], provide a significant generalization of the energy minimization methods used in [4], [5], [6], [10], [18], [26], [32], [39], and show how to minimize an interesting new class of energy functions.\nIn this paper, we only consider energy functions involving binary-valued variables. At first glance, this restriction seems severe since most work with graph cuts considers energy functions with variables that have many possible values. For example, the algorithms presented in [10] use graph cuts to address the standard pixel labeling problem that arises in early vision, including stereo, motion, and image restoration. In the pixel-labeling problem, the variables represent individual pixels and the possible values for an individual variable represent, e.g., its possible displacements or intensities. However, as we discuss in Section 2, many of the graph cut methods that handle multiple possible values work by repeatedly minimizing an energy function involving only binary variables. As we will see, our results generalize many graph cut algorithms [4], [5], [6], [10], [18], [26], [39] and can be easily applied to problems like pixel labeling, even though the pixels have many possible labels.", "publication_ref": ["b1", "b2", "b15", "b8", "b9", "b17", "b20", "b3", "b8", "b9", "b19", "b23", "b26", "b31", "b34", "b35", "b28", "b7", "b38", "b27", "b4", "b5", "b24", "b25", "b8", "b17", "b19", "b20", "b34", "b9", "b36", "b40", "b9", "b26", "b27", "b27", "b3", "b4", "b5", "b9", "b17", "b25", "b31", "b38", "b9", "b3", "b4", "b5", "b9", "b17", "b25", "b38"], "figure_ref": [], "table_ref": []}, {"heading": "Summary of Our Results", "text": "In this paper, we focus on two classes of energy functions. Let fx 1 ; . . . ; x n g, x i 2 f0; 1g be a set of binary-valued variables. We define the class F 2 to be functions that can be written as a sum of functions of up to two binary variables at a time,\nE\u00f0x 1 ; . . . ; x n \u00de \u00bc X i E i \u00f0x i \u00de \u00fe X i<j E i;j \u00f0x i ; x j \u00de:\u00f01\u00de\nWe define the class F 3 to be functions that can be written as a sum of functions of up to three binary variables at a time,\nE\u00f0x 1 ; . . . ; x n \u00de \u00bc X i E i \u00f0x i \u00de \u00fe X i<j E i;j \u00f0x i ; x j \u00de \u00fe X\ni<j<k E i;j;k \u00f0x i ; x j ; x k \u00de: \u00f02\u00de\nObviously, the class F 2 is a strict subset of the class F 3 . However, to simplify the discussion, we will begin by focusing on F 2 . Note that there is no restriction on the signs of the energy functions or of the individual terms.\nThe main results in this paper are:\n. A precise characterization of the class of functions in F 3 that can be minimized using graph cuts. . A general-purpose graph construction for minimizing any function in this class. . A necessary condition for any function of binary variables to be minimized via graph cuts. The rest of the paper is organized as follows: In Section 2, we describe how graph cuts can be used to minimize energy functions and discuss the importance of energy functions with binary variables in the context of two example vision problems, namely, stereo and multicamera scene reconstruction. In Section 3, we formalize the relationship between graphs and energy functions and provide a precise definition of the problem that we wish to solve. Section 4 contains our main theorem for the class of functions F 2 and shows how this result can be used for both stereo and multicamera scene reconstruction. Section 5 gives our results for the broader class F 3 and shows how this result can be used for multicamera scene reconstruction. A necessary condition for an arbitrary function of binary variables to be minimized via graph cuts is presented in Section 6. We discuss some related work in the theory of submodular functions in Section 7 and give a summary of our graph constructions in Section 8. Software can be downloaded from http://www.cs.cornell.edu/~rdz/ graphcuts.html that automatically constructs the appropriate graph and minimizes the energy. An NP-hardness result and a proof of one of our theorems are deferred to the Appendix.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "MINIMIZING ENERGY FUNCTIONS VIA GRAPH CUTS", "text": "Many vision problems, especially in early vision, can naturally be formulated in terms of energy minimization. Energy minimization has a long history in computer vision (see [34] for several examples). The classical use of energy minimization is to solve the pixel-labeling problem, which is a generalization of such problems as stereo, motion, and image restoration. The input is a set of pixels P and a set of labels L. The goal is to find a labeling f (i.e., a mapping from P to L) which minimizes some energy function.\nA standard form of the energy function is\nE\u00f0f\u00de \u00bc X p2P D p \u00f0f p \u00de \u00fe X p;q2N V p;q \u00f0f p ; f q \u00de;\u00f03\u00de\nwhere N & P \u00c2 P is a neighborhood system on pixels. 1 D p \u00f0f p \u00de is a function derived from the observed data that measures the cost of assigning the label f p to the pixel p. V p;q \u00f0f p ; f q \u00de measures the cost of assigning the labels f p ; f q to the adjacent pixels p; q and is used to impose spatial smoothness. At the borders of objects, adjacent pixels should often have very different labels and it is important that E not overpenalize such labelings. This requires that V be a nonconvex function of jf p \u00c0 f q j. Such an energy function is called discontinuity-preserving. Energy functions of the form (3) can be justified on Bayesian grounds using the wellknown Markov Random Fields (MRF) formulation [16], [31]. Energy functions like E are extremely difficult to minimize, however, as they are nonconvex functions in a space with many thousands of dimensions. They have traditionally been minimized with general-purpose optimization techniques (such as simulated annealing) that can minimize an arbitrary energy function. As a consequence of their generality, however, such techniques require exponential time and are extremely slow in practice. In the last few years, however, efficient algorithms have been developed for these problems based on graph cuts. 2 ", "publication_ref": ["b33", "b15", "b30", "b1"], "figure_ref": [], "table_ref": []}, {"heading": "Graph Cuts", "text": "Suppose G \u00bc \u00f0V; E\u00de is a directed graph with nonnegative edge weights that has two special vertices (terminals), namely, the source s and the sink t. An s-t-cut (which we will refer to informally as a cut) C \u00bc S; T is a partition of the vertices in V into two disjoint sets S and T such that s 2 S and t 2 T . The cost of the cut is the sum of costs of all edges that go from S to T : c\u00f0S; T \u00de \u00bc X u2S;v2T ;\u00f0u;v\u00de2E c\u00f0u; v\u00de:\nThe minimum s-t-cut problem is to find a cut C with the smallest cost. Due to the theorem of Ford and Fulkerson [14], this is equivalent to computing the maximum flow from the source to sink. There are many algorithms that solve this problem in polynomial time with small constants [1], [7], [17].\nIt is convenient to note a cut C \u00bc S; T by a labeling f mapping from the set of the vertices V \u00c0 fs; tg to f0; 1g, where f\u00f0v\u00de \u00bc 0 means that v 2 S and f\u00f0v\u00de \u00bc 1 means that v 2 T . We will use this notation later.\nNote that a cut is a binary partition of a graph viewed as a labeling; it is a binary-valued labeling. While there are generalizations of the minimum s-t-cut problem that involve more than two terminals (such as the multiway cut problem [12]), such generalizations are NP-hard.\n1. Without loss of generality, we can assume that N contains only ordered pairs p; q for which p < q since we can combine two terms V p;q and V q;p into one term.\n2. It is interesting to note that some similar techniques have been developed by algorithms researchers working on the task assignment problem [30], [33], [40].", "publication_ref": ["b13", "b0", "b6", "b16", "b11", "b29", "b32", "b39"], "figure_ref": [], "table_ref": []}, {"heading": "Energy Minimization Using Graph Cuts", "text": "In order to minimize E using graph cuts, a specialized graph is created such that the minimum cut on the graph also minimizes E (either globally or locally). The form of the graph depends on the exact form of V and on the number of labels.\nIn certain restricted situations, it is possible to efficiently compute the global minimum. If there are only two labels, [18] showed how to compute the global minimum of E. This is also possible for an arbitrary number of labels as long as the labels are consecutive integers and V is the L 1 distance. The construction is due to [20] and is a modified version of [36]. This construction has been further generalized to handle an arbitrary convex V [22].\nHowever, a convex V is not discontinuity preserving and optimizing an energy function with such a V leads to oversmoothing at the borders of objects. The ability to find the global minimum efficiently, while theoretically of great value, does not overcome this drawback. This is clearly visible in the relatively poor performance of such algorithms on the stereo benchmarks described in [37].\nMoreover, efficient global energy minimization algorithms for even the simplest class of discontinuity-preserving energy functions almost certainly do not exist. Consider V \u00f0f p ; f q \u00de \u00bc T \u00bdf p 6 \u00bc f q , where the indicator function T \u00bd\u00c1 is 1 if its argument is true and otherwise 0. This smoothness term, sometimes called the Potts model, is clearly discontinuitypreserving. Yet, it is known to be NP-hard to minimize [10].\nHowever, graph cut algorithms have been developed that compute a local minimum in a strong sense [10]. As we shall see, these methods minimize an energy function with nonbinary variables by repeatedly minimizing an energy function with binary variables. 3 ", "publication_ref": ["b17", "b19", "b35", "b21", "b36", "b9", "b9", "b2"], "figure_ref": [], "table_ref": []}, {"heading": "The Expansion Move Algorithm", "text": "One of the most effective algorithms for minimizing discontinuity-preserving energy functions is the expansion move algorithm, which was introduced in [10]. This algorithm can be used whenever V is a metric on the space of labels; this includes several important discontinuitypreserving energy functions (see [10] for more details).\nConsider a labeling f and a particular label . Another labeling f 0 is defined to be an -expansion move from f if f 0 p 6 \u00bc implies f 0 p \u00bc f p . This means that the set of pixels assigned the label has increased when going from f to f 0 . An example of an expansion move is shown in Fig. 1.\nThe expansion move algorithm cycles through the labels in some order (fixed or random) and finds the lowest energy -expansion move from the current labeling. If this expansion move has lower energy than the current labeling, then it becomes the current labeling. The algorithm terminates with a labeling that is a local minimum of the energy with respect to expansion moves; more precisely, there is no -expansion move, for any label , with lower energy. It is also possible to prove that such a local minimum lies within a multiplicative factor of the global minimum [10] (the factor is at least 2 and depends only on V ).", "publication_ref": ["b9", "b9", "b9"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Applications of the Expansion Move Algorithm", "text": "Energy functions like that of (3) arise commonly in early vision, so it is straightforward to apply the expansion move algorithm to many vision problems. For example, the expansion move algorithm can be used for the standard 2-camera stereo problem, as well as for multicamera scene reconstruction.\nStereo. For the stereo problem, the labels are disparities and the data term D p \u00f0f p \u00de is some function of the intensity difference between the pixel p in the primary image and the pixel p \u00fe f p in the secondary image. On the stereo problem, the expansion move algorithm and other closely related energy minimization algorithms give very strong empirical performance. They have been used as a critical component of several algorithms [4], [27], [28], [32], including the top two algorithms (and five of the top six) according to a recent published survey [37] that used real data with dense ground truth.\nMulticamera scene reconstruction. It is also possible to use the expansion move algorithm for multicamera scene reconstruction, as reported in [28]. In their problem formulation, the energy function consists entirely of terms with two arguments (in other words, D p does not exist). The set of pixels P includes all pixels from all cameras and the labels correspond to planes. Thus, a pair hp; f p i specifies a 3D point and a labeling f gives the nearest scene element visible in each pixel in each camera.\nThe expansion move algorithm can be straightforwardly applied to this problem as long as the energy is of the right form. Note that an -expansion move increases the set of pixels labeled in all cameras at once, rather than in a single preferred image.\nThe actual energy function consists of three terms. All the terms are in the same form as V in that they depend on pairs of labels f p ; f q . One term enforces the visibility constraint. While this constraint is very important, it has no analogue in the simple pixel labeling problem formulation and we will not discuss it here. The other terms are analogous to the standard stereo data term and smoothness term.\nIn the multicamera scene reconstruction problem, the data term enforces photoconsistency. Let I be a set of pairs of \"nearby\" 3D points. These points will come from different cameras, but they will share the same depth (i.e., the points are of the form hp; f p i; hq; f q i where f p \u00bc f q and p; q are pixels from different cameras). Then, the data term is X fh\u00f0p;l\u00dei;h\u00f0q;l\u00dei2Ig\nD p;q;l \u00f0f p ; f q \u00de;\u00f04\u00de\nwhere\nD p;q;l \u00f0f p ; f q \u00de \u00bc D\u00f0p; q\u00de \u00c1 T \u00bdf p \u00bc f q \u00bc l:\nWe have rewritten each term in the sum as a function of f p ; f q (since p; q do not depend on f). The function D will be 3. This is somewhat analogous to the ZM algorithm [13], although that method produces a global minimum of a function with nonbinary variables by repeatedly minimizing a function with binary variables. some function of the intensity difference between p and q, typically, a monotonically increasing function.\nThe smoothness term, on the other hand, involves a single camera at a time. It is defined to be X\nfp;qg2N V p;q \u00f0f p ; f q \u00de;\u00f05\u00de\nwhere N is a neighborhood system on pixels in a single camera.", "publication_ref": ["b3", "b26", "b27", "b31", "b36", "b27", "b12"], "figure_ref": [], "table_ref": []}, {"heading": "Energy Functions of Binary Variables", "text": "The key subproblem in the expansion move algorithm is to compute the lowest energy labeling within a single -expansion of f. This subproblem is solved efficiently with a single graph cut [10], using a somewhat intricate graph construction.\nIt is important to note that this subproblem is an energy minimization problem over binary variables, even though the overall problem that the expansion move algorithm is solving involves nonbinary variables. This is because each pixel will either keep its old value under f or acquire the new label .\nFormally, any labeling f 0 within a single -expansion of the initial labeling f can be encoded by a binary vector x \u00bc fx p jp 2 Pg, where f 0 \u00f0p\u00de \u00bc f\u00f0p\u00de if x p \u00bc 0 and f 0 \u00f0p\u00de \u00bc if x p \u00bc 1. Let us denote the labeling defined by a binary vector x as f x . Since the energy function E is defined over all labelings, it is obviously also defined over labelings specified by binary vectors. The key step in the expansion move algorithm is therefore to find the minimum of E\u00f0f x \u00de over all binary vectors x.\nThe importance of energy functions of binary variables does not arise simply from the expansion move algorithm. Instead, it results from the fact that a graph cut effectively assigns one of two possible values to each vertex of the graph. So, in a certain sense, any energy minimization construction based on graph cuts relies on intermediate binary variables.\nIt is, of course, possible to use graph cuts in such a manner that variables in the original problem do not correspond in a one-to-one manner with vertices in the graph. This kind of complex transformation lies at the heart of the graph cut algorithms that compute a global minimum [20], [22]. However, the NP-hardness result given in [10] shows that (unless P = NP) such result cannot be achieved for even the simplest discontinuity-preserving energy function.", "publication_ref": ["b9", "b19", "b21", "b9"], "figure_ref": [], "table_ref": []}, {"heading": "REPRESENTING ENERGY FUNCTIONS WITH GRAPHS", "text": "Let us consider a graph G \u00bc \u00f0V; E\u00de with terminals s and t, thus V \u00bc fv 1 ; . . . ; v n ; s; tg. Each cut on G has some cost; therefore, G represents the energy function mapping from all cuts on G to the set of nonnegative real numbers. Any cut can be described by n binary variables x 1 ; . . . ; x n corresponding to vertices in G (excluding the source and the sink): x i \u00bc 0 when v i 2 S and x i \u00bc 1 when v i 2 T . Therefore, the energy E that G represents can be viewed as a function of n binary variables: E\u00f0x 1 ; . . . ; x n \u00de is equal to the cost of the cut defined by the configuration x 1 ; . . . ; x n (x i 2 f0; 1g). Note that the configuration that minimizes E will not change if we add a constant to E. We can efficiently minimize E by computing the minimum s-t-cut on G. This naturally leads to the question: What is the class of energy functions E for which we can construct a graph that represents E? We can also generalize our construction. Above, we used each vertex (except the source and the sink) for encoding one binary variable. Instead, we can specify a subset V 0 \u00bc fv 1 ; . . . ; v k g & V \u00c0 fs; tg and introduce variables only for the vertices in this set. Then, there may be several cuts corresponding to a configuration x 1 ; . . . ; x k . If we define the energy E\u00f0x 1 ; . . . ; x k \u00de as the minimum among the costs of all such cuts, then the minimum s-t-cut on G will again yield the configuration which minimizes E.\nWe will summarize the graph constructions that we allow in the following definition. Definition 3.1. A function E of n binary variables is called graphrepresentable if there exists a graph G \u00bc \u00f0V; E\u00de with terminals s and t and a subset of vertices V 0 \u00bc fv 1 ; . . . ; v n g & V \u00c0 fs; tg such that, for any configuration x 1 ; . . . ; x n , the value of the energy E\u00f0x 1 ; . . . ; x n \u00de is equal to a constant plus the cost of the minimum s-t-cut among all cuts C \u00bc S; T in which v i 2 S, if\nx i \u00bc 0, and v i 2 T , if x i \u00bc 1 (1 i n). We say that E is exactly represented by G, V 0 if this constant is zero.\nThe following lemma is an obvious consequence of this definition.\nLemma 3.2. Suppose the energy function E is graph-representable by a graph G and a subset V 0 . Then, it is possible to find the exact minimum of E in polynomial time by computing the minimum s-t-cut on G.\nIn this paper, we will give a complete characterization of the classes F 2 and F 3 in terms of graph representability and show how to construct graphs for minimizing graphrepresentable energies within these classes. Moreover, we will give a necessary condition for all other classes that must be met for a function to be graph-representable. Obviously, it would be sufficient to consider only the class F 3 since F 2 & F 3 . However, the condition for F 2 is simpler, so we will consider it separately.\nNote that the energy functions we consider can be negative, as can the individual terms in the energy functions. However, the graphs that we construct must have nonnegative edge weights. All previous work that used graph cuts for energy minimization dealt with nonnegative energy functions and terms.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "THE CLASS F 2", "text": "Our main result for the class F 2 is the following theorem. \n. ; x n \u00de \u00bc X i E i \u00f0x i \u00de \u00fe X i<j E i;j \u00f0x i ; x j \u00de:\u00f06\u00de\nThen, E is graph-representable if and only if each term E i;j satisfies the inequality E i;j \u00f00; 0\u00de \u00fe E i;j \u00f01; 1\u00de E i;j \u00f00; 1\u00de \u00fe E i;j \u00f01; 0\u00de: \u00f07\u00de\nWe will call functions satisfying the condition of ( 7) regular. 4 This theorem thus states that regularity is a necessary and sufficient condition for graph-representability, at least in F 2 .\nIn this section, we will give a constructive proof that regularity is a sufficient condition by describing how to build a graph that represents an arbitrary regular function in F 2 . The other half of the theorem is proven in much more generality in Section 6, where we show that a regularity is a necessary condition for any function to be graph-representable.\nRegularity is thus an extremely important property as it allows energy functions to be minimized using graph cuts. Moreover, without the regularity constraint, the problem becomes intractable. Our next theorem shows that minimizing an arbitrary nonregular function is NP-hard, even if we restrict our attention to F 2 .", "publication_ref": ["b3"], "figure_ref": [], "table_ref": []}, {"heading": "Theorem 4.2 (NP-Hardness)", "text": ". Let E 2 be a nonregular function of two variables. Then, minimizing functions of the form\nE\u00f0x 1 ; . . . ; x n \u00de \u00bc X i E i \u00f0x i \u00de \u00fe X \u00f0i;j\u00de2N E 2 \u00f0x i ; x j \u00de;\nwhere E i are arbitrary functions of one variable and N & f\u00f0i; j\u00dej1 i < j ng, is NP-hard.\nThe proof of this theorem is deferred to the Appendix. Note that this theorem implies the intractability of minimizing the entire class of nonregular functions in F 2 . It thus allows for the existence of nonregular functions in F 2 that can be minimized efficiently. 5 ", "publication_ref": ["b4"], "figure_ref": [], "table_ref": []}, {"heading": "Graph Construction for F 2", "text": "In this section, we will prove the constructive part of the F 2 theorem. Let E be a regular function of the form given in the theorem. We will construct a graph for each term separately and then \"merge\" all graphs together. This is justified by the additivity theorem, which is given in the Appendix.\nThe graph will contain n \u00fe 2 vertices: V \u00bc fs; t; v 1 ; . . . ; v n g. Each nonterminal vertex v i will encode the binary variable x i . For each term of E, we will add one or more edges that we describe next.\nFirst, consider a term E i depending on one variable x i . If E i \u00f00\u00de < E i \u00f01\u00de, then we add the edge \u00f0s; v i \u00de with the weight E i \u00f01\u00de \u00c0 E i \u00f00\u00de (Fig. 2a). Otherwise, we add the edge \u00f0v i ; t\u00de with the weight E i \u00f00\u00de \u00c0 E i \u00f01\u00de (Fig. 2b). It easy to see that, in both cases, the constructed graph represents the function E i (but with different constants: E i \u00f00\u00de in the former case and E i \u00f01\u00de in the latter). Now, consider a term E i;j depending on two variables x i , x j . It is convenient to represent it in Table 1. We can rewrite it as it is expressed in Table 2. The first term is a constant function, so we don't need to add any edges for it. The second and the third terms depend only on one variable x i and x j , respectively. Therefore, we can use the construction given above. To represent the last term, we add an edge \u00f0v i ; v j \u00de with the weight B \u00fe C \u00c0 A \u00c0 D (Fig. 2c). Note that this weight is nonnegative due to the regularity of E.\nA complete graph for E i;j will contain three edges. One possible case (C \u00c0 A > 0 and D \u00c0 C < 0) is illustrated in Fig. 2d.\nNote that we did not introduce any additional vertices for representing binary interactions of binary variables. This is in contrast to the construction in [10] which added auxiliary vertices for representing energies that we just considered. Our construction yields a smaller graph and, thus, the minimum cut can potentially be computed faster.", "publication_ref": ["b9"], "figure_ref": ["fig_2", "fig_2", "fig_2", "fig_2"], "table_ref": []}, {"heading": "Example: Applying Our Results for Stereo and Multicamera Scene Reconstruction", "text": "Our results give a generalization of a number of previous algorithms [4], [5], [6], [10], [18], [26], [32], [39] in the following sense. Each of these methods used a graph cut algorithm that was specifically constructed to minimize a certain form of energy function. The class of energy functions that we show how to minimize is much larger and includes the techniques used in all of these methods as special cases.\nTo illustrate the power of our results, we return to the use of the expansion move algorithm for stereo and multicamera scene reconstruction described in Section 2.3.1. Recall that the key subproblem is to find the minimum energy labeling within a single -expansion of f, which is equivalent to minimizing the energy over binary variables x i .  ", "publication_ref": ["b3", "b4", "b5", "b9", "b17", "b25", "b31", "b38"], "figure_ref": [], "table_ref": []}, {"heading": "Stereo", "text": "The paper that proposed the expansion move algorithm [10] showed how to solve the key subproblem with graph cuts as long as D p is nonnegative and V is a metric on the space of labels. This involved an elaborate graph construction and several associated theorems.\nUsing our results, we can recreate the proof that such an energy function can be solved in just a few lines. All that we need is to prove that E is regular if D p is nonnegative and V is a metric. Obviously, the form of D p doesn't matter; we simply have to show that if V is a metric the individual terms satisfy the inequality in (7). Table 3 considers two neighboring pixels p; q, with associated binary variables i; j. If V is a metric, by definition, for any labels ; ;\nV \u00f0; \u00de \u00bc 0 and V \u00f0; \u00de \u00fe V \u00f0; \u00de ! V \u00f0; \u00de.\nThis gives the inequality of ( 7) and shows that E can be minimized using graph cuts.", "publication_ref": ["b9", "b6"], "figure_ref": [], "table_ref": []}, {"heading": "Multicamera Scene Reconstruction", "text": "We can also show that the expansion move algorithm can be used for a different energy function, namely, the one proposed for multicamera scene reconstruction in [28]. We need to show that the smoothness (5) and the data (4) energy functions are regular. The argument for the smoothness term is identical to the one we just gave for stereo because the smoothness term is regular.\nThe data term for multicamera scene reconstruction is perhaps the best demonstration of the utility of our results. The function in the data term is clearly not a metric on the space of labels (for example, it is entirely possible that D p;q;l \u00f0; \u00de 6 \u00bc 0 for some label ). Prior to our results, the only way to use the expansion move algorithm for this energy function would be to create an elaborate graph construction that is specific to this particular energy function. Worse, it was not a priori obvious that such a construction existed.\nUsing our results, it is simple to show that the data term can be made regular and the expansion move algorithm can be applied. Let us write out the sum in (4) and consider a single term D\u00f0p; q\u00de \u00c1 T \u00bdf p \u00bc f q \u00bc l, which imposes a penalty if p and q both have the label l. Recall that we are seeking the lowest energy labeling within a single -expansion of f. We will have two binary variables which are 0 if the associated pixel keeps its original label in f and 1 if it acquires the new label .\nThere are two cases that must be analyzed separately: l 6 \u00bc and l \u00bc . Consider the case l 6 \u00bc . If f p 6 \u00bc l or f q 6 \u00bc l, then the term is zero for any values of the binary variables. If f p \u00bc f q \u00bc l, then the penalty is only imposed when the binary variables are both 0. We can graphically show this in Table 4.\nIf l \u00bc , then, if either f p or f q are , the penalty imposed is independent of one of the binary variables and it is easy to see that this is regular. If l \u00bc and neither f p nor f q are , then the penalty is only imposed when the binary variables are both 1. Graphically, this can be shown in Table 5. Overall, the energy function is regular if D\u00f0p; q\u00de is nonpositive. Recall that D\u00f0p; q\u00de is a photoconsistency term. It is typically a monotonically increasing function of the intensity difference between p and q. By simply subtracting a large constant, we can ensure that D is nonpositive and, thus, apply our construction.", "publication_ref": ["b27"], "figure_ref": [], "table_ref": []}, {"heading": "THE CLASS F 3", "text": "Before stating our theorem for the class F 3 , we will extend the definition of regularity to arbitrary functions of binary variables. This requires a notion of projections.\nSuppose we have a function E of n binary variables. If we fix m of these variables, then we get a new function E 0 of n \u00c0 m binary variables; we will call this function a projection of E. The notation for projections is as follows: where x i \u00bc i for i 2 I. We say that we fix the variables x i\u00f01\u00de , . . . , x i\u00f0m\u00de . Now, we can give a generalized definition of regularity.\nDefinition 5.2.\n. All functions of one variable are regular.\n. A function E of two variables is called regular if E\u00f00; 0\u00de \u00fe E\u00f01; 1\u00de E\u00f00; 1\u00de \u00fe E\u00f01; 0\u00de. . A function E of more than two variables is called regular if all projections of E of two variables are regular.\nFor the class F 2 , this definition is equivalent to the previous one. A proof of this fact is given in Section 5.3. Now, we are ready to formulate our main theorem for F 3 .\nTheorem 5.3 (F 3 Theorem). Let E be a function of n binary variables from F 3 , i.e.,\nE\u00f0x 1 ; . . . ; x n \u00de \u00bc X i E i \u00f0x i \u00de \u00fe X i<j E i;j \u00f0x i ; x j \u00de \u00fe X i<j<k E i;j;k \u00f0x i ; x j ; x k \u00de:\u00f08\u00de\nThen, E is graph-representable if and only if E is regular. ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Graph Construction for F 3", "text": "Consider a regular function E of the form given in (8). The regularity of E does not necessarily imply that each term in ( 8) is regular. However, we will give an algorithm for converting any regular function in F 3 to the form ( 8) where each term is regular (see the regrouping theorem in the next section). Note that this was not necessary for the class F 2 since, for any representation of a regular function in the form ( 6), each term in the sum is regular.\nHere, we will give graph construction for a regular function E of the form as in the F 3 theorem assuming that each term of E is regular. The graph will contain n \u00fe 2 vertices: V \u00bc fs; t; v 1 ; . . . ; v n g as well as some additional vertices described below. Each nonterminal vertex v i will encode the binary variable x i . For each term of E, we will add one or more edges and, possibly, an additional (unique) vertex that we describe next. Again, our construction is justified by the additivity theorem given in the Appendix.\nTerms depending on one and two variables were considered in the previous section, so we will concentrate on a term E i;j;k depending on three variables x i , x j , x k . It is convenient to represent it in Table 6.\nLet us denote\nP \u00bc \u00f0A \u00fe D \u00fe F \u00fe G\u00de \u00c0 \u00f0B \u00fe C \u00fe E \u00fe\nH\u00de. We consider two cases: Case 1. P >\u00bc 0. E i;j;k can be rewritten as shown in Table 7, where\nP 1 \u00bc F \u00c0 B, P 2 \u00bc G \u00c0 E, P 3 \u00bc D \u00c0 C, P 23 \u00bc B \u00fe C \u00c0 A \u00c0D, P 31 \u00bc B \u00fe E \u00c0 A \u00c0 F , P 12 \u00bc C \u00fe E \u00c0 A \u00c0 G. E i;j;k\nis regular, therefore, by considering projections E i;j;k \u00bdx 1 \u00bc 0, E i;j;k \u00bdx 2 \u00bc 0, E i;j;k \u00bdx 3 \u00bc 0, we conclude that P 23 , P 31 , P 12 are nonnegative.\nThe first term is a constant function, so we don't need to add any edges for it. The next three terms depend only on one variable (x i , x j , x k , respectively), so we can use the construction given in the previous section. The next three terms depend on two variables; the nonnegativity of P 23 , P 31 , P 12 implies that they are all regular. Therefore, we can again use the construction of the previous section. (Three edges will be added: \u00f0v j ; v k \u00de, \u00f0v k ; v i \u00de, \u00f0v i ; v j \u00de with weights P 23 , P 31 , P 12 , respectively).\nTo represent the last term, we will add an auxiliary vertex u ijk and four edges \u00f0v i ; u ijk \u00de, \u00f0v j ; u ijk \u00de, \u00f0v k ; u ijk \u00de, \u00f0u ijk ; t\u00de with the weight P . This is shown in Fig. 3a. Let us prove these four edges exactly represent the function shown in Table 8. If\nx i \u00bc x j \u00bc x k \u00bc 1,\nthen the cost of the minimum cut is 0 (the minimum cut is S \u00bc fsg, T \u00bc fv i ; v j ; v k ; u ijk ; tg. Suppose at least one of the variables x i , x j , x k is 0; without loss of generality, we can assume that x i \u00bc 0, i.e., v i 2 S. If u ijk 2 S, then the edge \u00f0u ijk ; t\u00de is cut; if u ijk 2 T , the edge \u00f0v i ; u ijk \u00de is cut yielding the cost P . Hence, the cost of the minimum cut is at least P . However, if u ijk 2 S, the cost of the cut is exactly P , no matter where the vertices v i , v j , v k are. Therefore, the cost of the minimum cut will be 0 if x i \u00bc x j \u00bc x k \u00bc 1 and P otherwise, as desired.\nCase 2. P < 0. This case is similar to the Case 1. E i;j;k can be rewritten as shown in Table 9, where\nP 1 \u00bc C \u00c0 G, P 2 \u00bc B \u00c0 D, P 3 \u00bc E \u00c0 F , P 32 \u00bc F \u00fe G \u00c0 E \u00c0 H, P 13 \u00bc D \u00fe G \u00c0 C \u00c0 H, P 21 \u00bc D \u00fe F \u00c0 B \u00c0 H. By considering projec- tions E i;j;k \u00bdx 1 \u00bc 1, E i;j;k \u00bdx 2 \u00bc 1, E i;j;k \u00bdx 3 \u00bc 1, we conclude that P 32 , P 13 , P 21 are nonnegative.\nAs in the previous case, all terms except the last are regular and depend on at most two variables, so we can use the construction of the previous section. We will have, for example, edges \u00f0v k ; v j \u00de, \u00f0v i ; v k \u00de, \u00f0v j ; v i \u00de with weights P 32 , P 13 , P 21 , respectively.\nTo represent the last term, we will add an auxiliary vertex u ijk and four edges \u00f0u ijk ; v i \u00de, \u00f0u ijk ; v j \u00de, \u00f0u ijk ; v k \u00de, \u00f0s; u ijk \u00de with the weight \u00c0P . This is shown in Fig. 3b.   Note that, in both cases, we added an auxiliary vertex u ijk . It is easy to see that this is necessary since graphs without auxiliary vertices can only represent functions in F 2 . Each edge represents a function of at most two variables, so the whole graph represents a function that is a sum of terms of at most two variables.", "publication_ref": ["b7"], "figure_ref": ["fig_4", "fig_4"], "table_ref": ["tab_2"]}, {"heading": "Constructive Proof of the Regrouping Theorem", "text": "Now, we will show how to convert a regular function in F 3 to the form given in ( 8) where each term is regular.\nTheorem 5.4 (regrouping). Any regular function E from the class F 3 can be rewritten as a sum of terms such that each term is regular and depends on at most three variables.\nWe will assume E given as\nE\u00f0x 1 ; . . . ; x n \u00de \u00bc X i<j<k E i;j;k \u00f0x i ; x j ; x k \u00de;\nwhere i, j, k are indices from the set f1; . . . ; ng (we omitted terms involving functions of one and two variables since they can be viewed as functions of three variables).\nWe begin by giving a definition.\nDefinition 5.5. The functional will be a mapping from the set of all functions (of binary variables) to the set of real numbers which is defined as follows. For a function E\u00f0x 1 ; . . . ; x n \u00de \u00f0E\u00de \u00bc X\nx12f0;1g;...;xn2f0;1g\n\u00c5 n i\u00bc1\u00f0\u00c01\u00de\nx i \u00c0 \u00c1 E\u00f0x 1 ; . . . ; x n \u00de:\nFor example, for a function E of two variables \u00f0E\u00de \u00bc E\u00f00; 0\u00de \u00c0 E\u00f00; 1\u00de \u00c0 E\u00f01; 0\u00de \u00fe E\u00f01; 1\u00de. Note that a function E of two variables is regular if and only if \u00f0E\u00de 0.\nIt is trivial to check the following lemma.\nLemma 5.6. The functional has the following properties.\n. is linear, i.e., for a scalar c and two functions E 0 , E 00 of n variables \u00f0E\n0 \u00fe E 00 \u00de \u00bc \u00f0E 0 \u00de \u00fe \u00f0E 00 \u00de and \u00f0c \u00c1 E 0 \u00de \u00bc c \u00c1 \u00f0E 0 \u00de. . If E\nis a function of n variables that does not depend on at least one of the variables, then \u00f0E\u00de \u00bc 0.\nWe will prove the theorem using the following lemma and a trivial induction argument. Definition 5.7. Let E i;j;k be a function of three variables. The functional N\u00f0E i;j;k \u00de is defined as the number of projections of two variables of E i;j;k with positive values of the functional .\nNote that N\u00f0E i;j;k \u00de \u00bc 0 exactly when E i;j;k is regular.\nLemma 5.8. Suppose the function E of n variables can be written as\nE\u00f0x 1 ; . . . ; x n \u00de \u00bc X i<j<k E i;j;k \u00f0x i ; x j ; x k \u00de;\nwhere some of the terms are not regular. Then, it can be written as\nE\u00f0x 1 ; . . . ; x n \u00de \u00bc X i<j<k\u1ebc E i;j;k \u00f0x i ; x j ; x k \u00de;\nwhere\nX i<j<k N\u1ebc E i;j;k \u00c0 \u00c1 < X i<j<k N E i;j;k \u00c0 \u00c1 :\nProof. For simplicity of notation, let us assume that the term E 1;2;3 is not regular and \u00f0E 1;2;3 \u00bdx 3 \u00bc 0\u00de > 0 or \u00f0E 1;2;3 \u00bdx 3 \u00bc 1\u00de > 0 (we can ensure this by renaming indices). Let\nC k \u00bc max k 2f0;1g \u00f0E 1;2;k \u00bdx k \u00bc k \u00de k 2 f4; . . . ; ng C 3 \u00bc \u00c0 X n k\u00bc4 C k :\nNow, we will modify the terms E 1;2;3 , . . . , E 1;2;n as follows:\nE E 1;2;k E 1;2;k \u00c0 R\u00bdC k k 2 f3; . . . ; ng;\nwhere R\u00bdC is the function of two variables x 1 and x 2 defined by Table 10 (other terms are unchanged: E E i;j;k E i;j;k , \u00f0i; j\u00de 6 \u00bc \u00f01; 2\u00de). We have\nE\u00f0x 1 ; . . . ; x n \u00de \u00bc X i<j<k\u1ebc E i;j;k \u00f0x i ; x j ; x k \u00de since P n k\u00bc3 C k \u00bc 0 and P n k\u00bc3 R\u00bdC k 0.\nIf we consider R\u00bdC as a function of n variables and take a projection of two variables where the two variables that are not fixed are x i and x j (i < j), then the functional will be C, if \u00f0i; j\u00de \u00bc \u00f01; 2\u00de, and 0 otherwise (since, in the latter case, a projection actually depends on, at most, one variable). Hence, the only projections of two variables that could have changed their value of the functional ar\u1ebd E E 1;2;k \u00bdx 3 \u00bc 3 ; . . . ; x n \u00bc n , k 2 f3; . . . ; ng, if we treat\u1ebc E 1;2;k as functions of n variables, or\u1ebc E 1;2;k \u00bdx k \u00bc k , if we treat E E 1;2;k as functions of three variables. First, let us consider terms with k 2 f4; . . . ; ng. We have\n\u00f0E 1;2;k \u00bdx k \u00bc k \u00de C k , thus \u00f0\u1ebc E 1;2;k \u00bdx k \u00bc k \u00de \u00bc\u00f0E 1;2;k \u00bdx k \u00bc k \u00de \u00c0 \u00f0R\u00bdC k \u00bdx k \u00bc k \u00de C k \u00c0 C k \u00bc 0:\nTherefore, we did not introduce any nonregular projections for these terms. Now, let us consider the term \u00f0\u1ebc E 1;2;3 \u00bdx 3 \u00bc 3 \u00de. We can write\n\u00f0\u1ebc E 1;2;3 \u00bdx 3 \u00bc 3 \u00de \u00bc \u00f0E 1;2;3 \u00bdx 3 \u00bc 3 \u00de \u00c0 \u00f0R\u00bdC 3 \u00bdx 3 \u00bc 3 \u00de \u00bc \u00f0E 1;2;3 \u00bdx 3 \u00bc 3 \u00de \u00c0 \u00f0\u00c0 X n k\u00bc4 C k \u00de \u00bc X n k\u00bc3 \u00f0E 1;2;k \u00bdx k \u00bc k \u00de;\nwhere k \u00bc arg max 2f0;1g \u00f0E 1;2;k \u00bdx k \u00bc \u00de, k 2 f4; . . . ; ng. The last expression is just \u00f0E\u00bdx 3 \u00bc 3 ; . . . ; x n \u00bc n \u00de and is nonpositive since E is regular by assumption. Hence, values \u00f0\u1ebc E 1;2;3 \u00bdx 3 \u00bc 0\u00de and \u00f0\u1ebc E 1;2;3 \u00bdx 3 \u00bc 1\u00de are both nonpositive and, therefore, the number of nonregular projections has decreased.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "t u", "text": "The complexity of a single step is O\u00f0n\u00de since it involves modifying at most n terms. Therefore, the complexity of the whole algorithm is O\u00f0mn\u00de, where m is the number of terms in (8) since, in the beginning, P i<j<k N\u00f0E i;j;k \u00de is at most 6m and each step decreases it by at least one.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "The Two Definitions of Regularity Are Equivalent", "text": "We now prove that the definition of regularity 5.2 is equivalent to the previous definition of regularity for the class F 2 . Note that the latter one is formulated not only as a property of the function E but also as a property of its representation as a sum in (6). We will show equivalence for an arbitrary representation, which will imply that the definition of regularity for the class F 2 depends only on E but not on the representation. Let us consider a graph-representable function E from the class F 2 :\nE\u00f0x 1 ; . . . ; x n \u00de \u00bc X i E i \u00f0x i \u00de \u00fe X i<j E i;j \u00f0x i ; x j \u00de:\nConsider a projection where the two variables that are not fixed are x i and x j . By Lemma 5.6, the value of the functional of this projection is equal to \u00f0E i;j \u00de (all other terms yield zero). Therefore, this projection is regular if and only if E i;j \u00f00; 0\u00de \u00fe E i;j \u00f01; 1\u00de E i;j \u00f00; 1\u00de \u00fe E i;j \u00f01; 0\u00de, which means that the two definitions are equivalent.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Example: Multicamera Scene Reconstruction", "text": "We now show an example of function from the class F 3 that is potentially useful in vision. Consider the multicamera scene reconstruction problem described earlier. Similar to the data term depending on pairs of pixels, we can define a term depending on triples of pixels. 6 Let I 3 be a set of triples of \"nearby\" 3D points. These points will come from three different cameras, but they will share the same depth (i.e., the points are of the form hp; f q i; hq; f q i; hr; f r i, where f p \u00bc f q \u00bc f r and p; q; r are pixels from different cameras). The new data term will be X fhp;li;hq;li;hr;li2I 3 g D p;q;r;l \u00f0f p ; f q ; f r \u00de; \u00f09\u00de\nwhere\nD p;q;r;l \u00f0f p ; f q ; f r \u00de \u00bc D\u00f0p; q; r\u00de \u00c1 T \u00bdf p \u00bc f q \u00bc f r \u00bc l:\nThis term can be motivated as follows: If three pixels have similar intensities, then it is more likely that they see the same scene element than if only two pixels have similar intensities. We now show the expansion move algorithm can be used for minimizing this new term, i.e., that the resulting energy function is regular. The proof proceeds similarly to the proof in Section 4.2.2. Consider a single term D\u00f0p; q; r\u00de \u00c1 T \u00bdf p \u00bc f q \u00bc f r \u00bc l, which imposes a penalty if p, q, and r have the label l. We will have three binary variables which are 0 if the associated pixel keeps its original label in f and 1 if it acquires the new label .\nAgain, there are two cases that must be analyzed separately: l 6 \u00bc and l \u00bc . Consider the case l 6 \u00bc . If at least one of labels f p ; f q ; f r is not l, then the term is zero for any values of binary variables. If f p \u00bc f q \u00bc f r \u00bc l, then the penalty is only imposed when the binary variables are all 0. Graphically, we show this in Table 11. Now, consider the case l \u00bc . If at least one of the labels f p ; f q ; f r is then the penalty imposed is independent of one of the binary variables; therefore, this case reduces to a data term depending on two variables, which has been analyzed earlier.\nSuppose that all labels f p ; f q ; f r are different from . Then, the penalty is only imposed when the binary variables are all 1, which is written graphically in Table 12. We get the result similar to the previous one: The energy function is regular if D\u00f0p; q; r\u00de is nonpositive.", "publication_ref": ["b5"], "figure_ref": [], "table_ref": ["tab_5", "tab_0"]}, {"heading": "MORE GENERAL CLASSES OF ENERGY FUNCTIONS", "text": "Finally, we give a necessary condition for graph representability for arbitrary functions of binary variables.  12 6. We thank Rick Szeliski for discussions that have led to the development of this term. Theorem 6.1 (regularity). Let E be a function of binary variables. If E is not regular, then E is not graph-representable. This theorem will imply the corresponding directions of the F 2 and F 3 theorems (Theorems 4.1 and 5.3). Definition 6.2. Let G \u00bc \u00f0V; E\u00de be a graph, v 1 ; . . . ; v k be a subset of vertices V, and 1 ; . . . ; k be binary constants whose values are from f0; 1g. We will define the graph G\u00bdx 1 \u00bc 1 ; . . . ; x k \u00bc k as follows: Its vertices will be the same as in G and its edges will be all edges of G plus additional edges corresponding to vertices v 1 ; . . . ; v k : for a vertex v i , we add the edge \u00f0s; v i \u00de if i \u00bc 0 or \u00f0v i ; t\u00de if i \u00bc 1, with an infinite capacity. It should be obvious that these edges enforce constraints f\u00f0v 1 \u00de \u00bc 1 , . . . , f\u00f0v k \u00de \u00bc k in the minimum cut on G\u00bdx 1 \u00bc 1 ; . . . ; x k \u00bc k , i.e., if i \u00bc 0, then v i 2 S and if i \u00bc 1, then v i 2 T . (If, for example, i \u00bc 0 and v i 2 T , then the edge \u00f0s; v i \u00de must be cut yielding an infinite cost, so it would not the minimum cut.)\nNow, we can give a definition of graph representability which is equivalent to Definition 3.1. This new definition will be more convenient for the proof. Definition 6.3. We say that the function E of n binary variables is exactly represented by the graph G \u00bc \u00f0V; E\u00de and the set V 0 & V if for any configuration 1 ; . . . ; n the cost of the minimum cut on G\u00bdx 1 \u00bc 1 ; . . . ; x k \u00bc k is E\u00f0 1 ; . . . ; n \u00de. Lemma 6.4. Any projection of a graph-representable function is graph-representable.\nProof. Let E be a graph-representable function of n variables and the graph G \u00bc \u00f0V; E\u00de and the set V 0 represents E. Suppose that we fix variables x i\u00f01\u00de ; . . . ; x i\u00f0m\u00de . It is straightforward to check that the graph G\u00bdx i\u00f01\u00de \u00bc i\u00f01\u00de ; . . . ; x i\u00f0m\u00de \u00bc i\u00f0m\u00de and the set V 0 0 \u00bc V 0 \u00c0 fv i\u00f01\u00de ; . . . ; v i\u00f0m\u00de g represents the function E 0 \u00bc E\u00bdx i\u00f01\u00de \u00bc i\u00f01\u00de ; . . . ; x i\u00f0m\u00de \u00bc i\u00f0m\u00de . t u This lemma implies that it suffices to prove Theorem 3.1 only for energy functions of two variables.\nLet \" E E\u00f0x 1 ; x 2 \u00de be a graph-representable function of two variables. Let us prove that \" E E is regular, i.e., that A 0, where\nA \u00bc \u00f0 \" E E\u00de\u00bc \" E E\u00f00; 0\u00de\u00fe \" E E\u00f01; 1\u00de \u00c0 \" E E\u00f00;\n1\u00de\u00c0 \" E E\u00f01; 0\u00de. Suppose this is not true: A > 0.\nIn Table 13, all the functions on the right side are graphrepresentable, therefore, by the additivity theorem (see the Appendix), the function E is graph-representable as well, where, in Table 14, consider a graph G and a set V 0 \u00bc fv 1 ; v 2 g representing E. This means that there is a constant K such that 15).\nG, V 0 exactly represent E 0 \u00f0x 1 ; x 2 \u00de \u00bc E\u00f0x 1 ; x 2 \u00de \u00fe K (Table\nThe cost of the minimum s-t-cut on G is K (since this cost is just the minimum entry in the table for E 0 ); hence, K ! 0. Thus, the value of the maximum flow from s to t in G is K. Let G 0 be the residual graph obtained from G after pushing the flow K. Let E 0 \u00f0x 1 ; x 2 \u00de be the function exactly represented by G 0 ; V 0 .\nBy the definition of graph representability, E 0 \u00f0 1 ; 2 \u00de is equal to the value of the minimum cut (or maximum flow) on the graph G\u00bdx\n1 \u00bc 1 ; x 2 \u00bc 2 .\nThe following sequence of operations shows one possible way to push the maximum flow through this graph.\n. First, we take the original graph G and push the flow K;\nthen we get the residual graph G 0 . (This is equivalent to pushing flow through G\u00bdx 1 \u00bc 1 ; x 2 \u00bc 2 , where we do not use edges corresponding to the constraints x 1 \u00bc 1 and x 2 \u00bc 2 ). . Then, we add edges corresponding to these constraints; we get the graph G 0 \u00bdx 1 \u00bc 1 ; x 2 \u00bc 2 . . Finally, we push the maximum flow possible through the graph G 0 \u00bdx 1 \u00bc 1 ; x 2 \u00bc 2 ; the amount of this flow is E 0 \u00f0 1 ; 2 \u00de according to the definition of graph representability. The total amount of flow pushed during all steps is\nK \u00fe E 0 \u00f0 1 ; 2 \u00de; thus, E 0 \u00f0 1 ; 2 \u00de \u00bc K \u00fe E 0 \u00f0 1 ; 2 \u00de or E\u00f0 1 ; 2 \u00de \u00bc E 0 \u00f0 1 ; 2 \u00de: We have proven that E is exactly represented by G 0 , V 0 .\nThe value of the minimum cut/maximum flow on G 0 is 0 (it is the minimum entry in the table for E); thus, there is no augmenting path from s to t in G 0 . However, if we add the edges \u00f0v 1 ; t\u00de and \u00f0v 2 ; t\u00de, then there will be an augmenting path from s to t in G 0 \u00bdx 1 \u00bc 1 ; x 2 \u00bc 2 since E\u00f01; 1\u00de \u00bc A > 0. Hence, this augmenting path will contain at least one of these edges and, therefore, either v 1 or v 2 will be in the path. Let P be the part of this path going from the source until v 1 or v 2 is first encountered. Without loss of generality, we can assume that it will be v 1 . Thus, P is an augmenting path from s to v 1 which does not contain edges that we added, namely, \u00f0v 1 ; t\u00de and \u00f0v 2 ; t\u00de.\nFinally, let us consider the graph G 0 \u00bdx 1 \u00bc 1; x 2 \u00bc 0 which is obtained from G 0 by adding edges \u00f0v 1 ; t\u00de and \u00f0s; v 2 \u00de with infinite capacities. There is an augmenting path fP ; \u00f0v 1 ; t\u00deg from the source to the sink in this graph; hence, the minimum cut/maximum flow on it is greater than zero or E\u00f01; 0\u00de > 0. We get a contradiction. ", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_0"]}, {"heading": "RELATED WORK", "text": "There is an interesting relationship between regular functions and submodular functions. 7 Let S be a finite set and g : 2 S ! R be a real-valued function defined on the set of all subsets of S. g is called submodular if for any X; Y & S\ng\u00f0X\u00de \u00fe g\u00f0Y \u00de ! g\u00f0X [ Y \u00de \u00fe g\u00f0X \\ Y \u00de:\nSee [15], for example, for a discussion of submodular functions. An equivalent definition of submodular functions is that g is called submodular if, for any X & S and i; j 2 S \u00c0 X, g\u00f0X [ fjg\u00de \u00c0 g\u00f0X\u00de ! g\u00f0X [ fi; jg\u00de \u00c0 g\u00f0X [ fig\u00de:\nObviously, functions of subsets X of S \u00bc f1; . . . ; ng can be viewed as functions of n binary variables \u00f0x 1 ; . . . ; x n \u00de; the indicator variable x i is 1 if i is included in X and 0 otherwise. Then, it is easy to see that the second definition of submodularity reduces to the definition of regularity. Thus, submodular functions and regular functions are essentially the same. We use different names to emphasize a technical distinction between them: Submodular functions are functions of subsets of S while regular functions are functions of binary variables. From our experience, the second point of view is much more convenient for vision applications.\nSubmodular functions have received significant attention in the combinatorial optimization literature. A remarkable fact about submodular functions is that they can be minimized in polynomial time [19], [23], [38]. A function g is assumed to be given as a value oracle, i.e., a \"black box\" which, for any input subset X returns the value g\u00f0X\u00de.\nUnfortunately, algorithms for minimizing arbitrary submodular functions are extremely slow. For example, the algorithm of [23] runs in O\u00f0n 5 minflog nM; n 2 log ng\u00de time, where M is an upper bound on jg\u00f0X\u00dej among X 2 2 S . Thus, our work can be viewed as identifying an important subclass of submodular functions for which much faster algorithm can be used.\nIn addition, a relation between submodular functions and certain graph-representable functions called cut functions is already known. Using our terminology, cut functions can be defined as functions that can be represented by a graph without the source and the sink and without auxiliary vertices. It is well-known that cut functions are submodular. Cunningham [11] characterizes cut functions and gives a general-purpose graph construction for them.\nIt can be shown that the set of cut functions is a strict subset of F 2 . We allow a more general graph construction; as a result, we can minimize a larger class of functions, namely, regular functions in F 3 .", "publication_ref": ["b6", "b14", "b18", "b22", "b37", "b22", "b10"], "figure_ref": [], "table_ref": []}, {"heading": "SUMMARY OF GRAPH CONSTRUCTIONS", "text": "We now summarize the graph constructions used for regular functions. Software can be downloaded from http:// www.cs.cornell.edu/~rdz/graphcuts.html that takes an energy function as input and automatically constructs the appropriate graph, then minimizes the energy.\nRecall that, for a function E\u00f0x 1 ; . . . ; x n \u00de, we define \u00f0E\u00de \u00bc X\nx 1 2f0;1g;...;x n 2f0;1g \u00c5 n i\u00bc1 \u00f0\u00c01\u00de x i \u00c0 \u00c1 E\u00f0x 1 ; . . . ; x n \u00de:\nThe notation edge\u00f0v; c\u00de will mean that we add an edge \u00f0s; v\u00de with the weight c if c > 0 or an edge \u00f0v; t\u00de with the weight \u00c0c if c < 0.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Regular Functions of One Binary Variable", "text": "Recall that all functions of one variable are regular. For a function E\u00f0x 1 \u00de, we construct a graph G with three vertices V \u00bc fv 1 ; s; tg. There is a single edge edge\u00f0v 1 ; E\u00f01\u00de \u00c0 E\u00f00\u00de\u00de.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Regular Functions of Two Binary Variables", "text": "We now show how to construct a graph G for a regular function E\u00f0x 1 ; x 2 \u00de of two variables. It will contain four vertices: V \u00bc fv 1 ; v 2 ; s; tg. The edges E are given below:\n. edge\u00f0v 1 ; E\u00f01; 0\u00de \u00c0 E\u00f00; 0\u00de\u00de;\n. edge\u00f0v 2 ; E\u00f01; 1\u00de \u00c0 E\u00f01; 0\u00de\u00de;\n. \u00f0v 1 ; v 2 \u00de with the weight \u00c0\u00f0E\u00de.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Regular Functions of Three Binary Vvariables", "text": "We next show how to construct a graph G for a regular function E\u00f0x 1 ; x 2 ; x 3 \u00de of three variables. It will contain five vertices: V \u00bc fv 1 ; v 2 ; v 3 ; u; s; tg. If \u00f0E\u00de ! 0, then the edges are . edge\u00f0v 1 ; E\u00f01; 0; 1\u00de \u00c0 E\u00f00; 0; 1\u00de\u00de;\n. edge\u00f0v 2 ; E\u00f01; 1; 0\u00de \u00c0 E\u00f01; 0; 0\u00de\u00de;\n. edge\u00f0v 3 ; E\u00f00; 1; 1\u00de \u00c0 E\u00f00; 1; 0\u00de\u00de;\n. \u00f0v 2 ; v 3 \u00de with the weight \u00c0\u00f0E\u00bdx 1 \u00bc 0\u00de;\n. \u00f0v 3 ; v 1 \u00de with the weight \u00c0\u00f0E\u00bdx 2 \u00bc 0\u00de;\n. \u00f0v 1 ; v 2 \u00de with the weight \u00c0\u00f0E\u00bdx 3 \u00bc 0\u00de;\n. \u00f0v 1 ; u\u00de, \u00f0v 2 ; u\u00de, \u00f0v 3 ; u\u00de, \u00f0u; t\u00de with the weight \u00f0E\u00de. If \u00f0E\u00de < 0, then the edges are . edge\u00f0v 1 ; E\u00f01; 1; 0\u00de \u00c0 E\u00f00; 1; 0\u00de\u00de; . edge\u00f0v 2 ; E\u00f00; 1; 1\u00de \u00c0 E\u00f00; 0; 1\u00de\u00de; . edge\u00f0v 3 ; E\u00f01; 0; 1\u00de \u00c0 E\u00f01; 0; 0\u00de\u00de; . \u00f0v 3 ; v 2 \u00de with the weight \u00c0\u00f0E\u00bdx 1 \u00bc 1\u00de;\n. \u00f0v 1 ; v 3 \u00de with the weight \u00c0\u00f0E\u00bdx 2 \u00bc 1\u00de; . \u00f0v 2 ; v 1 \u00de with the weight \u00c0\u00f0E\u00bdx 3 \u00bc 1\u00de; . \u00f0u; v 1 \u00de, \u00f0u; v 2 \u00de, \u00f0u; v 3 \u00de, \u00f0s; u\u00de with the weight \u00c0\u00f0E\u00de.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "APPENDIX A PROOF OF THE NP-HARDNESS THEOREM", "text": "We now give a proof of the NP-hardness theorem (Theorem 4.2), which shows that, without the regularity constraint, it is intractable to minimize energy functions in F 2 .\nProof. Adding functions of one variable does not change the class of functions that we are considering. Thus, we can assume without loss of generality that E 2 has the form that is shown in Table 16. (We can transform an arbitrary function of two variables to this form as follows: We subtract a constant from the first row to make the upper left element zero, then we subtract a constant from the second row to make the bottom left element zero, and, finally, we subtract a constant from the second column to make the upper right element zero.) These transformations preserve the functional , so E 2 is nonregular, which means that A > 0.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_2"]}, {"heading": "ACKNOWLEDGMENTS", "text": "The authors are grateful to Olga Veksler and Yuri Boykov for their careful reading of this paper and for valuable comments that greatly improved its readability. They would like to thank Jon Kleinberg and Eva Tardos for helping them understand the relationship between their work and submodular function minimization. They would also like to thank Ian Jermyn and several anonymous reviewers for helping them clarify the paper's presentation. ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": " ", "text": "7\n. We thank Yuri Boykov and Howard Karloff for pointing this out.\nWe will prove the theorem by reducing the maximum independent set problem, which is known to be NP-hard, to our energy minimization problem.\nLet an undirected graph G \u00bc \u00f0V; E\u00de be the input to the maximum independent set problem. A subset U & V is said to be independent if, for any two vertices u; v 2 U, the edge \u00f0u; v\u00de is not in E. The goal is to find an independent subset U \u00c3 & V of maximum cardinality. We construct an instance of the energy minimization problem as follows: There will be n \u00bc jVj binary variables x 1 ; . . . ; x n corresponding to the vertices v 1 ; . . . ; v n of V. Let us consider the energy\nwhere\nThere is a one-to-one correspondence between all configurations \u00f0x 1 ; . . . ; x n \u00de and subsets U & V: A vertex v i is in U if and only if x i \u00bc 1. Moreover, the first term of E\u00f0x 1 ; . . . ; x n \u00de is \u00c0 A 2n times the cardinality of U (which cannot be less than \u00c0 A\n2 ) and the second term is 0 if U is independent and at least A otherwise. Thus, minimizing the energy yields the independent subset of maximum cardinality.\nt u", "publication_ref": ["b6"], "figure_ref": [], "table_ref": []}, {"heading": "APPENDIX B THE ADDITIVITY THEOREM", "text": "We now prove the additivity theorem, which plays an important role in our constructions.\nTheorem (additivity). The sum of two graph-representable functions is graph-representable.\nIt is important to note that the proof of this theorem is constructive. The construction has a particularly simple form if the graphs representing the two functions are defined on the same set of vertices (i.e., they differ only in their edge weights). In this case, by simply adding the edge weights together, we obtain a graph that represents the sum of the two functions. If one of the graphs has no edge between two vertices, we can add an edge with weight 0.\nProof. Let us assume for simplicity of notation that E 0 and E 00 are functions of all n variables: E 0 \u00bc E 0 \u00f0x 1 ; . . . ; x n \u00de, E 00 \u00bc E 00 \u00f0x 1 ; . . . ; x n \u00de. By the definition of graph representability, there exist constants K 0 , K 00 , graphs G 0 \u00bc \u00f0V 0 ; E 0 \u00de, G 00 \u00bc \u00f0V 00 ; E 00 \u00de, and the set V 0 \u00bc fv 1 ; . . . ; v n g, V 0 & V 0 \u00c0 fs; tg, V 0 & V 00 \u00c0 fs; tg such that E 0 \u00fe K 0 is exactly represented by G 0 , V 0 and E 00 \u00fe K 00 is exactly represented by G 00 , V 0 . We can assume that the only common vertices of G 0 and G 00 are V 0 [ fs; tg. Let us construct the graph G \u00bc \u00f0V; E\u00de as the combined graph of G 0 and G 00 :\nLet\u1ebc E be the function that G, V 0 exactly represents. Let us prove that\u1ebc E E \u00fe \u00f0K 0 \u00fe K 00 \u00de (and, therefore, E is graph-representable).\nConsider a configuration x 1 ; . . . ; x n . Let C 0 \u00bc S 0 ; T 0 be the cut on G 0 with the smallest cost among all cuts for which\nAccording to the definition of graph representability, E 0 \u00f0x 1 ; . . . ; x n \u00de \u00fe K 0 \u00bc X u2S 0 ;v2T 0 ;\u00f0u;v\u00de2E 0 c\u00f0u; v\u00de:\nLet C 00 \u00bc S 00 ; T 00 be the cut on G 00 with the smallest cost among all cuts for which v i 2 S 00 if x i \u00bc 0, and v i 2 T 00 if\nSimilarly, E 00 \u00f0x 1 ; . . . ; x n \u00de \u00fe K 00 \u00bc X u2S 00 ;v2T 00 ;\u00f0u;v\u00de2E 0 0 c\u00f0u; v\u00de:\nIt is easy to check that C \u00bc S; T is a cut on G. Thus, E E\u00f0x 1 ; . . . ; x n \u00de X u2S;v2T ;\u00f0u;v\u00de2E c\u00f0u; v\u00de \u00bc X u2S 0 ;v2T 0 ;\u00f0u;v\u00de2E 0 c\u00f0u; v\u00de \u00fe X u2S 00 ;v2T 00 ;\u00f0u;v\u00de2E 0 0 c\u00f0u; v\u00de\nNow, let C \u00bc S; T be the cut on G with the smallest cost among all cuts for which\nIt is easy to see that C 0 \u00bc S 0 ; T 0 , and C 00 \u00bc S 00 ; T 00 are cuts on G 0 and G 00 , respectively. According to the definition of graph representability, ", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Network Flows: Theory, Algorithms, and Applications", "journal": "Prentice Hall", "year": "1993", "authors": "R K Ahuja; T L Magnanti; J B Orlin"}, {"ref_id": "b1", "title": "Using Dynamic Programming for Solving Variational Problems in Vision", "journal": "IEEE Trans. Pattern Analysis and Machine Intelligence", "year": "1990-09", "authors": "A Amini; T Weymouth; R Jain"}, {"ref_id": "b2", "title": "Stochastic Stereo Matching Over Scale", "journal": "Int'l J. Computer Vision", "year": "1989", "authors": "S Barnard"}, {"ref_id": "b3", "title": "Multiway Cut for Stereo and Motion with Slanted Surfaces", "journal": "", "year": "1999", "authors": "S Birchfield; C Tomasi"}, {"ref_id": "b4", "title": "Interactive Organ Segmentation Using Graph Cuts", "journal": "", "year": "2000", "authors": "Y Boykov; M.-P Jolly"}, {"ref_id": "b5", "title": "Interactive Graph Cuts for Optimal Boundary and Region Segmentation of Objects in N-D Images", "journal": "", "year": "2001", "authors": "Y Boykov; M.-P Jolly"}, {"ref_id": "b6", "title": "An Experimental Comparison of Min-Cut/Max-Flow Algorithms for Energy Minimization in Computer Vision", "journal": "Springer-Verlag", "year": "2001-09", "authors": "Y Boykov; V Kolmogorov"}, {"ref_id": "b7", "title": "Computing Geodesics and Minimal Surfaces via Graph Cuts", "journal": "", "year": "2003", "authors": "Y Boykov; V Kolmogorov"}, {"ref_id": "b8", "title": "Markov Random Fields with Efficient Approximations", "journal": "", "year": "1998", "authors": "Y Boykov; O Veksler; R Zabih"}, {"ref_id": "b9", "title": "Fast Approximate Energy Minimization via Graph Cuts", "journal": "", "year": "2001-11", "authors": "Y Boykov; O Veksler; R Zabih"}, {"ref_id": "b10", "title": "Minimum Cuts, Modular Functions, and Matroid Polyhedra", "journal": "Networks", "year": "1985", "authors": "W H Cunningham"}, {"ref_id": "b11", "title": "The Complexity of Multiway Cuts", "journal": "", "year": "1992", "authors": "E Dahlhaus; D S Johnson; C H Papadimitriou; P D Seymour; M Yannakakis"}, {"ref_id": "b12", "title": "The ZM Algorithm: A Method for Interferometric Image Reconstruction in SAR/SAS", "journal": "IEEE Trans. Image Processing", "year": "2002-04", "authors": "J Dias; J Leitao"}, {"ref_id": "b13", "title": "Flows in Networks", "journal": "Princeton Univ. Press", "year": "1962", "authors": "L Ford; D Fulkerson"}, {"ref_id": "b14", "title": "Submodular Functions and Optimization", "journal": "Annals of Discrete Math", "year": "1990", "authors": "S Fujishige"}, {"ref_id": "b15", "title": "Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images", "journal": "IEEE Trans. Pattern Analysis and Machine Intelligence", "year": "1984", "authors": "S Geman; D Geman"}, {"ref_id": "b16", "title": "A New Approach to the Maximum Flow Problem", "journal": "J. ACM", "year": "1988-10", "authors": "A Goldberg; R Tarjan"}, {"ref_id": "b17", "title": "Exact Maximum A Posteriori Estimation for Binary Images", "journal": "J. Royal Statistical Soc., Series B", "year": "1989", "authors": "D Greig; B Porteous; A Seheult"}, {"ref_id": "b18", "title": "Geometric Algorithms and Combinatorial Optimization", "journal": "Springer-Verlag", "year": "1988", "authors": "M Gr\u00f6 Tschel; L Lovasz; A Schrijver"}, {"ref_id": "b19", "title": "Occlusions, Discontinuities, and Epipolar Lines in Stereo", "journal": "", "year": "1998", "authors": "H Ishikawa; D Geiger"}, {"ref_id": "b20", "title": "Segmentation by Grouping Junctions", "journal": "", "year": "1998", "authors": "H Ishikawa; D Geiger"}, {"ref_id": "b21", "title": "Exact Optimization for Markov Random Fields with Convex Priors", "journal": "IEEE Trans. Pattern Analysis and Machine Intelligence", "year": "2003-10", "authors": "H Ishikawa"}, {"ref_id": "b22", "title": "A Combinatorial, Strongly Polynomial Algorithm for Minimizing Submodular Functions", "journal": "J. ACM", "year": "2001-07", "authors": "S Iwata; L Fleischer; S Fujishige"}, {"ref_id": "b23", "title": "Visual Correspondence Using Energy Minimization and Mutual Information", "journal": "", "year": "2003", "authors": "J Kim; V Kolmogorov; R Zabih"}, {"ref_id": "b24", "title": "Automatic Segmentation of Contrast-Enhanced Image Sequences", "journal": "", "year": "2003", "authors": "J Kim; R Zabih"}, {"ref_id": "b25", "title": "Incorporating Spatial Priors into an Information Theoretic Approach for FMRI Data Analysis", "journal": "", "year": "2000", "authors": "J Kim; J Fisher; A Tsai; C Wible; A Willsky; W Wells"}, {"ref_id": "b26", "title": "Visual Correspondence with Occlusions Using Graph Cuts", "journal": "", "year": "2001", "authors": "V Kolmogorov; R Zabih"}, {"ref_id": "b27", "title": "Multi-Camera Scene Reconstruction via Graph Cuts", "journal": "", "year": "2002", "authors": "V Kolmogorov; R Zabih"}, {"ref_id": "b28", "title": "Graphcut Textures: Image and Video Synthesis Using Graph Cuts", "journal": "", "year": "2003-07", "authors": "V Kwatra; A Sch\u00f6 Dl; I Essa; G Turk; A Bobick"}, {"ref_id": "b29", "title": "Optimal Task Assignment in Linear Array Networks", "journal": "IEEE Trans. Computers", "year": "1992-07", "authors": "C.-H Lee; D Lee; M Kim"}, {"ref_id": "b30", "title": "Markov Random Field Modeling in Computer Vision", "journal": "Springer-Verlag", "year": "1995", "authors": "S Li"}, {"ref_id": "b31", "title": "Surfaces with Occlusions from Layered Stereo", "journal": "", "year": "2002-12", "authors": "M H Lin"}, {"ref_id": "b32", "title": "Task Assignment in Distributed Systems Using Network Flow Methods", "journal": "Springer-Verlag", "year": "1996", "authors": "I Milis"}, {"ref_id": "b33", "title": "Computational Vision and Regularization Theory", "journal": "Nature", "year": "1985", "authors": "T Poggio; V Torre; C Koch"}, {"ref_id": "b34", "title": "Stereo without Epipolar Lines: A Maximum Flow Formulation", "journal": "Int'l J. Computer Vision", "year": "1999", "authors": "S Roy"}, {"ref_id": "b35", "title": "A Maximum-Flow Formulation of the n-Camera Stereo Correspondence Problem", "journal": "", "year": "1998", "authors": "S Roy; I Cox"}, {"ref_id": "b36", "title": "A Taxonomy and Evaluation of Dense Two-Frame Stereo Correspondence Algorithms", "journal": "Int'l J. Computer Vision", "year": "2002-04", "authors": "D Scharstein; R Szeliski"}, {"ref_id": "b37", "title": "A Combinatorial Algorithm Minimizing Submodular Functions in Strongly Polynomial Time", "journal": "J. Combinatorial Theory", "year": "2000", "authors": "A Schrijver"}, {"ref_id": "b38", "title": "Exact Voxel Occupancy with Graph Cuts", "journal": "", "year": "2000", "authors": "D Snow; P Viola; R Zabih"}, {"ref_id": "b39", "title": "Multiprocessor Scheduling with the Aid of Network Flow Algorithms", "journal": "IEEE Trans. Software Eng", "year": "1977", "authors": "H S Stone"}, {"ref_id": "b40", "title": "An Experimental Comparison of Stereo Algorithms", "journal": "Springer-Verlag", "year": "1999-09", "authors": "R Szeliski; R Zabih"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Fig. 1 .1Fig.1. An example of an expansion move. The labeling on the right is a white-expansion move from the labeling on the left.", "figure_data": ""}, {"figure_label": "412", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Theorem 4 . 1 (F 2412Theorem). Let E be a function of n binary variables from the class F 2 , i.e., E\u00f0x 1 ; . .", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Fig. 2 .2Fig.2. Graphs that represent some functions in F 2 . (a) Graph for E i , where E i \u00f00\u00de > E i \u00f01\u00de. (b) Graph for E i , where E i \u00f00\u00de 6 > E i \u00f00\u00de. (c) Third edge for E i;j . (d) Complete graph for E i;j if C > A and C > D.", "figure_data": ""}, {"figure_label": "51", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Definition 5 . 1 .51Let E\u00f0x 1 ; . . . ; x n \u00de be a function of n binary variables and let I, J be a disjoint partition of the set of indices f1; . . . ; ng: I \u00bc fi\u00f01\u00de; . . . ; i\u00f0m\u00deg, J \u00bc fj\u00f01\u00de; . . . ; j\u00f0n \u00c0 m\u00deg. Let i\u00f01\u00de ; . . . ; i\u00f0m\u00de be binary constants. A projection E 0 \u00bc E\u00bdx i\u00f01\u00de \u00bc i\u00f01\u00de ; . . . ; x i\u00f0m\u00de \u00bc i\u00f0m\u00de is a function of n \u00c0 m variables defined by E 0 \u00f0x j\u00f01\u00de ; . . . ; x j\u00f0n\u00c0m\u00de \u00de \u00bc E\u00f0x 1 ; . . . ; x n \u00de;", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Fig. 3 .3Fig. 3. Graphs for functions in F 3 . (a) Edge weights are all P . (b) Edge weights are all \u00c0P .", "figure_data": ""}, {"figure_label": "12", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "", "figure_data": ""}, {"figure_label": "345", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "", "figure_data": ""}, {"figure_label": "6", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "", "figure_data": ""}, {"figure_label": "78", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "", "figure_data": ""}, {"figure_label": "910", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "", "figure_data": ""}, {"figure_label": "11", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "", "figure_data": ""}, {"figure_label": "131415", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "E\u00f0x 1 ; . . . ; x n \u00de \u00bc X i E i \u00f0x i \u00de \u00fe X i<j E i;j \u00f0x i ; x j \u00de:\u00f01\u00de", "formula_coordinates": [2.0, 62.19, 155.18, 215.05, 27.78]}, {"formula_id": "formula_1", "formula_text": "E\u00f0x 1 ; . . . ; x n \u00de \u00bc X i E i \u00f0x i \u00de \u00fe X i<j E i;j \u00f0x i ; x j \u00de \u00fe X", "formula_coordinates": [2.0, 64.01, 214.48, 175.48, 43.79]}, {"formula_id": "formula_2", "formula_text": "E\u00f0f\u00de \u00bc X p2P D p \u00f0f p \u00de \u00fe X p;q2N V p;q \u00f0f p ; f q \u00de;\u00f03\u00de", "formula_coordinates": [2.0, 338.34, 102.22, 201.96, 28.52]}, {"formula_id": "formula_3", "formula_text": "D p;q;l \u00f0f p ; f q \u00de;\u00f04\u00de", "formula_coordinates": [3.0, 415.39, 678.8, 124.91, 9.57]}, {"formula_id": "formula_4", "formula_text": "D p;q;l \u00f0f p ; f q \u00de \u00bc D\u00f0p; q\u00de \u00c1 T \u00bdf p \u00bc f q \u00bc l:", "formula_coordinates": [3.0, 337.67, 726.65, 154.21, 9.57]}, {"formula_id": "formula_5", "formula_text": "fp;qg2N V p;q \u00f0f p ; f q \u00de;\u00f05\u00de", "formula_coordinates": [4.0, 115.94, 121.74, 161.31, 19.38]}, {"formula_id": "formula_6", "formula_text": "x i \u00bc 0, and v i 2 T , if x i \u00bc 1 (1 i n). We say that E is exactly represented by G, V 0 if this constant is zero.", "formula_coordinates": [4.0, 301.15, 260.46, 239.14, 20.68]}, {"formula_id": "formula_7", "formula_text": ". ; x n \u00de \u00bc X i E i \u00f0x i \u00de \u00fe X i<j E i;j \u00f0x i ; x j \u00de:\u00f06\u00de", "formula_coordinates": [4.0, 357.68, 595.34, 182.62, 27.78]}, {"formula_id": "formula_8", "formula_text": "E\u00f0x 1 ; . . . ; x n \u00de \u00bc X i E i \u00f0x i \u00de \u00fe X \u00f0i;j\u00de2N E 2 \u00f0x i ; x j \u00de;", "formula_coordinates": [5.0, 58.56, 558.09, 184.77, 28.8]}, {"formula_id": "formula_9", "formula_text": "V \u00f0; \u00de \u00bc 0 and V \u00f0; \u00de \u00fe V \u00f0; \u00de ! V \u00f0; \u00de.", "formula_coordinates": [6.0, 26.2, 300.32, 251.07, 20.51]}, {"formula_id": "formula_10", "formula_text": "E\u00f0x 1 ; . . . ; x n \u00de \u00bc X i E i \u00f0x i \u00de \u00fe X i<j E i;j \u00f0x i ; x j \u00de \u00fe X i<j<k E i;j;k \u00f0x i ; x j ; x k \u00de:\u00f08\u00de", "formula_coordinates": [6.0, 327.0, 680.95, 213.3, 53.12]}, {"formula_id": "formula_11", "formula_text": "P \u00bc \u00f0A \u00fe D \u00fe F \u00fe G\u00de \u00c0 \u00f0B \u00fe C \u00fe E \u00fe", "formula_coordinates": [7.0, 100.74, 439.39, 160.07, 9.14]}, {"formula_id": "formula_12", "formula_text": "P 1 \u00bc F \u00c0 B, P 2 \u00bc G \u00c0 E, P 3 \u00bc D \u00c0 C, P 23 \u00bc B \u00fe C \u00c0 A \u00c0D, P 31 \u00bc B \u00fe E \u00c0 A \u00c0 F , P 12 \u00bc C \u00fe E \u00c0 A \u00c0 G. E i;j;k", "formula_coordinates": [7.0, 26.19, 472.84, 251.07, 20.57]}, {"formula_id": "formula_13", "formula_text": "x i \u00bc x j \u00bc x k \u00bc 1,", "formula_coordinates": [7.0, 289.25, 375.32, 70.51, 9.57]}, {"formula_id": "formula_14", "formula_text": "P 1 \u00bc C \u00c0 G, P 2 \u00bc B \u00c0 D, P 3 \u00bc E \u00c0 F , P 32 \u00bc F \u00fe G \u00c0 E \u00c0 H, P 13 \u00bc D \u00fe G \u00c0 C \u00c0 H, P 21 \u00bc D \u00fe F \u00c0 B \u00c0 H. By considering projec- tions E i;j;k \u00bdx 1 \u00bc 1, E i;j;k \u00bdx 2 \u00bc 1, E i;j;k \u00bdx 3 \u00bc 1, we conclude that P 32 , P 13 , P 21 are nonnegative.", "formula_coordinates": [7.0, 289.25, 500.33, 251.03, 55.21]}, {"formula_id": "formula_15", "formula_text": "E\u00f0x 1 ; . . . ; x n \u00de \u00bc X i<j<k E i;j;k \u00f0x i ; x j ; x k \u00de;", "formula_coordinates": [8.0, 75.74, 358.53, 150.41, 28.0]}, {"formula_id": "formula_16", "formula_text": "\u00c5 n i\u00bc1\u00f0\u00c01\u00de", "formula_coordinates": [8.0, 149.1, 492.08, 37.6, 12.38]}, {"formula_id": "formula_17", "formula_text": "x i \u00c0 \u00c1 E\u00f0x 1 ; . . . ; x n \u00de:", "formula_coordinates": [8.0, 144.85, 485.47, 109.14, 17.8]}, {"formula_id": "formula_18", "formula_text": "0 \u00fe E 00 \u00de \u00bc \u00f0E 0 \u00de \u00fe \u00f0E 00 \u00de and \u00f0c \u00c1 E 0 \u00de \u00bc c \u00c1 \u00f0E 0 \u00de. . If E", "formula_coordinates": [8.0, 50.12, 607.42, 227.13, 33.72]}, {"formula_id": "formula_19", "formula_text": "E\u00f0x 1 ; . . . ; x n \u00de \u00bc X i<j<k E i;j;k \u00f0x i ; x j ; x k \u00de;", "formula_coordinates": [8.0, 338.74, 170.09, 150.47, 28.0]}, {"formula_id": "formula_20", "formula_text": "E\u00f0x 1 ; . . . ; x n \u00de \u00bc X i<j<k\u1ebc E i;j;k \u00f0x i ; x j ; x k \u00de;", "formula_coordinates": [8.0, 338.74, 229.73, 150.47, 28.0]}, {"formula_id": "formula_21", "formula_text": "X i<j<k N\u1ebc E i;j;k \u00c0 \u00c1 < X i<j<k N E i;j;k \u00c0 \u00c1 :", "formula_coordinates": [8.0, 351.33, 274.23, 128.41, 27.95]}, {"formula_id": "formula_22", "formula_text": "C k \u00bc max k 2f0;1g \u00f0E 1;2;k \u00bdx k \u00bc k \u00de k 2 f4; . . . ; ng C 3 \u00bc \u00c0 X n k\u00bc4 C k :", "formula_coordinates": [8.0, 311.19, 368.1, 207.13, 59.94]}, {"formula_id": "formula_23", "formula_text": "E E 1;2;k E 1;2;k \u00c0 R\u00bdC k k 2 f3; . . . ; ng;", "formula_coordinates": [8.0, 325.3, 465.73, 177.34, 11.18]}, {"formula_id": "formula_24", "formula_text": "E\u00f0x 1 ; . . . ; x n \u00de \u00bc X i<j<k\u1ebc E i;j;k \u00f0x i ; x j ; x k \u00de since P n k\u00bc3 C k \u00bc 0 and P n k\u00bc3 R\u00bdC k 0.", "formula_coordinates": [8.0, 301.15, 518.52, 187.56, 48.36]}, {"formula_id": "formula_25", "formula_text": "\u00f0E 1;2;k \u00bdx k \u00bc k \u00de C k , thus \u00f0\u1ebc E 1;2;k \u00bdx k \u00bc k \u00de \u00bc\u00f0E 1;2;k \u00bdx k \u00bc k \u00de \u00c0 \u00f0R\u00bdC k \u00bdx k \u00bc k \u00de C k \u00c0 C k \u00bc 0:", "formula_coordinates": [9.0, 37.08, 192.75, 229.33, 45.48]}, {"formula_id": "formula_26", "formula_text": "\u00f0\u1ebc E 1;2;3 \u00bdx 3 \u00bc 3 \u00de \u00bc \u00f0E 1;2;3 \u00bdx 3 \u00bc 3 \u00de \u00c0 \u00f0R\u00bdC 3 \u00bdx 3 \u00bc 3 \u00de \u00bc \u00f0E 1;2;3 \u00bdx 3 \u00bc 3 \u00de \u00c0 \u00f0\u00c0 X n k\u00bc4 C k \u00de \u00bc X n k\u00bc3 \u00f0E 1;2;k \u00bdx k \u00bc k \u00de;", "formula_coordinates": [9.0, 30.39, 302.39, 242.71, 41.91]}, {"formula_id": "formula_27", "formula_text": "E\u00f0x 1 ; . . . ; x n \u00de \u00bc X i E i \u00f0x i \u00de \u00fe X i<j E i;j \u00f0x i ; x j \u00de:", "formula_coordinates": [9.0, 62.19, 653.85, 179.1, 27.78]}, {"formula_id": "formula_28", "formula_text": "D p;q;r;l \u00f0f p ; f q ; f r \u00de \u00bc D\u00f0p; q; r\u00de \u00c1 T \u00bdf p \u00bc f q \u00bc f r \u00bc l:", "formula_coordinates": [9.0, 314.76, 364.16, 200.02, 9.57]}, {"formula_id": "formula_29", "formula_text": "A \u00bc \u00f0 \" E E\u00de\u00bc \" E E\u00f00; 0\u00de\u00fe \" E E\u00f01; 1\u00de \u00c0 \" E E\u00f00;", "formula_coordinates": [10.0, 26.19, 568.4, 143.33, 11.03]}, {"formula_id": "formula_30", "formula_text": "G, V 0 exactly represent E 0 \u00f0x 1 ; x 2 \u00de \u00bc E\u00f0x 1 ; x 2 \u00de \u00fe K (Table", "formula_coordinates": [10.0, 26.19, 645.86, 231.89, 10.99]}, {"formula_id": "formula_31", "formula_text": "1 \u00bc 1 ; x 2 \u00bc 2 .", "formula_coordinates": [10.0, 359.66, 207.51, 66.77, 9.57]}, {"formula_id": "formula_32", "formula_text": "K \u00fe E 0 \u00f0 1 ; 2 \u00de; thus, E 0 \u00f0 1 ; 2 \u00de \u00bc K \u00fe E 0 \u00f0 1 ; 2 \u00de or E\u00f0 1 ; 2 \u00de \u00bc E 0 \u00f0 1 ; 2 \u00de: We have proven that E is exactly represented by G 0 , V 0 .", "formula_coordinates": [10.0, 289.25, 385.62, 239.91, 86.87]}, {"formula_id": "formula_33", "formula_text": "g\u00f0X\u00de \u00fe g\u00f0Y \u00de ! g\u00f0X [ Y \u00de \u00fe g\u00f0X \\ Y \u00de:", "formula_coordinates": [11.0, 75.8, 140.45, 151.88, 9.14]}], "doi": ""}