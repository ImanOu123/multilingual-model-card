{"title": "PaperMage: A Unified Toolkit for Processing, Representing, and Manipulating Visually-Rich Scientific Documents", "authors": "Kyle Lo; Zejiang Shen; Benjamin Newman; Joseph Chee Chang; Russell Authur; Erin Bransom; Stefan Candra; Yoganand Chandrasekhar; Regan Huff; Bailey Kuehl; Amanpreet Singh; Chris Wilhelm; Angele Zamarron; Marti A Hearst; Daniel S Weld; Doug Downey; Luca Soldaini", "pub_date": "", "abstract": "Despite growing interest in applying natural language processing (NLP) and computer vision (CV) models to the scholarly domain, scientific documents remain challenging to work with. They're often in difficult-to-use PDF formats, and the ecosystem of models to process them is fragmented and incomplete. We introduce papermage, an opensource Python toolkit for analyzing and processing visually-rich, structured scientific documents. papermage offers clean and intuitive abstractions for seamlessly representing and manipulating both textual and visual document elements. papermage achieves this by integrating disparate state-of-the-art NLP and CV models into a unified framework, and provides turnkey recipes for common scientific document processing use-cases. papermage has powered multiple research prototypes of AI applications over scientific documents, along with Semantic Scholar's large-scale production system for processing millions of PDFs.", "sections": [{"heading": "Introduction", "text": "Research papers and textbooks are central to the scientific enterprise, and there is increasing interest in developing new tools for extracting knowledge from these visually-rich documents. Recent research has explored, for example, AI-powered reading support for math symbol definitions (Head et al., 2021), in-situ passage explanations or summaries Rachatasumrit et al., 2022;, automatic span highlighting Fok et al., 2023b), interactive clipping and synthesis (Kang et al., 2022 * Core contributors; see author contributions for details. 1 We use code snippets to illustrate our toolkit's core designs and abstractions. Exact syntax in paper may differ from the actual code, as software will evolve beyond the paper and we opt to simplify syntax when needed for legibility and clarity. We refer readers to our public code for latest documentation. and more. Further, extracting clean, properlystructured scientific text from PDF documents (Lo et al., 2020; forms a critical first step in pretraining language models of science Lee et al., 2019;Gu et al., 2020;Luo et al., 2022;Taylor et al., 2022;Trewartha et al., 2022;Hong et al., 2023), automatic generation of more accessible paper formats , and developing datasets for scientific natural language processing (NLP) tasks over structured full text (Jain et al., 2020;Subramanian et al., 2020;Dasigi et al., 2021;Lee et al., 2023).\nHowever, this type of NLP research on scientific corpora is difficult because the documents come in difficult-to-use formats like PDF, 2 and existing tools for working with the documents are limited. Typically, the first step in scientific document processing is to invoke a parser on a document file to convert it into a sequence of tokens and bounding boxes in inferred reading order. Parsers extract only the raw document content, and obtaining richer document structure (e.g., titles, authors, figures) or linguistic structure and semantics (e.g., sentences, discourse units, scientific claims) requires sending the token sequence through downstream models.\nUnlike more mature parsers ( \u00a72.1), these downstream models are often research prototypes ( \u00a72.2) that are limited to extracting only a subset of the structures needed for one's research (e.g., the same model may not provide both sentence splits and figure detection). As a result, users must write extensive custom code that strings pipelines of multiple models together. Research projects using models of different modalities (e.g., combining an imagebased formula detector with a text-based definition extractor) can require hundreds of lines of code. We introduce papermage, an open-source Python toolkit for processing scientific documents. Its contributions include (1) magelib, a library of primitives and methods for representing and manipulating visually-rich documents as multimodal constructs, (2) Predictors, a set of implementations that integrate different state-of-the-art scientific document analysis models into a unified interface, even if individual models are written in different frameworks or operate on different modalities, and (3) Recipes, which provide turn-key access to well-tested combinations of individual (often single-modality) modules to form sophisticated, extensible multimodal pipelines.", "publication_ref": ["b13", "b36", "b10", "b19", "b30", "b25", "b12", "b31", "b45", "b14", "b18", "b41", "b8", "b26"], "figure_ref": [], "table_ref": []}, {"heading": "Related Work", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Turn-key software for scientific documents", "text": "Processing visually-rich documents like scientific documents requires a joint understanding of both visual and textual information. In practice, this often requires combining different models into complex processing pipelines. For example, GRO-BID (Grobid, 2008(Grobid, -2023, a widely-adopted software tool for scientific document processing, uses twelve interdependent sequence labeling models 3 to perform its full text extraction. Other similar tools inlude CERMINE (Tkaczyk et al., 2015) and ParsCit (Councill et al., 2008). While such software is often an ideal choice for off-the-shelf processing, they are not necessarily designed for easy extension and/or integration with newer research models. 4", "publication_ref": ["b44"], "figure_ref": [], "table_ref": []}, {"heading": "Models for scientific document processing", "text": "While aforementioned software tools use CRF or BiLSTM-based models, Transformer-based models have seen wide adoption among NLP researchers for their powerful processing capabilities. Recent years have seen the rise of layout-infused Transformers (Xu et al., 2019;Shen et al., 2022;Xu et al., 2021;Huang et al., 2022b; for processing visually-rich documents, including recovering logical structure (e.g., titles, abstracts) of scientific papers (Huang et al., 2022a). Similarly, computer vision (CV) researchers have also shown impressive capabilities of CNN-based object detection models (Ren et al., 2015;Tan et al., 2020) for segmenting visually-rich documents based on their layout. While these research models are powerful and extensible for research purposes, it often requires significant \"glue\" code and stitching software tools to create robust processing pipelines. For example, Lincker et al. (2023) bootstraps a sophisticated processing pipeline around a research model for processing children's textbooks.", "publication_ref": ["b51", "b39", "b49", "b16", "b15", "b37", "b42"], "figure_ref": [], "table_ref": []}, {"heading": "Combining models and pipelines", "text": "papermage's use case lies between that of turnkey software and a framework for supporting research. Similar to Transformers (Wolfe et al., 2022)'s integration of different research models into standard interfaces, others have done similarly for the visually-rich document domain. LayoutParser (Shen et al., 2021) provides models for visually-rich documents and supports the creation of document processing pipelines. papermage, in fact, depends on LayoutParser for access to vision models, but is designed to also integrate text models which are omitted from LayoutParser. To allow models of different modalities to work well together, we also developed the magelib library ( \u00a73.1).\n3 Design of papermage papermage is three parts: (1) magelib, a library for intuitively representing and manipulating visuallyrich documents, (2) Predictors, implementations of models for analyzing scientific papers that unify disparate machine learning frameworks under a common interface, and (3) Recipes, combinations of Predictors that form multimodal pipelines.", "publication_ref": ["b48", "b40"], "figure_ref": [], "table_ref": []}, {"heading": "Representing and manipulating visually-rich documents with magelib", "text": "In this section, we use code snippets to show how our library's abstractions and syntax are tailored for the visually-rich document problem domain.\nData Classes. magelib provides three base data classes for representing fundamental elements of visually-rich, structured documents: Document, Layers and Entities. First, a Document might minimally store text as a string of symbols:\nBut visually-rich documents are more than a linearized string. For example, analyzing a scientific paper requires access to its visuospatial layout (e.g., pages, blocks, lines), logical structure (e.g., title, abstract, figures, tables, footnotes, sections), semantic units (e.g., paragraphs, sentences, tokens), and more (e.g., citations, terms). In practice, this means different parts of doc.symbols can correspond to different paragraphs, sentences, tokens, etc. in the Document, each with its own set of corresponding coordinates representing its visual position on a page. magelib represents structure using Layers that can be accessed as attributes of a Document (e.g., doc.sentences, doc.figures, doc.tokens) (Figure 1). Each Layer is a sequence of content units, called Entities, which store both textual (e.g., spans, strings) and visuospatial (e.g., bounding boxes, pixel arrays) information:\n1 >>> sentences = Layer ( entities =[ 2 Entity (...) , Entity (...) , ... See Figure 2 for an example on how \"sentences\" in a scientific document are represented as Entities. Section \u00a73.2 explains in more detail how a user can generate Entities.\nMethods. magelib also provides a set of functions for building and interacting with data: augmenting a Document with additional Layers, traversing and spatially searching for matching Entities in one Layer, and cross-referencing between Layers (see Figure 3).\nA Document that only contains doc.symbols can be augmented with additional Layers:\n1 >>> paragraphs = Layer (...) 2 >>> sentences = Layer (...) 3 >>> tokens = Layer (...) [\"Techniques\", \"for\", \"collecting\", \"labeled\", \"data\", \"perts\", \"for\", \"manual\", \"annotation\", ...]\nCrowdsourcing provides a scalable and efficient way to construct labeled datasets for training machine learning systems. However, creating comprehensive label guidelines for crowdworkers is often prohibitive even for seemingly simple concepts. Incomplete or ambiguous label guidelines can then result in differing interpretations of concepts and inconsistent labels. Existing approaches for improving label quality, such as worker screening or detection of poor work, are ineffective for this problem and can lead to rejection of honest work and a missed opportunity to capture rich interpretations about data. We introduce Revolt, a collaborative approach that brings ideas from expert annotation workflows to crowd-based labeling.\nRevolt eliminates the burden of creating detailed label guidelines by harnessing crowd disagreements to identify ambiguous concepts and create rich structures (groups of semantically related items) for post-hoc label decisions. Experiments comparing Revolt to traditional crowdsourced labeling show that Revolt produces high quality labels without requiring label guidelines in turn for an increase in monetary cost. This up front cost, however, is mitigated by Revolt's ability to produce reusable structures that can accommodate a variety of label boundaries without requiring new data to be collected. Further comparisons of Revolt's collaborative and non-collaborative variants show that collabvoration reaches higher label accuracy with lower monetary cost.\nlearned models that must be trained on representative datasets labeled according to target concepts (e.g., speech labeled by their intended commands, faces labeled in images, emails labeled as spam or not spam).   In this example, papermage runs PDF2TextParser (using pdfplumber) to extract the textual information from a PDF file.\nThen it runs PDF2ImageRasterizer (using pdf2image) to update the first Document with images of pages.", "publication_ref": [], "figure_ref": ["fig_0", "fig_1"], "table_ref": []}, {"heading": "Interfacing with models for scientific document analysis through Predictors", "text": "In \u00a73.1, we described how users create Layers by assembling collections of Entities. But how would they make Entities in the first place? For example, to identify multimodal structures in visually-rich documents, researchers might want to build complex pipelines that run and combine output from many different models (e.g., computer vision models for extracting figures, NLP models for classifying body text). papermage provides a unified interface, called Predictors, to ensure models produce Entities that are compatible with the Document. papermage includes several ready-to-use Predictors that leverage state-of-the-art models to extract specific document structures (Table 1). While magelib's abstractions are general for visually-rich documents, Predictors are optimized for parsing of scientific documents. They are designed to (1) be compatible with models from many different machine learning frameworks, (2) support inference with text-only, vision-only, and multimodal models, and (3) support both adaptation of off-the-shelf, pretrained models as well as", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_3"]}, {"heading": "Use case Description Examples", "text": "Linguistic/ Semantic Segments doc into text units often used for downstream models.\nSentencePredictor wraps sciSpaCy (Neumann et al., 2019) and PySBD (Sadvilkar and Neumann, 2020) to segment sentences. WordPredictor is a custom scikit-learn model to identify broken words split across PDF lines or columns. ParagraphPredictor is a set of heuristics on top of both layout and logical structure models to extract paragraphs. Layout Structure Segments doc into visual block regions.\nBoxPredictor wraps models from LayoutParser (Shen et al., 2021), which provides vision models like EfficientDet (Tan et al., 2020) pretrained on scientific layouts (Zhong et al., 2019).", "publication_ref": ["b32", "b38", "b40", "b42", "b51"], "figure_ref": [], "table_ref": []}, {"heading": "Logical Structure", "text": "Segments doc into organizational units like title, abstract, body, footnotes, caption, and more.\nSpanPredictor wraps Token Classifiers from Transformers (Wolfe et al., 2022), which provides both pretrained weights from VILA (Shen et al., 2022), as well as RoBERTa (Liu et al., 2019), SciBERT  weights that we've finetuned on similar data. Taskspecific Models for a given scientific document processing task can be used with papermage if wrapped as a Predictor following common patterns.\nAs many practitioners depend on prompting a model through an API call, we implement APIPredictor which interfaces external APIs, such as GPT-3 (Brown et al., 2020), to perform tasks like question answering over a structured Document.\nWe also implement SnippetRetrievalPredictor which wraps models like Contriever (Izacard et al., 2022) to perform top-k within-document snippet retrieval. See \u00a74 for how these two can be combined.  Predictors return a list of Entities, which can be group_by() to organize them based on predicted label value (e.g., tokens classified as \"title\" or \"authors\"). Finally, these predictions are passed to doc.annotate() to be added to Document.", "publication_ref": ["b48", "b39", "b28", "b17"], "figure_ref": [], "table_ref": []}, {"heading": "End-to-end processing with Recipes", "text": "Finally, papermage provides predefined combinations of Predictors, called Recipes, for users seeking high-quality options for turn-key processing of visually-rich documents: Recipes can also be flexibly modified to support development. For example, our current default combines the pdfplumber PDF parsing utility with the I-VILA (Shen et al., 2022) research model. We show in Table 2 an evaluation comparing this against the same recipe but configured to (1) swap I-VILA for a RoBERTa model, as well as (2) swap both for Grobid API calls. We expect Recipes to appeal to two groups of users-end-to-end consumers, and developers of high-level applications. The former is comprised of developers and researchers who are looking for a one-step solution to multimodal scientific document analysis. The latter are likely developers and researchers looking to combine document structure primitives to build a complex application (see example in \u00a74).  2023), Lucy is studying how language models can be used to resolve questions that arise while reading a paper (e.g. What does this mean? or What does this refer to?). In her prototype interface, a user can highlight a passage in a PDF and ask a question about it. A retrieval model then finds relevant passages from the rest of the paper. The prototype then uses the text of the retrieved passages along with the user question to prompt a language model to generate an answer.\nWhen presenting the answer to the user, the prototype also visually highlights the retrieved passages as supporting evidence to the generated answer. Formatting output. Lucy runs her QA system on her newly acquired text data and now has (1) a model-generated answer and (2) several retrieved evidence passages. She realizes that she already has access to the evidences' bounding boxes via a similar call to how she defined the model input context (e.g., [s.boxes for s in doc.sentences]). She can easily pass this to the user interface to enable linking to and highlighting of those passages.\nDefining a Predictor. The pattern Lucy has followed is used in our many Predictor implementations: (1) gain access to text by traversing Layers (e.g., sentences), ( 2) perform all usual NLP computation on that text, and (3) format model output as Entities. This simple pattern allows users to reuse familiar models in existing frameworks and eschews lengthy onboarding to papermage. Lucy wraps her prompting and retrieval code in new classes: APIPredictor and SnippetRetrievalPredictor (see Table 1).\nFast iterations. Leveraging the bounding box data from papermage to visually highlight the retrieved passages, Lucy suspects the retrieval component is likely underperforming. She makes a simple edit from doc.sentences to doc.paragraphs and evaluates system performance under different input granularity. She also realizes the system often retrieves content outside the main body text. She restricts her traversal to filter out paragraphs that overlap with footnotes-[p.text for p in doc.paragraphs if len(p.footnotes) == 0]making clever use of the cross-referencing functionality to detect when a paragraph is actually coming from a footnote. This example demonstrates the versatility of the affordances provided by magelib.", "publication_ref": ["b39"], "figure_ref": [], "table_ref": ["tab_4", "tab_3"]}, {"heading": "Conclusion", "text": "In this work, we've introduced papermage, an open-source Python toolkit for processing scientific documents. papermage was developed to supply high-quality data and reduce friction for research prototype development at Semantic Scholar. Today, it is being used in the production PDF processing pipeline to provide data for both the literature graph (Ammar et al., 2018;Kinney et al., 2023) and the paper-reading interface . It has also been used in working research prototypes which have since contributed to research publications (Fok et al., 2023b;. 6 We open-source papermage in hopes it will simplify research workflows that depend on scientific documents and promote extensions to other visuallyrich documents like textbooks (Lincker et al., 2023) and digitized print media (Lee et al., 2020).", "publication_ref": ["b0", "b29", "b10", "b24"], "figure_ref": [], "table_ref": []}, {"heading": "Ethical Considerations", "text": "As a toolkit primarily designed to process scientific documents, there are two areas where papermage could cause harms or have unintended effects.\nExtraction of bibliographic information papermage could be used to parse author names, affiliation, emails from scientific documents. Like any software, this extraction can be noisy, leading to incorrect parsing and thus mis-attribution of manuscripts. Further, since papermage relies on static PDF documents, rather than metadata dynamically retrieved from publishers, users of papermage need consider how and when extracted names should no longer be associated with authors, a harmful practice called deadnaming (Queer in AI et al., 2023). We recommend papermage users to exercise caution when using our toolkit to extract metadata, to cross-reference extracted content with other sources when possible, and to design systems such that authors have the ability to manually edit any data about themselves.     (Shen et al., 2022). These are per-category metrics for Table 2. Metrics are computed for token-level classification, macro-averaged over categories. The \"Grobid Subset\" limits evaluation to only categories for which Grobid returns bounding box information, which was necessary for evaluation on S2-VL.", "publication_ref": ["b39"], "figure_ref": [], "table_ref": ["tab_4"]}, {"heading": "Acknowledgements", "text": "We thank our teammates at Semantic Scholar for their help on this project. In particular: Rodney Kinney provided insight during discussions about how best to represent data extracted from documents; Paul Sayre provided feedback on initial designs of the library; Chloe Anastasiades, Dany Haddad and Egor Klevak tested earlier versions of the library; Tal August, Raymond Fok, and Andrew Head motivated the need for such a toolkit during their internships building augmented reading interfaces; Jaron Lochner and Kelsey MacMillan helped us get additional engineering support; and Oren Etzioni provided enthusiasm and support for continued investment in this toolkit.\nThis project was supported in part by NSF Grant OIA-2033558 and NSF Grant CNS-2213656.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Author Contributions", "text": "All authors contributed to the implementation of papermage and/or the writing of this paper.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A Appendix", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A.1 Comparison and Compatibility with XML", "text": "One can view Layers as capturing content hierarchy (e.g., tokens vs sentences) similar to that of other structured document representations, like TEI XML trees. We note that Layers are stored as unordered attributes and don't require nesting. This allows for specific cross-layer referencing operations that don't adhere to strict nesting relationships. For example:\n1 for sentence in doc . sentences :\nfor line in sentence . lines :\nRecall that a sentence can begin or end midway through a line and cross multiple lines ( \u00a73.1). Similarly, not all lines are exactly contained within the boundaries of a sentence. As such, sentences and lines are not strictly nested within each other. This relationship would be difficult to encode in an XML format adhering to document tree structure.\nRegardless, the way we represent structure in documents is highly versatile. We demonstrate this by also implementing GrobidParser as an alternative to the PDF2TextParser in \u00a73.1. GrobidParser invokes Grobid to process PDFs, and reads the resulting TEI XML file generated by Grobid by converting each XML tag of a common level into an Entity of its own Layer. We use this to perform the evaluation in Table 2.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A.2 Additional magelib Protocols and Utilities", "text": "Serialization. Any Document and all of its Layers can be exported to a JSON format, and perfectly reconstructed:\n1 import json 2 with open ( \" .... json \" , \"w \") as f_out : Here, we detail how we performed the evaluation reported in \u00a73.3 (Table 2). We also provide a full breakdown by category in Table 3.\nAs described earlier in the paper, Grobid is quite difficult to evaluate as it is developed with tight coupling between the PDF parser (pdfalto) and the models it employs to perform logical structure recovery over the resulting token stream. As such, there is no straightforward way to run just the model components of Grobid on an alternative token stream like that provided in the S2-VL (Shen et al., 2022) dataset.\nTo perform this baseline evaluation, we ran the original PDFs that were annotated for S2-VL through our GrobidParser using v0.7.3. Grobid also returns bounding boxes of some predicted categories (e.g., authors, abstract, paragraphs). We use these bounding boxes to create Entities that we annotate on a Document constructed manually from from S2-VL data. Using magelib cross-layer referencing, we were able to match Grobid predictions to S2-VL data to perform this evaluation.\nThough we found there are certain categories for which bounding box information was either not available (e.g., Titles) or Grobid simply did not return that output (e.g., Figure text extraction). These are represented by zeros in Table 3, which contributes to the lower scores in Table 2 after macro averaging. For a more apples-to-apples comparison, we also included a \"Grobid Subset\" evaluation which restricted to just categories in S2-VL for which Grobid produced bounding box information.\nIn addition to Grobid, we evaluate two of our provided Transformer-based models. The RoBERTalarge (Liu et al., 2019) model is a Transformers token classification model that we finetuned on the S2-VL training set. The I-VILA model is a layoutinfused Transformer model pretrained by Shen et al. (2022) on the S2-VL training set. Like we did with Grobid, we ran our CoreRecipe using these two models on the original PDFs in S2-VL, and performed a similar token mapping operation since our PDF2TextParser also produces a different token stream than that provided in S2-VL.\nAt the end of the day, the Transformer-based models performed better at this task than Grobid. This is unsurprising given expected improvements using a Transformer model over a CRF or BiL-STM. The Transformer models were also trained on S2-VL data, which gave them an advantage over Grobid. Overall, this evaluation intended to show how papermage enables cross-system comparisons, even eschewing token stream incompatibility, and to illustrate an upper bound of the performance left on the table by existing software systems that don't use of state-of-the-art models.", "publication_ref": ["b39", "b28", "b39"], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Construction of the literature graph in semantic scholar", "journal": "Association for Computational Linguistics", "year": "2018", "authors": "Waleed Ammar; Dirk Groeneveld; Chandra Bhagavatula; Iz Beltagy; Miles Crawford; Doug Downey; Jason Dunkelberger; Ahmed Elgohary; Sergey Feldman; Vu Ha; Rodney Kinney; Sebastian Kohlmeier; Kyle Lo; Tyler Murray;  Hsu-Han; Matthew Ooi; Joanna Peters; Sam Power; Lucy Lu Skjonsberg; Chris Wang; Zheng Wilhelm; Madeleine Yuan; Oren Van Zuylen;  Etzioni"}, {"ref_id": "b1", "title": "Paper 501 plain: Making medical research papers approachable to healthcare consumers with natural language processing", "journal": "ACM Trans. Comput.-Hum. Interact", "year": "2023", "authors": "Tal August; Lucy Lu Wang; Jonathan Bragg; Marti A Hearst; Andrew Head; Kyle Lo"}, {"ref_id": "b2", "title": "SciB-ERT: A pretrained language model for scientific text", "journal": "", "year": "2019", "authors": "Iz Beltagy; Kyle Lo; Arman Cohan"}, {"ref_id": "b3", "title": "Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners", "journal": "Curran Associates, Inc", "year": "", "authors": "Tom Brown; Benjamin Mann; Nick Ryder; Melanie Subbiah; Jared D Kaplan; Prafulla Dhariwal; Arvind Neelakantan; Pranav Shyam; Girish Sastry; Amanda Askell; Sandhini Agarwal; Ariel Herbert-Voss; Gretchen Krueger; Tom Henighan; Rewon Child; Aditya Ramesh; Daniel Ziegler; Jeffrey Wu; Clemens Winter; Chris Hesse; Mark Chen; Eric Sigler; Mateusz Litwin"}, {"ref_id": "b4", "title": "Revolt: Collaborative crowdsourcing for labeling machine learning datasets", "journal": "Association for Computing Machinery", "year": "2017", "authors": "Joseph Chee Chang; Saleema Amershi; Ece Kamar"}, {"ref_id": "b5", "title": "Citesee: Augmenting citations in scientific papers with persistent and personalized historical context", "journal": "Association for Computing Machinery", "year": "2023", "authors": "Joseph Chee Chang; Amy X Zhang; Jonathan Bragg; Andrew Head; Kyle Lo; Doug Downey; Daniel S Weld"}, {"ref_id": "b6", "title": "Are layout-infused language models robust to layout distribution shifts? a case study with scientific documents", "journal": "", "year": "2023", "authors": "Catherine Chen; Zejiang Shen; Dan Klein; Gabriel Stanovsky; Doug Downey; Kyle Lo"}, {"ref_id": "b7", "title": "ParsCit: an open-source CRF reference string parsing package", "journal": "", "year": "2008", "authors": "C Lee Isaac Councill; Min-Yen Giles;  Kan"}, {"ref_id": "b8", "title": "A dataset of information-seeking questions and answers anchored in research papers", "journal": "Association for Computational Linguistics", "year": "2021", "authors": "Pradeep Dasigi; Kyle Lo; Iz Beltagy; Arman Cohan; Noah A Smith; Matt Gardner"}, {"ref_id": "b9", "title": "Qlarify: Bridging scholarly abstracts and papers with recursively expandable summaries. arXiv", "journal": "", "year": "2023", "authors": "Raymond Fok; Joseph Chee Chang; Tal August; Amy X Zhang; Daniel S Weld"}, {"ref_id": "b10", "title": "Scim: Intelligent skimming support for scientific papers", "journal": "", "year": "2023", "authors": "Raymond Fok; Hita Kambhamettu; Luca Soldaini; Jonathan Bragg; Kyle Lo; Marti Hearst; Andrew Head; Daniel S Weld"}, {"ref_id": "b11", "title": "", "journal": "", "year": "2008", "authors": " Grobid"}, {"ref_id": "b12", "title": "Domainspecific language model pretraining for biomedical natural language processing", "journal": "ACM Transactions on Computing for Healthcare (HEALTH)", "year": "2020", "authors": "Yu Gu; Robert Tinn; Hao Cheng; Michael R Lucas; Naoto Usuyama; Xiaodong Liu; Tristan Naumann; Jianfeng Gao; Hoifung Poon"}, {"ref_id": "b13", "title": "Augmenting scientific papers with justin-time, position-sensitive definitions of terms and symbols", "journal": "Association for Computing Machinery", "year": "2021", "authors": "Andrew Head; Kyle Lo; Dongyeop Kang; Raymond Fok; Sam Skjonsberg; Daniel S Weld; Marti A Hearst"}, {"ref_id": "b14", "title": "The diminishing returns of masked language models to science", "journal": "Association for Computational Linguistics", "year": "2023", "authors": "Zhi Hong; Aswathy Ajith; James Pauloski; Eamon Duede; Kyle Chard; Ian Foster"}, {"ref_id": "b15", "title": "Lightweight contextual logical structure recovery", "journal": "Association for Computational Linguistics", "year": "2022", "authors": "Po-Wei Huang; Abhinav Ramesh Kashyap; Yanxia Qin; Yajing Yang; Min-Yen Kan"}, {"ref_id": "b16", "title": "Layoutlmv3: Pre-training for document ai with unified text and image masking", "journal": "", "year": "2022", "authors": "Yupan Huang; Tengchao Lv; Lei Cui; Yutong Lu; Furu Wei"}, {"ref_id": "b17", "title": "Unsupervised dense information retrieval with contrastive learning", "journal": "Transactions on Machine Learning Research", "year": "2022", "authors": "Gautier Izacard; Mathilde Caron; Lucas Hosseini; Sebastian Riedel; Piotr Bojanowski; Armand Joulin; Edouard Grave"}, {"ref_id": "b18", "title": "SciREX: A challenge dataset for document-level information extraction", "journal": "", "year": "2020", "authors": "Sarthak Jain; Madeleine Van Zuylen; Hannaneh Hajishirzi; Iz Beltagy"}, {"ref_id": "b19", "title": "Threddy: An interactive system for personalized thread-based exploration and organization of scientific literature", "journal": "Association for Computing Machinery", "year": "2022", "authors": "B Hyeonsu; Joseph Chee Kang; Yongsung Chang; Aniket Kim;  Kittur"}, {"ref_id": "b20", "title": "Synergi: A mixedinitiative system for scholarly synthesis and sensemaking", "journal": "Association for Computing Machinery", "year": "2023", "authors": "B Hyeonsu; Sherry Tongshuang Kang; Joseph Chee Wu; Aniket Chang;  Kittur"}, {"ref_id": "b21", "title": "Papeos: Augmenting research papers with talk videos", "journal": "", "year": "2023", "authors": "Tae Soo Kim; Matt Latzke; Jonathan Bragg; Amy X Zhang; Joseph Chee Chang"}, {"ref_id": "b22", "title": "", "journal": "Madeleine Van Zuylen", "year": "", "authors": "Rodney Kinney; Chloe Anastasiades; Russell Authur; Iz Beltagy; Jonathan Bragg; Alexandra Buraczynski; Isabel Cachola; Stefan Candra; Yoganand Chandrasekhar; Arman Cohan; Miles Crawford; Doug Downey; Jason Dunkelberger; Oren Etzioni; Rob Evans; Sergey Feldman; Joseph Gorney; David Graham; Fangzhou Hu; Regan Huff; Daniel King; Sebastian Kohlmeier; Bailey Kuehl; Michael Langan; Daniel Lin; Haokun Liu; Kyle Lo; Jaron Lochner; Kelsey Macmillan; Tyler Murray; Chris Newell; Smita Rao; Shaurya Rohatgi; Paul Sayre; Zejiang Shen; Amanpreet Singh; Luca Soldaini; Shivashankar Subramanian; Amber Tanaka; Alex D Wade; Linda Wagner; Lucy Lu Wang; Chris Wilhelm; Caroline Wu; Jiangjiang Yang; Angele Zamarron"}, {"ref_id": "b23", "title": "Inquisitive question generation for high level text comprehension", "journal": "Online. Association for Computational Linguistics", "year": "2020", "authors": "Wei-Jen Ko; Te-Yuan Chen; Yiyan Huang; Greg Durrett; Junyi Jessy Li"}, {"ref_id": "b24", "title": "The newspaper navigator dataset: Extracting headlines and visual content from 16 million historic newspaper pages in chronicling america", "journal": "Association for Computing Machinery", "year": "2020", "authors": "Benjamin Charles ; Germain Lee; Jaime Mears; Eileen Jakeway; Meghan Ferriter; Chris Adams; Nathan Yarasavage; Deborah Thomas; Kate Zwaard; Daniel S Weld"}, {"ref_id": "b25", "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining", "journal": "Bioinformatics", "year": "2019", "authors": "Jinhyuk Lee; Wonjin Yoon; Sungdong Kim; Donghyeon Kim; Sunkyu Kim; Chan Ho So; Jaewoo Kang"}, {"ref_id": "b26", "title": "QASA: Advanced question answering on scientific articles", "journal": "PMLR", "year": "2023", "authors": "Yoonjoo Lee; Kyungjae Lee; Sunghyun Park; Dasol Hwang; Jaehyeon Kim"}, {"ref_id": "b27", "title": "Vincent Mousseau, and Caroline Huron. 2023. Layout and activity-based textbook modeling for automatic pdf textbook extraction", "journal": "", "year": "", "authors": "\u00c9lise Lincker; Olivier Pons; Camille Guinaudeau; Isabelle Barbet; J\u00e9r\u00f4me Dupire; C\u00e9line Hudelot"}, {"ref_id": "b28", "title": "", "journal": "RoBERTa: A Robustly Optimized BERT Pretraining Approach. ArXiv", "year": "2019", "authors": "Yinhan Liu; Myle Ott; Naman Goyal; Jingfei Du; Mandar Joshi; Danqi Chen; Omer Levy; Mike Lewis; Luke Zettlemoyer; Veselin Stoyanov"}, {"ref_id": "b29", "title": "The Semantic Reader Project: Augmenting", "journal": "", "year": "2023", "authors": "Kyle Lo; Joseph Chee Chang; Andrew Head; Jonathan Bragg; Amy X Zhang; Cassidy Trier; Chloe Anastasiades; Tal August; Russell Authur; Danielle Bragg; Erin Bransom; Isabel Cachola; Stefan Candra; Yoganand Chandrasekhar; Yen-Sung Chen; Evie Yu-Yen; Yvonne Cheng; Doug Chou; Rob Downey; Raymond Evans; Fangzhou Fok; Regan Hu; Dongyeop Huff; Tae Soo Kang; Rodney Kim; Aniket Kinney; Hyeonsu Kittur; Egor Kang; Bailey Klevak;  Kuehl ; Smita; Paul Rao; Zejiang Sayre; Pao Shen; Luca Siangliulue; Huy Soldaini; Madeleine Tran; Lucy Lu Van Zuylen; Christopher Wang; Caroline Wilhelm; Jiangjiang Wu; Angele Yang; Marti A Zamarron; Daniel S Hearst;  Weld"}, {"ref_id": "b30", "title": "S2ORC: The semantic scholar open research corpus", "journal": "", "year": "2020", "authors": "Kyle Lo; Lucy Lu Wang; Mark Neumann; Rodney Kinney; Daniel Weld"}, {"ref_id": "b31", "title": "Biogpt: Generative pre-trained transformer for biomedical text generation and mining", "journal": "Briefings in bioinformatics", "year": "2022", "authors": "Renqian Luo; Liai Sun; Yingce Xia; Tao Qin; Sheng Zhang; Hoifung Poon; Tie-Yan Liu"}, {"ref_id": "b32", "title": "ScispaCy: Fast and robust models for biomedical natural language processing", "journal": "Association for Computational Linguistics", "year": "2019", "authors": "Mark Neumann; Daniel King; Iz Beltagy; Waleed Ammar"}, {"ref_id": "b33", "title": "A question answering framework for decontextualizing user-facing snippets from scientific documents", "journal": "EMNLP", "year": "2023", "authors": "Benjamin Newman; Luca Soldaini; Raymond Fok; Arman Cohan; Kyle Lo"}, {"ref_id": "b34", "title": "Arjun Subramonian, Ashwin Singh, Claas Voelcker", "journal": "", "year": "", "authors": ""}, {"ref_id": "b35", "title": "Manu Saraswat, Nikhil Vytla, and Luke Stark. 2023. Queer In AI: A Case Study in Community-Led Participatory AI", "journal": "Association for Computing Machinery", "year": "", "authors": "Davide Sutherland; Eva Locatelli; Filip Breznik; Hang Klubicka;  Yuan; J Hetvi; Huan Zhang; Jaidev Shriram; Kruno Lehman; Luca Soldaini; Maarten Sap; Marc Peter Deisenroth; Maria Leonor Pacheco; Maria Ryskina; Martin Mundt; Milind Agarwal; Nyx Mclean; Pan Xu; Raj Pranav; Ruchira Korpan; Sarah Ray; Sarthak Mathew; St Arora; Tanvi John; Vishakha Anand; William Agrawal; Yanan Agnew; Zijie J Long; Zeerak Wang; Avijit Talat; Nathaniel Ghosh; Michael Dennler; Sharvani Noseworthy; Emi Jha; Aditya Baylor; Natalia Y Joshi; Andrew Bilenko; Raphael Mcnamara; Alex Gontijo-Lopes; Evyn Markham; Jackie Dong;  Kay"}, {"ref_id": "b36", "title": "Citeread: Integrating localized citation contexts into scientific paper reading", "journal": "Association for Computing Machinery", "year": "2022", "authors": "Napol Rachatasumrit; Jonathan Bragg; Amy X Zhang; Daniel S Weld"}, {"ref_id": "b37", "title": "Faster r-cnn: Towards real-time object detection with region proposal networks", "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": "2015", "authors": "Kaiming Shaoqing Ren; Ross B He; Jian Girshick;  Sun"}, {"ref_id": "b38", "title": "PySBD: Pragmatic sentence boundary disambiguation", "journal": "Online. Association for Computational Linguistics", "year": "2020", "authors": "Nipun Sadvilkar; Mark Neumann"}, {"ref_id": "b39", "title": "VILA: Improving structured content extraction from scientific PDFs using visual layout groups", "journal": "Transactions of the Association for Computational Linguistics", "year": "2022", "authors": "Zejiang Shen; Kyle Lo; Lucy Lu Wang; Bailey Kuehl; Daniel S Weld; Doug Downey"}, {"ref_id": "b40", "title": "Layoutparser: A unified toolkit for deep learning based document image analysis", "journal": "", "year": "2021", "authors": "Zejiang Shen; Ruochen Zhang; Melissa Dell; B Lee; Jacob Carlson; Weining Li"}, {"ref_id": "b41", "title": "MedICaT: A dataset of medical images, captions, and textual references", "journal": "Online. Association for Computational Linguistics", "year": "2020", "authors": "Sanjay Subramanian; Lucy Lu Wang; Ben Bogin; Sachin Mehta; Madeleine Van Zuylen; Sravanthi Parasa; Sameer Singh; Matt Gardner; Hannaneh Hajishirzi"}, {"ref_id": "b42", "title": "Efficientdet: Scalable and efficient object detection", "journal": "IEEE Computer Society", "year": "2020", "authors": "M Tan; R Pang; Q V Le"}, {"ref_id": "b43", "title": "Andrew Poulton", "journal": "", "year": "", "authors": "Ross Taylor; Marcin Kardas; Guillem Cucurull; Thomas Scialom; Anthony S Hartshorn; Elvis Saravia"}, {"ref_id": "b44", "title": "Cermine: Automatic extraction of structured metadata from scientific literature", "journal": "Int. J. Doc. Anal. Recognit", "year": "2015", "authors": "Dominika Tkaczyk; Pawe\u0142 Szostek; Mateusz Fedoryszak; Piotr Jan Dendek; Lukasz Bolikowski"}, {"ref_id": "b45", "title": "Quantifying the advantage of domain-specific pre-training on named entity recognition tasks in materials science", "journal": "Patterns", "year": "2022", "authors": "Amalie Trewartha; Nicholas Walker; Haoyan Huo; Sanghoon Lee; Kevin Cruse; John Dagdelen; Alex Dunn; Kristin Aslaug Persson; Gerbrand Ceder; Anubhav Jain"}, {"ref_id": "b46", "title": "Improving the accessibility of scientific documents: Current state, user needs, and a system solution to enhance scientific pdf accessibility for blind and low vision users", "journal": "ArXiv", "year": "2021", "authors": "Lucy Lu Wang; Isabel Cachola; Jonathan Bragg; Evie ( Yu-Yen; ) Cheng; Chelsea Hess Haupt; Matt Latzke; Bailey Kuehl; Madeleine Van Zuylen; Linda M Wagner; Daniel S Weld"}, {"ref_id": "b47", "title": "CORD-19: The COVID-19 open research dataset", "journal": "Association for Computational Linguistics", "year": "", "authors": "Lucy Lu Wang; Kyle Lo; Yoganand Chandrasekhar; Russell Reas; Jiangjiang Yang; Doug Burdick; Darrin Eide; Kathryn Funk; Yannis Katsis; Rodney Michael Kinney; Yunyao Li; Ziyang Liu; William Merrill; Paul Mooney; Dewey A Murdick; Devvret Rishi; Jerry Sheehan; Zhihong Shen; Brandon Stilson; Alex D Wade; Kuansan Wang"}, {"ref_id": "b48", "title": "Supporting mouthing in signed languages: New innovations and a proposal for future corpus building", "journal": "", "year": "2022", "authors": "Rosalee Wolfe; John Mcdonald; Ronan Johnson; Ben Sturr; Syd Klinghoffer; Anthony Bonzani; Andrew Alexander; Nicole Barnekow"}, {"ref_id": "b49", "title": "LayoutLMv2: Multi-modal pre-training for visually-rich document understanding", "journal": "Association for Computational Linguistics", "year": "2021", "authors": "Yang Xu; Yiheng Xu; Tengchao Lv; Lei Cui; Furu Wei; Guoxin Wang; Yijuan Lu; Dinei Florencio; Cha Zhang; Wanxiang Che; Min Zhang; Lidong Zhou"}, {"ref_id": "b50", "title": "Layoutlm: Pre-training of text and layout for document image understanding", "journal": "", "year": "2019", "authors": "Yiheng Xu; Minghao Li; Lei Cui; Shaohan Huang; Furu Wei; Ming Zhou"}, {"ref_id": "b51", "title": "Publaynet: largest dataset ever for document layout analysis", "journal": "IEEE", "year": "2019", "authors": "Xu Zhong; Jianbin Tang; Antonio Jimeno Yepes"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 :1Figure 1: papermage's document creation and representation. (A) Recipes are turn-key methods for processing a PDF. (B) They compose models operating across different data modalities and machine learning frameworks to extract document structure, which we conceptualize as layers of annotation that store textual and visual information. (C) Users can access and manipulate layers.", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 2 :2Figure2: Entities are multimodal content units. Here, spans of a sentence are used to identify its text among all symbols, while boxes map its visual coordinates on a page. spans and boxes can include non-contiguous units, allowing great flexibility in Entities to handle layout nuances. A sentence split across columns/pages and interrupted by floating figures/footnotes would require multiple spans and bounding boxes to represent.", "figure_data": ""}, {"figure_label": "13", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 1 .Figure 3 :13Figure 1. Revolt creates labels for unanimously labeled \"certain\" items (e.g., cats and not cats), and surfaces categories of \"uncertain\" items enriched with crowd feedback (e.g., cats and dogs and cartoon cats in the dotted middle region are annotated with crowd explanations). Rich structures allow label requesters to better understand concepts in the data and make post-hoc decisions on label boundaries (e.g., assigning cats and dogs to the cats label and cartoon cats to the not cats label) rather than providing crowd-workers with a priori label guidelines.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "1from papermage import CoreRecipe 2 recipe = CoreRecipe () 3 doc = recipe . run ( \" ... pdf \") 4 doc . captions [0]. text 5 >>> \" Figure 1. ... \"", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "4Vignette: Building an Attributed QA System for Scientific Papers How could researchers leverage papermage for their research? Here, we walk through a user scenario in which a researcher (Lucy) is prototyping an attributed QA system for science. System Design. Drawing inspiration from Ko et al. (2020), Lee et al. (2023), Fok et al. (2023a), and Newman et al. (", "figure_data": ""}, {"figure_label": "5", "figure_type": "table", "figure_id": "tab_0", "figure_caption": ">>> doc . add ( paragraphs , sentences , tokens )    Adding Layers automatically grants users the ability to iterate through Entities and crossreference intersecting Entities across Layers:1 >>> for paragraph in doc . paragraphs :2 for sent in paragraph . sentences : 3 for token in sentence . tokens : 4 ... magelib also supports cross-modality operations. For example, searching for textual Entities within a visual region on the PDF (See Figure 3 F):", "figure_data": ">>> doc.paragraphs[0]>>> doc.paragraphs[0].sentences[2]or>>> doc.sentences[2]>>> doc.sentences[2].tokens[9:13]or>>> doc.tokens[169:173]>>> doc.figures[0]>>> doc.captions[0]>>> user_query = Box(l,t,w,h, page=0)>>> selected_tokens =doc.find(user_query, layer=\"tokens\")>>> [token.text fortoken in selected_tokens]"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_2", "figure_caption": ">>> rasterizer = pm . PDF2ImageRasterizer () 10 >>> doc2 = rasterizer . rasterize (\" ... pdf \") 11 >>> doc . images = doc2 . images 12 >>> doc . images 13 [ Image ( np . array (...)) , ...]", "figure_data": "7 None89"}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "Types of Predictors implemented in papermage.", "figure_data": "ModelPFull RF1Grobid Subset P R F1GrobidCRF 40.6 38.3 39.1 81.2 76.7 78.9 GrobidNN 42.0 36.5 37.6 84.1 73.0 78.2 RoBERTa 75.9 80.0 76.8 82.6 83.9 83.2 I-VILA 92.0 94.1 92.7 92.2 95.2 93.7"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "Evaluating performance of CoreRecipe for logical structure recovery on S2-VL(Shen et al., 2022). >>> import papermage as pm 2 >>> cv = pm . BoxPredictor (...) 3 >>> tables , figures = cv . predict ( doc ) 4 >>> doc . add ( tables , figures ) 5 6 >>> nlp_neu = pm . SpanPredictor (...) 7 >>> titles , authors = nlp_neu . predict ( doc ) 8 >>> doc . add ( titles , authors ) 9 10 >>> nlp_sym = pm . SentencePredictor (...) 11 >>> sentences = nlp_sym . predict ( doc )", "figure_data": "Metrics are computed for token-level classification, macro-averaged over categories. The \"Grobid Subset\" limits evaluation to only categories for which Grobid returns bounding box information, which was necessary for evaluation on S2-VL. See Appendix A.3 for details.development of new ones from scratch. Similarlyto the Transformers library, a Predictor'simplementation is typically independent fromits configuration, allowing users to customizeeach Predictor by tweaking hyperparameters orloading a different set of weights.Below, we showcase how a vision model andtwo text models (both neural and symbolic) can beapplied in succession to a single Document. SeeTable 1 for a summary of supported Predictors."}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "Getting started quickly. As a researcher proficient in Python, it only takes Lucy minutes to install papermage using pip and successfully process a local PDF file by following the example code snippet for CoreRecipe in \u00a73.2. In an interactive session, she familiarizes herself with the provided Layers by following the traversal, cross-referencing and querying examples in \u00a73.1. She makes sure she can serialize and re-instantiate her Document ( \u00a7A.2).", "figure_data": "Formatting input. Before using papermage, Lucy has prior experience building QA pipelines,but has only dealt with documents as sentence-split text data (e.g., <List[str]>). Lucy realizesthat she can reuse her prior text-only code withpapermage by implementing a couple of wrappersto gain additional capabilities: First, she convertsa user's highlighted passage from a visual selec-tion to text following the example in Figure 3F.Next, she converts Document to her required textformat by following the traversal examples in  \u00a73.1(e.g., using [s.text for s in doc.sentences]).Within a few lines of code, Lucy has everythingshe needs for text-only input to her QA pipeline."}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "Core contributors. Kyle Lo and Zejiang Shen initiated the project and co-wrote initial implementations of magelib and some Predictors. Later, Kyle Lo and Luca Soldaini refactored a majority of magelib, Predictors, and added Recipes. Benjamin Newman added new Predictors to support use-cases like those in the Vignette ( \u00a74). Joseph Chee Chang implemented an end-to-end web-based visual interface for papermage and helped iterate on papermage's designs. All core contributors helped with writing. Finally, Kyle Lo led all aspects of the project, including design and implementation, as well as mentorship of other contributors to the toolkit (see below).Other contributors. Russell Authur, Stefan Candra, Yoganand Chandrasekhar, Regan Huff, Amanpreet Singh and Angele Zamarron each worked closely with Kyle Lo to contribute a Predictor to papermage. Erin Bransom and Bailey Kuehl helped with data annotation for training and evaluating those Predictors. Chris Wilhelm provided feedback on papermage's design and implemented faster indexing of Entities when building Layers. Finally, Marti Hearst, Daniel Weld, and Doug Downey helped with writing and overall advising on the project.", "figure_data": "Structure CategoryPGROBID CRF R F1PGROBID NN RF1PRoBERTa RF1PI-VILA RF1Abstract81.9 89.1 85.3 85.3 89.8 87.5 89.2 93.7 91.4 97.4 98.3 97.8Author55.2 42.6 48.1 75.1 14.0 23.6 87.5 73.5 79.9 65.5 96.9 78.2Bibliography96.5 98.6 97.5 95.5 97.6 96.5 93.6 93.3 93.5 99.7 98.2 99.0Caption70.3 70.0 70.2 70.2 69.7 70.0 80.0 77.3 78.6 93.1 89.6 91.3Equation71.1 85.3 77.6 71.1 85.3 77.6 55.0 85.7 67.0 90.7 94.Misrepresentation or fabrication of informa-tion in documents In  \u00a73, we discussed how papermage can be easily extended to support high-level applications. Such applications might includequestion answering chatbots, or AI summarizersthat perform information synthesis over one ormore papermage documents. Such applicationstypically rely on generative models to produce theiroutput, which might fabricate incorrect informa-tion or misstate claims. Developers should be vig-ilant when integrating papermage output into anydownstream application, especially in systems thatpurport to represent information gathered from sci-entific publications."}, {"figure_label": "97", "figure_type": "table", "figure_id": "tab_7", "figure_caption": "", "figure_data": ".3 58.6 73.2 97.9 58.6 73.3 94.7 71.8 81.7 96.1 94.9 95.5Title0.00.00.00.00.00.076.3 96.7 85.3 98.7 99.9 99.3Macro Avg (Full S2-VL)40.6 38.3 39.1 42.0 36.5 37.6 75.9 80.0 76.8 92.0 94.1 92.7Macro Avg (Grobid Subset)81.2 76.7 78.9 84.1 73.0 78.2 82.6 83.9 83.2 92.2 95.2 93.7"}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_8", "figure_caption": "Evaluating CoreRecipe for logical structure recovery on S2-VL", "figure_data": ""}], "formulas": [], "doi": "10.18653/v1/N18-3011"}