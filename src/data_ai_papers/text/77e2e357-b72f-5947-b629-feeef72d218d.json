{"title": "Towards Facilitating Empathic Conversations in Online Mental Health Support: A Reinforcement Learning Approach", "authors": "Ashish Sharma; Inna W Lin; Adam S Miner; David C Atkins; Tim Althoff", "pub_date": "", "abstract": "Online peer-to-peer support platforms enable conversations between millions of people who seek and provide mental health support. If successful, web-based mental health conversations could improve access to treatment and reduce the global disease burden. Psychologists have repeatedly demonstrated that empathy, the ability to understand and feel the emotions and experiences of others, is a key component leading to positive outcomes in supportive conversations. However, recent studies have shown that highly empathic conversations are rare in online mental health platforms. In this paper, we work towards improving empathy in online mental health support conversations. We introduce a new task of empathic rewriting which aims to transform low-empathy conversational posts to higher empathy. Learning such transformations is challenging and requires a deep understanding of empathy while maintaining conversation quality through text fluency and specificity to the conversational context. Here we propose Partner, a deep reinforcement learning (RL) agent that learns to make sentence-level edits to posts in order to increase the expressed level of empathy while maintaining conversation quality. Our RL agent leverages a policy network, based on a transformer language model adapted from GPT-2, which performs the dual task of generating candidate empathic sentences and adding those sentences at appropriate positions. During training, we reward transformations that increase empathy in posts while maintaining text fluency, context specificity, and diversity. Through a combination of automatic and human evaluation, we demonstrate that Partner successfully generates more empathic, specific, and diverse responses and outperforms NLP methods from related tasks such as style transfer and empathic dialogue generation. This work has direct implications for facilitating empathic conversations on web-based platforms.", "sections": [{"heading": "Specific portions", "text": "Figure 1: An overview of the empathic rewriting task. Given a post from support seeker and a low-empathy response, the task is to rewrite the response for making it more empathic, through text insertions and deletions. This task requires inferring specific feelings and experiences from seeker's post and using them for making appropriate changes to the response through empathic mechanisms like emotional reactions, interpretations, and explorations [59]. Examples in this paper have been paraphrased for anonymization [42].", "publication_ref": ["b58", "b41"], "figure_ref": [], "table_ref": []}, {"heading": "INTRODUCTION", "text": "Online mental health support platforms such as TalkLife (talklife.co) are used by millions of users for expressing emotions, sharing stigmatized experiences, and receiving peer support. These platforms might help improve access to mental health support as mental health care remains a global challenge with widespread shortages of workforce [45], limited in-person treatment options, and other barriers like stigma [69]. A key component of providing successful support is empathy, the ability to understand or feel the emotions and experiences of others [17]. Quantitative evidence shows that empathic interactions have strong associations with symptom improvement in mental health support [18] and are instrumental in building therapeutic alliance and rapport [3,54]. Yet, highly empathic conversations are rare on online support platforms [59].\nEmpowering peer supporters on online support platforms with feedback and training, for example through machine-in-the-loop writing systems [9,64], has the potential to help supporters express higher levels of empathy and in turn improve the effectiveness of these platforms [26,44,59]. Traditional methods for training empathy (e.g., in-person counselor training) do not scale to the millions of users of online support platforms. However, computational methods that can support peer-supporters by suggesting ways to modify existing conversation utterances to make them more empathic may arXiv:2101.07714v3 [cs.CL] 16 May 2021 help meet this need of feedback and training and indirectly benefit support seekers on the platform.\nIn this paper, we introduce Empathic Rewriting, a new task that aims to transform low-empathy conversations to higher empathy (Figure 1). For example, given a post from a support seeker \"I can't deal with this part of my bipolar. I need help.\" and a lowempathy response \"Don't worry! Try to relax. Anyone you can talk to?\", we want to increase empathy in the response by transforming it to \"Being Manic is no fun. It's scary! I'm sorry to hear this is troubling you. Try to relax. Anyone you can talk to?\"; the rewritten response should communicate more empathy through an understanding of feelings and experiences (\"Being manic is no fun. It's scary\") and display of felt emotions (\"I'm sorry to hear this is troubling you\").\nPerforming such transformations is a challenging task: First, empathy is a complex, conceptually nuanced construct and requires understanding the feelings and experiences shared by the support seeker. In the example above, one needs to understand that being \"bipolar\" can be \"scary\", involves \"manic\" phases, and communicate this in the response. Second, for empathic rewriting to be purposeful, it should not undermine other conversation goals like language fluency, context specificity, and diversity. Making changes that lead to ungrammatical posts with empathic portions (e.g., \"Scary it is manic being\") may not be helpful and obstruct useful feedback. Further, making the same transformation to every response (e.g., rewrite every response to \"I understand how you feel\") would lead to non-specific and generic responses reducing the overall conversational quality [30,56]. Third, the task of empathic rewriting requires changes that go beyond simple word-level transformations, often requiring multiple new sentences to be added or replaced (e.g., three sentence insertions and one sentence removal in the example in Figure 1). This is different from related style transfer tasks [31,61] where even changing a single word may suffice for transferring from negative to positive sentiment (e.g., replace \"bad\" with \"good\" in the sentence \"the movie was bad\"). Finally, supervised methods commonly used for similar tasks such as style transfer [31,61] and content debiasing [39,51] usually require a large parallel dataset. Such a dataset is not yet available for empathic rewriting and hard to collect as it would require a large number of clinical psychologists and counselors well-versed in the complex construct of empathy.\nTo address the challenges described above, we propose Partner, 1 a deep reinforcement learning (RL) model for the task of empathic rewriting (Section 5). We design an RL agent which learns to add new empathic sentences to posts or replace existing sentences in posts with more empathic ones. The agent operates on a pair of seeker post and the original response post (which rarely is highly empathic [59]) and makes edits to the response at the level of a sentence by simultaneously (a) identifying positions in the original response post where changes are required, and (b) generating empathic sentences for insertion or replacement at the identified positions (Section 5.3). We model this agent using a policy network based on a transformer decoder model adapted from GPT-2 [52]. We build upon existing large-scale pre-training of GPT-2 on conversations, as done in DialoGPT [75], and modify it to perform the two simultaneous actions of identifying positions and generating empathic sentences for empathic rewriting (Section 5.4). Through 1 emPAthic RewriTing in meNtal hEalth suppoRt carefully constructed scoring functions, we reward transformations that increase empathy in posts while maintaining text fluency, context specificity, and diversity (Section 5.5).\nEvaluating complex conversational constructs such as empathy is fundamentally challenging [59]. Therefore, we combine comprehensive automatic evaluation with expert-based human evaluation. Our experiments demonstrate that Partner can effectively increase empathy in posts in fluent, specific, and diverse ways and outperforms baselines used in related text generation tasks by > 35% in empathy improvement (Section 6). Also, Partner is the only approach that consistently improves empathy and does not lead to a loss of empathy when rewriting an already highly empathic post, while all baselines tend to propose a large number of edits that only make the situation worse (Section 6.1). Lastly, through comprehensive human evaluation, we show that experts in clinical psychology prefer rewritings of Partner compared to baselines, based on empathy, specificity, and fluency (Section 6.4). We view our approach and findings as a key step towards building AI systems for facilitating empathic conversations on online mental health support platforms, but these insights may generalize beyond mental health to other conversational settings on web-based platforms. We share our code publicly at https://github.com/behavioral-data/PARTNER.", "publication_ref": ["b44", "b68", "b16", "b17", "b2", "b53", "b58", "b8", "b63", "b25", "b43", "b58", "b29", "b55", "b30", "b60", "b30", "b60", "b38", "b50", "b58", "b51", "b74", "b58"], "figure_ref": [], "table_ref": []}, {"heading": "RELATED WORK", "text": "We build upon prior work on NLP for online mental health support, empathic dialogue generation, reinforcement learning for text rewriting and natural language generation, and AI-assisted writing.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "NLP for online mental health support", "text": "Broadly, our work relates to existing research on NLP for online mental health support. These efforts have predominantly focused on analyzing techniques that are effective for seeking and providing conversational support such as adaptability to various contexts and diversity of responses [1,49,60,72,73]. Researchers have also built methods for identifying therapeutic actions [28], quantifying language development of counselors [74], extracting patterns of conversational engagement [58], analyzing moderation [67], and detecting cognitive restructuring [50] in supportive conversations. Here, we focus on a particular conversation technique, empathy, which is key in counseling and mental health support [7,17]. Our work builds on previous efforts on understanding and building computational methods for identifying empathy in online health communities [27], face-to-face therapy [20,48], and text-based peerto-peer support [59]. We extend this work by learning to improve empathy in online mental health support conversations through a reinforcement learning method for empathic rewriting (Section 5).", "publication_ref": ["b0", "b48", "b59", "b71", "b72", "b27", "b73", "b57", "b66", "b49", "b6", "b16", "b26", "b19", "b47", "b58"], "figure_ref": [], "table_ref": []}, {"heading": "Empathic dialogue generation", "text": "Our task of empathic rewriting is related to empathic dialogue generation but has a key difference as it involves making empathic changes to existing responses instead of generating new responses from scratch. While research on generating empathic dialogue has mainly focused on chit-chat, open-domain conversations [34,41,53], we work on conversations in online mental health support. Moreover, most empathic dialogue generation methods have a tendency of enabling empathic conversations through emotional grounding [53] or emotion mimicking [41]. In mental health support, however, communicating the cognitive aspects of empathy, related to understanding the experiences and feelings of others, are more valued by mental health professionals [57,59,65]. We extend this work with the task of empathic rewriting (Section 4) and by leveraging both emotional and cognitive aspects of empathy, using a theoretically-grounded framework of empathy [59] (Section 5).", "publication_ref": ["b33", "b40", "b52", "b52", "b40", "b56", "b58", "b64", "b58"], "figure_ref": [], "table_ref": []}, {"heading": "Text rewriting and AI-assisted systems", "text": "Text rewriting is a broad subarea in natural language processing that includes tasks such as style transfer [31,61], content debiasing [39,51], and controllable text generation [13,24,40]. We propose empathic rewriting as a new text rewriting task in which conversational utterances are rewritten for increasing them in empathy (Section 4). This task presents unique challenges different from other text rewriting tasks: it requires understanding empathy in conversational contexts and leveraging that understanding for making empathic changes while ensuring high conversational quality in terms of language fluency, context specificity, and diversity.\nHere, we propose a reinforcement learning (RL) model for the task of empathic rewriting (Section 5). Previous work has used RL for the task of sentiment transfer [37] by only using text generations as actions. Here, we design an RL agent that simultaneously learns to (a) identify positions for making improvements and (b) generating empathic sentences for insertion or replacement at the identified positions. These actions are important because the task of empathic rewriting requires changes that go beyond simple wordlevel transformations, as common in sentiment transfer tasks (e.g., change \"bland\" to \"delicious\" in \"the food was bland\" for transferring from negative to positive sentiment).\nPrior work has built systems that leverage identification of effective conversational strategies such as asking open-ended questions for training users in counseling [25]. Computational methods that can perform empathic rewriting can be used for suggesting ways to make conversations more empathic in similar feedback and training systems for mental health support and counseling. In related context, researchers have built AI tools for writing assistance in negotiations [76], composing emails [8], language translation [55], creative writing [9], and communication of politeness [19].", "publication_ref": ["b30", "b60", "b38", "b50", "b12", "b23", "b39", "b36", "b24", "b75", "b7", "b54", "b8", "b18"], "figure_ref": [], "table_ref": []}, {"heading": "DATASET DESCRIPTION", "text": "In this section, we describe the dataset used for the task of empathic rewriting.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "The TalkLife platform", "text": "TalkLife (talklife.co) is the largest online peer-to-peer support platform for mental health support. It enables conversations between people seeking support (support seekers) and people providing support (peer supporters) in a thread-like setting. We call the post authored by a support seeker as seeker post, and the response by a peer supporter as response post. Table 1 describes the statistics of conversational threads on the TalkLife platform.\nCurating mental health-related conversations. As noted by Sharma et al. [59], the TalkLife platform hosts a significant number of common social media interactions (e.g., Happy mother's day).   Here, we focus our analyses on mental health-related conversations and filter out such posts. We manually annotate \u223c3k posts with answers to the question \"Is the seeker talking about a mental health related issue or situation in his/her post?\". Using this annotated dataset, we train a standard text classifier based on BERT [15] (achieving an accuracy of \u223c85%). We apply this classifier to the entire TalkLife dataset and create a filtered dataset of mental healthrelated conversations. This dataset contains 3.33M interactions from 1.48M seeker posts.", "publication_ref": ["b58", "b14"], "figure_ref": [], "table_ref": []}, {"heading": "Dataset Statistics", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Creating a dataset of empathic posts", "text": "Training supervised methods would require a large parallel dataset of corresponding pairs of posts with low and high empathy, respectively. As empathy is a complex phenomenon, collecting such a dataset is challenging and would likely require psychology experts.\nHere, we create a large non-parallel dataset with empathy measurements for training unsupervised and self-supervised computational models and a small parallel dataset with expert empathic rewritings for conducting evaluations.\nComputational labeling with empathy measurements. We computationally label our dataset of 3.33M interactions with empathy measurements using a recently proposed framework of expressed empathy in mental health support [59]. This framework consists of three empathy communication mechanisms -(1) Emotional Reactions (expressing emotions such as warmth, compassion), (2) Interpretations (communicating an understanding of feelings and experiences), and (3) Explorations (improving understanding of the seeker by exploring feelings and experiences). For each communication mechanism, the authors design a three-point scale (0 to 2). We computationally label all pairs of (seeker post, response post) in our dataset based on this empathy scale. For this, we use a classification model (RoBERTa-based, bi-encoder attention with an accuracy of \u223c80%) developed by Sharma et al. [59]. Figure 2 shows the statistics which indicate that high levels of empathy expressions are uncommon in online support platforms, highlighting the need for building systems for improving empathy (e.g., through feedback using empathic rewriting (Section 4)). We use this dataset for a supervised warm-start training in our reinforcement learning model (Section 5.6) and for training unsupervised baselines (Section 6.2).\nExpert empathic rewritings. Additionally, we create a small parallel dataset of 180 pairs of corresponding low and rewritten high empathy response posts with rewritings from people having substantial expertise in empathy, mental health, and therapy (six graduate students in clinical psychology; none are co-authors). We showed them pairs of seeker and response posts and asked them to modify the response post for improving it in empathy. This expertbased dataset is designed to represent the best possible responses and we use it as ground truth for evaluation (Section 6.4).", "publication_ref": ["b58", "b58"], "figure_ref": ["fig_2"], "table_ref": []}, {"heading": "Privacy, ethics, and disclosure", "text": "The dataset was sourced with license and consent from the TalkLife platform. All personally identifiable information (user and platform identifiers) in our dataset was removed. This work was approved by University of Washington's Institutional Review Board. We do not make any treatment recommendations or diagnostic claims.\nTowards preventing unsafe rewritings. We acknowledge that building computational models for intervention in high-stakes settings such as mental health necessitates ethical considerations.\nThere is a risk that in attempting to help, responses could have the opposite effect, which could be deadly in cases of self-harm.\nNo current computational approach will identify and respond to harm-related utterances perfectly [43]. Thus, risk mitigation steps are appropriate in this context. Here, we remove all posts that contain a pre-defined unsafe regular expression (e.g., * commit suicide * ) from our analyses and training in collaboration with mental health professionals. Future work testing or deploying AI systems should assess safety-related risk, and also potential sources of bias (e.g., race, ethnicity, age, or gender bias in training data or models).", "publication_ref": ["b42"], "figure_ref": [], "table_ref": []}, {"heading": "PROBLEM DEFINITION AND GOALS", "text": "In this section, we formulate the task of empathic rewriting and state the associated goals.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Empathic Rewriting", "text": "We introduce empathic rewriting, a new task that aims to transform low-empathy conversational posts to higher empathy. In contrast with empathic dialogue generation [34,41,53], where the objective is to generate empathic posts from scratch, this task requires making changes to existing posts in order to make them empathic. This is more consistent with realistic use-cases in difficult, highstakes settings such as online support systems, which are likely to augment, rather than replace humans [44]. Formally, let S i be a seeker post and R i be a corresponding response post. We aim to transform R i into its more empathic counterpartR i .", "publication_ref": ["b33", "b40", "b52", "b43"], "figure_ref": [], "table_ref": []}, {"heading": "Goals", "text": "For empathic rewriting to be useful in improving mental health support conversations, the rewriting process should achieve specific goals related to empathy, conversation and natural language generation quality, and purposeful and precise feedback:\nTheoretically-grounded empathy. Empathy is complex and conceptually nuanced; over time psychology research has emphasized multiple aspects of empathy [2,4,14,16]. For example, computational research typically defines empathy as reacting with emotions of warmth and compassion [6]. However, psychotherapy research emphasizes aspects of empathy related to communicating cognitive understanding of feelings and experiences of others [57]. For empathic rewriting to be useful and potentially adopted in online mental health support, we need to design methods grounded in psychology and psychotherapy research. Here, we adopt the theoretically-grounded framework of empathy designed by Sharma et al. [59]. We leverage empathy measurements based on this framework as (1) reward signals in our model for empathic rewriting (Section 5.5), and (2) an automatic evaluation metric for judging improvements in empathy from various rewriting models (Section 6.3).\nContext specificity and response diversity. Consider a rewriting approach that transforms every response to a generic but empathic response (e.g., \"That must have been really hard for you\"). While this approach may seem to \"solve\" empathic rewriting, it suffers from two key issues. First, the responses generated by this approach would lack specificity to the emotions and experiences shared in the seeker post, which is important for empathy and effective mental health support [41,54]. Second, performing this same transformation to millions of responses on online platforms would dramatically reduce response diversity which has been shown to be important for mental health support [1] as well as in general dialogue research [30,56].\nThus, the task of empathic rewriting interplays with other issues related to conversation and natural language generation quality and effective mental health support. Ensuring that the rewritten response is specific and diverse, along with empathic is challenging but critical for obtaining purposeful transformations. In this work, we learn rewriting actions that simultaneously achieve the goals of context specificity and response diversity using a reinforcement learning approach (Section 5.5) and we evaluate these goals using a combination of automatic and human evaluation (Section 6.3,6.4).\nText fluency and sentence coherence. In addition, only generating empathic words or phrases may not be sufficient. Without appropriate measures, the rewriting process may lead to an ungrammatical, non-fluent final response (e.g., \"Scary being is it manic\"). Also, making changes that are incoherent with the original response may not be appropriate (e.g., changing \"Sorry to hear that you lost your job. I hope you get a new job soon.\" to \"Sorry to hear that you lost your job. Congrats on your job promotion. I hope you get a new job soon.\"). In this paper, we avoid such responses with non-fluent and incoherent portions through carefully constructed reward functions (Section 5.5) and conduct both automatic and human evaluations of models on text fluency and sentence coherence (Section 6.3,6.4).\nRewriting for feedback and training. An important way in which the task of empathic rewriting can be used is for providing feedback and training to people through machine-in-the-loop writing systems [9,64]. For humans to adopt such feedback, however, the rewriting process should make changes that are precise and specific to the original response. This means that the number of changes should be kept minimal and that the changes themselves should be suitable to the original response. For example, adding Insert at p i = 0\nCandidate sentence (C i,j )\nRewritten response ( ) i,j:j+k )\nMutual information reward ( )\n= * + * + * + *\nPosition to insert/replace (p i ) Figure 3: Partner uses a deep reinforcement learning approach for Empathic Rewriting. It leverages a transformer language model for performing the two actions of (1) selecting positions for insertion or replacement and (2) generating candidate empathic sentences. It uses four reward functions that promote increase in empathy, text fluency, sentence coherence, context specificity, and diversity.\n10 sentences to a one-sentence response may not be useful. Here, we train a reinforcement learning agent which learns when to stop making changes through a special \"stopping\" action (Section 5.3). We evaluate the number of transformations different models need for empathic rewriting through a standard edit-distance based scoring metric (Section 6.3).", "publication_ref": ["b1", "b3", "b13", "b15", "b5", "b56", "b58", "b40", "b53", "b0", "b29", "b55", "b8", "b63"], "figure_ref": [], "table_ref": []}, {"heading": "PARTNER: EMPATHIC REWRITING USING REINFORCEMENT LEARNING", "text": "Here, we present Partner, a reinforcement learning model for the task of empathic rewriting. We first explain the general reinforcement learning framework and its applicability to our setting. We then describe the various components of our model (states, actions, policy, and rewards) and our training strategy.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Reinforcement Learning Framework", "text": "We adopt the standard reinforcement learning framework consisting of a collection of states S, a set of actions A, a policy , and rewards R [63]. In this framework, given a state \u2208 S, an agent takes an action \u2208 A according to the policy :\nS \u00d7 A \u2192 [0, 1].\nThe policy defines whether the agent should take action in a state . The goal of the reinforcement learning agent is to learn a policy which maximizes the reward :\nS \u00d7 A \u2192 R.\nHere, we design a reinforcement learning model for the task of empathic rewriting. Conceptually, our agent leverages context from the seeker post which it uses for making specific empathic changes. Alongside, it operates on the response post, looks for areas where empathy could be improved, and works on those improvements in fluent, coherent, specific, and diverse ways. Moreover, it ensures that the changes are minimal and precise by learning when to stop through a special \"stopping\" action.\nIn our reinforcement learning model, we construct states based on seeker posts and fixed-length contiguous spans in the associated response posts (Section 5.2). Insertion, replacement, and deletion of sentences in response posts are defined as actions (Section 5.3). We learn a policy that uses transformer language models at its core (Section 5.4). We design a reward function that favors empathic, fluent, coherent, specific, and diverse transformations (Section 5.5).", "publication_ref": ["b62"], "figure_ref": [], "table_ref": []}, {"heading": "State: seeker post & fixed-length contiguous spans of response post", "text": "Our agent simultaneously operates on seeker post and fixed-length contiguous spans of response post. The use of seeker post helps us in leveraging conversational context, thereby enabling transformations that are specific to the feelings and experiences shared in the seeker post. The response post is used for making transformations. The use of fixed-length contiguous spans enables a static action set. Formally, let R i contain sentences R i,1 , ..., R i,n . At each step, we focus on a contiguous window of sentences starting from the th sentence R i,j:j+k = R i,j , ..., R i,j+k\u22121 . Then, our state \u2208 S is denoted by the pair (S i , R i,j:j+k ). Our policy uses a string containing S i concatenated with R i,j:j+k separated by a special <SPLIT> token (as commonly used in BERT-like models [15]).", "publication_ref": ["b14"], "figure_ref": [], "table_ref": []}, {"heading": "Actions: sentence-level edits", "text": "Our agent takes actions at the level of a sentence, i.e. it either inserts new sentences or replaces existing sentences with newer ones. A deletion operation is equivalent to replacing a sentence with an empty string. Our agent can make word-level changes by replacing the original sentence with a slightly different sentence containing only word-level edits. We focus on sentence-level edits because the task of empathic rewriting requires changes that go beyond simple word-level edits. Empathic responses typically contain multiple sentences with different goals such as emotional reactions, interpretations, and explorations [59]; generating these sentences and using them for making changes to the response is important for empathic rewriting. In a state (S i , R i,j:j+k ), our agent simultaneously takes two actions -( 1) select a position in R i,j:j+k for insertion or replacement, ( 2 ) generate a candidate empathic sentence. The action space A 1 of 1 consists of 2k+2 actions -k+1 positions for insertions, k positions for replacements, and one special action for no insertion or replacement, which stops the agent from making any further changes. The action space A 2 of 2 consists of all arbitrary-length sentences. We denote the action taken by our agent as = ( 1 , 2 ) \u2208 A 1 \u00d7 A 2 .", "publication_ref": ["b58"], "figure_ref": [], "table_ref": []}, {"heading": "Policy", "text": "At its core, our policy has a transformer language model consisting of a stack of masked multi-head self-attention layers, based on GPT-2 (for a detailed description, see Vaswani et al. [66], Radford et al. [52]). It takes as input an encoded representation of our state (S i , R i,j:j+k ) and generates the action = ( 1 , 2 ).\n( 1) Selecting a position for insertion or replacement. Given (S i , R i,j:j+k ) as input, we want to identify a position p i in R i,j:j+k where changes need to be made for improving empathy through insertion or replacement operations. A sentence window R i,j:j+k has + 1 positions for insertions and positions for replacement. Then, our task is to select one of these 2 +1 positions. We formulate this as a classification problem with 2 + 2 classes. The first 2 + 1 classes represent one of the 2 + 1 potential positions and the last class represents the \"stopping\" action of not selecting any position, thereby stopping the agent from making any changes and keeping the response span unchanged.\nFor selecting this position, we first encode the input string \"S i <SPLIT> R i,j:j+k \" using the transformer block of GPT-2. We then pass this encoded representation through a linear layer to get the predictionp i of the position for insertion or replacement. We denote our position classifier as pos .\n( 2) Generating a candidate sentence. Given (S i , R i,j:j+k ) as input, we want to generate a candidate sentence C i,j to be used for making changes to R i,j:j+k . We frame this task as a language modeling problem where the objective is to generate C i,j that maximizes the conditional probability sent (C i,j |S i , R i,j:j+k ).\nSimilar to the position selection action, we first encode our input string \"S i <SPLIT> R i,j:j+k \" using the transformer block of GPT-2. We then compute a probability distribution over vocabulary tokens by transforming the encoded representation into a vocabulary-sized vector through a softmax layer. Finally, we use top-p sampling [23] 2 over this probability distribution to generate the desired C i,j . The generation is terminated when the sampling process encounters a special end-of-sequence token.", "publication_ref": ["b65", "b51"], "figure_ref": [], "table_ref": []}, {"heading": "Rewards", "text": "Our reward functions aim to increase empathy in posts and maintain text fluency, sentence coherence, context specificity, and diversity: 2 For generating every word in a sequence, top-p sampling (or nucleus sampling) chooses from the smallest set of words whose total probability is more than p.\nChange in empathy. The task of empathic rewriting requires transformations that can increase empathy of posts. Thus, we want to reward actions that increase empathy of R i and penalize actions that decrease empathy of R i . Let (\u2022) be a function that measures empathy of posts. Then, the change in empathy reward, , is defined as:\n= (R i ) \u2212 (R i )(1)\nHere, we estimate (\u2022) using the empathy classification model developed by Sharma et al. [59] for predicting empathy levels of responses. Sharma et al. [59] leverage a theoretically-grounded framework of empathy consisting of three empathy communication mechanisms (emotional reactions, interpretations, and explorations) and devise a scale of empathy levels from 0 to 6. They train a classification model (RoBERTa [36], accuracy \u223c 80%) for predicting empathy of response posts on this scale. We use their trained model as (\u2022) which gives us empathy scores ofR i s in the range of 0 to 6.\nText fluency. We want to prevent actions that lead to outputs that are highly empathic but not fluent or grammatically correct. Therefore, we want to reward actions that lead to fluent outputs and penalize actions resulting in non-fluent outputs. Here, we operationalize text fluency as the inverse of perplexity of the generated R i s. We define the text fluency reward, as:\n= LM R i (1/ )(2)\nwhere LM is a general language model for English and is the number of words inR i . Here, we use GPT-2 [52] as our LM , following previous work [12,39].", "publication_ref": ["b1", "b58", "b58", "b35", "b51", "b11", "b38"], "figure_ref": [], "table_ref": []}, {"heading": "Sentence coherence.", "text": "A key component of our action space is the addition of the candidate sentence to the original response. While the candidate sentence might be highly empathic and fluent, it may not be well-suited for the response R i to which it would be added, leading to incoherent sentences in the transformed responseR i . This may not be handled by perplexity which tends to give high scores to posts where individual sentences are all fluent but are not coherent at the macro response level. Here, we design a reward function, that measures coherence of the candidate sentence C i,j with the response span R i,j:j+k . measures the average sentence coherence probability between a candidate sentence and existing sentences in the response. First, we create a dataset of likely coherent and incoherent sentence pairs. Given two sentences R i,j1 and R i,j2 in a response R i , we call (R i,j1 , R i,j2 ) a potential coherent sentence pair. We randomly sample a sentence R \u2032 which is not a part of responses posted to the current seeker post S i and call ( \u2032 , R i,j ) a potential incoherent sentence pair (\u2200R i,j \u2208 R i ). Next, we train a text classification model, based on BERT [15], on this dataset. We take softmax at the last layer which gives us probabilities of a sentence pair being coherent ( coherent ) or incoherent ( incoherent ). Then, our sentence coherence reward is defined as:\n= = + \u2211\ufe01 = coherent , , R i,l(3)\nMutual information for specificity and diversity. In the pro-cess of empathic rewriting, the final rewritten response may become generic (e.g., \"I understand how you feel\") thereby affecting the overall conversation quality [30,56]. In order to ensure specificity to the seeker post and diversity of responses, we exploit the idea of maximizing mutual information between seeker post and the rewritten response post [30,32]. Our mutual information reward is:\n= MI * log \u2212 \u2192 R i |S i + (1 \u2212 MI ) * log \u2190 \u2212 S i |R i (4)\nwhere \u2212 \u2192 is the transformer language model used in our policy and \u2190 \u2212 is an identical language model for performing the reverse task of generating seeker post from the rewritten response.\nTotal reward. Our total reward is = * + * + * + * .", "publication_ref": ["b14", "b29", "b55", "b29", "b31"], "figure_ref": [], "table_ref": []}, {"heading": "Optimization and training", "text": "Warm-start using supervised learning. We use the pre-trained weights of DialoGPT [75] for initializing our transformer language model. Next, we use a warm-start strategy using supervised learning on a parallel dataset of (low empathy, high empathy) pairs, following previous work in reinforcement learning for dialogue generation [32]. For creating this dataset, we follow the reverse process of making highly empathic responses less empathic by removing sentences that are high in empathy. Similar \"reverseengineering\" strategy has also been shown to work well in other complex linguistic phenomenon like humor [68]. We first identify highly empathic sentences (with scores \u2265 2) in our dataset of empathic interactions (Section 3.2). For a seeker post S i and response post R i having a highly empathy sentence R i,j , we create a dataset with (S i <SPLIT> R i , R i \u2212R i,j ) pairs. 3 We use this dataset to finetune our DialoGPT-initialized transformer language model. REINFORCE with a baseline value for training. We use the standard REINFORCE algorithm [70] for training our agent. Our loss function is defined as:\n( ) = \u2212( \u2212 ) * log pos 1 |S i , R i,j:j+k + log sent 2 |S i , R i,j:j+k (5)\nwhere is our set of parameters and is a baseline estimate of the reward (running average of previous 100 reward values) used for stabilizing training.\nExperimental setup. We use a batch size of 16 and train our model for 20000 steps using a learning rate of 1e-5. We use = 1.0, = 10.0, = 0.1, and = 0.1 (selected using a grid-search approach with three values (0.1, 1.0, 10.0) for each hyperparameter). Moreover, we choose = 2, p = 0.92, and MI = 0.5. We truncate both seeker and response post to 64 tokens each.", "publication_ref": ["b74", "b31", "b67", "b2", "b69"], "figure_ref": [], "table_ref": []}, {"heading": "EXPERIMENTS", "text": "Next, we present experiments for analyzing the performance of Partner on the task of empathic rewriting. We first describe automatic evaluation metrics (Section 6.1) based on the desired goals for empathic rewriting (Section 4.2), baseline approaches and ablations (Section 6.2), and demonstrate results on the automatic evaluation metrics (Section 6.3). Since evaluation using automated metrics in 3 R i \u2212 R i,j refers to the full response post R i with the sentence R i,j removed. language generation tasks are often not robust [35], we additionally present human evaluation results from people having expertise in therapy and mental health (Section 6.4). We end with a qualitative discussion on the model's performance (Section 6.5).", "publication_ref": ["b2", "b34"], "figure_ref": [], "table_ref": []}, {"heading": "Automatic evaluation metrics", "text": "We use a number of automatic metrics that are based on the goals associated with empathic rewriting (Section 4.2):\n\u2022 Change in empathy: A key metric for successful empathic rewriting is how much the empathy has changed from the original response to the rewritten response. Similar to our reward function (Section 5.5), we measure this change using the empathy classification model developed by Sharma et al. [59]. The model computes empathy scores in the range 0 to 6 (leading to change of empathy ranging from -6 to 6). \u2022 Perplexity: Similar to our text fluency reward (Section 5.5), we measure perplexity for quantifying fluency of the rewritten responses. For this, we use a pre-trained GPT-2 language model that has not been fine-tuned on our dataset, following previous work [12,39]. \u2022 Sentence coherence: Since empathic rewriting requires changes at the sentence level, ensuring coherent sentences in the final rewritten response is crucial. Here, we measure sentence coherence using the scoring mechanism developed in Section 5.5. \u2022 Specificity: The rewritten response should be specific to the seeker post. Following Xu et al. [71], we measure specificity using word embedding similarity between seeker post and rewritten response post (using embeddings from BERT [15]). \u2022 Diversity: Since empathic rewriting has implications on millions of conversations on online mental health platforms, ensuring diversity of responses is important. Here, we measure diversity using the distinct-1 and distinct-2 metrics, following Li et al. [30]. The two metrics compute the number of distinct unigrams and bigrams respectively divided by the total number of tokens. \u2022 Edit rate: The changes in empathic rewriting should be minimal and precise. Here, we use edit rate [62] to measure the number of changes between the original response and the rewritten response. Edit rate is defined by the Levenshtein distance between the two responses divided by the length of the original response.", "publication_ref": ["b58", "b11", "b38", "b70", "b14", "b29", "b61"], "figure_ref": [], "table_ref": []}, {"heading": "Baselines and Ablations", "text": "As the task of empathic rewriting has not been explored before, we compare against baseline approaches from the related tasks of dialogue generation and style transfer. Our baselines are:\n\u2022 DialoGPT [75]: A large dialogue generation model, based on GPT-2 [52] and pre-trained on Reddit conversations. \u2022 MIME [41]: An empathic dialogue generation model which exploits emotion mimicking while accounting for emotion polarity (positive or negative). \u2022 Deep latent sequence model [22]: A deep generative model designed for unsupervised style transfer. \u2022 BART [29]: An encoder-decoder model for sequence-tosequence language generation.   DialoGPT and MIME baselines completely disregard the original response; the rewritten response is the response generated given a seeker post by the respective dialogue generation models. Deep latent sequence model and BART perform a sequence-to-sequence generation from a (seeker post, original response post) pair to a response with higher empathy. We use publicly available implementations of all our baselines. We further fine-tune deep latent sequence model on the dataset of empathy-labeled interactions (Section 3.2) and BART on the heuristic-based dataset created for warm-start (Section 5.6).\nAdditionally, we investigate the importance of different components of our model using the following ablated baselines:\n\u2022 Warm-start only, no RL training: We analyze the performance of the model at the end of our warm-start stage, i.e. without any RL training. \u2022 No coherence reward: We train the model without using the sentence coherence reward. \u2022 No mutual information: We train the model without using the mutual information component.", "publication_ref": ["b51", "b40", "b21", "b28"], "figure_ref": [], "table_ref": []}, {"heading": "Automatic metrics results", "text": "Baseline Results. Table 2 reports the results of Partner on the automatic evaluation metrics and comparisons with baselines. We find that empathic rewriting through Partner achieves the largest change in empathy (35% more than the next best approach, MIME) and is more specific than all baselines. MIME generates empathic outputs (+1.21 change in empathy) but the generations have low diversity (86% less than Partner) indicating similar responses for most seeker posts. BART generates outputs with lowest perplexity, highest diversity, and lowest edit rate, which is consistent with substantial improvements to language models in recent years [5]. However, to our surprise, the rewritten responses through BART receive an overall drop of 0.06 in empathy, indicating that the model is unable to perform the task of empathic rewriting well and only generates non-empathic, fluent, diverse text.\nOur specificity metric can be hard to interpret with values having a really small range (0.85 to 0.9). However, with human-based evaluation (Section 6.4), we find that a difference of 0.05 on this metric (between Partner and latent seq.) translates to a 90% preference towards Partner. Moreover, while Partner has the lowest sentence coherence score, we find that this is likely due to higher number of sentences generated by it compared to baselines. The baselines generate 1-2 sentence responses on an average, where achieving high coherence between sentences is expected (e.g., a one-sentence response by design has a coherence of 1.0). Partner, on the contrary, generates responses with \u223c70% more sentences than baselines, affecting the overall coherence score.\nAdaptability of rewritings to original post. Adapting to different types of original responses and making appropriate changes is an important aspect of empathic rewriting. A low empathic response needs a lot more improvements and edits than a highly empathic response. Figure 4a shows the change in empathy of responses given their original empathy levels. We find that Partner performs better than baselines in improving responses with low empathy. Importantly, only Partner succeeds at not deteriorating responses that are already highly empathic, indicating the effectiveness of Partner at adapting to responses with different empathy levels. We also analyze the number of edits by each model on responses with different original empathy levels (Figure 4b). Partner not only effects a greater change in empathy than baselines, it achieves so with the least number of edits for both low and high empathy responses.\nAblation Results. Table 3 ", "publication_ref": ["b4"], "figure_ref": ["fig_4", "fig_4"], "table_ref": ["tab_4"]}, {"heading": "Human evaluation results", "text": "Since automatic evaluation in language generation is often not robust [35], we perform a human evaluation on our key metrics (empathy, fluency, and specificity) through A/B testing. We recruit six graduate students in clinical psychology with expertise in empathy and mental health support 4 and ask them to compare outputs from Partner against other baseline models, ablations, and expert empathic rewritings (Section 3.2) given the same input. Presenting a seeker post, a rewritten response post from Partner, and a rewritten response post from a baseline/ablation/expert-rewrite, we ask them to choose (a) response post which is more empathic, (b) response post which is more fluent, and (c) response post which is more specific. For each model, we collect evaluations on 50-100 examples.\nResults: Baselines and ablations. Figure 5 shows the percentage of instances in which Partner was preferred over other baselines and ablations (values > 50% indicate preference towards Partner). We find that rewritten responses from Partner are preferred for empathic and specific responses over all baselines. DialoGPT is judged more fluent (Figure 4a) but generates responses following similar templates (e.g., \"I'm sorry you.... I hope you....\"). Moreover, Partner has \u223c55% preference for empathy over ablations where coherence and mutual information rewards are not used ( < 0.01).\nResults: Expert rewritings. The most appropriate way of performing empathic rewriting is through human experts. However, experts with training in therapy and mental health support are limited [45] which makes it infeasible to employ them for millions of conversations on online support platforms. We use the small dataset of 180 empathic rewritings from experts to establish what the gold-standard performance for empathic rewritings in mental health support looks like. Unsurprisingly, experts are preferred \u223c80-90% times over Partner in empathy, fluency, and specificity ( < 0.001). However, in 10-20% cases Partner rewritings are preferred; these are typically instances where Partner is able to make empathic changes to responses while the experts leave it unchanged.\nResults: BLEU scores. We also use the dataset of expert empathic rewritings (Section 3.2) as a ground truth of empathic rewritings and compare outputs of Partner, baselines, and ablations based on this ground truth using the BLEU metric [47] (Table 4). We find 4 Most participants were PhD students in second or subsequent years of their degree program. Research in Psychology has shown that clinical psychology graduate students are, in general, representative of mental health professionals [46]. Although there are likely some differences between students and licensed psychologists, clinical outcomes in empathy-related measures such as therapeutic alliance have been shown to be comparable while students receive supervision [21].\n0% 25% 50% 75% 100%   that the outputs from Partner are closest to expert rewritings (86% better than the next best baseline, BART).", "publication_ref": ["b34", "b3", "b44", "b46", "b3", "b45", "b20"], "figure_ref": ["fig_6", "fig_4"], "table_ref": ["tab_5"]}, {"heading": "Qualitative examples", "text": "We present example rewritings from Partner and baselines in Table 5. Partner generates rewritings that leverage both seeker post and original response post for empathic responses. For example, from the seeker post \"I feel like nobody cares about my existence\", Partner is able to infer \"It's hard to find others who can relate\". Also, Partner can coherently transform the response post \"What happened between you two?\" to \"What happened between you two? What caused you to break?\". Table 5: Qualitative examples of empathic rewriting using Partner and baseline methods. Partner generates rewritings that leverage both seeker post and original response post for empathic responses. It infers perspective from seeker posts (\"I feel like nobody cares about my existence\" \u2192 \"It's hard to find others who can relate\") and generates empathic sentences which can be coherently inserted to response posts (\"What happened between you two?\" \u2192 \"What happened between you two? What caused you to break?\")", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "DISCUSSION AND CONCLUSION", "text": "The burden of mental illness globally is overwhelming, and common mental disorders are some of the most debilitating illnesses worldwide [11]. Existing mental health resources and interventions are ill-suited to the size of the need. Online mental health support platforms that make use of peer supporters is one route to scaling up support, but the biggest challenge is to effectively train or scaffold the peer supporters. Our empathic rewriting approach represents a foundational proof-of-concept of how computational methods may help peer supporters online.\nRewriting human-generated responses may be an effective approach to balancing the benefits and risks of using artificial intelligence in mental health settings. By combining human knowledge of context and experience, our approach can both provide feedback to online peer-supporters with actionable, real-time examples, and provide support seekers with more empathic responses. Importantly, this machine-in-the-loop approach can help mitigate some of the risks related to toxicity and safety of AI systems in settings of suicidal ideation, self-harm, or insensitive comments related to race/ethnicity/gender [10,33,38].", "publication_ref": ["b10", "b9", "b32", "b37"], "figure_ref": [], "table_ref": []}, {"heading": "Summary of contributions.", "text": "Our work proposes a new task of empathic rewriting for transforming low-empathy conversational posts in online mental health support platforms to higher empathy. For this task, we develop and train Partner, a reinforcement learning model which makes sentence-level edits to posts for making them empathic. Through extensive experiments based on automatic and human evaluation, we show that Partner can effectively generate more empathic posts and outperforms baseline methods from related tasks.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "ACKNOWLEDGMENTS", "text": "We would like to thank TalkLife and Jamie Druitt for their support and for providing us access to a TalkLife dataset. We also thank the members of UW Behavioral Data Science Group and the anonymous reviewers for their suggestions and feedback. This research has been supported in part by a Microsoft AI for Accessibility grant, the Allen Institute for Artificial Intelligence, NSF grant IIS-1901386 ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "", "text": "Conflict of Interest Disclosure. D.C.A. is a co-founder with equity stake in a technology company, Lyssn.io, focused on tools to support training, supervision, and quality assurance of psychotherapy and counseling.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Large-scale analysis of counseling conversations: An application of natural language processing to mental health", "journal": "TACL", "year": "2016", "authors": "Tim Althoff; Kevin Clark; Jure Leskovec"}, {"ref_id": "b1", "title": "These things called empathy: eight related but distinct phenomena", "journal": "", "year": "2009", "authors": "Daniel Batson"}, {"ref_id": "b2", "title": "Psychotherapy relationships that work: Therapist contributions and responsiveness to patients", "journal": "", "year": "2002", "authors": "C Arthur; Robert Bohart;  Elliott; S Leslie; Jeanne C Greenberg;  Watson"}, {"ref_id": "b3", "title": "Empathy reconsidered: New directions in psychotherapy", "journal": "American Psychological Association", "year": "1997", "authors": "C Arthur; Leslie S Bohart;  Greenberg"}, {"ref_id": "b4", "title": "", "journal": "", "year": "2020", "authors": "Benjamin Tom B Brown; Nick Mann; Melanie Ryder; Jared Subbiah; Prafulla Kaplan; Arvind Dhariwal; Pranav Neelakantan; Girish Shyam;  Sastry"}, {"ref_id": "b5", "title": "Modeling Empathy and Distress in Reaction to News Stories", "journal": "", "year": "2018", "authors": "Sven Buechel; Anneke Buffone; Barry Slaff; Lyle Ungar; Jo\u00e3o Sedoc"}, {"ref_id": "b6", "title": "How and why are some therapists better than others?: Understanding therapist effects", "journal": "American Psychological Association", "year": "2017", "authors": "G Louis; Clara E Castonguay;  Hill"}, {"ref_id": "b7", "title": "Gmail smart compose: Real-time assisted writing", "journal": "", "year": "2019", "authors": "Mia Xu Chen; N Benjamin; Gagan Lee; Yuan Bansal; Shuyuan Cao; Justin Zhang; Jackie Lu; Yinan Tsay;  Wang; M Andrew; Zhifeng Dai;  Chen"}, {"ref_id": "b8", "title": "Creative writing with a machine in the loop: Case studies on slogans and stories", "journal": "", "year": "2018", "authors": "Elizabeth Clark; Anne Spencer Ross; Chenhao Tan; Yangfeng Ji; Noah A Smith"}, {"ref_id": "b9", "title": "Suicide prevention and emergent media: surfing the opportunity", "journal": "", "year": "2012", "authors": "Sunny Collings; Thomas Niederkrotenthaler"}, {"ref_id": "b10", "title": "Grand challenges in global mental health", "journal": "Nature", "year": "2011", "authors": "Y Pamela; Vikram Collins;  Patel; S Sarah; Dana Joestl;  March;  Thomas R Insel; S Abdallah; Isabel A Daar; Jane Bordin; Maureen Costello; Christopher Durkin;  Fairburn"}, {"ref_id": "b11", "title": "Style transformer: Unpaired text style transfer without disentangled latent representation", "journal": "ACL", "year": "2019", "authors": "Ning Dai; Jianze Liang; Xipeng Qiu; Xuanjing Huang"}, {"ref_id": "b12", "title": "Plug and Play Language Models: A Simple Approach to Controlled Text Generation", "journal": "", "year": "2020", "authors": "Sumanth Dathathri; Andrea Madotto; Janice Lan; Jane Hung; Eric Frank; Piero Molino; Jason Yosinski; Rosanne Liu"}, {"ref_id": "b13", "title": "A multidimensional approach to individual differences in empathy", "journal": "Journal of Personality and Social Psychology", "year": "1980", "authors": "H Mark;  Davis"}, {"ref_id": "b14", "title": "Bert: Pre-training of deep bidirectional transformers for language understanding", "journal": "", "year": "2019", "authors": "Jacob Devlin; Ming-Wei Chang; Kenton Lee; Kristina Toutanova"}, {"ref_id": "b15", "title": "The current state of empathy research", "journal": "Journal of counseling psychology", "year": "1996", "authors": "Changming Duan; Clara E Hill"}, {"ref_id": "b16", "title": "", "journal": "Psychotherapy", "year": "2011", "authors": "Robert Elliott; C Arthur; Jeanne C Bohart; Leslie S Watson;  Greenberg"}, {"ref_id": "b17", "title": "Therapist empathy and client outcome: An updated meta-analysis", "journal": "Psychotherapy", "year": "2018", "authors": "Robert Elliott; C Arthur; Jeanne C Bohart; David Watson;  Murphy"}, {"ref_id": "b18", "title": "Facilitating the Communication of Politeness through Fine-Grained Paraphrasing", "journal": "", "year": "2020", "authors": "Liye Fu; Susan R Fussell; Cristian Danescu-Niculescu-Mizil"}, {"ref_id": "b19", "title": "A Deep Learning Approach to Modeling Empathy in Addiction Counseling", "journal": "Interspeech", "year": "2016", "authors": "James Gibson; Do\u011fan Can; Bo Xiao; E Zac;  Imel; C David; Panayiotis Atkins; Shrikanth S Georgiou;  Narayanan"}, {"ref_id": "b20", "title": "Outcomes, skill acquisition, and the alliance: Similarities and differences between clinical trial and student therapists", "journal": "Behaviour research and therapy", "year": "2020", "authors": "Abby D Adler Lizabeth A Goldstein; Robert J Mandel; Daniel R Derubeis;  Strunk"}, {"ref_id": "b21", "title": "A Probabilistic Formulation of Unsupervised Text Style Transfer", "journal": "", "year": "2019", "authors": "Junxian He; Xinyi Wang; Graham Neubig; Taylor Berg-Kirkpatrick"}, {"ref_id": "b22", "title": "The curious case of neural text degeneration", "journal": "", "year": "2020", "authors": "Ari Holtzman; Jan Buys; Li Du; Maxwell Forbes; Yejin Choi"}, {"ref_id": "b23", "title": "Toward controlled generation of text", "journal": "", "year": "2017", "authors": "Zhiting Hu; Zichao Yang; Xiaodan Liang; Ruslan Salakhutdinov; Eric P Xing"}, {"ref_id": "b24", "title": "Challenges in Building Intelligent Open-domain Dialog Systems", "journal": "ACM Transactions on Information Systems", "year": "2020", "authors": "Minlie Huang; Xiaoyan Zhu; Jianfeng Gao"}, {"ref_id": "b25", "title": "Computational psychotherapy research: Scaling up the evaluation of patient-provider interactions", "journal": "Psychotherapy", "year": "2015", "authors": "E Zac; Mark Imel; David C Steyvers;  Atkins"}, {"ref_id": "b26", "title": "Identifying empathetic messages in online health communities", "journal": "", "year": "2017", "authors": "Hamed Khanpour; Cornelia Caragea; Prakhar Biyani"}, {"ref_id": "b27", "title": "Identifying therapist conversational actions across diverse psychotherapeutic approaches", "journal": "", "year": "2019", "authors": "Fei-Tzin Lee; Derrick Hull; Jacob Levine; Bonnie Ray; Kathleen Mckeown"}, {"ref_id": "b28", "title": "Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension", "journal": "", "year": "2019", "authors": "Mike Lewis; Yinhan Liu; Naman Goyal; Marjan Ghazvininejad; Abdelrahman Mohamed; Omer Levy; Ves Stoyanov; Luke Zettlemoyer"}, {"ref_id": "b29", "title": "A Diversity-Promoting Objective Function for Neural Conversation Models", "journal": "", "year": "2016", "authors": "Jiwei Li; Michel Galley; Chris Brockett; Jianfeng Gao; Bill Dolan"}, {"ref_id": "b30", "title": "Delete, Retrieve, Generate: a Simple Approach to Sentiment and Style Transfer", "journal": "", "year": "2018", "authors": "Juncen Li; Robin Jia; He He; Percy Liang"}, {"ref_id": "b31", "title": "Deep Reinforcement Learning for Dialogue Generation", "journal": "", "year": "2016", "authors": "Jiwei Li; Will Monroe; Alan Ritter; Dan Jurafsky; Michel Galley; Jianfeng Gao"}, {"ref_id": "b32", "title": "Developing a delivery science for artificial intelligence in healthcare", "journal": "NPJ Digital Medicine", "year": "2020", "authors": "C Ron;  Li; M Steven;  Asch; H Nigam;  Shah"}, {"ref_id": "b33", "title": "Moel: Mixture of empathetic listeners", "journal": "", "year": "2019", "authors": "Zhaojiang Lin; Andrea Madotto; Jamin Shin; Peng Xu; Pascale Fung"}, {"ref_id": "b34", "title": "How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation", "journal": "", "year": "2016", "authors": "Chia-Wei Liu; Ryan Lowe; Iulian Vlad Serban; Mike Noseworthy; Laurent Charlin; Joelle Pineau"}, {"ref_id": "b35", "title": "Roberta: A robustly optimized bert pretraining approach", "journal": "", "year": "2019", "authors": "Yinhan Liu; Myle Ott; Naman Goyal; Jingfei Du; Mandar Joshi; Danqi Chen; Omer Levy; Mike Lewis; Luke Zettlemoyer; Veselin Stoyanov"}, {"ref_id": "b36", "title": "A dual reinforcement learning framework for unsupervised text style transfer", "journal": "", "year": "2019", "authors": "Fuli Luo; Peng Li; Jie Zhou; Pengcheng Yang; Baobao Chang; Xu Sun; Zhifang Sui"}, {"ref_id": "b37", "title": "Social media and suicide: a public health perspective", "journal": "American journal of public health", "year": "2012", "authors": "Jennifer D David D Luxton; Jonathan M June;  Fairall"}, {"ref_id": "b38", "title": "Power-Transformer: Unsupervised controllable revision for biased language correction", "journal": "EMNLP", "year": "2020", "authors": "Xinyao Ma; Maarten Sap; Hannah Rashkin; Yejin Choi"}, {"ref_id": "b39", "title": "Plug and Play Autoencoders for Conditional Text Generation", "journal": "", "year": "2020", "authors": "Florian Mai; Nikolaos Pappas; Ivan Montero; A Noah; James Smith;  Henderson"}, {"ref_id": "b40", "title": "Rada Mihalcea, and Soujanya Poria. 2020. MIME: MIMicking Emotions for Empathetic Response Generation", "journal": "", "year": "", "authors": "Navonil Majumder; Pengfei Hong; Shanshan Peng; Jiankun Lu; Deepanway Ghosal; Alexander Gelbukh"}, {"ref_id": "b41", "title": "Stories from survivors: Privacy & security practices when coping with intimate partner abuse", "journal": "", "year": "2017", "authors": "Tara Matthews; O' Kathleen; Anna Leary; Manya Turner; Jill Palzkill Sleeper; Martin Woelfer; Cori Shelton; Elizabeth F Manthorne; Sunny Churchill;  Consolvo"}, {"ref_id": "b42", "title": "Assessing the accuracy of automatic speech recognition for psychotherapy", "journal": "NPJ Digital Medicine", "year": "2020", "authors": "S Adam; Albert Miner; Jason A Haque;  Fries; L Scott; Denise E Fleming; Terence Wilfley; Arnold Wilson; Dan Milstein;  Jurafsky; A Bruce;  Arnow;  Stewart Agras"}, {"ref_id": "b43", "title": "Key considerations for incorporating conversational AI in psychotherapy", "journal": "Frontiers in psychiatry", "year": "2019", "authors": "S Adam; Nigam Miner;  Shah; D Kim;  Bullock; A Bruce; Jeremy Arnow; Jeff Bailenson;  Hancock"}, {"ref_id": "b44", "title": "Building the mental health workforce capacity needed to treat adults with serious mental illnesses", "journal": "Health Affairs", "year": "2016", "authors": "Mark Olfson"}, {"ref_id": "b45", "title": "The effects of cognitive behavior therapy delivered by students in a psychologist training program: An effectiveness study", "journal": "Behavior Therapy", "year": "2012", "authors": "Lars-G\u00f6ran \u00d6st; Anna Karlstedt; Sara Wid\u00e9n"}, {"ref_id": "b46", "title": "BLEU: a method for automatic evaluation of machine translation", "journal": "", "year": "2002", "authors": "Kishore Papineni; Salim Roukos; Todd Ward; Wei-Jing Zhu"}, {"ref_id": "b47", "title": "Understanding and predicting empathic behavior in counseling therapy", "journal": "", "year": "2017", "authors": "Ver\u00f3nica P\u00e9rez-Rosas; Rada Mihalcea; Kenneth Resnicow; Satinder Singh; Lawrence An"}, {"ref_id": "b48", "title": "What Makes a Good Counselor? Learning to Distinguish between High-quality and Low-quality Counseling Conversations", "journal": "", "year": "2019", "authors": "Ver\u00f3nica P\u00e9rez-Rosas; Xinyi Wu; Kenneth Resnicow; Rada Mihalcea"}, {"ref_id": "b49", "title": "Moments of Change: Analyzing Peer-Based Cognitive Support in Online Mental Health Forums", "journal": "", "year": "2019", "authors": "Yada Pruksachatkun; Amit Sachin R Pendse;  Sharma"}, {"ref_id": "b50", "title": "Automatically neutralizing subjective bias in text", "journal": "", "year": "2020", "authors": "Reid Pryzant; Richard Diehl Martinez; Nathan Dass; Sadao Kurohashi; Dan Jurafsky; Diyi Yang"}, {"ref_id": "b51", "title": "Language models are unsupervised multitask learners", "journal": "OpenAI Blog", "year": "2019", "authors": "Alec Radford; Jeffrey Wu; Rewon Child; David Luan; Dario Amodei; Ilya Sutskever"}, {"ref_id": "b52", "title": "Towards Empathetic Open-domain Conversation Models: A New Benchmark and Dataset", "journal": "", "year": "2019", "authors": "Eric Michael Hannah Rashkin; Margaret Smith; Y-Lan Li;  Boureau"}, {"ref_id": "b53", "title": "", "journal": "Empathy. Psychotherapy", "year": "2011", "authors": "Elliot Robert; C Arthur; J C Bohart; L S Watson;  Greenberg"}, {"ref_id": "b54", "title": "INMT: Interactive Neural Machine Translation Prediction", "journal": "", "year": "2019", "authors": "Sebastin Santy; Sandipan Dandapat; Monojit Choudhury; Kalika Bali"}, {"ref_id": "b55", "title": "What makes a good conversation? How controllable attributes affect human judgments", "journal": "", "year": "2019", "authors": "Abigail See; Stephen Roller; Douwe Kiela; Jason Weston"}, {"ref_id": "b56", "title": "Growth of interpersonal understanding", "journal": "Academic Press", "year": "1980", "authors": " Robert L Selman"}, {"ref_id": "b57", "title": "Engagement Patterns of Peer-to-Peer Interactions on Mental Health Platforms", "journal": "", "year": "2020", "authors": "Ashish Sharma; Monojit Choudhury; Tim Althoff; Amit Sharma"}, {"ref_id": "b58", "title": "A Computational Approach to Understanding Empathy Expressed in Text-Based Mental Health Support", "journal": "", "year": "2020", "authors": "Ashish Sharma; S Adam;  Miner; C David; Tim Atkins;  Althoff"}, {"ref_id": "b59", "title": "Mental Health Support and its Relationship to Linguistic Accommodation in Online Communities", "journal": "", "year": "2018", "authors": "Eva Sharma; Munmun De Choudhury"}, {"ref_id": "b60", "title": "Style transfer from non-parallel text by cross-alignment", "journal": "", "year": "2017", "authors": "Tianxiao Shen; Tao Lei; Regina Barzilay; Tommi Jaakkola"}, {"ref_id": "b61", "title": "A study of translation edit rate with targeted human annotation", "journal": "", "year": "2006", "authors": "Matthew Snover; Bonnie Dorr; Richard Schwartz; Linnea Micciulla; John Makhoul"}, {"ref_id": "b62", "title": "Reinforcement learning: An introduction", "journal": "MIT press", "year": "2018", "authors": "S Richard; Andrew G Sutton;  Barto"}, {"ref_id": "b63", "title": "Development and Evaluation of ClientBot: Patient-Like Conversational Agent to Train Basic Counseling Skills", "journal": "JMIR", "year": "2019", "authors": "J Michael; Christina S Tanana; Vivek Soma;  Srikumar; C David; Zac E Atkins;  Imel"}, {"ref_id": "b64", "title": "Modern applications in psychology. Toward effective counseling and psychotherapy: Training and practice", "journal": "Aldine Publishing Co", "year": "1967", "authors": "C B Truax;  Carkhuff"}, {"ref_id": "b65", "title": "Attention is all you need", "journal": "", "year": "2017", "authors": "Ashish Vaswani; Noam Shazeer; Niki Parmar; Jakob Uszkoreit; Llion Jones; Aidan N Gomez; \u0141ukasz Kaiser; Illia Polosukhin"}, {"ref_id": "b66", "title": "The Effect of Moderation on Online Mental Health Conversations", "journal": "", "year": "2021", "authors": "David Wadden; Tal August; Qisheng Li; Tim Althoff"}, {"ref_id": "b67", "title": "Reverse-engineering satire, or \"paper on computational humor accepted despite making serious advances", "journal": "", "year": "2019", "authors": "Robert West; Eric Horvitz"}, {"ref_id": "b68", "title": "Receiving social support online: implications for health education", "journal": "Health education research", "year": "2001", "authors": "Marsha White; M Steve;  Dorman"}, {"ref_id": "b69", "title": "Simple statistical gradient-following algorithms for connectionist reinforcement learning", "journal": "Machine learning", "year": "1992", "authors": "J Ronald;  Williams"}, {"ref_id": "b70", "title": "Better conversations by modeling, filtering, and optimizing for coherence and diversity", "journal": "ACL", "year": "2018", "authors": "Xinnuo Xu; Ond\u0159ej Du\u0161ek"}, {"ref_id": "b71", "title": "The Channel Matters: Self-disclosure, Reciprocity and Social Support in Online Cancer Support Groups", "journal": "", "year": "2019", "authors": "Diyi Yang; Zheng Yao; Joseph Seering; Robert Kraut"}, {"ref_id": "b72", "title": "Balancing Objectives in Counseling Conversations: Advancing Forwards or Looking Backwards", "journal": "", "year": "2020", "authors": "Justine Zhang; Cristian Danescu-Niculescu-Mizil"}, {"ref_id": "b73", "title": "Finding Your Voice: The Linguistic Development of Mental Health Counselors", "journal": "", "year": "2019", "authors": "Justine Zhang; Robert Filbin; Christine Morrison; Jaclyn Weiser; Cristian Danescu-Niculescu-Mizil"}, {"ref_id": "b74", "title": "DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation", "journal": "", "year": "2020", "authors": "Yizhe Zhang; Siqi Sun; Michel Galley; Yen-Chun Chen; Chris Brockett; Xiang Gao; Jianfeng Gao; Jingjing Liu; Bill Dolan"}, {"ref_id": "b75", "title": "A Dynamic Strategy Coach for Effective Negotiation", "journal": "", "year": "2019", "authors": "Yiheng Zhou; He He; Alan W Black; Yulia Tsvetkov"}], "figures": [{"figure_label": "", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Ican't deal with this part of my bipolar. I need help. Seeker Don't worry! Try to relax. Anyone you can talk to? Peer Supporter Being manic is no fun. It's scary! I'm sorry to hear this is troubling you. Try to relax. Anyone you can talk to? Empathic Rewriting Text inserted Text removed", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 2 :2Figure 2: Expression of high levels of empathy is very low in online support platforms, especially for Interpretations (IP) and Explorations (EX). Emotional reactions (ER) are slightly more common.Here, we focus our analyses on mental health-related conversations and filter out such posts. We manually annotate \u223c3k posts with answers to the question \"Is the seeker talking about a mental health related issue or situation in his/her post?\". Using this annotated dataset, we train a standard text classifier based on BERT[15] (achieving an accuracy of \u223c85%). We apply this classifier to the entire TalkLife dataset and create a filtered dataset of mental healthrelated conversations. This dataset contains 3.33M interactions from 1.48M seeker posts.", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Table 2 :2Performance of Partner and comparisons with dialogue generation and other sequence-to-sequence generation baselines on the set of automatic metrics. Partner outperforms all baselines in empathy improvement and generates fluent, specific, and diverse outputs with lower edits. (\u2191) indicates higher is better, (\u2193) indicates lower is better. Partner and MIME are effective at increasing empathy in zeroempathy responses. However, Partner is more effective in increasing empathy in low, non-zero empathic responses and doesn't make an already empathic post worse. Partner makes lesser number of changes compared to baselines. The changes are relatively more for less empathic responses which also tend to be shorter.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 4 :4Figure 4: Analysis of empathic rewritings. All error bars in this paper are 95% confidence intervals.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "m -s ta r t", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Figure 5 :5Figure 5: Human evaluation of empathy, fluency, and specificity in rewritings from Partner vs. (a) rewritings from baseline models, and (b) rewritings from ablations. Partner is preferred over baselines and ablations in empathy and specificity and is competitive in fluency.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": ", and Bill & Melinda Gates Foundation (INV-004841). A.S.M. was supported by grants from the National Institutes of Health, National Center for Advancing Translational Science, Clinical and Translational Science Award (KL2TR001083 and UL1TR001085) and the Stanford Human-Centered AI Institute. D.C.A. was supported in part by an NIAAA K award (K02 AA023814).", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "reports results on ablated versions of Partner. Only using warm-start and no RL training is +0.2783 points better than the related off-the-shelf DialoGPT baseline on empathy improvement. However, the RL training in Partner further improves over this warm-start model by +0.8929 points. Using the coherence and mutual information rewards leads to small performance improvements, particularly in empathy (+0.03).", "figure_data": "ModelChange in empathy (\u2191)Perplexity (\u2193) Specificity (\u2191)Diversity (\u2191) distinct-1 distinct-2Sentence coherence (\u2191)Edit rate (\u2193)Partner1.64107.36410.90520.06590.38070.30300.9654-no coherence1.61277.28060.90550.06630.38440.30051.0108-no mutual info.1.61327.32740.90450.06740.38590.30781.0071-warm-start only0.74817.18580.90270.08160.42380.29351.0327"}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "Ablation results. Warm-start improves over DialoGPT but is still much worse than Partner in empathy improvement, highlighting the effectiveness of our RL-based training.", "figure_data": ""}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "BLEU scores of all models against empathic rewritings from experts. The rewritings from Partner are closest to expert rewritings.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "PartnerIt's hard to find others who can relate. I feel the same.", "figure_data": "Seeker postResponse postModelRewritten response postI feel like nobody cares about my existence.I feel the same.DialoGPT MIMEI care. That is awful, i am sorry to hear that. I hope you feel better.Latent Seq.I'm sorry to hear that.BARTI think i feel the same way. I do.PartnerIt's hard when you're with such people and theyI overthink everything my friends say. I disregard them when they praise me but if they say somethingI understand completely. I feel the same way.DialoGPTare being like that to you. I understand com-pletely. I feel the same way. I'm the same way. I'm not sure why, but I just don't like being told I'm being paranoid.negative I take it so person-ally. I'm sick of being so paranoid.MIME Latent Seq.That is a shame, i am sure it will not be a bit of a bit! I know that, i feel the same way i'm sorry to.BARTI'm sorry, I understand completely. I feel thesame way. I'm here for you.PartnerThat's awful. What happened between you two?What caused you to break?I hope I didn't lose my only two best friends. They are the only ones I could relate to.What happened between you two?DialoGPT MIMEI hope you didn't lose them. I don't want to lose them. That is a good thing to do.Latent Seq.I'm sorry to hear that.BARTWhat happened? What happened between youtwo?"}], "formulas": [{"formula_id": "formula_0", "formula_text": "= * + * + * + *", "formula_coordinates": [5.0, 165.41, 205.28, 60.27, 17.05]}, {"formula_id": "formula_1", "formula_text": "S \u00d7 A \u2192 [0, 1].", "formula_coordinates": [5.0, 234.86, 558.54, 60.56, 8.08]}, {"formula_id": "formula_2", "formula_text": "S \u00d7 A \u2192 R.", "formula_coordinates": [5.0, 172.71, 591.42, 47.47, 7.7]}, {"formula_id": "formula_3", "formula_text": "= (R i ) \u2212 (R i )(1)", "formula_coordinates": [6.0, 410.23, 157.99, 147.98, 9.6]}, {"formula_id": "formula_4", "formula_text": "= LM R i (1/ )(2)", "formula_coordinates": [6.0, 412.19, 348.68, 146.02, 16.17]}, {"formula_id": "formula_5", "formula_text": "= = + \u2211\ufe01 = coherent , , R i,l(3)", "formula_coordinates": [6.0, 393.08, 654.12, 165.12, 36.56]}, {"formula_id": "formula_6", "formula_text": "= MI * log \u2212 \u2192 R i |S i + (1 \u2212 MI ) * log \u2190 \u2212 S i |R i (4)", "formula_coordinates": [7.0, 88.65, 156.11, 205.4, 14.11]}, {"formula_id": "formula_7", "formula_text": "( ) = \u2212( \u2212 ) * log pos 1 |S i , R i,j:j+k + log sent 2 |S i , R i,j:j+k (5)", "formula_coordinates": [7.0, 100.41, 471.56, 193.64, 24.36]}], "doi": "10.1145/3442381.3450097"}