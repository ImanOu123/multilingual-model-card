{"title": "Delayed Impact of Fair Machine Learning", "authors": "Lydia T Liu; Sarah Dean; Esther Rolf; Max Simchowitz; Moritz Hardt", "pub_date": "2018-04-10", "abstract": "Fairness in machine learning has predominantly been studied in static classification settings without concern for how decisions change the underlying population over time. Conventional wisdom suggests that fairness criteria promote the long-term well-being of those groups they aim to protect. We study how static fairness criteria interact with temporal indicators of well-being, such as long-term improvement, stagnation, and decline in a variable of interest. We demonstrate that even in a one-step feedback model, common fairness criteria in general do not promote improvement over time, and may in fact cause harm in cases where an unconstrained objective would not. We completely characterize the delayed impact of three standard criteria, contrasting the regimes in which these exhibit qualitatively different behavior. In addition, we find that a natural form of measurement error broadens the regime in which fairness criteria perform favorably. Our results highlight the importance of measurement and temporal modeling in the evaluation of fairness criteria, suggesting a range of new challenges and trade-offs.", "sections": [{"heading": "Introduction", "text": "Machine learning commonly considers static objectives defined on a snapshot of the population at one instant in time; consequential decisions, in contrast, reshape the population over time. Lending practices, for example, can shift the distribution of debt and wealth in the population. Job advertisements allocate opportunity. School admissions shape the level of education in a community.\nExisting scholarship on fairness in automated decision-making criticizes unconstrained machine learning for its potential to harm historically underrepresented or disadvantaged groups in the population [Executive Office of the President, 2016, Barocas and Selbst, 2016]. Consequently, a variety of fairness criteria have been proposed as constraints on standard learning objectives. Even though, in each case, these constraints are clearly intended to protect the disadvantaged group by an appeal to intuition, a rigorous argument to that effect is often lacking.\nIn this work, we formally examine under what circumstances fairness criteria do indeed promote the long-term well-being of disadvantaged groups measured in terms of a temporal variable of interest. Going beyond the standard classification setting, we introduce a one-step feedback model of decision-making that exposes how decisions change the underlying population over time.\nOur running example is a hypothetical lending scenario. There are two groups in the population with features described by a summary statistic, such as a credit score, whose distribution differs between the two groups. The bank can choose thresholds for each group at which loans are offered. While group-dependent thresholds may face legal challenges [Ross and Yinger, 2006], they are generally inevitable for some of the criteria we examine. The impact of a lending decision has multiple facets. A default event not only diminishes profit for the bank, it also worsens the financial situation of the borrower as reflected in a subsequent decline in credit score. A successful lending outcome leads to profit for the bank and also to an increase in credit score for the borrower.\nWhen thinking of one of the two groups as disadvantaged, it makes sense to ask what lending policies (choices of thresholds) lead to an expected improvement in the score distribution within that group. An unconstrained bank would maximize profit, choosing thresholds that meet a breakeven point above which it is profitable to give out loans. One frequently proposed fairness criterion, sometimes called demographic parity, requires the bank to lend to both groups at an equal rate. Subject to this requirement the bank would continue to maximize profit to the extent possible. Another criterion, originally called equality of opportunity, equalizes the true positive rates between the two groups, thus requiring the bank to lend in both groups at an equal rate among individuals who repay their loan. Other criteria are natural, but for clarity we restrict our attention to these three.\nDo these fairness criteria benefit the disadvantaged group? When do they show a clear advantage over unconstrained classification? Under what circumstances does profit maximization work in the interest of the individual? These are important questions that we begin to address in this work.", "publication_ref": ["b0"], "figure_ref": [], "table_ref": []}, {"heading": "Contributions", "text": "We introduce a one-step feedback model that allows us to quantify the long-term impact of classification on different groups in the population. We represent each of the two groups A and B by a score distribution \u03c0 A and \u03c0 B , respectively. The support of these distributions is a finite set X corresponding to the possible values that the score can assume. We think of the score as highlighting one variable of interest in a specific domain such that higher score values correspond to a higher probability of a positive outcome. An institution chooses selection policies \u03c4 A , \u03c4 B : X \u2192 [0, 1] that assign to each value in X a number representing the rate of selection for that value. In our example, these policies specify the lending rate at a given credit score within a given group. The institution will always maximize their utility (defined formally later) subject to either (a) no constraint, or (b) equality of selection rates, or (c) equality of true positive rates.\nWe assume the availability of a function \u2206 : X \u2192 R such that \u2206(x) provides the expected change in score for a selected individual at score x. The central quantity we study is the expected difference in the mean score in group j \u2208 {A, B} that results from an institutions policy, \u2206\u00b5 j defined formally in Equation (2). When modeling the problem, the expected mean difference can also absorb external factors such as \"reversion to the mean\" so long as they are mean-preserving. Qualitatively, we distinguish between long-term improvement (\u2206\u00b5 j > 0), stagnation (\u2206\u00b5 j = 0), and decline (\u2206\u00b5 j < 0). Our findings can be summarized as follows:\n1. Both fairness criteria (equal selection rates, equal true positive rates) can lead to all possible outcomes (improvement, stagnation, and decline) in natural parameter regimes. We provide a complete characterization of when each criterion leads to each outcome in Section 3.\n\u2022 There are a class of settings where equal selection rates cause decline, whereas equal true positive rates do not (Corollary 3.5), \u2022 Under a mild assumption, the institution's optimal unconstrained selection policy can never lead to decline (Proposition 3.1).\n2. We introduce the notion of an outcome curve (Figure 1) which succinctly describes the different regimes in which one criterion is preferable over the others.\n3. We perform experiments on FICO credit score data from 2003 and show that under various models of bank utility and score change, the outcomes of applying fairness criteria are in line with our theoretical predictions. 4. We discuss how certain types of measurement error (e.g., the bank underestimating the repayment ability of the disadvantaged group) affect our comparison. We find that measurement error narrows the regime in which fairness criteria cause decline, suggesting that measurement should be a factor when motivating these criteria.\n5. We consider alternatives to hard fairness constraints.\n\u2022 We evaluate the optimization problem where fairness criterion is a regularization term in the objective. Qualitatively, this leads to the same findings. \u2022 We discuss the possibility of optimizing for group score improvement \u2206\u00b5 j directly subject to institution utility constraints. The resulting solution provides an interesting possible alternative to existing fairness criteria.\nWe focus on the impact of a selection policy over a single epoch. The motivation is that the designer of a system usually has an understanding of the time horizon after which the system is evaluated and possibly redesigned. Formally, nothing prevents us from repeatedly applying our model and tracing changes over multiple epochs. In reality, however, it is plausible that over greater time periods, economic background variables might dominate the effect of selection.\nReflecting on our findings, we argue that careful temporal modeling is necessary in order to accurately evaluate the impact of different fairness criteria on the population. Moreover, an understanding of measurement error is important in assessing the advantages of fairness criteria relative to unconstrained selection. Finally, the nuances of our characterization underline how intuition may be a poor guide in judging the long-term impact of fairness constraints.", "publication_ref": [], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Related work", "text": "Recent work by Hu and Chen [2018] considers a model for long-term outcomes and fairness in the labor market. They propose imposing the demographic parity constraint in a temporary labor market in order to provably achieve an equitable long-term equilibrium in the permanent labor market, reminiscent of economic arguments for affirmative action [Foster and Vohra, 1992]. The equilibrium analysis of the labor market dynamics model allows for specific conclusions relating fairness criteria to long term outcomes. Our general framework is complementary to this type of domain specific approach. Fuster et al. [2017] consider the problem of fairness in credit markets from a different perspective. Their goal is to study the effect of machine learning on interest rates in different groups at an equilibrium, under a static model without feedback. Ensign et al. [2017] consider feedback loops in predictive policing, where the police more heavily monitor high crime neighborhoods, thus further increasing the measured number of crimes in those neighborhoods. While the work addresses an important temporal phenomenon using the theory of urns, it is rather different from our one-step feedback model both conceptually and technically.\nDemographic parity and its related formulations have been considered in numerous papers [e.g. Calders et al., 2009, Zafar et al., 2017. Hardt et al. [2016] introduced the equality of opportunity constraint that we consider and demonstrated limitations of a broad class of criteria. Kleinberg et al. [2017] and Chouldechova [2016] point out the tension between \"calibration by group\" and equal true/false positive rates. These trade-offs carry over to some extent to the case where we only equalize true positive rates [Pleiss et al., 2017].\nA growing literature on fairness in the \"bandits\" setting of learning [see Joseph et al., 2016, et sequelae] deals with online decision making that ought not to be confused with our one-step feedback setting. Finally, there has been much work in the social sciences on analyzing the effect of affirmative action [see e.g., Keith et al., 1985, Kalev et al., 2006.", "publication_ref": ["b8", "b5", "b6", "b3", "b1", "b7", "b13", "b2", "b9", "b11", "b10"], "figure_ref": [], "table_ref": []}, {"heading": "Discussion", "text": "In this paper, we advocate for a view toward long-term outcomes in the discussion of \"fair\" machine learning. We argue that without a careful model of delayed outcomes, we cannot foresee the impact a fairness criterion would have if enforced as a constraint on a classification system. However, if such an accurate outcome model is available, we show that there are more direct ways to optimize for positive outcomes than via existing fairness criteria. We outline such an outcome-based solution in Section 4.3. Specifically, in the credit setting, the outcome-based solution corresponds to giving out more loans to the protected group in a way that reduces profit for the bank compared to unconstrained profit maximization, but avoids loaning to those who are unlikely to benefit, resulting in a maximally improved group average credit score. The extent to which such a solution could form the basis of successful regulation depends on the accuracy of the available outcome model. This raises the question if our model of outcomes is rich enough to faithfully capture realistic phenomena. By focusing on the impact that selection has on individuals at a given score, we model the effects for those not selected as zero-mean. For example, not getting a loan in our model has no negative effect on the credit score of an individual. 1 This does not mean that wrongful rejection (i.e., a false negative) has no visible manifestation in our model. If a classifier has a higher false negative rate in one group than in another, we expect the classifier to increase the disparity between the two groups (under natural assumptions). In other words, in our outcomebased model, the harm of denied opportunity manifests as growing disparity between the groups. The cost of a false negative could also be incorporated directly into the outcome-based model by a simple modification (see Footnote 2). This may be fitting in some applications where the immediate impact of a false negative to the individual is not zero-mean, but significantly reduces their future success probability.\nIn essence, the formalism we propose requires us to understand the two-variable causal mechanism that translates decisions to outcomes. This can be seen as relaxing the requirements compared with recent work on avoiding discrimination through causal reasoning that often required stronger assumptions [Kusner et al., 2017, Nabi and Shpitser, 2017, Kilbertus et al., 2017. In particular, these works required knowledge of how sensitive attributes (such as gender, race, or proxies thereof) causally relate to various other variables in the data. Our model avoids the delicate modeling step involving the sensitive attribute, and instead focuses on an arguably more tangible economic mechanism. Nonetheless, depending on the application, such an understanding might necessitate greater domain knowledge and additional research into the specifics of the application. This is consistent with much scholarship that points to the context-sensitive nature of fairness in machine learning.", "publication_ref": ["b14", "b15", "b12"], "figure_ref": [], "table_ref": []}, {"heading": "Problem Setting", "text": "We consider two groups A and B, which comprise a g A and g B = 1 \u2212 g A fraction of the total population, and an institution which makes a binary decision for each individual in each group, called selection. Individuals in each group are assigned scores in X := [C], and the scores for group j \u2208 {A, B} are distributed according \u03c0 j \u2208 Simplex C\u22121 . The institution selects a policy \u03c4 := (\u03c4 A , \u03c4 B ) \u2208 [0, 1] 2C , where \u03c4 j (x) corresponds to the probability the institution selects an individual in group j with score x. One should think of a score as an abstract quantity which summarizes how well an individual is suited to being selected; examples are provided at the end of this section.\nWe assume that the institution is utility-maximizing, but may impose certain constraints to ensure that the policy \u03c4 is fair, in a sense described in Section 2.2. We assume that there exists a function u : C \u2192 R, such that the institution's expected utility for a policy \u03c4 is given by\nU(\u03c4 ) = j\u2208{A,B} g j x\u2208X \u03c4 j (x)\u03c0 j (x)u(x).\n(1)\nNovel to this work, we focus on the effect of the selection policy \u03c4 on the groups A and B. We quantify these outcomes in terms of an average effect that a policy \u03c4 j has on group j. Formally, for a function \u2206(x) : X \u2192 R, we define the average change of the mean score \u00b5 j for group j \u2206\u00b5 j (\u03c4 ) := x\u2208X \u03c0 j (x)\u03c4 j (x)\u2206(x) .\n(2)\nWe remark that many of our results also go through if \u2206\u00b5 j (\u03c4 ) simply refers to an abstract change in well-being, not necessarily a change in the mean score. Furthermore, it is possible to modify the definition of \u2206\u00b5 j (\u03c4 ) such that it directly considers outcomes of those who are not selected. 2 Lastly, we assume that the success of an individual is independent of their group given the score; that is, the score summarizes all relevant information about the success event, so there exists a function \u03c1 : X \u2192 [0, 1] such that individuals of score x succeed with probability \u03c1(x). We now introduce the specific domain of credit scores as a running example in the rest of the paper, after which we present two more examples showing the general applicability of our formulation to many domains.\nExample 2.1 (Credit scores). In the setting of loans, scores x \u2208 [C] represent credit scores, and the bank serves as the institution. The bank chooses to grant or refuse loans to individuals according to a policy \u03c4 . Both bank and personal utilities are given as functions of loan repayment, and 2 If we consider functions \u2206p(x) : X \u2192 R and \u2206n(x) : X \u2192 R to represent the average effect of selection and non-selection respectively, then \u2206\u00b5 j (\u03c4 ) :=\nx\u2208X \u03c0 j (x) (\u03c4 j (x)\u2206p(x) + (1 \u2212 \u03c4 j (x))\u2206n(x)). This model corresponds to replacing \u2206(x) in the original outcome definition with \u2206p(x) \u2212 \u2206n(x), and adding a offset x\u2208X \u03c0 j (x)\u2206n(x). Under the assumption that \u2206p(x) \u2212 \u2206n(x) increases in x, this model gives rise to outcomes curves resembling those in Figure 1 up to vertical translation. All presented results hold unchanged under the further assumption that \u2206\u00b5(\u03b2 MaxUtil ) \u2265 0.\ntherefore depend on the success probabilities \u03c1(x), representing the probability that any individual with credit score x can repay a loan within a fixed time frame. The expected utility to the bank is given by the expected return from a loan, which can be modeled as an affine function of \u03c1(x): u(x) = u + \u03c1(x) + u \u2212 (1 \u2212 \u03c1(x)), where u + denotes the profit when loans are repaid and u \u2212 the loss when they are defaulted on. Individual outcomes of being granted a loan are based on whether or not an individual repays the loan, and a simple model for \u2206(x) may also be affine in \u03c1(x):\n\u2206(x) = c + \u03c1(x) + c \u2212 (1 \u2212 \u03c1(x))\n, modified accordingly at boundary states. The constant c + denotes the gain in credit score if loans are repaid and c \u2212 is the score penalty in case of default.\nExample 2.2 (Advertising). A second illustrative example is given by the case of advertising agencies making decisions about which groups to target. An individual with product interest score x responds positively to an ad with probability \u03c1(x). The ad agency experiences utility u(x) related to click-through rates, which increases with \u03c1(x). Individuals who see the ad but are uninterested may react negatively (becoming less interested in the product), and \u2206(x) encodes the interest change. If the product is a positive good like education or employment opportunities, interest can correspond to well-being. Thus the advertising agency's incentives to only show ads to individuals with extremely high interest may leave behind groups whose interest is lower on average. A related historical example occurred in advertisements for computers in the 1980s, where male consumers were targeted over female consumers, arguably contributing to the current gender gap in computing.\nExample 2.3 (College Admissions). The scenario of college admissions or scholarship allotments can also be considered within our framework. Colleges may select certain applicants for acceptance according to a score x, which could be thought encode a \"college preparedness\" measure. The students who are admitted might \"succeed\" (this could be interpreted as graduating, graduating with honors, finding a job placement, etc.) with some probability \u03c1(x) depending on their preparedness. The college might experience a utility u(x) corresponding to alumni donations, or positive rating when a student succeeds; they might also show a drop in rating or a loss of invested scholarship money when a student is unsuccessful. The student's success in college will affect their later success, which could be modeled generally by \u2206(x). In this scenario, it is challenging to ensure that a single summary statistic x captures enough information about a student; it may be more appropriate to consider x as a vector as well as more complex forms of \u03c1(x).\nWhile a variety of applications are modeled faithfully within our framework, there are limitations to the accuracy with which real-life phenomenon can be measured by strictly binary decisions and success probabilities. Such binary rules are necessary for the definition and execution of existing fairness criteria, (see Sec. 2.2) and as we will see, even modeling these facets of decision making as binary allows for complex and interesting behavior.", "publication_ref": [], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "The Outcome Curve", "text": "We now introduce important outcome regimes, stated in terms of the change in average group score. A policy (\u03c4 A , \u03c4 B ) is said to cause active harm to group j if \u2206\u00b5 j (\u03c4 j ) < 0, stagnation if \u2206\u00b5 j (\u03c4 j ) = 0, and improvement if \u2206\u00b5 j (\u03c4 j ) > 0. Under our model, MaxUtil policies can be chosen in a standard fashion which applies the same threshold \u03c4 MaxUtil for both groups, and is agnostic to the distributions \u03c0 A and \u03c0 B . Hence, if we define \u2206\u00b5 MaxUtil we say that a policy causes relative harm to group j if \u2206\u00b5 j (\u03c4 j ) < \u2206\u00b5 MaxUtil j , and relative improvement if \u2206\u00b5 j (\u03c4 j ) > \u2206\u00b5 MaxUtil j . In particular, we focus on these outcomes for a disadvantaged group, and consider whether imposing a fairness constraint improves their outcomes relative to the MaxUtil strategy. From this point forward, we take A to be disadvantaged or protected group.\nFigure 1 displays the important outcome regimes in terms of selection rates \u03b2 j := x\u2208X \u03c0 j (x)\u03c4 j (x). This succinct characterization is possible when considering decision rules based on (possibly randomized) score thresholding, in which all individuals with scores above a threshold are selected. In Section 5, we justify the restriction to such threshold policies by showing it preserves optimality. In Section 5.1, we show that the outcome curve is concave, thus implying that it takes the shape depicted in Figure 1. To explicitly connect selection rates to decision policies, we define the rate function r \u03c0 (\u03c4 j ) which returns the proportion of group j selected by the policy. We show that this function is invertible for a suitable class of threshold policies, and in fact the outcome curve is precisely the graph of the map from selection rate to outcome \u03b2 \u2192 \u2206\u00b5 A (r \u22121 \u03c0 A (\u03b2)). Next, we define the values of \u03b2 that mark boundaries of the outcome regions. Definition 2.1 (Selection rates of interest). Given the protected group A, the following selection rates are of interest in distinguishing between qualitatively different classes of outcomes (Figure 1). We define \u03b2 MaxUtil as the selection rate for A under MaxUtil; \u03b2 0 as the harm threshold, such that \u2206\u00b5 A (r \u22121 \u03c0 A (\u03b2 0 )) = 0; \u03b2 * as the selection rate such that \u2206\u00b5 A is maximized; \u03b2 as the outcomecomplement of the MaxUtil selection rate, \u2206\u00b5 A r \u22121\n\u03c0 A (\u03b2)) = \u2206\u00b5 A (r \u22121 \u03c0 A (\u03b2 MaxUtil )) with \u03b2 > \u03b2 MaxUtil .", "publication_ref": [], "figure_ref": ["fig_0", "fig_0", "fig_0"], "table_ref": []}, {"heading": "Decision Rules and Fairness Criteria", "text": "We will consider policies that maximize the institution's total expected utility, potentially subject to a constraint: \u03c4 \u2208 C \u2208 [0, 1] 2C which enforces some notion of \"fairness\". Formally, the institution selects \u03c4 * \u2208 argmax U(\u03c4 ) s.t. \u03c4 \u2208 C. We consider the three following constraints:\nDefinition 2.2 (Fairness criteria). The maximum utility (MaxUtil) policy corresponds to the nullconstraint C = [0, 1] 2C , so that the institution is free to focus solely on utility. The demographic parity (DemParity) policy results in equal selection rates between both groups. Formally, the constraint is C = (\u03c4 A , \u03c4 B ) :\nx\u2208X \u03c0 A (x)\u03c4 A = x\u2208X \u03c0 B (x)\u03c4 B .\nThe equal opportunity (EqOpt) policy results in equal true positive rates (TPR) between both group, where TPR is defined as TPR j (\u03c4 ) :\n= x\u2208X \u03c0 j (x)\u03c1(x)\u03c4 (x)\nx\u2208X \u03c0 j (x)\u03c1(x) . EqOpt ensures that the conditional probability of selection given that the individual will be successful is independent of the population, formally enforced by the constraint\nC = {(\u03c4 A , \u03c4 B ) : TPR A (\u03c4 A ) = TPR B (\u03c4 B )} .\nJust as the expected outcome \u2206\u00b5 can be expressed in terms of selection rate for threshold policies, so can the total utility U. In the unconstrained cause, U varies independently over the selection rates for group A and B; however, in the presence of fairness constraints the selection rate for one group determines the allowable selection rate for the other. The selection rates must be equal for DemParity, but for EqOpt we can define a transfer function, G (A\u2192B) , which for every loan rate \u03b2 in group A gives the loan rate in group B that has the same true positive rate. Therefore, when considering threshold policies, decision rules amount to maximizing functions of single parameters. This idea is expressed in Figure 2, and underpins the results to follow.", "publication_ref": [], "figure_ref": ["fig_2"], "table_ref": []}, {"heading": "Results", "text": "In order to clearly characterize the outcome of applying fairness constraints, we make the following assumption.\nAssumption 1 (Institution utilities). The institution's individual utility function is more stringent than the expected score changes, u(x) > 0 =\u21d2 \u2206(x) > 0. (For the linear form presented in Example 2.1, u \u2212 u + < c \u2212 c + is necessary and sufficient.)\nThis simplifying assumption quantifies the intuitive notion that institutions take a greater risk by accepting than the individual does by applying. For example, in the credit setting, a bank loses the amount loaned in the case of a default, but makes only interest in case of a payback. Using Assumption 1, we can restrict the position of MaxUtil on the outcome curve in the following sense. We direct the reader to Appendix C for the proof of the above proposition, and all subsequent results presented in this section. The results are corollaries to theorems presented in Section 6.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Prospects and Pitfalls of Fairness Criteria", "text": "We begin by characterizing general settings under which fairness criteria act to improve outcomes over unconstrained MaxUtil strategies. For this result, we will assume that group A is disadvantaged in the sense that the MaxUtil acceptance rate for B is large compared to relevant acceptance rates for A. \ng 0 < g 1 < 1 such that, for all g A \u2208 [g 0 , g 1 ], \u03b2 MaxUtil A < \u03b2 DemParity A < \u03b2. That is, DemParity causes relative improvement. (b) Under the assumption that there exist \u03b2 MaxUtil A < \u03b2 < \u03b2 < \u03b2 such that \u03b2 MaxUtil B > G (A\u2192B) (\u03b2), G (A\u2192B) (\u03b2 ), there exist population proportions g 2 < g 3 < 1 such that, for all g A \u2208 [g 2 , g 3 ], \u03b2 MaxUtil A < \u03b2 EqOpt A < \u03b2. That is, EqOpt causes relative improvement.\nThis result gives the conditions under which we can guarantee the existence of settings in which fairness criteria cause improvement relative to MaxUtil. Relying on machinery proved in Section 6, the result follows from comparing the position of optima on the utility curve to the outcome curve. Figure 2 displays a illustrative example of both the outcome curve and the institutions' utility U as a function of the selection rates in group A. In the utility function (1), the contributions of each group are weighted by their population proportions g j , and thus the resulting selection rates are sensitive to these proportions.\nAs we see in the remainder of this section, fairness criteria can achieve nearly any position along the outcome curve under the right conditions. This fact comes from the potential mismatch between the outcomes, controlled by \u2206, and the institution's utility u.\nThe next theorem implies that DemParity can be bad for long term well-being of the protected group by being over-generous, under the mild assumption that \u2206\u00b5 A (\u03b2 MaxUtil B ) < 0: The assumption \u2206\u00b5 A (\u03b2 MaxUtil B ) < 0 implies that a policy which selects individuals from group A at the selection rate that MaxUtil would have used for group B necessarily lowers average score in A. This is one natural notion of protected group A's 'disadvantage' relative to group B. In this case, DemParity penalizes the scores of group A even more than a naive MaxUtil policy, as long as group proportion g A is small enough. Again, small g A is another notion of group disadvantage.\nUsing credit scores as an example, Corollary 3.3 tells us that an overly aggressive fairness criterion will give too many loans to people in a protected group who cannot pay them back, hurting the group's credit scores on average. In the following theorem, we show that an analogous result holds for EqOpt. We remark that in Corollary 3.4, we rely on the transfer function, G (A\u2192B) , which for every loan rate \u03b2 in group A gives the loan rate in group B that has the same true positive rate. Notice that if G (A\u2192B) were the identity function, Corollary 3.3 and Corollary 3.4 would be exactly the same. Indeed, our framework (detailed in Section 6 and Appendix B) unifies the analyses for a large class of fairness constraints that includes DemParity and EqOpt as specific cases, and allows us to derive results about impact on \u2206\u00b5 using general techniques. In the next section, we present further results that compare the fairness criteria, demonstrating the usefulness of our technical framework.", "publication_ref": [], "figure_ref": ["fig_2"], "table_ref": []}, {"heading": "Comparing EqOpt and DemParity", "text": "Our analysis of the acceptance rates of EqOpt and DemParity in Section 6 suggests that it is difficult to compare DemParity and EqOpt without knowing the full distributions \u03c0 A , \u03c0 B , which is necessary to compute the transfer function G (A\u2192B) . In fact, we have found that settings exist both in which DemParity causes harm while EqOpt causes improvement and in which DemParity causes improvement while EqOpt causes harm. There cannot be one general rule as to which fairness criteria provides better outcomes in all settings. We now present simple sufficient conditions on the geometry of the distributions for which EqOpt is always better than DemParity in terms of \u2206\u00b5 A .\nCorollary 3.5 (EqOpt may avoid active harm where DemParity fails). Fix a selection rate \u03b2. Suppose \u03c0 A , \u03c0 B are identical up to a translation with \u00b5 A < \u00b5 B , i.e. \u03c0 A (x) = \u03c0 B (x + (\u00b5 B \u2212 \u00b5 A )). For simplicity, take \u03c1(x) to be linear in x. Suppose\n\u03b2 > x>\u00b5 A \u03c0 A .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Then there exists an interval", "text": "[g 1 , g 2 ] \u2286 [0, 1], such that \u2200g A > g 1 , \u03b2 EqOpt < \u03b2 while \u2200g A < g 2 , \u03b2 DemParity > \u03b2.\nIn particular, when \u03b2 = \u03b2 0 , this implies DemParity causes active harm but EqOpt causes improvement for g A \u2208 [g 1 , g 2 ], but for any g A such that DemParity causes improvement, EqOpt also causes improvement.\nTo interpret the conditions under which Corollary 3.5 holds, consider when we might have \u03b2 0 > x>\u00b5 A \u03c0 A . This is precisely when \u2206\u00b5 A ( x>\u00b5 A \u03c0 A ) > 0, that is, \u2206\u00b5 A > 0 for a policy that selects every individual whose score is above the group A mean, which is reasonable in reality.\nIndeed, the converse would imply that group A has such low scores that even selecting all above average individuals in A would hurt the average score. In such a case, Corollary 3.5 suggests that EqOpt is better than DemParity at avoiding active harm, because it is more conservative. A natural question then is: can EqOpt cause relative harm by being too stingy? Corollary 3.6 (DemParity never loans less than MaxUtil, but EqOpt might). Recall the definition of the TPR functions TPR j , and suppose that the MaxUtil policy \u03c4 MaxUtil is such that\n\u03b2 MaxUtil A < \u03b2 MaxUtil B and TPR A (\u03c4 MaxUtil ) > TPR B (\u03c4 MaxUtil ) (4\n)\nThen \u03b2 EqOpt A < \u03b2 MaxUtil A < \u03b2 DemParity A\n. That is, EqOpt causes relative harm by selecting at a rate lower than MaxUtil.\nThe above theorem shows that DemParity is never stingier than MaxUtil to the protected group A, as long as a A is disadvantaged in the sense that MaxUtil selects a larger proportion of B than A. On the other hand, EqOpt can select less of group A than MaxUtil, and by definition, cause relative harm. This is a surprising result about EqOpt, and this phenomenon arises from high levels of ingroup inequality for group A. Moreover, we show in Appendix C that there are parameter settings where the conditions in Corollary 3.6 are satisfied even under a stringent notion of disadvantage we call CDF domination, described therein.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Relaxations of Constrained Fairness", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Regularized fairness", "text": "In many cases, it may be unrealistic for an institution to ensure that fairness constraints are met exactly. However, one can consider \"soft\" formulations of fairness constraints which either penalized the differences in acceptance rate (DemParity) or the differences in TPR (EqOpt). In Appendix B, we formulate these soft constraints as regularized objectives. For example, a soft-DemParity can be rendered as\nmax \u03c4 :=\u03c4 A ,\u03c4 B U(\u03c4 ) \u2212 \u03bb\u03a6( \u03c0 A , \u03c4 A \u2212 \u03c0 B , \u03c4 B ) ,(5)\nwhere \u03bb > 0 is a regularization parameter, and \u03a6(t) is a convex regularization function. We show that the solutions to these objectives are threshold policies, and can be fully characterized in terms of the group-wise selection rate. We also make rigorous the notion that policies which solve the softconstraint objective interpolate between MaxUtil policies at \u03bb = 0 and hard-constrained policies (DemParity or EqOpt) as \u03bb \u2192 \u221e. This fact is clearly demonstrated by the form of the solutions in the special case of the regularization function \u03a6(t) = |t|, provided in the appendix.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Fairness Under Measurement Error", "text": "Next, consider the implications of an institution with imperfect knowledge of scores. Under a simple model in which the estimate of an individual's score X \u223c \u03c0 is prone to errors e(X) such that X + e(X) := X \u223c \u03c0. Constraining the error to be negative results in the setting that scores are systematically underestimated. In this setting, it is equivalent to consider the CDF of underestimated distribution \u03c0 to be dominated by the CDF true distribution \u03c0, that is\nx\u2265c \u03c0(x) \u2264 x\u2265c \u03c0(x) for all c \u2208 [C].\nThen we can compare the institution's behavior under this estimation to its behavior under the truth. Proposition 4.1 (Underestimation causes underselection). Fix the distribution of B as \u03c0 B and let \u03b2 be the acceptance rate of A when the institution makes the decision using perfect knowledge of the distribution \u03c0 A . Denote \u03b2 as the acceptance rate when the group is instead taken as \u03c0 A . Then\n\u03b2 MaxUtil A > \u03b2 MaxUtil A and \u03b2 DemParity A > \u03b2 DemParity A\n. If the errors are further such that the true TPR dominates the estimated TPR, it is also true that \u03b2\nEqOpt A > \u03b2 EqOpt A .\nBecause fairness criteria encourage a higher selection rate for disadvantaged groups (Corollary 3.2), systematic underestimation widens the regime of their applicability. Furthermore, since the estimated MaxUtil policy underloans, the region for relative improvement in the outcome curve (Figure 1) is larger, corresponding to more regimes under which fairness criteria can yield favorable outcomes. Thus the potential for measurement error should be a factor when motivating these criteria.", "publication_ref": [], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Outcome-based alternative", "text": "As explained in the preceding sections, fairness criteria may actively harm disadvantaged groups. It is thus natural to consider a modified decision rule which involves the explicit maximization of \u2206\u00b5 A . In this case, imagine that the institution's primary goal is to aid the disadvantaged group, subject to a limited profit loss compared to the maximum possible expected profit U MaxUtil . The corresponding problem is as follows. max\n\u03c4 A \u2206\u00b5 A (\u03c4 A ) s.t. U MaxUtil A \u2212 U(\u03c4 ) < \u03b4 .(6)\nUnlike the fairness constrained objective, this objective no longer depends on group B and instead depends on our model of the mean score change in group A, \u2206\u00b5 A .\nProposition 4.2 (Outcome-based solution). In the above setting, the optimal bank policy \u03c4 A is a threshold policy with selection rate \u03b2 = min{\u03b2 * , \u03b2 max }, where \u03b2 * is the outcome-optimal loan rate and \u03b2 max is the maximum loan rate under the bank's \"budget\".\nThe above formulation's advantage over fairness constraints is that it directly optimizes the outcome of A and can be approximately implemented given reasonable ability to predict outcomes. Importantly, this objective shifts the focus to outcome modeling, highlighting the importance of domain specific knowledge. Future work can consider strategies that are robust to outcome model errors.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Optimality of Threshold Policies", "text": "Next, we move towards statements of the main theorems underlying the results presented in Section 3. We begin by establishing notation which we shall use throughout. Recall that \u2022 denotes the Hadamard product between vectors. We identify functions mapping X \u2192 R with vectors in R C . We also define the group-wise utilities\nU j (\u03c4 j ) := x\u2208X \u03c0 j (x)\u03c4 j (x)u(x) ,(7)\nso that for \u03c4 = (\u03c4 A , \u03c4 B ), U(\u03c4 ) := g A U A (\u03c4 A ) + g B U B (\u03c4 B ). First, we formally describe threshold policies, and rigorously justify why we may always assume without loss of generality that the institution adopts policies of this form. Definition 5.1 (Threshold selection policy). A single group selection policy \u03c4 \u2208 [0, 1] C is called a threshold policy if it has the form of a randomized threshold on score:\n\u03c4 c,\u03b3 = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 1, x > c \u03b3, x = c 0, x < c , for some c \u2208 [C] and \u03b3 \u2208 (0, 1] . (8\n)\nAs a technicality, if no members of a population have a given score x \u2208 X , there may be multiple threshold policies which yield equivalent selection rates for a given population. To avoid redundancy, we introduce the notation \u03c4 j \u223c = \u03c0 j \u03c4 j to mean that the set of scores on which \u03c4 j and \u03c4 j differ has probability 0 under \u03c0 j ; formally, x:\u03c4 j (x) =\u03c4 j (x) \u03c0 j (x) = 0. For any distribution \u03c0 j , \u223c = \u03c0 j is an equivalence relation. Moreover, we see that if \u03c4 j \u223c = \u03c0 j \u03c4 j , then \u03c4 j and \u03c4 j both provide the same utility for the institution, induce the same outcomes for individuals in group j, and have the same selection and true positive rates. Hence, if (\u03c4 A , \u03c4 B ) is an optimal solution to any of MaxUtil, EqOpt, or DemParity, so is any (\u03c4 A , \u03c4 B ) for which\n\u03c4 A \u223c = \u03c0 A \u03c4 A and \u03c4 B \u223c = \u03c0 B \u03c4 B .\nFor threshold policies in particular, their equivalence class under \u223c = \u03c0 j is uniquely determined by the selection rate function,\nr \u03c0 j (\u03c4 j ) := x\u2208X \u03c0 j (x)\u03c4 j (x) ,(9)\nwhich denotes the fraction of group j which is selected. Indeed, we have the following lemma (proved in Appendix A.1):\nLemma 5.1. Let \u03c4 j and \u03c4 j be threshold policies. Then \u03c4 j \u223c = \u03c0 j \u03c4 j if and only if r \u03c0 j (\u03c4 j ) = r \u03c0 j (\u03c4 j ). Further, r \u03c0 j (\u03c4 j ) is a bijection from T thresh (\u03c0 j ) to [0, 1], where T thresh (\u03c0 j ) is the set of equivalence classes between threshold policies under \u223c = \u03c0 j . Finally, \u03c0 j \u2022 r \u22121 \u03c0 j (\u03b2 j ) is well defined.\nRemark that r \u22121 \u03c0 j (\u03b2 j ) is an equivalence class rather than a single policy. However, \u03c0 j \u2022 r \u22121 \u03c0 j (\u03c4 j ) is well defined, meaning that \u03c0 j \u2022 \u03c4 j = \u03c0 j \u2022 \u03c4 j for any two policies in the same equivalence class. Since all quantities of interest will only depend on policies \u03c4 j through \u03c0 j \u2022 \u03c4 j , it does not matter which representative of r \u22121 \u03c0 j (\u03b2 j ) we pick. Hence, abusing notation slightly, we shall represent T thresh (\u03c0 j ) by choosing one representative from each equivalence class under \u223c = \u03c0 j 3 . It turns out the policies which arise in this away are always optimal in the sense that, for a given loan rate \u03b2 j , the threshold policy r \u22121 \u03c0 j (\u03b2 j ) is the (essentially unique) policy which maximizes both the institution's utility and the utility of the group. Defining the group-wise utility,\nU j (\u03c4 j ) := x\u2208X u(x)\u03c0 j (x)\u03c4 j (x) ,(10)\nwe have the following result:\nProposition 5.1 (Threshold policies are preferable). Suppose that u(x) and \u2206(x) are strictly increasing in x. Given any loaning policy \u03c4 j for population with distribution \u03c0 j , then the policy \u03c4 thresh j := r \u22121 \u03c0 j (r \u03c0 j (\u03c4 j )) \u2208 T thresh (\u03c0 j ) satisfies \u2206\u00b5 j (\u03c4 thresh j ) \u2265 \u2206\u00b5 j (\u03c4 j ) and U j (\u03c4 thresh j ) \u2265 U j (\u03c4 j ) .\nMoreover, both inequalities hold with equality if and only if \u03c4 j \u223c = \u03c0 j \u03c4 thresh j .\nThe map \u03c4 j \u2192 r \u22121 \u03c0 j (r \u03c0 j (\u03c4 j )) can be thought of transforming an arbitrary policy \u03c4 j into a threshold policy with the same selection rate. In this language, the above proposition states that this map never reduces institution utility or individual outcomes. We can also show that optimal MaxUtil and DemParity policies are threshold policies, as well as all EqOpt policies under an additional assumption: Proposition 5.2 (Existance of optimal threshold policies under fairness constraints). Suppose that u(x) is strictly increasing in x. Then all optimal MaxUtil policies (\u03c4 A , \u03c4 B ) satisfy \u03c4 j \u223c = \u03c0 j r \u22121 \u03c0 j r \u03c0 j (\u03c4 j ) for j \u2208 {A, B}. The same holds for all optimal DemParity policies, and if in addition u(x)/\u03c1(x) is increasing, the same is true for all optimal EqOpt policies.\nTo prove proposition 5.1, we invoke the following general lemma which is proved using standard convex analysis arguments (in Appendix A.2):\nLemma 5.2. Let v \u2208 R C , and let w \u2208 R C >0 , and suppose either that v(x) is increasing in x, and v(x)/w(x) is increasing or, \u2200x \u2208 X , w(\nx) = 0. Let \u03c0 \u2208 Simplex C\u22121 and fix t \u2208 [0, x\u2208X \u03c0(x) \u2022 w(x)]. Then any \u03c4 * \u2208 arg max \u03c4 \u2208[0,1] C v \u2022 \u03c0, \u03c4 s.t. \u03c0 \u2022 w, \u03c4 = t (12\n)\nsatisfies \u03c4 * \u223c = \u03c0 r \u22121 \u03c0 (r \u03c0 (\u03c4 * )). Moreover, at least one maximizer \u03c4 * \u2208 T thresh (\u03c0) exists.\nProof of Proposition 5.1. We will first prove Proposition 5.1 for the function U j . Given our nominal policy \u03c4 j , let \u03b2 j = r \u03c0 j (\u03c4 j ). We now apply Lemma 5.2 with v(x) = u(x) and w(x) = 1. For this choice of v and w, v, \u03c4 = U j (\u03c4 ) and that \u03c0 j \u2022 w, \u03c4 = r \u03c0 j (\u03c4 ). Then, if \u03c4 j \u2208 arg max \u03c4 U j (\u03c4 ) s.t. r \u03c0 j (\u03c4 ) = \u03b2 j , Lemma 12 implies that \u03c4 j \u223c = \u03c0 j r \u22121 \u03c0 j (r \u03c0 j (\u03c4 j )). On the other hand, assume that \u03c4 j \u223c = \u03c0 j r \u22121 \u03c0 j r \u03c0 j (\u03c4 j ) . We show that r \u22121 \u03c0 j (r \u03c0 j (\u03c4 j )) is a maximizer; which will imply that \u03c4 j is a maximizer since \u03c4 j \u223c = \u03c0 j r \u22121 \u03c0 j (r \u03c0 j (\u03c4 j )) implies that U j (\u03c4 j ) = \u03c4 j \u223c = \u03c0 j r \u22121 \u03c0 j (r \u03c0 j (\u03c4 j )). By Lemma 5.2 there exists a maximizer \u03c4 * j \u2208 T thresh (\u03c0), which means that \u03c4 * j = r \u22121 \u03c0 j (r \u03c0 j (\u03c4 * j )). Since \u03c4 * j is feasible, we must have r \u03c0 j (\u03c4 * j ) = r \u03c0 j (\u03c4 j ), and thus \u03c4 * j = r \u22121 \u03c0 j (r \u03c0 j (\u03c4 j )), as needed. The same argument follows verbatim if we instead choose v(x) = \u2206(x), and compute v, \u03c4 = \u2206\u00b5 j (\u03c4 ). We now argue Proposition 5.2 for MaxUtil, as it is a straightforward application of Lemma 5.2. We will prove Proposition 5.2 for DemParity and EqOpt separately in Sections 6.1 and 6.2.\nProof of Proposition 5.2 for MaxUtil. MaxUtil follows from lemma 5.2 with v(x) = u(x), and t = 0 and w = 0.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Quantiles and Concavity of the Outcome Curve", "text": "To further our analysis, we now introduce left and right quantile functions, allowing us to specify thresholds in terms of both selection rate and score cutoffs.\nDefinition 5.2 (Upper quantile function). Define Q to be the upper quantile function corresponding to \u03c0, i.e. Q j (\u03b2) = argmax{c :\nC x=c \u03c0 j (x) > \u03b2} and Q + j (\u03b2) := argmax{c :\nC x=c \u03c0 j (x) \u2265 \u03b2} . (13\n)\nCrucially Q(\u03b2) is continuous from the right, and Q + (\u03b2) is continuous from the left. Further, Q(\u2022) and Q + (\u2022) allow us to compute derivatives of key functions, like the mapping from selection rate \u03b2 to the group outcome associated with a policy of that rate, \u2206\u00b5(r \u22121 \u03c0 (\u03b2)). Because we take \u03c0 to have discrete support, all functions in this work are piecewise linear, so we shall need to distinguish between the left and right derivatives, defined as follows\n\u2202 \u2212 f (x) := lim t\u21920 \u2212 f (x + t) \u2212 f (x) t and \u2202 + f (y) := lim t\u21920 + f (y + t) \u2212 f (y) t . (14\n)\nFor f supported on [a, b], we say that f is left-(resp. right-) differentiable if \u2202 \u2212 f (x) exists for all x \u2208 (a, b] (resp. \u2202 + f (y) exists for all y \u2208 [a, b)).\nWe now state the fundamental derivative computation which underpins the results to follow:\nLemma 5.3. Let e x denote the vector such that e x (x) = 1, and e x (x ) = 0 for x = x. Then\n\u03c0 j \u2022 r \u22121 \u03c0 j (\u03b2) : [0, 1] \u2192 [0, 1] C\nis continuous, and has left and right derivatives\n\u2202 + \u03c0 j \u2022 r \u22121 \u03c0 j (\u03b2) = e Q(\u03b2) and \u2202 \u2212 \u03c0 j \u2022 r \u22121 \u03c0 j (\u03b2) = e Q + (\u03b2) . (15\n)\nThe above lemma is proved in Appendix A.3. Moreover, Lemma 5.3 implies that the outcome curve is concave under the assumption that \u2206(x) is monotone:\nProposition 5.3. Let \u03c0 be a distribution over C states. Then \u03b2 \u2192 \u2206\u00b5(r \u22121 \u03c0 (\u03b2)) is concave. In fact, if w(x) is any non-decreasing map from X \u2192 R, \u03b2 \u2192 w, r \u22121 \u03c0 (\u03b2) is concave.\nProof. Recall that a univariate function f is concave (and finite) on [a, b] if and only (a) f is left-and\nright-differentiable, (b) for all x \u2208 (a, b), \u2202 \u2212 f (x) \u2265 \u2202 + f (x) and (c) for any x > y, \u2202 \u2212 f (x) \u2264 \u2202 + f (y). Observe that \u2206\u00b5(r \u22121 \u03c0 (\u03b2)) = \u2206, \u03c0 \u2022 r \u22121 \u03c0 (\u03b2) . By Lemma 5.3, \u03c0 \u2022 r \u22121 \u03c0 (\u03b2)\nhas right and left derivatives e Q(\u03b2) and e Q + (\u03b2) . Hence, we have that\n\u2202 + \u2206\u00b5(\u03b2 B ) = \u2206(Q(\u03b2 B )) and \u2202 \u2212 \u2206\u00b5(\u03b2 B ) = \u2206(Q + (\u03b2 B )) . (16\n)\nUsing the fact that \u2206(x) is monotone, and that Q \u2264 Q + , we see that \n\u2202 + \u2206\u00b5(f \u22121 \u03c0 (\u03b2 B )) \u2264 \u2202 \u2212 \u2206\u00b5(f \u22121 \u03c0 (\u03b2 B )", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Proofs of Main Theorems", "text": "We are now ready to present and prove theorems that characterize the selection rates under fairness constraints, namely DemParity and EqOpt. These characterizations are crucial for proving the results in Section 3. Our computations also generalize readily to other linear constraints, in a way that will become clear in Section 6.2.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A Characterization Theorem for DemParity", "text": "In this section, we provide a theorem that gives an explicit characterization for the range of selection rates \u03b2 A for A when the bank loans according to DemParity. Observe that the DemParity objective corresponds to solving the following linear program:\nmax \u03c4 =(\u03c4 A ,\u03c4 B )\u2208[0,1] 2C U(\u03c4 ) s.t. \u03c0 A , \u03c4 A = \u03c0 B , \u03c4 B .\nLet us introduce the auxiliary variable \u03b2 := \u03c0 A , \u03c4 A = \u03c0 B , \u03c4 B corresponding to the selection rate which is held constant across groups, so that all feasible solutions lie on the green DP line in Figure 3. We can then express the following equivalent linear program:\nmax \u03c4 =(\u03c4 A ,\u03c4 B )\u2208[0,1] 2C ,\u03b2\u2208[0,1] U(\u03c4 ) s.t. \u03b2 = \u03c0 j , \u03c4 j , j \u2208 {A, B} .\nThis is equivalent because, for a given \u03b2, Proposition 5.2 says that the utility maximizing policies are of the form \u03c4 j = r \u22121 \u03c0 j (\u03b2). We now prove this:\nProof of Proposition 5.2 for DemParity. Noting that r \u03c0 j (\u03c4 j ) = \u03c0 j , \u03c4 j , we see that, by Lemma 5.2, under the special case where v(x) = u(x) and w(x) = 1, the optimal solution (\u03c4 * A (\u03b2), \u03c4 * B (\u03b2)) for fixed r \u03c0 A (\u03c4 A ) = r \u03c0 B (\u03c4 B ) = \u03b2 can be chosen to coincide with the threshold policies. Optimizing over \u03b2, the global optimal must coincide with thresholds.\nHence, any optimal policy is equivalent to the threshold policy \u03c4 = (r \u22121 \u03c0 A (\u03b2), r \u22121 \u03c0 B (\u03b2)), where \u03b2 solves the following optimization:\nmax \u03b2\u2208[0,1] U r \u22121 \u03c0 A (\u03b2), r \u22121 \u03c0 B (\u03b2) . (17\n)\nWe shall show that the above expression is in fact a concave function in \u03b2, and hence the set of optimal selection rates can be characterized by first order conditions. This is presented formally in the following theorem:\nTheorem 6.1 (Selection rates for DemParity). The set of optimal selection rates \u03b2 * satisfying (17)\nforms a continuous interval [\u03b2 \u2212 DemParity , \u03b2 + DemParity ], such that for any \u03b2 \u2208 [0, 1], we have \u03b2 < \u03b2 \u2212 DemParity if g A u (Q A (\u03b2)) + g B u (Q B (\u03b2)) > 0 , \u03b2 > \u03b2 + DemParity if g A u Q + A (\u03b2) + g B u Q + B (\u03b2) < 0 .\nProof. Note that we can write\nU r \u22121 \u03c0 A (\u03b2), r \u22121 \u03c0 B (\u03b2) = g A u, \u03c0 A \u2022 r \u22121 \u03c0 A (\u03b2) + g B u, \u03c0 B \u2022 r \u22121 \u03c0 B (\u03b2) . Since u(x) is non-decreasing in x, Proposition 5.3 implies that \u03b2 \u2192 U r \u22121 \u03c0 A (\u03b2), r \u22121 \u03c0 B (\u03b2) is concave in \u03b2.\nHence, all optimal selection rates \u03b2 * lie in an interval [\u03b2 \u2212 , \u03b2 + ]. To further characterize this interval, let us us compute left-and right-derivatives.\n\u2202 + U r \u22121 \u03c0 A (\u03b2), r \u22121 \u03c0 B (\u03b2) = \u2202 + g A u, \u03c0 A \u2022 r \u22121 \u03c0 A (\u03b2) + \u2202 + g B u, \u03c0 B \u2022 r \u22121 \u03c0 B (\u03b2) = g A u, \u2202 + \u03c0 A \u2022 r \u22121 \u03c0 A (\u03b2) + g B u, \u2202 + \u03c0 B \u2022 r \u22121 \u03c0 B (\u03b2) Lemma 5.3 = g A u, e Q A (\u03b2) + g B u, e Q B (\u03b2) = g A u(Q A (\u03b2)) + g B u(Q B (\u03b2)) .\nThe same argument shows that\n\u2202 \u2212 U((r \u22121 \u03c0 A (\u03b2), r \u22121 \u03c0 B (\u03b2))) = g A u(Q + A (\u03b2)) + g B u(Q + B (\u03b2)).\nBy concavity of U r \u22121 \u03c0 A (\u03b2), r \u22121 \u03c0 B (\u03b2) , a positive right derivative at \u03b2 implies that \u03b2 < \u03b2 * for all \u03b2 * satisfying (17), and similarly, a negative left derivative at \u03b2 implies that \u03b2 > \u03b2 * for all \u03b2 * satisfying (17).\nWith a result of the above form, we can now easily prove statements such as that in Corollary 3.3 (see appendix C for proofs), by fixing a selection rate of interest (e.g. \u03b2 0 ) and inverting the inequalities in Theorem 6.1 to find the exact population proportions under which, for example, DemParity results in a higher selection rate than \u03b2 0 .", "publication_ref": [], "figure_ref": ["fig_6"], "table_ref": []}, {"heading": "EqOpt and General Constraints", "text": "Next, we will provide a theorem that gives an explicit characterization for the range of selection rates \u03b2 A for A when the bank loans according to EqOpt. Observe that the EqOpt objective corresponds to solving the following linear program:\nmax \u03c4 =(\u03c4 A ,\u03c4 B )\u2208[0,1] 2C U(\u03c4 ) s.t. w A \u2022 \u03c0 A , \u03c4 A = w B \u2022 \u03c0 B , \u03c4 B ,(18)\nwhere w j = \u03c1 \u03c1,\u03c0 j . This problem is similar to the demographic parity optimization in ( 17), except for the fact that the constraint includes the weights. Whereas we parameterized demographic parity solutions in terms of the acceptance rate \u03b2 in equation ( 17), we will parameterize equation ( 18) in terms of the true positive rate (TPR), t := w A \u2022 \u03c0 A , \u03c4 A . Thus, (18) becomes\nmax t\u2208[0,tmax] max (\u03c4 A ,\u03c4 B )\u2208[0,1] 2C j\u2208{A,B} g j U j (\u03c4 j ) s.t. w j \u2022 \u03c0 j , \u03c4 j = t, j \u2208 {A, B} ,(19)\nwhere t max = min j\u2208{A,B} { \u03c0 j , w j } is the largest possible TPR. The magenta EO curve in Figure 3 illustrates that feasible solutions to this optimization problem lie on a curve parametrized by t.\nNote that the objective function decouples for j \u2208 {A, B} for the inner optimization problem, max\n\u03c4 j \u2208[0,1] C j\u2208{A,B} g j U j (\u03c4 j ) s.t. w j \u2022 \u03c0 j , \u03c4 j = t .(20)\nWe will now show that all optimal solutions for this inner optimization problem are \u03c0 j -a.e. equal to a policy in T thresh (\u03c0 j ), and thus can be written as r \u22121 \u03c0 j (\u03b2 j ), depending only on the resulting selection rate.\nProof of Proposition 5.2 for EqOpt. We apply Lemma 5.2 to the inner optimization in (20) with v(x) = u(x) and w(x) = \u03c1(x)\n\u03c1,\u03c0 j . The claim follows from the assumption that u(x)/\u03c1(x) is increasing by optimizing over t.\nThis selection rate \u03b2 j is uniquely determined by the TPR t (proof appears in Appendix B.1): Lemma 6.1. Suppose that w(x) > 0 for all x. Then the function\nT j ,w j (\u03b2) := r \u22121 \u03c0 j (\u03b2), \u03c0 j \u2022 w j is a bijection from [0, 1] to [0, \u03c0 j , w ].\nHence, for any t \u2208 [0, t max ], the mapping from TPR to acceptance rate, T \u22121 j ,w j (t), is well defined and any solution to (20) is \u03c0 j -a.e. equal to the policy r \u22121 \u03c0 j (T \u22121 j ,w j (t)). Thus (19) reduces to max\nt\u2208[0,tmax] j\u2208{A,B} g j U j r \u22121 \u03c0 j T \u22121 j ,w j (t) .(21)\nThe above expression parametrizes the optimization problem in terms of a single variable. We shall show that the above expression is in fact a concave function in t, and hence the set of optimal selection rates can be characterized by first order conditions. This is presented formally in the following theorem: Theorem 6.2 (Selection rates for EqOpt). The set of optimal selection rates \u03b2 * for group A satsifying (19) forms a continuous interval [\u03b2 \u2212 EqOpt , \u03b2 + EqOpt ], such that for any \u03b2 \u2208 [0, 1], we have\n\u03b2 < \u03b2 \u2212 EqOpt if g A u(Q A (\u03b2)) w A (Q A (\u03b2)) + g B u(Q B (G (A\u2192B) w (\u03b2))) w B (Q B (G (A\u2192B) w (\u03b2))) > 0 , \u03b2 > \u03b2 + EqOpt if g A u(Q + A (\u03b2)) w A (Q + A (\u03b2)) + g B u(Q + B (G (A\u2192B) w (\u03b2))) w B (Q + B (G (A\u2192B) w (\u03b2))) < 0 .\nHere, G\n(A\u2192B) w (\u03b2) := T \u22121 B,w B (T \u22121 A,w A (\u03b2)\n) denotes the (well-defined) map from selection rates \u03b2 A for A to the selection rate \u03b2 B for B such that the policies \u03c4 *\nA := r \u22121 \u03c0 A (\u03b2 A ) and \u03c4 * B := r \u22121 \u03c0 B (\u03b2 B ) satisfy the constraint in (18).\nProof. Starting with the equivalent problem in ( 21), we use the concavity result of Lemma B.1. Because the objective function is the positive weighted sum of two concave functions, it is also concave. Hence, all optimal true positive rates t * lie in an interval [t \u2212 , t + ]. To further characterize [t \u2212 , t + ], we can compute left-and right-derivatives, again using the result of Lemma B.1.\n\u2202 + j\u2208{A,B} g j U j r \u22121 \u03c0 j (T \u22121 j ,w j (t)) = g A \u2202 + U A r \u22121 \u03c0 A (T \u22121 A ,w A (t)) + g A \u2202 + U A r \u22121 \u03c0 A (T \u22121 A ,w A (t)) = g A u(Q A (T \u22121 A ,w A (t))) w A (Q A (T \u22121 A ,w A (t))) + g B u(Q B (T \u22121 B ,w B (t))) w B (Q B (T \u22121 B ,w B (t)))\nThe same argument shows that\n\u2202 \u2212 j\u2208{A,B} g j U j r \u22121 \u03c0 j (T \u22121 j ,w j (t)) = g A u(Q + A (T \u22121 A ,w A (t)) w A (Q + A (T \u22121 A ,w A (t))) + g B u(Q + B (T \u22121 B ,w B (t))) w B (Q + B (T \u22121 B ,w B (t)))\n.\nBy concavity, a positive right derivative at t implies that t < t * for all t * satisfying (21), and similarly, a negative left derivative at t implies that t > t * for all t * satisfying (21). Finally, by Lemma 6.1, this interval in t uniquely characterizes an interval of acceptance rates. Thus we translate directly into a statement about the selection rates \u03b2 for group A by seeing that T \u22121 A ,w A (t) = \u03b2 and T \u22121 B ,w\nB (t) = G (A\u2192B) w (\u03b2).\nLastly, we remark that the results derived in this section go through verbatim for any linear constraint of the form w, \u03c0 A \u2022 \u03c4 A = w, \u03c0 B \u2022 \u03c4 B , as long as u(x)/w(x) is increasing in x, and w(x) > 0. ", "publication_ref": [], "figure_ref": ["fig_6"], "table_ref": []}, {"heading": "Simulations", "text": "We examine the outcomes induced by fairness constraints in the context of FICO scores for two race groups. FICO scores are a proprietary classifier widely used in the United States to predict credit worthiness. Our FICO data is based on a sample of 301,536 TransUnion TransRisk scores from 2003 [US Federal Reserve, 2007], preprocessed by Hardt et al. [2016]. These scores, corresponding to x in our model, range from 300 to 850 and are meant to predict credit risk. Empirical data labeled by race allows us to estimate the distributions \u03c0 j , where j represents race, which is restricted to two values: white non-Hispanic (labeled \"white\" in figures), and black. Using national demographic data, we set the population proportions to be 18% and 82%.\nIndividuals were labeled as defaulted if they failed to pay a debt for at least 90 days on at least one account in the ensuing 18-24 month period; we use this data to estimate the success probability given score, \u03c1 j (x), which we allow to vary by group to match the empirical data (see Figure 4). Our outcome curve framework allows for this relaxation; however, this discrepancy can also be attributed to group-dependent mismeasurement of score, and adjusting the scores accordingly would allow for a single \u03c1(x). We use the success probabilities to define the affine utility and score change functions defined in Example 2.1. We model individual penalties as a score drop of c \u2212 = \u2212150 in the case of a default, and in increase of c + = 75 in the case of successful repayment.\nIn Figure 5, we display the empirical CDFs along with selection rates resulting from different loaning strategies for two different settings of bank utilities. In the case that the bank experiences a loss/profit ratio of u \u2212 u + = \u221210, no fairness criteria surpass the active harm rate \u03b2 0 ; however, in the case of u \u2212 u + = \u22124, DemParity overloans, in line with the statement in Corollary 3.3. These results are further examined in Figure 6, which displays the normalized outcome curves and the utility curves for both the white and the black group. To plot the MaxUtil utility curves, the group that is not on display has selection rate fixed at \u03b2 MaxUtil . In this figure, the top panel corresponds to the average change in credit scores for each group under different loaning rates \u03b2; the bottom panels shows the corresponding total utility U (summed over both groups and weighted by group population sizes) for the bank. Figure 6 highlights that the position of the utility optima in the lower panel determines the loan (selection) rates. In this specific instance, the utility and change ratios are fairly close, u \u2212 u + = \u22124, and c \u2212 c + = \u22122, meaning that the bank's profit motivations align with individual outcomes to some extent. Here, we can see that EqOpt loans much closer to optimal than DemParity, similar to the setting suggested by Corollary 3.2.\nAlthough one might hope for decisions made under fairness constraints to positively affect the black group, we observe the opposite behavior. The MaxUtil policy (solid orange line) and the EqOpt policy result in similar expected credit score change for the black group. However, DemParity (dashed green line) causes a negative expected credit score change in the black group, corresponding to active harm. For the white group, the bank utility curve has almost the same shape under the fairness criteria as it does under MaxUtil, the main difference being that fairness criteria lowers the total expected profit from this group. This behavior stems from a discrepancy in the outcome and profit curves for each population. While incentives for the bank and positive results for individuals are somewhat aligned for the majority group, under fairness constraints, they are more heavily misaligned in the minority group, as seen in graphs (left) in Figure 6. We remark that in other settings where the unconstrained profit maximization is misaligned with individual outcomes (e.g., when u \u2212 u + = \u221210), fairness criteria may perform more favorably for the minority group by pulling the utility curve into a shape consistent with the outcome curve.\nBy analyzing the resulting affects of MaxUtil, DemParity, and EqOpt on actual credit score lending data, we show the applicability of our model to real-world applications. In particular, some results shown in Section 3 hold empirically for the FICO TransUnion TransRisk scores.  ", "publication_ref": ["b7"], "figure_ref": ["fig_7", "fig_8", "fig_10", "fig_10", "fig_10"], "table_ref": []}, {"heading": "Conclusion and Future Work", "text": "We argue that without a careful model of delayed outcomes, we cannot foresee the impact a fairness criterion would have if enforced as a constraint on a classification system. However, if such an accurate outcome model is available, we show that there are more direct ways to optimize for positive outcomes than via existing fairness criteria.\nOur formal framework exposes a concise, yet expressive way to model outcomes via the expected change in a variable of interest caused by an institutional decision. This leads to the natural concept of an outcome curve that allows us to interpret and compare solutions effectively. In essence, the formalism we propose requires us to understand the two-variable causal mechanism that translates decisions to outcomes. Depending on the application, such an understanding might necessitate greater domain knowledge and additional research into the specifics of the application. This is consistent with much scholarship that points to the context-sensitive nature of fairness in machine learning.\nAn interesting direction for future work is to consider other characteristics of impact beyond the change in population mean. Variance and individual-level outcomes are natural and important considerations. Moreover, it would be interesting to understand the robustness of outcome optimization to modeling and measurement errors. ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A Optimality of Threshold Policies", "text": "A.1 Proof of Lemma 5.1\nWe begin with the first statement of the lemma. Suppose \u03c4 j \u223c = \u03c0 j \u03c4 j . Then there exists a set S \u2282 X such that \u03c0 j (x) = 0 for all x \u2208 S, and for all x / \u2208 S, \u03c4 j (x) = \u03c4 j (x). Thus,\nr \u03c0 (\u03c4 j ) \u2212 r \u03c0 j (\u03c4 j ) = x\u2208X \u03c0 j (x)(\u03c4 j (x) \u2212 \u03c4 j (x)) = x\u2208S \u03c0 j (x)(\u03c4 j (x) \u2212 \u03c4 j (x)) = 0 .\nConversely, suppose that r \u03c0 j (\u03c4 j ) = r \u03c0 j (\u03c4 j ). Let \u03c4 j = \u03c4 c,\u03b3 and \u03c4 j = \u03c4 c ,\u03b3 as in Definition 5.1. We now have the following cases:\n1. Case 1: c = c . Then \u03c4 j (x) = \u03c4 j (x) for all x \u2208 X \u2212 {c}. Hence,\n0 = r \u03c0 (\u03c4 j ) \u2212 r \u03c0 j (\u03c4 j ) = \u03c0(x)(\u03c4 j (c) \u2212 \u03c4 j (c)) .\nThis implies that either \u03c4 j (c) = \u03c4 j (c), and thus \u03c4 j (x) = \u03c4 j (x) for all x \u2208 X , or otherwise \u03c0(c) = 0, in which case we still have \u03c4 j \u223c = \u03c0 j \u03c4 j (since the two policies agree every outside the set {c}).\n2. Case 2: c = c . We assume assume without loss of generality that c < c \u2264 C. Since the policies \u03c4 c ,1 and \u03c4 c +1,0 are identity for c < C, we may also assume without loss of generality that \u03b3 \u2208 [0, 1). Thus for all x \u2208 S := {c , c + 1, . . . , C}, we have \u03c4 j (x) < \u03c4 j (x). This implies that\n0 = r \u03c0 (\u03c4 j ) \u2212 r \u03c0 j (\u03c4 j ) = x\u2208S \u03c0 j (x)(\u03c4 j (x) \u2212 \u03c4 j (x)) \u2265 min x\u2208S (\u03c4 j (c) \u2212 \u03c4 j (x)) \u2022 x\u2208S \u03c0(x) .\nSince min x\u2208S (\u03c4 j (c) \u2212 \u03c4 j (x)) > 0, it follows that x\u2208S \u03c0 j (x) = 0, whence \u03c4 j \u223c = \u03c0 j \u03c4 j .\nNext, we show that r \u03c0 is a bijection from T thresh (\u03c0) \u2192 [0, 1]. That r \u03c0 is injective follows immediately from the fact if r \u03c0 j (\u03c4 ) = r \u03c0 j (\u03c4 j ), then \u03c4 j \u223c = \u03c0 j \u03c4 j . To show it is surjective, we exhibit for every \u03b2 \u2208 [0, 1] a threshold policy \u03c4 c,\u03b3 for which r \u03c0 j (\u03c4 c,\u03b3 ) = \u03b2. We may assume \u03b2 < 1, since the all-ones policy has a selection rate of 1.\nRecall the definition of the inverse CDF Q j (\u03b2) := argmax{c :\nC x=c \u03c0(x) > \u03b2} . Since \u03b2 < 1, Q j (\u03b2) \u2264 C. Let \u03b2 + = C\nx=Q j (\u03b2) \u03c0(x), and let \u03b2 \u2212 = C x=Q j (\u03b2)+1 \u03c0(x). Note that by definition, we have \u03b2 \u2212 \u2264 \u03b2 < \u03b2 + , and\n\u03b2 + \u2212 \u03b2 \u2212 = \u03c0(Q j (\u03b2)). Hence, if we define \u03b3 = \u03b2\u2212\u03b2 \u2212 \u03b2 + \u2212\u03b2 \u2212 , we have r \u03c0 j (\u03c4 Q j (\u03b2),\u03b3 ) = \u03c0(Q j (\u03b2))\u03b3 + C x=Q j (\u03b2)+1 \u03c0(x) = \u03b2 \u2212 + (\u03b2 + \u2212 \u03b2 \u2212 )\u03b3 = \u03b2 \u2212 + \u03b2 \u2212 \u03b2 \u2212 = \u03b2 . A.2 Proof of Lemma 5.2 Given \u03c4 \u2208 [0, 1] C , we define the normal cone at \u03c4 as NC(\u03c4 ) := ConicalHull{z : \u03c4 + z \u2208 [0, 1] C }.\nWe can describe NC(\u03c4 ) explicitly as:\nNC(\u03c4 ) := {z \u2208 R C : z i \u2264 0 if \u03c4 i = 0, z i \u2265 0 if \u03c4 i = 1} .\nImmediately from the above definition, we have the following useful identity, which is that for any vector g \u2208 R C , g, z \u2264 0 \u2200z \u2208 NC(\u03c4 ), if and only if \u2200x \u2208 X ,\n\uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 \u03c4 (x) = 0 g(x) < 0 \u03c4 (x) = 1 g(x) > 0 \u03c4 (x) \u2208 [0, 1] g(x) = 0 .(22)\nNow consider the optimization problem (12). By the first order KKT conditions, we know that for any optimizer \u03c4 * of the above objective, there exists some \u03bb \u2208 R such that, for all z \u2208 NC(\u03c4 * )\nz, v \u2022 \u03c0 + \u03bb\u03c0 \u2022 w \u2264 0 . By (22), we must have that \u03c4 * (x) = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 0 \u03c0(x)(v(x) + \u03bbw(x)) < 0 1 \u03c0(x)(v(x) + \u03bbw(x)) > 0 \u2208 [0, 1] \u03c0(x)(v(x) + \u03bbw(x)) = 0 . Now \u03c4 * (x)\nis not necessarily a threshold policy. To conclude the theorem, it suffices to exhibit a threshold policy \u03c4 * such that \u03c4 * (x) \u223c = \u03c0 \u03c4 * . (Note that \u03c4 * (x) will also be feasible for the constraint, and have the same objective value; hence \u03c4 * will be optimal as well.)\nGiven \u03c4 * and \u03bb, let c * = min{c \u2208 X : v(x) + \u03bbw(x) \u2265 0}. If either (a) w(x) = 0 for all x \u2208 X and v(x) is strictly increasing or (b) v(x)/w(x) is strictly increasing, then the modified policy\n\u03c4 * (x) = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 0 x < c * \u03c4 * (x) x = c * 1 x > c * ,\nis a threshold policy, and \u03c4 * (x) \u223c = \u03c0 \u03c4 * . Moreover, w, \u03c4 * = w, \u03c4 * and \u03c0, \u03c4 * = \u03c0, \u03c4 * , which implies that \u03c4 * is an optimal policy for the objective in Lemma 5.2.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A.3 Proof of Lemma 5.3", "text": "We shall prove\n\u2202 + \u03c0 j \u2022 r \u22121 \u03c0 j (\u03b2) = e Q j (\u03b2) ,(23)\nwhere the derivative is with respect to \u03b2. The computation of the left-derivative is analogous. Since we are concerned with right-derivatives, we shall take \u03b2 \u2208 [0, 1). Since \u03c0 j \u2022 r \u22121 \u03c0 j (\u03b2) does not depend on the choice of representative for r \u22121 \u03c0 j , we can choose a cannonical representation for r \u22121 \u03c0 j . In Section A.1, we saw that the threshold policy \u03c4 Q j (\u03b2),\u03b3(\u03b2) had acceptance rate \u03b2, where we had defined\n\u03b2 + = C x=Q j (\u03b2) \u03c0(x) and \u03b2 \u2212 = C x=Q j (\u03b2)+1 \u03c0(x) ,(24)\n\u03b3(\u03b2) = \u03b2 \u2212 \u03b2 \u2212 \u03b2 + \u2212 \u03b2 \u2212 . (25\n)\nNote then that for each x, \u03c4 Q j (\u03b2),\u03b3(\u03b2) (x) is piece-wise linear, and thus admits left and right derivatives. We first claim that \u2200x \u2208 X \\ {Q j (\u03b2)}, \u2202 + \u03c4 Q j (\u03b2),\u03b3(\u03b2) (x) = 0 .\nTo see this, note that Q j (\u03b2) is right continuous, so for all sufficiently small, Q j (\u03b2 + ) = Q j (\u03b2). Hence, for all sufficiently small and all x = Q(\u03b2), we have \u03c4 Q j (\u03b2+ ),\u03b3(\u03b2+ ) (x) = \u03c4 Q j (\u03b2+ ),\u03b3(\u03b2+ ) (x), as needed. Thus, Equation ( 26) implies that \u2202 + \u03c0 j \u2022 r \u22121 \u03c0 j (\u03b2) is supported on x = Q j (\u03b2), and hence\n\u2202 + \u03c0 j \u2022 r \u22121 \u03c0 j (\u03b2) = \u2202 + \u03c0 j (x)\u03c4 Q j (\u03b2),\u03b3(\u03b2) (x) x=Q j (\u03b2) \u2022 e Q j (\u03b2) .\nTo conclude, we must show that \u2202 + \u03c0 j (x)\u03c4 Q j (\u03b2),\u03b3(\u03b2) (x) x=Q j (\u03b2) = 1. To show this, we have In this section, we prove Lemma 6.1, which we recall below.\nLemma 6.1. Suppose that w(x) > 0 for all x. Then the function T j ,w j (\u03b2) := r \u22121 \u03c0 j (\u03b2), \u03c0 j \u2022 w j is a bijection from [0, 1] to [0, \u03c0 j , w ].\nWe will prove Lemma 6.1 in tandem with the following derivative computation which we applied in the proof of Theorem 6.2.\nLemma B.1. The function U j (t; w j ) := U j r \u22121\n\u03c0 j T \u22121 j ,w j (t)\nis concave in t and has left and right derivatives \u2202 + U j (t; w j ) = u(Q j (T \u22121 j ,w j (t))) w j (Q j (T \u22121 j ,w j (t)))\nand \u2202 \u2212 U j (t; w j ) = u(Q + j (T \u22121 j ,w j (t))) w j (Q + j (T \u22121 j ,w j (t)))\n.\nProof of Lemmas 6.1 and B.1. Consider a \u03b2 \u2208 [0, 1]. Then, \u03c0 j \u2022 r \u22121 \u03c0 j (\u03b2) is continuous and left and right differentiable by Lemma 5.3, and its left and right derivatives are indicator vectors e Q j (\u03b2) and e Q + j (\u03b2) , respectively. Consequently, \u03b2 \u2192 w j , \u03c0 j \u2022 r \u22121 \u03c0 j (\u03b2) has left and right derivatives w j (Q(\u03b2)) and w j (Q + (\u03b2)), respectively; both of which are both strictly positive by the assumption w(x) > 0. Hence, T j ,w j (\u03b2) = w j , \u03c0 j \u2022 r \u22121 \u03c0 j (\u03b2) is strictly increasing in \u03b2, and so the map is injective. It is also surjective because \u03b2 = 0 induces the policy \u03c4 j = 0 and \u03b2 = 1 induces the policy \u03c4 j = 1 (up to \u03c0 j -measure zero). Hence, T j ,w j (\u03b2) is an order preserving bijection with left-and right-derivatives, and we can compute the left and right derivatives of its inverse as follows:\n\u2202 + T \u22121 j ,w j (t) = 1 \u2202 + T j ,w j (\u03b2) \u03b2=T \u22121 j ,w j (t) =\n1 w j (Q j (T \u22121 j ,w j (t)))\n, and similarly, \u2202 \u2212 T \u22121 j ,w j (t) = 1 w j (Q + (T \u22121 j ,w j (t))) . Then we can compute that \u2202 + U j (r \u03c0 j (T \u22121 j ,w j (t))) = \u2202 + U(r \u03c0 j (\u03b2)) \u03b2=T \u22121 j ,w j (t)) \u2022 \u2202 + T j ,w j (sup(t))\n= u(Q j (T \u22121 j ,w j (t))) w j (Q j (T \u22121 j ,w j (t)))\n.\nand similarly \u2202 \u2212 U j (r \u03c0 j (T j ,w j (t))) = U (Q + j (T \u22121 j ,w j (t))) w j (Q + j (T \u22121 j ,w j (t))) . One can verify that for all t 1 < t 2 , one has that concavity, we conclude that \u2202G 2 (t A ; \u03bb) is non-decreasing in \u03bb. Hence, Lemma B.3 implies that T A (\u03bb) is non-decreasing in \u03bb.\nFinally, to show that max{|\u2206| : \u2206 \u2208 D(\u03bb)|} \u2192 0, Note that the left and right derivatives of g A U A (t; w A ) and g B U B (t; w B ) are upper bounded by M whereas, since \u03a6 is strictly convex, we know that for every > 0, min{|\u2202 + \u03a6(\u2206)|, |\u2202 \u2212 \u03a6(\u2206)|} > m( ) for all \u2206 : |\u2206| > . Hence, the first order optimality conditions cannot be satisfied for |\u2206| > , and \u03bb > M m( ) , so as \u03bb \u2192 \u221e, |\u2206| \u2192 0.\nProof of Lemma B.3. We prove the case where \u2202G 2 (t; \u03bb) is non-increasing. The first order conditions requires that at an optimal t, one has\n\u2202 \u2212 G 1 (t) + \u2202G 2 (t; \u03bb) \u2212 \u2265 0 \u2265 \u2202 + G 1 (t) + \u2202G 2 (t; \u03bb) +\nwhere the super-gradients are amended to take into account boundary conditions. Suppose that for the sake of contradiction that for \u03bb > \u03bb, MAX(\u03bb ) MAX(\u03bb) fails. Then, there (a) exists a t \u2208 MAX(\u03bb) such that {t} \u227a MAX(\u03bb ), or (b) t \u2208 MAX(\u03bb ) such that {t} MAX(\u03bb ). Note that if {t} \u227a MAX(\u03bb ), it must be the case that\n\u2202 + G 1 (t) + \u2202G 2 (t; \u03bb ) + > 0 .\nBy assumption, \u2202 \u2212 G 2 (t; \u03bb ) + \u2264 \u2202 0 G 2 (t; \u03bb) + , which implies\n\u2202 + G 1 (t) + \u2202G 2 (t; \u03bb ) + \u2264 \u2202 + G 1 (t) + \u2202 + G 2 (t; \u03bb) \u2212 0 \u2264 0 , a contradiction.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C Proofs of Main Results", "text": "We remark that the proofs in this section rely crucially on the characterizations of the optimal fairness-constrained policies developed in Section 6. We first define the notion of CDF domination, which is referred to in a few of the proofs. Intuitively, it means that for any score, the fraction of group B above this is higher than that for group A. It is realistic to assume this if we keep with our convention that group A is the disadvantaged group relative to group B.\nDefinition C.1 (CDF domination). \u03c0 A is said to be dominated by \u03c0 B if \u2200a \u2265 1, x>a \u03c0 A <\nx>a \u03c0 B . We denote this as \u03c0 A \u227a \u03c0 B .\nWe remark that the \u227a notation in this section is entirely unrelated to the the partial order on intervals from Section B.3. Frequently, we shall use the following lemma:\nLemma C.1. Suppose that \u03c0 A \u227a \u03c0 B . Then, for all \u03b2 > 0, it holds that Q A (\u03b2) \u2264 Q B (\u03b2) and u(Q A (\u03b2)) \u2264 u(Q A (\u03b2))\nProof. The fact that Q A (\u03b2) \u2264 Q B (\u03b2) follows directly from the definition of monotonicty of u implies that u(Q A (\u03b2)) \u2264 u(Q B (\u03b2)).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgements", "text": "We thank Lily Hu, Aaron Roth, and Cathy O'Neil for discussions and feedback on an earlier version of the manuscript. We thank the students of CS294: Fairness in Machine Learning (Fall 2017, University of California, Berkeley) for inspiring class discussions and comments on a presentation that was a precursor of this work. This material is based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant No. DGE 1752814.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "", "text": "\u2202 + U j (r \u03c0 j (T \u22121 j ,w j (t 1 ))) \u2265 \u2202 \u2212 U j (r \u03c0 j (T \u22121 j ,w j (t 2 ))), and that for all t, \u2202 + U j (r \u03c0 j (T \u22121 j ,w j (t))) \u2264 \u2202 \u2212 U j (r \u03c0 j (T \u22121 j ,w j (t))). These facts establish that the mapping t \u2192 U j (r \u03c0 j (T \u22121 j ,w j (t))) is concave.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B.2 Characterizations Under Soft Constraints", "text": "Given a convex penalty \u03a6 : R \u2192 R \u22650 , and \u03bb \u2208 R \u22650 , one can write down the general form for soft constrained utility optimization\nwhere w A and w B represent generic constraints. Again, we shall assume that for j \u2208 {A, B}, u(x)/w j (x) is non-decreasing. Recall that for w j = (1, 1, . . . , 1), one recovers the soft version of DemParity, whereas for w j = \u03c1 \u03c1,\u03c0 j , one recovers the soft constrained version of EqOpt. The same argument presented in Section 6.2 shows that the optimal policies are of the form \u03c4 j = r \u22121 \u03c0 j (T \u22121 j ,w j (t j )) , where (t A , t B ) are solutions to the following optimization problem:\nThe following lemma gives us a first order characterization of these optimal TPRs, (t A , t B ). \nwhere\nProof. Let \u2202(\u2022) denote the super-gradient set of a concave function. Note that if F is left-and-right differentiable and concave, then\n. By concavity of U j and convexity of \u03a6, we must have that\nIn general, a closed form solution for the soft constrained problem may be difficult to state. However, for the case of \u03a6(t) = |t|, we can state an explicit closed form solution: Proposition B.1 (Special case of \u03a6(t) = |t|). Let \u03a6(t) = |t|, fix \u03bb, and let [\u03b2 \u03bb,\u2212\nA , \u03b2 \u03bb,+ A ] denote the interval of optimal selection rates for Equation (27) with regularization \u03bb. Finally, suppose that for any optimal MaxUtil selection rates (\u03b2\ndenote the optimal loan rates in (27). Then there exists a \u03bb * such that, for \u03bb \u2265 \u03bb * , [\u03b2 \u2212 A , \u03b2 + A ] coincides with the hard constrained solution. Moreover, for \u03bb < \u03bb * , any\nProof. Given a set of optimal constraint values (t A , t B ) = (T A ,w A (\u03b2 A ), T B ,w B (\u03b2 B )) for optimal selection rates (\u03b2 A , \u03b2 B ) for a given parameter \u03bb. By Proposition B.2 below, it follows that if t A = t B for all optimal solutions, then for all \u03bb \u2265 \u03bb, all optimal solutions must also have t A = t B . Hence, it suffices to show that (a) there exists a finite \u03bb such that all solutions must have t A = t B , and (b) if t A = t B , then the display in (B.1) holds.\nTo prove (a) and (b), suppose t A = t B . By Proposition B.2 below and the fact that T A ,w A (\u03b2 MaxUtil ) < T B ,w B (\u03b2 MaxUtil B ), we have t A < t B . Moreover we can compute that\nwhich immediately implies point (b). Point (a) follows from the above display by noting that, since w j (x) > 0 and u(x) < \u221e for all x, where exists a \u03bb sufficiently large such that (29) cannot hold for any \u03b2 A .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B.3 Qualitative Behavior of Soft Constraints", "text": "We now present a proposition which formalizes the intuition that soft constraints interpolate between MaxUtil and the general hard constraint ( 18) in Section 6.2 (for arbitrary w, not just for EqOpt). Because optimal policies may not be unique, we define the solution sets P(\u03bb) := {(\u03c4 A , \u03c4 B ) : (\u03c4 A , \u03c4 B ) solves ( 27) with parameter \u03bb} , with the set P(\u221e) denoting the set of solutions to (18). At a high level, we parameterize the soft constrained solution in terms of the value of the constraint t A = \u03c4 A , w A \u2022 \u03c0 A for A and the difference in constraint values \u2206 = \u03c4 A , w A \u2022 \u03c0 A \u2212 \u03c4 B , w B \u2022 \u03c0 B , where (\u03c4 A , \u03c4 B ) \u2208 P(\u03bb). We show that t A interpolates between the value of the constraint on A at \u03bb = 0 and at \u03bb = \u221e, and that \u2206 interpolates between the difference at \u03bb = 0 (MaxUtil) and at \u2206 = 0 at \u03bb = \u221e. To be rigorous, we note that the possible values for t A and \u2206 for each \u03bb are actually contiguous intervals. Hence, to make the interpolation precise, we define the following partial order on such intervals:\nIn these terms, the interpolation of the soft constraints can be stated as follows: 2. If 0 \u2208 D(\u03bb), then there exists a MaxUtil solution satisfying (18). Thus, for all \u03bb > 0, P(\u03bb) = P(\u221e). Again, we parameterize all solutions to the soft-constrained problem as in correspondence with solutions (t A , t B ) to\n.\nLetting \u2206 := t B \u2212 t A , we can reparameterize the above as\nNote then that D(\u03bb) denotes the set of \u2206 which are partial maximimizers of the above display. If 0 \u2208 {D(\u03bb)}, this implies that there exists a MaxUtil solution for which \u2206 = 0, therefore, for all \u03bb > 0, all solutions will be MaxUtil solutions for which D(\u03bb) = 0. Otherwise assume without loss of generality that D(\u03bb) < {0}.\nFirst, the statement {0} = D(\u221e) D(\u03bb) {min : \u2206 \u2208 D(0)}, and T A (\u221e) T A (\u03bb) {min : \u2206 \u2208 T A (\u03bb)}, and vice versa if D(\u03bb) {0} can be solved by on a case-by-case basis. The strategy is to show that if any of these inequalities are violated, then the associated values of \u2206 and t A are not partial maximizers of the soft constraint objective. In particular, T A (\u03bb) \u2282 [T \u2212 , T + ] for some appropriate T \u2212 , T + .\nWe now show that D(\u03bb) and T A (\u03bb) are non-increasing and non-decreasing, respectively. We shall do so invoking the following technical lemma.\ndenotes the super-gradient set of the concave mapping t \u2192 \u2202G 2 (t; \u03bb).\nThen if \u03bb \u2192 \u2202G 2 (t; \u03bb) is non-increasing (resp. non-decreasing) in \u03bb, the interval valued function defined below is non-increasing (resp. non-decreasing) in \u03bb\nFor D(\u03bb), one can write any partial maximizer \u2206 as\nconcave, being the partial maximization of a concave function, and \u2202G 2 (\u2206; \u03bb) = \u2212t\u2202\u03a6(\u2206). Since \u2202\u03a6(\u2206) {0} for \u2206 \u2265 0 (by convexity of \u03c6) , we have that \u2202G 2 (\u2206; \u03bb) = \u2212t\u2202\u03a6(\u2206) is non-increasing in \u03bb. Hence Lemma B.3 implies that interval valued function D(\u03bb) is non-increasing.\nTo show that T A (\u03bb) is non-decreasing, we have that any maximizer t A can be written as\nwhere G 1 (t A ) = g A U A (t A ; w A ) and G 2 (t A ; \u03bb) = max \u2206\u22650 g B U B (t A + \u2206; w B ) + \u03bb\u03a6(\u2206). By Danskin's theorem,\nNote that {\u2206 \u2208 arg max G 2 (t A ; \u03bb)} is non-increasing in \u03bb for a fixed t A , since the contribution of the regularizer increases. Since the sets \u2202U B (t A + \u2206; w B ) are themselves non-increasing in \u2206 by", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C.1 Proof of Proposition 3.1", "text": "The MaxUtil policy for group j solves the optimization max\nComputing left and right derivatives of this objective yields\nBy concavity, solutions \u03b2 * satisfy\nTherefore, we conclude that the MaxUtil policy loans only to scores x s.t. u(x) > 0, which implies \u2206(x) > 0 for all scores loaned to. Therefore we must have that 0 \u2264 \u2206\u00b5 MaxUtil . By definition \u2206\u00b5 MaxUtil \u2264 \u2206\u00b5 * .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C.2 Proof of Corollary 3.2", "text": "We begin with proving part (a), which gives conditions under which DemParity cases relative improvement. Recall that \u03b2 is the largest selection rate for which U(\u03b2) = U(\u03b2 MaxUtil", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A", "text": "). First, we derive a condition which bounds the selection rate \u03b2 DemParity A from below. Fix an acceptance rate \u03b2 such that \u03b2 MaxUtil A < \u03b2 < min{\u03b2 MaxUtil B , \u03b2}. By Theorem 6.1, we have that DemParity selects to group A with rate higher than \u03b2 as long as\n.\nBy (30) and the monotonicity of u, u(Q A (\u03b2)) < 0 and u(Q B (\u03b2)) > 0, so 0 < g 1 < 1. Next, we derive a condition which bounds the selection rate \u03b2 DemParity A from above. First, consider the case that \u03b2 MaxUtil B < \u03b2, and fix \u03b2 such that \u03b2 MaxUtil B < \u03b2 < \u03b2. Then DemParity selects group A at a rate \u03b2 A < \u03b2 for any proportion g A . This follows from applying Theorem 6.1 since we have that u(Q + A (\u03b2 )) < 0 and u(Q + B (\u03b2 )) < 0 by (30) and the monotonicity of u. Instead, in the case that\nThen DemParity selects group A at a rate less than \u03b2 as long as\n.\nBy (30) and the monotonicity of u, 0 < g 0 < g 1 . Thus for g A \u2208 [g 0 , g 1 ], the DemParity selection rate for group A is bounded between \u03b2 and \u03b2 , and thus DemParity results in relative improvement. Next, we prove part (b), which gives conditions under which EqOpt cases relative improvement. First, we derive a condition which bounds the selection rate \u03b2 EqOpt A from below. Fix an acceptance rate \u03b2 such that \u03b2 MaxUtil A < \u03b2 and \u03b2 MaxUtil B > G (A\u2192B) (\u03b2). By Theorem 6.2, EqOpt selects group A at a rate higher than \u03b2 as long as\n.\nBy ( 30) and the monotonicity of u, u(Q A (\u03b2)) < 0 and u(Q B (G (A\u2192B) (\u03b2))) > 0, so g 3 > 0.\nNext, we derive a condition which bounds the selection rate \u03b2 EqOpt A from above. First, consider the case that there exists \u03b2 such that \u03b2 < \u03b2 and \u03b2 MaxUtil B < G (A\u2192B) (\u03b2 ) . Then EqOpt selects group A at a rate less than this \u03b2 for any g A . This follows from Theorem 6.2 since we have that u(Q + A (\u03b2 )) < 0 and u(Q + B (G (A\u2192B) (\u03b2 ))) < 0 by (30) and the monotonicity of u. In the other case, fix \u03b2 such that \u03b2 < \u03b2 < \u03b2 and \u03b2 MaxUtil B > G (A\u2192B) (\u03b2 ). By Theorem 6.2, EqOpt selects group A at a rate lower than \u03b2 as long as\n.\nBy ( 30) and the monotonicity of u, 0 < g 2 < g 3 . Thus for g A \u2208 [g 2 , g 3 ], the EqOpt selection rate for group A is bounded between \u03b2 and \u03b2 , and thus EqOpt results in relative improvement.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C.3 Proof of Corollary 3.3", "text": "Recall our assumption that \u03b2 > \u03b2 MaxUtil A and \u03b2 MaxUtil B > \u03b2. As argued in the above proof of Corollary 3.2, by (30) and the monotonicity of u, u(Q A (\u03b2)) < 0 and u(Q B (\u03b2)) > 0. Applying Theorem 6.1, DemParity selects at a higher rate than \u03b2 for any population proportion g A \u2264 g 0 , where g 0 = 1/(1 \u2212 u(Q A (\u03b2)) u(Q B (\u03b2)) ) \u2208 (0, 1). In particular, if \u03b2 = \u03b2 0 , which we defined as the harm threshold (i.e. \u2206\u00b5 A (r \u22121 \u03c0 A (\u03b2 0 )) = 0 and \u2206\u00b5 A is decreasing at \u03b2 0 ), then by the concavity of \u2206\u00b5 A , we have that \u2206\u00b5 A (r \u22121 \u03c0 A (\u03b2 DemParity A\n)) < 0, that is, DemParity causes active harm.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C.4 Proof of Corollary 3.4", "text": "By Theorem 6.2, EqOpt selects at a higher rate than \u03b2 for any population proportion g A \u2264 g 0 , where\n, we have that u(Q B (G (A\u2192B) (\u03b2))) > 0 and u(Q A (\u03b2)) < 0, by (30) and the monotonicity of u. This verifies that g 0 \u2208 (0, 1). In particular, if \u03b2 = \u03b2 0 , then by the concavity of \u2206\u00b5 A , we have that \u2206\u00b5 A (r \u22121 \u03c0 A (\u03b2 EqOpt A\n)) < 0, that is, EqOpt causes active harm.\nC.5 Proof of Corollary 3.5\nApplying Theorem 6.1, we have\nApplying Theorem 6.2, we have:\nBy Corollaries 3.3 and 3.4, choosing g A < g 2 := 1/(1 \u2212 u(Q A (\u03b2)) u(Q B (\u03b2)) ) and\n) ) satisfies the above. It remains to check that g 1 < g 2 . Since we assumed \u03b2 > x>\u00b5 A \u03c0 A , we may apply Lemma C.2 to verify this.\nThus we indeed have sufficient conditions for \u03b2 DemParity > \u03b2 > \u03b2 EqOpt . In particular, if \u03b2 = \u03b2 0 , then by the concavity of \u2206\u00b5 A , we have that \u2206\u00b5 A (r \u22121 \u03c0 A (\u03b2\n)) > 0, that is, EqOpt causes improvement, and \u2206\u00b5 A (r \u22121 \u03c0 A (\u03b2 DemParity A\n)) < 0, that is, DemParity causes active harm. Lastly, because \u03b2 DemParity > \u03b2 EqOpt , it is always true that \u2206\u00b5 A (r \u22121 \u03c0 A (\u03b2\n)) > 0, using the concavity of the outcome curve. \nProof. If we have \u03b2 > x>\u00b5 A \u03c0 A , by lemma C.3, we must also have \u00b5 B \u00b5 A < Q B (\u03b2 0 ) Q A (\u03b2 0 ) . This implies \u03ba = x \u03c0 B (x)\u03c1(x)\nx \u03c0 A (x)\u03c1(x) < \u03c1(Q B (\u03b2)) \u03c1(Q A (\u03b2 0 )) by linearity of expectation and linearity of \u03c1. Therefore,\nFurther, using G (A\u2192B) (\u03b2) > \u03b2 from lemma C.3 and the fact that u(x) \u03c1(x) is increasing in x, we have\nwhere the last inequality follows from (31).\nWe use the following technical lemma in the proof of the above lemma.\nLemma C.3. If \u03c0 A , \u03c0 B that are identical up to a translation with \u00b5 A < \u00b5 B , then\nProof. For (32), observe that TPR A = \u03c1(\u00b5 A ) < TPR B = \u03c1(\u00b5 B ). For any \u03b2, we can write Q B (\u03b2) = \u00b5 B + c and Q A (\u03b2) = \u00b5 A + c for some c, since \u03c0 A , \u03c0 B that are identical up to translation by .\nWe now give a very simple example of \u03c0 A \u227a \u03c0 B where Theorem 3.5 holds. The construction of the example exemplifies the more general idea of using large in-group inequality in group A to skew the true positive rate at MaxUtil, making TPR A (\u03c4 MaxUtil ) > TPR B (\u03c4 MaxUtil ).\nExample C.1 (EqOpt causes relative harm). Let C = 6, and let the utility function be such that u(4) = 0. Suppose \u03c0 A (5) = 1 \u2212 2 , \u03c0 A (1) = 2 and \u03c0 B (5) = 1 \u2212 , \u03c0 B (3) = .\nWe can easily check that \u03c0 A \u227a \u03c0 B . However, for any \u2208 (0, 1/4), we have that TPR B (\u03c4 MaxUtil ) =\n5(1\u2212 ) 5(1\u2212 )+3 < TPR A (\u03c4 MaxUtil ) = 5(1\u22122 ) 5(1\u22122 )+2 .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C.7 Proof of Proposition 4.1", "text": "Denote the upper quantile function under \u03c0 as Q. Since \u03c0 \u227a \u03c0, we have Q(\u03b2) \u2264 Q(\u03b2). The conclusion follows for MaxUtil and DemParity from Theorem 6.1 by the monotonicity of u.\nIf we have that TPR A (\u03c4 ) > TPR A (\u03c4 ) \u2200 \u03c4 , that is, the true TPR dominates estimated TPR, the conclusion for EqOpt follows from Theorem 6.2, by the same argument as in the proof of Corollary 3.6. ", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Big data's disparate impact", "journal": "California Law Review", "year": "2016", "authors": "Solon Barocas; Andrew D Selbst"}, {"ref_id": "b1", "title": "Building classifiers with independency constraints", "journal": "", "year": "2009", "authors": "Toon Calders; Faisal Kamiran; Mykola Pechenizkiy"}, {"ref_id": "b2", "title": "Fair prediction with disparate impact: A study of bias in recidivism prediction instruments", "journal": "FATML", "year": "2016", "authors": "Alexandra Chouldechova"}, {"ref_id": "b3", "title": "Runaway feedback loops in predictive policing", "journal": "", "year": "2017", "authors": "Danielle Ensign; A Sorelle; Scott Friedler; Carlos Neville; Suresh Scheidegger;  Venkatasubramanian"}, {"ref_id": "b4", "title": "Executive Office of the President. Big data: A report on algorithmic systems, opportunity, and civil rights", "journal": "", "year": "2016-05", "authors": ""}, {"ref_id": "b5", "title": "An economic argument for affirmative action", "journal": "Rationality and Society", "year": "1992", "authors": "P Dean;  Foster; V Rakesh;  Vohra"}, {"ref_id": "b6", "title": "Predictably unequal? the effects of machine learning on credit markets", "journal": "", "year": "2017", "authors": "Andreas Fuster; Paul Goldsmith-Pinkham; Tarun Ramadorai; Ansgar Walther"}, {"ref_id": "b7", "title": "Equality of opportunity in supervised learning", "journal": "", "year": "2016", "authors": "Moritz Hardt; Eric Price; Nati Srebro"}, {"ref_id": "b8", "title": "A short-term intervention for long-term fairness in the labor market", "journal": "", "year": "2018", "authors": "Lily Hu; Yiling Chen"}, {"ref_id": "b9", "title": "Fairness in learning: Classic and contextual bandits", "journal": "", "year": "2016", "authors": "Matthew Joseph; Michael Kearns; Jamie H Morgenstern; Aaron Roth"}, {"ref_id": "b10", "title": "Best Practices or Best Guesses? Assessing the Efficacy of Corporate Affirmative Action and Diversity Policies", "journal": "American Sociological Review", "year": "2006", "authors": "Alexandra Kalev; Frank Dobbin; Erin Kelly"}, {"ref_id": "b11", "title": "Effects of affirmative action in medical schools", "journal": "New England Journal of Medicine", "year": "1985", "authors": "N Stephen; Robert M Keith; August G Bell; Albert P Swanson;  Williams"}, {"ref_id": "b12", "title": "Avoiding discrimination through causal reasoning", "journal": "", "year": "2017", "authors": "Niki Kilbertus; Mateo Rojas-Carulla; Giambattista Parascandolo; Moritz Hardt; Dominik Janzing; Bernhard Sch\u00f6lkopf"}, {"ref_id": "b13", "title": "Inherent trade-offs in the fair determination of risk scores", "journal": "", "year": "2017", "authors": "Jon M Kleinberg; Sendhil Mullainathan; Manish Raghavan"}, {"ref_id": "b14", "title": "Counterfactual fairness", "journal": "", "year": "2017", "authors": "Matt J Kusner; Joshua R Loftus; Chris Russell; Ricardo Silva"}, {"ref_id": "b15", "title": "Fair inference on outcomes", "journal": "", "year": "2017", "authors": "Razieh Nabi; Ilya Shpitser"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 :1Figure 1: The above figure shows the outcome curve. The horizontal axis represents the selection rate for the population; the vertical axis represents the mean change in score. (a) depicts the full spectrum of outcome regimes, and colors indicate regions of active harm, relative harm, and no harm. In (b): a group that has much potential for gain, in (c): a group that has no potential for gain.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Proposition 3.1 (MaxUtil does not cause active harm). Under Assumption 1, 0 \u2264 \u2206\u00b5 MaxUtil \u2264 \u2206\u00b5 * .", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 2 :2Figure 2: Both outcomes \u2206\u00b5 and institution utilities U can be plotted as a function of selection rate for one group. The maxima of the utility curves determine the selection rates resulting from various decision rules.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Corollary 3.2 (Fairness Criteria can cause Relative Improvement). (a) Under the assumption that \u03b2 MaxUtil A < \u03b2 and \u03b2 MaxUtil B > \u03b2 MaxUtil A , there exist population proportions", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Corollary 3.3 (DemParity can cause harm by being over-eager). Fix a selection rate \u03b2. Assume that \u03b2 MaxUtil B > \u03b2 > \u03b2 MaxUtil A . Then, there exists a population proportion g 0 such that, for all g A \u2208 [0, g 0 ], \u03b2 DemParity A > \u03b2. In particular, when \u03b2 = \u03b2 0 , DemParity causes active harm, and when \u03b2 = \u03b2, DemParity causes relative harm.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Corollary 3.4 (EqOpt can cause harm by being over-eager). Suppose that \u03b2 MaxUtil B > G (A\u2192B) (\u03b2) and \u03b2 > \u03b2 MaxUtil A . Then, there exists a population proportion g 0 such that, for all g A \u2208 [0, g 0 ], \u03b2 EqOpt A > \u03b2. In particular, when \u03b2 = \u03b2 0 , EqOpt causes active harm, and when \u03b2 = \u03b2, EqOpt causes relative harm.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Figure 3 :3Figure3: Considering the utility as a function of selection rates, fairness constraints correspond to restricting the optimization to one-dimensional curves. The DemParity (DP) constraint is a straight line with slope 1, while the EqOpt (EO) constraint is a curve given by the graph of G(A\u2192B)  . The derivatives considered throughout Section 6 are taken with respect to the selection rate \u03b2 A (horizontal axis); projecting the EO and DP constraint curves to the horizontal axis recovers concave utility curves such as those shown in the lower panel of Figure2(where MaxUtil in is represented by a horizontal line through the MU optimal solution).", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "Figure 4 :4Figure4: The empirical payback rates as a function of credit score and CDF for both groups from the TransUnion TransRisk dataset.", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "Figure 5 :5Figure 5: The empirical CDFs of both groups are plotted along with the decision thresholds resulting from MaxUtil, DemParity, and EqOpt for a model with bank utilities set to (a) u \u2212 u + = \u22124 and (b) u \u2212 u + = \u221210. The threshold for active harm is displayed; in (a) DemParity causes active harm while in (b) it does not. EqOpt and MaxUtil never cause active harm.", "figure_data": ""}, {"figure_label": "6", "figure_type": "figure", "figure_id": "fig_10", "figure_caption": "Figure 6 :6Figure6: The outcome and utility curves are plotted for both groups against the group selection rates. The relative positions of the utility maxima determine the position of the decision rule thresholds. We hold u \u2212 u + = \u22124 as fixed.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_11", "figure_caption": "1 = \u2202 + (\u03b2) = \u2202 + (r \u03c0 j (\u03c4 Q j (\u03b2),\u03b3(\u03b2) )) since r \u03c0 j (\u03c4 Q j (\u03b2),\u03b3(\u03b2) ) = \u03b2 \u2200\u03b2 \u2208 [0, 1) = \u2202 + x\u2208X \u03c0(x) \u2022 \u03c4 Q j (\u03b2),\u03b3(\u03b2) (x) = \u2202 + \u03c0(x) \u2022 \u03c4 Q j (\u03b2),\u03b3(\u03b2) (x)x=Q j (\u03b2) , as needed.B Characterization of Fairness Solutions B.1 Derivative Computation for EqOpt", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "Geoff Pleiss, Manish Raghavan, Felix Wu, Jon Kleinberg, and Kilian Q Weinberger. On fairness and calibration. In Advances in Neural Information Processing Systems 30, pages 5684-5693, 2017.Stephen Ross and John Yinger.The Color of Credit: Mortgage Discrimination, Research Methodology, and Fair-Lending Enforcement. MIT Press, Cambridge, 2006. US Federal Reserve. Report to the congress on credit scoring and its effects on the availability and affordability of credit, 2007. Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez Rogriguez, and Krishna P. Gummadi. Fairness Constraints: Mechanisms for Fair Classification. In Proc. 20th AISTATS, pages 962-970. PMLR, 2017.", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "U(\u03c4 ) = j\u2208{A,B} g j x\u2208X \u03c4 j (x)\u03c0 j (x)u(x).", "formula_coordinates": [5.0, 196.9, 348.4, 198.28, 12.26]}, {"formula_id": "formula_1", "formula_text": "\u2206(x) = c + \u03c1(x) + c \u2212 (1 \u2212 \u03c1(x))", "formula_coordinates": [6.0, 72.0, 156.77, 143.36, 10.67]}, {"formula_id": "formula_2", "formula_text": "\u03c0 A (\u03b2)) = \u2206\u00b5 A (r \u22121 \u03c0 A (\u03b2 MaxUtil )) with \u03b2 > \u03b2 MaxUtil .", "formula_coordinates": [7.0, 301.22, 648.29, 238.78, 14.67]}, {"formula_id": "formula_3", "formula_text": "x\u2208X \u03c0 A (x)\u03c4 A = x\u2208X \u03c0 B (x)\u03c4 B .", "formula_coordinates": [8.0, 224.64, 186.29, 163.88, 12.26]}, {"formula_id": "formula_4", "formula_text": "= x\u2208X \u03c0 j (x)\u03c1(x)\u03c4 (x)", "formula_coordinates": [8.0, 123.96, 211.55, 90.64, 13.98]}, {"formula_id": "formula_5", "formula_text": "C = {(\u03c4 A , \u03c4 B ) : TPR A (\u03c4 A ) = TPR B (\u03c4 B )} .", "formula_coordinates": [8.0, 123.3, 244.98, 204.58, 10.81]}, {"formula_id": "formula_6", "formula_text": "g 0 < g 1 < 1 such that, for all g A \u2208 [g 0 , g 1 ], \u03b2 MaxUtil A < \u03b2 DemParity A < \u03b2. That is, DemParity causes relative improvement. (b) Under the assumption that there exist \u03b2 MaxUtil A < \u03b2 < \u03b2 < \u03b2 such that \u03b2 MaxUtil B > G (A\u2192B) (\u03b2), G (A\u2192B) (\u03b2 ), there exist population proportions g 2 < g 3 < 1 such that, for all g A \u2208 [g 2 , g 3 ], \u03b2 MaxUtil A < \u03b2 EqOpt A < \u03b2. That is, EqOpt causes relative improvement.", "formula_coordinates": [9.0, 72.0, 399.22, 468.0, 67.88]}, {"formula_id": "formula_7", "formula_text": "\u03b2 > x>\u00b5 A \u03c0 A .", "formula_coordinates": [10.0, 274.9, 556.61, 62.21, 23.24]}, {"formula_id": "formula_8", "formula_text": "[g 1 , g 2 ] \u2286 [0, 1], such that \u2200g A > g 1 , \u03b2 EqOpt < \u03b2 while \u2200g A < g 2 , \u03b2 DemParity > \u03b2.", "formula_coordinates": [10.0, 72.0, 591.73, 468.0, 24.49]}, {"formula_id": "formula_9", "formula_text": "\u03b2 MaxUtil A < \u03b2 MaxUtil B and TPR A (\u03c4 MaxUtil ) > TPR B (\u03c4 MaxUtil ) (4", "formula_coordinates": [11.0, 156.81, 174.81, 378.54, 13.7]}, {"formula_id": "formula_10", "formula_text": ")", "formula_coordinates": [11.0, 535.35, 176.73, 4.65, 9.57]}, {"formula_id": "formula_11", "formula_text": "Then \u03b2 EqOpt A < \u03b2 MaxUtil A < \u03b2 DemParity A", "formula_coordinates": [11.0, 72.0, 198.29, 184.4, 15.47]}, {"formula_id": "formula_12", "formula_text": "max \u03c4 :=\u03c4 A ,\u03c4 B U(\u03c4 ) \u2212 \u03bb\u03a6( \u03c0 A , \u03c4 A \u2212 \u03c0 B , \u03c4 B ) ,(5)", "formula_coordinates": [11.0, 195.97, 476.99, 344.03, 16.59]}, {"formula_id": "formula_13", "formula_text": "x\u2265c \u03c0(x) \u2264 x\u2265c \u03c0(x) for all c \u2208 [C].", "formula_coordinates": [12.0, 83.52, 75.48, 184.43, 12.25]}, {"formula_id": "formula_14", "formula_text": "\u03b2 MaxUtil A > \u03b2 MaxUtil A and \u03b2 DemParity A > \u03b2 DemParity A", "formula_coordinates": [12.0, 72.0, 147.82, 228.35, 15.47]}, {"formula_id": "formula_15", "formula_text": "EqOpt A > \u03b2 EqOpt A .", "formula_coordinates": [12.0, 317.53, 163.1, 76.36, 15.47]}, {"formula_id": "formula_16", "formula_text": "\u03c4 A \u2206\u00b5 A (\u03c4 A ) s.t. U MaxUtil A \u2212 U(\u03c4 ) < \u03b4 .(6)", "formula_coordinates": [12.0, 212.9, 381.18, 327.1, 18.49]}, {"formula_id": "formula_17", "formula_text": "U j (\u03c4 j ) := x\u2208X \u03c0 j (x)\u03c4 j (x)u(x) ,(7)", "formula_coordinates": [12.0, 224.17, 673.25, 315.83, 22.29]}, {"formula_id": "formula_18", "formula_text": "\u03c4 c,\u03b3 = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 1, x > c \u03b3, x = c 0, x < c , for some c \u2208 [C] and \u03b3 \u2208 (0, 1] . (8", "formula_coordinates": [13.0, 177.57, 161.24, 357.78, 44.97]}, {"formula_id": "formula_19", "formula_text": ")", "formula_coordinates": [13.0, 535.35, 179.86, 4.65, 9.57]}, {"formula_id": "formula_20", "formula_text": "\u03c4 A \u223c = \u03c0 A \u03c4 A and \u03c4 B \u223c = \u03c0 B \u03c4 B .", "formula_coordinates": [13.0, 315.32, 314.47, 132.84, 15.32]}, {"formula_id": "formula_21", "formula_text": "r \u03c0 j (\u03c4 j ) := x\u2208X \u03c0 j (x)\u03c4 j (x) ,(9)", "formula_coordinates": [13.0, 233.17, 370.07, 306.83, 22.29]}, {"formula_id": "formula_22", "formula_text": "U j (\u03c4 j ) := x\u2208X u(x)\u03c0 j (x)\u03c4 j (x) ,(10)", "formula_coordinates": [13.0, 224.17, 615.67, 315.83, 22.29]}, {"formula_id": "formula_24", "formula_text": "x) = 0. Let \u03c0 \u2208 Simplex C\u22121 and fix t \u2208 [0, x\u2208X \u03c0(x) \u2022 w(x)]. Then any \u03c4 * \u2208 arg max \u03c4 \u2208[0,1] C v \u2022 \u03c0, \u03c4 s.t. \u03c0 \u2022 w, \u03c4 = t (12", "formula_coordinates": [14.0, 72.0, 366.44, 468.0, 57.64]}, {"formula_id": "formula_25", "formula_text": ")", "formula_coordinates": [14.0, 535.15, 406.91, 4.85, 9.57]}, {"formula_id": "formula_26", "formula_text": "C x=c \u03c0 j (x) \u2265 \u03b2} . (13", "formula_coordinates": [15.0, 422.79, 168.34, 112.37, 33.17]}, {"formula_id": "formula_27", "formula_text": ")", "formula_coordinates": [15.0, 535.15, 179.97, 4.85, 9.57]}, {"formula_id": "formula_28", "formula_text": "\u2202 \u2212 f (x) := lim t\u21920 \u2212 f (x + t) \u2212 f (x) t and \u2202 + f (y) := lim t\u21920 + f (y + t) \u2212 f (y) t . (14", "formula_coordinates": [15.0, 123.45, 290.79, 411.7, 24.43]}, {"formula_id": "formula_29", "formula_text": ")", "formula_coordinates": [15.0, 535.15, 298.17, 4.85, 9.57]}, {"formula_id": "formula_30", "formula_text": "For f supported on [a, b], we say that f is left-(resp. right-) differentiable if \u2202 \u2212 f (x) exists for all x \u2208 (a, b] (resp. \u2202 + f (y) exists for all y \u2208 [a, b)).", "formula_coordinates": [15.0, 72.0, 327.3, 468.0, 24.18]}, {"formula_id": "formula_31", "formula_text": "\u03c0 j \u2022 r \u22121 \u03c0 j (\u03b2) : [0, 1] \u2192 [0, 1] C", "formula_coordinates": [15.0, 72.0, 388.51, 128.41, 14.61]}, {"formula_id": "formula_32", "formula_text": "\u2202 + \u03c0 j \u2022 r \u22121 \u03c0 j (\u03b2) = e Q(\u03b2) and \u2202 \u2212 \u03c0 j \u2022 r \u22121 \u03c0 j (\u03b2) = e Q + (\u03b2) . (15", "formula_coordinates": [15.0, 150.65, 417.68, 384.5, 15.16]}, {"formula_id": "formula_33", "formula_text": ")", "formula_coordinates": [15.0, 535.15, 420.18, 4.85, 9.57]}, {"formula_id": "formula_34", "formula_text": "Proposition 5.3. Let \u03c0 be a distribution over C states. Then \u03b2 \u2192 \u2206\u00b5(r \u22121 \u03c0 (\u03b2)) is concave. In fact, if w(x) is any non-decreasing map from X \u2192 R, \u03b2 \u2192 w, r \u22121 \u03c0 (\u03b2) is concave.", "formula_coordinates": [15.0, 72.0, 480.91, 468.0, 27.19]}, {"formula_id": "formula_35", "formula_text": "right-differentiable, (b) for all x \u2208 (a, b), \u2202 \u2212 f (x) \u2265 \u2202 + f (x) and (c) for any x > y, \u2202 \u2212 f (x) \u2264 \u2202 + f (y). Observe that \u2206\u00b5(r \u22121 \u03c0 (\u03b2)) = \u2206, \u03c0 \u2022 r \u22121 \u03c0 (\u03b2) . By Lemma 5.3, \u03c0 \u2022 r \u22121 \u03c0 (\u03b2)", "formula_coordinates": [15.0, 72.0, 532.48, 468.0, 25.24]}, {"formula_id": "formula_36", "formula_text": "\u2202 + \u2206\u00b5(\u03b2 B ) = \u2206(Q(\u03b2 B )) and \u2202 \u2212 \u2206\u00b5(\u03b2 B ) = \u2206(Q + (\u03b2 B )) . (16", "formula_coordinates": [15.0, 156.81, 582.68, 378.34, 13.27]}, {"formula_id": "formula_37", "formula_text": ")", "formula_coordinates": [15.0, 535.15, 585.17, 4.85, 9.57]}, {"formula_id": "formula_38", "formula_text": "\u2202 + \u2206\u00b5(f \u22121 \u03c0 (\u03b2 B )) \u2264 \u2202 \u2212 \u2206\u00b5(f \u22121 \u03c0 (\u03b2 B )", "formula_coordinates": [15.0, 391.9, 607.73, 163.51, 13.65]}, {"formula_id": "formula_39", "formula_text": "max \u03c4 =(\u03c4 A ,\u03c4 B )\u2208[0,1] 2C U(\u03c4 ) s.t. \u03c0 A , \u03c4 A = \u03c0 B , \u03c4 B .", "formula_coordinates": [16.0, 178.16, 553.81, 235.75, 18.22]}, {"formula_id": "formula_40", "formula_text": "max \u03c4 =(\u03c4 A ,\u03c4 B )\u2208[0,1] 2C ,\u03b2\u2208[0,1] U(\u03c4 ) s.t. \u03b2 = \u03c0 j , \u03c4 j , j \u2208 {A, B} .", "formula_coordinates": [16.0, 156.63, 636.73, 278.81, 18.31]}, {"formula_id": "formula_41", "formula_text": "max \u03b2\u2208[0,1] U r \u22121 \u03c0 A (\u03b2), r \u22121 \u03c0 B (\u03b2) . (17", "formula_coordinates": [17.0, 229.26, 187.78, 305.89, 19.29]}, {"formula_id": "formula_42", "formula_text": ")", "formula_coordinates": [17.0, 535.15, 190.28, 4.85, 9.57]}, {"formula_id": "formula_43", "formula_text": "forms a continuous interval [\u03b2 \u2212 DemParity , \u03b2 + DemParity ], such that for any \u03b2 \u2208 [0, 1], we have \u03b2 < \u03b2 \u2212 DemParity if g A u (Q A (\u03b2)) + g B u (Q B (\u03b2)) > 0 , \u03b2 > \u03b2 + DemParity if g A u Q + A (\u03b2) + g B u Q + B (\u03b2) < 0 .", "formula_coordinates": [17.0, 72.0, 281.27, 414.88, 59.11]}, {"formula_id": "formula_44", "formula_text": "U r \u22121 \u03c0 A (\u03b2), r \u22121 \u03c0 B (\u03b2) = g A u, \u03c0 A \u2022 r \u22121 \u03c0 A (\u03b2) + g B u, \u03c0 B \u2022 r \u22121 \u03c0 B (\u03b2) . Since u(x) is non-decreasing in x, Proposition 5.3 implies that \u03b2 \u2192 U r \u22121 \u03c0 A (\u03b2), r \u22121 \u03c0 B (\u03b2) is concave in \u03b2.", "formula_coordinates": [17.0, 72.0, 390.91, 468.0, 50.12]}, {"formula_id": "formula_45", "formula_text": "\u2202 + U r \u22121 \u03c0 A (\u03b2), r \u22121 \u03c0 B (\u03b2) = \u2202 + g A u, \u03c0 A \u2022 r \u22121 \u03c0 A (\u03b2) + \u2202 + g B u, \u03c0 B \u2022 r \u22121 \u03c0 B (\u03b2) = g A u, \u2202 + \u03c0 A \u2022 r \u22121 \u03c0 A (\u03b2) + g B u, \u2202 + \u03c0 B \u2022 r \u22121 \u03c0 B (\u03b2) Lemma 5.3 = g A u, e Q A (\u03b2) + g B u, e Q B (\u03b2) = g A u(Q A (\u03b2)) + g B u(Q B (\u03b2)) .", "formula_coordinates": [17.0, 100.07, 467.03, 402.62, 68.35]}, {"formula_id": "formula_46", "formula_text": "\u2202 \u2212 U((r \u22121 \u03c0 A (\u03b2), r \u22121 \u03c0 B (\u03b2))) = g A u(Q + A (\u03b2)) + g B u(Q + B (\u03b2)).", "formula_coordinates": [17.0, 169.44, 571.04, 253.19, 15.29]}, {"formula_id": "formula_47", "formula_text": "max \u03c4 =(\u03c4 A ,\u03c4 B )\u2208[0,1] 2C U(\u03c4 ) s.t. w A \u2022 \u03c0 A , \u03c4 A = w B \u2022 \u03c0 B , \u03c4 B ,(18)", "formula_coordinates": [18.0, 151.74, 190.44, 388.27, 18.22]}, {"formula_id": "formula_48", "formula_text": "max t\u2208[0,tmax] max (\u03c4 A ,\u03c4 B )\u2208[0,1] 2C j\u2208{A,B} g j U j (\u03c4 j ) s.t. w j \u2022 \u03c0 j , \u03c4 j = t, j \u2208 {A, B} ,(19)", "formula_coordinates": [18.0, 124.29, 290.26, 415.71, 22.91]}, {"formula_id": "formula_49", "formula_text": "\u03c4 j \u2208[0,1] C j\u2208{A,B} g j U j (\u03c4 j ) s.t. w j \u2022 \u03c0 j , \u03c4 j = t .(20)", "formula_coordinates": [18.0, 184.56, 380.6, 355.45, 22.83]}, {"formula_id": "formula_50", "formula_text": "T j ,w j (\u03b2) := r \u22121 \u03c0 j (\u03b2), \u03c0 j \u2022 w j is a bijection from [0, 1] to [0, \u03c0 j , w ].", "formula_coordinates": [18.0, 72.0, 563.76, 285.22, 37.71]}, {"formula_id": "formula_51", "formula_text": "t\u2208[0,tmax] j\u2208{A,B} g j U j r \u22121 \u03c0 j T \u22121 j ,w j (t) .(21)", "formula_coordinates": [18.0, 207.7, 655.8, 332.31, 25.29]}, {"formula_id": "formula_52", "formula_text": "\u03b2 < \u03b2 \u2212 EqOpt if g A u(Q A (\u03b2)) w A (Q A (\u03b2)) + g B u(Q B (G (A\u2192B) w (\u03b2))) w B (Q B (G (A\u2192B) w (\u03b2))) > 0 , \u03b2 > \u03b2 + EqOpt if g A u(Q + A (\u03b2)) w A (Q + A (\u03b2)) + g B u(Q + B (G (A\u2192B) w (\u03b2))) w B (Q + B (G (A\u2192B) w (\u03b2))) < 0 .", "formula_coordinates": [19.0, 157.5, 176.79, 297.0, 70.91]}, {"formula_id": "formula_53", "formula_text": "(A\u2192B) w (\u03b2) := T \u22121 B,w B (T \u22121 A,w A (\u03b2)", "formula_coordinates": [19.0, 110.17, 258.65, 132.75, 17.28]}, {"formula_id": "formula_54", "formula_text": "A := r \u22121 \u03c0 A (\u03b2 A ) and \u03c4 * B := r \u22121 \u03c0 B (\u03b2 B ) satisfy the constraint in (18).", "formula_coordinates": [19.0, 72.0, 275.6, 468.0, 25.07]}, {"formula_id": "formula_55", "formula_text": "\u2202 + j\u2208{A,B} g j U j r \u22121 \u03c0 j (T \u22121 j ,w j (t)) = g A \u2202 + U A r \u22121 \u03c0 A (T \u22121 A ,w A (t)) + g A \u2202 + U A r \u22121 \u03c0 A (T \u22121 A ,w A (t)) = g A u(Q A (T \u22121 A ,w A (t))) w A (Q A (T \u22121 A ,w A (t))) + g B u(Q B (T \u22121 B ,w B (t))) w B (Q B (T \u22121 B ,w B (t)))", "formula_coordinates": [19.0, 102.32, 379.0, 400.55, 61.03]}, {"formula_id": "formula_56", "formula_text": "\u2202 \u2212 j\u2208{A,B} g j U j r \u22121 \u03c0 j (T \u22121 j ,w j (t)) = g A u(Q + A (T \u22121 A ,w A (t)) w A (Q + A (T \u22121 A ,w A (t))) + g B u(Q + B (T \u22121 B ,w B (t))) w B (Q + B (T \u22121 B ,w B (t)))", "formula_coordinates": [19.0, 110.93, 471.99, 366.0, 33.87]}, {"formula_id": "formula_57", "formula_text": "B (t) = G (A\u2192B) w (\u03b2).", "formula_coordinates": [19.0, 177.31, 571.84, 85.88, 16.46]}, {"formula_id": "formula_58", "formula_text": "r \u03c0 (\u03c4 j ) \u2212 r \u03c0 j (\u03c4 j ) = x\u2208X \u03c0 j (x)(\u03c4 j (x) \u2212 \u03c4 j (x)) = x\u2208S \u03c0 j (x)(\u03c4 j (x) \u2212 \u03c4 j (x)) = 0 .", "formula_coordinates": [25.0, 184.18, 351.8, 243.65, 52.59]}, {"formula_id": "formula_59", "formula_text": "0 = r \u03c0 (\u03c4 j ) \u2212 r \u03c0 j (\u03c4 j ) = \u03c0(x)(\u03c4 j (c) \u2212 \u03c4 j (c)) .", "formula_coordinates": [25.0, 206.64, 484.9, 206.06, 11.73]}, {"formula_id": "formula_60", "formula_text": "0 = r \u03c0 (\u03c4 j ) \u2212 r \u03c0 j (\u03c4 j ) = x\u2208S \u03c0 j (x)(\u03c4 j (x) \u2212 \u03c4 j (x)) \u2265 min x\u2208S (\u03c4 j (c) \u2212 \u03c4 j (x)) \u2022 x\u2208S \u03c0(x) .", "formula_coordinates": [25.0, 231.89, 623.29, 175.49, 72.25]}, {"formula_id": "formula_61", "formula_text": "C x=c \u03c0(x) > \u03b2} . Since \u03b2 < 1, Q j (\u03b2) \u2264 C. Let \u03b2 + = C", "formula_coordinates": [26.0, 72.0, 172.72, 309.61, 58.39]}, {"formula_id": "formula_62", "formula_text": "\u03b2 + \u2212 \u03b2 \u2212 = \u03c0(Q j (\u03b2)). Hence, if we define \u03b3 = \u03b2\u2212\u03b2 \u2212 \u03b2 + \u2212\u03b2 \u2212 , we have r \u03c0 j (\u03c4 Q j (\u03b2),\u03b3 ) = \u03c0(Q j (\u03b2))\u03b3 + C x=Q j (\u03b2)+1 \u03c0(x) = \u03b2 \u2212 + (\u03b2 + \u2212 \u03b2 \u2212 )\u03b3 = \u03b2 \u2212 + \u03b2 \u2212 \u03b2 \u2212 = \u03b2 . A.2 Proof of Lemma 5.2 Given \u03c4 \u2208 [0, 1] C , we define the normal cone at \u03c4 as NC(\u03c4 ) := ConicalHull{z : \u03c4 + z \u2208 [0, 1] C }.", "formula_coordinates": [26.0, 72.0, 234.69, 468.0, 121.08]}, {"formula_id": "formula_63", "formula_text": "NC(\u03c4 ) := {z \u2208 R C : z i \u2264 0 if \u03c4 i = 0, z i \u2265 0 if \u03c4 i = 1} .", "formula_coordinates": [26.0, 164.77, 381.77, 262.53, 13.13]}, {"formula_id": "formula_64", "formula_text": "\uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 \u03c4 (x) = 0 g(x) < 0 \u03c4 (x) = 1 g(x) > 0 \u03c4 (x) \u2208 [0, 1] g(x) = 0 .(22)", "formula_coordinates": [26.0, 358.3, 444.89, 181.7, 44.97]}, {"formula_id": "formula_65", "formula_text": "z, v \u2022 \u03c0 + \u03bb\u03c0 \u2022 w \u2264 0 . By (22), we must have that \u03c4 * (x) = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 0 \u03c0(x)(v(x) + \u03bbw(x)) < 0 1 \u03c0(x)(v(x) + \u03bbw(x)) > 0 \u2208 [0, 1] \u03c0(x)(v(x) + \u03bbw(x)) = 0 . Now \u03c4 * (x)", "formula_coordinates": [26.0, 72.0, 543.34, 333.28, 118.77]}, {"formula_id": "formula_66", "formula_text": "\u03c4 * (x) = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 0 x < c * \u03c4 * (x) x = c * 1 x > c * ,", "formula_coordinates": [27.0, 231.9, 112.23, 128.27, 46.04]}, {"formula_id": "formula_67", "formula_text": "\u2202 + \u03c0 j \u2022 r \u22121 \u03c0 j (\u03b2) = e Q j (\u03b2) ,(23)", "formula_coordinates": [27.0, 231.7, 260.14, 308.3, 15.16]}, {"formula_id": "formula_68", "formula_text": "\u03b2 + = C x=Q j (\u03b2) \u03c0(x) and \u03b2 \u2212 = C x=Q j (\u03b2)+1 \u03c0(x) ,(24)", "formula_coordinates": [27.0, 206.79, 365.7, 333.21, 35.39]}, {"formula_id": "formula_69", "formula_text": "\u03b3(\u03b2) = \u03b2 \u2212 \u03b2 \u2212 \u03b2 + \u2212 \u03b2 \u2212 . (25", "formula_coordinates": [27.0, 206.79, 406.29, 328.36, 25.5]}, {"formula_id": "formula_70", "formula_text": ")", "formula_coordinates": [27.0, 535.15, 413.67, 4.85, 9.57]}, {"formula_id": "formula_72", "formula_text": "\u2202 + \u03c0 j \u2022 r \u22121 \u03c0 j (\u03b2) = \u2202 + \u03c0 j (x)\u03c4 Q j (\u03b2),\u03b3(\u03b2) (x) x=Q j (\u03b2) \u2022 e Q j (\u03b2) .", "formula_coordinates": [27.0, 167.77, 559.01, 256.53, 16.78]}, {"formula_id": "formula_73", "formula_text": "\u03c0 j T \u22121 j ,w j (t)", "formula_coordinates": [28.0, 302.58, 309.46, 53.28, 15.16]}, {"formula_id": "formula_74", "formula_text": "\u2202 + T \u22121 j ,w j (t) = 1 \u2202 + T j ,w j (\u03b2) \u03b2=T \u22121 j ,w j (t) =", "formula_coordinates": [28.0, 169.4, 527.13, 167.53, 31.76]}, {"formula_id": "formula_75", "formula_text": "\u2202 \u2212 G 1 (t) + \u2202G 2 (t; \u03bb) \u2212 \u2265 0 \u2265 \u2202 + G 1 (t) + \u2202G 2 (t; \u03bb) +", "formula_coordinates": [33.0, 176.39, 205.35, 238.79, 10.63]}, {"formula_id": "formula_76", "formula_text": "\u2202 + G 1 (t) + \u2202G 2 (t; \u03bb ) + > 0 .", "formula_coordinates": [33.0, 230.73, 295.02, 130.62, 10.63]}, {"formula_id": "formula_77", "formula_text": "\u2202 + G 1 (t) + \u2202G 2 (t; \u03bb ) + \u2264 \u2202 + G 1 (t) + \u2202 + G 2 (t; \u03bb) \u2212 0 \u2264 0 , a contradiction.", "formula_coordinates": [33.0, 72.0, 344.03, 353.77, 34.08]}], "doi": ""}