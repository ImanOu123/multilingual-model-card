{"title": "Tracking in Low Frame Rate Video: A Cascade Particle Filter with Discriminative Observers of Different Lifespans", "authors": "Yuan Li; Haizhou Ai; Takayoshi Yamashita; Shihong Lao; Masato Kawade", "pub_date": "", "abstract": "Tracking object in low frame rate video or with abrupt motion poses two main difficulties which conventional tracking methods can barely handle: 1) poor motion continuity and increased search space; 2) fast appearance variation of target and more background clutter due to increased search space. In this paper, we address the problem from a view which integrates conventional tracking and detection, and present a temporal probabilistic combination of discriminative observers of different lifespans. Each observer is learned from different ranges of samples, with different subsets of features, to achieve varying level of discriminative power at varying cost. An efficient fusion and temporal inference is then done by a cascade particle filter which consists of multiple stages of importance sampling. Experiments show significantly improved accuracy of the proposed approach in comparison with existing tracking methods, under the condition of low frame rate data and abrupt motion of both target and camera.", "sections": [{"heading": "Introduction", "text": "Tracking in low frame rate (LFR) video is a practical requirement of many of today's real-time applications such as in micro embedded systems and visual surveillance. The reason is various: hardware costs, LFR data source, online processing speed which upper-bounds the frame rate, etc. Moreover, for a tracking system, LFR condition is equivalent to abrupt motion, which is often encountered but hard to cope with.\nAlthough the body of literature regarding tracking is huge, most existing approaches (except a few categories) cannot be readily applied to LFR tracking problems, either because of the slow speed or the vulnerability to motion and appearance discontinuity caused by LFR data.\nThe key notion of our solution is that detection and tracking can be integrated to overcome this difficulty. As two extremes, conventional tracking facilitates itself with every possible assumption of temporal continuity, while detection\n#1 #2 #3 #4\n(a) CONDENSATION.\n(b) Multi-scale Kanade-Lucas-Tomasi feature tracker (implemented by [3]).\n(c) Our approach (yellow rectangle denotes target in the previous frame). aims at the universal description or discrimination of the target from the others. In LFR tracking, the continuity of target is often too weak for conventional tracking (Figure 1); meanwhile, applying reliable detection over a large search space is often unaffordable, neither is it capable of identifying target through frames due to neglect of context. Therefore it is desirable to have the two complementing each other -achieving strong discriminative power yet maintaining the grasp of weak spatial-temporal continuity. We approach this by adopting a series of observation models (observers) with different \"lifespan\"s. By \"lifespan\" we mean the learning period and service period of an observer. E.g., a two-frame template matching tracker can be viewed as an observer with learning period and service period both of one frame; and an offline trained detector can be view as one with a very long lifespan, in the sense that it is trained by as many exemplars as possible and is expected to apply to most sorts of appearance that belong to the target category (e.g., face). The advantage lies in that observers with shorter lifespan can grab target appearance more specifically and rule out non-target candidates faster, the training cost is also lower since there is not much knowledge to mas-ter; while those with longer lifespan can produce more accurate result and prevent the \"drift\" problem which is typical of an online learning system.\nFurther in organizing these observers, rather than adopting a cascade (which is a common approach in detection literature, however problematic in our approach as will be shown) and a standard particle filter (which is also one of the most celebrated tracking frameworks), we instead propose a \"cascade particle filter\" in the hope of combining the two successful ideas in both fields to satisfy the special needs of our particular problem.\nIn the next section, related work is briefly summarized. Section 3 is devoted to the learning of different observers. Section 4 first introduces the common approach of particle filter and reveals its deficiency in the view of LFR issue, and then describes the cascade particle filter and compares it with existing methods. After that are the experiment and conclusion sections.", "publication_ref": ["b2"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Related work", "text": "LFR is in most cases equivalent to abrupt motion. However, a large part of traditional tracking approaches heavily depend on motion continuity. Particle filters [10] uses a dynamic model to guide the particle propagation within a limited sub-space of target state. Other methods based on iterative optimization such as mean shift [4] and Kanade-Lucas-Tomasi feature tracker [17] generally require the kernels or feature patches in consecutive frames to overlap with or be in a very close vicinity of each other. These, however, are presumptions too expensive under conditions of LFR or abrupt motion.\nSeveral existing publications have been aware of this pitfall, may the motive be LFR tracking or not, the remedy has been quite unanimous: detection. Okuma et al. [14] uses a boosted detector to amend the trial distribution of particle filter. Such mixture trial distribution can also be found in many other works such as [12], although not aimed at LFR videos. Porilkli and Tuzel [15] extend the standard mean shift technique by optimizing around multiple kernels at motion areas detected by background modeling, to track in 1-fps camera-fixed surveillance video. These ideas can be concluded as using an independent detector to guide the search of an existing tracker when target motion becomes unpredictable.\nAnother extreme is to \"detect and connect\" [7][11]. Such approaches are of potential to deal with LFR tracking, because they first detect the objects of interest (sometimes track them through short sequences), and then construct trajectories (or connect trajectory fragments) by analysis of motion continuity, appearance similarity, etc. Real-time algorithms of this category are mostly limited in backgroundfixed scenes where a fast change detector is readily at hand. The two categories above has a common drawback that  they need a detector fast enough to be applied to large search areas (in most cases, the whole frame), partly because the detector is only loosely coupled with the tracker.\nThe seemingly most similar work to ours may be the multi-scale approaches for abrupt motion [8][3] and layered sampling of multi-scale likelihoods [16]. However, multiscale approaches adopt essentially the same observation model on several down-scaled images, while our approach applies a pipeline of complementary observation models on the same image space. The latter's advantage lies in that discriminative power is increased and no risk of losing image information in down-scaling is induced.\nRecently there has been a trend of introducing learning techniques into tracking problems, and tracking is viewed as a classification problem in the sense of distinguishing tracking target from the background. Representative publications include [2] [19], which have shown increased discriminative power of the tracker. Although none of them have targeted at LFR tracking, we will also incorporate online learning in our approach, only that online classifiers will be unified with offline ones to achieve enhanced robustness.", "publication_ref": ["b9", "b3", "b16", "b13", "b11", "b14", "b15", "b1", "b18"], "figure_ref": [], "table_ref": []}, {"heading": "Learning discriminative observers", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Representation", "text": "Following the convention of sequential Bayesian estimation, denote the state of the target object and the observation at time t by x t and z t respectively (in this section we suppress the subscript t when there is no ambiguity). In the case of face tracking, we define x = (x, y, s), namely the position and size. An observer outputs p(z|x) for each input candidate x. Since we adopt m observers, it is convenient to define z = (z 1 , . . . , z m ), and denote the output of the k-th observer as p(z k |x).\nFurther, each observer here is represented by its learner L, training sample set S, feature pool F for learning, as well as the time complexities: offline training complexity \u03c4 off , online training complexity \u03c4 on and testing complexity \u03c4 test (defined as the time to calculate p(z|x) for each x). Therefore we formalize the k-th observer as\nO k = (L k , F k , S k , \u03c4 k,on , \u03c4 k,off , \u03c4 k,test ).(1)\nDenote the features selected by L k asF k (\u2282 F k ), and S k as the test samples input to the k-th observer (the output    \nO(|F 1 | 2 |S 1 |) O(|F 2 | 2 |S 2 | + |S 2 |P 2 ) 0 \u03c4 k,off Negligible Negligible Several days \u03c4 k,test O(|F 1 |) O(|F 2 |) O(|F 3 |)\n\u03c4 online = m k=1 (\u03c4 k,on + |\u015c k | \u2022 \u03c4 k,test ).(2)\nFor tracking, \u03c4 online is of first concern. Notice that both training time (\u03c4 k,on + \u03c4 k,off ) and testing time \u03c4 k,test increase with an observer's lifespan, since training sample number |S k | accumulates and a larger F k (also a more sophisticated L k ) is required to learn the knowledge provided by S k , and the resultingF k is also larger.\nTherefore, to minimize the testing part in (3) it is desirable to arrange the observers in a lifespan-ascending order so that |\u015c \n1 | < |\u015c 2 | < \u2022 \u2022 \u2022 < |\u015c m | (", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Configuration and learning", "text": "Based on the above analysis, different settings for each observation model is carefully chosen to balance effectiveness and efficiency -in other words, each learner L k and feature pool F k should be competent yet not \"over-qualified\" for the learning task on sample set S k . Table 1 gives a summary.\nFeature Sharing (Figure 3) is a distinct feature to be introduced before each observer. We use a Haar-like feature set extended from that of [18]. Calculation of such features is extremely efficient, on the premise that a pyramid of first-and second-order integral images has been built, which is relatively time-consuming in a real-time system. This makes feature sharing a reasonable choice. Feature pool for each observer is selected by offline learning. All observers work on grayscale data.\nObserver 1 is an LDA classifier learned on all samples from the previous frame, using only 5 Haar-like features for fast elimination of non-target. Denote the LDA projection vector as w, the 5d feature vector as f (x) and the classification threshold as \u03b7, the observation likelihood is modeled as a sigmoid function based on the classifier's output:\np(z 1 |x) \u221d 1 1 + exp (\u2212(w T f (x) \u2212 \u03b7)) . (4\n)\nObserver 2 is a strong classifier boosted from a pool of LDA classifiers. At each frame t, with the samples S 2 = (S 2,pos , S 2,neg ) gathered from the past 5 frames, the learning process is \np(z 2 |x) \u221d 1 1 + exp \u2212 P p \u03b1psign(w T p fp(x)\u2212\u03b7p) P p \u03b1p . (5\n)\nObserver 3 is a tree-structured detector similar to [9]. Each tree node is a strong classifier boosted from histogram weak classifiers. Since it consists of multiple layers, for an input x, the output is the number of layers h that x passes and the confidence c given by the last strong classifier it passed. The observation likelihood is defined as\np(z 3 |x) \u221d 1/ (1 + \u03c6 h exp(\u2212c)) ,(6)\nwhere \u03c6 h is the a priori ratio of negative samples to positive samples for the h-th layer (obtained during training process). It decreases as h increases to reflect the fact that the more layers x passes, the more likely it is the true target.\nThe elements of learning techniques chosen here are well-established and we would not elaborate on them. However, why they are chosen is paid much consideration and has withstood extensive experiments. E.g., while both Observer 2 and 3 adopt boosting algorithms, the differences between them is meaningful: for Observer 2 we use a much smaller weak classifier pool and Discrete AdaBoost instead of Real AdaBoost, so that both the training time and the risk of over-fitting on small online training set are reduced; on the other hand, since the number of weak classifiers is limited, 10d LDA is adopted to compound simple Haar-like features into more powerful descriptors to guarantee quick training convergence.", "publication_ref": ["b17", "b8"], "figure_ref": ["fig_2"], "table_ref": ["tab_2"]}, {"heading": "Cascade particle filter", "text": "In this section we first reveal the deficiency of the common approach of particle filter in case of LFR, then describe how the above observers can be coupled tightly together in cascade particle filter to tackle our problem.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Particle filter under unpredictable motion", "text": "By our notation for target state and observation, the aim of a tracking system is to estimate p(x t |Z t ), which stands for the distribution of target state given all observations Z t = (z 1 , . . . , z t ) up to time t. Particle filter (PF, or CON-DENSATION [10]) simulates this distribution by the wellknown two-step recursion:\nPrediction : p(x t |Z t\u22121 ) = p(x t |x t\u22121 )p(x t\u22121 |Z t\u22121 )dx t\u22121 , Update : p(x t |Z t ) \u221d p(z t |x t )p(x t |Z t\u22121 ).(7)\nCalculation of the integral is carried out by importance sampling, which means samples are generated from a trial distribution. A common practice is to use a presumed p(x t |x t\u22121 ) as the trail.\nBut when target motion becomes drastic and unpredictable (e.g., under LFR conditions), such trial distribution will result in gradual departure of the sample set from the true target state which eventually leads to tracking loss (Figure 1(a)). It may be remedied by increasing samples -decreasing efficiency at the mean time. Another choice is to introduce p(z t |x t ) into the trail [14] [12], which requires calculation of p(z t |x t ) over large state space. Therefore, under both choices, the system's efficiency degrades towards exhaustive calculation of p(z t |x t ) under unpredictable motion. This problem looms as long as only one computation-intensive p(z t |x t ) is available. So how can we overcome this when multiple observers are available?", "publication_ref": ["b9", "b13", "b11"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Cascade particle filter", "text": "Denote the observation vector as z = (z 1 , . . . , z m ), assuming independency among the observers will grant us:\np(z|x) = p(z 1 , . . . , z m |x) = m k=1 p(z k |x).(8)\nA standard PF can be directly adopted by updating particle weight by m k=1 p(z k |x). But besides what we have analyzed in the above subsection, it is also particularly inefficient here because every particle must be evaluated by every classifier while most of them end up with a weight close to zero (a comparison based on Effective Sample Size [13] will illustrate this point in the next section). In the detection problem, the cascade detector has been invented for this very reason. However, the conventional cascade detector can only be viewed as an extreme case where each p(z i |x) either takes the value 0 or 1, and those x with p(z|x) > 0 are classified as positive. And detection using such classifier structure by exhaustive search is like uniformly scattering particles over the whole state space of x.\nTo overcome the deficiencies of standard PF and cascade detector while combining their merits, our method melts a series of observers into multiple stages of importance sampling (IS). Define\n\u03c0 0 (x t ) = p(x t |Z t\u22121 ),(9)\n\u03c0 k (x t ) = p(z k,t |x t )\u03c0 k\u22121 (x t ), k = 1..m.(10)\nBy this definition we also have\n\u03c0 m (x t ) = p(x t |Z t\u22121 ) m k=1 p(z k |x t ) (11) = p(x t |Z t\u22121 )p(z t |x t ) = p(x t |Z t ),(12)\nwhich is the target distribution of our interest. The algorithm proceeds as follows.\nAt the k-th stage, IS is done to simulate \u03c0 k (x t ) with weighted particles. \u03c0 k\u22121 (x t ) is used as the trial distribution of IS, for which we have already obtained a weighted particle set\nP k\u22121,t = {x (i) k\u22121,t , w (i) k\u22121,t } N k\u22121 i=1\n\u223c \u03c0 k\u22121 (x t ) from previous stages. Therefore sampling from this trial distribution can be carried out by re-sampling of P k\u22121,t to obtain {x\n(i) k,t , 1/N k } N k i=1 . The weight of x (i)\nk,t should be updated according to IS as\nw (i) k,t = \u03c0 k (x (i) k,t ) \u03c0 k\u22121 (x (i) k,t ) = p(z k,t |x (i) k,t ). (13\n)\nThe particle set P k,t = {x\n(i) k,t , w (i)\nk,t } can be used to represent \u03c0 k (x t ). IS is repeated for m stages to obtain P m,t = {x  Here we assume the initial particles for the cascade particle filter is uniformly distributed, which might not be the exact case in practice due to temporal propagation.\n(i) m,t , w (i) m,t } \u223c \u03c0 m (x t ) = p(x t |Z t ).", "publication_ref": ["b12"], "figure_ref": [], "table_ref": []}, {"heading": "Method Time Complexity Comments", "text": "Standard Particle Filter\nN P m k=1 \u03c4 k,test\nWhen N is sufficiently large to ensure an accurate result, the time complexity also becomes much larger than the other two methods. Cascade Detector  further comparison of standard PF, cascade detector and our method is shown in Table 2.\nP m k=1 N k \u03c4 k,test N 1 > N 2 > \u2022 \u2022 \u2022 > N m . N k de\nIn implementation, we have observed p(z k |x) noisy and with many peaks (see Figure 5(a) for an idea), which is typical for discriminative models. And the peaks of successive observers do not necessarily overlap. This would cause problems in approaches using observation model in a cascade detector manner without re-distributing and reweighting particles (such as that in [20] which simply discards low-weight particles and keeps high-weight ones). But in our framework it is handled conveniently by adding With {x\n(i) m,t\u22121 , w (i) m,t\u22121 } Nm i=1\nthe particle set at the previous time step, proceed as follows at time t:\n\u2022 Resample (also to enlarge the particle number from Nm to N 1 ): simulate \u03b1 j \u223c {w\n(i) m,t\u22121 } Nm i=1 ,", "publication_ref": ["b19"], "figure_ref": ["fig_9"], "table_ref": ["tab_5"]}, {"heading": "and replace {x", "text": "(i) m,t\u22121 , w (i) m,t\u22121 } Nm i=1 with {x (\u03b1 j ) m,t\u22121 , 1/N 1 } N 1 j=1 . \u2022 Prediction: For i = 1..N 1 , simulate x (i) 1,t \u223c p(xt|x (i) t\u22121 ), note that x (i)\n1,t should be diffused enough to cover the expected range of possible state transition.\n\u2022 At stage 1 do:\nFor i = 1..N 1 let w (i) 1,t = p(z 1,t |x (i) 1,t ).\n\u2022 For stage k = 2..m do:\n-Resample (also to reduce the particle number from\nN k\u22121 to N k ): simulate \u03b1 j \u223c {w (i) k\u22121,t } N k\u22121 i=1\nand replace\n{x (i) k\u22121,t , w (i) k\u22121,t } N k\u22121 i=1 with {x (\u03b1 j ) k\u22121,t , 1/N k } N k j=1 . -Add small diffusion: For i = 1..N k , simulate x (i) k,t \u223c g(x k,t |x (i) k\u22121,t ), and let \u03bb (i) = g(x (i) k,t |x (i) k\u22121,t ),\nwhere g is a 0-mean gaussian.\n-For i = 1..N k , let w (i) k,t = p(z k,t |x (i) k,t )/\u03bb (i) . -Normalize weight so that P N k i=1 w (i) k,t = 1.\n\u2022 Estimate xt: Cluster the particles {x\n(i) m,t , w(i)\nm,t } Nm i=1 . Select the cluster C with maximum weight. Outputxt =\nP i\u2208C w (i) m,t \u2022x (i) m,t P i\u2208C w (i) m,t .\nTable 3. Algorithm of the cascade particle filter.\na small gaussian diffusion into the trial distributions in each IS stage. The final algorithm is show in Table 3.\nAlso, we would like to mention the annealed particle filter [5], which is quite similar to our approach at the first glance. Both of them seek for the global maximum of multimodal likelihood functions in a particle-based stochastic manner. However, they are different in motive and measure: 1) annealed PF is originally designed for searching in a high dimensional state space; cascade PF is for searching in a large range of state space; 2) the number of particles in each stage of cascade PF is decreased instead of being constant as in annealed PF; 3) different observers are adopted in each stage of cascade PF, while annealed PF uses the same likelihood function only with a increasing power (w(z, x) \u03b2m for the m-th stage).", "publication_ref": ["b4"], "figure_ref": [], "table_ref": []}, {"heading": "Experiment and discussion", "text": "The algorithm is implemented in C++ and runs at about 30fps for 320x240 video (single target) on a PC with Pentium 2.8GHz CPU. The numbers of particles adopted in each level are 3000, 600, and 200 respectively.   ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Analysis of the sampling process", "text": "To give a vivid view of how our algorithm works, Figure 5(a) shows the sampling steps in one frame of a video. As is expected, likelihood output by the higher-level observer is more peaked, and as a result the particles are more focused around the true target state after each level's re-weighting and re-sampling. Also notice that the likelihood output of the later two observation models are not smooth even near the true target (which is typical of a discriminative model), making the re-sampling with diffusion necessary.\nWith comparison to CONDENSATION with different number of particles, Figure 5(b) includes a quantitative analysis of sampling effectiveness and efficiency, by the curve of tracking error on the left and the curve of Effective Sample Size (ESS) on the right. It is obvious that enlarging particle set of CONDENSATION compensates its poor accuracy under drastic motion to some extent (compare the green curve with 800 particles and the red one with 200 particles), but the error of our method is still lower (the blue curve). Further, a much higher sampling efficiency of our method is shown by the \"rule of thumb\" of importance sampling [13] -the ESS, calculated by ESS(N ) = N/(1 + cv 2 (\u03c9)), where N is particle number and cv 2 (\u03c9) is the coefficient of variation of the unnormalized weight. ESS can be interpreted as that N weighted samples are worth of ESS(N ) samples drawn from the target distribution.", "publication_ref": ["b12"], "figure_ref": ["fig_9", "fig_9"], "table_ref": []}, {"heading": "Quantitative comparison", "text": "A comparison is done among CONDENSATION, mean shift using color histogram (implemented by [1]), online tracker of [19] (by online selecting Haar-like features) and our method on videos with manually labeled ground truth for comparison. All videos are taken by hand-held camera and down-sampled to 5pfs. baseball.mpg (Figure 7) and hopping.mpg record single person engaged in sports, excursion{1|2}.mpg (Figure 1 and 6) record several people walking along a passage, and boy{1|2}.mpg (Figure 8) record children playing (2676 frames in all). By using these videos we aim to test our algorithm on concurrence of abrupt motion, low frame rate and a moving camera. Tracking accuracy is shown in Figure 9 and Table 4. Our method shows much higher accuracy than other methods under LFR condition. For more tracking results please refer to the supplementary video.", "publication_ref": ["b0", "b18"], "figure_ref": ["fig_0"], "table_ref": ["tab_7"]}, {"heading": "Discussion on scenarios", "text": "Online and offline fusion. In Figure 7 we selected two challenging cases. The first is a fast camera motion which caused both drastic target motion and appearance blur. Applying the offline trained face detector, we observe missing detection. Moreover, an offline trained model cannot identify targets by online context. On the other hand, our method successfully grabs the target appearance and adapts itself to the variation (blur). The second case is a quick pose change (more than 120 \u2022 within 5 frames). While our tracker accurately located the target, a tracker which solely depends on online knowledge exhibits a \"drift\" which eventually leads to failure. These phenomena are frequently observed in our experiments, which illustrate the importance of complementing online and offline models with each other.\nMulti-target tracking. We extend the proposed method to multi-target tracking in a simple way: after each target is tracked individually, several particle clusters are obtained for each target. A data-association stage is then added, by greedily associate one target with the highest-weighted cluster, and then eliminate clusters of un-determined targets that overlaps with determined ones. During the experiment, we observe that the online observation models not only develop discriminative power against background clutter, but   also against ambiguity with other targets (Figure 6).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Conclusion and future work", "text": "There are always two essential parts in a tracking system: the observation model, and the temporal inference process based on it. To deal with LFR conditions, we have pushed both of them towards integration with their counterparts in a detection problem, to enhance discriminative power and efficiency. A temporal probabilistic combination of observers is presented, in which each observer is statistically learned from online or offline samples, to grasp target appearance of longer or shorter temporal vicinity. The cascade particle filter serves for efficient fusion, and combines the advantages of a cascade detector and the nonparametric temporal propagation framework of particle filter.\nUsing multiple observers has enabled efficient cascade structure and avoided the difficulty in incrementally up-dating one offline learned model, which could be timeconsuming when the model complexity is high (especially for discriminative models); also, setting the updating ratio can be very subtle because over-update may even ruin the original model. Nevertheless, we regard sustainable incremental learning as a promising direction for further improving our observers. Also, a detailed performance analysis by modeling and controlling training and testing errors of online learned observers will be necessary to make the system more robust and stable.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgement", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "", "text": "(d) Proposed approach under fast view change (right full profile to left profile in 5 frames).\nFigure 7. Comparison with offline approach and online approach in challenging cases (baseball.mpg).  ", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "", "journal": "Intel opencv library", "year": "", "authors": ""}, {"ref_id": "b1", "title": "Ensamble tracking", "journal": "PAMI", "year": "2007", "authors": "S Avidan"}, {"ref_id": "b2", "title": "Source code of the klt feature tracker", "journal": "", "year": "2006", "authors": "S Birchfield"}, {"ref_id": "b3", "title": "Real-time tracking of non-rigid objects using mean shift", "journal": "", "year": "2000", "authors": "D Comaniciu; V Ramesh; P Meer"}, {"ref_id": "b4", "title": "Experiments with a new boosting algorithm", "journal": "", "year": "2000", "authors": "J Deutscher; A Blake; I Reid"}, {"ref_id": "b5", "title": "Experiments with a new boosting algorithm", "journal": "", "year": "1996", "authors": "Y Freund; R E Schapire"}, {"ref_id": "b6", "title": "A detection-based multiple object tracking method", "journal": "", "year": "2004", "authors": "M Han; A Sethi; W Hua; Y Gong"}, {"ref_id": "b7", "title": "Multi-scale visual tracking by sequential belief propagation", "journal": "", "year": "2004", "authors": "G Hua; Y Wu"}, {"ref_id": "b8", "title": "Vector boosting for rotation invariant multi-view face detection", "journal": "", "year": "2005", "authors": "C Huang; H Ai; Y Li; S Lao"}, {"ref_id": "b9", "title": "Condensation -conditional density propagation for visual tracking", "journal": "IJCV", "year": "1998", "authors": "M Isard; A Blake"}, {"ref_id": "b10", "title": "A unified framework for tracking through occlusions and across sensor gaps", "journal": "", "year": "2005", "authors": "R Kaucic; A G A Perera; G Brooksby; J Kaufhold; A Hoogs"}, {"ref_id": "b11", "title": "Hierarchical shape modeling for automatic face localization", "journal": "", "year": "2002", "authors": "C Liu; H.-Y Shum; C Zhang"}, {"ref_id": "b12", "title": "Monte Carlo Strategies in Scientific Computing", "journal": "Springer", "year": "1994", "authors": "J S Liu"}, {"ref_id": "b13", "title": "A boosted particle filter: Multitarget detection and tracking", "journal": "", "year": "2004", "authors": "K Okuma; A Taleghani; D Freitas; J J Little; D G Lowe"}, {"ref_id": "b14", "title": "Object tracking in low-frame-rate video", "journal": "", "year": "2005", "authors": "F Porikli; O Tuzel"}, {"ref_id": "b15", "title": "Object localization by bayesian correlation", "journal": "", "year": "1999", "authors": "J Sullivan; A Blake; M Isard; J Maccormick"}, {"ref_id": "b16", "title": "Detection and tracking of point features", "journal": "", "year": "1991", "authors": "C Tomasi; T Kanade"}, {"ref_id": "b17", "title": "Robust real-time object detection", "journal": "", "year": "2001", "authors": "P Viola; M Jones"}, {"ref_id": "b18", "title": "Online selecting discriminative tracking features using particle filter", "journal": "", "year": "2005", "authors": "J Wang; X Chen; W Gao"}, {"ref_id": "b19", "title": "Fast multiple object tracking via a hierarchical particle filter", "journal": "", "year": "2005", "authors": "C Yang; R Duraiswami; L Davis"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 .1Figure 1. Tracking 4 consecutive frames in a 5pfs video.", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 2 .2Figure 2. Life-spans of observation models (observers).", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 3 .3Figure 3. Feature set of each observation model.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "should be p(z k |x) for each x \u2208\u015c k ). The training time (\u03c4 k,off + \u03c4 k,on ) usually increases with |F k | and |S k |, and the testing time \u03c4 k,test increases with |F k |. And the total offline and online time complexities are \u03c4 offline = m k=1 \u03c4 k,off ,", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Section 3 is devoted to how to achieve this). Meanwhile, to minimize the online training part in (3), F k must be carefully selected and as much of training as possible should be done offline.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Figure 44gives an illustration of a cascade PF and a conventional cascade detector both with 3 classifiers. And a", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Figure 4 .4Figure 4. Illustration of our method and the cascade detector, both with 3 classifiers. Here we assume the initial particles for the cascade particle filter is uniformly distributed, which might not be the exact case in practice due to temporal propagation.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "Sampling process in each level: observation likelihood and corresponding sample set after updating weight.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "Tracking error curve and ESS curve of CONDEN-SATION and proposed approach. Results of proposed approach are shown in frames where CONDENSA-TION have large error (yellow rectangle denotes target in the previous frame).", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "Figure 5 .5Figure 5. Illustration of sampling process, comparison of tracking accuracy and sampling efficiency between CONDENSATION and proposed approach.", "figure_data": ""}, {"figure_label": "69", "figure_type": "figure", "figure_id": "fig_10", "figure_caption": "Figure 6 .Figure 9 .69Figure 6. Multi-target tracking and likelihood output of online observers for different targets, yellow rectangle denotes target in the previous frame (excursion2.mpg).", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "Select samples for adding new weak classifiers: all positive samples S 2,pos and only the negative samples S 2,neg = {x|x \u2208 S 2,neg \u2227 p(z t\u22121,2 |x) > \u03be}, where p(z t\u22121,2 |x) is the old observation likelihood and \u03be is a threshold. The reason is that new weak classifiers should focus on samples which are not well handled by the old model. 2. Add new weak classifiers by bootstrap. Each is learned by LDA with 10 features selected from F 2 . 3. Weight weak classifiers by Discrete AdaBoost [6]. 4. Discard weak classifiers which are not selected for a certain number of frames.Denote the p-th weak classifier as (\u03b1 p , w p , f p , \u03b7 p ), where \u03b1 p is the boosted weight, f p and w p are the features and corresponding projection vector learned by LDA, and \u03b7 p is the threshold. The final observation likelihood is modeled by a Sigmoid function of the boosted output:", "figure_data": ""}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "A comparison among standard particle filter, conventional cascade detector, and our method. \u03c4 k,test is the cost of calculating p(z k |x); N k (or N k ) is the number of particles (or passed candidates) in the k-th stage.", "figure_data": ""}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_7", "figure_caption": "Comparison with other methods. Error is normalized by ground truth target size. And the criterion of successful tracking is that both position and scale errors are smaller than 0.5.", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "#1 #2 #3 #4", "formula_coordinates": [1.0, 343.67, 245.25, 159.84, 6.48]}, {"formula_id": "formula_1", "formula_text": "O k = (L k , F k , S k , \u03c4 k,on , \u03c4 k,off , \u03c4 k,test ).(1)", "formula_coordinates": [2.0, 328.79, 671.6, 216.33, 9.65]}, {"formula_id": "formula_2", "formula_text": "O(|F 1 | 2 |S 1 |) O(|F 2 | 2 |S 2 | + |S 2 |P 2 ) 0 \u03c4 k,off Negligible Negligible Several days \u03c4 k,test O(|F 1 |) O(|F 2 |) O(|F 3 |)", "formula_coordinates": [3.0, 56.49, 279.24, 212.41, 40.72]}, {"formula_id": "formula_3", "formula_text": "\u03c4 online = m k=1 (\u03c4 k,on + |\u015c k | \u2022 \u03c4 k,test ).(2)", "formula_coordinates": [3.0, 70.76, 430.18, 215.6, 53.24]}, {"formula_id": "formula_5", "formula_text": "1 | < |\u015c 2 | < \u2022 \u2022 \u2022 < |\u015c m | (", "formula_coordinates": [3.0, 88.7, 589.86, 106.31, 9.65]}, {"formula_id": "formula_6", "formula_text": "p(z 1 |x) \u221d 1 1 + exp (\u2212(w T f (x) \u2212 \u03b7)) . (4", "formula_coordinates": [3.0, 328.79, 281.07, 212.45, 22.31]}, {"formula_id": "formula_7", "formula_text": ")", "formula_coordinates": [3.0, 541.24, 288.13, 3.87, 8.64]}, {"formula_id": "formula_8", "formula_text": "p(z 2 |x) \u221d 1 1 + exp \u2212 P p \u03b1psign(w T p fp(x)\u2212\u03b7p) P p \u03b1p . (5", "formula_coordinates": [3.0, 325.98, 583.67, 215.27, 33.54]}, {"formula_id": "formula_9", "formula_text": ")", "formula_coordinates": [3.0, 541.24, 590.73, 3.87, 8.64]}, {"formula_id": "formula_10", "formula_text": "p(z 3 |x) \u221d 1/ (1 + \u03c6 h exp(\u2212c)) ,(6)", "formula_coordinates": [3.0, 328.79, 704.2, 216.33, 9.65]}, {"formula_id": "formula_11", "formula_text": "Prediction : p(x t |Z t\u22121 ) = p(x t |x t\u22121 )p(x t\u22121 |Z t\u22121 )dx t\u22121 , Update : p(x t |Z t ) \u221d p(z t |x t )p(x t |Z t\u22121 ).(7)", "formula_coordinates": [4.0, 50.11, 474.44, 248.59, 29.69]}, {"formula_id": "formula_12", "formula_text": "p(z|x) = p(z 1 , . . . , z m |x) = m k=1 p(z k |x).(8)", "formula_coordinates": [4.0, 328.79, 120.76, 216.33, 30.55]}, {"formula_id": "formula_13", "formula_text": "\u03c0 0 (x t ) = p(x t |Z t\u22121 ),(9)", "formula_coordinates": [4.0, 329.22, 380.19, 215.89, 9.65]}, {"formula_id": "formula_14", "formula_text": "\u03c0 k (x t ) = p(z k,t |x t )\u03c0 k\u22121 (x t ), k = 1..m.(10)", "formula_coordinates": [4.0, 328.79, 395.13, 216.33, 9.65]}, {"formula_id": "formula_15", "formula_text": "\u03c0 m (x t ) = p(x t |Z t\u22121 ) m k=1 p(z k |x t ) (11) = p(x t |Z t\u22121 )p(z t |x t ) = p(x t |Z t ),(12)", "formula_coordinates": [4.0, 328.79, 429.33, 216.33, 44.5]}, {"formula_id": "formula_16", "formula_text": "P k\u22121,t = {x (i) k\u22121,t , w (i) k\u22121,t } N k\u22121 i=1", "formula_coordinates": [4.0, 308.86, 540.76, 133.88, 14.44]}, {"formula_id": "formula_17", "formula_text": "(i) k,t , 1/N k } N k i=1 . The weight of x (i)", "formula_coordinates": [4.0, 319.89, 579.06, 134.71, 14.3]}, {"formula_id": "formula_18", "formula_text": "w (i) k,t = \u03c0 k (x (i) k,t ) \u03c0 k\u22121 (x (i) k,t ) = p(z k,t |x (i) k,t ). (13", "formula_coordinates": [4.0, 328.79, 611.1, 212.18, 31.85]}, {"formula_id": "formula_19", "formula_text": ")", "formula_coordinates": [4.0, 540.96, 622.8, 4.15, 8.64]}, {"formula_id": "formula_20", "formula_text": "(i) k,t , w (i)", "formula_coordinates": [4.0, 418.79, 650.94, 31.15, 14.3]}, {"formula_id": "formula_21", "formula_text": "(i) m,t , w (i) m,t } \u223c \u03c0 m (x t ) = p(x t |Z t ).", "formula_coordinates": [4.0, 319.89, 677.15, 137.55, 13.74]}, {"formula_id": "formula_22", "formula_text": "N P m k=1 \u03c4 k,test", "formula_coordinates": [5.0, 95.35, 356.28, 55.97, 11.25]}, {"formula_id": "formula_23", "formula_text": "P m k=1 N k \u03c4 k,test N 1 > N 2 > \u2022 \u2022 \u2022 > N m . N k de", "formula_coordinates": [5.0, 95.35, 396.52, 181.25, 11.53]}, {"formula_id": "formula_24", "formula_text": "(i) m,t\u22121 , w (i) m,t\u22121 } Nm i=1", "formula_coordinates": [5.0, 343.24, 73.8, 69.11, 12.13]}, {"formula_id": "formula_25", "formula_text": "(i) m,t\u22121 } Nm i=1 ,", "formula_coordinates": [5.0, 461.08, 113.14, 40.69, 12.13]}, {"formula_id": "formula_26", "formula_text": "(i) m,t\u22121 , w (i) m,t\u22121 } Nm i=1 with {x (\u03b1 j ) m,t\u22121 , 1/N 1 } N 1 j=1 . \u2022 Prediction: For i = 1..N 1 , simulate x (i) 1,t \u223c p(xt|x (i) t\u22121 ), note that x (i)", "formula_coordinates": [5.0, 325.95, 126.56, 225.54, 45.7]}, {"formula_id": "formula_27", "formula_text": "For i = 1..N 1 let w (i) 1,t = p(z 1,t |x (i) 1,t ).", "formula_coordinates": [5.0, 384.15, 191.6, 128.35, 12.02]}, {"formula_id": "formula_28", "formula_text": "N k\u22121 to N k ): simulate \u03b1 j \u223c {w (i) k\u22121,t } N k\u22121 i=1", "formula_coordinates": [5.0, 357.08, 230.34, 193.91, 21.74]}, {"formula_id": "formula_29", "formula_text": "{x (i) k\u22121,t , w (i) k\u22121,t } N k\u22121 i=1 with {x (\u03b1 j ) k\u22121,t , 1/N k } N k j=1 . -Add small diffusion: For i = 1..N k , simulate x (i) k,t \u223c g(x k,t |x (i) k\u22121,t ), and let \u03bb (i) = g(x (i) k,t |x (i) k\u22121,t ),", "formula_coordinates": [5.0, 348.12, 253.47, 203.37, 44.49]}, {"formula_id": "formula_30", "formula_text": "-For i = 1..N k , let w (i) k,t = p(z k,t |x (i) k,t )/\u03bb (i) . -Normalize weight so that P N k i=1 w (i) k,t = 1.", "formula_coordinates": [5.0, 348.12, 311.03, 159.09, 30.03]}, {"formula_id": "formula_31", "formula_text": "(i) m,t , w(i)", "formula_coordinates": [5.0, 460.95, 350.43, 30.63, 11.85]}, {"formula_id": "formula_32", "formula_text": "P i\u2208C w (i) m,t \u2022x (i) m,t P i\u2208C w (i) m,t .", "formula_coordinates": [5.0, 488.76, 363.63, 60.19, 21.08]}], "doi": ""}