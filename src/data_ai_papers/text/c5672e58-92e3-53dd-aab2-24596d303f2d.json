{"title": "3D Statistical Shape Models Using Direct Optimisation of Description Length", "authors": "Rhodri H Davies; Carole J Twining; Tim F Cootes; John C Waterton; Chris J Taylor", "pub_date": "", "abstract": "We describe an automatic method for building optimal 3D statistical shape models from sets of training shapes. Although shape models show considerable promise as a basis for segmenting and interpreting images, a major drawback of the approach is the need to establish a dense correspondence across a training set of example shapes. It is important to establish the correct correspondence, otherwise poor models can result. In 2D, this can be achieved using manual 'landmarks', but in 3D this becomes impractical. We show it is possible to establish correspondences automatically, by casting the correspondence problem as one of finding the 'optimal' parameterisation of each shape in the training set. We describe an explicit representation of surface parameterisation, that ensures the resulting correspondences are legal, and show how this representation can be manipulated to minimise the description length of the training set using the model. This results in compact models with good generalisation properties. Results are reported for two sets of biomedical shapes, showing significant improvement in model properties compared to those obtained using a uniform surface parameterisation.", "sections": [{"heading": "Introduction", "text": "Statistical models of shape show considerable promise as a basis for segmenting and interpreting images in 2D [5]. The basic idea is to establish, from a training set, the pattern of 'legal' variation in the shapes and spatial relationships of structures for a given class of images. Statistical analysis is used to give an efficient parameterisation of this variability, providing a compact representation of shape and allowing shape constraints to be applied effectively during image interpretation [6]. A key step in building a model involves establishing a dense correspondence between shape boundaries/surfaces over a reasonably large set of training images. It is important to establish the 'correct' correspondences, otherwise an inefficient parameterisation of shape can result, leading to difficulty in defining shape constraints effectively. In 2D, correspondence is often established using manually defined 'landmarks' but this is a time-consuming, error-prone and subjective process. In principle, the method extends to 3D, but in practice, manual landmarking becomes impractical. In this paper we show how an 'optimal' model can be built by automatically defining correspondences across a training set of 3D shapes.\nSeveral previous attempts have been made to build 3D statistical shape models [3,4,10,12,13,14,21,25]. The problem of establishing dense correspondence over a set of training shapes can be posed as that of defining a parameterisation for each of the training set, assuming correspondence between equivalently parameterised points. Kelemen et. al [14] and Hill et. al [12] use different arbitrary parameterisations of the training shapes. Christiensen et al. [7], Szekely and Lavalle [23] and Rueckert et al. [21] describe methods for warping the space in which the shapes are embedded. Models can then be built from the resulting deformation field [10,13,21]. Brett and Taylor [3,4] and Wang et. al [25] use shape 'features' (e.g. regions of high curvature) to establish point correspondences.\nThe correspondences found using the methods described above are not, in any obvious sense, the correct ones. We show in section 2 (fig. 1) that unsatisfactory models can result if correspondences are chosen inappropriately. We start from the position that the correct correspondences are, by definition, those that build the 'best' model. We define the 'best' model as that with optimal compactness, specificity and generalisation ability. We have shown elsewhere [8] that a model with these properties can be obtained using an objective function based on the minimum description length principle [18]. We have also described a method that uses the objective function to build models in 2D that are better than the best models we could build using manual landmarks [9]. The representation of the parameterisation did not, however, extend to surfaces in 3D. In this paper we describe the derivation of the objective function. We also describe a novel method of representing and manipulating the parameterisation of a surface allowing the construction of shape models in 3D. The method ensures that only valid correspondences can be represented.\nIn the remainder of the paper, we establish notation, and outline the modelbuilding problem. We then provide a summary of the derivation of the minimum description length objective function. We show how a set of surface parameterisations can be represented explicitly and manipulated to build an optimal model. Finally, we present qualitative and quantitative results of applying the method to surfaces obtained from 3D MR images of brain ventricles and rat kidneys.", "publication_ref": ["b4", "b5", "b2", "b3", "b9", "b11", "b12", "b13", "b20", "b24", "b13", "b11", "b6", "b22", "b20", "b9", "b12", "b20", "b2", "b3", "b24", "b7", "b17", "b8"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Statistical Shape Models", "text": "A 2d (3d) statistical shape model is built from a training set of example outlines (surfaces), aligned to a common coordinate frame. Each shape, S i , (i = 1, . . . n s ), can (without loss of generality) be represented by a set of n points regularly sampled on the shape, as defined by some parameterisation \u03c6 i . This allows each shape S i to be represented by an n p -dimensional shape vector x i , formed by concatenating the coordinates of its sample points. Using Principal Component analysis, each shape vector can be expressed using a linear model of the form:\nx i =x + Pb i =x + m p m b m i ,(1)\nwherex is the mean shape vector, P = {p m } are the eigenvectors of the covariance matrix (with corresponding eigenvalues {\u03bb m }) that describe a set of orthogonal modes of shape variation and b = {b m } are shape parameters that control the modes of variation.\nSince our training shapes are continuous, we are interested in the limit n p \u2192 \u221e. This leads to an infinitely large covariance matrix, but we note that there can only be, at most, n s \u2212 1 eigenvalues that are not identically zero (although they may be computationally zero). This means that in the summation above, the index m only takes values in the range 1 to n s \u2212 1.\nTo calculate the non-zero eigenvalues, we consider the n p \u00d7 n s data matrix W constructed from the set of vectors {(x i \u2212x) : i = 1, . . . n s }. The n p \u00d7 n p covariance matrix is given by D = 1 npns WW T with eigenvectors and eigenvalues {p m , \u03bb m } thus:\nDp m = \u03bb m p m . (2\n)\nIf we define {p m , \u03bb m , } to be the eigenvectors and eigenvalues of the n s \u00d7 n s matrix, D = 1 npns W T W then:\nD p m = \u03bb m p m From (2) : Dp m = \u03bb m p m \u21d2 1 n p n s WW T p m = \u03bb m p m ,(3)\npre-multiplying by W T :\n\u21d2 D (W T p m ) = \u03bb m (W T p m ) Similarly: D(Wp m ) = \u03bb m (Wp m ).(4)\nTherefore, for all \u03bb m = 0, we can assign indices such that:\n\u03bb m = \u03bb m and p m = Wp m . (5\n)\nThus the n s \u2212 1 eigenvalues of D, which are not identically zero, can be obtained directly from D , and the eigenvectors are a weighted sum of the training shapes. As shown in [15], in the limit n p \u2192 \u221e the ij th element of D is given by the inner product of shapes i and j:\nD ij = dt (S i (\u03c6 i (t)) \u2212S(t)) \u2022 (S j (\u03c6 j (t)) \u2212S(t))(6)\nwhereS = 1 ns ns i=1 S i is the mean shape and S i (\u03c6 i ) is a continuous representation of S i parameterised by \u03c6 i . The integral can be evaluated numerically. New examples of the class of shapes can be generated by choosing values of {b m } within the range found in the training set. The utility of the linear model of shape shown in (1) depends on the appropriateness of the set of parameterisations {\u03c6 i } that are chosen. An inappropriate choice can result in the need for a large set of modes (and corresponding shape parameters) to approximate the training shapes to a given accuracy and may lead to 'legal' values of {b m } generating 'illegal' shape instances. For example, figure 1 shows two 2D models generated from a set of 17 hand outlines. Model A uses a set of parameterisations of the outlines that cause 'natural' landmarks such as the tips of the fingers to correspond. Model B uses one such correspondence but then uses a simple path length parameterisation to position the other sample points. The variances of the three most significant modes of models A and B are (1.06, 0.58, 0.30) and (2.19, 0.78, 0.54) respectively. This suggests that model A is more compact than model B. The set of parameterisations used for model A were obtained by marking 'natural' landmarks manually on each training example, then using simple path length parameterisation to sample a fixed number of equally spaced points between them. This manual mark-up is a time-consuming and subjective process. In principle, the modelling approach extends to 3D, but in practice, manual landmarking becomes impractical. We propose to overcome this problem by automatically defining correspondences between a training set of example shapes.", "publication_ref": ["b14"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "An Information Theoretic Objective Function", "text": "We wish to define a criterion for selecting the set of parameterisations {\u03c6 i } that are used to construct a statistical shape model from a set of training boundaries {S i }. Our aim is to choose {\u03c6 i } so as to obtain the 'best possible' model. Ideally, we would like a model with optimal:\nGeneralisation Ability: the model can describe any instance of the objectnot just those seen in the training set; Specificity: the model can only represent valid instances of the object; Compactness: the variation is explained with few parameters. To achieve this, we follow the principle of Occam's razor which can be paraphrased: 'simple descriptions generalise best'. As a quantitative measure of 'simplicity', we choose to apply The Minimum Description Length (MDL) Principle [18,19]. The MDL principle is based on the idea of transmitting a data set as an encoded message, where the code is based on some pre-arranged set of parametric statistical models. The full transmission then has to include not only the encoded data values, but also the coded model parameter values. Thus MDL balances the model complexity, expressed in terms of the cost of sending the model parameters, against the quality of fit between the model and the data, expressed in terms of the coding length of the data. Comparison of Description Lengths calculated using models from different classes can be used as a way of solving the Model Selection Problem [11]. However, our emphasis here is not on selecting the class of model, but on using the Description Length for a single class of model as an objective function for optimisation of correspondence between the shapes.\nWe will use the simple two-part coding formulation of MDL. Although this does not give us a coding which is of the absolute minimum length [20], it does however give us a functional form which is computationally simple to evaluate, hence suitable to be used as an objective function for numerical optimisation.", "publication_ref": ["b17", "b18", "b10", "b19"], "figure_ref": [], "table_ref": []}, {"heading": "The Model", "text": "Our training set of n s shapes is sampled according to the parameterisations {\u03c6 i } to give a set of n p -dimensional shape vectors {x i }. We choose to model this set of shape vectors using a multivariate Gaussian model. The initial step in constructing such a model is to change to a coordinate system whose axes are aligned with the principal axes of the data set. This corresponds to the orientation of the linear model defined earlier (1):\nx i =x + ns\u22121 m=1 p m b m i . (7\n)\nThe n s \u2212 1 mutually-orthogonal eigenvectors {p m } span the subspace which contains the training set, and, by appropriate scaling, can be transformed into an orthonormal basis set for this subspace. We will also order these vectors in terms of non-decreasing eigenvalue to give us our final orthonormal basis set {p m }. To transmit a shape x i using this model, we first have to transmit the mean shapex, then the deviations from the mean shape, which can be written thus:\ny m i \u2261p m \u2022 (x i \u2212x). (8\n)\nWe will assume that the code length for the transmission of the mean shapex is a constant for a given training set and number of sample points. Furthermore, the code length for the transmission of the set of n s \u2212 1, n p -dimensional basis vectors {p m } is also constant for a given training set and number of sample points and need not be considered further.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "The Description Length", "text": "For each directionp m , we now have to transmit the set of values Y m \u2261 {y m i : i = 1 to n s }. Since we have aligned our coordinate axes with the principal axes of the data, and aligned our origin with the mean shape, each direction can now be modelled using a one-dimensional, centred Gaussian. In the Appendix, we derive an expression for the Description Length of one-dimensional, bounded and quantised data, coded using a centred Gaussian model. To utilise this result, we first have to calculate a strict upper-bound R on the range of our data and also estimate a suitable value for the data quantisation parameter \u2206.\nSuppose that, for our original shape data, we know that the coordinates of our sample points are strictly bounded thus:\n\u2212 r 2 \u2264 x i\u03b1 \u2264 r 2 for all \u03b1 = 1 to n p , i = 1 to n s . (9\n)\nThen, the strict bound for the coordinates {y m i } is given by:\nR = r \u221a n p , so that |y m i | \u2264 R for all i, m. (10\n)\nThe data quantisation parameter \u2206 can be determined by quantising the coordinates of our original sample points. Comparison of the original shape and the quantised shape then allows a maximum permissible value of \u2206 to be determined. For example, for boundaries obtained from voxelated images, \u2206 will typically be of the order of the voxel size. This also determines our lower bound on the modelled variance \u03c3 min \u2261 2\u2206. The parameters R and \u2206 are held constant for a given training set, hence we need not consider the Description Length for the transmission of these values.\nOur original data values Y m are now replaced by their quantised 1 values\u0176 m . The variance of the quantized data is then calculated thus:\n(\u03c3 m ) 2 = 1 n s ns i=1 (\u0177 m i ) 2 . (11\n)\nThe Description Length D m for each direction is then given by (see Appendix):\n\u2022 If \u03c3 m \u2265 \u03c3 min : D m = D (1) (\u03c3 m , n s , R, \u2206) \u2022 If \u03c3 m < \u03c3 min but the range of\u0176 m \u2265 \u2206: D m = D (2) (\u03c3 m , n s , R, \u2206) \u2022 Else: D m = 0.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "The Objective Function", "text": "Let us define n g to be the number of directions for which the first of the above criteria holds, and n min the number which satisfy the second. Then, since the directions are ordered in terms of non-increasing eigenvalue/variance, the total Description Length for our training set, and our Objective function, can be written thus:\nF = ng p=1 D (1) (\u03c3 p , n s , R, \u2206) + ng+nmin q=ng+1 D (2) (\u03c3 q , n s , R, \u2206). (12\n)\nWe now consider the form of this objective function. For the linear model defined earlier (1):\nn p \u03bb m = 1 n s ns i=1 (y m i ) 2(13)\nIn the limit \u2206 \u2192 0, the quantised values in\u0176 approach their continuum values, so that:\n\u03c3 m \u2192 n p \u03bb m . (14\n)\nIf we also consider the limit where n s is sufficiently large, it can be seen that the functions D (1) and D (2) can be written in the form:\nD (1) (\u03c3 m , n s , R, \u2206) \u2248 f (R, \u2206, n s ) + (n s \u2212 2) ln \u03c3 m (15\n)\nD (2) (\u03c3 m , n s , R, \u2206) \u2248 f (R, \u2206, n s ) + (n s \u2212 2) ln \u03c3 min + (n s + 3) 2 \u03c3 m \u03c3 min 2 \u2212 1\nwhere f is some function which depends only on R, \u2206 and n s . So, in this dual limit, the part of the objective function which depends on the {\u03c3 m } contains terms similar to the determinant of the covariance matrix (that is ln \u03bb m ) used by Kotcheff and Taylor [15]. However, our objective function is well-defined, even in the limit \u03bb m \u2192 0, where in fact such a direction makes no contribution to the objective function. Whereas in the form used previously, without the addition of artificial correction terms, it would have an infinitely large contribution.", "publication_ref": ["b0", "b1", "b14"], "figure_ref": [], "table_ref": []}, {"heading": "Manipulating the Parameterisation of a Surface", "text": "In order to build a statistical shape model, we need to sample a number of corresponding points on each shape. As demonstrated in section 2, the choice of correspondences determines the quality of the model. We have chosen to cast this correspondence problem as that of defining the parameterisation \u03c6 i , of each shape so as to minimise the value of F in (12). We propose to sove for {\u03c6 i } using numerical optimisation, which requires that we formulate an explicit (and ideally, compact) representation of the \u03c6 i that can be manipulated. We would also like the computational complexity to be minimal (i.e. it should only involve the evaluation of elementary functions).\nEach surface in our training set is originally represented as a triangular mesh that is topologically equivalent to a sphere. We obtain an initial parameterisation by mapping each surface mesh to a unit sphere, where the mapping must be such that there is no folding or tearing. Each mapped mesh can then be represented thus:\nS i = S i (\u03b8, \u03c8), S i R 3 (16)\nwhere S i is the set of original positions of the mesh vertices for the i th surface in Euclidean space, and (\u03b8, \u03c8) are the spherical polar coordinates of each mapped vertex. Various approaches have been described to achieve such mappings [1,2,24]. Since we intend to optimise the parameterisations, the final result should significantly not depend on this initial mapping. We have used the method described by Brechbulher [2] to produce the results reported below.\nChanges in parameterisation of a given surface correspond to altering the positions of the mapped vertices on the sphere. That is:\nS i \u2192 S i , \u03b8 \u2192 \u03b8 , \u03c8 \u2192 \u03c8 (17\n)\nwhere S i (\u03b8, \u03c8) = S i (\u03b8 , \u03c8 ) and \u03b8 = \u03c6 \u03b8 i (\u03b8, \u03c8), \u03c8 = \u03c6 \u03c8 i (\u03b8, \u03c8). Note that we have separate parameterisation functions \u03c6 i = (\u03c6 \u03b8 i , \u03c6 \u03c8 i ) for each surface. Valid parameterisation functions \u03c6 i correspond to exact homeomorphic mappings of the sphere. That is, mappings that are continuous, one-to-one and onto. In the following sections, we present a number of such mappings.", "publication_ref": ["b11", "b0", "b1", "b23", "b1"], "figure_ref": [], "table_ref": []}, {"heading": "Symmetric Theta Transformations", "text": "Consider an arbitrary point P on the unit sphere. For simplicity, assume that the spherical polar co-ordinates (\u03b8, \u03c8) on the sphere have been redefined so that P corresponds to the point \u03b8 = 0. Let us first consider a rotationally symmetric mapping that reparameterises the \u03b8 coordinate:\n\u03b8 \u2192 f (\u03b8). (18\n)\nFor the mapping to be homeomorphic and continuous with the identity, f must be a differentiable non-decreasing monotonic function over the range 0 < \u03b8 < \u03c0, with f (0) = 0, f(\u03c0) = \u03c0. Any such monotonic function f can be rewritten in terms of the cumulative distribution function of some density function \u03c1(\u03b8), defined over the range 0 \u2264 \u03b8 \u2264 \u03c0.\nAs our normalised density function, we take a constant term plus a wrapped Cauchy distribution. The wrapped Cauchy [16] is a normalisable, uni-modal distribution for circular data, of variable width, which has an analytic indefinite integral:\n\u03c1(\u03b8) = 1 N 1 + A 1 \u2212 \u03b1 2 1 + \u03b1 2 \u2212 2\u03b1 cos \u03b8 (19\n)\nwhere N = \u03c0 [1 + A]. Hence: where \u03b1 (\u03b1 \u2261 e \u2212a , a \u2208 R) is the width, and A (A \u2265 0) is the amplitude of the Cauchy.\nf (\u03b8) = \u03c0 \u03b8 0 ds \u03c1(s) = 1 1 + A \u03b8 + A arccos (1 + \u03b1 2 ) cos \u03b8 \u2212 2\u03b1 1 + \u03b1 2 \u2212 2\u03b1 cos \u03b8 (20)\nThe constant term is included so that f (\u03b8) = \u03b8 when A = 0. i.e. the parameterisation is unchanged when the Cauchy has zero magnitude.", "publication_ref": ["b15"], "figure_ref": [], "table_ref": []}, {"heading": "Asymmetric Theta Transformations", "text": "We can also perform non-symmetric transformations:\n\u03b8 \u2192 f (\u03b8, \u03c8). (21\n)\nDefine \u03c8 to be the \u03c8 coordinates redefined so that a point (Q = P ) corresponds to \u03c8 = 0. An asymmetric transformation around the point P , towards a point Q can be achieved using (20) and making the amplitude A a smooth function of the \u03c8 coordinate:\nA \u2192 A(\u03c8 ). (22\n)\nOne such way to do this is to use the wrapped Cauchy distribution to obtain:\nA(\u03c8 ) = A 0 1 \u2212 \u03b2 2 1 + \u03b2 2 \u2212 2\u03b2 cos \u03c8 \u2212 1 \u2212 \u03b2 2 (1 + \u03b2) 2 (23\n)\nwhere \u03b2 (\u03b2 \u2261 e \u2212b ) is the width of the subsidiary Cauchy. We have chosen the formulation such that A(\u03c8 ) has a minimum value of zero. An example of an asymmetric transformation is shown in figure 2.", "publication_ref": ["b19"], "figure_ref": ["fig_2"], "table_ref": []}, {"heading": "Shear and Twist", "text": "We also consider transformations of the \u03c8 coordinate. This is equivalent to shearing and twisting the sphere about the axis defined by the point P . So, for example, we could consider a reparameterisation of the form:\n\u03c8 \u2192 \u03c8 + g(\u03b8) (24\n)\nwhere\ng(\u03b8) = B 2\u03c0 1 \u2212 \u03b3 2 1 + \u03b3 2 \u2212 2\u03b3 cos (\u03b8 \u2212 \u03b8 0 ) (25\n)\nwhere B is the amplitude, \u03b3 (\u03b3 \u2261 e \u2212c , c \u2208 R) is the width and \u03b8 0 is the position of the centre. This transformation is continuous with the identity at B = 0 (i.e. the transformation has no affect when B = 0). It can also be localised about \u03b8 = \u03b8 0 in the limit of zero width. An example of such a transformation is shown in Figure 3. Figure 4 shows an example of applying a combination of all the transformations described above.", "publication_ref": [], "figure_ref": ["fig_3", "fig_4"], "table_ref": []}, {"heading": "Optimising the Parameterisations", "text": "We now wish to manipulate {\u03c6 i } so as to minimise F in (12). We have found that, for the objects modelled in this paper, the symmetric theta transformations, alone, provide a sufficient group of reparameterisations. To manipulate the parameterisations, we fix the position P and width a of each of the Cauchy kernels and vary its magnitude A.\nTo select the positions P of the kernels, we (approximately) uniformly sample the sphere and centre the kernels at these sample points. It is not strictly possible to position an arbitrary number of equidistant points on the sphere, but a good  approximation can be obtained by recursive subdivision of a polyhedron (initially an octohedron) and projecting the points onto the sphere surface. At each level of recursion, each triangle is divided into 4 smaller triangles by placing 3 new vertices halfway along each edge -this gives 12 \u00d7 4 k\u22122 new kernels on the k th level of recursion.\nWe choose to use a multiresolution approach to the optimisation. The basic idea is to begin with broad Cauchies and to iteratively refine the parameterisation by introducing additional, narrower Cauchies between the existing ones. We have found, by cross validation, that the best value for the width parameter, is a k = 1/2 k\u22122 , i.e. the widths are halved at each level of recursion.\nA local optimisation algorithm is employed to find the optimum magnitude of each kernel. At each level of recursion, we have 12 \u00d7 4 k\u22122 kernels for each shape, creating a 12n s \u00d7 4 k\u22122 -dimensional configuration space. This is generally too difficult to optimise robustly and reliably. We have found, however, that optimising the magnitude of a single kernel in turn on each shape gives better results and is substantially quicker. We used the Nelder-Mead simplex algorithm [17] to obtain the results reported in section 6.", "publication_ref": ["b11", "b16"], "figure_ref": [], "table_ref": []}, {"heading": "Results", "text": "We present qualitative and quantitative results of applying our method to a training set of 16 rat kidneys and 8 anterior horns of brain ventricles. In each case the shapes were segmented by hand from a set of 3D magnetic resonance images. The algorithm was run for three levels of recursion, giving a total of 66 kernels per shape. We compare the results to models built by uniformly sampling the surface.\nIn figures 5 and 6, we show qualitative results by displaying the variation captured by the first three modes of each model (b m varied by \u00b12[standard deviatiations seen across the training set]). We show quantitative results in    table 1, tabulating the variance explained by each mode, the total variance and the value of F . In both cases F is substantially better for the optimised model. Figure 7 shows the cumulative variance plotted against the number of modes used for each model; this measures the compactness of the model. The plots show that, for the entire range of modes, the optimised models are substantially more compact than those obtained by uniformly-sampling the surface. To test the generalisation ability of the models, we performed leaveone-out tests on each model. In figure 8 we show the approximation error for representing an unseen shape as a function of the number of modes used in the reconstruction. The optimised models perform substantially better than the uniformly sampled models whatever the number of modes used, demonstrating superior generalisation ability.", "publication_ref": [], "figure_ref": ["fig_7", "fig_8"], "table_ref": ["tab_0"]}, {"heading": "Discussion and Conclusions", "text": "We have described a method for building 3D statistical shape models by automatically establishing optimal correspondences between sets of shapes. We have shown that the method produces models that are more compact than those based on uniformly-sampled shapes and have substantially better generalisation ability.\nWe have described a novel method of reparameterising closed surfaces. The method guarantees that the resulting reparameterisation is homeomorphic -an essential constraint. With a suitable choice of boundary conditions, the representation can also be applied to reparameterise open surfaces.\nAlthough we have only reported results on a relatively small set of example shapes, we believe the method scales easily to deal with sets of 40-50 shapes. The local optimisation algorithm employed will, however, be substantially slower. We are currently looking for more robust and faster methods of finding the minimum.\nThe MDL objective function and optimisation approach provides a unified framework for dealing with all aspects of model building. For example, we plan to investigate including the alignment of the shapes in the optimisation.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Appendix: Description Length for One-Dimensional Centred Gaussian Models", "text": "In this Appendix, we show how to construct an expression for the description length required to send a one-dimensional, centred data set using a Gaussian model. Our data model is the family of centred Gaussian distributions:\n\u03c1(y; \u03c3) = 1 \u03c3 \u221a 2\u03c0 exp \u2212 y 2 2\u03c3 2 . (26\n)\nFollowing the two-part coding scheme [19], the total description length is computed as the sum of two parts; the description length for sending the value and accuracy of the parameter \u03c3, and the description length for coding the data according to this model. To calculate these description lengths, we use the fundamental result that the ideal-coding codeword length for a discrete event A, encoded using a statistical model with associated event probabilities P (A) is given by the Shannon Coding codeword length [22]:\nL(A; P ) = \u2212 log 2 P (A) bits, or: \u2212 ln P (A) nats. 2\nWe take our centred data set to be Y = {y i : i = 1 to n s }, where the data is known to lie within a strictly bounded region. To reduce the continuum values {y i } to a set of discrete events, we quantize the data values using a parameter \u2206, so that Y \u2192\u0176 = {\u0177 i : i = 1 to n s } 3 , where for any quantized value\u0177 from any possible data set: \u2212 R <\u0177 < R and\u0177 = m\u2206, m Z Z.\n(28)", "publication_ref": ["b18", "b21"], "figure_ref": [], "table_ref": []}, {"heading": "Coding the Parameters", "text": "We will assume that the parameter \u03c3 is described to an accuracy \u03b4. We will also assume that our now quantized parameter\u03c3 is bounded, hence has the allowed values:\u03c3 = n\u03b4, n IN and \u03c3 min \u2264\u03c3 \u2264 \u03c3 max . (\nGiven the absence of any prior knowledge, we assume a flat distribution for\u03c3 over this range, which gives us the codeword length:\nL\u03c3 = ln \u03c3 max \u2212 \u03c3 min \u03b4 . (30\n)\nNote that our receiver cannot decrypt the value of\u03c3 without knowing the value of \u03b4. If we assume that the quantization parameter \u03b4 is of the form:\n\u03b4 = 2 \u00b1k , k IN (31)\nthen it can easily be seen that it can be coded directly with a codeword length:\nL \u03b4 = 1 + | log 2 \u03b4| bits \u2248 1 + | ln \u03b4| nats (32\n)\nwhere the additional bit/nat codes for the sign in the exponent of \u03b4. The total code length for transmitting the parameters is then given by L\u03c3 + L \u03b4 .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Coding the Data", "text": "For our Gaussian data model, the probability P (\u0177) associated with a bin centred at\u0177 is:\nP (\u0177) =\u0177 +\u2206/2 \u0177\u2212\u2206/2 dk \u03c1(k;\u03c3) \u2248 \u2206 \u03c3 \u221a 2\u03c0 exp \u2212\u0177 2 /2\u03c3 2 . (33\n)\nIt can be shown numerically that this is a very good approximation (mean fractional error \u2264 1.0% \u00b1 0.8%) for all values\u03c3 \u2265 2\u2206, hence we will take \u03c3 min = 2\u2206. The code length for the data is then: In general \u03c3 differs from the nearest quantized value\u03c3 thus:\nL data = \u2212\n\u03c3 = \u03c3 + d \u03c3 , |d \u03c3 | \u2264 \u03b4 2 . (36\n)\nSo, averaging over an ensemble of data sets, and assuming a flat distribution for d \u03c3 over this range, we find:\nd 2 \u03c3 = \u03b4 2 12 , 1 \u03c3 2 \u2248 1 \u03c3 2 1 + \u03b4 2 4\u03c3 2 , ln\u03c3 2 \u2248 ln \u03c3 2 \u2212 \u03b4 2 12\u03c3 2 . (37\n)\nBy substituting these expressions into (34) and using (35) gives the following expression for the Description Length of the data:\nL data = \u2212n s ln \u2206 + n s 2 ln(2\u03c0\u03c3 2 ) + n s 2 + n s \u03b4 2 12\u03c3 2 . (38\n)\nThe total Description Length for the parameters and the data is then: which then allows us to write the above expression as:\nL (1) =\nL (1) = D (1) (\u03c3, n s , R, \u2206). (41\n)\nIn the case where \u03c3 < \u03c3 min , but the quantized data occupies more than one bin, we will model the data using a Gaussian of width \u03c3 min and a quantization parameter \u03b4 = \u03b4 * (\u03c3 min , n s ). An analogous derivation to that given above then gives us the Description Length: (2) (\u03c3, n s , R, \u2206).\nL (2) = 1 + ln \u03c3 max \u2212 \u03c3 min \u03b4 + | ln \u03b4| \u2212 n s ln \u2206 + n s 2 ln(2\u03c0\u03c3 2 min ) \u2212 n s \u03b4 2 24\u03c3 2 min + n s \u03c3 2 2\u03c3 2 min 1 + \u03b4 2 4\u03c3 2 min \u2261 D\n(\n)42\nThe only remaining case is where all the quantized data lies in one bin at the origin. This requires no further information to describe it fully, hence has a description length of zero.", "publication_ref": ["b1"], "figure_ref": [], "table_ref": []}, {"heading": "", "text": "Acknowledgements. The authors would like to thank Alan Brett and Johann Kim for their contribution to this work. Rhodri Davies would like to acknowledge the BBSRC and AstraZeneca 4 for their financial support.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "On the laplace-beltrami operator and brain surface flattening", "journal": "IEEE Trans. Medical Imaging", "year": "1999", "authors": "S Angenent; S Haker; A Tannenbaum; R Kikinis"}, {"ref_id": "b1", "title": "Parameterisation of closed surfaces for 3-D shape description", "journal": "", "year": "1995", "authors": "C Brechbulher; G Gerig; O Kubler"}, {"ref_id": "b2", "title": "A Method of automated landmark generation for automated 3D PDM construction", "journal": "Image and Vision Computing", "year": "2000", "authors": "A D Brett; C J Taylor"}, {"ref_id": "b3", "title": "Construction of 3D Shape Models of Femoral Articular Cartialge Using Harmonic Maps", "journal": "", "year": "2000", "authors": "A D Brett; C J Taylor"}, {"ref_id": "b4", "title": "The use of Active shape models for locating structures in medical images", "journal": "Image and Vision Computing", "year": "1994", "authors": "T Cootes; A Hill; C Taylor; J Haslam"}, {"ref_id": "b5", "title": "Active shape models -their training and application", "journal": "Computer Vision and Image Understanding", "year": "1995", "authors": "T Cootes; C Taylor; D Cooper; J Graham"}, {"ref_id": "b6", "title": "Volumetric Transformation of Brain Anatomy", "journal": "IEEE Trans. Medical Imaging", "year": "1997", "authors": "G E Christensen; S C Joshi; M I Miller"}, {"ref_id": "b7", "title": "A Minimum Description Length Approach to Statistical Shape Modelling", "journal": "", "year": "", "authors": "Rh H Davies; C J Twining; T F Cootes; J C Waterton; C J Taylor"}, {"ref_id": "b8", "title": "An Information Theoretic Approach to Statistical Shape Modelling", "journal": "", "year": "2001", "authors": "Rh H Davies; T F Cootes; C J Twining; C J Taylor"}, {"ref_id": "b9", "title": "Building a Complete Surface Model from Sparse Data Using Statistical Shape Models: Application to Computer Assisted Knee Surgery", "journal": "", "year": "1998", "authors": "M Fluete; S Lavalee"}, {"ref_id": "b10", "title": "Model Selection and the Principle of Minimum Description Length", "journal": "", "year": "1998", "authors": "M H Hansen; B Yu ; Murray; N J Hill"}, {"ref_id": "b11", "title": "Model based interpretation of 3D medical images", "journal": "", "year": "1993", "authors": "A Hill; A Thornham; C J Taylor"}, {"ref_id": "b12", "title": "Gaussian Random Fields on Sub-Manifolds for Characterizing Brain Surfaces", "journal": "", "year": "1997", "authors": " Joshi"}, {"ref_id": "b13", "title": "Elastic model-based segmentation of 3-D neuroradiological data sets", "journal": "IEEE Transactions On Medical Imaging", "year": "1999", "authors": "A Kelemen; G Szekely; G Gerig"}, {"ref_id": "b14", "title": "Automatic Construction of Eigenshape Models by Direct Optimisation", "journal": "Medical Image Analysis", "year": "1998", "authors": "A C W Kotcheff; C J Taylor"}, {"ref_id": "b15", "title": "Statistics of Directional Data", "journal": "Academic Press", "year": "1972", "authors": "K V Mardia"}, {"ref_id": "b16", "title": "Numerical Recipes in C", "journal": "Cambridge University Press", "year": "1993", "authors": "W H Press; S A Teukolsky; W T Vetterling; B P Flannery"}, {"ref_id": "b17", "title": "A universal prior for integers and estimation by minimum description length", "journal": "Annals of Statistics", "year": "1983", "authors": "J R Rissanen"}, {"ref_id": "b18", "title": "Stochastic Complexity in Statistical Inquiry", "journal": "World Scientific Series in Computer Science", "year": "1989", "authors": "J R Rissanen"}, {"ref_id": "b19", "title": "Fisher Information and Stochastic Complexity", "journal": "", "year": "1996", "authors": "J R Rissanen"}, {"ref_id": "b20", "title": "Automatic construction of 3D statistical deformation models using non-rigid registration", "journal": "", "year": "2001", "authors": "D Rueckert; F Frangi; J A Schnabel"}, {"ref_id": "b21", "title": "A mathematical theory of communication", "journal": "Bell System Technical Journal", "year": "1948", "authors": "C E Shannon"}, {"ref_id": "b22", "title": "Matching 3-D Anatomical Surface with Non-Rigid Deformations using Octree-Splines", "journal": "International Journal of Computer Vision", "year": "1996", "authors": "G Szeleky; S Lavalee"}, {"ref_id": "b23", "title": "Hemispherical map for the human brain cortex", "journal": "", "year": "2001", "authors": "D Tosun; J L Prince"}, {"ref_id": "b24", "title": "Shape-based 3D surface correspondence using geodesics and local geometry", "journal": "", "year": "2000", "authors": "Y Wang; B S Peterson; L H Staib"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Fig. 1 .1Fig.1. The first mode of variation (\u00b13\u03c3) of two shape models built from the training set of hand outlines but parameterised differently. Model A was parameterised using manual 'landmarks' and model B was parameterised using arc-length parameterisation. The figure demonstrates that model B can represent invalid shape instances.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "All the example shapes generated by model A using values of {b m } within the range found in the training set are 'legal' examples of hands, whilst model B generates implausible examples and is thus of limited utility for imposing shape constraints when the model is used for image search, see fig. 1.", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Fig. 2 .2Fig. 2. Left: Original sphere. Right: Sphere after asymmetric \u03b8 transformation.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Fig. 3 .3Fig. 3. Left: Original sphere. Right: Sphere after shear transformation.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Fig. 4 .4Fig. 4. Left: Original sphere. Right: Sphere after combined transformation.", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Fig. 5 .5Fig. 5. The first three modes of variation \u00b12\u03bb m of the automatically produced model of the brain ventricle", "figure_data": ""}, {"figure_label": "6", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Fig. 6 .6Fig. 6. The first three modes of variation \u00b12\u03bb m of the automatically produced model of the rat kidneys", "figure_data": ""}, {"figure_label": "7", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "Fig. 7 .7Fig. 7. A plot showing the cumulative variance described by each mode of the model. This is a measure of the compactness of each model.", "figure_data": ""}, {"figure_label": "8", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "Fig. 8 .8Fig. 8. Leave one out tests on the models. The plot shows the number of modes used against the mean squared approximation error. This measures the ability of each model to generalise to unseen examples.", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "2 i2ns i=1 ln P (\u0177 i ) = \u2212n s ln \u2206 + n and \u03c3 max = R. (35)", "figure_data": ""}, {"figure_label": "222", "figure_type": "figure", "figure_id": "fig_10", "figure_caption": "2 ln(2\u03c0\u03c3 2 )+ n s 2 + n s \u03b4 2 12\u03c3 2 .2221+ln \u03c3 max \u2212 \u03c3 min \u03b4 +| ln \u03b4|\u2212n s ln \u2206+ n s (39)By differentiating w.r.t. \u03b4 and setting the derivative to zero, we find that the optimum parameter accuracy \u03b4 is:\u03b4 * (\u03c3, n s ) = min 1, \u03c3 12 n s (40)", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "A quantitative comparison of each model showing the variance explained by each mode. F is the value of the objective function and VT is the total variance.", "figure_data": "KidneysVentriclesMode Automatic UniformMode Automatic Uniform13.063.23111.9812.5822.753.0121.411.7731.351.7031.161.4940.941.0840.690.7950.760.8750.360.4560.460.5760.220.24V T10.5111.98V T15.9017.46F13961417F366371"}], "formulas": [{"formula_id": "formula_0", "formula_text": "x i =x + Pb i =x + m p m b m i ,(1)", "formula_coordinates": [3.0, 148.61, 69.01, 240.99, 22.54]}, {"formula_id": "formula_1", "formula_text": "Dp m = \u03bb m p m . (2", "formula_coordinates": [3.0, 183.64, 257.68, 201.71, 12.09]}, {"formula_id": "formula_2", "formula_text": ")", "formula_coordinates": [3.0, 385.35, 259.81, 4.24, 9.96]}, {"formula_id": "formula_3", "formula_text": "D p m = \u03bb m p m From (2) : Dp m = \u03bb m p m \u21d2 1 n p n s WW T p m = \u03bb m p m ,(3)", "formula_coordinates": [3.0, 153.74, 312.68, 235.85, 54.0]}, {"formula_id": "formula_4", "formula_text": "\u21d2 D (W T p m ) = \u03bb m (W T p m ) Similarly: D(Wp m ) = \u03bb m (Wp m ).(4)", "formula_coordinates": [3.0, 134.13, 396.31, 255.46, 29.1]}, {"formula_id": "formula_5", "formula_text": "\u03bb m = \u03bb m and p m = Wp m . (5", "formula_coordinates": [3.0, 154.03, 457.82, 231.32, 11.83]}, {"formula_id": "formula_6", "formula_text": ")", "formula_coordinates": [3.0, 385.35, 459.69, 4.24, 9.96]}, {"formula_id": "formula_7", "formula_text": "D ij = dt (S i (\u03c6 i (t)) \u2212S(t)) \u2022 (S j (\u03c6 j (t)) \u2212S(t))(6)", "formula_coordinates": [3.0, 108.41, 544.34, 281.19, 11.68]}, {"formula_id": "formula_8", "formula_text": "x i =x + ns\u22121 m=1 p m b m i . (7", "formula_coordinates": [5.0, 173.05, 447.23, 212.3, 31.17]}, {"formula_id": "formula_9", "formula_text": ")", "formula_coordinates": [5.0, 385.35, 457.55, 4.24, 9.96]}, {"formula_id": "formula_10", "formula_text": "y m i \u2261p m \u2022 (x i \u2212x). (8", "formula_coordinates": [5.0, 174.02, 582.58, 211.33, 13.55]}, {"formula_id": "formula_11", "formula_text": ")", "formula_coordinates": [5.0, 385.35, 584.45, 4.24, 9.96]}, {"formula_id": "formula_12", "formula_text": "\u2212 r 2 \u2264 x i\u03b1 \u2264 r 2 for all \u03b1 = 1 to n p , i = 1 to n s . (9", "formula_coordinates": [6.0, 111.73, 272.38, 273.62, 23.54]}, {"formula_id": "formula_13", "formula_text": ")", "formula_coordinates": [6.0, 385.35, 279.12, 4.24, 9.96]}, {"formula_id": "formula_14", "formula_text": "R = r \u221a n p , so that |y m i | \u2264 R for all i, m. (10", "formula_coordinates": [6.0, 125.86, 320.88, 259.3, 17.91]}, {"formula_id": "formula_15", "formula_text": ")", "formula_coordinates": [6.0, 385.16, 327.12, 4.43, 9.96]}, {"formula_id": "formula_16", "formula_text": "(\u03c3 m ) 2 = 1 n s ns i=1 (\u0177 m i ) 2 . (11", "formula_coordinates": [6.0, 168.88, 476.78, 216.28, 31.29]}, {"formula_id": "formula_17", "formula_text": ")", "formula_coordinates": [6.0, 385.16, 487.11, 4.43, 9.96]}, {"formula_id": "formula_18", "formula_text": "\u2022 If \u03c3 m \u2265 \u03c3 min : D m = D (1) (\u03c3 m , n s , R, \u2206) \u2022 If \u03c3 m < \u03c3 min but the range of\u0176 m \u2265 \u2206: D m = D (2) (\u03c3 m , n s , R, \u2206) \u2022 Else: D m = 0.", "formula_coordinates": [6.0, 43.77, 537.06, 320.85, 37.06]}, {"formula_id": "formula_19", "formula_text": "F = ng p=1 D (1) (\u03c3 p , n s , R, \u2206) + ng+nmin q=ng+1 D (2) (\u03c3 q , n s , R, \u2206). (12", "formula_coordinates": [7.0, 96.57, 131.88, 288.59, 32.14]}, {"formula_id": "formula_20", "formula_text": ")", "formula_coordinates": [7.0, 385.16, 143.18, 4.43, 9.96]}, {"formula_id": "formula_21", "formula_text": "n p \u03bb m = 1 n s ns i=1 (y m i ) 2(13)", "formula_coordinates": [7.0, 171.2, 196.39, 218.39, 31.29]}, {"formula_id": "formula_22", "formula_text": "\u03c3 m \u2192 n p \u03bb m . (14", "formula_coordinates": [7.0, 183.77, 257.34, 201.39, 12.58]}, {"formula_id": "formula_23", "formula_text": ")", "formula_coordinates": [7.0, 385.16, 259.21, 4.43, 9.96]}, {"formula_id": "formula_24", "formula_text": "D (1) (\u03c3 m , n s , R, \u2206) \u2248 f (R, \u2206, n s ) + (n s \u2212 2) ln \u03c3 m (15", "formula_coordinates": [7.0, 43.76, 307.63, 341.98, 12.58]}, {"formula_id": "formula_25", "formula_text": ")", "formula_coordinates": [7.0, 385.75, 309.5, 4.43, 9.96]}, {"formula_id": "formula_26", "formula_text": "D (2) (\u03c3 m , n s , R, \u2206) \u2248 f (R, \u2206, n s ) + (n s \u2212 2) ln \u03c3 min + (n s + 3) 2 \u03c3 m \u03c3 min 2 \u2212 1", "formula_coordinates": [7.0, 43.77, 323.67, 338.94, 27.29]}, {"formula_id": "formula_27", "formula_text": "S i = S i (\u03b8, \u03c8), S i R 3 (16)", "formula_coordinates": [8.0, 167.2, 105.23, 222.39, 12.58]}, {"formula_id": "formula_28", "formula_text": "S i \u2192 S i , \u03b8 \u2192 \u03b8 , \u03c8 \u2192 \u03c8 (17", "formula_coordinates": [8.0, 159.55, 223.67, 225.62, 11.68]}, {"formula_id": "formula_29", "formula_text": ")", "formula_coordinates": [8.0, 385.16, 223.67, 4.43, 9.96]}, {"formula_id": "formula_30", "formula_text": "\u03b8 \u2192 f (\u03b8). (18", "formula_coordinates": [8.0, 195.74, 390.93, 189.42, 9.96]}, {"formula_id": "formula_31", "formula_text": ")", "formula_coordinates": [8.0, 385.17, 390.93, 4.43, 9.96]}, {"formula_id": "formula_32", "formula_text": "\u03c1(\u03b8) = 1 N 1 + A 1 \u2212 \u03b1 2 1 + \u03b1 2 \u2212 2\u03b1 cos \u03b8 (19", "formula_coordinates": [8.0, 130.17, 513.8, 255.0, 24.91]}, {"formula_id": "formula_33", "formula_text": ")", "formula_coordinates": [8.0, 385.17, 521.92, 4.43, 9.96]}, {"formula_id": "formula_34", "formula_text": "f (\u03b8) = \u03c0 \u03b8 0 ds \u03c1(s) = 1 1 + A \u03b8 + A arccos (1 + \u03b1 2 ) cos \u03b8 \u2212 2\u03b1 1 + \u03b1 2 \u2212 2\u03b1 cos \u03b8 (20)", "formula_coordinates": [8.0, 64.01, 560.39, 325.59, 37.26]}, {"formula_id": "formula_35", "formula_text": "\u03b8 \u2192 f (\u03b8, \u03c8). (21", "formula_coordinates": [9.0, 190.1, 384.3, 195.06, 9.96]}, {"formula_id": "formula_36", "formula_text": ")", "formula_coordinates": [9.0, 385.16, 384.3, 4.43, 9.96]}, {"formula_id": "formula_37", "formula_text": "A \u2192 A(\u03c8 ). (22", "formula_coordinates": [9.0, 191.38, 458.06, 193.79, 9.96]}, {"formula_id": "formula_38", "formula_text": ")", "formula_coordinates": [9.0, 385.16, 458.06, 4.43, 9.96]}, {"formula_id": "formula_39", "formula_text": "A(\u03c8 ) = A 0 1 \u2212 \u03b2 2 1 + \u03b2 2 \u2212 2\u03b2 cos \u03c8 \u2212 1 \u2212 \u03b2 2 (1 + \u03b2) 2 (23", "formula_coordinates": [9.0, 119.76, 499.65, 265.4, 24.91]}, {"formula_id": "formula_40", "formula_text": ")", "formula_coordinates": [9.0, 385.16, 507.76, 4.43, 9.96]}, {"formula_id": "formula_41", "formula_text": "\u03c8 \u2192 \u03c8 + g(\u03b8) (24", "formula_coordinates": [10.0, 187.09, 113.7, 198.08, 9.96]}, {"formula_id": "formula_42", "formula_text": ")", "formula_coordinates": [10.0, 385.16, 113.7, 4.43, 9.96]}, {"formula_id": "formula_43", "formula_text": "g(\u03b8) = B 2\u03c0 1 \u2212 \u03b3 2 1 + \u03b3 2 \u2212 2\u03b3 cos (\u03b8 \u2212 \u03b8 0 ) (25", "formula_coordinates": [10.0, 134.62, 143.79, 250.55, 25.66]}, {"formula_id": "formula_44", "formula_text": ")", "formula_coordinates": [10.0, 385.16, 151.91, 4.43, 9.96]}, {"formula_id": "formula_45", "formula_text": "\u03c1(y; \u03c3) = 1 \u03c3 \u221a 2\u03c0 exp \u2212 y 2 2\u03c3 2 . (26", "formula_coordinates": [14.0, 150.21, 476.07, 234.96, 26.02]}, {"formula_id": "formula_46", "formula_text": ")", "formula_coordinates": [14.0, 385.16, 484.19, 4.43, 9.96]}, {"formula_id": "formula_49", "formula_text": "L\u03c3 = ln \u03c3 max \u2212 \u03c3 min \u03b4 . (30", "formula_coordinates": [15.0, 160.55, 276.63, 224.61, 23.54]}, {"formula_id": "formula_50", "formula_text": ")", "formula_coordinates": [15.0, 385.16, 283.36, 4.43, 9.96]}, {"formula_id": "formula_51", "formula_text": "\u03b4 = 2 \u00b1k , k IN (31)", "formula_coordinates": [15.0, 183.46, 342.86, 206.13, 11.83]}, {"formula_id": "formula_52", "formula_text": "L \u03b4 = 1 + | log 2 \u03b4| bits \u2248 1 + | ln \u03b4| nats (32", "formula_coordinates": [15.0, 130.28, 388.71, 254.89, 11.65]}, {"formula_id": "formula_53", "formula_text": ")", "formula_coordinates": [15.0, 385.17, 388.71, 4.43, 9.96]}, {"formula_id": "formula_54", "formula_text": "P (\u0177) =\u0177 +\u2206/2 \u0177\u2212\u2206/2 dk \u03c1(k;\u03c3) \u2248 \u2206 \u03c3 \u221a 2\u03c0 exp \u2212\u0177 2 /2\u03c3 2 . (33", "formula_coordinates": [15.0, 110.05, 496.32, 275.11, 38.85]}, {"formula_id": "formula_55", "formula_text": ")", "formula_coordinates": [15.0, 385.16, 510.49, 4.43, 9.96]}, {"formula_id": "formula_56", "formula_text": "L data = \u2212", "formula_coordinates": [16.0, 82.51, 97.57, 44.2, 10.71]}, {"formula_id": "formula_57", "formula_text": "\u03c3 = \u03c3 + d \u03c3 , |d \u03c3 | \u2264 \u03b4 2 . (36", "formula_coordinates": [16.0, 168.44, 195.58, 216.72, 23.54]}, {"formula_id": "formula_58", "formula_text": ")", "formula_coordinates": [16.0, 385.16, 202.32, 4.43, 9.96]}, {"formula_id": "formula_59", "formula_text": "d 2 \u03c3 = \u03b4 2 12 , 1 \u03c3 2 \u2248 1 \u03c3 2 1 + \u03b4 2 4\u03c3 2 , ln\u03c3 2 \u2248 ln \u03c3 2 \u2212 \u03b4 2 12\u03c3 2 . (37", "formula_coordinates": [16.0, 93.75, 252.36, 291.41, 24.91]}, {"formula_id": "formula_60", "formula_text": ")", "formula_coordinates": [16.0, 385.17, 260.48, 4.43, 9.96]}, {"formula_id": "formula_61", "formula_text": "L data = \u2212n s ln \u2206 + n s 2 ln(2\u03c0\u03c3 2 ) + n s 2 + n s \u03b4 2 12\u03c3 2 . (38", "formula_coordinates": [16.0, 116.16, 313.7, 269.01, 24.91]}, {"formula_id": "formula_62", "formula_text": ")", "formula_coordinates": [16.0, 385.17, 321.81, 4.43, 9.96]}, {"formula_id": "formula_63", "formula_text": "L (1) =", "formula_coordinates": [16.0, 48.75, 366.14, 28.08, 11.83]}, {"formula_id": "formula_64", "formula_text": "L (1) = D (1) (\u03c3, n s , R, \u2206). (41", "formula_coordinates": [16.0, 163.9, 470.78, 221.26, 12.58]}, {"formula_id": "formula_65", "formula_text": ")", "formula_coordinates": [16.0, 385.17, 472.65, 4.43, 9.96]}, {"formula_id": "formula_66", "formula_text": "L (2) = 1 + ln \u03c3 max \u2212 \u03c3 min \u03b4 + | ln \u03b4| \u2212 n s ln \u2206 + n s 2 ln(2\u03c0\u03c3 2 min ) \u2212 n s \u03b4 2 24\u03c3 2 min + n s \u03c3 2 2\u03c3 2 min 1 + \u03b4 2 4\u03c3 2 min \u2261 D", "formula_coordinates": [16.0, 74.61, 544.78, 284.14, 53.86]}, {"formula_id": "formula_67", "formula_text": ")42", "formula_coordinates": [16.0, 376.31, 579.82, 13.29, 9.96]}], "doi": ""}