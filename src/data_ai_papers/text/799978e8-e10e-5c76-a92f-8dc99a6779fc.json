{"title": "Construction of Dependent Dirichlet Processes based on Poisson Processes", "authors": "Dahua Lin; Eric Grimson; John Fisher", "pub_date": "", "abstract": "We present a novel method for constructing dependent Dirichlet processes. The approach exploits the intrinsic relationship between Dirichlet and Poisson processes in order to create a Markov chain of Dirichlet processes suitable for use as a prior over evolving mixture models. The method allows for the creation, removal, and location variation of component models over time while maintaining the property that the random measures are marginally DP distributed. Additionally, we derive a Gibbs sampling algorithm for model inference and test it on both synthetic and real data. Empirical results demonstrate that the approach is effective in estimating dynamically varying mixture models.", "sections": [{"heading": "Introduction", "text": "As the cornerstone of Bayesian nonparametric modeling, Dirichlet processes (DP) [22] have been applied to a wide variety of inference and estimation problems [3,10,20] with Dirichlet process mixtures (DPMs) [15,17] being one of the most successful. DPMs are a generalization of finite mixture models that allow an indefinite number of mixture components. The traditional DPM model assumes that each sample is generated independently from the same DP. This assumption is limiting in cases when samples come from many, yet dependent, DPs. HDPs [23] partially address this modeling aspect by providing a way to construct multiple DPs implicitly depending on each other via a common parent. However, their hierarchical structure may not be appropriate in some problems (e.g. temporally varying DPs).\nConsider a document model where each document is generated under a particular topic and each topic is characterized by a distribution over words. Over time, topics change: some old topics fade while new ones emerge. For each particular topic, the word distribution may evolve as well. A natural approach to model such topics is to use a Markov chain of DPs as a prior, such that the DP at each time is generated by varying the previous one in three possible ways: creating a new topic, removing an existing topic, and changing the word distribution of a topic.\nSince MacEachern introduced the notion of dependent Dirichlet processes (DDP) [12], a variety of DDP constructions have been developed, which are based on either weighted mixtures of DPs [6,14,18], generalized Chinese restaurant processes [4,21,24], or the stick breaking construction [5,7]. Here, we propose a fundamentally different approach, taking advantage of the intrinsic relationship between Dirichlet processes and Poisson processes: a Dirichlet process is a normalized Gamma process, while a Gamma process is essentially a compound Poisson process. The key idea is motivated by the following: observations that preserve complete randomness when applied to Poisson processes result in a new process that remains Poisson. Consequently, one can obtain a Dirichlet process which is dependent on other DPs by applying such operations to their underlying compound Poisson processes. In particular, we discuss three specific operations: superposition, subsampling, and point transition. We develop a Markov chain of DPs by combining these operations, leading to a framework that allows creation, removal, and location variation of particles. This construction inherently comes with an elegant property that the random measure at each time is marginally DP distributed. Our approach relates to previous efforts in constructing dependent DPs while overcoming inherent limitations. A detailed comparison is given in section 4.", "publication_ref": ["b21", "b2", "b9", "b19", "b14", "b16", "b22", "b11", "b5", "b13", "b17", "b3", "b20", "b23", "b4", "b6"], "figure_ref": [], "table_ref": []}, {"heading": "Poisson, Gamma, and Dirichlet Processes", "text": "Our construction of dependent Dirichlet processes rests upon the connection between Poisson, Gamma, and Dirichlet processes, as well as the concept of complete randomness. We briefly review these concepts; Kingman [9] provides a detailed exposition of the relevant theory.\nLet (\u2126, F \u2126 ) be a measurable space, and \u03a0 be a random point process on \u2126. Each realization of \u03a0 uniquely corresponds to a counting measure N \u03a0 defined by N \u03a0 (A) #(\u03a0 \u2229 A) for each A \u2208 F \u2126 . Hence, N \u03a0 is a measure-valued random variable or simply a random measure. A Poisson process \u03a0 on \u2126 with mean measure \u00b5, denoted \u03a0 \u223c PoissonP(\u00b5), is defined to be a point process such that N \u03a0 (A) has a Poisson distribution with mean \u00b5(A) and that for any disjoint measurable sets A 1 , . . . , A n , N \u03a0 (A 1 ), . . . , N \u03a0 (A n ) are independent. The latter property is referred to as complete randomness. Poisson processes are the only point process that satisfies this property [9]: Theorem 1. A random point process \u03a0 on a regular measure space is a Poisson process if and only if N \u03a0 is completely random. If this is true, the mean measure is given by \u00b5(A) = E(N \u03a0 (A)).\nConsider \u03a0 * \u223c PoissonP(\u00b5 * ) on a product space \u2126 \u00d7 R + . For each realization of \u03a0 * , We define\n\u03a3 * : F \u2126 \u2192 [0, +\u221e] as \u03a3 * (\u03b8,w \u03b8 )\u2208\u03a0 * w \u03b8 \u03b4 \u03b8 (1)\nIntuitively, \u03a3 * (A) sums up the values of w \u03b8 with \u03b8 \u2208 A. Note that \u03a3 * is also a completely random measure (but not a point process in general), and is essentially a generalization of the compound Poisson process. As a special case, if we choose \u00b5 * to be\n\u00b5 * = \u00b5 \u00d7 \u03b3 with \u03b3(dw) = w \u22121 e \u2212w dw,(2)\nThen the random measure as defined in Eq.( 1) is called a Gamma process with base measure \u00b5, denoted by G \u223c \u0393P(\u00b5). Normalizing any realization of G \u223c \u0393P(\u00b5) yields a sample of a Dirichlet process, as\nD G/G(\u2126) \u223c DP(\u00b5).(3)\nIn conventional parameterization, \u00b5 is often decomposed into two parts: a base distribution p \u00b5 \u00b5/\u00b5(\u2126), and a concentration parameter \u03b1 \u00b5 \u00b5(\u2126).", "publication_ref": ["b8", "b8"], "figure_ref": [], "table_ref": []}, {"heading": "Construction of Dependent Dirichlet Processes", "text": "Motivated by the relationship between Poisson and Dirichlet processes, we develop a new approach for constructing dependent Dirichlet processes (DDPs). Our approach can be described as follows:\ngiven a collection of Dirichlet processes, one can apply operations that preserve the complete randomness of their underlying Poisson processes. This yields a new Poisson process (due to theorem 1) and a related DP which depends on the source. In particular, we consider three such operations: superposition, subsampling, and point transition.\nSuperposition of Poisson processes: Combining a set of independent Poisson processes yields a Poisson process whose mean measure is the sum of mean measures of the individual ones. Theorem 2 (Superposition Theorem [9]). Let \u03a0 1 , . . . , \u03a0 m be independent Poisson processes on \u2126 with \u03a0 k \u223c PoissonP(\u00b5 k ), then their union has\n\u03a0 1 \u222a \u2022 \u2022 \u2022 \u222a \u03a0 m \u223c PoissonP(\u00b5 1 + \u2022 \u2022 \u2022 + \u00b5 m ).(4)\nGiven a collection of independent Gamma processes G 1 , . . . , G m , where for each k = 1, . . . , m, G k \u223c \u0393P(\u00b5 k ) with underlying Poisson process \u03a0 * k \u223c PoissonP(\u00b5 k \u00d7 \u03b3). By theorem 2, we have\nm k=1 \u03a0 * k \u223c PoissonP m k=1 (\u00b5 k \u00d7 \u03b3) = PoissonP m k=1 \u00b5 k \u00d7 \u03b3 .(5)\nDue to the relationship between Gamma processes and their underlying Poisson processes, such a combination is equivalent to the direct superposition of the Gamma processes themselves, as\nG := G 1 + \u2022 \u2022 \u2022 + G m \u223c \u0393P(\u00b5 1 + \u2022 \u2022 \u2022 + \u00b5 m ).(6)\nLet D k = G k /G k (\u2126), and g k = G k (\u2126), then D k is independent of g k , and thus\nD := G /G (\u2126) = (g 1 D 1 + \u2022 \u2022 \u2022 + g m D m )/(g 1 + \u2022 \u2022 \u2022 + g m ) = c 1 D 1 + \u2022 \u2022 \u2022 + c m D m . (7)\nHere, c k = g k / m l=1 g l , which has (c 1 , . . . , c m ) \u223c Dir(\u00b5 1 (\u2126), . . . , \u00b5 m (\u2126)). Consequently, one can construct a Dirichlet process through a random convex combination of independent Dirichlet processes. This result is summarized by the following theorem: Theorem 3. Let D 1 , . . . , D m be independent Dirichlet processes on \u2126 with D k \u223c DP(\u00b5 k ), and (c 1 , . . . , c m ) \u223c Dir(\u00b5 1 (\u2126), . . . , \u00b5 m (\u2126)) be independent of D 1 , . . . , D m , then\nD 1 \u2295 \u2022 \u2022 \u2022 \u2295 D m := c 1 D 1 + \u2022 \u2022 \u2022 c m D m \u223c DP(\u00b5 1 + \u2022 \u2022 \u2022 + \u00b5 m ).(8)\nHere, we use the symbol \u2295 to indicate superposition via a random convex combination. Let \u03b1 k = \u00b5 k (\u2126) and \u03b1 = m k=1 \u03b1 k , then for each measurable subset A,\nE(D (A)) = m k=1 \u03b1 k \u03b1 E(D k (A)), and Cov(D (A), D k (A)) = \u03b1 k \u03b1 Var(D k (A)).(9)\nSubsampling Poisson processes: Random subsampling of a Poisson process via independent Bernoulli trials yields a new Poisson process. Theorem 4 (Subsampling Theorem). Let \u03a0 \u223c PoissonP(\u00b5) be a Poisson process on the space \u2126, and q : \u2126 \u2192 [0, 1] be a measurable function. If we independently draw z \u03b8 \u2208 {0, 1} for each \u03b8 \u2208 \u03a0 0 with P(z \u03b8 = 1) = q(\u03b8), and let \u03a0 k = {\u03b8 \u2208 \u03a0 : z \u03b8 = k} for k = 0, 1, then \u03a0 0 and \u03a0 1 are independent Poisson processes on \u2126, with\n\u03a0 0 \u223c PoissonP((1 \u2212 q)\u00b5) and \u03a0 1 \u223c PoissonP(q\u00b5) 1 .\nWe emphasize that subsampling is via independent Bernoulli trials rather than choosing a fixed number of particles. We use S q (\u03a0) := \u03a0 1 to denote the result of subsampling, where q is referred to as the acceptance function. Note that subsampling the underlying Poisson process of a Gamma process G is equivalent to subsampling the terms of G. Let G = \u221e i=1 w i \u03b4 \u03b8i , and for each i, we draw z i with P(z i = 1) = q(\u03b8 i ). Then, we have\nG = S q (G) := i:zi=1 w i \u03b4 \u03b8i \u223c \u0393P(q\u00b5). (10\n)\nLet D be a Dirichlet process given by D = G/G(\u2126), then we can construct a new Dirichlet process D = G /G (\u2126) by subsampling the terms of D and renormalizing their coefficients. This is summarized by the following theorem. Theorem 5. Let D \u223c DP(\u00b5) be represented by D = n i=1 r i \u03b4 \u03b8i and q : \u2126 \u2192 [0, 1] be a measurable function. For each i we independently draw z i with P(z i = 1) = q(\u03b8 i ), then\nD = S q (D) := i:zi=1 r i \u03b4 \u03b8i \u223c DP(q\u00b5),(11)\nwhere r i := r i / j:zj =1 r j are the re-normalized coefficients for those i with z i = 1.\nLet \u03b1 = \u00b5(\u2126) and \u03b1 = (q\u00b5)(\u2126), then for each measurable subset A,\nE(D (A)) = (q\u00b5)(A) (q\u00b5)(\u2126) = A qd\u00b5 \u2126 qd\u00b5 ,and\nCov(D (A), D(A)) = \u03b1 \u03b1 Var(D (A)).(12)\nPoint transition of Poisson processes: The third operation moves each point independently following a probabilistic transition. Formally, a probabilistic transition is defined to be a function\nT : \u2126 \u00d7 F \u2126 \u2192 [0, 1] such that for each \u03b8 \u2208 F \u2126 , T (\u03b8, \u2022\n) is a probability measure on \u2126 that describes the distribution of where \u03b8 moves, and for each A \u2208 F \u2126 , T (\u2022, A) is integrable. T can be considered as a transformation of measures over \u2126, as\n(T \u00b5)(A) := \u2126 T (\u03b8, A)\u00b5(d\u03b8). (13\n)\n1 q\u00b5 is a measure on \u2126 given by (q\u00b5)(A) = R A qd\u00b5, or equivalently (q\u00b5)(d\u03b8) = q(\u03b8)\u00b5(d\u03b8).\nTheorem 6 (Transition Theorem). Let \u03a0 \u223c PoissonP(\u00b5) and T be a probabilistic transition, then\nT (\u03a0) := {T (\u03b8) : \u03b8 \u2208 \u03a0} \u223c PoissonP(T \u00b5).(14)\nWith a slight abuse of notation, we use T (\u03b8) to denote an independent sample from T (\u03b8, \u2022).\nAs a consequence, we can derive a Gamma process and thus a Dirichlet process by applying the probabilistic transition to the location of each term, leading to the following:\nTheorem 7. Let D = \u221e i=1 r i \u03b4 \u03b8i \u223c DP(\u00b5) be a Dirichlet process on \u2126, then T (D) := \u221e i=1 r i \u03b4 T (\u03b8i) \u223c DP(T \u00b5).(15)\nTheorems 1 and 2 are immediate consequences of the results in [9]. We derive Theorems 3 to Theorem 7 independently as part of the proposed approach. Detailed explanation of relevant concepts and the proofs of Theorem 2 to Theorem 7 are provided in the supplement.", "publication_ref": ["b8", "b8"], "figure_ref": [], "table_ref": []}, {"heading": "A Markov Chain of Dirichlet Processes", "text": "Integrating these three operations, we construct a Markov chain of DPs formulated as\nD t = T (S q (D t\u22121 )) \u2295 H t , with H t \u223c DP(\u03bd).(16)\nThe model can be explained as follows: given D t\u22121 , we choose a subset of terms by subsampling, then move their locations via a probabilistic transition T , and finally superimpose a new DP H t on the resultant process to form D t . Hence, creating new particles, removing existing particles, and varying particle locations are all allowed, respectively, via superposition, subsampling, and point transition. Note that while they are based on the operations of the underlying Poisson processes, due to theorems 3, 5, and 7, we operate directly on the DPs, without the need of explicitly instantiating the associated Poisson processes or Gamma processes. Let \u00b5 t be the base measure of D t , then\n\u00b5 t = T (q\u00b5 t\u22121 ) + \u03bd.(17)\nParticularly, if the acceptance probability q is a constant, then \u03b1 t = q\u03b1 t\u22121 + \u03b1 \u03bd . Here, \u03b1 t = \u00b5 t (\u2126) and \u03b1 \u03bd = \u03bd(\u2126) are the concentration parameters. One may hold \u03b1 t fixed over time by choosing appropriate values for q and \u03b1 \u03bd . Furthermore, it can be shown that\nCov(D t+n (A), D t (A)) \u2264 q n Var(D t (A)).(18)\nThe covariance with previous DPs decays exponentially when q < 1. This is often a desirable property in practice. Moreover, we note that \u03bd and q play different roles in controlling the process. Generally, \u03bd determines how frequently new terms appear; while q governs the life span of a term which has a geometric distribution with mean (1 \u2212 q) \u22121 .\nWe aim to use the Markov chain of DPs as a prior of evolving mixture models. This provides a mechanism with which new component models can be brought in, existing components can be removed, and the model parameters can vary smoothly over time.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Comparison with Related Work", "text": "In his pioneering work [12], MacEachern proposed the \"single-p DDP model\". It considers DDP as a collection of stochastic processes, but does not provide a natural mechanism to change the collection size over time. M\u00fcller et al [14] formulated each DP as a weighted mixture of a common DP and an independent DP. This formulation was extended by Dunson [6] in modeling latent trait distributions. Zhu et al [24] presented the Time-sensitive DP, in which the contribution of each DP decays exponentially. Teh et al [23] proposed the HDP where each child DP takes its parent DP as the base measure. Ren [18] combines the weighted mixture formulation with HDP to construct the dynamic HDP. In contrast to the model proposed here, a fundamental difference of these models is that the marginal distribution at each node is generally not a DP.\nCaron et al [4] developed a generalized Polya Urn scheme while Ahmed and Xing [1] developed the recurrent Chinese Restaurant process (CRP). Both generalize the CRP to allow time-variation, while retaining the property of being marginally DP. The motivation underlying these methods fundamentally differs from ours, leading to distinct differences in the sampling algorithm. In particular, [4] supports innovation and deletion of particles, but does not support variation of locations. Moreover, its deletion scheme is based on the distribution in history, but not on whether a component model fits the new observation. While [1] does support innovation and point transition, there is no explicit way to delete old particles. It can be considered a special case of the proposed framework in which subsampling operation is not incorporated. We note that [1] is motivated from an algorithmic rather than theoretical perspective.\nGrifin and Steel [7] present the \u03c0DDP based on the stick breaking construction [19], reordering the stick breaking ratios for each time so as to obtain different distributions over the particles. This work is further extended [8] to a generic stick breaking processes. Chung et al [5] propose a local DP that generalizes \u03c0DDP. Rather than reordering the stick breaking ratios, they regroup them locally such that dependent DPs can be constructed over a general covariate space. Inference in these models requires sampling a series of auxiliary variables, considerably increasing computational costs. Moreover, the local DP relies on a truncated approximation to devise the sampling scheme.\nRecently, Rao and Teh [16] proposed the spatially normalized Gamma process. They construct a universal Gamma process in an auxiliary space and obtain dependent DPs by normalizing it within overlapped local regions. The theoretical foundation differs in that it does not exploit the relationship between the Gamma and Poisson process which is at the heart of the proposed model. In [16], the dependency is established through region overlapping; while in our work, this is accomplished by explicitly transferring particles from one DP to another. In addition, this work does not support location variation, as it relies on a universal particle pool that is fixed over time.", "publication_ref": ["b11", "b13", "b5", "b23", "b22", "b17", "b3", "b0", "b3", "b0", "b0", "b6", "b18", "b7", "b4", "b15", "b15"], "figure_ref": [], "table_ref": []}, {"heading": "The Sampling Algorithm", "text": "We develop a Gibbs sampling procedure based on the construction of DDPs introduced above. The key idea is to derive sampling steps by exploiting the fact that our construction maintains the property of being marginally DP via connections to the underlying Poisson processes. Furthermore, the derived procedure unifies distinct aspects (innovation, removal, and transition) of our model. Let D \u223c DP(\u00b5) be a Dirichlet process on \u2126. Then given a set of samples \u03a6 \u223c D, in which \u03c6 i appears c i times, we have D|\u03a6 \u223c DP(\u00b5 + c 1 \u03b4 \u03c61 + \u2022 \u2022 \u2022 + c n \u03b4 \u03c6n ). Let D be a Dirichlet process depending on D as in Eq.( 16), \u03b1 0 = (q\u00b5)(\u2126), and q i = q(\u03b8 i ). Given \u03a6 \u223c D, we have\nD |\u03a6 \u223c DP \u03b1 \u03bd p \u03bd + \u03b1 0 p q\u00b5 + m k=1 q k c k T (\u03c6 k , \u2022) .(19)\nSampling from D . Let \u03b8 1 \u223c D . Marginalizing over D , we get\n\u03b8 1 |\u03a6 \u223c \u03b1 \u03bd \u03b1 1 p \u03bd + \u03b1 0 \u03b1 1 p q\u00b5 + m k=1 q k c k \u03b1 1 T (\u03c6 k , \u2022) with \u03b1 1 = \u03b1 \u03bd + \u03b1 0 + m k=1 q k c k .(20)\nThus we sample \u03b8 1 from three types of sources: the innovation distribution p \u03bd , the q-subsampled base distribution p q\u00b5 , and the transition distribution T (\u03c6 k , \u2022). In doing so, we first sample a variable u 1 that indicates which source to sample from. Specifically, when u 1 = \u22121, u 1 = 0, or u 1 = l > 0, we respectively sample \u03b8 1 from p \u03bd , p q\u00b5 , or T (\u03c6 l , \u2022). The probabilities of these cases are \u03b1 \u03bd /\u03b1 1 , \u03b1 0 /\u03b1 1 , and q i c i /\u03b1 1 respectively. After u 1 is obtained, we then draw \u03b8 1 from the indicated source. The next issue is how to update the posterior given \u03b8 1 and u 1 . The answer depends on the value of u 1 . When u 1 = \u22121 or 0, \u03b8 1 is a new particle, and we have\nD |\u03b8 1 , {u 1 \u2264 0} \u223c DP \u03b1 \u03bd p \u03bd + \u03b1 0 p q\u00b5 + m k=1 q k c k T (\u03c6 k , \u2022) + \u03b4 \u03b81 .(21)\nIf u 1 = l > 0, we know that the particle \u03c6 l is retained in the subsampling process (i.e. the corresponding Bernoulli trial outputs 1), and the transited version T (\u03c6 l ) is determined to be \u03b8 1 . Hence,\nD |\u03b8 1 , {u 1 = l > 0} \u223c DP \uf8eb \uf8ed \u03b1 \u03bd p \u03bd + \u03b1 0 p q\u00b5 + k =l q k c k T (\u03b8 k , \u2022) + (c l + 1)\u03b4 \u03b81 \uf8f6 \uf8f8 .(22)\nWith this posterior distribution, we can subsequently draw the second sample and so on. This process generalizes the Chinese restaurant process in several ways: (1) it allows either inheriting previous particles or drawing new ones; (2) it uses q k to control the chance that we sample a previous particle;\n(3) the transition T allows smooth variation when we inherit a previous particle.\nInference with Mixture Models. We use the Markov chain of DPs as the prior of evolving mixture models. The generation process is formulated as \u03b8 1 , . . . , \u03b8 n \u223c D i.i.d., and\nx i \u223c L(\u03b8 i ), i = 1, . . . , n.(23)\nHere, L(\u03b8 i ) is the observation model parameterized by \u03b8 i . According to the analysis above, we derive an algorithm to sample \u03b8 1 , . . . , \u03b8 n conditioned on the observations x 1 , . . . , x n as follows.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Initialization. (1)", "text": "Letm denote the number of particles, which is initialized to be m and will increase as we draw new particles from p \u03bd or p q\u00b5 . (2) Let w k denote the prior weights of different sampling sources which may also change during the sampling. Particularly, we set w k = q k c k for k > 0, w \u22121 = \u03b1 \u03bd , and w 0 = \u03b1 0 . (3) Let \u03c8 k denote the particles, whose value is decided when a new particle or the transited version of a previous one is sampled. (4) The label l i indicates to which particle \u03b8 i corresponds and the counter r k records the number of times that \u03c8 k has been sampled (set to 0 initially). (5) We compute the expected likelihood, as given by F (k, i) := E p k (f (x i |\u03b8)). Here, f (x i |\u03b8) is the likelihood of x j with respect to the parameter \u03b8, and p k is p \u03bd , p q\u00b5 or T (\u03c6 k , \u2022) respectively when k = \u22121, k = 0 and k \u2265 1. Sequential Sampling. For each i = 1, . . . , n, we first draw the indicator u i with probability P(u i = k) \u221d w k F (k, i). Depending on the value of u i , we sample \u03b8 i from different sources. For brevity, let p|x to denote the posterior distribution derived from the prior distribution p conditioned on the observation x. (1) If u i = \u22121 or 0, we draw \u03b8 i from p \u03bd |x i or p q\u00b5 |x i , respectively, and then add it as a new particle. Concretely, we increasem by 1, let \u03c8m = \u03b8 j , rm = wm = 1, and set l i =m. Moreover, we compute F (m, i) = f (x i |\u03c8m) for each i. (2) Suppose u i = k > 0. If r k = 0 then it is the first time we have drawn u i = k. Since \u03c8 k has not been determined, we sample \u03b8 i \u223c T (\u03c6 k , \u2022)|x i , then set \u03c8 k = \u03b8 i . If r k > 0, the k-th particle has been sampled before. Thus, we can simply set \u03b8 i = \u03c8 k . In both cases, we set the label l i = k, increase the weight w i and the counter r i by 1, and update F (k, i) to f (x i |\u03c8 k ) for each i.\nNote that this procedure is inefficient in that it samples each particle \u03c6 k merely based on the first observation with label k. Therefore, we use this procedure for bootstrapping, and then run a Gibbs sampling scheme that iterates between parameter update and label update.\n(Parameter update): We resample each particle \u03c8 k from its source distribution conditioned on all samples with label k. In particular, for k \u2208 [1, m] with r k > 0, we draw \u03c8 k \u223c T (\u03c6 k , \u2022)|{x i : l i = k}, and for k \u2208 [m + 1,m], we draw \u03c8 k \u223c p|{x i : l i = k}, where p = p q\u00b5 or p \u03bd , depending which source \u03c8 k was initially sampled from. After updating \u03c8 k , we need to update F (k, i) accordingly.\n(Label update): The label updating is similar to the bootstrapping procedure described above. The only difference is that when we update a label from k to k , we need to decrease the weight and counter for k. If r k decreases to zero, we remove \u03c8 k , and reset w k to q k c k when k \u2264 m.\nAt the end of each phase t, we sample \u03c8 k \u223c T (\u03c6 k , \u2022) for each k with r k = 0. In addition, for each such particle, we update the acceptance probability as q k \u2190 q k \u2022q(\u03c6 k ), which is the prior probability that the particle \u03c6 k will survive in next phase. MATLAB code is available in the following website: http://code.google.com/p/ddpinfer/.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Experimental Results", "text": "Here we present experimental results on both synthetic and real data. In the synthetic case, we compare our method with dynamic FMM in modeling mixtures of Gaussians whose number and centers evolve over time. For real data, we test the approach in modeling the motion of people in crowded scenes and the trends of research topics reflected in index terms.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Simulations on Synthetic Data", "text": "The data for simulations were synthesized as follows. We initialized the model with two Gaussian components, and added new components following a temporal Poisson process (one per 20 phases  on average). For each component, the life span has a geometric distribution with mean 40, the mean evolves independently as a Brownian motion, and the variance is fixed to 1. We performed the simulation for 80 phases, and at each phase, we drew 1000 samples for each active component. At each phase, we sample for 5000 iterations, discarding the first 2000 for burn-in, and collecting a sample every 100 iterations for performance evaluation. The particles of the last iteration at each phase were incorporated into the model as a prior for sampling in the next phase. We obtained the label for each observation by majority voting based on the collected samples, and evaluated the performance by measuring the dissimilarity between the resultant clusters and the ground truth using the variation of information [13] criterion. Under each parameter setting, we repeated the experiment 20 times, utilizing the median of the dissimilarities for comparison.\nWe compare our approach (D-DPMM) with dynamic finite mixtures (D-FMM), which assumes a fixed number of Gaussians whose centers vary as Brownian motion. From Figure 1(a), we observe that when the fixed number K of components equals the actual number, they yield comparable performance; while when they are not equal, the errors of D-FMM substantially increase. Particularly, K less than the actual number results in significant underfitting (e.g. D-FMM with K = 2 or 3 at phases 30\u221250 and 66\u221276); when K is greater than the actual number, samples from the same component are divided into multiple groups and assigned to different components (e.g. D-FMM with K = 5 at phases 1 \u2212 10 and 30 \u2212 50). In all cases, D-DPMM consistently outperforms D-FMM due to its ability to adjust the number of components to adapt to the change of observations. We also studied how design parameters impact performance. In Figure 1(b), we see that an acceptance probability q to 0.1 creates new components rather than inheriting from previous phases, leading to poor performance when the number of samples is limited. If we set q = 0.9, the components in previous phases have a higher survival rate, resulting in more reliable estimation of the component parameters from multiple phases. Figure 1(c) shows the effect of the diffusion variance that controls the parameter variation. When it is small, the parameter in the next phase is tied tightly with the previous value; when it is large, the estimation basically relies on new observations. Both cases lead to performance degradation on small datasets, which indicates that it is important to maintain a balance between inheritance and innovation. Our framework provides the flexibility to attain such a balance. Cross-validation can be used to set these parameters automatically.", "publication_ref": ["b12"], "figure_ref": ["fig_1", "fig_1", "fig_1"], "table_ref": []}, {"heading": "Real Data Applications", "text": "Modeling People Flows. It was observed [11] that the majority of people walking in crowded areas such as a rail station tend to follow motion flows. Typically, there are several flows at a time, and each flow may last for a period. In this experiment, we apply our approach to extract the flows. The test was conducted on video acquired in New York Grand Central Station, which comprises 90, 000 frames for one hour (25 fps). A low level tracker was used to obtain the tracks of people, which were then processed by a rule-based filter that discards obviously incorrect tracks. We adopt the flow model described in [11], which uses an affine field to capture the motion patterns of each flow. The observation for this model is in the form of location-velocity pairs. We divided the entire sequence into 60 phases (each for one minute), extract location-velocity pairs from all tracks, and randomly choose 3000 pairs for each phase for model inference. The algorithm infers 37 flows in total, while at each phase, the numbers of active flows range from 10 to 18. By parsing the webpage of IEEE Xplore, we collected the index terms for 3014 papers published in PAMI from Jan, 1990 to May, 2010. We first compute the similarity between each pair of papers in terms of relative fraction of overlapped index terms. We derive a 12-dimensional feature vector using spectral embedding [2] over the similarity matrix for each paper. We run our algorithm on these features with each phase corresponding to a year. Each cluster of papers is deemed a topic.\nWe compute the histogram of index terms and sorted them in decreasing order of frequency for each topic. Figure 2(b) shows the timelines of top 10 topics, and together with the top two index terms for each of them. Not surprisingly, we see that topics such as \"neural networks\" arise early and then diminish while \"image segmentation\" and \"motion estimation\" persist.", "publication_ref": ["b10", "b10", "b1"], "figure_ref": ["fig_2"], "table_ref": []}, {"heading": "Conclusion and Future Directions", "text": "We developed a principled framework for constructing dependent Dirichlet processes. In contrast to most DP-based approaches, our construction is motivated by the intrinsic relation between Dirichlet processes and compound Poisson processes. In particular, we discussed three operations: superposition, subsampling, and point transition, which produce DPs depending on others. We further combined these operations to derive a Markov chain of DPs, leading to a prior of mixture models that allows creation, removal, and location variation of component models under a unified formulation. We also presented a Gibbs sampling algorithm for inferring the models. The simulations on synthetic data and the experiments on modeling people flows and paper topics clearly demonstrate that the proposed method is effective in estimating mixture models that evolve over time.\nThis framework can be further extended along different directions. The fact that each completely random point process is a Poisson process suggests that any operation that preserves the complete randomness can be applied to obtain dependent Poisson processes, and thus dependent DPs. Such operations are definitely not restricted to the three ones discussed in this paper. For example, random merging and random splitting of particles also possess this property, which would lead to an extended framework that allows merging and splitting of component models. Furthermore, while we focused on Markov chain in this paper, the framework can be straightforwardly generalized to any acyclic network of DPs. It is also interesting to study how it can be generalized to the case with undirected network or even continuous covariate space. We believe that as a starting point, this paper would stimulate further efforts to exploit the relation between Poisson processes and Dirichlet processes.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Dynamic Non-Parametric Mixture Models and The Recurrent Chinese Restaurant Process : with Applications to Evolutionary Clustering", "journal": "", "year": "2008", "authors": "A Ahmed; E Xing"}, {"ref_id": "b1", "title": "Learning spectral clustering", "journal": "", "year": "2003", "authors": "F R Bach; M I Jordan"}, {"ref_id": "b2", "title": "Syntactic Topic Models", "journal": "", "year": "2008", "authors": "J Boyd-Graber; D M Blei"}, {"ref_id": "b3", "title": "Generalized Polya Urn for Time-varying Dirichlet Process Mixtures", "journal": "", "year": "2007", "authors": "F Caron; M Davy; A Doucet"}, {"ref_id": "b4", "title": "The local Dirichlet Process", "journal": "Annals of the Inst. of Stat. Math", "year": "2007-10", "authors": "Y Chung; D B Dunson"}, {"ref_id": "b5", "title": "Bayesian Dynamic Modeling of Latent Trait Distributions", "journal": "Biostatistics", "year": "2006-10", "authors": "D B Dunson"}, {"ref_id": "b6", "title": "Order-Based Dependent Dirichlet Processes", "journal": "Journal of the American Statistical Association", "year": "2006-03", "authors": "J E Griffin; M F J Steel"}, {"ref_id": "b7", "title": "Time-Dependent Stick-Breaking Processes", "journal": "", "year": "2009", "authors": "J E Griffin; M F J Steel"}, {"ref_id": "b8", "title": "Poisson Processes", "journal": "Oxford University Press", "year": "1993", "authors": "J F C Kingman"}, {"ref_id": "b9", "title": "Learning Multiscale Representations of Natural Scenes Using Dirichlet Processes", "journal": "", "year": "2007", "authors": "J J Kivinen; E B Sudderth; M I Jordan"}, {"ref_id": "b10", "title": "Learning Visual Flows: A Lie Algebraic Approach", "journal": "", "year": "2009", "authors": "D Lin; E Grimson; J Fisher"}, {"ref_id": "b11", "title": "Dependent Nonparametric Processes", "journal": "", "year": "1999", "authors": "S N Maceachern"}, {"ref_id": "b12", "title": "Comparing clusterings -An Axiomatic View", "journal": "", "year": "2005", "authors": "M Meila"}, {"ref_id": "b13", "title": "A Method for Combining Inference across Related Nonparametric Bayesian Models", "journal": "J. R. Statist. Soc. B", "year": "2004-08", "authors": "P Muller; F Quintana; G Rosner"}, {"ref_id": "b14", "title": "Markov Chain Sampling Methods for Dirichlet Process Mixture Models", "journal": "Journal of computational and graphical statistics", "year": "2000", "authors": "R M Neal"}, {"ref_id": "b15", "title": "Spatial Normalized Gamma Processes", "journal": "", "year": "2009", "authors": "V Rao; Y W Teh"}, {"ref_id": "b16", "title": "The Infinite Gaussian Mixture Model", "journal": "", "year": "2000", "authors": "C E Rasmussen"}, {"ref_id": "b17", "title": "The Dynamic Hierarchical Dirichlet Process", "journal": "ACM Press", "year": "2008", "authors": "L Ren; D B Dunson; L Carin"}, {"ref_id": "b18", "title": "A Constructive Definition of Dirichlet Priors", "journal": "Statistica Sinica", "year": "1994", "authors": "J Sethuraman"}, {"ref_id": "b19", "title": "Hidden Markov Dirichlet process: modeling genetic recombination in open ancestral space", "journal": "", "year": "2007", "authors": "K Sohn; E Xing"}, {"ref_id": "b20", "title": "Time-Varying Topic Models using Dependent Dirichlet Processes", "journal": "", "year": "2005", "authors": "N Srebro; S Roweis"}, {"ref_id": "b21", "title": "Dirichlet Process", "journal": "", "year": "2007", "authors": "Y W Teh"}, {"ref_id": "b22", "title": "Hierarchical Dirichlet Processes", "journal": "", "year": "2006", "authors": "Y W Teh; M I Jordan; M J Beal; D M Blei"}, {"ref_id": "b23", "title": "Time-Sensitive Dirichlet Process Mixture Models", "journal": "", "year": "2005", "authors": "X Zhu; J Lafferty"}], "figures": [{"figure_label": "", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "For different diffusion var.", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 1 :1Figure 1: The simulation results: (a) compares the performance between D-DPMM and D-FMM with differing numbers of components. The upper graph shows the median of distance between the resulting clusters and the ground truth at each phase. The lower graph shows the actual numbers of clusters. (b) shows the performance of D-DPMM with different values of acceptance probability, under different data sizes. (c) shows the performance of D-DPMM with different values of diffusion variance, under different data sizes.", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 2 :2Figure 2: The experiment results on real data. (a) left: the timelines of the top 20 flows; right: illustration of first two flows. (Illustrations of larger sizes are in the supplement.) (b) left: the timelines of the top 10 topics; right: the two leading keywords for these topics. (A list with more keywords is in the supplement.)", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 2 (2a) shows the timelines of the top 20 flows (in terms of the numbers of assigned observations). We compare the performance of our method with D-FMM by measuring the average likelihood on a disjoint dataset. The value for our method is \u22123.34, while those for D-FMM are \u22126.71, \u22125.09, \u22123.99, \u22123.49, and \u22123.34, when K are respectively set to 10, 20, 30, 40, and 50. Consequently, with a much smaller number of components (12 active components on average), our method attains a similar modeling accuracy as a D-FMM with 50 components.Modeling Paper Topics. Next we analyze the evolution of paper topics for IEEE Trans. on PAMI.", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "\u03a3 * : F \u2126 \u2192 [0, +\u221e] as \u03a3 * (\u03b8,w \u03b8 )\u2208\u03a0 * w \u03b8 \u03b4 \u03b8 (1)", "formula_coordinates": [2.0, 108.0, 320.02, 396.0, 36.72]}, {"formula_id": "formula_1", "formula_text": "\u00b5 * = \u00b5 \u00d7 \u03b3 with \u03b3(dw) = w \u22121 e \u2212w dw,(2)", "formula_coordinates": [2.0, 220.75, 398.2, 283.25, 11.03]}, {"formula_id": "formula_2", "formula_text": "D G/G(\u2126) \u223c DP(\u00b5).(3)", "formula_coordinates": [2.0, 252.71, 450.62, 251.29, 8.96]}, {"formula_id": "formula_3", "formula_text": "\u03a0 1 \u222a \u2022 \u2022 \u2022 \u222a \u03a0 m \u223c PoissonP(\u00b5 1 + \u2022 \u2022 \u2022 + \u00b5 m ).(4)", "formula_coordinates": [2.0, 211.53, 655.32, 292.48, 9.65]}, {"formula_id": "formula_4", "formula_text": "m k=1 \u03a0 * k \u223c PoissonP m k=1 (\u00b5 k \u00d7 \u03b3) = PoissonP m k=1 \u00b5 k \u00d7 \u03b3 .(5)", "formula_coordinates": [2.0, 161.03, 704.65, 342.97, 30.55]}, {"formula_id": "formula_5", "formula_text": "G := G 1 + \u2022 \u2022 \u2022 + G m \u223c \u0393P(\u00b5 1 + \u2022 \u2022 \u2022 + \u00b5 m ).(6)", "formula_coordinates": [3.0, 212.41, 110.96, 291.59, 9.65]}, {"formula_id": "formula_6", "formula_text": "D := G /G (\u2126) = (g 1 D 1 + \u2022 \u2022 \u2022 + g m D m )/(g 1 + \u2022 \u2022 \u2022 + g m ) = c 1 D 1 + \u2022 \u2022 \u2022 + c m D m . (7)", "formula_coordinates": [3.0, 132.45, 140.92, 371.55, 9.65]}, {"formula_id": "formula_7", "formula_text": "D 1 \u2295 \u2022 \u2022 \u2022 \u2295 D m := c 1 D 1 + \u2022 \u2022 \u2022 c m D m \u223c DP(\u00b5 1 + \u2022 \u2022 \u2022 + \u00b5 m ).(8)", "formula_coordinates": [3.0, 176.8, 217.52, 327.2, 9.65]}, {"formula_id": "formula_8", "formula_text": "E(D (A)) = m k=1 \u03b1 k \u03b1 E(D k (A)), and Cov(D (A), D k (A)) = \u03b1 k \u03b1 Var(D k (A)).(9)", "formula_coordinates": [3.0, 140.36, 263.48, 363.64, 30.55]}, {"formula_id": "formula_9", "formula_text": "\u03a0 0 \u223c PoissonP((1 \u2212 q)\u00b5) and \u03a0 1 \u223c PoissonP(q\u00b5) 1 .", "formula_coordinates": [3.0, 277.5, 360.98, 217.69, 11.0]}, {"formula_id": "formula_10", "formula_text": "G = S q (G) := i:zi=1 w i \u03b4 \u03b8i \u223c \u0393P(q\u00b5). (10", "formula_coordinates": [3.0, 223.66, 443.88, 276.19, 19.91]}, {"formula_id": "formula_11", "formula_text": ")", "formula_coordinates": [3.0, 499.85, 444.2, 4.15, 8.64]}, {"formula_id": "formula_12", "formula_text": "D = S q (D) := i:zi=1 r i \u03b4 \u03b8i \u223c DP(q\u00b5),(11)", "formula_coordinates": [3.0, 223.59, 534.72, 280.41, 19.91]}, {"formula_id": "formula_13", "formula_text": "E(D (A)) = (q\u00b5)(A) (q\u00b5)(\u2126) = A qd\u00b5 \u2126 qd\u00b5 ,and", "formula_coordinates": [3.0, 132.27, 598.73, 163.68, 26.06]}, {"formula_id": "formula_14", "formula_text": "Cov(D (A), D(A)) = \u03b1 \u03b1 Var(D (A)).(12)", "formula_coordinates": [3.0, 305.91, 599.42, 198.09, 22.31]}, {"formula_id": "formula_15", "formula_text": "T : \u2126 \u00d7 F \u2126 \u2192 [0, 1] such that for each \u03b8 \u2208 F \u2126 , T (\u03b8, \u2022", "formula_coordinates": [3.0, 108.0, 656.41, 216.66, 9.65]}, {"formula_id": "formula_16", "formula_text": "(T \u00b5)(A) := \u2126 T (\u03b8, A)\u00b5(d\u03b8). (13", "formula_coordinates": [3.0, 243.96, 698.31, 255.89, 17.24]}, {"formula_id": "formula_17", "formula_text": ")", "formula_coordinates": [3.0, 499.85, 698.63, 4.15, 8.64]}, {"formula_id": "formula_18", "formula_text": "T (\u03a0) := {T (\u03b8) : \u03b8 \u2208 \u03a0} \u223c PoissonP(T \u00b5).(14)", "formula_coordinates": [4.0, 214.68, 102.24, 289.32, 8.96]}, {"formula_id": "formula_19", "formula_text": "Theorem 7. Let D = \u221e i=1 r i \u03b4 \u03b8i \u223c DP(\u00b5) be a Dirichlet process on \u2126, then T (D) := \u221e i=1 r i \u03b4 T (\u03b8i) \u223c DP(T \u00b5).(15)", "formula_coordinates": [4.0, 108.0, 162.74, 396.0, 49.57]}, {"formula_id": "formula_20", "formula_text": "D t = T (S q (D t\u22121 )) \u2295 H t , with H t \u223c DP(\u03bd).(16)", "formula_coordinates": [4.0, 201.83, 309.71, 302.17, 9.65]}, {"formula_id": "formula_21", "formula_text": "\u00b5 t = T (q\u00b5 t\u22121 ) + \u03bd.(17)", "formula_coordinates": [4.0, 264.9, 409.9, 239.1, 9.65]}, {"formula_id": "formula_22", "formula_text": "Cov(D t+n (A), D t (A)) \u2264 q n Var(D t (A)).(18)", "formula_coordinates": [4.0, 220.5, 464.18, 283.5, 11.72]}, {"formula_id": "formula_23", "formula_text": "D |\u03a6 \u223c DP \u03b1 \u03bd p \u03bd + \u03b1 0 p q\u00b5 + m k=1 q k c k T (\u03c6 k , \u2022) .(19)", "formula_coordinates": [5.0, 198.87, 461.68, 305.13, 30.55]}, {"formula_id": "formula_24", "formula_text": "\u03b8 1 |\u03a6 \u223c \u03b1 \u03bd \u03b1 1 p \u03bd + \u03b1 0 \u03b1 1 p q\u00b5 + m k=1 q k c k \u03b1 1 T (\u03c6 k , \u2022) with \u03b1 1 = \u03b1 \u03bd + \u03b1 0 + m k=1 q k c k .(20)", "formula_coordinates": [5.0, 144.11, 514.89, 359.89, 30.55]}, {"formula_id": "formula_25", "formula_text": "D |\u03b8 1 , {u 1 \u2264 0} \u223c DP \u03b1 \u03bd p \u03bd + \u03b1 0 p q\u00b5 + m k=1 q k c k T (\u03c6 k , \u2022) + \u03b4 \u03b81 .(21)", "formula_coordinates": [5.0, 164.09, 634.27, 339.91, 30.55]}, {"formula_id": "formula_26", "formula_text": "D |\u03b8 1 , {u 1 = l > 0} \u223c DP \uf8eb \uf8ed \u03b1 \u03bd p \u03bd + \u03b1 0 p q\u00b5 + k =l q k c k T (\u03b8 k , \u2022) + (c l + 1)\u03b4 \u03b81 \uf8f6 \uf8f8 .(22)", "formula_coordinates": [5.0, 131.28, 698.98, 372.72, 33.76]}, {"formula_id": "formula_27", "formula_text": "x i \u223c L(\u03b8 i ), i = 1, . . . , n.(23)", "formula_coordinates": [6.0, 326.41, 160.19, 177.59, 9.65]}], "doi": ""}