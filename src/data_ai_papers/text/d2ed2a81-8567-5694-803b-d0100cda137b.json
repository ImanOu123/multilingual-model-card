{"title": "Learning to Solve Hard Minimal Problems *", "authors": "Petr Hruby; Timothy Duff; Anton Leykin; Tomas Pajdla", "pub_date": "2021-12-06", "abstract": "We present an approach to solving hard geometric optimization problems in the RANSAC framework. The hard minimal problems arise from relaxing the original geometric optimization problem into a minimal problem with many spurious solutions. Our approach avoids computing large numbers of spurious solutions. We design a learning strategy for selecting a starting problem-solution pair that can be numerically continued to the problem and the solution of interest. We demonstrate our approach by developing a RANSAC solver for the problem of computing the relative pose of three calibrated cameras, via a minimal relaxation using four points in each view. On average, we can solve a single problem in under 70 \u00b5s. We also benchmark and study our engineering choices on the very familiar problem of computing the relative pose of two calibrated cameras, via the minimal case of five points in two views.", "sections": [{"heading": "Introduction", "text": "Minimal problems arise from geometrical problems in 3D reconstruction [59,61,62], image matching [55], visual oodometry,and localization [3,49,57,66]. Many geometrical problems have been successfully formulated and solved as minimal problems [1, 4-6, 11, 12, 18, 27, 33-36, 44, 45, 48, 54, 56, 58, 64, 67]. Technically, minimal problems are systems of polynomial equations which depend on the input data and have a finite number of solutions.", "publication_ref": ["b61", "b63", "b64", "b57", "b3", "b50", "b59", "b68"], "figure_ref": [], "table_ref": []}, {"heading": "Motivation", "text": "Many geometrical problems are optimization problems that have only one optimal solution. Minimal problems, however, often have many additional spurious solutions. The optimal solution is typically real, satisfies inequality constraints, and fits well all data. Such constraints, however, can not be used by methods of nonlinear algebra [13,65] which have no ability to bypass finding (or incurring the cost of finding) all solutions of polynomial systems.\nRANSAC [23,53] approximates the optimal solution to a geometrical problem by computing candidate solutions from data samples and picking a solution with maximal data support. This is done by iterating over the samples in an outer loop and over the solutions of a minimal problem for each sample in an inner loop. To find a single solution for a data sample in the inner loop, the state-of-the-art \"solve & pick\" approach first computes all solutions of a minimal problem and then picks the optimal solutions by removing nonreal solutions, using inequalities, and evaluating the support. Optimization in the inner loop may be very costly when there are many spurious solutions to the minimal problem. Fig. 1 compares the standard \"solve & pick\" approach with our \"pick & solve\" approach that learns, for a given data sample, how to first pick a promising starting point and then (ideally) continue it to a meaningful solution. Figure 1. The inner RANSAC loop finds the best solution for a data sample p. This is very expensive when a minimal problem has many spurious solutions. Our efficient homotopy continuation combined with machine learning avoids solving for the spurious solutions. Thus, using minimal problems in RANSAC becomes effectively independent from the number of spurious solutions.\nRecent results [15,16] show that there are many minimal problems in multiview geometry with many spurious solutions which the state-of-the-art polynomial solvers cannot solve efficiently. 1 ", "publication_ref": ["b13", "b67", "b24", "b55", "b15", "b16", "b0"], "figure_ref": [], "table_ref": []}, {"heading": "Contribution", "text": "We present a method for combining optimized homotopy continuation (HC) with machine learning to avoid solving for spurious solutions. The main idea is to learn a single starting point for a real HC path that has a good chance to reach a good solution of the original geometrical problem.\nTo demonstrate our method on a hard problem, we develop an efficient solver for the \"Scranton\" minimal problem obtained by relaxing the overconstrained problem of four points in three views (4pt) [50]. We train a model that predicts a starting problem for a single path real HC method to find a good solution. Our solver is implemented efficiently in C++ and evaluated on the state-of-the-art data in computer vision. It successfully solves about 26.3% of inputs in 16.3\u00b5s, Tab. 4. In Sec. 9 we show that when used in RANSAC, about 4 samples suffice on average to obtain a valid candidate of camera geometry in 61.6\u00b5s. No such efficient solver has been known for this problem before. The best-known runtime for a very carefully designed approximation of the problem, reported in [50], was on the order of milliseconds. We thus achieve more than ten times speedup compared to [50]. Most importantly, our approach is general and opens the door to solving other hard minimal problems, e.g., from [15,16].\nWe benchmark (Sec. 9) our approach on the classical 5-point problem (5pt) [48] using standard benchmarks [47]. We show that for the 5pt problem, we can solve 29.0% of inputs in about 7.6\u00b5s, Tab. 4. Thus, in RANSAC, we can solve it in average in 26.1\u00b5s.\nOur approach is general. It can be applied even in some cases where the number of spurious solutions is not finite. For instance, our depth formulation of the Scranton problem has an infinite family of solutions where some depths may be zero. Additional polynomial constraints, which do not need to be explicitly enforced, reduce the number of potential solutions to 272-see 15. Thus, by exploiting the \"locality\" of HC methods, we can guarantee that when starting from a good starting point, we can ignore other spurious solutions with no additional computational cost.\nIt is important to highlight that, unlike the current symbolic-numeric solvers, our method is coupled with the rest of SfM pipeline, i.e., it uses the real data distribution in a particular vision problem at hand.", "publication_ref": ["b51", "b9", "b51", "b51", "b15", "b16", "b49", "b48"], "figure_ref": [], "table_ref": []}, {"heading": "Previous work", "text": "The state-of-the-art approach to solving polynomial systems in computer vision is based on symbolic-numeric solvers, which combine elimination (by Gr\u00f6bner bases [36,39,64] or resultants [8,19,29]) with eigenvector computation [65] to find all complex solutions. Currently, symbolic-numeric solvers [36,[39][40][41] provide efficient and stable results for minimal problems with as many as 64 complex solutions [8,42]. However, these solvers mostly fail to deliver practical results for hard computer vision problems with many solutions. Symbolic/numeric solvers involve two hard computational tasks. First, in the symbolic part, large matrices are constructed and triangularized by the Gauss-Jordan elimination. Secondly, in the numeric part, the eigenvectors of n \u00d7 n matrices, where n is the number of all complex solutions, are computed. Both steps are prohibitive for generic polynomial systems with many spurious solutions. Methods which deal with real solutions only, e.g. Sturm sequences [48], also generally require expensive manipulations (reduction to a univariate polynomial) and may still need to consider many spurious real solutions.\nGlobal HC methods give an alternative, well-studied approach [7,10,14,68] to finding all complex solutions of polynomial systems. Off-the-shelf HC solvers [7,10,14,68] have been proven useful for studying the structure of minimal problems [2,30,31,52]. However, the off-the-shelf solvers are much slower (10 3 \u2212 10 5 times) than current symbolic-numeric solvers. For instance, our experiments, Tab. 7, show that solving [48] with complex homotopy continuation in Macaulay2 [43] takes about 10 5 \u00b5s compared to 5 \u00b5s when [38] implementation of [48] is used.\nThe previous work [20] closest to this work addresses the problem of speeding up minimal HC solvers. This paper took notable steps towards the practical use of homotopy continuation for minimal problem solving. In that work, an off-the-shelf HC implementation [43] has been optimized and efficiently implemented in modern C++. Two hard problems in trifocal geometry have been solved in about 660ms. Despite not providing practical solvers for RANSAC [23,53], the results of [20] demonstrated that hard multiview problems involving 312 and 216 solutions can be solved in a stable way and thus could be useful for building practical structure from motion algorithms.\nOur paper considers a novel solver for a problem named \"Scranton\" 2 , which is a minimal relaxation of the overconstrained 4pt problem [50]. Previous work formulated Scranton using camera parameters and found that it has 272 complex solutions [16,31]. We consider an alternative formulation in terms of 3D point depths, analogous to [52], which has 272 potentially meaningful solutions. The original 4pt problem was solved by numerical search in [50], with about 1ms runtime. A depth-formulated 4pt problem was also studied in [52], showing that the overconstrained problem with exact input has a unique solution. Their exact solution does not apply to problems with noisy data.\nWe also study the classical, well-understood 5-point problem (5pt) of computing the relative pose of two calibrated cameras [48]. Unlike Scranton, this problem has many practical solutions [9,27,37,48,59]. Currently, the most efficient symbolicnumeric solver [41] of the 5pt problem solves for up to 10 essential matrices in about 5\u00b5s. Although the 5pt problem is not as hard as Scranton in terms of the number of spurious solutions, it does provide an important testing ground for us.", "publication_ref": ["b37", "b40", "b66", "b8", "b20", "b30", "b67", "b37", "b40", "b41", "b42", "b8", "b43", "b49", "b7", "b10", "b14", "b70", "b7", "b10", "b14", "b70", "b2", "b31", "b32", "b54", "b49", "b44", "b39", "b49", "b21", "b44", "b24", "b55", "b21", "b51", "b16", "b32", "b54", "b51", "b54", "b49", "b9", "b28", "b38", "b49", "b61", "b42"], "figure_ref": [], "table_ref": []}, {"heading": "Our approach", "text": "Here we present our approach to solving hard minimal problems. We shall use HC methods to track one real solution of a start problem to obtain one real solution of the target problem. We shall design an algorithm such that this one solution we obtain is a meaningful solution with sufficient probability.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Problem-solution manifold", "text": "We operate in the problem-solution manifold M of problem-solution (p-s) pairs (p, s), where p is a problem and s is a solution of p. Problem p belongs to a real vector space P . Solution s comes from a real vector space of solutions. The projection \u03c0 \u2236 M \u2192 P is defined by (p, s) \u21a6 p. The preimage \u03c0 \u22121 (p) \u2208 M contains all p-s pairs that correspond to a particular problem p. Example 1. To illustrate the introduced concepts, let us look at one equation x 3 + ax + b = 0 in one unknown x with two parameters a and b. Here a problem p = (a, b) has either one or three real solutions depending on whether the discriminant D = 4a 3 + 27b 2 is positive or negative; see the corresponding problem-solution manifold M in Fig. 2a.\nTo be precise, the equation defines an algebraic variety, which is guaranteed to be a smooth manifold when points above the discriminant locus D = 0 are removed.\nSee SM Sec. 13 for the detailed examples of setting up problem-solution manifolds for the 5pt problem and Scranton, a minimal relaxation for the 4pt problem. Below is a condensed version of the 5pt problem.\nExample 2. Consider the classical 5pt problem of computing the relative pose of two calibrated cameras which view five world points where the scale is fixed such that the first 3D point lies in the first image plane.\nDenote by x the images of 5 points in 2 views: i.e., x is a point in P = R 20 . Assume the points are in front of both cameras: i.e., their depths \u03bb i,j , (i = 1, . . . , 5; j = 1, 2) are all positive. Our assumptions imply that \u03bb 1,1 = 1. The unknown depths vector in the solution space R 9 determines the relative pose. Therefore, the problem-solution manifold M is contained in the ambient space R 20 \u00d7 R 9 . Equations vanishing on M are given in Sec. 7.1. ", "publication_ref": [], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "Probability distribution on M", "text": "We introduce a probability density \u00b5 on the problem-solution manifold M that gives the distribution of real-world problemsolution pairs. In Fig. 2a, we give an example of \u00b5 depicted with shades of gray (darker is bigger) on the manifold M . Note that the density is such that any problem with a set S of three solutions has only one s \u2208 S with \u00b5(s) > 0. We shall (implicitly) operate under the following assumption:\nAn input problem p is likely to have one meaningful solution that is dominant, i.e., occurs much more frequently in the real data than other meaningful solutions.\nIn many problems (e.g., the one in Section 7.2) the number of meaningful solutions is guaranteed to be exactly one generically. The distribution \u00b5 is hard to model; in what follows it is represented by training data.", "publication_ref": [], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "Pick & solve vs. solve & pick", "text": "A typical local iterative method (e.g. Newton's method, gradient descent, etc.) would attempt solving a problem p by obtaining an initial approximate solution s 0 with a hope that it is not too far away from an actual solution and then producing a sequence of its refinements s 0 , s 1 , s 2 , . . . until either a desired quality is reached or some termination-with-failure criterion is satisfied.\nOur homotopy approach is a generalization of such local methods. In a nutshell, given a problem p, 1. we select a suitable start problem-solution pair (p 0 , s 0 ) \u2208 M for p, 2. we choose a path p 0 \u219d p in the problem space P , leading from p 0 to p, 3. we track the path (p 0 , s 0 ) \u219d (p, s) to obtain the target solution s of p.\nSelecting a start pair (p 0 , s 0 ) is the key ingredient of our approach. Given a real HC method, one can aim to construct the selection strategy \u03c3(p) = (p 0 , s 0 ) in two steps. First, one finds a small set of anchors A \u2282 M , such that it is possible to reach (cover) a significant part of M from A by the real homotopy continuation. Secondly, one learns a selection strategy \u03c3 such that starting from (p 0 , s 0 ) \u2208 A, the meaningful problem-solution pair is reached with sufficiently high frequency to make RANSAC work.\nIntuitively, one may perceive a minimal solver employed in RANSAC as an arrow p \u2192 S in the following diagram:\np S = \u03c0 \u22121 (p) s a = (p 0 , s 0 ) solve (minimal problem) pick (anchor) pick (s \u2208 S) solve (homotopy)\nwhere an instance p of a minimal problem is \"solved\" (all solutions in S are found.) Then RANSAC \"picks\" at most one solution, S \u2192 s, a candidate that maximizes the number of inliers.\nLooking for a shortcut that would allow us to go directly p \u2192 s, we reverse this flow: first \"picking\" an anchor and then tracking one HC path to \"solve\".", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Structure of our solvers", "text": "Our solvers for both 5pt and Scranton minimal problems have a common structure, consisting of an offline training stage and an online evaluation stage. Offline computations may be resource-intensive; however, the online stage must be very efficient to achieve practical sub-millisecond run times. The offline stage consists of:\n1. Sampling data D, according to \u00b5, representing the (preprocessed) problem-solution manifold M (Sec 3). 2. Covering a sufficient fraction of the data with anchors A \u2282 D (Sec. 4).\n3. Learning a model \u03c3 which selects a starting ps-pair (p 0 , s 0 ) \u2208 A for any given problem p (Sec. 5).\nThe online stage consists of:\n1. Preprocessing the input p to reduce its variability (Sec. 8). 2. Selecting a starting pair from A as (p 0 , s 0 ) = \u03c3(p). 3. Constructing polynomial equations of p (Sec. 7). 4. Computing solution s of p by HC from (p 0 , s 0 ) (Sec. 6). 5. Recover solution s of the original problem p (Sec. 8).\nThe next sections describe these steps in detail.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Sampling data representing M and \u00b5", "text": "The offline stages of our solvers begin by sampling the data D given by 3D models of various realistic objects. We use models from ETH 3D Dataset to represent \u00b5.\nA 3D model consists of 3D points X, cameras C, and relation I \u2282 X \u00d7 C encoding observations ((X m , C i ) \u2208 I iff C i observes X m ). For Scranton, we may sample a single p-s pair (p, s) \u2208 M as follows:\n1. Select 3 cameras C i , C j , C k \u2208 C 2. Select 4 points X l , X m , X n , X o \u2208 X \u2236 (X a , C b ) \u2208 I \u2200a \u2208 {l, m, n, o}, b \u2208 {i, j, k} 3.\nProject the points to the cameras to get 12 2D points x a,b , concatenate them to 24-dim vector p \u2208 P 4. Get the depths \u03bb a,b of the points in the cameras, concatenate them to 12-dim vector s \u2208 S Sampling for the 5pt problem is similar; in step 1 we select 2 cameras, and in step 2 we select 5 points.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Selecting anchors A", "text": "We now describe how the starting p-s pairs are obtained. Our goal is to find a small set A of starting p-s pairs (the set of anchors), from which a high portion of p-s pairs from a given distribution can be tracked by HC.\nIf we limit ourselves to a finite set of p-s pairs and the anchors are selected from the same set, the optimal procedure for the anchor selection consists of building a graph with p-s pairs as vertices. The nodes (p i , s i ), (p j , s j ) are connected with an edge, if the correct solution s j can be obtained by tracking HC from (p i , s i ) to p j . A set of anchors covering all problems in this graph is called a dominating set. Since computing a minimum-size dominating set is NP-hard, we replace it with a greedy proxy, which is known to perform well 3 2. Study of sources for anchor selection. Rows correspond to different models or combinations of models, from which the anchors are generated. For each source of anchors, we measure the percentage \u03b1 of testing p-s problems (generated from models delivery area, electro, facade, kicker, meadow, pipes) that can be reached from any of the anchors generated from the given source. Anchor sets of 100 anchors are considered for every source.\nTo show that the selected anchors generalize well to p-s pairs from other scenes, we consider 40000 anchors generated from office and terrains. For testing data, we generated p-s pairs from the models delivery area, and facade.\nWe have tracked the solutions with HC starting from each of the anchors. The portion of problems correctly tracked from any of the anchors is shown in Tab. 3. The resulting percentage is equivalent to using an oracle that always finds the best anchor to start from.\nNext, we show that if the number of vertices in the graph is sufficiently high, a reasonable portion of different p-s pairs from the same scene can be solved by HC starting from one of the anchors A we generate.\nWe have generated n problem-solution pairs from models office and terrains 4 . Out of these problem-solution pairs, we have selected anchors which cover 50%, 75%, 90%, 95%, and 100% of data. Tab. 1 shows the number of anchors which cover the data for different values of n for both problems. The number of anchors for 50% and 75% saturates when n = 10000. Therefore, we may assume that these anchors will cover a significant portion of problems from the given distribution. Tab. 2 shows a comparison of different sources of anchors. The combination of models office and terrains gives the best generalizability out of all considered sources.", "publication_ref": ["b3"], "figure_ref": [], "table_ref": []}, {"heading": "Learning \u03c3 to select the starting p-s pair", "text": "We formulate the problem of finding the best starting p-s pair as a classification task. Our method relies on a classifier \u03c3, which for a sample problem p \u2208 P assigns a label from \u03c3(p) \u2208 A \u222a {T RASH}, where A is the anchor set generated in Sec. 4. The label T RASH is included for cases where no problem in A covers p.\nOur goal is to minimize the effective time t = \u00b5 t \u03c1 of the solver, where \u00b5 t is the total time 5 and \u03c1 is the success rate. Therefore, we must be able to classify p very fast, on the order of 10\u00b5s for a subsequent HC path \u03c3(p) \u219d (p, s) \u03c3(p) \u2260 {T RASH}.) Now, we are going to describe the classifier and its training.\nFor both problems, we use a Multi-Layer Perceptron (MLP) with 6 hidden layers of 100 neurons with bias. 6 The input layer has size dim P , and the output layer has size A + 1. We use the PReLU activation function. During training, we use the dropout before the last layer to prevent overfitting. The classification time of the MLP is about 8\u00b5s for both 5pt and 4pt problems. Table 3. Percentage of testing problem-solution pairs which are solvable by the anchors generated from model Office and Terrains. The anchors are taken from Tab. 1 for n = 40000. The problem-solution pair is considered solvable by the anchors, if the correct solution can be obtained by HC starting in any of the anchors. The solution is considered correct if the Euclidean distance from the obtained solution to the ground-truth solution is less than 10 \u22125 . This is equivalent to using an oracle classifier that always finds the best anchor to start from.\nThe input to the MLP is a normalized (Sec. 8) problem p \u2208 P . The output is a vector of A + 1 numbers, which give the score for every starting p-s pair (p 0 , s 0 ), as well as for T RASH. If the score of T RASH is higher than the scores of all anchors, we skip the sample. Otherwise, we track from the p-s pair with the highest score.\nDuring training, we normalize the output of the MLP with a softmax layer, and we use a cross-entropy loss, which is a standard method for training classifiers. We use the SGD optimizer, which gives us better results than other optimizers, such as Adam. We generate training and testing data data according to Sec. 5.1, and train the MLP by minimizing the loss on the training data for 80 epochs. Then, we select the parameters which maximize the success rate on the validation data. The evaluation of the classifier is shown in Sec. 5.2.", "publication_ref": ["b6"], "figure_ref": [], "table_ref": []}, {"heading": "Training data generation", "text": "We use the training and testing data generated from ETH 3D Dataset. Testing data is generated from models delivery area and facade, training data from 23 other sequences. First, we generated p-s pairs (p, s) from the models according to Sec. 3. Then, we normalized each problem p (Sec. 8), and tracked the solution to problem p from each anchor (p a ,s a ) \u2208 A. If the solution to p obtained by HC starting in anchor (p a ,s a ) \u2208 A is equal to the expected solution s, then the ID a of the anchor is assigned as the label of problem p. If solution s cannot be reached from any anchor, the label of p is T RASH. A problem may have multiple labels. We note that this procedure allows us, in principle, to generate an unlimited amount of training data 7 .\nIn our experiments, we use about 1 million training p-s pairs per model (23M in total) and 30000 validation p-s pairs per model.", "publication_ref": ["b7"], "figure_ref": [], "table_ref": []}, {"heading": "Classifier evaluation", "text": "Now, we are going to show the evaluation of the trained MLPs. During the evaluation, an anchor (p 0 , s 0 ) is selected by the classifier, and HC is tracked from (p 0 , s 0 ). Success rate is the percentage of test p-s pairs (p, s) for which the correct solution s is obtained by HC from (p 0 , s 0 ). The classification task is difficult because for some problems p, multiple geometrically meaningful solutions (all points in front of cameras, small ratios between the depths, and small baseline) exist. Therefore, we also consider MLP classifiers which return m best anchors. Then, the classification is successful if the correct solution s can be tracked from any of the selected anchors.\nTo show the benefits of our classifier, we also compare it with the following baselines: Note that the first baseline gives the upper bound on the success rate for a given anchor set A. The downside of this baseline is that HC paths from all A anchors must be tracked. Success rate and total time for different classifiers are shown in Tab. 4. The solution s is considered correct if the squared Euclidean distance from the obtained solution to the ground-truth solution is less than 10 \u22125 .  4. Classifier evaluation. Rows correspond to start problem selection strategies. The anchors are extracted from datasets Office and Terrains (Tab. 1). The strategies are evaluated on datasets Delivery area and Facade. An denotes a set of anchors covering n% of the training datasets. B1 tracks from all anchors in An. The success rate of B1 is equivalent to an \"Oracle\", which gives the best possible \"retrieval\" of the starting problem to reach the target problem, for a given set of anchors. \"B2, An\" selects the starting problem as the nearest anchor to the target problem (measured by the Euclidean distance in the space of normalized image points) from An. \"B3, An\" selects the starting problem as the nearest anchor to the target problem measured by the Mahalanobis distance. \"MLP+T, anchors An\" is our method selecting the starting problem as the one from An with the highest score given by the MLP constructed in Sec.5. Columns: \u03c1 is the success rate (recall) of retrieving a starting point from which the target problem can be reached, \u00b5t is the mean solving time,", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Homotopy continuation", "text": "We now recall the basic principles of HC methods [7,46,63] in the framework of our work. Suppose we have a square system of n polynomial equations f (p, s) = (f 1 (p, s), . . . , f n (p, s)) in n unknowns s = (s 1 , . . . , s n ) that vanish on our problem/solution manifold M .\nOur task is to numerically continue a known problem/solution pair (p 0 , s 0 ) \u2208 M to a pair (p, s) \u2208 M for some problem of interest p \u2208 P. This may be accomplished by introducing a parameter homotopy H(s, t) = f (p(t), s) where p(t) \u2236 [0, 1] \u2192 P is some differentiable function with p(0) = p 0 and p(1) = p. The goal is to compute a differentiable path (p(t), s(t)) \u2236 [0, 1] \u2192 M such that s(0) = s 0 and satisfying the implicit equation H(p(t), s(t)) = 0. Note that the homotopy H depends on p(t), and that many choices are possible. We mainly consider Linear segment HC: that is, we choose p(t) = (1\u2212t) p 0 +t p.\nIn practice, we compute an approximation of the solution curve s(t) by numerical predictor/corrector methods, illustrated in Fig. 2b. In our predictor step, the value s(t i ) * for a given t i \u2208 [0, 1) is known, and the value s(t i + \u2206t) for an adaptivelychosen stepsize \u2206t is approximated using the standard fourth-order Runge-Kutta method. In the corrector step, the value s(t i + \u2206t) is refined by up to 3 steps of Newton's method.\nFor both cases of 5pt and Scranton problems, there are additional polynomial constraints which rule out certain spurious solutions. However, one advantage of our HC method is that, although the vanishing set of the f we use is strictly larger than M, these additional constraints do not need to be explicitly enforced-See SM Sec. 16", "publication_ref": ["b7", "b47", "b65"], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "Efficient HC implementation", "text": "Our work builds on the core of an optimized HC solver introduced in [20] that was originally developed for the problem of computing the relative pose of three calibrated cameras from corresponding point-line incidences. The optimized solver in that work is globally convergent with probability 1, but needs about 500 miliseconds to track 312 complex solution paths to solve a single problem instance. By contrast, our solver for Scranton tracks a single path in under 10 microseconds, a speedup of more than 1000\u00d7. As noted in Sec. 1.3, much of this dramatic speedup is because global HC methods must compute all solutions over the complex numbers, whereas our method computes one, allowing now a greater probability of failure for a given data sample. Moreover, the start system in our HC method is tailored to the input by the anchor selection procedure.\nC i C j X m X k x k,i x m,i x k,j x m,j \u03bb m,i v m,i \u03bb m,j v m,j C 1 C 3 C 2 X m X 1 x m,1 x m,3 x m,2 x 1,1 l \u03bb m,1 v m,1\nThere are also significant implementation-specific speedups. For instance, we obtain another \u2248 14\u00d7 speedup by performing all computations in real, instead of complex arithmetic. We also obtain an \u2248 5 speedup by optimizing the linear algebra underlying predictor/corrector steps; the Jacobian matrices of our depth-formulated are sparse, leading to inexpensive closedform solutions. 8 ", "publication_ref": ["b21", "b8"], "figure_ref": [], "table_ref": []}, {"heading": "Minimal problem formulation", "text": "We now describe the polynomial systems used by our 5pt and 4pt HC solvers. The unknowns in both systems are the normalized depths in each camera, as formulated in previous works [52,69]. We choose this formulation over others because (i) due to low degree and sparsity, it leads to fast evaluation of straight-line programs and fast execution of linear algebra subroutines used in homotopy tracking and (ii) it works well in tandem with our normalization procedure described in Sec. 8.\nTo derive polynomial constraints relating depths and image points, consider two 3D points X k , X m labeled by k, m that are projected by two calibrated cameras labeled by i, j into image points x k,i , x m,i , x k,j , x m,j with the corresponding homogeneouos coordinates given by v = [x; 1]. We see, Fig. 3, that \u03bb \nk,i v k,i \u2212 \u03bb m,i v m,i 2 = \u03bb k,j v k,j \u2212 \u03bb m,j v m,j2\nmust hold, where the unknown \u03bb k,i is the depth of the 3D point X k in camera i. This constraint means that the distance between every two 3D points, when reconstructed in different cameras, must be the same.", "publication_ref": ["b54", "b71"], "figure_ref": ["fig_3"], "table_ref": []}, {"heading": "5pt minimal problem", "text": "The 5pt problem is parametrized by the projection of 5 3D points into 2 calibrated cameras. There are 10 unknown depths \u03bb i,j , i = 1, . . . , 5, j = 1, 2, and 10 = 5 2 equations\n\u03bb k,1 v k,1 \u2212 \u03bb m,1 v m,1 2 = \u03bb k,2 v k,2 \u2212 \u03bb m,2 v m,22\n(1)\nk, m = 1, . . . , 5, k \u2260 m. To dehomogenize this system, we set \u03bb 1,1 = 1 to obtain a system of 10 equations in 9 unknowns. It has 80 solutions for generic parameters v i,j . There are two isolated singular solutions \u03bb = [1, 0, 0, 0, 0; \u00b1a, 0, 0, 0, 0], with multiplicity 20, and 40 isolated nonsingular solutions. Among the 40 nonsingular solutions, there are at most 10 with all depths positive which extend to a rotation with det R 2 = 1.\nFor our HC solver, we have to select a square subsystem, i.e., 9 equations for 9 unknowns. For generic parameters, any equation can be dropped to get a square system with 160 solutions, where the two singular solutions have multiplicity 32 and the number of nonsingular solutions rises to 96. As noted in Sec. 6, the dropped equation and other polynomial constraints (det R 2 = 1) need not be explicitly enforced by our HC solver. 9 .", "publication_ref": ["b9"], "figure_ref": [], "table_ref": []}, {"heading": "Scranton relaxation of the 4pt problem", "text": "The 4pt problem consists of the projection of 4 points into 3 calibrated cameras. Therefore, it involves 12 unknown depths \u03bb i,j , i = 1, 2, 3, 4, j = 1, 2, 3, and 18 = 4 2 3 2 equations. However, only 2 equations, from each 3 2 equations involving the same pair of 3D points, are independent. Hence we get 12 equations\n\u03bb k,i v k,i \u2212 \u03bb m,i v m,i 2 = \u03bb k,j v k,j \u2212 \u03bb m,j v m,j 2(2)\nk, m = 1, . . . , 4, k \u2260 m and, e.g., i = 1, 2, j = i + 1. To dehomogenize the system, we set \u03bb 1,1 = 1. Unlike for the 5pt problem, here we get an overconstrained system of 12 equations for 11 unknown depths, which has no solution for generic (noisy) parameters v k,i . To get a minimal problem, we replace v 1,1 by v 1,1 + l [0; 1; 0], where l is a new unknown. This relaxation allows us to \"adjust\" the second coordinate of the first point in the first camera. Notice that by relaxing the first point in the first view, which has \u03bb 1,1 = 1, the equations involving that point\nv 1,1 + l [0; 1; 0] \u2212 \u03bb m,1 v m,1 2 = \u03bb 1,2 v 1,2 \u2212 \u03bb m,2 v m,22\nfor m = 2, 3, 4 remain quadratic in unknowns (\u03bb, l). Solutions to the minimal problem \"Scranton\", Fig. 3, are solutions to this square, inhomogeneous system of 12 polynomials used in our HC solver. 10 .", "publication_ref": ["b3", "b10"], "figure_ref": ["fig_3"], "table_ref": []}, {"heading": "Problem preprocessing", "text": "To simplify both the learning the anchor selection strategy \u03c3 and the HC tracking, we considered several schemes for normalizing the input image correspondences, i.e., the parameters p of the problems. Our chosen normalization yields single representative p for all problems that differ from p up to camera re-orientation or permutation of cameras or correspondences. Once the normalized problem is solved, the original problem may be solved by applying a transformation R \u22121 i described below.\nFor the 5pt problem, a problem p is given by image coordinates x i,j \u2208 R 2 with cameras indexed by i = 1, 2 and points indexed by j = 1, . . . , 5. First, we construct unit 3D vectors representing the rays of the image points as v i,j = [x i,j ; 1] [x i,j ; 1] . Next, we compute the mean ray for each camera m i = mean j (v i,j ). Then, we find the ray v i * j * that contains the largest angle with the mean ray m i of its camera, i.e., (i * , j * ) = argmax (i,j) \u2220(x i,j , m i ). Next, we compute w i,j = R i v i,j such that R i m i = [0; 0; 1] and y i * ,j * , as well as the corresponding y 1\u2212i * ,j * , have the second coordinate equal to 0, i.e., we put them on the \"x axis\". Finally, we swap the cameras to make the camera i * the first one, project 3D rays w i,j back to the image points x i,j = w i,j w\n(3) i,j , and reorder the image correspondences counterclockwise starting with j * 11 . For the 4pt problem, cameras are ordered according to angles of the first point;\n\u2220([x 1,1 ; 1], [0, 0, 1]) \u2265 \u2220([x 2,1 ; 1], [0, 0, 1]) \u2265 \u2220([x 3,1 ; 1], [0, 0, 1]).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Experiments -RANSAC evaluation", "text": "To show how our method generalizes to different real scenes and to data contaminated by noise and wrong matches, we evaluate our approach for the 5pt problem on the dataset from the CVPR 2020 RANSAC Tutorial [47] consising of 2 validation scenes and 11 test scenes, each comprising 4950 camera pairs. For every camera pair, a set of matched 2D points is known. The points are contaminated with noise and mismatches. We evaluate solvers by plugging them into a RANSAC scheme [53] and computing relative poses for camera pairs in each scene. We evaluate the rotation error and translation error separately. Our evaluation metric is the percentage of relative poses whose angular distance from the ground truth is less than 10 \u25cb . We believe that this metric is justified, because the main purpose of the RANSAC procedure is to separate the correct matches from the mismatches, and a more precise relative pose can be obtained by local optimization on the inliers. We consider our HC solver with a single anchor, our HC solver with MLP without trash, and our HC solver with MLP and trash. To estimate the success rate of our solver on this data, we compare it with the Nist\u00e9r 5 point solver [48]. The success rate of the Nist\u00e9r solver is close to 100%, and its errors are only due to the noise and mismatches in the data. Therefore, if the success rate of a solver on the given data is, e.g., 25%, we expect it to need 4 times the number of samples used for the Nist\u00e9r solver to get the same results. We have considered RANSAC with 25, 50, 100, 200, 400, 800, 1600, and 3200 samples. The inlier ratio is 3px. The relation between the number of samples and the percentage of correctly estimated cameras is shown in Fig. 4. The graph shows that the lower success rate of our method can be compensated by running RANSAC for more samples. Our method with MLP requires about 4 times more samples than the Nist\u00e9r solver. Therefore, the success rate on the data from [47] is around 25%, which is about 1.6 times lower than the success rate on the testing data from ETH 3D dataset 12 .", "publication_ref": ["b48", "b55", "b49", "b48"], "figure_ref": ["fig_4"], "table_ref": []}, {"heading": "Conclusion", "text": "Our approach to solving hard minimal problems for RANSAC framework, which uses efficient homotopy continuation and machine learning to avoid solving for many spurious solutions, is fast and delivers correct results. Supplementary Material (SM) presents more details and experiments. Our code and and data are available at https://github.com/petrhruby97/learning minimal Limitations of our approach: First, we sacrifice the high success rate of a complex HC method for a fast, real HC method that fails more frequently. Nevertheless, when combined with trained models, our method succeeds in computing real solutions often enough to be useful in RANSAC. Secondly, our MLP model represents only what it is trained for. Still, we saw that it was able to represent real data distributions while keeping small size and fast evaluation. Fitting to a particular data distribution may also be useful in special situations, e.g., when cameras are mounted on a vehicle, hence having special motions.\nFigure 5. Illustration of generating anchors. A minimal sample of cameras and points is sampled from an existing 3D model. Then, the sampled geometry is converted to the problem-solution pairs. A graph is built whose nodes are the sampled problem-solution pairs. HC is tracked from every p-s pair to every other p-s pair. If the obtained solution is equal to the sampled solution, the p-s pairs are connected with an edge. The selected anchors are a vertex cover of the graph obtained with a greedy algorithm.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Supplementary Material", "text": "Here we give additional details, including an analysis of the 5pt and Scranton minimal problem solutions, details of our efficient homotopy continuation implementation, and experiments justifying our engineering choices. Our code is available at https://github.com/petrhruby97/learning minimal", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A classical example of a minimal problem", "text": "A classical, easy, but still essential, minimal problem in computer vision is computing the pose of a calibrated perspective camera [28] from three points in space and their image projections [25,26,32,41,51]. In one of its classical formulations [25], it leads to a polynomial system of three equations\nX 1 \u2212 X 2 2 = \u03bb 1 u 1 \u2212 \u03bb 2 u 2 2 X 2 \u2212 X 3 2 = \u03bb 2 u 2 \u2212 \u03bb 3 u 3 2 X 3 \u2212 X 1 2 = \u03bb 3 u 3 \u2212 \u03bb 1 u 1 2\nof degree two in three unknown depths \u03bb 1 , \u03bb 2 , \u03bb 3 . Parameters of the problem are three 3D points X i \u2208 R 3 and homogeneous coordinates u i \u2208 R 2 of three image projections, altogether on 3 \u00d7 3 + 3 \u00d7 2 = 15 parameters. For generic data, the system has eight complex solutions for \u03bb's with up to eight real solutions [22]. However, often, there are only zero, two, or four real solutions with positive \u03bb's. This example illustrates a typical situation occurring in minimal problem solving. The minimal problem obtained by relaxing a geometrical optimization problem, which has one optimal solution, brings in seven additional (spurious) solutions. In this case, there are always at least two real solutions corresponding to seeing the three points from the opposite sides of the plain they span.", "publication_ref": ["b29", "b26", "b27", "b33", "b42", "b52", "b26", "b23"], "figure_ref": [], "table_ref": []}, {"heading": "Interesting hard minimal problems", "text": "Recent results [15,16] suggest that solving minimal problems with many complex solutions is interesting. A complete classification of minimal problems for points, lines, and their incidences in the calibrated multi-view geometry appeared for the case of complete multi-view visibility [15]. It has been found that there are only 30 minimal problems in that setting, but it also became clear that problems involving more than two cameras are hard for the current symbolic-numeric and homotopy continuation solvers. The number of solutions for three views starts with 64, interesting cases have 200+ solutions, and 5view cases have 10000+ solutions. Allowing for occlusion or missed detection in images leads to even harder problems. The follow-up work [16] developed a complete classification of minimal problems for generic arrangements of points and lines in space, observed partially by three calibrated perspective cameras when each line is incident to at most one point. It has been found that there is an infinite number of such minimal problems arranged into 74575 equivalence classes when caring only about camera configurations. Interestingly, this classification involves all calibrated trifocal geometry of computer vision for nonincident points and lines in space. Out of 74575 classes, only 759 classes have less than 300 solutions. The rest have (many) more solutions. Thus, for many interesting and potentially practical problems, computing all solutions in a reasonable time is a task beyond the reach of current symbolic-numeric and homotopy continuation solving methods.", "publication_ref": ["b15", "b16", "b15", "b16"], "figure_ref": [], "table_ref": []}, {"heading": "Examples of problem-solution manifolds worked out in detail", "text": "Let us now provide a detailed explanation of the problem-solution manifold concept introduced in Sec. 2.1 for the 5pt and 4pt problems solved in this work. Example 3. Consider the 5pt problem of computing the relative pose of two calibrated cameras from 5 correspondences in two images,i.e., two 3 \u00d7 4 matrices C 1 = R 1 t 1 = I 0 , C 2 = R 2 t 2 in the special Euclidean group SE R (3), which view five world points X 1 , . . . , X 5 \u2208 R 3 where X 1 is normalized to lie in the first image plane:\n{X 1 X (3) 1 = 1} \u2245 R 2 .\nThe points are in front of both cameras iff their depths\n\u03bb i,j = \u03bb i,j (X, C) = R j (3,\u2236) X i + t (3) j\nare all positive (R j (3,\u2236) is the third row of R j and t\n(3) j the third entry of t i .) Consider\n\u03a8 5pt \u2236 R 2 \u00d7 (R 3 ) 4 \u00d7 SE R (3) \u2192 R 2 10 \u00d7 R 9 (X , C) \u21a6 (x, \u03bb)\nwhere\nx = \u03bb \u22121 i,j (R j X i + t j ) (1\u22362) i=1,...,5; j=1,2; (i,j)\u2260(1,1) .(3)\nHere the problem space is P = R 2 10 the solution space is S = R 9 , \u03c0(x, \u03bb) = x, and our problem-solution manifold M = M 5pt is the set of smooth points in the semialgebraic set im(\u03a8 5pt ) \u2229 (R >0 ) 9 \u00d7 R 2 10 .\nRemark 1. For a generic problem x \u2208 M 5pt , the fiber \u03c0 \u22121 (x) consists of at most 10 solutions \u03bb > 0, and every such \u03bb can be extended uniquely to a pair (X, C) \u21a6 (x, \u03bb).\nRemark 2. Our assumptions in Example 3 imply that \u03bb 1,1 = 1. In subsequent sections, we treat the five-point problem as a system of equations in the nine remaining unknown depths. More generally, we could dehomogenize our system by setting any linear form in \u03bb's equal to 1.\nExample 4. Consider the Scranton relaxation of the 4pt problem computing the relative pose of three calibrated cameras from 4 correspondences in 3 images. We have 4 world points X 1 , . . . , X 4 with X\n(3) 1 = 1 and three cameras C 1 = I 0 , C 2 = R 2 t 2 , C 3 = R 3 t 3 such that cameras C 1 , C 2 , C 3 view X 2 , . . . , X 4 , cameras C 2 , C 3 view X 1 , and camera C 1 views the line in the direction e 2 = 0 1 0 \u22ba that passes through X 1 , parametrized as (l) = X 1 + le 2 . Now, we have a map\n\u03a8 Scr \u2236 R 2 \u00d7 (R 3 ) 3 \u00d7 R \u00d7 (SE R (3)) 2 \u2192 R 2 12 \u00d7 R 12 ((X, l) , C) \u21a6 (x, (\u03bb, l))\nwhere x i,j are as in Eq. (3) except that\nx 1,1 = (X i + t j \u2212 le 2 ) (1\u22362) .\nHere the problem space is P = R 2 12 the solution space is S = R 12 , \u03c0(x, \u03bb) = x, and our problem-solution manifold\nM = M Scr is the set of smooth points in the semialgebraic set im(\u03a8 Scr ) \u2229 (R >0 ) 11 \u00d7 R \u00d7 R 2 12 .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Additional details for 5pt formulation", "text": "Here we provide additional details concerning the solutions of the depth-formulated 5pt problem developed in Section 7.1. Given (x, \u03bb) \u2208 M 5pt , we first note that a valid rotation matrix R(x, \u03bb) may be estimated by computing certain auxiliary quantites: for i \u2208 {1, . . . , 5} and v \u2208 {1, 2}, we define X i,v = \u03bb i,v x i,v , and, for distinct i, j, k \u2208 {2, 3, 4, 5},\nA (v) i,j,k = X i,v \u2212 X 1,v X j,v \u2212 X 1,v X k,v \u2212 X 1,v . Thus, det A (v)\ni,j,k gives the oriented volume of a tetrahedron whose vertices are X 1,v , X i,v , X j,v , X k,v . To estimate the rotation from a geometrically meaningful solution, one may compute either .\nR 2 (x, \u03bb) = A (2) 2,3,4 A (1) 2,3,4 \u22121 (4)\n(\n)5\nThe solutions to Equation ( 1) need not satisfy the additional constraint det R 2 (x, \u03bb) = 1, since there is a sign-symmetry \u03bb i,v \u21a6 (\u22121) v+1 \u03bb i,v which changes the sign of det R 2 (x, \u03bb) but leaves Equation (1) invariant. Moreover, there are 76 nonsingular, spurious solutions to the square subsystem obtained by dropping one equation, plus an additional 2 of higher multiplicity. For these 78 spurious solutions, either of the matrices in Eq. (4) or Eq. (5) may have determinant \u22121. These spurious solutions may be ruled out by enforcing det = 1 for either both of these matrices, or for one of these matrices in addition to all original depth constraints. With these constraints enforced, the generic number of solutions drops to 20. Moreover, there is an additional symmetry given by the \"twisted pair\" [28]: letting\nt(x, \u03bb) = \u03bb 1,2 v 1,2 \u2212 R(x, \u03bb)\u03bb 1,1 v 1,1 ,\nwe define tw(x, \u03bb) coordinate-wise fixing x and tw(\u03bb i,j ) = (\u22121) j+1 t(x, \u03bb)\n2 \u03bb i,j \u03bb i,2 v i,2 2 \u2212 \u03bb i,1 v i,1 2\nThe map on p-s pairs (x, \u03bb) \u21a6 (x, tw(x, \u03bb)) reverses the signs of depths in the second view. This justifies our claim that there are at most 10 geometrically meaningful solutions to Eq. (1). We remark that the partition of 20 solutions into twisted pairs is preserved along non-singular solution curves computed by our HC method.", "publication_ref": ["b29"], "figure_ref": [], "table_ref": []}, {"heading": "Additional details for Scranton formulation", "text": "Unlike the system used for the 5pt problem, the square system for Scranton has infinitely many solutions. Recall that this system is given by the relaxed depth constraint\nv 1,1 + l [0; 1; 0] \u2212 \u03bb m,1 v m,1 2 = \u03bb 1,2 v 1,2 \u2212 \u03bb m,2 v m,22\nand Eq. (2) for remaining points and cameras. A one-dimensional family of solutions may be obtained by setting all depths except \u03bb 1,1 , \u03bb 1,2 , \u03bb 1,3 to 0, resulting in 2 nontrivial equations in the remaining 3 unknowns: namely,\nv 1,1 + l [0; 1; 0] 2 = \u03bb 1,2 v 1,2 2 \u03bb 1,2 v 1,2 2 = \u03bb 1,3 v 1,3 2\nThe square system for Scranton also has several families of isolated singular solutions where certain depths equal 0. However, for generic data, the number of nonsingular solutions equals the number of solutions with nonzero depths, which is 1408. Among these, there is a four-fold sign symmetry where \u03bb i,2 \u21a6 \u00b1\u03bb i,2 , \u03bb i,3 \u21a6 \u00b1\u03bb i,3 , and 320 = 4 \u00d7 80 cannot be lifted to a valid pair of rotations (R 2 (x, \u03bb), R 3 (x, \u03bb)) .\nTaking these facts into account, there are at most 1408 \u2212 3 \u00d7 272 \u2212 4 \u00d7 80 = 272 geometrically relevant solutions on the problem-solution manifold. This agrees with the number of solutions reported in both [31] and [16], where formulations in Figure 7. Illustration of testing the classifier. A minimal sample p is obtained in the RANSAC scheme. Then, the sample is normalized. The normalized sample is used as the input to the trained MLP, which selects the starting p-s pair (p0, s0). Then, HC is tracked from (p0, s0) to p. If a solution s is obtained, it is converted to a relative pose and the RANSAC score of it is evaluated.\nterms of trifocal tensors and camera matrices, respectively, were employed. We note that, unlike the five-point problem, there is no further reduction in the number of solutions implied by a symmetry such as the twisted pair; this follows by numerically computing the Galois group associated to Scranton, using techniques described in [17], which turns out to be the symmetric group on 272 letters.", "publication_ref": ["b32", "b16", "b18"], "figure_ref": [], "table_ref": []}, {"heading": "Additional details on HC methods", "text": "As noted in Sec. 6, our homotopy H depends on the choice of a path p(t) connecting p 0 to p, where (p 0 , s 0 ) is a known p-s pair and p is the problem to be solved. In all of our experiments, we consider one of two choices. Mostly, we use 1) Linear segment HC: that is, we choose p(t) = (1 \u2212 t) p 0 + t p. This linear segment homotopy has several advantages; among them, the straight-line programs needed to evaluate H and its derivatives are much simpler than for other paths, and the fact that p(t) is real-valued for all t. However, under Linear segment HC, a differentiable solution curve s(t) satisfying H(p(t), s(t)) = 0 need not exist for all t \u2208 [0, 1]. For instance, a problem with singular solutions may exist somewhere along the segment connected in P connecting p 0 and p. However, the solution curve s(t) will exist for all t \u2208 [0, 1] if p 0 and p are \"close enough\"-more precisely, if p(t) avoids the lower-dimensional set of critical values of \u03c0 in P for all t \u2208 [0, 1].\nAlternatively, one may consider 2) Circular arc HC: here, we reparametrize the segment p(t) via a circular arc t(\u03c4 ) \u2236 [0, 1] \u2192 [0, 1] obtained by fixing a random \u03b3 \u2208 C (typically of modulus 1) and t(\u03c4 ) = \u03b3 \u03c4 1+(\u03b3\u22121)\u03c4 . This is the \u03b3-trick of [63,Lemma 7.1.3 ]. Numerical continuation with the resulting homotopy H(s, \u03c4 ) is globally convergent with probability one: for almost all choices of \u03b3, the solution curves s(t) are defined for all t \u2208 [0, 1], and any isolated target solution (p, s) is the endpoint of some solution curve. However, this necessitates computing many spurious solutions. An experimental comparison of Linear segment and Circular arc HC may be found in Tab. 7.\nWe now explain why the square systems used in our homotopies are sufficient when starting from a p-s pair on the problemsolution manifold. Consider a path t \u21a6 (p(t), s(t)) \u2208 P \u00d7 S where (p(0), s(0)) = (p 0 , s 0 ) \u2208 M and such that that the n \u00d7 n Jacobian matrix d H d s (p(t), s(t)) has rank n for all t \u2208 [0, 1]. Thus, the path t \u21a6 (p(t), s(t)) is contained in a single connected component of the set of nonsingular points in the complex vanishing set {(p, s) \u2208 P C \u00d7 S C f (p, s) = 0}. Among these connected components is the set of smooth points in the Zariski closure of M . Indeed, the complex Zariski closure of M has a rational parametrization (given by one of the maps \u03a8 5pt , \u03a8 Scr defined in Sec. 13), so it is irreducible, and the connectedness of its smooth points follows by [24, pp. 21-22]. Since the point (p 0 , s 0 ) is contained in this connected component, so also\nmust (p(t), s(t)) for all t \u2208 [0, 1]. Thus, any polynomial g(p, s) vanishing on M satisfies g(p(t), s(t)) = 0 for all t \u2208 [0, 1].\nThis means that, if HC tracking from (p 0 , s 0 ) \u2208 M succeeds using our square system of constraints, then all additional constraints which are polynomial equalities are automatically satisfied. This justifies the fact that we do not explicitly enforce constraints like det R 2 (x, \u03bb) = 1, since it is enough to enforce them for the initial p-s pair.", "publication_ref": ["b65", "b7"], "figure_ref": [], "table_ref": []}, {"heading": "Efficient evaluation of predictor/corrector", "text": "The Runge-Kutta method used for the predictor step and Newton's method used for the corrector step in our HC implementation both require solving systems of linear equations. In either step, the coefficient matrix is given by the Jacobian \u2202H(s,t) \u2202s (Sec. 6). In the case of the depth formulation of the Five-Point problem (1) and the Four-Point problem (2), the associated Jacobian matrix is sparse. The sparsity pattern of the Jacobian matrix \u2202H(s,t) \u2202s is shown in (6) for the Five-Point problem, and in (7) for the Four-Point problem.  \n\u23a1 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a3 A0,3 0 0 0 A0,4 A0,5 0 0 0 0 A1,1 0 0 A1,4 0 A1,6 0 0 A2,0 A2,1 0 A2,3 0 0 A2,6 0 0 0 0 A3,2 0 A3,4 0 0 A3,7 0 A4,0 0 A4,2 0 0 A4,5 0 A4,7 0 0 A5,1 A5,2 0 0 0 A5,6 A5,7 0 0 0 0 A6,3 A6,4 0 0 0 A6,8 A7,0 0 0 A7,3 0 A7,5 0 0 A7,8 0 A8,1 0 A8,3 0 0 A8,6 0 A8,8 \u23a4 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a6 (6) \u23a1 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a3 A 0,0 0 0 A 0,3 A 0,4 0 0 0 0 0 0 0 0 A 1,1 0 A 1,3 0 A 1,5 0 0 0 0 0 0 A 2,0 A 2,1 0 0 A 2,4 A 2,5 0 0 0 0 0 0 0 0 A 3,2 A 3,3 0 0 A 3,6 0 0 0 0 0 A 4,0 0 A 4,2 0 A 4,4 0 A 4,6 0 0 0 0 0 0 A 5,1 A 5,2 0 0 A 5,5 A 5,6 0 0 0 0 0 A 6,0 0 0 0 0 0 0 A 6,7 A 6,8 0 0 0 0 A 7,1 0 0 0 0 0 A 7,7 0 A 7,9 0 0 A 8,0 A 8,1 0 0 0 0 0 0 A 8,\n\u23a4 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a6(7)\nUsing generic methods such as LU decomposition, as in previous work [21], numerical linear algebra becomes a significant bottleneck in both the predictor and corrector stages. To overcome this bottleneck, we replace the generic numerical linear algebra with closed-form solutions to the systems of linear equations with coefficient matrices (6) and (7). This replacement results in about 5x speedup for both problems.", "publication_ref": ["b6", "b7", "b22", "b7"], "figure_ref": [], "table_ref": []}, {"heading": "Variations of the normalization", "text": "Let us provide additional details about our normalization of problems to simplify their variability and thus to make learning of the picking function \u03c3 easier.\nFig. 8 shows an example of the normalized 5pt problem. The mean direction vectors m 1 , m 2 in both images are at [0; 0; 1]. The first correspondence, x 1,1 , x 2,1 is on the x axis. The first image is chosen such that it contains the larger angle with its corresponding m u . This also means that the first correspondence point has a larger x image coordinate:\nx (1) 1,1 >, x(1)\n2,1 . To make the normalized problems independent on the ordering of the correspondences, we sort them by their polar angles in the coordinate system in the the first image. Notice that their order may be swapped in the second image, e.g., as for x 2,2 , x 3,2 . Such a swap is mainly due to a large change of the order of depth of the corresponding points in the scene, as seen from different view points, which is in practice much less frequent than keeping the order [70].\nOur normalization is chosen as the best one among several meaningful alternatives. The evaluation of the alternative normalization methods is shown in Tab. 5 for the 5pt problem and in Tab. 6 for the Scranton problem. The tables show that our strategy, labeled by A, which rotates the center of mass to zero and the farthest point on the x-axis, has the best success rate for both problems. Note that every normalization strategy performs better than when tracking without normalization.\nThe normalization strategies are as follows:\nA. Rotate the center of mass to zero, rotate the point farthest from zero to x-axis. B. Rotate the center of mass to zero with an iterative procedure, rotate the point farthest from zero to x-axis. C. Rotate the closest point to center of mass to zero and the point farthest from zero to x-axis. D. Rotate the center of mass to zero and the maximal variance to x-axis. E. Rotate the closest point to center of mass to zero and the maximal variance to x-axis.\nIn the case of the Scranton problem, we also have to decide which point in which view to relax on the line. Here, we consider:  6. Evaluation of the normalization for the Scranton problem. We have generated 4000 problem-solution pairs, normalized them with a given strategy and tracked HC from every p-s pair to every other. We consider strategies from Sec. 17. We measure the success rate, average time of the normalization and of HC. The track is considered successful if the squared Euclidean distance from the obtained solution to the ground-truth is less than 10 \u22125 .\nStrategy\na) The farthest point and view.\nb) The point rotated to zero (if possible).\nOur normalization induces three linear constraints for every view. The instance p of the 5pt problem consists of 2D projections of 5 points into two views, therefore p \u2208 R 20 . The normalized instances live in a 20 \u2212 2 \u00d7 3 = 14 dimensional subspace of R 20 . The instance p of the 4pt problem consists of 2D projections of 4 points into 3 views, p \u2208 R 24 . The normalized instances live in a 24 \u2212 3 \u00d7 3 = 15 dimensional subspace of R 24 .\nThe values of the success rate in this experiment are low because we use randomly sampled data and track from every p-s pair to every other p-s pair. Tab. 9 shows that the success rate significantly increases if we track from preselected anchors which are chosen to perform well and we select the best starting anchor with a trained classifier.", "publication_ref": ["b72", "b25", "b25"], "figure_ref": [], "table_ref": []}, {"heading": "Study to justify engineering choices", "text": "Let us describe the data sets we use to study our engineering choices. Training data set D 5pt consists of 40000 p-s pairs. We randomly sample pairs of cameras and 5-tuples of 3D points from the ETH 3D dataset [60] \"Office\" and \"Terrains\". Problem parameters p are 10D vectors of 2D image coordinates obtained by projecting the sampled 5-tuples of 3D points by the camera pairs. The corresponding solutions s are 10D vectors of the depths of the 3D points in the two cameras normalized to have the first depth equal to 1. Data set D Scr , consisting of 40000 p-s pairs, is constructed analagously by sampling 4-tuples of 3D points and triplets of cameras. Data sets are used to select anchor sets and to train our model for selecting the starting problem-solution pair.\nAnchor Table 7. Homotopy continuation study. The rows represent variations mixing the solving technique of complex (C-HC) and real (R-HC) homotopy continuation, the Newton's local method (Newton) with starting from all solutions (All Sols), real solutions only (R Sols), and the fabricated solution only (Fab Sol) of a problem. The columns represent different implementations of homotopy continuation. M2 denotes the off-the-shelf implementation in Macaulay2 [43]. MINUS denotes the implementation based on [20]. OUR denotes our efficient implementation. To compare MINUS and OUR, we selected 20 subsets Pi, i = 1, . . . , 20, each containing 50 random problems from P 5pt for 5pt problem and from P Scr for Scranton. All problems were normalized. For each Pi, we compute the success rate \u00b5s i of 50 2 \u2212 50 of homotopy continuations from each start problem pij \u2208 Pi to each different target problem p ik \u2208 Pi. We consider a homotopy continuation successful if the fabricated solution of the target problem p ik is among the solutions reached by the homotopy continuation within 10 \u22125 Euclidean distance in the solution space of depths. We report the mean success rate \u00b5s = mean(\u00b5s i ) and the standard deviation \u03b4s = std(\u00b5s i ) over all Pi's for each implementation and mean computation times \u00b5t.  9. Percentage of different results of real homotopy continuation. In \"All pairs\", we track from each pi \u2208 P to each other pj \u2208 P . In \"MLP\", we solve each p \u2208 V by selecting a starting p-s pair (p0, s0) from A90, and by tracking HC from p0 to p. \"Fabricated sol.\" means that the fabricated solution was reached, \"1 rel. pose correct\" means that if we convert the obtained solution of the Scranton problem to the relative poses, then at least one of three relative poses is correct. \"Other meaningful\" means that a non-fabricated solution with positive depths and valid rotation matrix was reached, \"Sol. with det -1\" means that the matrix R is not a valid rotation. \"Sol. with zeros\" means that some depths are equal to 0, \"Negative sol.\" means that some depths are negative, and \"Failed track\" means that the HC track has failed and, thus, the solution has not been found.\nstarting p-s pairs (Sec. 4) and trained the MLP for the Newton method. The comparison of the solvers using the Homotopy Continuation and the Newton method is shown in Tab. 8. We can see that the effective time (the average time needed to obtain one correct solution in the RANSAC scheme) of the solver using Homotopy Continuation is about 2x lower than the effective time of the solver using Newton method. While the solvers using Newton method are faster, the success rate of the solver, which combines Homotopy Continuation and MLP classifier has a higher success rate. The possible explanation for this is that the Newton method behaves \"more randomly\" than the Homotopy Continuation, and therefore, it is more difficult to train. Tab. 9 provides a more detailed analysis of the frequency of different results of real Homotopy Continuation tracked from the fabricated solution. We consider two different settings. In the \"All pairs\" setting, we track from each p i \u2208 P to each other p j \u2208 P . Then, in the MLP setting, we select a starting p-s pair (p 0 , s 0 ) from A 90 , and track from p 0 to p. We measure how often we reach the fabricated solution, non-fabricated meaningful solution, a non-valid solution, and how often HC fails and does not deliver any solution. The table shows that the MLP increases the probability of reaching the fabricated solution about 10x for 5pt and 20x for Scranton. The probability of reaching another meaningful solution increases about 3x for both problems, while the probability of reaching a non-valid solution and the probability of failing decreases.", "publication_ref": ["b62", "b44", "b21"], "figure_ref": [], "table_ref": []}, {"heading": "Comparison of different settings our solver", "text": "Here, we show how different settings of the solver influence the resulting success rate \u03c1, mean running time \u00b5 t , and efficient time t . We perform this study on our solver for the Scranton problem. For every experiment, we use the settings from the main paper, except that one parameter is varied. The solver uses anchors A Scr 90 and it is evaluated on data V Scr . Our goal is to show that we have selected the optimal settings for our solver. Formulation Succ. rate First depth fixed 2.30 % Quan symmetrical [52] 1.47 % Quan asymmetrical [52] 1.13 % Table 10. Scranton dehomogenization study. Rows correspond to different formulations of the problems. For each method, we compute the success rate of 4000 2 \u2212 4000 HC calls from each starting p-s pair to each other target p-s pair. We consider the result successful if the fabricated solution of the target problem is and the result computed by HC are sufficiently close ( \u2264 10 \u22125 Euclidean distance in the solution space of depths.) We compare different methods of dehomogenizing Scranton problem in Tab. 10. This justifies our choice of fixing the first depth \u03bb 1,1 = 1, which gives a superior success rate compared to \"symmetric\" and \"asymmetric\" dehomogenization proposed in [52].\nSee Fig. 9 for a code snippet showing the structure of our MLP model. In Tab. 11, we show how the success rate \u03c1 and running time \u00b5 t depends on the size of the MLP that is used for the classification of the anchors. Larger networks have a higher success rate. However, the efficient time of the solver with the smaller MLP is better because the time needed for the evaluation of the MLP grows faster than the success rate.\nFinally, in Tab. 12, we show how the number of HC tracks per problem influences the success rate \u03c1, running time \u00b5 t , and efficient time t . In this experiment, we use the MLP trained in 5, and we perform n tracks from n anchors with the highest score. We consider the solution successful if at least one track reaches the fabricated solution of the target problem. Much like using larger MLP as Tab. 11, such a strategy involving multiple anchors suggests a future approach to improving our solvers' success rates. However, we note that the efficient time t in Tab. 12 grows with the number of tracks, since the evaluation time grows faster than the success rate. ", "publication_ref": ["b54", "b54", "b54"], "figure_ref": ["fig_8"], "table_ref": ["tab_0"]}, {"heading": "", "text": "Data set V Scr , consisting of 60000 p-s pairs, is constructed analagously. We use V 5pt and V Scr in the experiments studying anchor set selection methods reported in Tab. 4.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Comparison of different tracking approaches", "text": "Data set P 5pt consists of of 3751 p-s pairs sampled from the ETH 3D dataset \"Courtyard\". A 5pt and P 5pt are disjoint. All problems in P 5pt are checked to be generic and can be used as good starting problem-solution pairs. We select 20 random pairwise disjoint P 5pt i \u2282 P 5pt consisting of 50 problem-solution pairs. Data sets P Scr , consisting of 5727 problem-solutions pairs, and P Scr i , consisting of 50 p-s pairs, are constructed analagously. We use P 5pt\ni 's and P Scr i in the experiments studying variations of the homotopy continuation methods reported in Tab. 7. In this table, we measure the success rate for a given subset P i as a percentage of different pairs p i,j \u2208 P i , p i,k \u2208 P i for which the fabricated solution to the target problem p i,k can be recovered when tracking from p i,j to p i,k . Then, we find the mean success rate \u00b5 s , and the standard deviation \u03b4 s over all subsets P i , i \u2208 {1, ..., 20}.\nTab. 7 shows that for every setting, our evaluation (Sec. 16.1) brings about 5x speedup over the previous work [20] without any impact on the success rate.\nThe table also shows that Homotopy Continuation in the complex domain tracked from every solution has almost 100% success rate, but the running time of the solver is prohibitively slow to be used in the RANSAC scheme. We can see that reducing the number of tracks, as well as tracking in R instead of C can significantly reduce the running time (about 10000x for the Scranton problem) at the cost of a lower success rate. Note (Tab. 9), that the issue with the low success rate may be remedied by selecting an appropriate starting problem-solution pair (p 0 , s 0 ) for every target problem p.\nTab. 7 also shows that using the Newton method may be a promising approach for solving the minimal problems, as it has a higher success rate and lower running time than Homotopy Continuation with the same setting. Therefore, we have found", "publication_ref": ["b21"], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "On the existence of epipolar matrices", "journal": "International Journal of Computer Vision", "year": "2017", "authors": "Sameer Agarwal; Hon-Leung Lee; Bernd Sturmfels; Rekha R Thomas"}, {"ref_id": "b1", "title": "18 for the study of our engineering choices", "journal": "", "year": "", "authors": "S M See;  Sec"}, {"ref_id": "b2", "title": "The ideal of the trifocal variety", "journal": "Math. Comput", "year": "2014", "authors": "Chris Aholt; Luke Oeding"}, {"ref_id": "b3", "title": "Evaluating pose estimation methods for stereo visual odometry on robots", "journal": "", "year": "2001", "authors": "Brett Hatem Said Alismail; M Bernardine Browning;  Dias"}, {"ref_id": "b4", "title": "Five-point fundamental matrix estimation for uncalibrated cameras", "journal": "", "year": "2018-06-18", "authors": "Daniel Barath"}, {"ref_id": "b5", "title": "Efficient recovery of essential matrix from two affine correspondences", "journal": "IEEE Trans. Image Processing", "year": "2018", "authors": "Daniel Barath; Levente Hajder"}, {"ref_id": "b6", "title": "A minimal solution for two-view focal-length estimation using two affine correspondences", "journal": "", "year": "2017-07-21", "authors": "Daniel Barath; Tekla Toth; Levente Hajder"}, {"ref_id": "b7", "title": "Numerically Solving Polynomial Systems with Bertini", "journal": "Software, environments, tools. SIAM", "year": "2008", "authors": "J Daniel; Andrew J Bates; Jonathan D Sommese; Charles W Hauenstein;  Wampler"}, {"ref_id": "b8", "title": "A sparse resultant based method for efficient minimal solvers", "journal": "", "year": "2020", "authors": "Snehal Bhayani; Zuzana Kukelova; Janne Heikkil\u00e4"}, {"ref_id": "b9", "title": "The OpenCV Library. Dr. Dobb's Journal of Software Tools", "journal": "", "year": "2000", "authors": "G Bradski"}, {"ref_id": "b10", "title": "Homotopycontinuation.jl: A package for homotopy continuation in julia", "journal": "Springer", "year": "2018", "authors": "Paul Breiding; Sascha Timme"}, {"ref_id": "b11", "title": "A column-pivoting based strategy for monomial ordering in numerical Gr\u00f6bner basis calculations", "journal": "Springer", "year": "2008", "authors": "Martin Byr\u00f6d; Klas Josephson; Kalle\u00e5str\u00f6m "}, {"ref_id": "b12", "title": "Minimal solvers for generalized pose and scale estimation from two rays and one point", "journal": "", "year": "2016", "authors": "F Camposeco; T Sattler; M Pollefeys"}, {"ref_id": "b13", "title": "Using Algebraic Geometry", "journal": "Springer", "year": "1998", "authors": "David Cox; John Little; Donald O' Shea"}, {"ref_id": "b14", "title": "Solving polynomial systems via homotopy continuation and monodromy", "journal": "IMA Journal of Numerical Analysis", "year": "2018", "authors": "Timothy Duff; Cvetelina Hill; Anders Jensen; Kisun Lee; Anton Leykin; Jeff Sommars"}, {"ref_id": "b15", "title": "PLMP -point-line minimal problems in complete multi-view visibility", "journal": "", "year": "2019", "authors": "T Duff; K Kohn; A Leykin; T Pajdla"}, {"ref_id": "b16", "title": "PL 1 P -point-line minimal problems under partial visibility in three views", "journal": "", "year": "", "authors": "Timothy Duff; Kathl\u00e9n Kohn; Anton Leykin; Tom\u00e1s Pajdla"}, {"ref_id": "b17", "title": "Proceedings, Part XXVI", "journal": "Springer", "year": "2020", "authors": ""}, {"ref_id": "b18", "title": "Galois/monodromy groups for decomposing minimal problems in 3d reconstruction", "journal": "", "year": "2021", "authors": "Timothy Duff; Viktor Korotynskiy; Tomas Pajdla; Margaret H Regan"}, {"ref_id": "b19", "title": "Line-based relative pose estimation", "journal": "IEEE Computer Society", "year": "2011-06-25", "authors": "Ali Elqursh; Ahmed M Elgammal"}, {"ref_id": "b20", "title": "A general solver based on sparse resultants. CoRR, abs/1201", "journal": "", "year": "2012", "authors": "Z Ioannis;  Emiris"}, {"ref_id": "b21", "title": "TRPLP -Trifocal relative pose from lines at points", "journal": "", "year": "2020", "authors": "Ricardo Fabbri; Timothy Duff; Hongyi Fan; Margaret H Regan; David Da Costa De Pinho; Elias P Tsigaridas; Charles W Wampler; Jonathan D Hauenstein; Peter J Giblin; Benjamin B Kimia; Anton Leykin; Tom\u00e1s Pajdla"}, {"ref_id": "b22", "title": "Camera pose estimation using first-order curve differential geometry", "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": "2020", "authors": "R Fabbri; P Giblin; B Kimia"}, {"ref_id": "b23", "title": "Classification of the perspective-three-point problem, discriminant variety and real solving polynomial systems of inequalities", "journal": "ACM", "year": "2008-07-20", "authors": "Jean-Charles Faug\u00e8re; Guillaume Moroz; Fabrice Rouillier; Mohab Safey El Din"}, {"ref_id": "b24", "title": "Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography", "journal": "Commun. ACM", "year": "1981", "authors": "M A Fischler; R C Bolles"}, {"ref_id": "b25", "title": "Principles of algebraic geometry", "journal": "Wiley Classics Library. John Wiley & Sons, Inc", "year": "1994", "authors": "Phillip Griffiths; Joseph Harris"}, {"ref_id": "b26", "title": "Das pothenotische Problem in erweiterter Gestalt nebst\u00fcber seine Anwendungen in Geod\u00e4sie", "journal": "", "year": "", "authors": "J A Grunert"}, {"ref_id": "b27", "title": "Review and analysis of solutions of the three point perspective pose estimation problem", "journal": "Int. J. Comput. Vis", "year": "1994", "authors": "Robert M Haralick; Chung-Nan Lee; Karsten Ottenberg; Michael N\u00f6lle"}, {"ref_id": "b28", "title": "An efficient hidden variable approach to minimal-case camera motion estimation", "journal": "IEEE PAMI", "year": "2012", "authors": "R Hartley; Hongdong Li"}, {"ref_id": "b29", "title": "Multiple View Geometry in Computer Vision. Cambridge", "journal": "", "year": "2003", "authors": "Richard Hartley; Andrew Zisserman"}, {"ref_id": "b30", "title": "Using sparse elimination for solving minimal problems in computer vision", "journal": "IEEE Computer Society", "year": "2017-10-22", "authors": "Janne Heikkil\u00e4"}, {"ref_id": "b31", "title": "Uniqueness of solutions to three perspective views of four points", "journal": "IEEE Trans. Pattern Anal. Mach. Intell", "year": "1995", "authors": "J Robert; Arun N Holt;  Netravali"}, {"ref_id": "b32", "title": "Minimal problems for the calibrated trifocal variety", "journal": "SIAM Journal on Applied Algebra and Geometry", "year": "2017", "authors": "Joe Kileel"}, {"ref_id": "b33", "title": "A novel parametrization of the perspective-three-point problem for a direct computation of absolute camera position and orientation", "journal": "", "year": "2011", "authors": "L Kneip; D Scaramuzza; R Siegwart"}, {"ref_id": "b34", "title": "Finding the exact rotation between two images independently of the translation", "journal": "", "year": "2012", "authors": "L Kneip; R Siegwart; M Pollefeys"}, {"ref_id": "b35", "title": "Pose estimation with unknown focal length using points, directions and lines", "journal": "", "year": "2013", "authors": "Yubin Kuang;  Kalle\u00e5str\u00f6m"}, {"ref_id": "b36", "title": "Stratified sensor network self-calibration from TDOA measurements", "journal": "", "year": "2013", "authors": "Yubin Kuang;  Kalle\u00e5str\u00f6m"}, {"ref_id": "b37", "title": "Automatic generator of minimal problem solvers", "journal": "", "year": "2002", "authors": "Zuzana Kukelova; Martin Bujnak; Tomas Pajdla"}, {"ref_id": "b38", "title": "Polynomial eigenvalue solutions to minimal problems in computer vision", "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": "", "authors": "Zuzana Kukelova; Martin Bujnak; Tomas Pajdla"}, {"ref_id": "b39", "title": "PoseLib -Minimal Solvers for Camera Pose Estimation", "journal": "", "year": "", "authors": " Viktor Larsson"}, {"ref_id": "b40", "title": "Efficient solvers for minimal problems by syzygy-based reduction", "journal": "", "year": "2017", "authors": " Viktor Larsson; Magnus Kalle\u00e5str\u00f6m;  Oskarsson"}, {"ref_id": "b41", "title": "Polynomial solvers for saturated ideals", "journal": "", "year": "2017-10-22", "authors": " Viktor Larsson; Magnus Kalle\u00e5str\u00f6m;  Oskarsson"}, {"ref_id": "b42", "title": "Making minimal solvers for absolute pose estimation compact and robust", "journal": "", "year": "2003", "authors": "Zuzana Viktor Larsson; Yinqiang Kukelova;  Zheng"}, {"ref_id": "b43", "title": "Beyond grobner bases: Basis selection for minimal solvers", "journal": "", "year": "2018-06-18", "authors": "Magnus Viktor Larsson;  Oskarsson; Alge Kalle\u00e5str\u00f6m; Zuzana Wallis; Tom\u00e1s Kukelova;  Pajdla"}, {"ref_id": "b44", "title": "Numerical algebraic geometry", "journal": "Journal of Software for Algebra and Geometry", "year": "2011", "authors": "Anton Leykin"}, {"ref_id": "b45", "title": "A minimal closed-form solution for multi-perspective pose estimation using points and lines", "journal": "", "year": "2018", "authors": "Pedro Miraldo; Tiago Dias; Srikumar Ramalingam"}, {"ref_id": "b46", "title": "Optimal estimation of vanishing points in a manhattan world", "journal": "", "year": "2011", "authors": "M Faraz;  Mirzaei;  Stergios I Roumeliotis"}, {"ref_id": "b47", "title": "Solving Polynomial Systems Using Continuation for Engineering and Scientific Problems", "journal": "Classics in Applied Mathematics. Society for Industrial and Applied Mathematics", "year": "2009", "authors": "A Morgan"}, {"ref_id": "b48", "title": "Benchmarking robust estimation methods. Tutorial \"RANSAC in 2020", "journal": "CVPR", "year": "2020", "authors": "Dmytro Myshkin"}, {"ref_id": "b49", "title": "An efficient solution to the five-point relative pose problem", "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": "2004-06-01", "authors": "D Nist\u00e9r"}, {"ref_id": "b50", "title": "Visual odometry", "journal": "", "year": "2004", "authors": "David Nist\u00e9r; Oleg Naroditsky; James Bergen"}, {"ref_id": "b51", "title": "Four points in two or three calibrated views: Theory and practice", "journal": "International Journal of Computer Vision", "year": "2006", "authors": "David Nist\u00e9r; Frederik Schaffalitzky"}, {"ref_id": "b52", "title": "Lambda twist: An accurate fast robust perspective three point (P3P) solver", "journal": "", "year": "2018", "authors": "Mikael Persson; Klas Nordberg"}, {"ref_id": "b53", "title": "", "journal": "", "year": "2018", "authors": " Springer"}, {"ref_id": "b54", "title": "Some results on minimal euclidean reconstruction from four points", "journal": "Journal of Mathematical Imaging and Vision", "year": "2006", "authors": "Long Quan; Bill Triggs; Bernard Mourrain"}, {"ref_id": "b55", "title": "USAC: A universal framework for random sample consensus", "journal": "IEEE Transactions on Pattern Analysis Machine Intelligence", "year": "2013", "authors": "R Raguram; O Chum; M Pollefeys; J Matas; J.-M Frahm"}, {"ref_id": "b56", "title": "Minimal solutions for generic imaging models", "journal": "", "year": "2008", "authors": "S Ramalingam; P F Sturm"}, {"ref_id": "b57", "title": "Neighbourhood consensus networks", "journal": "", "year": "2018", "authors": "Ignacio Rocco; Mircea Cimpoi; Relja Arandjelovi\u0107; Akihiko Torii; Tomas Pajdla; Josef Sivic"}, {"ref_id": "b58", "title": "Robust and accurate line-and/or point-based pose estimation without manhattan assumptions", "journal": "", "year": "2016", "authors": "Yohann Sala\u00fcn; Renaud Marlet; Pascal Monasse"}, {"ref_id": "b59", "title": "Efficient & effective prioritized matching for large-scale image-based localization", "journal": "IEEE Trans. Pattern Anal. Mach. Intell", "year": "2017", "authors": "Torsten Sattler; Bastian Leibe; Leif Kobbelt"}, {"ref_id": "b60", "title": "A minimal solution to the rolling shutter pose estimation problem", "journal": "IEEE", "year": "2015", "authors": "Olivier Saurer; Marc Pollefeys; Gim Hee Lee"}, {"ref_id": "b61", "title": "Structure-from-motion revisited", "journal": "", "year": "2016", "authors": "Johannes Lutz Sch\u00f6nberger; Jan-Michael Frahm"}, {"ref_id": "b62", "title": "A multi-view stereo benchmark with high-resolution images and multi-camera videos", "journal": "", "year": "2017", "authors": "Thomas Sch\u00f6ps; Johannes L Sch\u00f6nberger; Silvano Galliani; Torsten Sattler; Konrad Schindler; Marc Pollefeys; Andreas Geiger"}, {"ref_id": "b63", "title": "Photo tourism: exploring photo collections in 3D", "journal": "", "year": "2006", "authors": "N Snavely; S M Seitz; R Szeliski"}, {"ref_id": "b64", "title": "Modeling the world from internet photo collections", "journal": "International Journal of Computer Vision (IJCV)", "year": "2008", "authors": "Noah Snavely; M Steven; Richard Seitz;  Szeliski"}, {"ref_id": "b65", "title": "The numerical solution of systems of polynomials -arising in engineering and science", "journal": "World Scientific", "year": "2005", "authors": "J Andrew; Charles W Sommese; I I Wampler"}, {"ref_id": "b66", "title": "Recent developments on direct relative orientation", "journal": "ISPRS J. of Photogrammetry and Remote Sensing", "year": "2006", "authors": "H Stewenius; C Engels; D Nist\u00e9r"}, {"ref_id": "b67", "title": "Solving Systems of Polynomial Equations", "journal": "CBMS Regional Conferences Series. Amer.Math.Soc", "year": "2002", "authors": "Bernd Sturmfels"}, {"ref_id": "b68", "title": "InLoc: Indoor visual localization with dense matching and view synthesis", "journal": "", "year": "2018", "authors": "Hajime Taira; Masatoshi Okutomi; Torsten Sattler; Mircea Cimpoi; Marc Pollefeys; Josef Sivic; Tomas Pajdla; Akihiko Torii"}, {"ref_id": "b69", "title": "An efficient minimal solution for multi-camera motion", "journal": "", "year": "2015", "authors": "Jonathan Ventura; Clemens Arth; Vincent Lepetit"}, {"ref_id": "b70", "title": "Polynomial homotopy continuation with phcpack", "journal": "ACM Commun. Comput. Algebra", "year": "2010", "authors": "Jan Verschelde"}, {"ref_id": "b71", "title": "Pose-free structure from motion using depth from motion constraints", "journal": "IEEE transactions on image processing", "year": "2011", "authors": "Ji Zhang; Mireille Boutin; Daniel G Aliaga"}, {"ref_id": "b72", "title": "A generalized ordering constraint for stereo correspondence", "journal": "A.I. Memo", "year": "1994", "authors": "A L Yuille; T Poggio"}], "figures": [{"figure_label": "", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "problem p \u2192 S \u2193 Pick the best s \u2208 S \u2193 Score s, update s * (a) The standard use of minimal problems in RANSAC calls for solving and scoring a large number of spurious solutions in S. Sample p \u2193 Pick & Solve Pick a = \u03c3(p) \u2193 Homotopy from a to s \u2193 Score s, update s * (b) We suggest to learn a picking function \u03c3 that finds start parameters a from which the homotopy continuation reaches s.", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 2 .2Figure 2. (a) Problem-solution manifold M projected to the problem space P . (b) Numerical HC method.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "B1Start from every anchor in A. B2 Start from the closest anchor (p 0 , s 0 ) in terms of Euclidean distance. B3 Start from the closest anchor (p 0 , s 0 ) in terms of Mahalanobis distance.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 3 .3Figure 3. (left) The main geometrical constraint. (right) Scranton formulation. Four points Xm, m \u2208 {1, ..., 4} are projected into three cameras C1, C2, C3. The first point X1 projects in the first camera to a point on a vertical line passing through x1,1, with l being distance from x1,1.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 4 .4Figure 4. Percentage of camera pairs from the 2020 RANSAC Tutorial [47] for which the relative pose obtained by RANSAC has rotation and translation error less than 10 \u25cb .", "figure_data": ""}, {"figure_label": "6", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Figure 6 .6Figure 6. Illustration of generating training data and training the classifier.A minimal sample of cameras and points is sampled from an existing 3D model. Then, the sampled geometry is converted to the problem-solution pairs. Every generated problem-solution pair (p, s) is tracked from every anchor (p0, s0). If the correct solution is obtained, problem p is added to the training data, whereby the ID of the anchor (p0, s0) is used as the expected label. Then, the MLP is trained on the generated training data.", "figure_data": ""}, {"figure_label": "58", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "5 Figure 8 .58Figure 8. An example of a 5pt problem after normalization of image coordinates.", "figure_data": ""}, {"figure_label": "88119", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "8 A 8 11 , 9 A8811911,10 A 11,11    ", "figure_data": ""}, {"figure_label": "9", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "Figure 9 .9Figure 9. Code snippet describing our MLP.", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "Number of anchors obtained according to Sec. 4 which are needed to cover 50%, 75%, 90%, 95%, and 100% of n problemsolution pairs. Different values of n are considered. A problem-solution pair is covered by the set of anchors if there is at least one anchor from which the problem-solution pair can be correctly tracked. A track is considered correct if the Euclidean distance from the obtained solution to the ground-truth solution is less than 10 \u22125 .", "figure_data": "."}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "[%] \u00b5t[\u00b5s] t[\u00b5s] \u03c1[%] \u00b5t[\u00b5s] t[\u00b5s] MLP T A 75 29.0 7.6 26.1 19.0 13.5 71.1 MLP T A 90 36.8 10.8 29.3 26.3 16.2 61.6", "figure_data": "5pt problem4pt problemB1, A5047.3 \u221e\u221e44.2 \u221e\u221eB1, A7574.2 \u221e\u221e72.0 \u221e\u221eB1, A9087.7 \u221e\u221e87.9 \u221e\u221eB2, A509.9 11.8 119.5 5.2 16.1 310.5B2, A759.0 12.4 137.8 4.9 16.7 340.9B2, A908.4 12.1 144.5 5.0 16.3 324.5B2, A11.2 327.9 2927.7 9.8 150.1 1531.6B3, A5014.0 12.2 87.35.1 15.9 312.2B3, A7513.4 12.8 95.34.8 17.0 352.7B3, A904.2 19.5 460.2 4.8 19.9 413.5MLP, A50 29.3 15.7 53.5 21.6 19.7 91.3MLP, A75 38.8 15.0 38.7 27.8 20.3 73.0MLP, A90 39.9 14.3 35.8 29.2 19.6 66.9MLP T A 50 17.0 4.626.99.1 8.996.8Table"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "Succ. rate Time inv. Time HC 73% 0.43 \u00b5s 11.80 \u00b5s B. 3.70% 0.77 \u00b5s 11.88 \u00b5s C. 2.29% 0.36 \u00b5s 11.19 \u00b5s D. 1.56% 1.03 \u00b5s 12.18 \u00b5s E. 0.71% 0.68 \u00b5s 10.44 \u00b5s Table5. Evaluation of the normalization for the 5 pt problem. We have generated 4000 problem-solution pairs, normalized them with a given strategy and tracked HC from every p-s pair to every other. We consider strategies from Sec. 17. We measure the success rate, average time of the normalization and of HC. The track is considered successful if the squared Euclidean distance from the obtained solution to the ground-truth is less than 10 \u22125 . .93 \u00b5s 18.46 \u00b5s", "figure_data": "No inv.0.53%014.25 \u00b5sA. 3.Strategy Line strategy Succ. rate Time inv. Time HCNo inv.-0.21%022.11 \u00b5sA.a)1.44% 0.50 \u00b5s 17.82 \u00b5sB.a)1.44% 1.16 \u00b5s 17.40 \u00b5sC.a)0.80% 0.82 \u00b5s 19.57 \u00b5sC.b)0.32% 0.78 \u00b5s 17.37 \u00b5sD.a)0.61% 1.39 \u00b5s 20.13 \u00b5sE.a)0.37% 1.01 \u00b5s 20.43 \u00b5sE. 0.27% 0Table b)"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "D 5pt where A 5pt 50 of 8 anchors covers 50% of problems in D 5pt , A 5pt 75 of 26 anchors covers 75% of problems in D 5pt , A 5pt 90 of 70 anchors covers 90% of problems in D 5pt and A 5pt 100 of 465 anchors covers 100% of problems in D 5pt . Data sets, A Scr 50 , of 16 anchors, A Scr 75 , of 50 anchors, A Scr 90 , of 134 anchors and A Scr 100 , of 1205 anchors, are constructed analagously from A Scr . Test data set V 5pt consists of 60000 p-s pairs constructed as above from the ETH 3D dataset \"Delivery area\" and \"Facade\". Succ. rate \u00b5 s \u00b1 \u03b4 s [%] / Time \u00b5 t [\u00b5s] All Sols 98.9 \u00b1 0.2/ 1.9 \u00d7 10 5 97.7 \u00b1 0.2 / 15197.1 97.7 \u00b1 0.1 / 5133.7 C-HC, R Sols 56.1 \u00b1 3.3 / 1.2 \u00d7 10 5 55.3 \u00b1 2.6 / 5704.7 54.7 \u00b1 3.2 / 1895.1 C-HC, Fab Sol 12.9 \u00b1 0.9 / 9.8 \u00d7 10 4", "figure_data": "5pt problemSolving techniqueM2 [43]MINUS [20]OURC-HC, 12.0 \u00b1 1.5 / 638.0 13.1 \u00b1 1.4 / 165.8R-HC, R Sols9.9 \u00b1 1.7 / 5.7 \u00d7 10 49.7 \u00b1 1.5 / 647.9 9.7 \u00b1 1.5 / 106.8R-HC, Fab Sol3.4\u00b1 1.3 / 4.4 \u00d7 10 42.7 \u00b1 0.8 / 67.62.7 \u00b1 0.8 / 11.1Newton, Fab Sol4.0\u00b1 0.6 / 1.4 \u00d7 10 44.0 \u00b1 0.7 / 8.54.0 \u00b1 0.7 / 1.3Succ. rate \u00b5 s \u00b1 \u03b4 s [%] / Time \u00b5 t [\u00b5s]ScrantonSolving techniqueMINUS [20]OURC-HC, All Sols95.5 \u00b1 2.6 / 608332.0 95.7 \u00b1 2.6 / 187364.5C-HC, R Sols22.7 \u00b1 1.6 / 47961.4 22.5 \u00b1 1.7 / 14905.1C-HC, Fab Sol3.5 \u00b1 0.7 / 1280.73.3 \u00b1 0.9 / 405.7R-HC, R Sols7.5 \u00b1 1.2 / 2548.47.6 \u00b1 1.2 / 484.4R-HC, Fab Sol1.2 \u00b1 0.3 / 70.21.2 \u00b1 0.3 / 14.1Newton, Fab Sol1.9 \u00b1 0.6 / 8.62.0 \u00b1 0.4 / 1.4sets A 5pt 50 , A 5pt 75 , A 5pt 90 , A 5pt 100 are selected by the procedure described in Sec. 4 such that A 5pt 50 \u2282 A 5pt 75 \u2282 A 5pt 90 \u2282 A 5pt 100 \u2282"}, {"figure_label": "8", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "Study of methods for starting problem selection and tracking for Scranton problem. The strategies are evaluated on datasets Deilvery area and Facade. Tracking methods: 'N3': Newton method with 3 steps, 'N15': Newton method with 15 steps (this number of steps maximizes the efficient time), 'HC': Homotopy Continuation as described in Sec 6. Problem selection methods: 'B1': Tracks always from the same anchor. 'MLP': selecting the starting problem as the one with the highest score given by the MLP.", "figure_data": "Method\u03c1[%] \u00b5 t [\u00b5s] t [\u00b5s]N3 + B10.01 1.73 15159.7N3 + MLP 0.12 8.2 6811.2N15 + B12.12.6119.7N15 + MLP 10.6 10.6 100.0HC + B14.2 18.7 442.1HC + MLP 26.3 16.261.6All pairsMLPResult [%]5 pt 4 pt 5pt 4ptFabricated sol.3.64 1.49 38.8 29.21 rel. pose correct-0.74-4.53Other meaningful 9.50 13.43 31.6 34.2Sol. with det -10.00 0.00 0.00 0.00Sol. with zeros0.03 1.53 0.01 0.52Negative sol.0.52 10.86 0.83 8.54Failed track86.31 71.94 28.8 23.0Table"}, {"figure_label": "1112", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "Study of different MLP sizes. The strategies are evaluated on datasets Deilvery area and Facade. Scranton problem, MLP+HC, A75. Rows correspond to different sizes of hidden MLP layers. Number of tracks study. The strategies are evaluated on datasets Deilvery area and Facade. Scranton problem, MLP+HC, A90. Rows correspond to different numbers of tracks conducted after the MLP is evaluated.", "figure_data": "Layer size \u03c1[%] \u00b5 t [\u00b5s] t [\u00b5s]10027.8 20.3 73.120031.3 30.8 98.350034.7 79.0 227.6# Tracks \u03c1[%] \u00b5 t [\u00b5s] t [\u00b5s]129.2 19.6 67.0237.2 33.3 89.6342.2 45.0 106.8445.9 60.8 132.6856.4 118.1 209.51667.9 245.3 361.5"}], "formulas": [{"formula_id": "formula_0", "formula_text": "p S = \u03c0 \u22121 (p) s a = (p 0 , s 0 ) solve (minimal problem) pick (anchor) pick (s \u2208 S) solve (homotopy)", "formula_coordinates": [5.0, 188.41, 94.61, 218.41, 51.01]}, {"formula_id": "formula_1", "formula_text": "1. Select 3 cameras C i , C j , C k \u2208 C 2. Select 4 points X l , X m , X n , X o \u2208 X \u2236 (X a , C b ) \u2208 I \u2200a \u2208 {l, m, n, o}, b \u2208 {i, j, k} 3.", "formula_coordinates": [5.0, 62.57, 511.83, 337.52, 36.85]}, {"formula_id": "formula_2", "formula_text": "C i C j X m X k x k,i x m,i x k,j x m,j \u03bb m,i v m,i \u03bb m,j v m,j C 1 C 3 C 2 X m X 1 x m,1 x m,3 x m,2 x 1,1 l \u03bb m,1 v m,1", "formula_coordinates": [9.0, 65.11, 75.32, 464.5, 150.55]}, {"formula_id": "formula_3", "formula_text": "k,i v k,i \u2212 \u03bb m,i v m,i 2 = \u03bb k,j v k,j \u2212 \u03bb m,j v m,j2", "formula_coordinates": [9.0, 336.68, 524.12, 185.7, 11.42]}, {"formula_id": "formula_4", "formula_text": "\u03bb k,1 v k,1 \u2212 \u03bb m,1 v m,1 2 = \u03bb k,2 v k,2 \u2212 \u03bb m,2 v m,22", "formula_coordinates": [9.0, 202.05, 620.92, 195.05, 11.92]}, {"formula_id": "formula_5", "formula_text": "\u03bb k,i v k,i \u2212 \u03bb m,i v m,i 2 = \u03bb k,j v k,j \u2212 \u03bb m,j v m,j 2(2)", "formula_coordinates": [10.0, 204.9, 192.44, 340.21, 11.92]}, {"formula_id": "formula_6", "formula_text": "v 1,1 + l [0; 1; 0] \u2212 \u03bb m,1 v m,1 2 = \u03bb 1,2 v 1,2 \u2212 \u03bb m,2 v m,22", "formula_coordinates": [10.0, 188.35, 284.1, 222.44, 11.92]}, {"formula_id": "formula_7", "formula_text": "\u2220([x 1,1 ; 1], [0, 0, 1]) \u2265 \u2220([x 2,1 ; 1], [0, 0, 1]) \u2265 \u2220([x 3,1 ; 1], [0, 0, 1]).", "formula_coordinates": [10.0, 50.11, 508.81, 510.33, 21.61]}, {"formula_id": "formula_8", "formula_text": "X 1 \u2212 X 2 2 = \u03bb 1 u 1 \u2212 \u03bb 2 u 2 2 X 2 \u2212 X 3 2 = \u03bb 2 u 2 \u2212 \u03bb 3 u 3 2 X 3 \u2212 X 1 2 = \u03bb 3 u 3 \u2212 \u03bb 1 u 1 2", "formula_coordinates": [15.0, 230.48, 377.44, 118.26, 41.81]}, {"formula_id": "formula_9", "formula_text": "{X 1 X (3) 1 = 1} \u2245 R 2 .", "formula_coordinates": [16.0, 434.28, 146.92, 93.11, 15.48]}, {"formula_id": "formula_10", "formula_text": "\u03bb i,j = \u03bb i,j (X, C) = R j (3,\u2236) X i + t (3) j", "formula_coordinates": [16.0, 225.57, 180.1, 143.58, 15.6]}, {"formula_id": "formula_11", "formula_text": "\u03a8 5pt \u2236 R 2 \u00d7 (R 3 ) 4 \u00d7 SE R (3) \u2192 R 2 10 \u00d7 R 9 (X , C) \u21a6 (x, \u03bb)", "formula_coordinates": [16.0, 199.66, 227.74, 195.4, 26.01]}, {"formula_id": "formula_12", "formula_text": "x = \u03bb \u22121 i,j (R j X i + t j ) (1\u22362) i=1,...,5; j=1,2; (i,j)\u2260(1,1) .(3)", "formula_coordinates": [16.0, 194.66, 271.07, 350.45, 19.22]}, {"formula_id": "formula_13", "formula_text": "\u03a8 Scr \u2236 R 2 \u00d7 (R 3 ) 3 \u00d7 R \u00d7 (SE R (3)) 2 \u2192 R 2 12 \u00d7 R 12 ((X, l) , C) \u21a6 (x, (\u03bb, l))", "formula_coordinates": [16.0, 180.32, 473.47, 234.08, 26.01]}, {"formula_id": "formula_14", "formula_text": "x 1,1 = (X i + t j \u2212 le 2 ) (1\u22362) .", "formula_coordinates": [16.0, 243.4, 516.04, 108.43, 14.18]}, {"formula_id": "formula_15", "formula_text": "M = M Scr is the set of smooth points in the semialgebraic set im(\u03a8 Scr ) \u2229 (R >0 ) 11 \u00d7 R \u00d7 R 2 12 .", "formula_coordinates": [16.0, 50.11, 551.5, 408.74, 14.55]}, {"formula_id": "formula_16", "formula_text": "A (v) i,j,k = X i,v \u2212 X 1,v X j,v \u2212 X 1,v X k,v \u2212 X 1,v . Thus, det A (v)", "formula_coordinates": [16.0, 50.11, 639.48, 358.49, 37.15]}, {"formula_id": "formula_17", "formula_text": "R 2 (x, \u03bb) = A (2) 2,3,4 A (1) 2,3,4 \u22121 (4)", "formula_coordinates": [16.0, 239.34, 695.74, 305.77, 18.8]}, {"formula_id": "formula_18", "formula_text": ")5", "formula_coordinates": [17.0, 537.37, 260.98, 7.74, 8.64]}, {"formula_id": "formula_19", "formula_text": "t(x, \u03bb) = \u03bb 1,2 v 1,2 \u2212 R(x, \u03bb)\u03bb 1,1 v 1,1 ,", "formula_coordinates": [17.0, 223.62, 373.78, 147.99, 9.65]}, {"formula_id": "formula_20", "formula_text": "2 \u03bb i,j \u03bb i,2 v i,2 2 \u2212 \u03bb i,1 v i,1 2", "formula_coordinates": [17.0, 275.99, 414.88, 91.54, 25.49]}, {"formula_id": "formula_21", "formula_text": "v 1,1 + l [0; 1; 0] \u2212 \u03bb m,1 v m,1 2 = \u03bb 1,2 v 1,2 \u2212 \u03bb m,2 v m,22", "formula_coordinates": [17.0, 188.35, 549.37, 222.44, 11.92]}, {"formula_id": "formula_22", "formula_text": "v 1,1 + l [0; 1; 0] 2 = \u03bb 1,2 v 1,2 2 \u03bb 1,2 v 1,2 2 = \u03bb 1,3 v 1,3 2", "formula_coordinates": [17.0, 236.73, 604.29, 125.7, 28.29]}, {"formula_id": "formula_23", "formula_text": "must (p(t), s(t)) for all t \u2208 [0, 1]. Thus, any polynomial g(p, s) vanishing on M satisfies g(p(t), s(t)) = 0 for all t \u2208 [0, 1].", "formula_coordinates": [18.0, 50.11, 562.84, 495.0, 9.3]}, {"formula_id": "formula_24", "formula_text": "\u23a1 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a3 A0,3 0 0 0 A0,4 A0,5 0 0 0 0 A1,1 0 0 A1,4 0 A1,6 0 0 A2,0 A2,1 0 A2,3 0 0 A2,6 0 0 0 0 A3,2 0 A3,4 0 0 A3,7 0 A4,0 0 A4,2 0 0 A4,5 0 A4,7 0 0 A5,1 A5,2 0 0 0 A5,6 A5,7 0 0 0 0 A6,3 A6,4 0 0 0 A6,8 A7,0 0 0 A7,3 0 A7,5 0 0 A7,8 0 A8,1 0 A8,3 0 0 A8,6 0 A8,8 \u23a4 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a6 (6) \u23a1 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a3 A 0,0 0 0 A 0,3 A 0,4 0 0 0 0 0 0 0 0 A 1,1 0 A 1,3 0 A 1,5 0 0 0 0 0 0 A 2,0 A 2,1 0 0 A 2,4 A 2,5 0 0 0 0 0 0 0 0 A 3,2 A 3,3 0 0 A 3,6 0 0 0 0 0 A 4,0 0 A 4,2 0 A 4,4 0 A 4,6 0 0 0 0 0 0 A 5,1 A 5,2 0 0 A 5,5 A 5,6 0 0 0 0 0 A 6,0 0 0 0 0 0 0 A 6,7 A 6,8 0 0 0 0 A 7,1 0 0 0 0 0 A 7,7 0 A 7,9 0 0 A 8,0 A 8,1 0 0 0 0 0 0 A 8,", "formula_coordinates": [19.0, 179.96, 180.9, 365.16, 168.15]}, {"formula_id": "formula_25", "formula_text": "\u23a4 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a6(7)", "formula_coordinates": [19.0, 410.29, 261.32, 134.82, 87.73]}, {"formula_id": "formula_26", "formula_text": "x (1) 1,1 >, x(1)", "formula_coordinates": [19.0, 479.54, 479.68, 46.94, 15.48]}], "doi": ""}