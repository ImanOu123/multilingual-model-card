{"title": "Flexible Modeling and Multitask Learning using Differentiable Tree Ensembles", "authors": "Shibal Ibrahim; Hussein Hazimeh; Rahul Mazumder", "pub_date": "2022-05-19", "abstract": "Decision tree ensembles are widely used and competitive learning models. Despite their success, popular toolkits for learning tree ensembles have limited modeling capabilities. For instance, these toolkits support a limited number of loss functions and are restricted to single task learning. We propose a flexible framework for learning tree ensembles, which goes beyond existing toolkits to support arbitrary loss functions, missing responses, and multi-task learning. Our framework builds on differentiable (a.k.a. soft) tree ensembles, which can be trained using first-order methods. However, unlike classical trees, differentiable trees are difficult to scale. We therefore propose a novel tensor-based formulation of differentiable trees that allows for efficient vectorization on GPUs. We perform experiments on a collection of 28 real open-source and proprietary datasets, which demonstrate that our framework can lead to 100x more compact and 23% more expressive tree ensembles than those by popular toolkits.", "sections": [{"heading": "Introduction", "text": "Decision tree ensembles are popular models that have proven successful in various machine learning applications and competitions [Erdman andBates, 2016, Chen and. Besides their competitive performance, decision trees are appealing in practice because of their interpretability, robustness to outliers, and ease of tuning [Hastie et al., 2009]. Training a decision tree naturally requires solving a combinatorial optimization problem, which is difficult to scale. In practice, greedy heuristics are commonly used to get feasible solutions to the combinatorial problem; for example CART [Breiman et al., 1984], C5.0 [Quinlan, 1993], and OC1 [Murthy et al., 1994]. By building on these heuristics, highly scalable toolkits for learning tree ensembles have been developed, e.g., XGBoost  and LightGBM [Ke et al., 2017]. These toolkits are considered a defacto standard for training tree ensembles and have demonstrated success in various domains.\nDespite their success, popular toolkits for learning tree ensembles lack modeling flexibility. For example, these toolkits support a limited set of loss functions, which may not be suitable for the application at hand. Moreover, these toolkits are limited to single task learning. In many modern applications, it is desired to solve multiple, related machine learning tasks. In such applications, multi-task learning, i.e., learning tasks simultaneously, may be a more appropriate choice than single task learning [Chapelle et al., 2010, Kumar and Daum\u00e9, 2012, Han and Zhang, 2015, Crawshaw, 2020. If the tasks are sufficiently related, multi-task learning can boost predictive performance by leveraging task relationships during training.\nIn this paper, we propose a flexible modeling framework for training tree ensembles that addresses the aforementioned limitations. Specifically, our framework allows for training tree ensembles with any differentiable loss function, enabling the user to seamlessly experiment with different loss functions and select what is suitable for the application. Moreover, our framework equips tree ensembles with the ability to perform multi-task learning. To achieve this flexibility, we build up on soft trees [Kontschieder et al., 2015, Hazimeh et al., 2020, which are differentiable trees that can be trained with first-order (stochastic) gradient methods. Previously, soft tree ensembles have been predominantly explored for classification tasks with cross-entropy loss. In such cases, they were found to lead to more expressive and compact tree ensembles [Hazimeh et al., 2020]. However, the state-of-the-art toolkits e.g., TEL [Hazimeh et al., 2020], are slow as they only support CPU training and are difficult to customize. Our proposed tree ensemble learning framework supports a collection of loss functions such as classification, regression, Poisson regression, zero-inflation models, overdispersed distributions, multitask learning and has seamless support for others -the user can modify the loss function with a single line. We show loss customization can lead to a significant reduction in ensemble sizes (up to 20x). We also propose a careful tensor-based formulation of differentiable tree ensembles, which leads to more efficient training (10x) on CPUs as well as support .\nWe propose a novel extension for multi-task learning with tree ensembles -this may not be readily accommodated within popular gradient boosting toolkits. Our model can impose both 'soft' information sharing across tasks-soft information sharing is not possible with popular multi-task tree ensemble toolkits e.g., RF Breiman [2001], GRF Athey et al. [2019]. Our proposed framework leads to 23% performance gain (on average) and up to a 100x reduction in tree ensemble sizes on real-world datasets, offering a promising alternative approach for learning tree ensembles.\nContributions Our contributions can be summarized as follows. (i) We propose a flexible framework for training differentiable tree ensembles with seamless support for new loss functions. (ii) We introduce a novel, tensor-based formulation for differentiable tree ensembles that allows for efficient training on GPUs. Existing toolkits e.g., TEL Hazimeh et al. [2020], only support CPU training. (iii) We extend differentiable tree ensembles to multi-task learning settings by introducing a new regularizer that allows for soft parameter sharing across tasks. (iv) We introduce a new toolkit (based on Tensorflow 2.0) and perform experiments on a collection of 28 open-source and real-world datasets, demonstrating that our framework can lead to 100x more compact ensembles and up to 23% improvement in out-of-sample performance, compared to tree ensembles learnt by popular toolkits such as XGBoost .", "publication_ref": ["b0", "b2", "b3", "b4", "b5", "b6", "b7", "b8", "b9", "b10", "b11", "b12", "b12", "b12"], "figure_ref": [], "table_ref": []}, {"heading": "Related Work", "text": "Learning binary trees has been traditionally done in three ways. The first approach relies on greedy construction and/or optimization via methods such as CART [Breiman et al., 1984], C5.0 [Quinlan, 1993], OC1 [Murthy et al., 1994], TAO [Carreira-Perpinan and Tavallali, 2018]. These methods optimize a criterion at the split nodes based on the samples routed to each of the nodes. The second approach considers probabilistic relaxations/decisions at the split nodes and performs end-to-end learning with first order methods [Irsoy et al., 2012, Frosst and Hinton, 2017, Lay et al., 2018. The third approach considers optimal trees with mixed integer formulations and jointly optimize over all discrete/continuous parameters with MIP solvers [Bennett, 1992, Bennett and Blue, 1996, Bertsimas and Dunn, 2017, Zhu et al., 2020. Each of the three approaches have their pros and cons. The first approach is highly scalable because of greedy heuristics. In many cases, the tree construction uses a splitting criterion different from the optimization objective [Breiman et al., 1984] (e.g., gini criterion when performing classification) possibly resulting in sub-optimal performance. The second approach is also scalable but principled pruning in probabilistic trees remains an open research problem. The third approach scales to small datasets with samples N \u223c 10 4 , features p \u223c 10 and tree depths d \u223c 4.\nJointly optimizing over an ensemble of classical decision trees is a hard combinatorial optimization problem [Hyafil and Rivest, 1976]. Historically, tree ensembles have been trained with two methods. The first method relies on greedy heuristics with bagging/boosting: where individual trees are trained with CART on bootstrapped samples of the data e.g., random forests (RF) [Breiman, 2001] and its variants [Geurts et al., 2006, Athey et al., 2019; or sequentially/adaptively trained with gradient boosting: Gradient Boosting Decision Trees [Hastie et al., 2009] and efficient variants , Ke et al., 2017, Prokhorenkova et al., 2018, Schapire and Freund, 2012. Despite the success of ensemble methods, interesting challenges remain: (i) RF tend to under-perform gradient boosting methods such as XGBoost . (ii) The tree ensembles are typically very large, making them a complex and hardly interpretable decision structure. Recent work by Carreira-Perpinan andTavallali [2018], Zharmagambetov andCarreira-Perpi\u00f1\u00e1n [2020] improve RF with local search methods via alternating minimization. However, their implementation is not open-source. (iii) Open-source APIs for gradient boosting are limited in terms of flexibility. They lack support for multi-task learning, handling missing responses or catering to customized loss functions. Modifying these APIs require significant effort and research for custom applications.\nThe alternative approach for tree ensemble learning extends probabilistic/differentiable trees and performs end-to-end learning [Kontschieder et al., 2015, Hazimeh et al., 2020. These works build upon the idea of hierarchical mixture of experts introduced by [Jordan and Jacobs, 1994] and further developed by [Irsoy et al., 2012, Tanno et al., 2019, Frosst and Hinton, 2017 for greedy construction of trees. Some of these works [Kontschieder et al., 2015, Hazimeh et al., 2020 propose using differentiable trees as an output layer in a cascaded neural network for combining feature representation learning along with tree ensemble learning for classification. We focus on learning tree (ensembles) with hyperplane splits and constant leaf nodes-this allows us to expand the scope of trees to flexible loss functions, and develop specialized implementations that can be more efficient. One might argue that probabilistic trees are harder to interpret and suffer from slower inference as a sample must follow each root-leaf path, lacking conditional computation present in classical decision trees. However, Hazimeh et al. [2020] proposed a principled way to get conditional inference in probabilistic trees by introducing a new activation function; this allows for routing samples through small parts of the tree similar to classical decision trees. We refer the reader to Section 6.1 for a study on a single tree and highlight that the a soft tree with hyperplane splits and conditional inference has similar interpretability as that of a classical tree with hyperplane splits -see Figure 2. Additionally, a soft tree can lead to smaller optimal depths-see Supplemental Section S1.1.\nEnd-to-end learning with differentiable tree ensembles appears to have several advantages. (i) They are easy to setup with public deep learning API e.g., Tensorflow [Abadi et al., 2015], PyTorch [Paszke et al., 2019]. We demonstrate that with a careful implementation, the tree ensembles can perform efficient GPU-training -this is not possible with earlier toolkits e.g., TEL [Hazimeh et al., 2020]. (ii) Tensorflow-Probability library [Dillon et al., 2017] offers huge flexibility in modeling. For instance, they allow for modeling mixture likelihoods, which can cater to zero-inflated data applications. This makes it possible to combine differentiable tree ensembles with customized losses with minimal effort. (iii) Deep learning APIs e.g., Tensorflow offer great support for handling multi-task loss objectives without a need for specialized algorithm. This makes it convenient to perform multi-task learning with differentiable tree ensembles. (iv) Differentiable trees can lead to more expressive and compact ensembles [Hazimeh et al., 2020]. This can have important implications for interpretability, latency and storage requirements during inference.", "publication_ref": ["b3", "b4", "b5", "b16", "b17", "b18", "b19", "b20", "b21", "b22", "b3", "b23", "b13", "b24", "b14", "b2", "b6", "b25", "b26", "b15", "b11", "b12", "b28", "b16", "b29", "b17", "b11", "b12", "b12", "b30", "b31", "b12", "b32", "b12"], "figure_ref": ["fig_2"], "table_ref": []}, {"heading": "Optimizing Tree Ensembles", "text": "We assume a supervised multi-task learning setting, with input space X \u2286 R p and output space Y \u2286 R k . We learn a mapping f : R p \u2192 R k , from input space X to output space Y, where we parameterize function f with a differentiable tree ensemble. We consider a general optimization framework where the learning objective is to minimize any differentiable function g : R p \u00d7 R k \u2192 R. The framework can accommodate different loss functions arising in different applications and perform end-to-end learning with tree ensembles. We first briefly review differentiable tree ensembles in section 3.1. We later present a careful tensor-based implementation of the tree ensemble in section 3.2 that makes it possible to perform efficient training on both CPUs and GPUs. Next, we outline the need for flexible loss modeling and present some examples that our tree ensemble learning framework supports for learning compact tree ensembles in Sections 4 and 5. Finally, we present a metastudy on a large collection of real-world datasets to validate our framework.\nNotation We summarize our notation used in the paper. For an integer n \u2265 1, let [n] := {1, 2, ...., n}. We let 1 m denote the vector in R m with all coordinates being 1. For matrix B = ((B ij )) \u2208 R M \u00d7N , let the j-th column be denoted by\nB j := [B 1j , B 2j , ..., B M j ] T \u2208 R M for j \u2208 [N ]. A dot product between two vectors u, v \u2208 R m is denoted as u \u2022 v. A dot product between a matrix U \u2208 R m,n and a vector v \u2208 R m is denoted as U \u2022 v = U T v \u2208 R n . A dot product between a tensor U \u2208 R p,m,n and a vector v \u2208 R m is denoted as U \u2022 v = U T v \u2208 R p,n\nwhere the transpose operation of a tensor U T \u2208 R p,n,m permutes the last two dimensions of the tensor.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Preliminaries and Setup", "text": "We learn an ensemble of m differentiable trees. Let f j be the jth tree in the ensemble. For easier exposition, we consider a single-task regression or classification setting-see Section 5 for an extension to the multi-task setting. In a regression setting k = 1, while in multi-class classification setting k = C, where C is the number of classes. For an input feature-vector x \u2208 R p , we learn an additive model with the output being sum over outputs of all the trees:\nf (x) = m j=1 f j (x).\n(1)\nThe output, f (x), is a vector in R k containing raw predictions. For multiclass classification, mapping from raw predictions to Y is done by applying a softmax function on the vector f (x) and returning the class with the highest probability. Next, we introduce the key building block of the approach: the differentiable decision tree.\nDifferentiable decision trees for modelling f j Classical decision trees perform hard sample routing, i.e., a sample is routed to exactly one child at every splitting node. Hard sample routing introduces discontinuities in the loss function, making trees unamenable to continuous optimization. Therefore, trees are usually built in a greedy fashion. In this section, we first introduce a single soft tree proposed by Jordan and Jacobs [1994], which is utilized in Irsoy et al. [2012], Frosst and Hinton [2017], Blanquero et al. [2021] and extended to soft tree ensembles in Kontschieder et al. [2015], Hehn et al. [2019], Hazimeh et al. [2020]. A soft tree is a variant of a decision tree that performs soft routing, where every internal node can route the sample to the left and right simultaneously, with different proportions. This routing mechanism makes soft trees differentiable, so learning can be done using gradient-based methods. Notably, Hazimeh et al. [2020] introduced a new activation function for soft trees that allowed for conditional computation while preserving differentiability.\nLet us fix some j \u2208 [m] and consider a single tree f j in the additive model ( 1). Recall that f j takes an input sample and returns an output vector (logit), i.e., f j : X \u2208 R p \u2192 R k . Moreover, we assume that f j is a perfect binary tree with depth d. We use the sets I j and L j to denote the internal (split) nodes and the leaves of the tree, respectively. For any node i \u2208 I j \u222a L j , we define A j (i) as its set of ancestors and use the notation x \u2192 i for the event that a sample x \u2208 R p reaches i.\nRouting Internal (split) nodes in a differentiable tree perform soft routing, where a sample is routed left and right with different proportions. This soft routing can be viewed as a probabilistic model. Although the sample routing is formulated with a probabilistic model, the final prediction of the tree f is a deterministic function as it assumes an expectation over the leaf predictions. Classical decision trees are modeled with either axis-aligned splits [Breiman et al., 1984, Quinlan, 1993 or hyperplane (a.k.a. oblique) splits [Murthy et al., 1994]. Soft trees are based on hyperplane splits, where the routing decisions rely on a linear combination of the features. Particularly, each internal node i \u2208 I j is associated with a trainable weight vector w j i \u2208 R p that defines the node's hyperplane split. Let S : R \u2192 [0, 1] be an activation function. Given a sample x \u2208 R p , the probability that internal node i routes x to the left is defined by S(w j i \u2022 x). Now we discuss how to model the probability that x reaches a certain leaf l.\nLet [l i] (resp. [i l]\n) denote the event that leaf l belongs to the left (resp. right) subtree of node i \u2208 I j . Assuming that the routing decision made at each internal node in the tree is independent of the other nodes, the probability that x reaches l is given by:\nP j ({x \u2192 l}) = i\u2208A(l) r j i,l (x),(2)\nwhere r j i,l (x) is the probability of node i routing x towards the subtree containing leaf l, i.e., r j i,l (x) := S(w\nj i \u2022 x)1[l i] (1 \u2212 S(w j i \u2022 x))1[i l]\n. Next, we define how the root-to-leaf probabilities in (2) can be used to make the final prediction of the tree.\nPrediction As with classical decision trees, we assume that each leaf stores a weight vector o j l \u2208 R k (learned during training). Note that, during a forward pass, o j l is a constant vector, meaning that it is not a function of the input sample(s). For a sample x \u2208 R p , we define the prediction of the tree as the expected value of the leaf outputs, i.e.,\nf j (x) = l\u2208L P j ({x \u2192 l})o j l .(3)\nActivation Function In soft routing, the internal nodes use an activation function S in order to compute the routing probabilities. The logistic (a.k.a. sigmoid) function is the common choice for S in the literature on soft trees (see Jordan and Jacobs [1994], Kontschieder et al. [2015], Frosst and Hinton [2017], Tanno et al. [2019], Hehn et al. [2019]). While the logistic function can output arbitrarily small values, it cannot output an exact zero. This implies that any sample x will reach every node in the tree with a positive probability (as evident from ( 2)). Thus, computing the output of the tree in (3) will require computation over every node in the tree, an operation which is exponential in tree depth. Hazimeh et al. [2020] proposed a smooth-step activation function, which can output exact zeros and ones, thus allowing for true conditional computation. Furthermore, the smooth-step function allows efficient forward and backward propagation algorithms.", "publication_ref": ["b28", "b17", "b33", "b11", "b34", "b12", "b12", "b3", "b4", "b5", "b28", "b11", "b17", "b29", "b34", "b12"], "figure_ref": [], "table_ref": []}, {"heading": "Efficient Tensor Formulation", "text": "Current differentiable tree ensemble proposals and toolkits, for example deep neural decision forests 1 [Kontschieder et al., 2015] and TEL [Hazimeh et al., 2020]  We propose to model the internal nodes in the trees across the ensemble jointly as a \"supernodes\". In particular, an internal node i \u2208 I j at depth d in all trees can be condensed together into a supernode i \u2208 I. We define a learnable weight matrix W i \u2208 R p,m , where each j-th column of the weight matrix contains the learnable weight vector w j i of the original j-th tree in the ensemble. Similarly, the leaf nodes are defined to store a learnable weight matrix O l \u2208 R m,k , where each j-th row contains the learnable weight vector o j l in the original j-th tree in the ensemble. The prediction of the tree with supernodes can be written as\nf (x) = \uf8eb \uf8ed l\u2208L O l i\u2208A(l) R i,l \uf8f6 \uf8f8 \u2022 1 m (4)\nwhere denotes the element-wise product,\nR i,l = S(W i \u2022x)1[l i] (1\u2212S(W i \u2022x))1[i l] \u2208 R m,1\nand the activation function S is applied element-wise. This formulation of tree ensembles via supernodes allows for sharing of information across tasks via tensor formulation in multi-task learning -see Section 5 for more details.", "publication_ref": ["b11", "b12"], "figure_ref": [], "table_ref": []}, {"heading": "Toolkit", "text": "Our tree ensemble learning toolkit is built in Tensorflow (TF) 2.0 and integrates with Tensorflow-Probability. The toolkit allows the user to write a custom loss function, and TF provides automatic differentiation. Popular packages, such as XGBoost, require users to provide first/second order derivatives. In addition to writing a custom loss, the user can select from a wide range of predefined loss and likelihood functions from Tensorflow-Probability.  [Barron, 2019] can also be handled by our tree ensemble learning toolkit. To demonstrate the flexibility of our framework, we deeply investigate two specific examples: zero-inflated Poisson and negative binomial regression. These cannot be handled by the popular gradient boosting APIs such as XGBoost , LightGBM [Ke et al., 2017].", "publication_ref": ["b37", "b6"], "figure_ref": [], "table_ref": []}, {"heading": "Zero-inflated Poisson Regression", "text": "Zero-inflation occurs in many applications, e.g., understanding alcohol and drug abuse in young adults Jacobs et al. [2021], characterizing undercoverage and overcoverage to gauge the on-going quality of the census frames [Young et al., 2017], studying popularity of news items on different social media platforms Moniz and Torgo [2018], financial services applications Lee [2020] etc. Despite the prevalence of these applications, there has been limited work on building decision treebased approaches for zero-inflated data perhaps due to a lack of support public APIs. Therefore, practitioners either resort to Poisson regression with trees or simpler linear models to handle zero-inflated responses. A Poisson model can lead to sub-optimal performance due to the limiting equidispersion constraint (mean equals the variance).\nOthers take a two-stage approach [Cameron and Trivedi, 2013], where a classification model distinguishes the zero and non-zero and a second model is used to model the non-zero responses. This can be sup-optimal as errors in the first model can deteriorate the performance of the second model. We employ a more well-grounded approach by formulating the joint mixture model, where one part of the model tries to learn the mixture proportions (zero vs non-zero) and the other part models the actual non-zero responses. Such a mixture model permits a differentiable loss function when both components of the model are parameterized with differentiable tree ensembles and can be optimized with gradient descent method in an end-to-end fashion without the need for a custom solver. We provide an extensive study with our framework on small to large-scale real world zero-inflated datasets and demonstrate that such flexibility in distribution modeling can lead to significantly more compact and expressive tree ensembles. This has large implications for faster inference, storage requirements and interpretability.\nWe briefly review Poisson regression and then dive into zero-inflated Poisson models.\nPoisson regression stems from the generalized linear model (GLM) framework for modeling a response variable in the exponential family of distributions. In general, GLM uses a link function to provide the relationship between the linear predictors, x and the conditional mean of the density function: \ng[E(y|x)] = \u03b2 \u2022 x,(5)\nlog(\u00b5 n |x n ) = f (x n ; W, O). (6\n)\nwhere f is parameterized with a tree ensemble as in (1) and W, O are the learnable parameters in the supernodes and the leaves of the tree ensemble. When a count data has excess zeros, the equi-dispersion assumption of the Poisson is violated. The Poisson model is not an appropriate model for this situation anymore. Lambert [1992] proposed zero-inflated-Poisson (ZIP) models that address the mixture of excess zeros and Poisson count process. The mixture is indicated by the latent binary variable d n using a logit model and the density for the Poisson count given by the log-linear model. Thus,\ny n = 0, if d n = 0 y * n , if d n = 1 (7)\nwhere the latent indicator d n \u223c Bernoulli(\u03c0 n ) with \u03c0 n = P (d n = 1) and y * n \u223c P oisson(\u00b5 n ). The mixture yields the marginal probability mass function of the observed y n given as:\nZIP (y n |\u00b5 n , \u03c0 n ) = (1 \u2212 \u03c0 n ) + \u03c0 n e \u2212\u00b5n , if y n = 0 \u03c0 n e \u2212\u00b5n \u00b5 yn n /y n !, if y n = 1, 2, \u2022 \u2022 \u2022 (8)\nwhere \u00b5 n and \u03c0 n are modeled by\nlog \u03c0 n 1 \u2212 \u03c0 n |x n = f (x n ; Z, U ) (9) log(\u00b5 n |x n ) = f (x n ; W, O). (10\n)\nwhere Z, U are the learnable parameters in the splitting internal supernodes and the leaves of the tree ensemble for the logit model for \u03c0 n and W, O are the learnable parameters in the supernodes and the leaves of the tree ensemble for the log-tree model for \u00b5 n respectively. The likelihood function for this ZIP model is given by\nL(y n , f (x n )) = yn=0 (1 \u2212 \u03c0 n ) + \u03c0 n e \u2212\u00b5n yn>0\n\u03c0 n e \u2212\u00b5n \u00b5 yn n /y n ! ( 11)\nwhere \u03bb n = e f (xn;W,O) and \u03c0 n = e f (xn,Z;U ) /(1 + e f (xn;Z,U ) ).Such a model can be overparameterized and we observed that sharing the learnable parameters Z = W in the splitting internal supernodes across the log-mean and logit models can lead to better out-of-sample performance -see Section 6 for a thorough evaluation on real-world datasets.\nNegative Binomial Regression An alternative distribution to zero-inflation modeling that can cater to over-dispersion in the responses is Negative Binomial (NB) distribution. A negative binomial distribution for a random variable y with a nonnegative mean \u00b5 \u2208 R + and dispersion parameters \u03c6 \u2208 R + is given by:\nN B(y|\u00b5, \u03c6) = y + \u03c6 \u2212 1 y \u00b5 \u00b5 + \u03c6 y \u03c6 \u00b5 + \u03c6 \u03c6 (12)\nThe mean and variance of a random variable y \u223c N B(y|\u00b5, \u03c6) are E[y] = \u00b5 and Var[y] = \u00b5 + \u00b5 2 /\u03c6. Recall that Poisson(\u00b5) has variance \u00b5, so \u00b5 2 /\u03c6 > 0 is the additional variance of the negative binomial above that of the Poisson with mean \u00b5. So the inverse of parameter \u03c6 controls the overdispersion, scaled by the square of the mean, \u00b5 2 .\nWhen the responses y n (for n \u2208 [N ]) are i.i.d, and follow NB distribution conditioned on x n 's, we can use the log(.) as a link function to parameterize the log-mean and log-dispersion as linear functions of the covariates x n . In our parameterization with Tree Ensembles, we model them as given by:\nlog(\u00b5 n |x n ) = f (x n ; W, O) (13) log (\u03c6 n |x n ) = f (x n ; Z, U ). (14\n)\nwhere Z, U are the learnable parameters in the supernodes and the leaves of the tree ensemble for the log-mean and W, O are the learnable parameters in the supernodes and the leaves of the tree ensemble for the log-dispersion model for \u03c6 n respectively. Such a model can be overparameterized and we observed that sharing the learnable parameters Z = W in the splitting internal supernodes across the log-mean and log-dispersion models can lead to better out-of-sample performance. See Section 6.4 for empirical validation on a large-scale dataset.", "publication_ref": ["b38", "b39", "b40", "b41", "b42"], "figure_ref": [], "table_ref": []}, {"heading": "Multi-task Learning with Tree Ensembles", "text": "Multi-task Learning (MTL) aims to learn multiple tasks simultaneously by using a shared model. Unlike single task learning, MTL can achieve better generalization performance through exploiting task relationships [Caruana, 1997, Chapelle et al., 2010.\nOne key problem in MTL is how to share model parameters between tasks [Ruder, 2017]. For instance, sharing parameters between unrelated tasks can potentially degrade performance. MTL approaches for classical decision trees approaches e.g., RF [Linusson, 2013], GRF [Athey et al., 2019] have shared weights at the splitting nodes across the tasks. Only the leaf weights are task specific. However this can be limiting in terms of performance, despite easier interpretability associated with the same split nodes across tasks.\nTo perform flexible multi-task learning, we extend our formulation in Section 3.2 by using task-specific nodes in the tree ensemble. We consider T tasks. For easier exposition, we consider tasks of the same kind: multilabel classification or multi-task regression. For multilabel classification, each task is assumed to have same number of classes (with k = C) for easier exposition -our framework can handle multilabel settings with different number of classes per task. Similarly, for regression settings, k = 1. For multi-task zero-inflated Poisson or negative binomial regression, when two model components need to be estimated, we set k = 2 to predict log-mean and logit components for zero-inflated Poisson and log-mean and log-dispersion components for negative binomial.\nWe define a trainable weight tensor W i \u2208 R T,p,m for supernode i \u2208 I, where each t-th slice of the tensor W i [t, :, :] denotes the trainable weight matrix associated with task t. The prediction in this case is given by\nf (x) = l\u2208L O l i\u2208A(l) R i,l \u2022 1 m (15\n)\nwhere\nO l \u2208 R T,m,k denotes the trainable leaf tensor in leaf l, R i,l = S(W i \u2022 x)1[l i] (1 \u2212 S(W i \u2022 x))1[i l] \u2208 R T,m,1 .\nIn order to share information across the tasks, our framework imposes closeness penalty on the hyperplanes W i in the supernodes across the tasks. This results in an optimization formulation:\nmin W,O t\u2208T x,yt g t (y t , f t (x)) + \u03bb s<t,t\u2208T W :,s,:,: \u2212 W :,t,:,: 2 , (16\n)\nwhere W \u2208 R I,T,m,p denotes all the weights in all the supernodes, O \u2208 R L,m,k denotes all the weights in the leaves, and \u03bb \u2208 [0, \u221e) is a non-negative regularization penalty that controls how close the weights across the tasks are. The model behaves as single-task learning when \u03bb = 0 and complete sharing of information in the splitting nodes when \u03bb \u2192 \u221e. Note that when \u03bb \u2192 \u221e, the weights across the tasks in each of the internal supernodes become the same. This case can be separately handled more efficiently by using the function definition in (4) for f (x) without any closeness regularization in (16).\nOur model can control the level of sharing across the tasks by controlling \u03bb. In practice, we tune over \u03bb \u2208 [1e \u2212 5, 10] and select the optimal based on the validation set. This penalty assumes that the hyperplanes across the tasks should be equally close as we go down the depth of the trees. However this assumption maybe less accurate as we go down the tree. Empirically, we found that decaying \u03bb exponentially as \u03bb/2 d with depth d of the supernodes in the ensemble can achieve better test performance.", "publication_ref": ["b43", "b7", "b44", "b45", "b14"], "figure_ref": [], "table_ref": []}, {"heading": "Experiments", "text": "We study the performance of differentiable tree ensembles in various settings and compare against the relevant state-of-the-art baselines for each setting. The different settings can be summarized as follows: (i) Comparison of a single soft tree with state-of-the-art classical tree method in terms of test performance and depth. We include both axisaligned and oblique classical tree in our comparisons. (ii) Flexible zero-inflation models with tree ensembles. We compare against Poisson regression with tree ensembles and gradient boosting decision trees (GBDT). We consider test Poisson deviance and tree ensemble compactness for model evaluation (iii) We evaluate our proposed multi-task tree ensembles and compare them against multioutput RF, multioutput GRF and single-task GBDT. We consider both fully observed and partially observed responses across tasks. (iv) We also validate our tree ensemble methods with flexible loss functions (zero-inflated Poisson and negative binomial regression) on a large-scale multi-task proprietary dataset.\nModel Implementation Differentiable tree ensembles are implemented in Tensor-Flow 2.0 using Keras interface.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Datasets", "text": "We use 27 open-source regression datasets from various domains (e.g., social media platforms, human behavior, finance). 9 are from Mulan [Xioufis et al., 2016], 2 are from UCI data repository [Dua and Graff, 2017], 12 are from Delve database [Akujuobi and Zhang, 2017] and the 5 remaining are SARCOS [Vijayakumar and Schaal, 2000], Youth Risk Behavior Survey [Jacobs et al., 2021], Block-Group level Census data [US Census Bureau, 2021], and a financial services loss dataset from Kaggle 2 . We also validate our framework on a proprietary multi-task data with millions of samples from a multi-national financial services company.", "publication_ref": ["b46", "b47", "b48", "b38"], "figure_ref": [], "table_ref": []}, {"heading": "Studying a single tree", "text": "In this section, we compare performance and model compactness of a single tree on 12 regression datasets from Delve database: abalone, pumadyn-family, comp-activ (cpu, cpuSmall) and concrete.\nTable 1: Test mean squared error performance of a single axis aligned and oblique decision tree on various regression datasets.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Results", "text": "We present the out-of-sample mean-squared-error performance and optimal depths in Tables 1 and S1 (in Supplemental Section S1.1) respectively. Notably, in all 12 cases, soft tree outperforms all 3 baseline methods in terms of test performance. The soft tree finds a smaller optimal depth in majority cases in comparison with its classical counterpart i.e., oblique TAO tree -See Table S1 in Supplemental Section S1.1. This may be due to the end-to-end learning in a soft tree, unlike TAO that performs local search.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_9", "tab_9"]}, {"heading": "Zero-inflation", "text": "We consider a collection of real-world applications with zero-inflated data. The datasets include (i) yrbs: nationwide drug use behaviors of high school students as a function of demographics, e-cigarettes/mariyuana use etc.; (ii) news: popularity of news items on social media platforms Moniz and Torgo [2018] e.g., Facebook, Google+ as a function of topic and sentiments; (iii) census: number of people with zero, one, or two health insurances across all Census blocks in the ACS population as a function of housing and socio-economic demographics; (iv) fin-services-loss: financial services losses as a function of geodemographics, information on crime rate, weather.", "publication_ref": ["b40"], "figure_ref": [], "table_ref": []}, {"heading": "Competing methods", "text": "We consider Poisson regression with GBDT and differentiable tree ensembles. We also consider zero-inflation modeling with differentiable tree ensem-  bles. We use GBDT from sklearn Buitinck et al. [2013]. For additional details about the tuning experiments, please see Supplemental Section S1.2.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Results", "text": "We present the out-of-sample Poisson deviance performance in Table 2. Notably, tree ensembles with zero-inflated loss function leads the chart. We also present the optimal selection of tree ensemble sizes and depths in Table 3. We can observe that zero-inflation modeling can lead to significant benefits in terms of model compression. Both tree ensemble sizes and depths can potentially be made smaller, which have implications for faster inferences, memory footprint and interpretability. ", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_2", "tab_3"]}, {"heading": "Multi-task Regression", "text": "We compare performance and model compactness of our proposed regularized multi-task tree ensembles on 11 multi-task regression datasets from Mulan (atp1d,atp7d,sf1,sf2,jura,enb,slump,scm1d,scm20d), and UCI data repository (bike) and SARCOS dataset.\nCompeting Methods We focus on 4 tree ensemble baselines from literature: singletask soft tree ensembles, sklearn GBDT, sklearn multioutput RF Buitinck et al. [2013] and r-grf package for GRF Athey et al. [2019]. We consider two multi-task settings: (i) All Fully observed responses for all tasks, (ii) Partially observed responses across tasks.\nIn the former case, we compare against RF and GRF. In the latter case, we compare against single-task soft tree ensembles and GBDT. Note the open-source implementations for RF and GRF do not support partially observed responses for multi-task settings and GBDT does not have support for multi-task setting. We refer the reader to Supplemental Section S1.3 for tuning experiments details.", "publication_ref": ["b14"], "figure_ref": [], "table_ref": []}, {"heading": "Results", "text": "We present results for fully observed response settings in Table 4 and partially observed response settings in Table 6. In both cases, regularized multi-task soft trees lead the charts over the corresponding baselines in terms of out-of-sample mean squared error performance. For the fully observed response setting, we also show tree ensemble sizes in Table 5. We see a large reduction in the number of trees with out proposed multi-task tree ensembles.    We study the performance of our differentiable tree ensembles in a real-word, largescale multi-task setting from a multinational financial services company. The system encompasses costs and fees for millions of users for different products and services. The dataset has the following characteristics: (i) It is a multi-task regression dataset with 3 tasks. (ii) Each task has high degree of over-dispersion. (iii) All tasks are not fully observed as each user signs up for a subset of products/services. The degree of missing responses on average across tasks is \u223c 50%. (iv) Number of features is also large (\u223c 600).\nWe validate the flexibility of our end-to-end tree-ensemble learning framework with soft trees on a dataset of 1.3 million samples. We study the following flexible aspects of our framework: (i) Flexible loss handling with zero-inflation Poisson regression and negative binomial regression for single-task learning. (ii) Multi-task learning with our proposed regularized multi-task soft tree ensembles in the presence of missing responses across tasks. (iii) Flexible loss handling with zero-inflation Poisson/negative binomial regression in the context of multi-task learning.\nWe present our results in Table 7. We can see that we achieve the lowest Poisson deviance and highest AUC with multi-task regression via zero-inflated Poisson/negative binomial regression.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_4", "tab_6", "tab_5", "tab_7"]}, {"heading": "Conclusion", "text": "We propose a flexible and scalable tree ensemble learning framework with seamless support for new loss functions. Our framework makes it possible to compare different loss functions or incorporate new differentiable loss functions and train them with tree ensembles. Our proposal for tensor-based modeling of tree ensembles allows 10x faster training on CPU than existing toolkits and also allow for training differentiable tree ensembles on GPUs. We also propose a novel extension for multi-task learning with trees that allow soft sharing of information across tasks for more compact and expressive ensembles than those by existing tree ensemble toolkits. For a fair comparison, we run all 4 methods for 100 trials.\nOptimal depths We make a comparison of optimal depths between CART, TAO (both axis-aligned and oblique) and soft tree. The soft tree finds a smaller optimal depth in majority cases in comparison with its classical counterpart i.e., oblique TAO tree -See Table S1. This is hypothesized to be due to the end-to-end optimization done by soft tree as opposed to a local search performed by the TAO algorithm. For all models, we perform a random search with 1000 hyperparameter tuning trials.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_9"]}, {"heading": "S1.3 Tuning parameters for Sections 6.3", "text": "We tune number of trees in the interval [50 \u2212 1500] for RF, GRF and GBDT. For RF and GBDT, we also tune over depths between 2 \u2212 20. For GBDT, we tune learning rates between [1e \u2212 5, 1e \u2212 1]. For GRF, we also tune over min node size in the set [2 \u2212 20] and \u03b1 \u2208 [1e \u2212 3, 1e \u2212 1]. For single-task and multi-task trees, we tune over ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgements", "text": "We thank Denis Sai for his help with the experiments on large-scale multi-task data. This research was supported in part, by grants from the Office of Naval Research: ONR-N00014-21-1-2841 and award from Liberty Mutual Insurance.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "", "text": "Competing Methods and Implementation We focus on two baselines from classical tree literature: CART [Breiman et al., 1984] and Tree Alternating Optimization (TAO) method proposed by Carreira-Perpinan and Tavallali [2018]. The authors in Zharmagambetov and Carreira-Perpi\u00f1\u00e1n [2020] performed an extensive comparison of various single tree learners and demonstrated TAO to be the best performer. Hence, we include both axis-aligned and oblique decision tree versions of TAO in our comparisons. Given that the authors in Carreira-Perpinan and Tavallali [2018], Zharmagambetov and Supplementary Material S1 Additional details for Experimental Section 6 Datasets We use a collection of 27 open-source regression datasets from various domains (e.g., social media platforms, human behavior, financial risk data). 9 of these are from Mulan: A Java library for multi-label learning (Mulan) [Xioufis et al., 2016], 2 of them are from University of California Irvine data repository (UCI) [Dua and Graff, 2017], 12 of them are from Delve database [Akujuobi and Zhang, 2017] [Xioufis et al., 2016], we consider the first 4 tasks (out of the 16 tasks in the original dataset). For SARCOS, we consider 3 torques for prediction (torque-3, torque-4 and torque-7; we ignore the other torques as those seem to have poor correlations with these.)\nFor all datasets, we split the datasets into 64%/16%/20% training/validation/test splits. We train the models on the training set, perform hyperparameter tuning on the validation set and report out-of-sample performance on the test set.", "publication_ref": ["b3", "b46", "b47", "b48", "b46"], "figure_ref": [], "table_ref": []}, {"heading": "S1.1 Tuning parameters and optimal depths comparison for a", "text": "single tree in Section 6.1 TAO Implementation We wrote our own implementation of the TAO algorithm proposed in Carreira-Perpinan and Tavallali [2018]. We considered binary trees with TAO for both axis-aligned and oblique trees. In the case of axis-aligned splits, we initialize the tree with CART solution and run TAO iterations until there is no improvement in training objective. In the case of oblique trees, we initialize with a complete binary tree with random parameters for the hyperplanes in the split nodes and use logistic regression to solve the decision node optimization. We run the algorithm until either a maximum number of iterations are reached or the training objective fails to improve.\nTuning parameters For CART and axis-aligned TAO, we tune the depth in the range [2 \u2212 20]. We also optimize over the maximum number of iterations in the interval [20 \u2212 100]. For oblique TAO and soft tree, we tune the depth between 2 \u2212 10 and the number of iterations between 20 \u2212 100. Additionally, for soft tree, we also tune over the 1 The original test set has significant data leakage as noted by https://www.datarobot.com/blog/ running-code-and-failing-models/. Following their guidance we discard the original test set and use the original train set to generate train/validation/test splits.\n2 https://www.cdc.gov/healthyyouth/data/yrbs/data.htm 3 https://www.census.gov/topics/research/guidance/planning-databases.html 4 https://bit.ly/3swGnTo", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "The low response score (LRS)", "journal": "", "year": "2016-12", "authors": "Chandra Erdman; Nancy Bates"}, {"ref_id": "b1", "title": "Xgboost: A scalable tree boosting system", "journal": "Association for Computing Machinery", "year": "2016", "authors": "Tianqi Chen; Carlos Guestrin"}, {"ref_id": "b2", "title": "The Elements of Statistical Learning", "journal": "Springer", "year": "2009", "authors": "T J Hastie; R J Tibshirani; J Friedman"}, {"ref_id": "b3", "title": "Classification and Regression Trees", "journal": "Taylor & Francis", "year": "1984", "authors": "L Breiman; J Friedman; C J Stone; R A Olshen"}, {"ref_id": "b4", "title": "C4.5: Programs for Machine Learning", "journal": "Morgan Kaufmann Publishers Inc", "year": "1993", "authors": "J ; Ross Quinlan"}, {"ref_id": "b5", "title": "A system for induction of oblique decision trees", "journal": "J. Artif. Int. Res", "year": "1994-08", "authors": "K Sreerama; Simon Murthy; Steven Kasif;  Salzberg"}, {"ref_id": "b6", "title": "Lightgbm: A highly efficient gradient boosting decision tree", "journal": "Curran Associates, Inc", "year": "2017", "authors": "Guolin Ke; Qi Meng; Thomas Finley"}, {"ref_id": "b7", "title": "Boosted multi-task learning", "journal": "", "year": "2010", "authors": "Olivier Chapelle; K Pannagadatta; Srinivas Shivaswamy;  Vadrevu; Q Kilian; Ya Weinberger; Belle L Zhang;  Tseng"}, {"ref_id": "b8", "title": "Learning task grouping and overlap in multitask learning", "journal": "", "year": "2012", "authors": "Abhishek Kumar; Hal Daum\u00e9"}, {"ref_id": "b9", "title": "Learning tree structure in multi-task learning", "journal": "Association for Computing Machinery", "year": "2015", "authors": "Lei Han; Yu Zhang"}, {"ref_id": "b10", "title": "Multi-task learning with deep neural networks: A survey", "journal": "", "year": "2009", "authors": "Michael Crawshaw"}, {"ref_id": "b11", "title": "Deep neural decision forests", "journal": "", "year": "2015", "authors": "Peter Kontschieder; Madalina Fiterau; Antonio Criminisi"}, {"ref_id": "b12", "title": "The tree ensemble layer: Differentiability meets conditional computation. ArXiv, abs", "journal": "", "year": "2002", "authors": "Hussein Hazimeh; Natalia Ponomareva; Petros Mol; Zhenyu Tan; Rahul Mazumder"}, {"ref_id": "b13", "title": "Random forests", "journal": "", "year": "2001", "authors": "Leo Breiman"}, {"ref_id": "b14", "title": "Generalized random forests. The Annals of Statistics", "journal": "", "year": "2019", "authors": "Susan Athey; Julie Tibshirani; Stefan Wager"}, {"ref_id": "b15", "title": "Alternating optimization of decision trees, with application to learning sparse oblique trees", "journal": "Curran Associates, Inc", "year": "2018", "authors": "Miguel A Carreira-Perpinan; Pooya Tavallali"}, {"ref_id": "b16", "title": "Soft decision trees", "journal": "", "year": "2012", "authors": "O T Ozan Irsoy; Ethem Yildiz;  Alpaydin"}, {"ref_id": "b17", "title": "Distilling a neural network into a soft decision tree", "journal": "", "year": "2017", "authors": "Nicholas Frosst; Geoffrey Hinton"}, {"ref_id": "b18", "title": "Random hinge forest for differentiable learning", "journal": "", "year": "2018", "authors": "Nathan Lay; Adam P Harrison; Sharon Schreiber"}, {"ref_id": "b19", "title": "Decision Tree Construction Via Linear Programming. Number no. 1067 in Computer sciences technical report", "journal": "", "year": "1992", "authors": "K P Bennett"}, {"ref_id": "b20", "title": "Optimal decision trees", "journal": "R.P.I. Math Report", "year": "1996", "authors": "Kristin P Bennett; Jennifer A Blue"}, {"ref_id": "b21", "title": "Optimal classification trees", "journal": "", "year": "2017", "authors": "Dimitris Bertsimas; Jack Dunn"}, {"ref_id": "b22", "title": "A scalable mip-based method for learning optimal multivariate decision trees", "journal": "Curran Associates, Inc", "year": "2020", "authors": "Haoran Zhu; Pavankumar Murali; Dzung Phan; Lam Nguyen; Jayant Kalagnanam"}, {"ref_id": "b23", "title": "Constructing optimal binary decision trees is np-complete", "journal": "Information Processing Letters", "year": "1976", "authors": "Laurent Hyafil; Ronald L Rivest"}, {"ref_id": "b24", "title": "Extremely randomized trees", "journal": "", "year": "2006", "authors": "Pierre Geurts; Damien Ernst; Louis Wehenkel"}, {"ref_id": "b25", "title": "Catboost: Unbiased boosting with categorical features", "journal": "Curran Associates Inc", "year": "2018", "authors": "Liudmila Prokhorenkova; Gleb Gusev; Aleksandr Vorobev"}, {"ref_id": "b26", "title": "Boosting: Foundations and Algorithms", "journal": "The MIT Press", "year": "2012", "authors": "Robert E Schapire; Yoav Freund"}, {"ref_id": "b27", "title": "Arman Serikuly Zharmagambetov and Miguel\u00c1. Carreira-Perpi\u00f1\u00e1n. Smaller, more accurate regression forests using tree alternating optimization", "journal": "", "year": "2020", "authors": ""}, {"ref_id": "b28", "title": "Hierarchical mixtures of experts and the em algorithm", "journal": "Neural Comput", "year": "1994-03", "authors": "Michael I Jordan; Robert A Jacobs"}, {"ref_id": "b29", "title": "Adaptive neural trees. ArXiv, abs", "journal": "", "year": "1807", "authors": "Ryutaro Tanno; Kai Arulkumaran; Daniel C Alexander; Antonio Criminisi; Aditya V Nori"}, {"ref_id": "b30", "title": "TensorFlow: Large-scale machine learning on heterogeneous systems", "journal": "", "year": "2015", "authors": "Mart\u00edn Abadi; Ashish Agarwal; Paul Barham"}, {"ref_id": "b31", "title": "Pytorch: An imperative style, highperformance deep learning library", "journal": "Curran Associates, Inc", "year": "2019", "authors": "Adam Paszke; Sam Gross; Francisco Massa"}, {"ref_id": "b32", "title": "Tensorflow distributions. CoRR, abs", "journal": "", "year": "1711", "authors": "Joshua V Dillon; Ian Langmore; Dustin Tran"}, {"ref_id": "b33", "title": "Optimal randomized classification trees", "journal": "Computers & Operations Research", "year": "2021", "authors": "Rafael Blanquero; Emilio Carrizosa; Cristina Molero-R\u00edo; Dolores Romero Morales"}, {"ref_id": "b34", "title": "End-to-end learning of decision trees and forests", "journal": "International Journal of Computer Vision", "year": "2019", "authors": "Thomas M Hehn; Julian F P Kooij; Fred A Hamprecht"}, {"ref_id": "b35", "title": "Addressing imbalanced insurance data through zero-inflated poisson regression with boosting", "journal": "ASTIN Bulletin", "year": "2020", "authors": "C K Simon;  Lee"}, {"ref_id": "b36", "title": "Negative binomial mixed models for analyzing longitudinal cd4 count data", "journal": "Scientific Reports", "year": "2020", "authors": "A Ashenafi;  Yirga; F Sileshi; Henry G Melesse; Dawit G Mwambi;  Ayele"}, {"ref_id": "b37", "title": "A general and adaptive robust loss function", "journal": "", "year": "2019", "authors": "Jonathan T Barron"}, {"ref_id": "b38", "title": "Concurrent e-cigarette and marijuana use and health-risk behaviors among u.s. high school students", "journal": "Preventive Medicine", "year": "2021", "authors": "Wura Jacobs; Ehikowoicho Idoko; Latrice Montgomery; Matthew Lee Smith; Ashley L Merianos"}, {"ref_id": "b39", "title": "Zero-inflated modelling for characterizing coverage errors of extracts from the us census bureau's master address file", "journal": "Journal of The Royal Statistical Society Series A-statistics in Society", "year": "2017", "authors": "Derek S Young; Andrew M Raim; Nancy R Johnson"}, {"ref_id": "b40", "title": "Multi-source social feedback of online news feeds", "journal": "ArXiv", "year": "2018", "authors": "Nuno Moniz; Lu\u00eds Torgo"}, {"ref_id": "b41", "title": "Regression Analysis of Count Data. Econometric Society Monographs", "journal": "Cambridge University Press", "year": "2013", "authors": "A ; Colin Cameron; Pravin K Trivedi"}, {"ref_id": "b42", "title": "Zero-inflated poisson regression, with an application to defects in manufacturing", "journal": "Technometrics", "year": "1992-02", "authors": "Diane Lambert"}, {"ref_id": "b43", "title": "Multitask learning", "journal": "", "year": "1997", "authors": "Rich Caruana"}, {"ref_id": "b44", "title": "An overview of multi-task learning in deep neural networks. ArXiv, abs", "journal": "", "year": "1706", "authors": "Sebastian Ruder"}, {"ref_id": "b45", "title": "Multi-output random forests", "journal": "", "year": "2013", "authors": "Henrik Linusson"}, {"ref_id": "b46", "title": "Multitarget regression via input space expansion: treating targets as inputs", "journal": "", "year": "2016", "authors": "Grigorios Eleftherios Spyromitros Xioufis; William Tsoumakas;  Groves"}, {"ref_id": "b47", "title": "UCI machine learning repository", "journal": "", "year": "2017", "authors": "Dheeru Dua; Casey Graff"}, {"ref_id": "b48", "title": "Delve: A dataset-driven scholarly search and analysis system", "journal": "SIGKDD Explor. Newsl", "year": "2017-11", "authors": "Uchenna Akujuobi; Xiangliang Zhang"}, {"ref_id": "b49", "title": "All single-task models (soft tree ensembles, GBDT) are tuned for 1000 trials per task", "journal": "", "year": "", "authors": ""}, {"ref_id": "b50", "title": "We also optimize over the regularization penalty for multi-task soft decision trees", "journal": "", "year": "2016", "authors": " We; ; Xgboost; Guestrin Chen"}, {"ref_id": "b51", "title": "Zero-Inflated-Poisson, Negative Binomial are tuned for 1000 trials per task. All multi-task soft-trees are tuned for 1000 trials in total", "journal": "", "year": "", "authors": " Poisson"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 :1Figure 1: Timing comparison on CPU training with tensor-based implementation. GPU training with tensor-based implementation leads to an additional 40% improvement over CPU training with tensor-based implementation.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "where \u03b2 are parameters and g(\u2022) is the link function. When responses y n (for n \u2208 [N ]), are independent and identically distributed (i.i.d.) and follow the Poisson distribution conditional on x n 's, we use log(\u2022) as the link function and call the model a Poisson regression model: log(\u00b5 n |x n ) = \u03b2 \u2022 x n . We consider more general parameterizations with tree ensembles as given by", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 2 :2Figure 2: Classifier boundaries for CART [Left], TAO (oblique) [Middle] and Soft tree [Right]on a synthetic dataset with N train = N val = N test = 2500 generated using sklearn[Buitinck  et al., 2013]. We tune for 50 trials over depths in the range [2 \u2212 4] for TAO (oblique) and soft trees and [2 \u2212 10] for CART. Optimal depths for CART, TAO, Soft tree are 5, 4 and 2 respectively. Test AUCs are 0.950, 0.957, and 0.994 respectively.", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "S1. 22Tuning parameters for Sections 6.2 We use HistGBDT from sklearn Buitinck et al. [2013] (GBDT in sklearn does not support Poisson regression). We tune over depths in the range [2 \u2212 20], number of trees between 50 \u2212 1500 and learning rates on the log-uniform scale in the interval [1e \u2212 5, 1e \u2212 1]. For differentiable tree ensembles, we tune number of trees in the range [2, 100], depths in the set [2 \u2212 4], batch sizes {64, 128, 256, 512}, learning rates [1e \u2212 5, 1e \u2212 1] with Adam optimizer and perform early stopping with a patience of 25 based on the validation set.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "model trees individually. This leads to slow CPU-training times and makes these implementations hard to vectorize for fast GPU training. In fact, TEL[Hazimeh et al., 2020] doesn't support GPU training. We propose a tensor-based formulation of a tree ensemble that parallelizes routing decisions in nodes across the trees in the ensemble. This can lead to 10x faster CPU training times if the ensemble sizes are large e.g., 100. Additionally, the tensor-based formulation is GPU-friendly, which provides an additional 40% faster training times. See Figure1for a timing comparison on CPU training without/with tensor formulation. Next, we outline the tensor-based formulation.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "By relying on TF in the backend, our toolkit can easily exploit distributed computing. It can also run on multiple CPUs or GPUs, and on multiple platforms, including mobile platforms. Checkpointing for fault tolerance, incremental training and warm restarts are also supported. The toolkit will be open sourced if the paper is accepted.4 Flexible loss functionsOur framework can handle any differentiable loss function. Such flexibility is important as various applications require flexibility in loss functions beyond what is provided by current tree ensemble learning APIs. Our framework is built on Tensorflow, which gives us the capability to perform gradient-based optimization on scale. This coupled with our efficient differentiable tree ensemble formulation gives a powerful toolkit to seamlessly experiment with different loss functions and select what is suitable for the intended application. A few examples of flexible distributions that our toolkit supports -due to compatibility with Tensorflow-Probability -are normal, Poisson, gamma, exponential, mixture distributions e.g., zero-inflation models[Lee, 2020], and compound distributions e.g., negative binomial[Yirga et al., 2020]. Other loss functions such as robustness to outliers", "figure_data": ""}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Flexible modeling via zero-inflated Poisson for Soft Tree Ensembles leads to better out-of-sample performance.", "figure_data": "GBDTSoft Trees"}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "Flexible modeling via zero-inflated Poisson for Soft Tree Ensembles can lead to more compact tree ensembles, which can potentially lead to easier interpretability", "figure_data": "#TreesDepthGBDTSoft TreesGBDTSoft TreesDataPoissonZIPPoissonZIPyrbs-cocaine5757713423yrbs-heroine1425834442yrbs-meth1475164423yrbs-lsd12251745432news-facebook2006585444news-google+7508174444census-health012751010432census-health112751717422census-health2+13757356843fin-services-losses1225324432#wins047-58"}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "Performance of RF, GRF and multi-task Differentiable Tree Ensembles on 11 multi-task regression datasets with fully observed responses across tasks.", "figure_data": "Multi-task"}, {"figure_label": "5", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "Tree ensemble sizes for soft trees, RF, and GRF.", "figure_data": "atp1d atp7d sf1 sf2 jura enb slump scm1d scm20d bikeRF100125500 225150100825175100100GRF1050950350 10015010035050100250Ours10151244171354492593"}, {"figure_label": "6", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "Performance of GBDT, single-task and multi-task Soft Tree Ensembles on 11 multi-task regression datasets with 50% missing responses per task.", "figure_data": "Single-TaskMulti-Task"}, {"figure_label": "7", "figure_type": "table", "figure_id": "tab_7", "figure_caption": "Out-of-sample performance of single-task and multi-task tree ensembles with flexible loss functions for zero-inflation/overdispersion. We evaluate performance with weighted Poisson deviance and AUC across tasks.", "figure_data": "GBDTSoft TreesSingle-taskSingle-taskMulti-taskMetricTaskPoissonPoissonZIPNBPoissonZIPNBPoisson Deviance1 2 32.643E-04 8.029E-04 1.044E-032.624E-04 2.623E-04 2.623E-04 2.607E-04 2.605E-04 2.608E-04 8.050E-04 8.029E-04 8.044E-04 8.022E-04 8.014E-04 8.014E-04 1.045E-03 1.043E-03 1.042E-03 1.041E-03 1.040E-03 1.041E-0310.7100.7210.7220.7210.7300.7340.727AUC20.6900.6890.6900.6880.6910.6910.69230.6840.6830.6860.6850.6870.6890.6896.4 Large-scale multi-task data from a multinational financialservices company"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_8", "figure_caption": "Sethu Vijayakumar and Stefan Schaal. Locally weighted projection regression : An o(n) algorithm for incremental real time learning in high dimensional space. 2000. US Census Bureau. Planning database, Jun 2021. Lars Buitinck, Gilles Louppe, Mathieu Blondel, et al. API design for machine learning software: experiences from the scikit-learn project. In ECML PKDD Workshop: Languages for Data Mining and Machine Learning, pages 108-122, 2013. learning rates [1e \u2212 5, 1e \u2212 2] with Adam optimizer and batch sizes {64, 128, 256, 512}.", "figure_data": ""}, {"figure_label": "S1", "figure_type": "table", "figure_id": "tab_9", "figure_caption": "Optimal depth of a single axis aligned and oblique decision tree on various regression datasets.", "figure_data": "Axis-AlignedObliqueDataCARTTAOTAOSoft Treeabalone5542pumadyn-32nh6643pumadyn-32nm8854pumadyn-32fh3335pumadyn-32fm6654pumadyn-8nh6653pumadyn-8nm9875pumadyn-8fh5542pumadyn-8fm7763cpu10855cpuSmall8855concrete15859"}], "formulas": [{"formula_id": "formula_0", "formula_text": "B j := [B 1j , B 2j , ..., B M j ] T \u2208 R M for j \u2208 [N ]. A dot product between two vectors u, v \u2208 R m is denoted as u \u2022 v. A dot product between a matrix U \u2208 R m,n and a vector v \u2208 R m is denoted as U \u2022 v = U T v \u2208 R n . A dot product between a tensor U \u2208 R p,m,n and a vector v \u2208 R m is denoted as U \u2022 v = U T v \u2208 R p,n", "formula_coordinates": [5.0, 84.74, 348.49, 442.23, 68.97]}, {"formula_id": "formula_1", "formula_text": "f (x) = m j=1 f j (x).", "formula_coordinates": [5.0, 259.59, 572.44, 92.83, 35.77]}, {"formula_id": "formula_2", "formula_text": "Let [l i] (resp. [i l]", "formula_coordinates": [6.0, 85.04, 538.93, 444.2, 24.93]}, {"formula_id": "formula_3", "formula_text": "P j ({x \u2192 l}) = i\u2208A(l) r j i,l (x),(2)", "formula_coordinates": [6.0, 236.35, 607.15, 290.61, 27.2]}, {"formula_id": "formula_4", "formula_text": "j i \u2022 x)1[l i] (1 \u2212 S(w j i \u2022 x))1[i l]", "formula_coordinates": [6.0, 191.79, 665.59, 198.31, 15.72]}, {"formula_id": "formula_5", "formula_text": "f j (x) = l\u2208L P j ({x \u2192 l})o j l .(3)", "formula_coordinates": [7.0, 234.03, 171.5, 292.94, 26.76]}, {"formula_id": "formula_6", "formula_text": "f (x) = \uf8eb \uf8ed l\u2208L O l i\u2208A(l) R i,l \uf8f6 \uf8f8 \u2022 1 m (4)", "formula_coordinates": [8.0, 217.52, 362.09, 309.44, 40.6]}, {"formula_id": "formula_7", "formula_text": "R i,l = S(W i \u2022x)1[l i] (1\u2212S(W i \u2022x))1[i l] \u2208 R m,1", "formula_coordinates": [8.0, 85.04, 418.85, 427.8, 25.63]}, {"formula_id": "formula_8", "formula_text": "g[E(y|x)] = \u03b2 \u2022 x,(5)", "formula_coordinates": [10.0, 260.6, 155.81, 266.36, 10.52]}, {"formula_id": "formula_9", "formula_text": "log(\u00b5 n |x n ) = f (x n ; W, O). (6", "formula_coordinates": [10.0, 236.31, 260.96, 285.66, 11.54]}, {"formula_id": "formula_10", "formula_text": ")", "formula_coordinates": [10.0, 521.98, 261.0, 4.99, 10.48]}, {"formula_id": "formula_11", "formula_text": "y n = 0, if d n = 0 y * n , if d n = 1 (7)", "formula_coordinates": [10.0, 249.92, 396.64, 277.05, 30.0]}, {"formula_id": "formula_12", "formula_text": "ZIP (y n |\u00b5 n , \u03c0 n ) = (1 \u2212 \u03c0 n ) + \u03c0 n e \u2212\u00b5n , if y n = 0 \u03c0 n e \u2212\u00b5n \u00b5 yn n /y n !, if y n = 1, 2, \u2022 \u2022 \u2022 (8)", "formula_coordinates": [10.0, 161.62, 491.54, 365.34, 31.62]}, {"formula_id": "formula_13", "formula_text": "log \u03c0 n 1 \u2212 \u03c0 n |x n = f (x n ; Z, U ) (9) log(\u00b5 n |x n ) = f (x n ; W, O). (10", "formula_coordinates": [10.0, 219.84, 556.63, 307.12, 45.05]}, {"formula_id": "formula_14", "formula_text": ")", "formula_coordinates": [10.0, 521.76, 590.17, 5.2, 10.48]}, {"formula_id": "formula_15", "formula_text": "L(y n , f (x n )) = yn=0 (1 \u2212 \u03c0 n ) + \u03c0 n e \u2212\u00b5n yn>0", "formula_coordinates": [10.0, 162.62, 680.09, 212.52, 25.67]}, {"formula_id": "formula_16", "formula_text": "N B(y|\u00b5, \u03c6) = y + \u03c6 \u2212 1 y \u00b5 \u00b5 + \u03c6 y \u03c6 \u00b5 + \u03c6 \u03c6 (12)", "formula_coordinates": [11.0, 179.54, 244.47, 347.42, 30.14]}, {"formula_id": "formula_17", "formula_text": "log(\u00b5 n |x n ) = f (x n ; W, O) (13) log (\u03c6 n |x n ) = f (x n ; Z, U ). (14", "formula_coordinates": [11.0, 237.0, 415.84, 289.96, 28.98]}, {"formula_id": "formula_18", "formula_text": ")", "formula_coordinates": [11.0, 521.76, 433.31, 5.2, 10.48]}, {"formula_id": "formula_19", "formula_text": "f (x) = l\u2208L O l i\u2208A(l) R i,l \u2022 1 m (15", "formula_coordinates": [12.0, 217.88, 338.09, 303.88, 24.29]}, {"formula_id": "formula_20", "formula_text": ")", "formula_coordinates": [12.0, 521.76, 338.13, 5.2, 10.48]}, {"formula_id": "formula_21", "formula_text": "O l \u2208 R T,m,k denotes the trainable leaf tensor in leaf l, R i,l = S(W i \u2022 x)1[l i] (1 \u2212 S(W i \u2022 x))1[i l] \u2208 R T,m,1 .", "formula_coordinates": [12.0, 85.04, 377.07, 426.75, 27.57]}, {"formula_id": "formula_22", "formula_text": "min W,O t\u2208T x,yt g t (y t , f t (x)) + \u03bb s<t,t\u2208T W :,s,:,: \u2212 W :,t,:,: 2 , (16", "formula_coordinates": [12.0, 166.41, 461.21, 355.35, 26.82]}, {"formula_id": "formula_23", "formula_text": ")", "formula_coordinates": [12.0, 521.76, 464.3, 5.2, 10.48]}], "doi": "10.1017/CBO9781139013567"}