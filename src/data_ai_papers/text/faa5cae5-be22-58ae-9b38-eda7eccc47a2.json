{"title": "Solving Stackelberg Prediction Game with Least Squares Loss via Spherically Constrained Least Squares Reformulation", "authors": "Jiali Wang; Wen Huang; Rujun Jiang; Xudong Li; Alex L Wang", "pub_date": "2022-06-07", "abstract": "The Stackelberg prediction game (SPG) is popular in characterizing strategic interactions between a learner and an attacker. As an important special case, the SPG with least squares loss (SPG-LS) has recently received much research attention. Although initially formulated as a difficult bi-level optimization problem, SPG-LS admits tractable reformulations which can be polynomially globally solved by semidefinite programming or second order cone programming. However, all the available approaches are not well-suited for handling large-scale datasets, especially those with huge numbers of features. In this paper, we explore an alternative reformulation of the SPG-LS. By a novel nonlinear change of variables, we rewrite the SPG-LS as a spherically constrained least squares (SCLS) problem. Theoretically, we show that an \u01eb optimal solution to the SCLS (and the SPG-LS) can be achieved in\u00d5(N/ \u221a \u01eb) floating-point operations, where N is the number of nonzero entries in the data matrix. Practically, we apply two well-known methods for solving this new reformulation, i.e., the Krylov subspace method and the Riemannian trust region method. Both algorithms are factorization free so that they are suitable for solving large scale problems. Numerical results on both synthetic and real-world datasets indicate that the SPG-LS, equipped with the SCLS reformulation, can be solved orders of magnitude faster than the state of the art.", "sections": [{"heading": "Introduction", "text": "The big data era has led to an explosion in the availability of data from which to make decisions. It is thus indispensable to use machine learning techniques to gain deep insights from massive data. In practice, many classic data analytic approaches start by splitting available data into the training and test sets. Then, learning algorithms are fed with the training set and are expected to produce results which generalize well to the test set. However, this paradigm only works under the key implicit assumption that the available data in both training and test sets are independently and identically distributed, which, unfortunately, is not always the truth in practice. For example, in the context of email spam filtering, an attacker often adversarially generates spam emails based on his knowledge of the spam filter implemented by the email service provider (Br\u00fcckner & Scheffer, 2011;Zhou et al., 2019). In addition to malicious attacks, sometimes the data providers may manipulate data for their own interests. For instance, health insurance policy holders may decide to modify selfreported data to reduce their premiums. On the other hand, the insurers (the \"defenders\" in this scenario) aim to select a good price model for the true data despite only seeing the modified data.\nIn fact, these scenarios can be modeled by the Stackelberg prediction game (SPG) (Br\u00fcckner & Scheffer, 2011;Shokri et al., 2012;Zhou & Kantarcioglu, 2016;Wahab et al., 2016;Zhou et al., 2019;Bishop et al., 2020) which characterizes the interactions between two players, a learner (or, a leader) and a data provider (or, a follower). In this setting, the learner makes the first move by selecting a learning model. Then the data provider, with full knowledge of the learner's model, is allowed to modify its data. The learner's goal is to minimize its own loss function under the assumption that the training data has been optimally modified from the data provider's perspective. From the above description, we see that the SPG model concerns two levels of optimization problems: The follower optimally manipulates its data and the leader makes its optimal decision taking into account the data manipulation. Formally, it is often formulated as a hierarchical mathematical problem or a bi-level optimization problem, which is generally NP-hard even in the simplest case with linear constraints and objectives (Jeroslow, 1985).\nTo overcome this issue, Bishop et al. (2020) take the first step to focus on a subclass of SPGs that can be reformulated as fractional programs. Specifically, they assume that all the loss functions of the leader and the follower are least squares, and that a quadratic regularizer is added to the follower's loss to penalise its manipulation of the data. This assumption eventually turns the bi-level optimization problem into a single-level fractional optimization task which is proven to be polynomially globally solvable. Since no other assumption is made about the learner and data provider, this subclass of SPG, termed as the SPG-LS, is general enough to be applied in wide fields. However, the bisection algorithm proposed in Bishop et al. (2020) involves solving several tens of semidefinite programs (SDPs) which are computationally prohibitive in practice. Later, Wang et al. (2021b) improves over Bishop et al. (2020) by showing that the SPG-LS can be globally solved via solving only a single SDP with almost the same size as the ones in Bishop et al. (2020). Furthermore, this single SDP can be reduced to a second order cone program (SOCP). It is shown in Wang et al. (2021b) that the SOCP approach for solving SPG-LS can be over 20,000+ times faster than the bisection method proposed in Bishop et al. (2020). Yet, the SOCP method is still not wellsuited for solving large-scale SPG-LS. Indeed, the spectral decomposition in the SOCP reformulation process is time-consuming when the future dimension is high. This inevitably reduces the practical applicability of the SOCP approach for the SPG-LS.\nIn this paper, we present a novel reformulation to resolve the above mentioned issues of the SOCP method. Specifically, a nonlinear change of variables is proposed to reformulate the SPG-LS as a spherically constrained least squares (SCLS) problem. Then, we prove that an optimal solution to the SPG-LS can be recovered easily from any optimal solution to the SCLS under a mild assumption. The SCLS can be seen as an equality constrained version of the trust region subproblem (Conn et al., 2000), which admits a large amount of existing research on practical algorithms and theoretical complexity analysis. Based on this, we show that an \u01eb optimal solution 1 of the SCLS and thus SPG-LS can be solved in\u00d5(N/ \u221a \u01eb) flops, where N denotes the number of nonzero entries of the data matrix and\u00d5(\u2022) hides the logarithmic factors. This means there exits a linear time algorithm for finding an \u01eb optimal solution of the SPG-LS. Moreover, we demonstrate the empirical efficiency of our SCLS reformulation when matrix factorization free methods like the Krylov subspace method (Gould et al., 1999; and the Riemannian trust region Newton (RTRNewton) method (Absil et al., 2007) are used as solvers.\nWe summarise our contributions as follows:\n\u2022 We derive an SCLS reformulation for the SPG-LS that avoids spectral decomposition steps (which are expensive when the involved data matrices are large). Moreover, we show that an optimal solution to the SPG-LS can be recovered from any optimal solution to the SCLS reformulation under a mild condition.\n\u2022 Based on the reformulation, we show that an \u01eb optimal solution for the SCLS can be found using\u00d5(1/ \u221a \u01eb) matrix vector products. In other words, an \u01eb solution can be obtained in running time\u00d5(N/ \u221a \u01eb), where N is the number of nonzeros in the data matrix. Moreover, we show that an \u01eb optimal solution of SCLS can be used to recover an \u01eb optimal solution for the original SPG-LS.\n\u2022 Two practically efficient algorithms, which are factorization free, are adopted to solve the SCLS reformulation. We show that the SCLS approach significantly outperforms the SOCP approach with experiments on both real and synthetic data sets.", "publication_ref": ["b4", "b32", "b4", "b23", "b31", "b24", "b32", "b2", "b14", "b2", "b2", "b27", "b2", "b2", "b27", "b2", "b6", "b10", "b0"], "figure_ref": [], "table_ref": []}, {"heading": "Preliminaries", "text": "In this section, we elaborate on the SPG-LS problem adopting the same terminology as in Bishop et al. (2020); Wang et al. (2021b). To have a better understanding of our reformulation, a brief review of methods in Wang et al. (2021b), which is the fastest existing method for solving the SPG-LS, will also be provided.\nWe assume that the learner has access to m sample tuples\nS = {(x i , y i , z i )} m i=1\n, where x i \u2208 R n is input data with n features, y i and z i are the true output label of x i and the label that the data provider would like to achieve, respectively. These samples are assumed to follow some fixed but unknown distribution D. The learner aims at training a linear predictor w \u2208 R n to best estimate the true output label y i given the fake data. Meanwhile, the data provider, with full knowledge of the learner's predictive model w, selects its own strategy (i.e., the modified datax i ) to make the corresponding prediction w Tx i close to the desired label z i . Note that there is also a regularizer, \u03b3 > 0, to control the deviation from the original data x i . This hyper-parameter adjusts the trade-off between data manipulation and closeness to the aimed target.\nThe problem can be modeled as a Stackelberg prediction game (Br\u00fcckner & Scheffer, 2011;Bishop et al., 2020). On the one hand, each data provider aims to minimize its own loss function with a regularizer that penalizes the manipulation of the data by solving the following optimization problem:\nx * i = argmin x i w Tx i \u2212 z i 2 + \u03b3 x i \u2212x i 2 2 i \u2208 [m],\nwhere w is the learner's model parameter that is known to the data provider. On the other hand, the learner seeks to minimize the least squares loss with the modified data\n{x * i } m i=1 : w * \u2208 argmin w m i=1 w T x * i \u2212 y i 2 ,\nTo find the Stackelberg equilibrium of the two players, we focus on the following bi-level optimization problem\nmin w X * w \u2212 y 2 s.t. X * = argmin X X w \u2212 z 2 + \u03b3 X \u2212 X 2 F , (1)\nwhere the i-th row of X \u2208 R m\u00d7n is the input sample x i and the i-th entries of y, z \u2208 R m are labels y i and z i , respectively.\nIn the following section, we have a quick review of single SDP and SOCP methods in Wang et al. (2021b).", "publication_ref": ["b2", "b27", "b27", "b4", "b2", "b27"], "figure_ref": [], "table_ref": []}, {"heading": "SDP Reformulation", "text": "By using the Sherman-Morrison formula (Sherman & Morrison, 1950), the SPG-LS can be rewritten as a quadratic fractional program (Bishop et al., 2020) inf\nw 1 \u03b3 zw T w + Xw 1 + 1 \u03b3 w T w \u2212 y 2 .(2)\nIntroducing an augmented variable \u03b1 = w T w/\u03b3, we have the following quadratic fractional programming (QFP) reformulation.\ninf w, \u03b1 v(w, \u03b1)\n\u03b1z+Xw 1+\u03b1 \u2212 y 2 s.t. w T w = \u03b3\u03b1.(3)\nLemma 2.1 (Theorem 3.3 in Wang et al. (2021b)). Problem (3) is equivalent to the following SDP\nsup \u00b5,\u03bb \u00b5 s.t. A \u2212 \u00b5B + \u03bbC 0,(4)\nwhere A =\nX T X X T (z\u2212y) \u2212X T y (z\u2212y) T X z\u2212y 2 \u2212(z\u2212y) T y \u2212y T X \u2212y T (z\u2212y) y T y , B = On 1 1 1 1 and C = In \u03b3 0 \u2212 1 2 \u2212 1 2 0 .\nHere O n denotes a n \u00d7 n matrix with all entries being zeros and I n denotes the n \u00d7 n identity matrix. et al. (2021b) further constructed an invertible matrix V such that A, B and C are simultaneously congruent to arrow matrices via the change of variables associated to V , i.e.,\u00c3", "publication_ref": ["b22", "b2", "b27"], "figure_ref": [], "table_ref": []}, {"heading": "SOCP Reformulation", "text": "Wang\n:= V T AV = D b b T c ,\nwhere n+1) , b \u2208 R n+1 and c \u2208 R, and\nD = Diag(d 1 , . . . , d n+1 ) \u2208 R (n+1)\u00d7(\nB := V BV = On+1 4 andC = V T CV = 1 \u03b3 In+1 \u22121 .\nTherefore the linear matrix inequality (LMI) constraint in ( 4) is equivalent to\u00c3\u2212\u00b5B+\u03bbC 0. Using the generalized Schur complement, we further obtain an SOCP reformulation as follows.\nLemma 2.2 (Theorem 4.1 in Wang et al. (2021b)). With the same notation in this section, problem (4) is equivalent to the following SOCP problem sup \u00b5,\u03bb,s \u00b5 s.t.\nd i + \u03bb \u03b3 \u2265 0, i \u2208 [n + 1], c \u2212 4\u00b5 \u2212 \u03bb \u2212 n+1 i=1 s i \u2265 0, s i (d i + \u03bb \u03b3 ) \u2265 b 2 i , s i \u2265 0, i \u2208 [n + 1].(5)\nTo obtain the SOCP reformulation, we need a spectral decomposition to a matrix of order (n + 1) \u00d7 (n + 1) (Wang et al., 2021b), which is expensive when the dimension is high and may lead to inaccurate solutions when the matrix is ill-conditioned. To amend this issue, we obtain in the next section a factorization free method based on a novel reformulation of problem (2).", "publication_ref": ["b27", "b27"], "figure_ref": [], "table_ref": []}, {"heading": "Main Results", "text": "In this section, we show that using a nonlinear change of variables, we can rewrite (3) as a least squares problem over the unit sphere. This is the key observation of our paper.\nBefore presenting our main results, we first make a blanket assumption on the nonemptiness of the optimal solution set of (2).\nAssumption 3.1. Assume that the optimal solution set of (2) (or equivalently, (3)) is nonempty.\nOur main result is that under Assumption 3.1, the QFP (3) can be reformulated as a spherical constrained least squares (SCLS) problem mi\u00f1 w,\u03b1\u1e7d (w,\u03b1)\n\u03b1 2 z + \u221a \u03b3 2 Xw \u2212 (y \u2212 z 2 ) 2 s.t.w Tw +\u03b1 2 = 1.(6)\nA formal statement is deferred to Theorem 3.4.\nBefore presenting our main results, we first introduce two lemmas that show how, given a feasible solution in (3), we can construct a feasible solution with the same objective value in (6) and vice versa (up to a minor achievability issue).\nLemma 3.2. Suppose (w, \u03b1) is a feasible solution of (3). Then (w,\u03b1), defined as\nw := 2 \u221a \u03b3(\u03b1 + 1) w and\u03b1 := \u03b1 \u2212 1 \u03b1 + 1 ,(7)\nis feasible to (6) and v(w, \u03b1) =\u1e7d(w,\u03b1).\nProof. We first note that (w,\u03b1) are well-defined as \u03b1 \u2265 0 by the feasibility of (w, \u03b1) in (3). Next, we check feasibility of (w,\u03b1) in ( 6):\nw Tw +\u03b1 2 = 4 \u03b3(\u03b1 + 1) 2 w T w + (\u03b1 \u2212 1) 2 (\u03b1 + 1) 2 = 4\u03b1 + (\u03b1 \u2212 1) 2 (\u03b1 + 1) 2 = 1.\nHere, the second equality follows from the fact that w T w = \u03b3\u03b1. Finally, we see that v(w,\u03b1)\n= \u03b1 2 z + \u221a \u03b3 2 Xw \u2212 (y \u2212 z 2 ) 2 = \u03b1 \u2212 1 2(\u03b1 + 1) z + \u221a \u03b3 2 X 2 \u221a \u03b3(\u03b1 + 1) w \u2212 (y \u2212 z 2 ) 2 = \u03b1z + Xw \u03b1 + 1 \u2212 y 2 = v(w, \u03b1).\nThis completes the proof.\nLemma 3.3. Suppose (w,\u03b1) is feasible to (6) with\u03b1 = 1. Then (w, \u03b1), defined as\nw := \u221a \u03b3 1 \u2212\u03b1w and \u03b1 := 1 +\u03b1 1 \u2212\u03b1 , (8\n)\nis feasible to (3) and\u1e7d(w,\u03b1) = v(w, \u03b1).\nProof. We first note that (w, \u03b1) are well-defined as\u03b1 = 1.\nNext, we check feasibility of (w, \u03b1) in (2):\nw T w = \u03b3 (1 \u2212\u03b1) 2w Tw = \u03b3(1 \u2212\u03b1 2 ) (1 \u2212\u03b1) 2 = \u03b3(1 +\u03b1) 1 \u2212\u03b1 = \u03b3\u03b1.\nHere, the second equality follows from the fact thatw Tw + \u03b1 2 = 1. Finally, we check the objective value of (w, \u03b1):\n\u03b1z+Xw 1+\u03b1 \u2212 y 2 = (1+\u03b1)z+ \u221a \u03b3Xw (1\u2212\u03b1)+(1+\u03b1) \u2212 y 2 = \u03b1 2 z + \u221a \u03b3 2 Xw \u2212 (y \u2212 z/2) 2 .\nLet v * and\u1e7d * be the optimal values of ( 3) and ( 6), respectively. Now we are ready to present our main results.\nTheorem 3.4. Given Assumption 3.1, then there exists an optimal solution (w,\u03b1) to (6) with\u03b1 = 1. Moreover, (w, \u03b1), defined by (8), is an optimal solution to (3) and v * = v(w, \u03b1) =\u1e7d(w,\u03b1) =\u1e7d * .\nProof. Since the feasible region of ( 6) is compact and\u1e7d is continuous, it follows from the well-known Weierstrass theorem that there exists at least one optimal solution to (6).\nNote that if (w,\u03b1) with\u03b1 = 1 is a feasible solution in ( 6), we must havew = 0. Now we claim that (0, 1) cannot be the unique optimal solution to (6). Suppose on the contrary that (0, 1) is the unique optimal solution to (6). Let (w * , \u03b1 * ) be any optimal solution to (3). Then, from Lemma 3.2, we have\nv(w * , \u03b1 * ) =\u1e7d(w * ,\u03b1 * ),(9)\nwherew * := 2 \u221a \u03b3(\u03b1 * +1) w * ,\u03b1 * := \u03b1 * \u22121 \u03b1 * +1 < 1, and (w * ,\u03b1 * ) is feasible to (6). Since (0, 1) is the unique op- timal solution to (6), it holds that v(w * ,\u03b1 * ) >\u1e7d(0, 1) = z \u2212 y 2 . (10\n)\nOn the other hand, for any w = 0 and t > 0, the pair (tw, t 2 w T w/\u03b3) is clearly feasible to (3) with objective value v(tw, t 2 w T w/\u03b3)\n= t 2 w T w/\u03b3 1+t 2 w T w/\u03b3 z + t 1+t 2 w T w/\u03b3 Xw \u2212 y 2 \u2192 z \u2212 y 2 , as t \u2192 \u221e.(11)\nConsequently, for sufficiently large t, we must have from ( 9), ( 10) and ( 11) that v(w * , \u03b1 * ) > v(tw, t 2 w T w/\u03b3), which contradicts the optimality of (w * , \u03b1 * ) to (3).\nThe above claim shows that there exists an optimal solution (w,\u03b1) to ( 6) with\u03b1 = 1. Then, Lemma 3.3 yields v(w,\u03b1) =\u1e7d * = v(w, \u03b1) \u2265 v * with (w, \u03b1) defined in (8). Similarly, under Assumption 3.1, from Lemma 3.2, we see that v * \u2265\u1e7d * . Thus, v * =\u1e7d * . The proof is completed.\nWe remark that the other direction of above theorem also holds. That is, under Assumption 3.1, there exists an optimal solution (w, \u03b1) to (3), and, furthermore, (w,\u03b1), defined by ( 7), is optimal to (6). We also remark that using the relationship ( 8) and the equivalence of ( 2) and ( 3), an \u01eb optimal solution of the SCLS can be used to recover an \u01eb optimal solution of the SPG-LS.\nLettingL = \u221a \u03b3 2 X z 2 and r = (w \u03b1 ) , we can rewrite problem (6) in a more compact form\nmin r q(r) s.t. r T r = 1,(12)\nwhere q(r) is a least squares\nq(r) = L r \u2212 (y \u2212 z/2) 2 2 = r T Hr + 2g T r + p (13)\nwith H =L TL , g =L T (z/2\u2212y), p = (z/2\u2212y) T (z/2\u2212 y).\nIn the following of this paper, we focus on solving (12). Problem ( 12) is closed related to the well-known trust region subproblem (TRS), where the sphere constraint is replaced by a unit ball constraint. There exist various methods for solving (12) from the literature on TRS (Mor\u00e9 & Sorensen, 1983;Gould et al., 1999;Conn et al., 2000;Hazan & Koren, 2016;Ho-Nguyen & Kilinc-Karzan, 2017;Zhang et al., 2017;Carmon & Duchi, 2018), or the generalized trust region subproblem (GTRS) (Mor\u00e9, 1993;Pong & Wolkowicz, 2014;Jiang & Li, 2019;Wang & K\u0131l\u0131n\u00e7-Karzan, 2020;Wang et al., 2021a), which minimizes a (possible nonconvex) quadratic function over a (possible nonconvex) quadratic inequality or equality constraint. Note that the TRS differs from the SCLS in the constraint, and the GTRS contains the SCLS as a special case.", "publication_ref": ["b19", "b10", "b6", "b11", "b12", "b29", "b5", "b18", "b21", "b15", "b25", "b26"], "figure_ref": [], "table_ref": []}, {"heading": "Complexity and Algorithms", "text": "In this section, we first show that in theory there exists a linear time algorithm to find an \u01eb optimal solution for the SPG-LS. After that, we introduce two practically efficient algorithms to solve (12) (and thus recover a solution for the SPG-LS).\nWe point out that the linear time algorithms for the TRS (Hazan & Koren, 2016;Ho-Nguyen & Kilinc-Karzan, 2017) can be adapted to design a linear time algorithm with complexity\u00d5(N/ \u221a \u01eb) for the SCLS to achieve an \u01eb optimal solution, and the linear time algorithms for the GTRS (Jiang & Li, 2020;Wang & K\u0131l\u0131n\u00e7-Karzan, 2020;Wang et al., 2021a) indicate that the SCLS, as a special case of the GTRS, can also be solved in linear tim\u1ebd O(N/ \u221a \u01eb). Here N denotes the number of nonzero entries in the data matrix, and the logarithm in the runtime comes from the probability of success in Lanczos type methods for finding the smallest eigenvalue of a matrix. Once we obtain a solutionr such that r = 1 and q(r) \u2264 q(r * ) + \u01eb, where r * is an optimal solution of (12), we can set w \u03b1 =r and (w, \u03b1) as in ( 8). Then w is an \u01eb optimal solution to (2) because v(w, \u03b1) =\u1e7d(w,\u03b1) = q(r) and q(r * ) = v * for the same reasoning . Thus, one can obtain an \u01eb optimal solution to SPG-LS in runtime\u00d5 (N/ \u221a \u01eb) as the main cost is in solving the SCLS (12). However, in practice the computation of even an approximate minimum eigenvalue may be expensive. Instead, we will introduce two highly efficient algorithms to solve (6) without computing approximate eigenvalues. One is the Krylov subspace method (adapted to the spherically constrained case) proposed in Gould et al. (1999), and the other is the Riemannian trust region Newton (RTRNewton) method proposed in Absil et al. (2007).", "publication_ref": ["b11", "b12", "b16", "b25", "b26", "b10", "b0"], "figure_ref": [], "table_ref": []}, {"heading": "The Krylov Subspace Method", "text": "The simplest idea of the Krylov subspace method (Section 5 in Gould et al. (1999)) solves a sequence of smaller dimensional problems in the same form of (12). Specifically, define (k + 1)st Krylov subspace k+1) be an orthonormal basis produced by the generalized Lanczos process. Then assuming dim K k = k + 1, we have that Q T k HQ k is a tridiagonal matrix with Q T k Q k = I k+1 . Each iteration of the Krylov subspace method solves the following subproblem (adapted to the spherical constrained case) Gould et al. (1999) proved that the above subproblem can be solved efficiently in O(k) flops, if we use a safeguarded Newton's method, where the most expensive cost is k matrix-vector products for H t g, with t \u2208 [k]. We remark that though Gould et al. (1999) considered the case r \u2264 1, the two cases r \u2264 1 and r = 1 are essentially the same if the inequality in the TRS is active, which occur if (H \u2212 \u03bb min I) \u2020 g > 1 2 . Here (\u2022) \u2020 denotes the Moore-Penrose pseudoinverse of a matrix (\u2022).\nK k := {g, Hg, H 2 g, . . . , H k g}. Let Q k = [q 0 , q 1 , . . . , q k ] \u2208 R (n+1)\u00d7(\nmin r\u2208K k , r =1 r T Hr + 2g T r + p.(14)\nTo achieve better practical performance, Gould et al. (1999) proposed the generalized Lanczos trust-region (GLTR) method, which is an efficient implementation of the above Krylov subspace method. Based on an efficient nested restarting strategy,  further proposed a nested Lanczos method for TRS (LTRSR), which is an improvement for GLTR.\nThe convergence behavior of the Krylov subspace method is also well analyzed in the literature. The optimality condition of problem ( 12) is characterized as follows (adapted from Chapter 7 in Conn et al. (2000))\n(H + \u03bb * I)r * = \u2212g, H + \u03bb * I 0, r * = 1,(15)\nwhere \u03bb * is the corresponding Lagrangian multiplier. It is shown that there always exists an optimal solution r * and a unique Lagrangian multiplier \u03bb * , because different \u03bb * s yield different values for r * , contradicting r * = 1.", "publication_ref": ["b10", "b10", "b10", "b10", "b6"], "figure_ref": [], "table_ref": []}, {"heading": "Define", "text": "\u03ba = \u03bb max + \u03bb * \u03bb min + \u03bb * ,(16)\nfor \u03bb * \u2265 \u2212\u03bb min and use the convention 1 0 = \u221e. Here \u03ba is regarded as the condition number of ( 12) (Carmon & Duchi, 2018).  and Carmon & Duchi (2018) demonstrated that when \u03ba < \u221e, the Krylov subspace method satisfies\nf (r k ) \u2212 f (r * ) \u2264 O(exp(\u2212k/ \u221a \u03ba)),\nwhere r k is an optimal solution of ( 14), and r * is an optimal solution for (12). Carmon & Duchi (2018) further proved that for all cases including \u03bb * = \u2212\u03bb min , a variant of the Krylov subspace method where g is perturbed with random vector will output a solution r k satisfies\nf (r k ) \u2212 f (r * ) \u2264\u00d5(1/k 2 ).\nfor the SCLS (adapted from their analysis for the TRS). This indeed gives another\u00d5(N/ \u221a \u01eb) time algorithm for solving the SPG-LS up to \u01eb tolerance; see also Wang et al. (2021a) for extensions of this idea to the GTRS.\nNext we relate the existing convergence results with problem (12). Proof. Note that if \u03bb * = \u2212\u03bb min , then the first equation in (15) implies that r * = \u2212(H + \u03bb * I) \u2020 g and thus the assumption in the proposition implies r * > 1. However, this violates the constraint r * = 1. Therefore we must have \u03bb * > \u2212\u03bb min and thus \u03ba < \u221e.\nIn fact, we checked the data in the experiments in Section 5 and found that r > 1 always holds in real-world datasets and our synthetic datasets.", "publication_ref": ["b5", "b5", "b5", "b26"], "figure_ref": [], "table_ref": []}, {"heading": "The Riemannian Trust Region Newton (RTRNewton) Method", "text": "The feasible set in Problem ( 12) forms a unit sphere S n = {r \u2208 R n+1 : r T r = 1}. When S n is endowed with the Euclidean metric v, u = v T u, the unit sphere is a Riemannian manifold (Absil et al., 2008). Therefore, the RTRNewton method proposed in Absil et al. (2007) ", "publication_ref": ["b1", "b0"], "figure_ref": [], "table_ref": []}, {"heading": "can be", "text": "Algorithm 1 A Riemannian Trust Region Newton Method\nRequire: Initial iterate r 0 , real numbers \u2206 > 0, \u2206 0 \u2208 (0, \u2206), c \u2208 (0, 0.25), \u03c4 1 \u2208 (0, 1), and \u03c4 2 > 1;\n1: for k = 0, 1, 2, . . . do 2: Obtain s k \u2208 R d by (approximately) solving s k \u2248 argmin s 2\u2264\u2206k m k (s),(17)\nwhere\nm k (s) = q(r k ) + s T grad q(r k ) + 1 2 s T Hess q(r k )[s]\n, grad q denotes the Riemannian gradient of q in ( 18), and Hess q denotes the Riemannian Hessian of q in (19);\n3: Set \u03c1 k \u2190 q(r k )\u2212q(Rr k (s k )) m k (0)\u2212m k (s k )\n, where R denotes the retraction in (20);\n4: if \u03c1 k > c then 5: r k+1 \u2190 R r k (s k ); 6: else 7: r k+1 \u2190 r k ; 8: end if 9: if \u03c1 k > 3 4 then 10: If s k \u2265 0.8\u2206 k , then \u2206 k+1 \u2190 min(\u03c4 2 \u2206 k , \u2206); otherwise \u2206 k+1 \u2190 \u2206 k ; 11: else if \u03c1 k < 0.1 then 12: \u2206 k+1 \u2190 \u03c4 1 \u2206 k ;\n13: else 14:\n\u2206 k+1 \u2190 \u2206 k ;\n15:\nend if 16: end for used. The RTRNewton method for Problem (6) is summarized in Algorithm 1.\nAlgorithm 1 relies on the notion of Riemannian gradient, Riemannian Hessian, and retraction. We refer to Absil et al. (2008) for their rigorous definitions. Here, we give the Riemannian gradient, the Riemannian Hessian for Problem (12) and the used retraction.\nThe Riemannian gradient of q is given by grad q(r) = P TrS n \u2207q(r) = (I \u2212 rr T )(2Hr + 2g), (18) where P TrS n denotes the orthogonal projection onto the tangent space at r with T r S n = {s : s T r = 0}, and \u2207q(r) denotes the Euclidean gradient of q, i.e., \u2207q(r) = 2Hr + 2g. The action of the Riemannian Hessian of q at r along v \u2208 T r S n is given by\nHess q(r)[v] =P TrS n (\u2207 2 q(r)v \u2212 vr T \u2207q(r)), =(I \u2212 rr T )(2Hv \u2212 2vr T (Hr + g)),(19)\nwhere \u2207 2 q(r) = 2H denotes the Euclidean Hessian of q at r. The retraction R that we use is given by\nR r (v) = r + v r + v ,(20)\nwhere r \u2208 S n and v \u2208 T r S n .\nThe subproblem ( 17) is approximately solved by the truncated conjugate gradient method. We use the implementations in ROPTLIB (Huang et al., 2018).\nThe global convergence and local superlinear convergence rate of RTRNewton have been established by Theorem 7.4.4 and Theorem 7.4.11 of Absil et al. (2008). We state the results in the theorem below.\nTheorem 4.2. Let {r k } be a sequence of iterates generated by Algorithm 1. It follows that\nlim k\u2192\u221e grad q(r k ) = 0.\nSuppose r * is a nondegenerate local minimizer of q, i.e., grad q(r * ) = 0 and Hess q(r * ) is positive definite. Then there exists c > 0 such that for all sequence {r k } generated by Algorithm 1 converging to r * , there exists K > 0 such that for all k > K,\ndist(r k+1 , r * ) \u2264 c dist(r k , r * ) 2 . (21\n)\nThe proof for the theorem is deferred to Appendix A. The global convergence rate has also been established where the iteration complexity is O \u01eb \u22122 g for grad q(x) \u2264 \u01eb g . We refer interested readers to Theorem 3.9 of Boumal et al. (2019).", "publication_ref": ["b1", "b13", "b1", "b3"], "figure_ref": [], "table_ref": []}, {"heading": "Time complexity comparisons", "text": "In this section, we give a theoretical worst case time complexity of different methods for solving the SPG-LS. First we point out that the RTRNewton cannot be guaranteed to converge to the global minimum of SPG-LS. In the worst case, the RTRNewton needs to solve O \u01eb \u22122 g many trust region subproblems. This means the time complexity is much worse than the Krylov subspace method (Carmon & Duchi, 2018) studied in Section 4.1.\nNext we compare the time complexity of the Krylov subspace method and the SOCP method. In the case of dealing with a sparse data matrix, the time complexity of the Krylov subspace method is\u00d5 (N/ \u221a \u01eb), where N is the number of nonzero entries in the data matrix X. Here, we use the fact that the cost of the matrix-vector product in the Krylov subspace method is O(N ) as we can compute Hr byL T (Lr) for any given r \u2208 R n . If \u03ba < \u221e, then the complexity can be further improved to O(N log(1/\u01eb)).\nIn the dense case with m = O(n), the complexity is O (N/ \u221a \u01eb) and can be improved to O(n 2 log(1/\u01eb) if \u03ba < \u221e. Next we consider the time complexity for the SOCP method, which consists of the time complexity of formulating the matrix A, the spectral decomposition and the IPM for solving the SOCP. Since the spectral decomposition and the IPM can not benefit much from the data sparsity, we do not distinguish the sparse and dense cases for the SOCP method. Particularly, the cost of formulating the matrix A is lower bounded by O(N ) and upper bounded by O(n 2 ) and the spectral decomposition takes O (n \u03c9 ) flops for some \u03c9 satisfying 2 < \u03c9 < 3 (Demmel et al., 2007). Meanwhile, the iteration complexity for solving the SOCP reformulation is O( \u221a n log(1/\u01eb)) according to Monteiro & Tsuchiya (2000). As per iteration in cost in the IPM is O(n), the total cost of the IPM is O n 3 2 log(1/\u01eb) . Therefore the worst case complexity of the SOCP method is O n w + n\n3 2 log(1/\u01eb) .\nTheortically, it is hard to compare the Krylov subspace method and the SOCP method as the result depends on \u03ba, N , w and \u01eb. In practice, it usually holds that \u03ba < \u221e and the spectral decomposition step in the SOCP methods usually costs O(n 3 ). In fact, our experiments show that the spectral decomposition step often needs more time than the IPM for the SOCP. Thus, the Krylov subspace method, which can effectively utilize the data sparsity, is much faster than the SOCP approach especially for solving large-scale problems.", "publication_ref": ["b5", "b8", "b17"], "figure_ref": [], "table_ref": []}, {"heading": "Experiment Results", "text": "In this section, we present numerical results on both synthetic and real-world datasets to verify the superiority of our proposed reformulation in terms of computational costs. We refer a nested Lanczos Method for TRS (LTRSR)  to perform the GLTR method, and use the implementation of Riemannian trust-region Newton (RTRNewton) (Absil et al., 2007) from Riemannian Manifold Optimization Library (ROPTLIB) (Huang et al., 2018). Similar as the setting in Wang et al. (2021b), we compare the running time of above two methods with the SDP and SOCP approaches in Wang et al. (2021b), averaged over 10 trials, to evaluate the performance of our new reformulation. All the four methods solve the SDP, SOCP or the SCLS reformulations to their default precision and the solutions to the SPG-LS are recovered accordingly.\nAll simulations are implemented using MATLAB R2021b on a PC running Windows 10 Intel(R) Xeon(R) E5-2650 v4 CPU (2.2GHz) and 64GB RAM. We report the results of two real datasets and six synthetic datasets and defer other results to the supplementary material. In all following tests, the parameter \u03b3 is set as 0.1.", "publication_ref": ["b0", "b13", "b27", "b27"], "figure_ref": [], "table_ref": []}, {"heading": "Real-world Dataset", "text": "We first compare four methods on the red wine dataset (Cortez et al., 2009), which consist of 1599 instances each with 11 features. The output label is a physiochemical measurement ranged from 0 to 10, where a higher score means that the corresponding wine sample has better quality. Wine producers would like to manipulate the data to fool the learner to predict a higher score when the raw label is smaller than some threshold t. We consider the case that there are two kinds of providers A modest and A severe , where the details of the manipulation are set the same as Wang et al. (2021b). We also compare four methods on the residental building dataset 3 from the UCI data repository (Dua & Graff, 2017) as well. The building dataset includes 372 samples with 107 features. Each feature reflects information of a certain session such as project date, physical and financial elements. The output label is the sale prices to real estate single-family residential apartments. We consider a scenario where the seller wants to manipulate the price to higher level. As a buyer, our task is to predict the fair price under fake data. We still consider two types of sellers: A modest with \u03b4 = 20 and A severe with \u03b4 = 40.\nThe computational time for both datasets is reported in Figures 1 and 2. It show that LTRSR method outperforms others and follows by the SOCP and RTRNewton. One can also observe that RTRNewton is even more expensive than 3 https://archive.ics.uci.edu/ml/datasets/Residential+Building+Data+Set the SDP approach in Figure 1. The main reason is that in the red wine dataset, the number of features n is quite small (n = 11). Thus, the spectral decomposition step, as well as the iterations of the interior point method, in the SOCP approach is cheap.\nWe then report the relative errors of objective values (MSEs) of the SOCP method and our methods in Table 1 for red wine and residental building datasets. Indeed, all the methods have a very high accuracy as the relative errors are only up to 3.37e-5. More MSE comparisons can be found in Appendix 2.1. ", "publication_ref": ["b7", "b27", "b9"], "figure_ref": [], "table_ref": ["tab_0"]}, {"heading": "Synthetic Dataset", "text": "From the previous subsection, we also see that SOCP, LTRSR and RTRNewton are much faster than the SDP approach. To have a comprehensive comparison on wallclock time among SOCP, LTRSR and RTRNewton, we test these methods on synthetic experiments.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "DENSE DATA", "text": "We first conduct experiments on dense synthetic dataset.\nTo have better validation of the effectiveness of our proposed reformulation, we use the same artificial dataset in Wang et al. (2021b), which employs make regression function in scikit-learn (Pedregosa et al., 2011) with setting the noise as 0.1 and other parameters as default.\nTable 2 summarises the comparison of time on different scales with m = ln, l \u2208 {0.5, 1, 2}. Here, \"SOCP\" represents total time needed for the SOCP approach (including \"eig time\"), \"eig time\" represents the spectral decomposition time in the SOCP approach, \"RTRNew\" represents the RTRNewton method, \"LTRSR\" represents the LTRSR method, \"Ratio\" represents the ratio of times of SOCP method and LTRSR.\nFrom Table 2, we find that in large scale setting, the two methods RTRNewton and LTRSR are more efficient. LTRSR is of orders faster than the other two methods.\nFrom the \"Ratio\" values we also see that the time cost of SOCP approach is several tens times of that of LTRSR. We also observe that the spectral decomposition time in formulating SOCP is expensive and takes about 40% of total time. Indeed, the spectral decomposition time becomes ", "publication_ref": ["b27", "b20"], "figure_ref": [], "table_ref": ["tab_1", "tab_1"]}, {"heading": "SPARSE DATA", "text": "To further show the efficacy of our proposed reformulation, we conduct experiments on synthetic data with high feature dimension and various sparsity. We apply the sprandn function in MATLAB to obtain the data matrix X \u2208 R m\u00d7n , whose i-th row is input vector {x i } m i=1 . The noise measure- Wang et al. (2021b), we set the fake output label as z i = max{y i , y 0.25 }.\nments {\u03be i } m i=1 i.i.d from the uniform distribution [0, 0.5]. Then the output label {y i } m i=1 via y i = x T i \u03b2 + \u03be i . Fol- lowing\nTable 3 summarises time comparisons on synthetic datasets with different sparsity and different dimension for m = 0.5n. From these tables, we find that LTRSR and RTRNewton perform much better than the dense case, and their superiority over the SOCP approach becomes larger. This is mainly because both methods are the matrix free methods that require only matrix vector products in each iteration. However, the SOCP do not benefit from sparsity as well as the other two methods. We find that, by comparing the \"eig time\" for different instances with the same dimension but different sparsity, the \"eig time\" dominates the time of SOCP approach as the spectral decomposition cannot utilize the sparsity of the data. From the \"Ratio\" values, we find that the outperformance of LTRSR grows considerably when the sparsity and problem size increase. In the case of (m, n) = (15000, 30000) and sparsity = 0.0001, LTRSR takes up to 26,000+ times faster than the SOCP approach. Moreover, our LTRSR takes less than 0.05 second for all the instances with sparsity = 0.0001. More reports on relative errors of all methods are reported in Appendix 2.2.", "publication_ref": ["b27"], "figure_ref": [], "table_ref": ["tab_2"]}, {"heading": "Conclusion", "text": "We propose an SCLS reformulation for the SPG-LS and show its optimal solution can be used to recover an optimal solution of the SPG-LS. We further show that an \u01eb optimal solution of the SPG-LS can be also recovered from an \u01eb optimal solution of the SCLS. Moreover, such an \u01eb optimal solution obtained in runtime\u00d5(N/ \u221a \u01eb). We also introduce two practical efficient methods, LTRSR and RTRNewton, for solving the SCLS. Experiments show that the SCLS approach is much faster than the existing best approach. In particular, the performance of the LTRSR dominates both RTRNewton and SOCP methods. NSFC 12001455. Rujun Jiang is partly supported by NSFC 12171100 and 72161160340, and Natural Science Foundation of Shanghai 22ZR1405100. Xudong Li is partly supported by the \"Chenguang Program\" by Shanghai Education Development Foundation and Shanghai Municipal Education Commission 19CG02, and the Shanghai Science and Technology Program 21JC1400600. Table 4 shows the comparison of wall-clock time on different scales with m = ln, l \u2208 {0.5, 1, 2}, which is similar to the case of \u03b3 = 0.1. We observed that both SCLS approaches are faster than the SOCP approach. Moreover, all the LTRSR is less than 6 seconds while the SOCP can take up to about 110 seconds. ", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_3"]}, {"heading": "SPARSE DATA", "text": "We proceed to perform experiments on large-scale sparse dataset of various scales m = ln, l \u2208 {1, 2, 3} with different sparsity. All the other settings are the same as in Section 5.2.2.\nFrom Table 5, we observed the great superiority of our SCLS reformulation since all the LTRSR and RTRNewton method faster than SOCP method. LTRSR is of several orders faster than the SOCP approach, especially when the sparsity and dimension grow. The spectral time of decomposition in formulating SOCP is quite expensive as the problem size grows. In the case (m, n) = (90000, 30000), sparsity = 0.01, the decomposition time is up about 1000 seconds, while the LTRSR method only takes about 22 seconds to solve the problem.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C. Relative Error", "text": "This section reports relative errors of function values and MSEs between SOCP and our methods for all our experiments in Tables 6, 7, 8 and 9.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_5"]}, {"heading": "Real-world Dataset", "text": "In Tables 6 and 7, we show the relative errors of MSEs on training sets and test sets, respectively. Here, abbreviations \"Insur\" represents insurance dataset, \"Build\" represents building dataset, \"f\" represents the function value of related methods and \"M\" represents its MSE. In Table 6, We observe that LTRSR is more accurate than SOCP as its relative error preserves positive. Indeed, all the methods have a very high accuracy as the relative errors are only up to to 3.37e-5. Table 7 shows that all methods have similar test accuracy as the relative errors of the test MSEs of all the methods are up to 5.27e-4.        9 summarises relative error of objective values in synthetic dataset with different sparsity. Similar to the previous cases, both of our methods have high accuracy in terms of MSEs. These consistent results further prove the validity of our SCLS reformulation.  ", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_5", "tab_5", "tab_9"]}, {"heading": "Acknowledgements", "text": "Wen Huang is partly supported by the Fundamental Research Funds for the Central Universities 20720190060 and", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "", "text": "Proof. We only need to verify the assumptions of Theorem 7.4.4 and Theorem 7.4.11 of Absil et al. (2008).\nBy definition, the function q is bounded below. Since the unit sphere is a compact manifold, we have that the Riemannian Hessian Hess q(r) is bounded above for any r \u2208 S n , that q \u2022 R is radially Lipschitz continuously differentiable, and that q is Lipschitz continuously differentiable by Proposition 7.4.5 and Corollary 7.4.6 of Absil et al. (2008). The implementation in ROPTLIB for the subproblem ( 17) is Algorithm 11 of Absil et al. (2008) with \u03b8 = 1. Therefore, the Cauchy decrease inequality is satisfied. It follows that all the assumptions of Theorem 7.4.4 are satisfied.\nSince Retraction (20) is second order, the assumption of (7.36) in Theorem 7.4.11 of Absil et al. (2008) holds with \u03b2 H = 0. Since the function q is C \u221e and the manifold is compact, the assumption of (7.37) in Theorem 7.4.11 of Absil et al. (2008) holds. The local quadratic convergence rate in (21) thus follows.", "publication_ref": ["b1", "b1", "b1", "b1", "b1"], "figure_ref": [], "table_ref": []}, {"heading": "B. Additional Experiments", "text": "In this section, we provide additional numerical results to further show the efficiency of our proposed reformulation.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Real-world Dataset", "text": "We demonstrate the speed of our methods on two other real-world datasets, the insurance dataset 4 and the blogfeedback dataset 5 . Similar as the setting in previous section, we compare the wall-clock time of RTRNewton (Absil et al., 2007) and LTRSR  approaches with the SDP and SOCP methods proposed in Wang et al. (2021b).\nWe still apply four methods on the insurance dataset that has 1,338 instances with 7 features. Each feature shows information on certain aspects such as age, sex, bmi and region. The output labels are individual medical costs by buying health insurance. For model accuracy, we transform categorical features such as sex into a one-hot vector. We assume that the individuals incline to modify self-related data to reduce their insurance costs. Formally, the individual's desired outcome can be defined as z i = max{y i + \u03b4, 0}. We have two types of individual: A modest with \u03b4 = \u2212100 and A severe with \u03b4 = \u2212300. All the hyperparameters are the same as those in Wang et al. (2021b). As an insurer, our goal is to select a good price model to predict the insurance costs as true as possible.\nTo further illustrate the effectiveness of our new reformulation, we compare four methods on the blogfeedback dataset. The blog dataset contains 52,397 samples each with 281 features processed from raw feedback materials on the Internet. Each feature represents information of a certain session. The output label is the number of comments. As a learner, our task is to predict the future comments of blog. Similarly, we assume that the true output label y would be modified by data providers in order to achieve the goal of increasing blog comments. For example, public media intend to manipulate data to add the blog comments and enhance its news popularity. Formally, we define the altered label as z i = y i + \u03b4. We still have two types of data providers: A modest with \u03b4 = 5 and A severe with \u03b4 = 10.\nThe wall-clock time comparison can be found in Figure 3. Similar to the previous cases, LTRSR outperforms other approaches. However, as the dimension in this problem is too small, the comparison of the other three methods does not match their performance for large scale problems.", "publication_ref": ["b0", "b27", "b27"], "figure_ref": [], "table_ref": []}, {"heading": "Synthetic Dataset", "text": "To further demonstrate the efficiency and adaptiveness to high dimension problems of our proposed reformulation, we conduct experiments on more synthetic datasets with different hyperparameters and various dimensions and sparsity.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Trust-region methods on riemannian manifolds", "journal": "Foundations of Computational Mathematics", "year": "2007", "authors": "P.-A Absil; C G Baker; K A Gallivan"}, {"ref_id": "b1", "title": "Optimization algorithms on matrix manifolds", "journal": "Princeton University Press", "year": "2008", "authors": "P.-A Absil; R Mahony; R Sepulchre"}, {"ref_id": "b2", "title": "Optimal learning from verified training data", "journal": "NeurIPS", "year": "2020", "authors": "N Bishop; L Tran-Thanh; E Gerding"}, {"ref_id": "b3", "title": "Global rates of convergence for nonconvex optimization on manifolds", "journal": "IMA Journal of Numerical Analysis", "year": "2019", "authors": "N Boumal; P.-A Absil; C Cartis"}, {"ref_id": "b4", "title": "Stackelberg games for adversarial prediction problems", "journal": "", "year": "2011", "authors": "M Br\u00fcckner; T Scheffer"}, {"ref_id": "b5", "title": "Analysis of krylov subspace solutions of regularized nonconvex quadratic problems", "journal": "", "year": "2018", "authors": "Y Carmon; J C Duchi"}, {"ref_id": "b6", "title": "Trust region methods. SIAM", "journal": "", "year": "2000", "authors": "A R Conn; N I Gould; P L Toint"}, {"ref_id": "b7", "title": "Modeling wine preferences by data mining from physicochemical properties", "journal": "Decision support systems", "year": "2009", "authors": "P Cortez; A Cerdeira; F Almeida; T Matos; J Reis"}, {"ref_id": "b8", "title": "Fast linear algebra is stable", "journal": "Numerische Mathematik", "year": "2007", "authors": "J Demmel; I Dumitriu; O Holtz"}, {"ref_id": "b9", "title": "UCI machine learning repository", "journal": "", "year": "2017", "authors": "D Dua; C Graff"}, {"ref_id": "b10", "title": "Solving the trust-region subproblem using the lanczos method", "journal": "SIAM Journal on Optimization", "year": "1999", "authors": "N I Gould; S Lucidi; M Roma; P L Toint"}, {"ref_id": "b11", "title": "A linear-time algorithm for trust region problems", "journal": "Mathematical Programming", "year": "2016", "authors": "E Hazan; T Koren"}, {"ref_id": "b12", "title": "A second-order cone based approach for solving the trust-region subproblem and its variants", "journal": "SIAM Journal on Optimization", "year": "2017", "authors": "N Ho-Nguyen; F Kilinc-Karzan"}, {"ref_id": "b13", "title": "Roptlib: an object-oriented c++ library for optimization on riemannian manifolds", "journal": "ACM Transactions on Mathematical Software (TOMS)", "year": "2018", "authors": "W Huang; P.-A Absil; K A Gallivan; P Hand"}, {"ref_id": "b14", "title": "The polynomial hierarchy and a simple model for competitive analysis. Mathematical programming", "journal": "", "year": "1985", "authors": "R G Jeroslow"}, {"ref_id": "b15", "title": "Novel reformulations and efficient algorithms for the generalized trust region subproblem", "journal": "SIAM Journal on Optimization", "year": "2019", "authors": "R Jiang; D Li"}, {"ref_id": "b16", "title": "A linear-time algorithm for generalized trust region subproblems", "journal": "SIAM Journal on Optimization", "year": "2020", "authors": "R Jiang; D Li"}, {"ref_id": "b17", "title": "Polynomial convergence of primal-dual algorithms for the second-order cone program based on the mz-family of directions", "journal": "Mathematical programming", "year": "2000", "authors": "R D Monteiro; T Tsuchiya"}, {"ref_id": "b18", "title": "Generalizations of the trust region problem", "journal": "", "year": "1993", "authors": "J J Mor\u00e9"}, {"ref_id": "b19", "title": "Computing a trust region step", "journal": "SIAM Journal on scientific and statistical computing", "year": "1983", "authors": "J J Mor\u00e9; D C Sorensen"}, {"ref_id": "b20", "title": "Scikit-learn: Machine learning in python", "journal": "Journal of machine Learning research", "year": "2011", "authors": "F Pedregosa; G Varoquaux; A Gramfort; V Michel; B Thirion; O Grisel; M Blondel; P Prettenhofer; R Weiss; V Dubourg"}, {"ref_id": "b21", "title": "The generalized trust region subproblem. Computational optimization and applications", "journal": "", "year": "2014", "authors": "T K Pong; H Wolkowicz"}, {"ref_id": "b22", "title": "Adjustment of an inverse matrix corresponding to a change in one element of a given matrix", "journal": "The Annals of Mathematical Statistics", "year": "1950", "authors": "J Sherman; W J Morrison"}, {"ref_id": "b23", "title": "Protecting location privacy: optimal strategy against localization attacks", "journal": "", "year": "2012", "authors": "R Shokri; G Theodorakopoulos; C Troncoso; J.-P Hubaux; Le Boudec; J.-Y "}, {"ref_id": "b24", "title": "A stackelberg game for distributed formation of businessdriven services communities", "journal": "Expert Systems with Applications", "year": "2016", "authors": "O A Wahab; J Bentahar; H Otrok; A Mourad"}, {"ref_id": "b25", "title": "The generalized trust region subproblem: solution complexity and convex hull results", "journal": "", "year": "2020", "authors": "A L Wang; F K\u0131l\u0131n\u00e7-Karzan"}, {"ref_id": "b26", "title": "Implicit regularity and linear convergence rates for the generalized trustregion subproblem", "journal": "", "year": "2021", "authors": "A L Wang; Y Lu; F Kilinc-Karzan"}, {"ref_id": "b27", "title": "Fast algorithms for stackelberg prediction game with least squares loss", "journal": "PMLR", "year": "2021", "authors": "J Wang; H Chen; R Jiang; X Li; Z Li"}, {"ref_id": "b28", "title": "A nested lanczos method for the trust-region subproblem", "journal": "SIAM Journal on Scientific Computing", "year": "2018", "authors": "L.-H Zhang; C Shen"}, {"ref_id": "b29", "title": "On the generalized lanczos trust-region method", "journal": "SIAM Journal on Optimization", "year": "2017", "authors": "L.-H Zhang; C Shen; R.-C Li"}, {"ref_id": "b30", "title": "Error bounds of the lanczos approach for the trust-region subproblem", "journal": "Frontiers of Mathematics in China", "year": "2018", "authors": "L.-H Zhang; W H Yang; C Shen; J Feng"}, {"ref_id": "b31", "title": "Modeling adversarial learning as nested stackelberg games", "journal": "Springer", "year": "2016", "authors": "Y Zhou; M Kantarcioglu"}, {"ref_id": "b32", "title": "A survey of game theoretic approach for adversarial machine learning", "journal": "Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery", "year": "2019", "authors": "Y Zhou; M Kantarcioglu; B Xi"}], "figures": [{"figure_label": "", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Proposition 4.1. If (H \u2212 \u03bb min I) \u2020 g > 1, we must have \u03bb * > \u2212\u03bb min and thus f (r k ) \u2212 f (r * ) \u2264 O(exp(\u2212k/ \u221a \u03ba)),for \u03ba defined in (16).", "figure_data": ""}, {"figure_label": "12", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 1 .Figure 2 .12Figure 1. Comparison of four different algorithms on the red wine dataset. The left and right plots correspond to Amodest and Asevere, respectively.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 3 .3Figure3. Performance comparison between different algorithms on the insurance and blog dataset. The left two plots correspond to the wall-clock time comparison of insurance dataset generated by Amodest and Asevere, whilst the right two plots correspond to the wall-clock time comparison of blog dataset generated by Amodest and Asevere.", "figure_data": ""}, {"figure_label": "M", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Dataset ( MMSOCP \u2212 M LTRSR )/|M SOCP | (M SOCP \u2212 M RTRNew )/|M SOCP | Dataset (M SOCP \u2212 M LTRSR )/|M SOCP | (M SOCP \u2212 M RTRNew )/|M SOCP | 1.99E-07 -9.55E-07 4.31E-06 1.74E-07 -9.54E-07 3.99E-06 Insur Modest 1.05E-05 7.69E-07 4.21E-05 1.02E-05 -7.09E-07 4.28E-05 Wine Severe 2.03E-07 -1.79E-07 2.57E-06 2.64E-07 -4.55E-07 2.79E-06 Insur Severe 2.43E-06 -3.36E-07 1.01E-05 2.45E-06 -3.27E-07 1.01E-05 Build Modest -4.52E-06 -1.25E-04 1.23E-04 -1.25E-04 -5.27E-04 5.01E-04 Blog Modest -2.59E-09 -5.66E-07 2.99E-07 1.92E-09 -5.62E-07 3.03E-07 Build Severe 2.65E-07 -2.63E-05 2.54E-05 8.27E-06 -8.02E-05 1.47E-04 Blog Severe -2.06E-08 -8.12E-07 3.24E-07 -5.02E-09 -7.81E-07 3.06E-07 2. Synthetic Dataset 2.1. DENSE DATA", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "= 2n 1.01E-09 9.58E-11 3.41E-09 1.01E-09 9.58E-11 3.41E-09 m = 2n 1.51E-05 5.39E-08 4.60E-05 1.51E-05 5.39E-08 4.60E-05 m = n 2.26E-08 3.37E-11 1.34E-07 2.26E-08 3.36E-11 1.34E-07 m = n 2.11E-06 3.26E-07 7.40E-06 2.11E-06 3.26E-07 7.40E-06 m = 0.5n 8.27E-09 2.54E-12 4.82E-08 8.27E-09 2.05E-12 4.82E-08 m = 0.5n 2.21E-06 3.44E-07 6.87E-06 2.21E-06 3.44E-07 6.87E-06 2.2. SPARSE DATA Table", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "m= 3n 1.24E-09 1.48E-11 5.58E-09 1.24E-09 1.45E-11 5.58E-09 m = 3n 3.98E-09 5.27E-11 1.19E-08 3.97E-09 3.19E-11 1.19E-08 m = 2n 7.49E-11 3.53E-13 1.55E-10 7.47E-11 3.20E-13 1.54E-10 m = 2n 2.25E-09 2.62E-12 4.88E-09 2.24E-09 -3.51E-12 4.87E-09 m = n 9.10E-10 9.93E-12 2.01E-09 9.10E-10 9.73E-12 2.01E-09 m = n 7.95E-09 1.83E-10 2.34E-08 7.94E-09 1.16E-10 2.34E-08 m = 0.5n 3.06E-10 3.81E-12 6.60E-10 3.06E-10 3.70E-12 6.60E-10 m = 0.5n 3.07E-09 7.96E-13 6.28E-09 3.06E-09 -4.52E-12 6.28E-09 sparsity = 0.001\u03b3 = 0.1 (f SOCP \u2212 f LTRSR )/|f SOCP | (f SOCP \u2212 f RTRNew )/|f SOCP | \u03b3 = 0.01 (f SOCP \u2212 f LTRSR )/|f SOCP | (f SOCP \u2212 f RTRNew )/|fSOCP | 1.36E-09 5.73E-11 2.58E-09 1.36E-09 5.64E-11 2.58E-09 m = 3n 1.92E-08 5.04E-10 8.89E-08 1.92E-08 5.04E-10 8.89E-08 m = 2n 1.66E-09 6.00E-11 5.06E-09 1.66E-09 5.91E-11 5.06E-09 m = 2n 5.14E-08 9.80E-12 2.05E-07 5.14E-08 9.74E-12 2.05E-07 m = n 5.76E-10 1.53E-09 1.13E-12 6.19E-09 1.53E-09 -2.03E-13 m = n 1.96E-08 1.14E-10 4.83E-08 1.96E-08 1.14E-10 4.83E-08 m = 0.5n 1.90E-09 1.02E-10 6.68E-09 1.90E-09 1.01E-10 6.68E-09 m = 0.5n 4.42E-08 4.91E-09 1.34E-07 4.42E-08 4.91E-09 1.34E-07 sparsity = 0.01 \u03b3 = 0.1 (f SOCP \u2212 f LTRSR )/|f SOCP | (f SOCP \u2212 f RTRNew )/|f SOCP | \u03b3 = 0.01 (f SOCP \u2212 f LTRSR )/|f SOCP | (f SOCP \u2212 f RTRNew )/|f SOCP | 2.19E-08 2.64E-11 1.70E-08 2.19E-08 2.63E-11 1.70E-08 m = 3n 1.05E-07 2.15E-09 2.51E-07 1.05E-07 2.15E-09 2.51E-07 m = 2n 8.23E-08 8.23E-08 3.74E-07 1.02E-07 4.80E-11 3.74E-07 m = 2n 6.94E-07 3.99E-10 3.10E-06 6.94E-07 3.99E-10 3.10E-06 m = n 1.27E-08 9.14E-10 3.37E-08 1.27E-08 9.14E-10 3.37E-08 m = n 2.21E-06 7.78E-09 1.00E-05 2.21E-06 7.78E-09 1.00E-05 m = 0.5n 1.90E-08 3.52E-12 4.50E-08 1.90E-08 3.45E-12 4.50E-08 m = 0.5n 6.52E-06 6.40E-08 2.95E-05 6.52E-06 6.40E-08 2.95E-05", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "Relative error of objective valuesDataset (f SOCP \u2212 f LTRSR )/|f SOCP | (f SOCP \u2212 f RTRNew )/|f SOCP |", "figure_data": "AVGMINMAXAVGMINMAXWine Modest 6.17E-10 3.94E-12 4.23E-09 -8.26E-10 -4.66E-09 3.62E-09Wine Severe 1.32E-10 3.39E-12 1.84E-09 -8.30E-11 -4.07E-10 1.80E-09Build Modest 1.49E-07 1.93E-09 5.91E-07 -2.19E-05 -3.37E-05 -1.28E-05Build Severe 3.02E-08 4.02E-10 1.25E-07 -1.96E-06 -3.06E-06 -1.14E-06"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "Time (seconds) on synthetic data without sparsity", "figure_data": "m = 2nmnSOCP (eig time) RTRNew LTRSR Ratio2000 10000.585 (0.064) 0.7430.034 174000 20001.957 (0.317) 2.4590.177 118000 400010.693 (2.758) 9.2690.931 1112000 600029.304 (9.444) 18.824 2.120 1416000 8000 58.561 (21.634) 40.711 3.982 1520000 10000 114.376 (49.754) 59.768 6.099 19m = nmnSOCP (eig time) RTRNew LTRSR Ratio1000 10000.454 (0.065) 0.5940.017 272000 20002.104 (0.325) 2.6000.097 224000 400010.795 (2.698) 6.9580.478 236000 600028.391 (9.481) 17.835 1.083 268000 8000 55.263 (21.555) 35.510 2.011 2710000 10000 97.383 (40.091) 58.009 3.065 32m = 0.5nmnSOCP (eig time) RTRNew LTRSR Ratio500 10000.536 (0.059) 0.5230.022 241000 20001.748 (0.309) 1.4320.057 312000 40009.928 (2.526) 6.9320.251 403000 600027.230 (8.848) 19.179 0.532 514000 8000 54.174 (20.258) 28.953 0.928 585000 10000 94.548 (37.771) 52.756 1.558 61much larger as n increases, which is also evidenced fromour experiments for the sparse data setting in Table 3 below."}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Time (seconds) on synthetic data with sparsity", "figure_data": "sparsity = 0.01mnSOCP (eig time) RTRNew LTRSR Ratio5000 1000071.601 (39.432) 13.124 0.225 3187500 15000 217.529 (120.456) 26.551 0.534 40710000 20000 513.751 (288.490) 47.411 1.049 49012500 25000 941.394 (539.619) 69.421 1.606 58615000 30000 1539.443 (865.813) 113.223 2.416 637sparsity = 0.001mnSOCP (eig time) RTRNew LTRSR Ratio5000 1000061.587 (45.253) 1.4160.028 22007500 15000 153.075 (117.389) 2.3790.053 288810000 20000 335.956 (259.671) 5.4530.113 297312500 25000 638.175 (491.391) 7.7150.168 379915000 30000 1082.261 (832.413) 12.090 0.235 4605sparsity = 0.0001mnSOCP (eig time) RTRNew LTRSR Ratio5000 1000049.869 (45.462) 0.3910.009 55417500 15000 141.507 (134.525) 0.7160.014 1010810000 20000 310.991 (289.447) 0.9790.020 1555012500 25000 587.124 (540.314) 1.3010.030 1957115000 30000 991.070 (912.015) 2.1710.037 26786"}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_3", "figure_caption": ".903) 15.857 2.135 16 31.262 (11.691) 18.617 1.053 30 32.812 (11.008) 11.070 0.561 58 8000 66.816 (27.466) 38.501 3.768 18 63.983 (27.512) 34.655 1.984 32 59.725 (25.061) 27.201 0.961 62 10000 118.044 (49.477) 59.551 5.916 20 109.516 (50.018) 54.060 3.048 36 104.251 (47.261) 39.611 1.529 68", "figure_data": ". Time (seconds) on synthetic data without sparsity, \u03b3 = 0.01nm = 2nm = nm = 0.5nSOCP (eig time) RTRNew LTRSR Ratio SOCP (eig time) RTRNew LTRSR Ratio SOCP (eig time) RTRNew LTRSR Ratio10000.619 (0.087)0.7120.031 200.564 (0.086)0.7040.020 280.466 (0.078)0.6490.012 3920002.244 (0.419)2.5190.138 161.900 (0.471)1.8280.098 192.438 (0.401)2.0920.060 414000 12.123 (3.448)5.1790.956 1311.597 (3.539)6.7890.499 2311.645 (3.212)6.7780.249 476000 33.093 (11"}, {"figure_label": "56", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "Time (seconds) on synthetic data with different sparsity .142 223 160.486 (125.064) 5.166 0.131 1225 130.071 (118.582) 0.540 0.018 7226 20000 550.191 (281.018) 107.358 2.088 264 355.746 (278.687) 10.932 0.222 1603 299.496 (265.987) 1.075 0.029 10327 25000 1090.231 (581.289) 159.592 3.502 311 728.118 (560.429) 15.543 0.357 2040 591.172 (509.912) 1.285 0.038 15557 30000 1726.133 (963.081) 248.325 5.393 320 1240.319 (979.66) 19.947 0.528 2349 1040.441 (888.321) 2.323 0.056 18579 151.406) 117.217 2.609 121 173.231 (132.098) 12.230 0.257 674 148.608 (127.759) 0.947 0.028 5307 20000 643.464 (324.073) 219.622 5.056 127 379.145 (289.701) 23.199 0.457 830 338.119 (283.882) 1.241 0.048 7044 25000 1149.663 (605.581) 395.202 7.818 147 720.837 (561.652) 43.718 0.725 994 684.654 (563.812) 2.254 0.061 11224 30000 2026.088 (1080.883) 598.468 12.022 169 1217.779 (937.93) 45.074 1.100 1107 1106.028 (899.099) 3.869 0.083 13326 (143.174) 200.29 3.932 76 171.902 (129.377) 22.335 0.396 434 150.666 (123.946) 0.774 0.037 4072 20000 596.182 (288.772) 356.849 7.750 77 417.155 (312.681) 42.438 0.718 581 339.114 (274.737) 1.713 0.061 5559 25000 1152.428 (606.097) 614.192 13.592 85 782.197 (587.333) 43.646 1.151 680 641.319 (518.51) 2.678 0.085 7545 30000 1949.035 (1039.845) 948.449 21.749 90 1298.734 (971.861) 93.219 1.698 765 1085.053 (876.409) 5.526 0.119 9118 Relative error of objective values on training sets", "figure_data": "m = n"}, {"figure_label": "7", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "Relative error of MSEs on test sets", "figure_data": ""}, {"figure_label": "8", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "summarises relative errors of objective values on synthetic datasets without sparsity. Comparing to the result in real-world dataset, we find that all the methods have high accuracy as the relative errors of the MSEs are up to 4.60e-5.", "figure_data": ""}, {"figure_label": "8", "figure_type": "table", "figure_id": "tab_7", "figure_caption": "Relative error on synthetic dataset without sparsity\u03b3 = 0.1 (f SOCP \u2212 f LTRSR )/|f SOCP | (f SOCP \u2212 f RTRNew )/|f SOCP | \u03b3 = 0.01 (f SOCP \u2212 f LTRSR )/|f SOCP | (f SOCP \u2212 f RTRNew )/|f SOCP |", "figure_data": "AVGMINMAXAVGMINMAXAVGMINMAXAVGMINMAX"}, {"figure_label": "9", "figure_type": "table", "figure_id": "tab_9", "figure_caption": "Relative error on synthetic dataset without sparsitySOCP \u2212 f LTRSR )/|f SOCP | (f SOCP \u2212 f RTRNew )/|f SOCP | \u03b3 = 0.01 (f SOCP \u2212 f LTRSR )/|f SOCP | (f SOCP \u2212 f RTRNew )/|f SOCP |", "figure_data": "sparsity = 0.0001"}], "formulas": [{"formula_id": "formula_0", "formula_text": "S = {(x i , y i , z i )} m i=1", "formula_coordinates": [2.0, 307.44, 508.97, 87.97, 18.4]}, {"formula_id": "formula_1", "formula_text": "x * i = argmin x i w Tx i \u2212 z i 2 + \u03b3 x i \u2212x i 2 2 i \u2208 [m],", "formula_coordinates": [3.0, 60.0, 111.41, 224.88, 22.56]}, {"formula_id": "formula_2", "formula_text": "{x * i } m i=1 : w * \u2208 argmin w m i=1 w T x * i \u2212 y i 2 ,", "formula_coordinates": [3.0, 55.44, 176.45, 186.48, 50.41]}, {"formula_id": "formula_3", "formula_text": "min w X * w \u2212 y 2 s.t. X * = argmin X X w \u2212 z 2 + \u03b3 X \u2212 X 2 F , (1)", "formula_coordinates": [3.0, 78.0, 265.06, 211.43, 32.12]}, {"formula_id": "formula_4", "formula_text": "w 1 \u03b3 zw T w + Xw 1 + 1 \u03b3 w T w \u2212 y 2 .(2)", "formula_coordinates": [3.0, 112.2, 450.53, 177.32, 32.65]}, {"formula_id": "formula_5", "formula_text": "\u03b1z+Xw 1+\u03b1 \u2212 y 2 s.t. w T w = \u03b3\u03b1.(3)", "formula_coordinates": [3.0, 98.04, 529.73, 191.48, 31.6]}, {"formula_id": "formula_6", "formula_text": "sup \u00b5,\u03bb \u00b5 s.t. A \u2212 \u00b5B + \u03bbC 0,(4)", "formula_coordinates": [3.0, 118.44, 602.25, 171.08, 29.16]}, {"formula_id": "formula_7", "formula_text": "X T X X T (z\u2212y) \u2212X T y (z\u2212y) T X z\u2212y 2 \u2212(z\u2212y) T y \u2212y T X \u2212y T (z\u2212y) y T y , B = On 1 1 1 1 and C = In \u03b3 0 \u2212 1 2 \u2212 1 2 0 .", "formula_coordinates": [3.0, 63.0, 635.66, 226.38, 63.73]}, {"formula_id": "formula_8", "formula_text": "Wang", "formula_coordinates": [3.0, 306.96, 88.91, 22.98, 8.91]}, {"formula_id": "formula_9", "formula_text": ":= V T AV = D b b T c ,", "formula_coordinates": [3.0, 377.4, 134.85, 104.4, 21.96]}, {"formula_id": "formula_10", "formula_text": "D = Diag(d 1 , . . . , d n+1 ) \u2208 R (n+1)\u00d7(", "formula_coordinates": [3.0, 335.28, 164.21, 163.0, 18.4]}, {"formula_id": "formula_11", "formula_text": "B := V BV = On+1 4 andC = V T CV = 1 \u03b3 In+1 \u22121 .", "formula_coordinates": [3.0, 307.44, 197.2, 244.08, 22.07]}, {"formula_id": "formula_12", "formula_text": "d i + \u03bb \u03b3 \u2265 0, i \u2208 [n + 1], c \u2212 4\u00b5 \u2212 \u03bb \u2212 n+1 i=1 s i \u2265 0, s i (d i + \u03bb \u03b3 ) \u2265 b 2 i , s i \u2265 0, i \u2208 [n + 1].(5)", "formula_coordinates": [3.0, 362.76, 330.29, 178.76, 45.27]}, {"formula_id": "formula_13", "formula_text": "\u03b1 2 z + \u221a \u03b3 2 Xw \u2212 (y \u2212 z 2 ) 2 s.t.w Tw +\u03b1 2 = 1.(6)", "formula_coordinates": [3.0, 329.52, 662.57, 212.0, 34.6]}, {"formula_id": "formula_14", "formula_text": "w := 2 \u221a \u03b3(\u03b1 + 1) w and\u03b1 := \u03b1 \u2212 1 \u03b1 + 1 ,(7)", "formula_coordinates": [4.0, 89.76, 165.09, 199.76, 24.48]}, {"formula_id": "formula_15", "formula_text": "w Tw +\u03b1 2 = 4 \u03b3(\u03b1 + 1) 2 w T w + (\u03b1 \u2212 1) 2 (\u03b1 + 1) 2 = 4\u03b1 + (\u03b1 \u2212 1) 2 (\u03b1 + 1) 2 = 1.", "formula_coordinates": [4.0, 84.0, 269.57, 175.21, 53.08]}, {"formula_id": "formula_16", "formula_text": "= \u03b1 2 z + \u221a \u03b3 2 Xw \u2212 (y \u2212 z 2 ) 2 = \u03b1 \u2212 1 2(\u03b1 + 1) z + \u221a \u03b3 2 X 2 \u221a \u03b3(\u03b1 + 1) w \u2212 (y \u2212 z 2 ) 2 = \u03b1z + Xw \u03b1 + 1 \u2212 y 2 = v(w, \u03b1).", "formula_coordinates": [4.0, 68.28, 377.37, 207.85, 91.08]}, {"formula_id": "formula_17", "formula_text": "w := \u221a \u03b3 1 \u2212\u03b1w and \u03b1 := 1 +\u03b1 1 \u2212\u03b1 , (8", "formula_coordinates": [4.0, 100.68, 523.77, 184.93, 37.32]}, {"formula_id": "formula_18", "formula_text": ")", "formula_coordinates": [4.0, 285.61, 537.95, 3.91, 8.91]}, {"formula_id": "formula_19", "formula_text": "is feasible to (3) and\u1e7d(w,\u03b1) = v(w, \u03b1).", "formula_coordinates": [4.0, 55.44, 563.37, 164.37, 9.96]}, {"formula_id": "formula_20", "formula_text": "w T w = \u03b3 (1 \u2212\u03b1) 2w Tw = \u03b3(1 \u2212\u03b1 2 ) (1 \u2212\u03b1) 2 = \u03b3(1 +\u03b1) 1 \u2212\u03b1 = \u03b3\u03b1.", "formula_coordinates": [4.0, 55.44, 620.45, 235.8, 31.96]}, {"formula_id": "formula_21", "formula_text": "\u03b1z+Xw 1+\u03b1 \u2212 y 2 = (1+\u03b1)z+ \u221a \u03b3Xw (1\u2212\u03b1)+(1+\u03b1) \u2212 y 2 = \u03b1 2 z + \u221a \u03b3 2 Xw \u2212 (y \u2212 z/2) 2 .", "formula_coordinates": [4.0, 60.48, 678.65, 188.53, 44.43]}, {"formula_id": "formula_22", "formula_text": "v(w * , \u03b1 * ) =\u1e7d(w * ,\u03b1 * ),(9)", "formula_coordinates": [4.0, 375.0, 294.05, 166.52, 11.92]}, {"formula_id": "formula_23", "formula_text": "wherew * := 2 \u221a \u03b3(\u03b1 * +1) w * ,\u03b1 * := \u03b1 * \u22121 \u03b1 * +1 < 1, and (w * ,\u03b1 * ) is feasible to (6). Since (0, 1) is the unique op- timal solution to (6), it holds that v(w * ,\u03b1 * ) >\u1e7d(0, 1) = z \u2212 y 2 . (10", "formula_coordinates": [4.0, 306.24, 316.64, 236.96, 67.32]}, {"formula_id": "formula_24", "formula_text": ")", "formula_coordinates": [4.0, 537.45, 367.67, 4.19, 8.91]}, {"formula_id": "formula_25", "formula_text": "= t 2 w T w/\u03b3 1+t 2 w T w/\u03b3 z + t 1+t 2 w T w/\u03b3 Xw \u2212 y 2 \u2192 z \u2212 y 2 , as t \u2192 \u221e.(11)", "formula_coordinates": [4.0, 325.08, 443.45, 216.56, 38.68]}, {"formula_id": "formula_26", "formula_text": "min r q(r) s.t. r T r = 1,(12)", "formula_coordinates": [5.0, 122.16, 103.61, 167.48, 16.7]}, {"formula_id": "formula_27", "formula_text": "q(r) = L r \u2212 (y \u2212 z/2) 2 2 = r T Hr + 2g T r + p (13)", "formula_coordinates": [5.0, 64.56, 146.85, 225.08, 19.56]}, {"formula_id": "formula_28", "formula_text": "K k := {g, Hg, H 2 g, . . . , H k g}. Let Q k = [q 0 , q 1 , . . . , q k ] \u2208 R (n+1)\u00d7(", "formula_coordinates": [5.0, 307.44, 280.25, 183.24, 38.2]}, {"formula_id": "formula_29", "formula_text": "min r\u2208K k , r =1 r T Hr + 2g T r + p.(14)", "formula_coordinates": [5.0, 362.16, 378.65, 179.48, 18.31]}, {"formula_id": "formula_30", "formula_text": "(H + \u03bb * I)r * = \u2212g, H + \u03bb * I 0, r * = 1,(15)", "formula_coordinates": [5.0, 379.08, 661.85, 162.56, 35.74]}, {"formula_id": "formula_31", "formula_text": "\u03ba = \u03bb max + \u03bb * \u03bb min + \u03bb * ,(16)", "formula_coordinates": [6.0, 138.6, 130.01, 151.04, 26.14]}, {"formula_id": "formula_32", "formula_text": "f (r k ) \u2212 f (r * ) \u2264 O(exp(\u2212k/ \u221a \u03ba)),", "formula_coordinates": [6.0, 99.6, 223.89, 145.68, 24.72]}, {"formula_id": "formula_33", "formula_text": "f (r k ) \u2212 f (r * ) \u2264\u00d5(1/k 2 ).", "formula_coordinates": [6.0, 117.24, 321.29, 110.4, 18.87]}, {"formula_id": "formula_34", "formula_text": "1: for k = 0, 1, 2, . . . do 2: Obtain s k \u2208 R d by (approximately) solving s k \u2248 argmin s 2\u2264\u2206k m k (s),(17)", "formula_coordinates": [6.0, 312.36, 108.45, 229.28, 51.98]}, {"formula_id": "formula_35", "formula_text": "m k (s) = q(r k ) + s T grad q(r k ) + 1 2 s T Hess q(r k )[s]", "formula_coordinates": [6.0, 335.52, 171.89, 207.9, 25.93]}, {"formula_id": "formula_36", "formula_text": "3: Set \u03c1 k \u2190 q(r k )\u2212q(Rr k (s k )) m k (0)\u2212m k (s k )", "formula_coordinates": [6.0, 312.36, 219.53, 127.67, 20.67]}, {"formula_id": "formula_37", "formula_text": "4: if \u03c1 k > c then 5: r k+1 \u2190 R r k (s k ); 6: else 7: r k+1 \u2190 r k ; 8: end if 9: if \u03c1 k > 3 4 then 10: If s k \u2265 0.8\u2206 k , then \u2206 k+1 \u2190 min(\u03c4 2 \u2206 k , \u2206); otherwise \u2206 k+1 \u2190 \u2206 k ; 11: else if \u03c1 k < 0.1 then 12: \u2206 k+1 \u2190 \u03c4 1 \u2206 k ;", "formula_coordinates": [6.0, 307.92, 248.01, 234.37, 126.0]}, {"formula_id": "formula_38", "formula_text": "\u2206 k+1 \u2190 \u2206 k ;", "formula_coordinates": [6.0, 344.28, 380.85, 54.73, 17.04]}, {"formula_id": "formula_39", "formula_text": "Hess q(r)[v] =P TrS n (\u2207 2 q(r)v \u2212 vr T \u2207q(r)), =(I \u2212 rr T )(2Hv \u2212 2vr T (Hr + g)),(19)", "formula_coordinates": [6.0, 320.76, 652.97, 220.88, 39.92]}, {"formula_id": "formula_40", "formula_text": "R r (v) = r + v r + v ,(20)", "formula_coordinates": [7.0, 133.8, 87.21, 155.84, 23.52]}, {"formula_id": "formula_41", "formula_text": "lim k\u2192\u221e grad q(r k ) = 0.", "formula_coordinates": [7.0, 128.76, 263.61, 87.36, 15.69]}, {"formula_id": "formula_42", "formula_text": "dist(r k+1 , r * ) \u2264 c dist(r k , r * ) 2 . (21", "formula_coordinates": [7.0, 106.56, 354.29, 178.89, 19.0]}, {"formula_id": "formula_43", "formula_text": ")", "formula_coordinates": [7.0, 285.45, 356.99, 4.19, 8.91]}, {"formula_id": "formula_44", "formula_text": "3 2 log(1/\u01eb) .", "formula_coordinates": [7.0, 364.2, 242.44, 51.72, 12.05]}, {"formula_id": "formula_45", "formula_text": "ments {\u03be i } m i=1 i.i.d from the uniform distribution [0, 0.5]. Then the output label {y i } m i=1 via y i = x T i \u03b2 + \u03be i . Fol- lowing", "formula_coordinates": [9.0, 55.08, 532.85, 236.25, 35.0]}], "doi": ""}