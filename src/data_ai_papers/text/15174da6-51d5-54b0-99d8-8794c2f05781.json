{"title": "Temporal Collaborative Filtering with Graph Convolutional Neural Networks", "authors": "Esther Rodrigo Bonet; Minh Nguyen; Nikos Deligiannis", "pub_date": "2020-10-13", "abstract": "Temporal collaborative filtering (TCF) methods aim at modelling non-static aspects behind recommender systems, such as the dynamics in users' preferences and social trends around items. State-of-the-art TCF methods employ recurrent neural networks (RNNs) to model such aspects. These methods deploy matrix-factorization-based (MF-based) approaches to learn the user and item representations. Recently, graphneural-network-based (GNN-based) approaches have shown improved performance in providing accurate recommendations over traditional MF-based approaches in non-temporal CF settings. Motivated by this, we propose a novel TCF method that leverages GNNs to learn user and item representations, and RNNs to model their temporal dynamics. A challenge with this method lies in the increased data sparsity, which negatively impacts obtaining meaningful quality representations with GNNs. To overcome this challenge, we train a GNN model at each time step using a set of observed interactions accumulated time-wise. Comprehensive experiments on real-world data show the improved performance obtained by our method over several state-of-the-art temporal and non-temporal CF models.", "sections": [{"heading": "I. INTRODUCTION", "text": "Recommender systems aim to provide users with the most relevant information or products, with which they are likely to interact. Providing such information helps users quickly navigate and filter out irrelevant information from the plethora of data available online nowadays. As such, recommender systems have become indispensable components of online platforms, such as e-commerce, movie streaming and news websites, to drive user engagement and interactions.\nBuilding recommender systems has been a very active research topic for years, resulting in a great number of methods proposed in the literature. Among them, collaborative filtering (CF) methods are arguably the most popular ones due to favorable performance compared to other methods [1]. CF methods leverage collective user-item interactions and build models to predict the likelihood of unobserved interactions. For instance, models that follow the matrix-factorization (MF) approacha very common CF approach-learn users' and items' latent representation vectors (also referred to as latent embeddings or states) by factorizing data matrices which contain historical interactions. Unknown user-item interaction scores are then calculated by taking the dot product of the corresponding representation vectors. These vectors, or embeddings, are often interpreted as encoding preferences of users and characteristics of items.\nDespite being widely-adopted, traditional CF methods focus mainly on static settings, where user preferences and other factors such as social trends around items, are assumed to be stationary. In real application settings, however, such assumption seldom holds [2]. Recently, numerous works have focused on modeling the temporal dynamics in recommender systems [3], [4], [5]. They are referred to as time-aware or temporal collaborative filtering (TCF) methods [6], [7], [8]. TCF methods often employ recurrent neural networks (RNNs) to model the temporal trajectories of user embeddings [5], [9], or of both user and item embeddings [2], [3], [10]. They have achieved higher performance over non-temporal counterparts in predicting future ratings [2], [4], [7].\nA limitation of existing TCF methods is that they often rely on linear MF models to individually learn users' and items' embeddings, neglecting the fact that correlations amongst users and items are effective hints in modeling their latent representations. In contrast, recent studies on static CF have shown the benefits of modeling user-item interactions in forms of graphs and of using graph neural networks (GNNs) to learn representations over linear models [11], [12]. Motivated by this, we aim to leverage GNNs in the context of temporal CF. To this end, we propose a method that (i) employs a graphbased CF model, namely the Graph Convolutional Matrix Completion (GCMC) model [11], to effectively learn user and item embeddings and (ii) models the temporal trajectories of these embeddings using RNNs. The RNNs, after training, can propagate the latent embeddings to a future time step. These latent states are then used to predict potential useritem interactions. An inherent challenge with this method in the temporal CF setting lies in the increased data sparsity. To overcome the challenge of efficiently learning the embeddings from highly sparse data, we propose to use the historical useritem interactions, accumulated over time. Our experimental results show systematic performance improvement obtained with this approach.\nTo summarize, our contributions in the paper are two-fold:\n\u2022 We propose a method, coined Time-aware Graph-based Matrix Completion (TG-MC), which leverages the stateof-the-art graph-based CF model with RNNs for collaborative filtering. To the best of our knowledge, we are the first to leverage the graph-based CF approach for TCF. \u2022 We present comprehensive experiments on large-scale real-world data to assess the effectiveness of our method in comparison with the state of the art. The remainder of the paper is organized as follows: Section II reviews the related work, Section III presents our method in detail. Section IV describes the experimental settings and results while Section V concludes the paper.", "publication_ref": ["b0", "b1", "b2", "b3", "b4", "b5", "b6", "b7", "b4", "b8", "b1", "b2", "b9", "b1", "b3", "b6", "b10", "b11", "b10"], "figure_ref": [], "table_ref": []}, {"heading": "II. RELATED WORK", "text": "Our work lies in the intersection between the temporal collaborative filtering (TCF) and the graph-based collaborative filtering literature. In this section, we review these two areas and show the differences between our method and existing ones in each corresponding area.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A. Temporal Collaborative Filtering", "text": "Existing TCF methods focus on the temporal aspects of only users, of users and items, or of their interactions, e.g., rating scores. In this section, existing studies are grouped based on how they model users' preferences and items' social perception. Throughout the paper, the opinion that a social environment has of a product will be referred as item (social) perception.\nA number of works consider items' social perception as stationary and model users' preferences as evolving over time [9]. For instance, [9] uses random walks to independently learn short-and long-term user preferences.\nNevertheless, most TCF methods in the literature assume that both items' perception and users' preferences may evolve over time [2], [3], [4]. They either (a) model users' and items' latent states by means of temporal MF [2], [3] or (b) infer rating scores by modeling users' and items' dynamics by means of baseline predictors [4]. While [4] and [7] obtain time-stamped latent states by following a MF approach, [2] uses Long-Short Term Memory (LSTM) units [13] to learn time-varying functions, thus reconstructing the dynamics of the evolution rather than the latent states.\nThe previous studies propose methods that learn the evolution of users' preferences and items' perceptions using independent RNNs. Alternatively, other papers define baseline functions which only depend on previous rating scores and incorporate time-decay functions to penalize older ratings [14] or emphasize relevant periods like seasons or week-ends [15].\nUnlike the TCF techniques presented above, which employ baseline functions or MF methodologies, our method models the user-item interactions by means of graph-based techniques, that is, GNNs. Our target is to effectively learn the latent embeddings with these novel neural networks which allow for a more precise study of the interactions and an increase in computational complexity.", "publication_ref": ["b8", "b8", "b1", "b2", "b3", "b1", "b2", "b3", "b3", "b6", "b1", "b12", "b13", "b14"], "figure_ref": [], "table_ref": []}, {"heading": "B. Graph-based Collaborative Filtering", "text": "Link prediction refers to the task of anticipating whether an edge should be created between two nodes. Recommender systems can be formulated as a link prediction problem by representing users, items and their interactions in a bipartite graph. One of the first papers that proposed this methodology was [16] who introduced novel linkage functions as measure for inferring the rating scores in the model. Since then, various methods have followed proposed by [11], [12], [17], [18], [19].\nAlthough MF is arguably the most commonly employed approach for recommender systems, recent studies have also leveraged CNNs and GNNs with favorable outcomes. Mainly thanks to the development of CNNs and GNNs in recent years, interpreting recommender systems as a link prediction problem has received a boost in attention, leading to performance improvements. Namely, the methods by [11], [12], [19] outperform non-graph CF papers by incorporating GNNs, whereas [17] addresses the problem similarly using CNNs. In effect, these papers leverage the graph structure of the data and employ neural networks in the extraction of the latent embeddings of users and items. Differently, [18] proposed to leverage signal processing concepts such as as graph frequency and graph filters to address the problem.\nThe approaches reviewed in this subsection focus on the static CF problem and ignore the dynamics behind users' opinions and social trends. In this work, we attempt to combine graph-based and time-dependant techniques with the aim of learning user and item latent embeddings and their dynamics.", "publication_ref": ["b15", "b10", "b11", "b16", "b17", "b18", "b10", "b11", "b18", "b16", "b17"], "figure_ref": [], "table_ref": []}, {"heading": "III. THE PROPOSED METHOD", "text": "In this work, we follow the TCF approach for recommender systems and consider the time information associated to the user-item interactions. Concretely, we group the observed interactions by the time they occur, resulting in a sequence of T non-overlapping interaction matrices {R 1 , . . . , R T }. This is in contrast to the setting in static CF methods, where all the observed interactions are processed at once in a single data matrix. A time step t in our setting is associated to a matrix R t which contains interactions occurring between t \u2212 \u03b4/2 and t+\u03b4/2 with \u03b4 the time window's length. T is hence determined by the total time span of the data (between the first and the last observed interactions) and \u03b4.\nTo learn from the sequence of interaction matrices, we propose a method, coined Time-aware Graph-based Matrix Completion (TG-MC), which leverages a graph-based CF approach and temporal prediction techniques. The schema of our method is illustrated in Figure 1. During training, our method follows a two-stage pipeline. The first stage involves learning latent embeddings representing users and items using the GCMC model [11]. This step is performed independently for each interaction matrix R t with t = 1 . . . T , resulting in two length-T -sequences of latent embeddings for the users and the items. At each time step, a bi-linear decoder is trained together with the GCMC model as in [11]. In the second stage, we fit two RNNs on the sequences of user and item representations to model their temporal trajectories. During testing, these RNNs are used to propagate the user and item representation vectors to a future time instance, from which user-item interaction scores can be computed using the bilinear decoder trained in the first stage. Next, we present the steps involved in our method in detail.   Given the two sequences of users and items embeddings, two RNN models, which we refer to as user-and item-RNNs, predict the subsequent embeddings. The two RNNs can share weights or can be completely independent. (d) By matrix multiplication, the decoder step obtains, at the subsequent time instance, the output matrixRT +1 which contains the predicted ratings scores.", "publication_ref": ["b10", "b10"], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "A. Learning Users and Items Latent Embeddings with a", "text": "Graph-based Model 1) Modeling Users and Items: Following [11], we represent the rating matrices in the form of graphs. Concretely, the interaction matrix R t is represented as a bipartite graph G t where a node corresponds to either a user or an item, and an edge encodes a rating a user has given to an item. The aim of this step is to learn the latent representations associated to each user or item node. The latent embedding of the node i at time t is denoted with the vector z i,t \u2208 IR d\u00d71 , where d is the dimension of the latent representation.\nIndependently of the node type (item or user), a latent node embedding z i,t is learned by the following two steps. First, a vector h i,t is computed by accumulating all incoming links of node i (i.e. j \u2192 i, \u2200j\nconnected to i) in graph G t h i,t = \u03c3 \uf8ee \uf8f0 accum \uf8eb \uf8ed j\u2208Ni,1 \u00b5 j\u2192i,1,t , ..., j\u2208N i,R \u00b5 j\u2192i,R,t \uf8f6 \uf8f8 \uf8f9 \uf8fb ,(1)\nwhere \u03c3[\u2022] is the activation function and N i,r is the set of nodes with linked interactions to user (or item) i with rating score r \u2208 {1, . . . , R} and accum(\u2022) is an accumulation function, e.g., concatenation or element-wise addition. Each incoming link to node i is a user-item interaction and contributes by \u00b5 j\u2192i,r,t = 1 c i,j,t W r,t x j,t .\nHere, W r,t \u2208 IR H\u00d7N U are learnable weights. N U (or N V ) and H are, respectively, the input size and the hidden dimension size, x j,t is the initial feature vector of item-node j at time t, and c i,j,t is the normalization factor.\nIn the second step, the latent vector z i,t is computed by\nz i,t = \u03c3 (W t h i,t ) ,(3)\nwhere each weight matrix W t \u2208 IR d\u00d7H is learned from the available training data at time t. Depending on the node type (i.e., whether it represents a user or an item), we consider the learned representation z i,t as a user or an item vector, denoted as u i,t and v j,t respectively.\n2) Bi-linear Decoder: Following the GCMC model [11], for each time window, we compute the user-item interaction scores from the learned user and item embeddings using a bilinear decoder. In this work, as we consider ratings (e.g., oneto five-score rating) as the interaction type, the prediction of rating values can be treated as a classification problem. We calculate the probability of rating R i,j,t (user i rate item j at time t) to have value r according to\nP (R i,j,t = r) = exp(u T i,t Q r,t v j,t ) s\u2208R exp(u T i,t Q s,t v j,t ) ,(4)\nwith u i,t , v j,t the embeddings of user i and item j at time t and Q r,t \u2208 IR d\u00d7d , \u2200r = {1, . . . , R} the learnable parameters of the bi-linear decoder at time t.\nWe jointly train the parameters of the bi-linear decoder (Q r,t \u2208 IR d\u00d7d , \u2200r = {1, . . . , R}) and those of the graphbased user and item modelling (W ), separately at each time window t, by minimizing the negative log-likelihood objective function,\nL graph = \u2212 i,j\u2208\u2126t log P (R i,j,t = r),(5)\nwith \u2126 t the set of ratings available for training at time t, and r is the ground-truth rating that user i gives to item j.  3) Handling Data Sparsity: CF methods generally suffer from the data sparsity problem, i.e., the number of observed user-item interactions is scant compared to the total possible number of such interactions. In our case, this problem aggravates because the number of observed ratings is distributed with respect to their time instance: if the range of observed interactions is uniformly distributed across time, the density of R t is on average 1 / T that of R.\nTo mitigate this problem when building R t , rather than only using the interactions observed within t, we also include the interactions accumulated from previous time steps {1, . . . , t \u2212 1}. Following this approach, the density of the rating matrix increases through time, i.e., |\u2126 t+1 | > |\u2126 t |, \u2200t \u2208 {1, . . . , T \u2212 1}, which helps ease the learning of the GCMC model. In Section IV, we will compare the efficiency of this variance (accumulative representation) against the nonaccumulative representation.", "publication_ref": ["b10", "b10"], "figure_ref": [], "table_ref": []}, {"heading": "B. Modeling Users' and Items' Dynamics", "text": "By learning user and item embeddings for each time window t, with t \u2208 {1, . . . , T }, we obtain two length-T sequences of embeddings, one for the users and the other for the items. We denote these two sequences, respectively, by U t and V t with t \u2208 {1, . . . , T }. We have U t \u2208 IR N U \u00d7d , V t \u2208 IR N V \u00d7d where N U , N V are the number of users and items.\nWe employ two RNNs to model the temporal information in these sequences of embeddings, one for the users and one for the items, which we refer to as the user-RNN and item-RNN, respectively. This is motivated by the success of RNN and its variants in learning and predicting sequential data [22]. As we unify the dimensions of the user and item embeddings (both equal to d), we can have the user-RNN and item-RNN either sharing weights or operating separately. In Section IV, we will compare the results obtained with these two variants.\nUsing RNNs, we predict the embeddings at a time step T +1 from the embeddings of the previous T time steps (from t = 1 to T ). By re-iterating this process, we can further infer the embeddings at later time steps, e.g., T + 2 and T + 3 and so on. Formally, considering the user embeddings, we have:\nU T +1 = f RNN (U 1 , . . . , U T ),(6)\nwith U T +1 the predicted embeddings at time T + 1 and f RNN (\u2022) the function implemented by the user-RNN. The item embeddings at each time window can be predicted in the same way using the item-RNN whose operation is referred as g RNN .\nWe employ the mean-squared-error (MSE) loss function to train the user-and item-RNNs. Concerning the user-RNN, at time step t, the MSE is calculated between the predicted embedding U t produced by applying the model on the sequence of prior embeddings, U 1 , . . . , U t\u22121 , and the embedding produced by the GCMC model at time t, namely, U t , as illustrated in Eq. (7).\nL user-RNN = 1 N N i=1 U i \u2212 U i 2 F ,(7)\nwith . F the Frobenious norm. The loss function used to train the item-RNN is calculated analogously using the item embeddings.", "publication_ref": ["b21", "b6"], "figure_ref": [], "table_ref": []}, {"heading": "C. Predicting entry values at future time instances", "text": "Using the trained user-RNN and item-RNN models as presented above, we can predict the user and item embeddings at any future time step. Following the same setting, we employ the T bi-linear decoders learnt at time steps t = {1, . . . , T } and a LSTM-based RNN architecture to predict the bi-linear decoder weights at t = T + 1. The selected loss function is MSE as illustrated in Eq. (7). With this, we are able to predict the user-item interaction probabilities at t = T +1. Concretely, consider the time instance T + 1, the predicted probability for rating R i,j,T +1 to have value r is calculated following Eq. (4), with the embeddings produced by the (user-and item-) RNNs at time T +1 and the bi-linear decoder produced by the RNN at time T + 1. From the computed probabilities, we can produce the continuous-valued predictions according to:\nR i,j,t = r\u2208R rP (R i,j,t = r)(8)\nwhere R = {1, . . . , R} is the set of possible rating scores.", "publication_ref": ["b6"], "figure_ref": [], "table_ref": []}, {"heading": "IV. EXPERIMENTS", "text": "In this section, we present our experimental study to assess the effectiveness of the proposed methods compared to the state of the art. We first describe the experimental settings and then report the obtained results.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A. Experimental Settings", "text": "We employ the Netflix and MovieLens datasets [23], [24] in our experiments, both widely used in recent literature [2], [11], [21], [25] and with different characteristics regarding number of users, items and distribution of ratings. The Netflix dataset comprises a total of about 100M ratings, 480, 189 users and 17, 770 movies, whereas the MovieLens 1M (ML-1M) dataset has 6, 040 users, 3, 900 items and 1M observed ratings.\nA data point (i.e. rating) of any of the two sets contains a movie and user identifier as well as the rating score and the time of the event. The Netflix timestamp is given as YYYY-MM-DD while the ML-1M is given as seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970.\nFor the Netflix dataset, we follow the setup in [2] and consider a 6-month subset of the dataset (nearly 5M data points) with ratings occurring between July and December 2005. To respect causality considerations, ratings recorded in the month of December are kept for testing while those recorded between July and November are used for training. All the ratings are integer values in the range [1 \u2212 5]. We split the data according to a time window of 1 week. As the total time span of the data is 30 weeks, we obtain T = 30 interaction matrices, of which the first 26 ones are used for training (3M ratings) and the rest are reserved for testing (1.8M ratings). This results in a train-test split of 62%-38%.\nFor the ML-1M dataset, we follow [25] and split the dataset according to a time window of 3 months. As the total time span of the data ranges from May 2000 to January 2003, we obtain T = 11 time windows, where the first 9 are used for training and the remaining are kept for testing, resulting in a 99%-1% train-test split. Like on the Netflix dataset, the ratings are integers in the range [1 \u2212 5].\nWe compare the performance of our methods with that of state-of-the-art reference models, including non-temporal CF models such as the PMF [20], Autorec [21] and GCMC models [11] and temporal CF models [2], [4], [6], [10], [25], [26], [27], [28]. The performance of the models are assessed using two metrics, namely, the root mean squared error (RMSE) and mean absolute error (MAE). For each model, we report the mean results obtained after five different runs employing the test and train sets explained above.\nOn the GCMC model [11], the reported results are obtained by running their code on the whole matrix of ratings when T = 1 with the best hyperparameters reported in their paper. Equivalently, reported results from [2] on the Netflix dataset are collected from their papers. The temporal MF model from [26] was re-implemented and run for the best parameters we found. We followed an equivalent process for [6], [21], [27]. Results on [10], [25], [28] are taken from their paper since they follow the same experimental settings.", "publication_ref": ["b22", "b23", "b1", "b10", "b20", "b24", "b1", "b24", "b19", "b20", "b10", "b1", "b3", "b5", "b9", "b24", "b25", "b26", "b27", "b10", "b1", "b25", "b5", "b20", "b26", "b9", "b24", "b27"], "figure_ref": [], "table_ref": []}, {"heading": "B. Hyperparameters Selection", "text": "We empirically select the hyperparameters for the graph encoder, the user-and the item-RNNs.\na) The Graph-based Encoder: For this model, we employ a learning rate of 10 \u22122 , a dropout rate of 0.3 and rectified linear unit (ReLU) as the activation function after both dense and GNN layers.\nOn the Netflix dataset, we performed grid search to select the best combination of the output dimensions of the GNN and dense layers (H and d). We compared the results obtained by different combinations on a separate validation set containing 20% of the known ratings in the training set at the last training time step. This procedure results in H = 500 and d = 75. For each time step, we train the corresponding graph-based encoder for 1, 000 epochs with a batch size of 100, 000 training ratings. On the ML-1M dataset, we perform the same grid search procedure and accordingly set H = 500 and d = 50. For each time step, we train the model for 2, 500 epochs with a batch size of 100, 000 training samples.\nb) The user-and item-RNN models: We experiment with different variants of RNNs to construct the user-and itemrecurrent networks, including LSTM, GRU and vanilla RNN models, with one, two or three hidden layers. For each variant, we use the tanh activation function. As mentioned earlier, the weights between the user-and item-RNNs can be shared. For training, we employ the Adam optimizer with a learning rate of 10 \u22122 , running for 250 epochs. Throughout our experimental study, we empirically observe that using LSTM models with two hidden layers give the best performance overall, and that sharing weights between the user-and item-recurrent models improves the performance. As such, we use this configuration when comparing our method to the reference models.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C. Experimental Results", "text": "a) Non-Accumulative versus Accumulative Representations: Table I compares the results obtained by our methods on the Netflix and ML-1M datasets when using the nonaccumulative and accumulative data representations. Recall that with the former, only the ratings observed within a time window t are used to learn the user and item embeddings (U t and V t respectively), while with the latter, all ratings between the first and the t\u2212th time windows are employed.\nWe can observe from the two tables that, given the same experimental conditions and independently of the employed dataset and RNN variant, the accumulative data representation yields better results in terms of RMSE and MAE. Furthermore, it is worth mentioning that more complex units like LSTMs and GRUs provide lower prediction errors than the vanilla RNN.  [25] 0.777 NTF [10] 0.689 TG-MC (ours) 0.664 b) Comparison against Non-temporal CF models: In this paper, we argue that (i) learning user and item embeddings via GNNs and (ii) modeling the temporal dynamics improve the performance of CF models. To confirm both points, we compare the performance of our method with that of both non-temporal and non-graph-based reference CF models.\nTable II shows the RMSE scores obtained by our method and non-temporal CF reference methods on the Netflix and ML-1M datasets. As can be seen, our method yields the best performance on the Netflix dataset, followed by the PMF method. On the ML-1M dataset, the I-AutoRec model performs the best while our method has the second best performance. It should be noted that the performance difference between the two is relatively small (i.e., 0.001 point on RMSE on average), and that our method has lower MAE compared to the I-AutoRec model (0.664 versus 0.790, respectively).\nAmong the reference non-temporal models, the GCMC model [11] employs graph neural network to learn the latent representations. In fact, this model can be seen as a special case of our method where the time span \u03b4 is defined so that all the known rating scores are enclosed in one matrix (i.e., T = 1). However, directly applying the GCMC model on the TCF setting, where the training and testing sets are split according to the time stamps, results in poor performance on both the Netflix and ML-1M datasets, showing the benefits of modeling the temporal dynamics behind user and item embeddings in TCF.\nc) Comparison with State-of-the-art TCF models: Table III compares the performance of our method and that of reference TCF methods on the Netflix and ML-1M datasets. For a fair comparison, we follow most recent TCF papers [2], [4], [7] and report RMSE scores for the Netflix dataset, and MAE scores for the ML-1M dataset. It is worth re-calling that whenever applicable, we include the best scores reported in the corresponding papers in our comparison. From the table, it is noted that our method yields the best performance on the Netflix dataset. The LFM model achieves the second best RMSE score, followed by the NCF model. On the ML-1M dataset, our method out-performs all reference TCF methods by large margins.\nAmong the reference TCF models, our method of modeling the temporal trajectories of user and item embeddings is similar that of the Temporal MF model [26]. The key difference is that we employ graph neural network to learn the embeddings at each time step, while the Temporal MF models follow a matrix-factorization approach. The results reported in Table III consistently show significant performance improvements obtained by the TG-MC model over the Temporal MF model. This justifies the benefits of using graph neural networks in our method.", "publication_ref": ["b24", "b9", "b10", "b1", "b3", "b6", "b25"], "figure_ref": [], "table_ref": ["tab_1", "tab_1", "tab_1"]}, {"heading": "V. CONCLUSION", "text": "In this paper, we have presented a method for temporal collaborative filtering (TCF), which combines graph neural network (GNN) and recurrent neural network (RNN) models to effectively (i) learn the latent user and item representations, and (ii) model the trajectories of these representations across time. To deal with the increased data sparsity in the TCF setting, we proposed to train the GNNs using an accumulative data representation technique. Our comprehensive experiments on the Netflix and MovieLens 1M datasets justified the benefits of each of the proposed components, namely, the use of RNNs to model the temporal dynamics in the TCF settings, the use of GNNs to capture the latent representations of users and items and the benefits of training the models using accumulative data. The experimental results also showed that our method yielded favourable performance compared to several state-ofthe-art TCF models.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "ACKNOWLEDGEMENT", "text": "This research was supported by funding from the Flemish Government under the \"Onderzoeksprogramma Artifici\u00eble Intelligentie (AI) Vlaanderen\" programme.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Advances in collaborative filtering", "journal": "", "year": "2015-01", "authors": "Y Koren; R Bell"}, {"ref_id": "b1", "title": "Recurrent recommender networks", "journal": "", "year": "2017", "authors": "C.-Y Wu; A Ahmed; A Beutel; A Smola; H Jing"}, {"ref_id": "b2", "title": "Graph regularized nonnegative matrix factorization for temporal link prediction in dynamic networks", "journal": "Physica A: Statistical Mechanics and its Applications", "year": "2018", "authors": "X Ma; P Sun; Y Wang"}, {"ref_id": "b3", "title": "Collaborative filtering with temporal dynamics", "journal": "Commun. ACM", "year": "2010-04", "authors": "Y Koren"}, {"ref_id": "b4", "title": "Multi-Rate Deep Learning for Temporal Recommendation", "journal": "ACM", "year": "2016", "authors": "Y Song; A M Elkahky; X He"}, {"ref_id": "b5", "title": "Temporal collaborative filtering with bayesian probabilistic tensor factorization", "journal": "", "year": "2010", "authors": "L Xiong; X Chen; T.-K Huang; J Schneider; J Carbonell"}, {"ref_id": "b6", "title": "Social temporal collaborative ranking for context aware movie recommendation", "journal": "ACM Trans. Intell. Syst. Technol", "year": "2013-02", "authors": "N N Liu; L He; M Zhao"}, {"ref_id": "b7", "title": "Time-aware recommender systems: a comprehensive survey and analysis of existing evaluation protocols", "journal": "User Modeling and User-Adapted Interaction", "year": "2014-02", "authors": "P G Campos; F D\u00edez; I Cantador"}, {"ref_id": "b8", "title": "Temporal Recommendation on Graphs via Long-and Shortterm Preference Fusion", "journal": "ACM", "year": "2010", "authors": "L Xiang; Q Yuan; S Zhao; L Chen; X Zhang; Q Yang; J Sun"}, {"ref_id": "b9", "title": "Neural tensor factorization for temporal interaction learning", "journal": "Association for Computing Machinery", "year": "2019", "authors": "X Wu; B Shi; Y Dong; C Huang; N V Chawla"}, {"ref_id": "b10", "title": "Graph Convolutional Matrix Completion", "journal": "ArXiv", "year": "1706", "authors": "R Van Den; T N Berg; M Kipf;  Welling"}, {"ref_id": "b11", "title": "Session-based recommendation with graph neural networks", "journal": "", "year": "2019-07", "authors": "S Wu; Y Tang; Y Zhu; L Wang; X Xie; T Tan"}, {"ref_id": "b12", "title": "Long Short-Term Memory", "journal": "Neural computation", "year": "1997", "authors": "S Hochreiter; J Schmidhuber"}, {"ref_id": "b13", "title": "Collaborative Filtering Algorithm Based on User Characteristic and Time Weight", "journal": "ACM", "year": "2019", "authors": "P Wang; H Hou; X Guo"}, {"ref_id": "b14", "title": "Exploiting Contextual Information from Event Logs for Personalized Recommendation", "journal": "Springer", "year": "2010", "authors": "D Lee; S E Park; M Kahng; S Lee; S.-G Lee"}, {"ref_id": "b15", "title": "Link Prediction Approach to Collaborative Filtering", "journal": "", "year": "2005-06", "authors": "H Chen; X Li; Z Huang"}, {"ref_id": "b16", "title": "Convolutional matrix factorization for document context-aware recommendation", "journal": "Association for Computing Machinery", "year": "2016", "authors": "D Kim; C Park; J Oh; S Lee; H Yu"}, {"ref_id": "b17", "title": "Collaborative filtering via graph signal processing", "journal": "", "year": "2017", "authors": "W Huang; A G Marques; A Ribeiro"}, {"ref_id": "b18", "title": "Neural graph collaborative filtering", "journal": "", "year": "2019", "authors": "X Wang; X He; M Wang; F Feng; T.-S Chua"}, {"ref_id": "b19", "title": "Probabilistic Matrix Factorization", "journal": "Curran Associates Inc", "year": "2007", "authors": "R Salakhutdinov; A Mnih"}, {"ref_id": "b20", "title": "Autorec: Autoencoders meet collaborative filtering", "journal": "ACM", "year": "2015", "authors": "S Sedhain; A K Menon; S Sanner; L Xie"}, {"ref_id": "b21", "title": "Sequence to sequence learning with neural networks", "journal": "", "year": "2014", "authors": "I Sutskever; O Vinyals; Q V Le"}, {"ref_id": "b22", "title": "Netflix Prize Data Set", "journal": "", "year": "2009", "authors": ""}, {"ref_id": "b23", "title": "The movielens datasets: History and context", "journal": "ACM Trans. Interact. Intell. Syst", "year": "2015-12", "authors": "F M Harper; J A Konstan"}, {"ref_id": "b24", "title": "Collaborative temporal order modeling", "journal": "", "year": "2011", "authors": "A Karatzoglou"}, {"ref_id": "b25", "title": "Temporal matrix factorization for tracking concept drift in individual user preferences", "journal": "IEEE Transactions on Computational Social Systems", "year": "", "authors": "Y.-Y Lo; W Liao; C.-S Chang"}, {"ref_id": "b26", "title": "Neural collaborative filtering", "journal": "", "year": "2017", "authors": "X He; L Liao; H Zhang; L Nie; X Hu; T.-S Chua"}, {"ref_id": "b27", "title": "Long-term performance of collaborative filtering based recommenders in temporally evolving systems", "journal": "Neurocomputing", "year": "2017-06", "authors": "X Shi; X Luo; M S Shang; L Gu"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Fig. 1 :1Fig. 1: The proposed time-aware graph-based matrix completion architecture for Recommender Systems (TG-MC). (a) The model receives as input a sparse tensor of ratings R\u2208 IR N U \u00d7N V \u00d7T in three dimensions (users, items and time). The empty elements of R represent unknown rating scores from a user to a specific item. (b) The encoder is formed by combining GNNs and fully-connected layers. Running the encoder step for each time window results in two length-T sequences of latent representations for users and items. (c) The predictive step encompasses an RNN-, LSTM-or GRU-based architecture.Given the two sequences of users and items embeddings, two RNN models, which we refer to as user-and item-RNNs, predict the subsequent embeddings. The two RNNs can share weights or can be completely independent. (d) By matrix multiplication, the decoder step obtains, at the subsequent time instance, the output matrixRT +1 which contains the predicted ratings scores.", "figure_data": ""}, {"figure_label": "I", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "Average test RMSE and MAE scores for all variations of our method on the Netflix and MovieLens 1M datasets.", "figure_data": "Non-Accumulative RepresentationAccumulative RepresentationDatasetMethodRMSEMAERMSEMAETG-MC RNN1.008\u00b1 0.0850.921\u00b10.0401.001 \u00b1 0.033 0.822 \u00b1 0.022NetflixTG-MC GRU0.969 \u00b1 0.0340.876 \u00b1 0.0370.952 \u00b1 0.0230.767\u00b10.029TG-MC LSTM0.974 \u00b1 0.0280.918 \u00b1 0.0170.931\u00b10.0090.790\u00b10.020TG-MC RNN1.032\u00b1 0.0300.830\u00b10.0270.876 \u00b1 0.0230.783 \u00b1 0.027MovieLens 1MTG-MC GRU1.019\u00b10.0280.818\u00b1 0.0280.867 \u00b1 0.0130.697 \u00b1 0.023TG-MC LSTM1.015 \u00b1 0.0220.768\u00b1 0.0260.834 \u00b1 0.0110.664 \u00b1 0.028"}, {"figure_label": "II", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "RMSE scores obtained by our method and reference methods on the Netflix and MovieLens 1M datasets.", "figure_data": "MethodNetflix MovieLens 1MPMF [20]0.9570.883I-AutoRec [21]0.9790.833U-AutoRec [21]0.9850.877GCMC [11]1.2641.001TG-MC (ours)0.9310.834"}, {"figure_label": "III", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "Comparison of our method and TCF methods on the Netflix and MovieLens datasets. (a) Average test RMSE scores for different TCF models on the Netflix Data Set. Average test MAE scores for different TCF models on the Movie-Lens 1M Data Set.", "figure_data": "MethodRMSE(b) MethodMAETemporal MF [26] RRN [2] TimeSVD++ [4] NCF [27]1.112 0.944 0.962 0.947Temporal MF [26] RRN [2] AM N =10.843 0.793LFM [28]0.936TG-MC (ours)0.931"}], "formulas": [{"formula_id": "formula_0", "formula_text": "connected to i) in graph G t h i,t = \u03c3 \uf8ee \uf8f0 accum \uf8eb \uf8ed j\u2208Ni,1 \u00b5 j\u2192i,1,t , ..., j\u2208N i,R \u00b5 j\u2192i,R,t \uf8f6 \uf8f8 \uf8f9 \uf8fb ,(1)", "formula_coordinates": [3.0, 47.98, 516.85, 243.68, 62.25]}, {"formula_id": "formula_2", "formula_text": "z i,t = \u03c3 (W t h i,t ) ,(3)", "formula_coordinates": [3.0, 392.22, 363.15, 162.45, 9.65]}, {"formula_id": "formula_3", "formula_text": "P (R i,j,t = r) = exp(u T i,t Q r,t v j,t ) s\u2208R exp(u T i,t Q s,t v j,t ) ,(4)", "formula_coordinates": [3.0, 343.58, 540.81, 211.1, 27.66]}, {"formula_id": "formula_4", "formula_text": "L graph = \u2212 i,j\u2208\u2126t log P (R i,j,t = r),(5)", "formula_coordinates": [3.0, 354.7, 677.2, 199.97, 20.06]}, {"formula_id": "formula_5", "formula_text": "U T +1 = f RNN (U 1 , . . . , U T ),(6)", "formula_coordinates": [4.0, 371.54, 314.09, 183.14, 9.81]}, {"formula_id": "formula_6", "formula_text": "L user-RNN = 1 N N i=1 U i \u2212 U i 2 F ,(7)", "formula_coordinates": [4.0, 364.91, 479.48, 189.77, 30.32]}, {"formula_id": "formula_7", "formula_text": "R i,j,t = r\u2208R rP (R i,j,t = r)(8)", "formula_coordinates": [5.0, 109.53, 91.16, 182.13, 20.06]}], "doi": ""}