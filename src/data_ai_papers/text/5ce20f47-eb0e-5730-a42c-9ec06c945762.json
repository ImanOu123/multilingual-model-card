{"title": "On the Tractability of SHAP Explanations", "authors": "Guy Van Den Broeck; Anton Lykov; Maximilian Schleich; Dan Suciu", "pub_date": "2021-01-31", "abstract": "SHAP explanations are a popular feature-attribution mechanism for explainable AI. They use game-theoretic notions to measure the influence of individual features on the prediction of a machine learning model. Despite a lot of recent interest from both academia and industry, it is not known whether SHAP explanations of common machine learning models can be computed efficiently. In this paper, we establish the complexity of computing the SHAP explanation in three important settings. First, we consider fully-factorized data distributions, and show that the complexity of computing the SHAP explanation is the same as the complexity of computing the expected value of the model. This fully-factorized setting is often used to simplify the SHAP computation, yet our results show that the computation can be intractable for commonly used models such as logistic regression. Going beyond fullyfactorized distributions, we show that computing SHAP explanations is already intractable for a very simple setting: computing SHAP explanations of trivial classifiers over naive Bayes distributions. Finally, we show that even computing SHAP over the empirical distribution is #P-hard.", "sections": [{"heading": "Introduction", "text": "Machine learning is increasingly applied in high stakes decision making. As a consequence, there is growing demand for the ability to explain the prediction of machine learning models. One popular explanation technique is to compute feature-attribution scores, in particular using the Shapley values from cooperative game theory (Roth 1988) as a principled aggregation measure to determine the influence of individual features on the prediction of the collective model. Shapley value based explanations have several desirable properties (Datta, Sen, and Zick 2016), which is why they have attracted a lot of interest in academia as well as industry in recent years (see e.g., Gade et al. (2019)). Strumbelj and Kononenko (2014) show that Shapley values can be used to explain arbitrary machine learning models. Datta, Sen, and Zick (2016) use Shapley-value-based explanations as part of a broader framework for algorithmic transparency. Lundberg and Lee (2017) use Shapley values in a framework that unifies various explanation techniques, and they coined the term SHAP explanation. They show that the SHAP explanation is effective in explaining predictions in the medical domain; see Lundberg et al. (2020). More recently there has been a lot of work on the tradeoffs of variants of the original SHAP explanations, e.g., Sundararajan and Najmi (2020), Kumar et al. (2020), Janzing, Minorics, and Bloebaum (2020), Merrick and Taly (2020), and Aas, Jullum, and L\u00f8land (2019).\nDespite all of this interest, there is considerable confusion about the tractability of computing SHAP explanations. The SHAP explanations determine the influence of a given feature by systematically computing the expected value of the model given a subsets of the features. As a consequence, the complexity of computing SHAP explanations depends on the predictive model as well as assumptions on the underlying data distribution. Lundberg et al. (2020) describe a polynomial-time algorithm for computing the SHAP explanation over decision trees, but online discussions have pointed out that this algorithm is not correct as stated. We present a concrete example of this shortcoming in the supplementary material, in Appendix A. In contrast, for fully-factorized distributions, Bertossi et al. (2020) prove that there are models for which computing the SHAP explanation is #P-hard. A contemporaneous paper by Arenas et al. (2020) shows that computing the SHAP explanation for tractable logical circuits over uniform and fully factorized binary data distributions is tractable. In general, the complexity of the SHAP explanation is open.\nIn this paper we consider the original formulation of the SHAP explanation by Lundberg and Lee (2017) and analyze its computational complexity under the following data distributions and model classes:\n1. First, we consider fully-factorized distributions, which are the simplest possible data distribution. Fully-factorized distributions capture the assumption that the model's features are independent, which is a commonly used assumption to simplify the computation of the SHAP explanations, see for example Lundberg and Lee (2017).\nFor fully-factorized distributions and any prediction model, we show that the complexity of computing the SHAP explanation is the same as the complexity of computing the expected value of the model. It follows that there are classes of models for which the computation is tractable (e.g., linear regression, decision trees, tractable circuits) while for other models, including commonly used ones such as logistic regression and neural nets with sigmoid activation functions, it is #P-hard. 2. Going beyond fully-factorized distributions, we show that computing SHAP explanation becomes intractable already for the simplest probabilistic model that does not assume feature independence: naive Bayes. As a consequence, the complexity of computing SHAP explanations on such data distributions is also intractable for many classes of models, including linear and logistic regression. 3. Finally we consider the empirical distribution, and prove that computing SHAP explanations is #P-hard for this class of distributions. This result implies that the algorithm by Lundberg et al. (2020) cannot be fixed to compute the exact SHAP explanations over decision trees in polynomial time.", "publication_ref": ["b24", "b7", "b10", "b7", "b19", "b17", "b27", "b15", "b11", "b20", "b0", "b17", "b3", "b1", "b19", "b19", "b17"], "figure_ref": [], "table_ref": []}, {"heading": "Background and Problem Statement", "text": "Suppose our data is described by n indexed features X = {X 1 , . . . , X n }. Each feature variable X takes a value from a finite domain dom(X). A data instance x = (x 1 , . . . , x n ) consists of values x \u2208 dom(X) for every feature X. This instance space is denoted x \u2208 X = dom(X 1 ) \u00d7 \u2022 \u2022 \u2022 \u00d7 dom(X n ). We are also given a learned function F : X \u2192 R that computes a prediction F (x) on each instance x.\nThroughout this paper we assume that the prediction F (x) can be computed in polynomial time in n.\nFor a particular instance of prediction F (x), the goal of local explanations is to clarify why the function F gave its prediction on instance x, usually by attributing credit to the features. We will focus on local explanation that are inspired by game-theoretic Shapley values (Datta, Sen, and Zick 2016;Lundberg and Lee 2017). Specifically, we will work with the SHAP explanations as defined by Lundberg and Lee (2017).", "publication_ref": ["b7", "b19", "b19"], "figure_ref": [], "table_ref": []}, {"heading": "SHAP Explanations", "text": "To produce SHAP explanations, one needs an additional ingredient: a probability distribution Pr(X) over the features, which we call the data distribution. We will use this distribution to reason about partial instances. Concretely, for a set of indices S \u2286 [n] = {1, . . . , n}, we let x S denote the restriction of complete instance x to those features X S with indices in S. Abusing notation, we will also use x S to denote the probabilistic event X S = x S .\nUnder this data distribution, it now becomes possible to ask for the expected value of the predictive function F . Clearly, for a complete data instance x we have that E[F |x] = F (x), as there is no uncertainty about the features. However, for a partial instance x S , which does not assign values to the features outside of X S , we appeal to the data distribution Pr to compute the expectation of function\nF as E Pr [F |x S ] = x\u2208X F (x) Pr(x|x S ).\nThe SHAP explanation framework draws from Shapley values in cooperative game theory. Given a particular instance x, it considers features X to be players in a coalition game: the game of making a prediction for x. SHAP explanations are defined in terms of a set function v F,x,Pr : 2 X \u2192 R. Its purpose is to evaluate the \"value\" of each coalition of players/features X S \u2286 X in making the prediction F (x) under data distribution Pr. Concretely, following Lundberg and Lee (2017), this value function is the conditional expectation of function F :\nv F,x,Pr (X S ) def = E Pr [F |x S ].\n(1)\nWe will elide F , x, and Pr when they are clear from context. Our goal, however, is to assign credit to individual features. In the context of a coalition X S , the contribution of an individual feature X / \u2208 X S is given by\nc(X, X S ) def = v(X S \u222a {X}) \u2212 v(X S ). (2\n)\nwhere each term is implicitly w.r.t. the same F , x, and Pr.\nFinally, the SHAP explanation computes a score for each feature X \u2208 X averaged over all possible contexts, and thus measures the influence feature X has on the outcome. Let \u03c0 be a permutation on the set of features X, i.e., \u03c0 fixes a total order on all features. Let \u03c0 <X be the set of features that come before X in the order \u03c0. The SHAP explanations are then defined as computing the following scores. Definition 1 (SHAP Score). Fix an entity x, a predictive function F , and a data distribution Pr. The SHAP explanation of a feature X is the contribution of X given the features \u03c0 <X , averaged over all permutations \u03c0:\nSHAP(X) def = 1 n! \u03c0 c(X, \u03c0 <X ).(3)\nWe mention two simple properties of the SHAP explanations here; for more discussion see Datta, Sen, and Zick (2016) and Lundberg et al. (2020). First, for the linear combination of functions G(.) = k \u03bb k F k (.), we have that\nSHAP G (X) = k \u03bb k SHAP F k (X).(4)\nSecond, the sum of the SHAP explanation of all features is related to the expected value of function F :\ni SHAP F (X i ) = F (x) \u2212 E[F ].(5)", "publication_ref": ["b19", "b7", "b17"], "figure_ref": [], "table_ref": []}, {"heading": "Computational Problems", "text": "This paper studies the complexity of computing SHAP(X); a task we formally define next. We write F for a class of functions. We also write PR n for a class of data distributions over n features, and let PR = n PR n . We assume that all parameters are rationals. Because SHAP explanations are for an arbitrary fixed instance x, we will simplify the notation throughout this paper by assuming it to be the instance e = (1, 1, . . . , 1), and that each domain contains the value 1, which is without loss of generality. Definition 2 (SHAP Computational Problems). For each function class F and distribution class PR, consider the following computational problems.\n-The functional SHAP problem F-SHAP(F, PR): given a data distribution Pr \u2208 PR and a function F \u2208 F, compute SHAP(X 1 ), . . . , SHAP(X n ).\n-The decision SHAP problem D-SHAP(F, PR): given a data distribution Pr \u2208 PR, a function F \u2208 F, a feature X \u2208 X, and a threshold t \u2208 R, decide if SHAP(X) > t.\nTo establish the complexities of these problems, we use standard notions of reductions. A polynomial time reduction from a problem A to a problem B, denoted by A \u2264 P B, and also called a Cook reduction, is a polynomial-time algorithm for the problem A with access to an oracle for the problem B. We write A \u2261 P B when both A \u2264 P B and B \u2264 P A.\nIn the remainder of this paper will study the computational complexity of these problems for natural hypothesis classes F that are popular in machine learning, as well as common classes of data distributions PR, including those most often used to compute SHAP explanations.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "SHAP over Fully-Factorized Distributions", "text": "We start our study of the complexity of SHAP by considering the simplest probability distribution: a fully-factorized distribution, where all features are independent.\nThere are both practical and computational reasons why it makes sense to assume a fully-factorized data distribution when computing SHAP explanations. First, functions F are often the product of a supervised learning algorithm that does not have access to a generative model of the datait is purely discriminative. Hence, it is convenient to make the practical assumption that the data distribution is fully factorized, and therefore easy to estimate. Second, fullyfactorized distributions are highly tractable; for example they make it easy to compute expectations of linear regression functions (Khosravi et al. 2019b) and other hard inference tasks (Vergari et al. 2020). Lundberg and Lee (2017) indeed observe that computing the SHAP-explanation on an arbitrary data distribution is challenging and consider using fully-factorized distributions (Sec. 4, Eq. 11). Other prior work on computing explanations also use fully-factorized distributions of features, e.g., Datta, Sen, and Zick (2016); \u0160trumbelj and Kononenko (2014). As we will show, the SHAP explanation can be computed efficiently for several popular classifiers when the distribution is fully factorized. Yet, such simple data distributions are not a guarantee for tractability: computing SHAP scores will be intractable for some other common classifiers.", "publication_ref": ["b13", "b29", "b19", "b7"], "figure_ref": [], "table_ref": []}, {"heading": "Equivalence to Computing Expectations", "text": "Before studying various function classes, we prove a key result that connects the complexity of SHAP explanations to the complexity of computing expectations.\nLet IND n be the class of fully-factorized probability distributions over n discrete and independent random variables X 1 , . . . , X n . That is, for every instance (x 1 , . . . , x n ) \u2208 X , we have that Pr(X\n1 = x 1 , . . . , X n = x n ) = i Pr(X i = x i ). Let IND def = n\u22650 IND n .\nWe show that for every function class F, the complexity of F-SHAP(F, IND) is the same as that of the fully-factorized expectation problem.\nDefinition 3 (Fully-Factorized Expectation Problem). Let F be a class of real-valued functions with discrete inputs. The fully-factorized expectation problem for F, denoted E(F), is the following: given a function F \u2208 F and a probability distribution Pr \u2208 IND, compute E Pr (F ).\nWe know from Equation 5 that for any function\nF over n features, E({F }) \u2264 P F-SHAP({F }, IND n ), because E[F ] = F (x) \u2212 i=1,n SHAP F (X i ).\nIn this section we prove that the converse holds too: Theorem 1. For any function F : X \u2192 R, we have that\nF-SHAP({F }, IND n ) \u2261 P E({F }).\nIn other words, for any function F , the complexity of computing the SHAP scores is the same as the complexity of computing the expected value E[F ] under a fully-factorized data distribution. One direction of the proof is immediate: E({F }) \u2264 P F-SHAP({F }, IND n ) because, if we are given an oracle to compute SHAP F (X i ) for every feature X i , then we can obtain E[F ] from Equation 5(recall that we assumed that F (x) is computable in polynomial time). The hard part of the proof is the opposite direction: we will show in Sec. 3.2 how to compute SHAP F (X i ) given an oracle for computing E[F ]. Theorem 1 immediately extends to classes of functions F, and to any number of variables, and therefore implies that F-SHAP(F, IND) \u2261 P E(F).\nSections 3.3 and 3.4 will discuss the consequences of this result, by delineating which function classes support tractable SHAP explanations, and which do not. The next section is devoted to proving our main technical result.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Proof of Theorem 1", "text": "We start with the special case when all features X are binary: dom(X) = {0, 1}. We denote by INDB n the class of fullyfactorized distributions over binary domains. Theorem 2. For any function F : {0, 1} n \u2192 R, we have that F-SHAP({F }, INDB n ) \u2261 P E({F }).\nProof. We prove only F-SHAP(F, INDB n ) \u2264 P E({F }); the opposite direction follows immediately from Equation 5. We will assume w.l.o.g. that F has n + 1 binary features X \u2032 = {X 0 } \u222a X and show how to compute SHAP F (X 0 ) using repeated calls to an oracle for computing E[F ], i.e., the expectation of the same function F , but over fully-factorized distributions with different probabilities. The probability distribution Pr is given to us by n + 1 rational numbers,\np i def = Pr(X i = 1), i = 0, n; obviously, Pr(X i = 0) = 1 \u2212 p i .\nRecall that the instance whose outcome we want to explain is e = (1, . . . , 1). Recall that for any set S \u2286 [n] we write e S for the event i\u2208S (X i = 1). Then, we have that\nSHAP(X 0 ) = k=0,n k!(n \u2212 k)! (n + 1)! D k , where(6)\nD k def = S\u2286[n]:|S|=k E F |e S\u222a{0} \u2212 E[F |e S ] . Let F 0 def = F [X 0 := 0] and F 1 def = F [X 0 := 1]\n(both are functions in n binary features, X = {X 1 , . . . , X n }). Then:\nE F e S\u222a{0} = E[F 1 |e S ] E[F |e S ] = E[F 0 |e S ] \u2022 (1 \u2212 p 0 ) + E[F 1 |e S ] \u2022 p 0\nand therefore D k is given by:\nD k = (1 \u2212 p 0 ) S\u2286[n]:|S|=k (E[F 1 |e S ] \u2212 E[F 0 |e S ])\nFor any function G, Equation 1 defines value v G,e,Pr (X S ) as E[G|e S ]. Abusing notation, we write v G,k for the sum of these quantities over all sets S of cardinality k:\nv G,k def = S\u2286[n],|S|=k E[G|e S ].(7)\nWe will prove the following claim.\nClaim 1. Let G be a function over n binary variables. Then the n+1 quantities v G,0 until v G,n can be computed in polynomial time, using n + 1 calls to an oracle for E({G}).\nNote that an oracle for E({F }) is also an oracle for both E({F 0 }) and E({F 1 }), by simply setting Pr(X 0 = 1) = 0 or Pr(X 0 = 1) = 1 respectively. Therefore, Claim 1 proves Theorem 2, by applying it once to F 0 and once to F 1 in order to derive all the quantities v F0,k and v F1,k , thereby computing D k , and finally computing SHAP F (X 0 ) using Equation 6. It remains to prove Claim 1.\nFix a function G over n binary variables and let v k = v G,k . Let p j = Pr(X j = 1), for j = 1, n, define the distribution over which we need to compute v 0 , . . . , v n . We will prove the following additional claim.\nClaim 2. Given any real number z > 0, consider the distribution Pr z (X\nj ) = p \u2032 j def = pj +z 1+z , for j = 1, n. Let E z [G] denote E[G] under distribution Pr z . We then have that k=0,n z k \u2022 v k =(1 + z) n \u2022 E z [G].(8)\nAssuming Claim 2 holds, we prove Claim 1. Choose any n + 1 distinct values for z, use the oracle to compute the quantities E z0 [G], . . . , E zn [G], and form a system of n + 1 linear equations (8) with unknowns v 0 , . . . , v n . Next, observe that its matrix is a non-singular Vandermonde matrix, hence the system has a unique solution which can be computed in polynomial time. It remains to prove Claim 2.\nBecause of independence, the probability of instance\nx \u2208 {0, 1} n is Pr(x) = i:xi=1 p i \u2022 i:xi=0 (1 \u2212 p i ), where x i looks up the value of feature X i in instance x. Similarly, Pr z (x) = i:xi=1 p \u2032 i \u2022 i:xi=0 (1 \u2212 p \u2032 i ).\nUsing direct calculations we derive:\nPr(x) i:xi=1 1 + z p i = (1 + z) n \u2022 Pr z (x)(9)\nSeparately we also derive the following identity, using the fact that Pr(e S ) = i\u2208S p i by independence:\nE[G|e S ] = 1 i\u2208S p i x:xS=eS G(x) \u2022 Pr(x)(10)\nWe are now in a position to prove Claim 2:\nk=0,n z k \u2022 v k = k=0,n z k S\u2286[n]:|S|=k E[G|e S ] = S\u2286[n] z |S| \u2022 E[G|e S ] = S\u2286[n] z |S| i\u2208S p i x:xS=eS G(x) \u2022 Pr(x)\nThe last line follows from Equation 10. Next, we simply exchange the summations S and x , after which we apply the identity S\u2286A i\u2208S u i = i\u2208A (1 + u i ).\n(continuing)\n= x\u2208{0,1} n G(x) \u2022 Pr(x) S:xS =eS z |S| i\u2208S p i = x\u2208{0,1} n G(x) \u2022 Pr(x) i:xi=1 1 + z p i = (1 + z) n x\u2208{0,1} n G(x) \u2022 Pr z (x) = (1 + z) n \u2022 E z [G].\nThe final line uses Equation 9. This completes the proof of Claim 2 as well as Theorem 2.\nNext, we generalize this result from binary features to arbitrary discrete features. Fix a function with n inputs,\nF : X ( def = i dom(X i )) \u2192 R,\nwhere each domain is an arbitrary finite set, dom(X i ) = {1, 2, . . . , m i }; we assume w.l.o.g. that m i > 1. A fully factorized probability space Pr \u2208 IND n is defined by numbers p ij \u2208 [0, 1], i = 1, n, j = 1, m i , such that, for all i, j p ij = 1. Given F and Pr over the domain i dom(X i ), we define their projections, F \u03c0 , Pr \u03c0 over the binary domain {0, 1} n as follows. For any instance x \u2208 {0, 1} n , let T (x) denote the event asserting that X j = 1 iff x j = 1. Formally,\nT (x) def = j:xj =1 (X j = 1) \u2227 j:xj =0 (X j = 1).\nThen, the projections are defined as follows:\n\u2200x \u2208 {0, 1} n , Pr \u03c0 (x) def = Pr(T (x)) F \u03c0 (x) def = E[F | T (x)](11)\nNotice that F \u03c0 depends both on F and on the probability distribution Pr. Intuitively, the projections only distinguishes between X j = 1 and X j = 1, for example:\nF \u03c0 (1, 0, 0) =E[F |(X 1 = 1, X 2 = 1, X 3 = 1)] Pr \u03c0 (1, 0, 0) =Pr(X 1 = 1, X 2 = 1, X 3 = 1)\nWe prove the following result in Appendix B:\nProposition 3. Let F : X \u2192 R be a function with n input features, and Pr \u2208 IND n a fully factorized distribution over X . Then (1) for any feature X j , SHAP F,Pr (X j ) = SHAP F\u03c0,Pr\u03c0 (X j ), and (2) E({F \u03c0 }) \u2264 P E({F }).\nItem (1) states that the SHAP-score of F computed over the probability space Pr is the same as that of its projection F \u03c0 (which depends on Pr) over the projected probability space Pr \u03c0 . Item (2) says that, for any probability space over {0, 1} n (not necessarily Pr \u03c0 ), we can compute E[F \u03c0 ] in polynomial time given access to an oracle for computing E[F ]. We can now complete the proof of Theorem 1, by showing that F-SHAP({F }, IND n ) \u2264 P E({F }). Given a function F and probability space Pr \u2208 IND n , in order to compute SHAP F,Pr (X j ), by item (1) of Proposition 3 it suffices to show how to compute SHAP F\u03c0,Pr\u03c0 (X j ). By Theorem 2, we can compute the latter given access to an oracle for computing E[F \u03c0 ]. Finally, by item (2) of the proposition, we can compute E[F \u03c0 ] given an oracle for computing E[F ].", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Tractable Function Classes", "text": "Given the polynomial-time equivalence between computing SHAP explanations and computing expectations under fullyfactorized distributions, a natural next question is: which real-world hypothesis classes in machine learning support efficient computation of SHAP scores? ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Linear regression models 2. Decision and regression trees 3. Random forests or additive tree ensembles 4. Factorization machines, regression circuits 5. Boolean functions in d-DNNF, binary decision diagrams 6. Bounded-treewidth Boolean functions in CNF", "text": "These are all consequences of Theorem 1, and the fact that computing fully-factorized expectations E(F) for these function classes F is in polynomial time. Concretely, we have the following observations about fully-factorized expectations:\n1. Expectations of linear regression functions are efficiently computed by mean imputation (Khosravi et al. 2019b).\nThe tractability of SHAP on linear regression models is well known. In fact,\u0160trumbelj and Kononenko ( 2014) provide a closed-form formula for this case.\n2. Paths from root to leaf in a decision or regression tree are mutually exclusive. Their expected value is therefore the sum of expected values of each path, which are tractable to compute within IND; see Khosravi et al. (2020).\n3. Additive mixtures of trees, as obtained through bagging or boosting, are tractable, by the linearity of expectation.\n4. Factorization machines extend linear regression models with feature interaction terms and factorize the parameters of the higher-order terms (Rendle 2010). Their expectations remain easy to compute. Regression circuits are a graph-based generalization of linear regression. Khosravi et al. (2019a) provide an algorithm to efficiently take their expectation w.r.t. a probabilistic circuit distribution, which is trivial to construct for the fully-factorized case.\nThe remaining tractable cases are Boolean functions. Computing fully-factorized expectations of Boolean functions is widely known as the weighted model counting task (WMC) (Sang, Beame, and Kautz 2005;Chavira and Darwiche 2008). WMC has been extensively studied both in the theory and the AI communities, and the precise complexity of E(F) is known for many families of Boolean functions F. These results immediately carry over to the F-SHAP(F, IND) problem through Theorem 1:\n5. Expectations can be computed in time linear in the size of various circuit representations, called d-DNNF, which includes binary decision diagrams (OBDD, FBDD) and SDDs (Bryant 1986;Darwiche and Marquis 2002). 1\n6. Bounded-treewidth CNFs are efficiently compiled into OBDD circuits (Ferrara, Pan, and Vardi 2005), and thus enjoy tractable expectations.\nTo conclude this section, the reader may wonder about the algorithmic complexity of solving F-SHAP(F, IND) with an oracle for E(F) under the reduction in Section 3.2. Briefly, we require a linear number of calls to the oracle, as well as time in O(n 3 ) for solving a system of linear equations. Hence, for those classes, such as d-DNNF circuits, where expectations are linear in the size of the (circuit) representation of F , computing F-SHAP(F, IND) is also linear in the representation size and polynomial in n.", "publication_ref": ["b13", "b14", "b23", "b12", "b25", "b5", "b4", "b6", "b9"], "figure_ref": [], "table_ref": []}, {"heading": "Intractable Function Classes", "text": "The polynomial-time equivalence of Theorem 1 also implies that computing SHAP scores must be intractable whenever computing fully-factorized expectations is intractable. This section reviews some of those function classes F, including some for which the computational hardness of E(F) is well known. We begin, however, with a more surprising result.\nLogistic regression is one of the simplest and most widely used machine learning models, yet it is conspicuously absent from Corollary 4. We prove that computing the expectation of a logistic regression model is #P-hard, even under a uniform data distribution, which is of independent interest.\nA logistic regression model is a parameterized function\nF (x) def = \u03c3(w \u2022 x), where w = (w 0 , w 1 , . . . , w n ) is a vector of weights, \u03c3(z) = 1/(1+e \u2212z ) is the logistic function, x def = (1, x 1 , x 2 , . . . , x n ), and w \u2022 x def =\ni=0,n w i x i is the dot product. Note that we define the logistic regression function to output probabilities, not data labels. Let LOGIT n denote the class of logistic regression functions with n variables, and LOGIT = n LOGIT n . We prove the following: Theorem 5. Computing the expectation of a logistic regression model w.r.t. a uniform data distribution is #P-hard.\nThe full proof in Appendix C is by reduction from counting solutions to the number partitioning problem.\nBecause the uniform distribution is contained in IND, and following Theorem 1, we immediately obtain: Corollary 6. The computational problems E(LOGIT) and F-SHAP(LOGIT, IND) are both #P-hard.\nWe are now ready to list general function classes for which computing the SHAP explanation is #P-hard.\nCorollary 7. For the following function classes F, computing SHAP scores F-SHAP(F, IND) is #P-hard in the size of the representations of function F \u2208 F and fully-factorized distribution Pr \u2208 IND. Corollary 6)  2 ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Logistic regression models (", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Beyond Fully-Factorized Distributions", "text": "Features in real-world data distributions are not independent. In order to capture more realistic assumptions about the data when computing SHAP scores, one needs a more intricate probabilistic model. In this section we prove that the complexity of computing the SHAP-explanation quickly becomes intractable, even over the simplest probabilistic models, namely naive Bayes models. To make computing the SHAP-explanation as easy as possible, we will assume that the function F simply outputs the value of one feature. We show that even in this case, even for function classes that are tractable under fully-factorized distributions, computing SHAP explanations becomes computationally hard. Let NBN n denote the family of naive Bayes networks over n + 1 variables X = {X 0 , X 1 , . . . , X n }, with binary domains, where X 0 is a parent of all features:\nPr(X) = Pr(X 0 ) \u2022 i=1,n Pr(X i |X 0 ).\nAs usual, the class NBN def = n\u22650 NBN n . We write X 0 for the function F that returns the value of feature X 0 ; that is, F (x) = x 0 . We prove the following.\nTheorem 8. The decision problem D-SHAP({X 0 }, NBN) is NP-hard.\nThe proof in Appendix D is by reduction from the number partitioning problem, similar to the proof of Corollary 6. We note that the subset sum problem was also used to prove related hardness results, e.g., for proving hardness of the Shapely value in network games (Elkind et al. 2008). This result is in sharp contrast with the complexity of the SHAP score over fully-factorized distributions in Section 3. There, the complexity was dictated by the choice of function class F. Here, the function is as simple as possible, yet computing SHAP is hard. This ruins any hope of achieving tractability by restricting the function, and this motivates us to restrict the probability distribution in the next section. This result is also surprising because it is efficient to compute marginal probabilities (such as the expectation of X 0 ) and conditional probabilities in naive Bayes distributions.\nTheorem 8 immediately extends to a large class of probability distributions and functions. We say that F depends only on X i if there exist two constants c 0 = c 1 such that F (x) = c 0 when x i = 0 and F (x) = c 1 when x i = 1. In other words, F ignores all variables other than X i , and does depend on X i . We then have the following.\nCorollary 9. The problem D-SHAP(F, PR) is NP-hard, when PR is any of the following classes of distributions:\n1. Naive Bayes, bounded-treewidth Bayesian networks 2. Bayesian networks Markov networks, Factor graphs 3. Decomposable probabilistic circuits and when F is any class that contains some function F that depends only on X 0 , including the class of linear regression models and all the classes listed in Corollaries 4 and 7.\nThis corollary follows from two simple observations. First, each of the classes of probability distributions listed in the corollary can represent a naive Bayes network over binary variables X. For example, a Markov network will consists of n factors f 1 (X 0 , X 1 ), f 2 (X 0 , X 2 ), . . . , f n (X 0 , X n ); similar simple arguments prove that all the other classes can represent naive Bayes, including tractable probabilistic circuits such as sum-product networks (Vergari et al. 2020).\nSecond, for each function that depends only on X 0 , there exist two distinct constants c 0 = c 1 \u2208 R such that F (x) = c 0 when x 0 = 0 and F (x) = c 1 when x 0 = 1. For example, if we consider the class of logistic regression functions F (x) = \u03c3( i w i x i ), then we choose the weights w 0 = 1, w 1 = . . . = w n = 0 and we obtain F (x) = 1/2 when x 0 = 0 and F (x) = 1/(1 + e \u22121 ) when x 0 = 1. Then, over the binary domain {0, 1} the function is equivalent to F (x) = (c 1 \u2212 c 0 )x 0 + c 0 , and, therefore, by the linearity of the SHAP explanation (Equation 4) we have SHAP F (X 0 ) = (c 1 \u2212 c 0 ) \u2022 SHAP X0 (X 0 ) (because the SHAP explanation of a constant function c 0 is 0) for which, by Theorem 8, the decision problem is NP-hard.\nWe end this section by proving that Theorem 8 continues to hold even if the prediction function F is the value of some leaf node of a (bounded treewidth) Bayesian Network. In other words, the hardness of the SHAP explanation is not tied to the function returning the root of the network, and applies to more general functions.\nCorollary 10. The SHAP decision problem for Bayesian networks with latent variables is NP-hard, even if the function F returns a single leaf variable of the network.\nThe full proof is given in Appendix E.\nIn supervised learning one does not require a generative model of the data, instead, the model is trained on some concrete data set: the training data. When some probabilistic model is needed, then the training data itself is conveniently used as a probability model, called the empirical distribution. This distribution captures dependencies between features, while its set of possible worlds is limited to those in the data set. For example, the intent of the Ker-nelSHAP algorithm by Lundberg and Lee (2017) is to compute the SHAP explanation on the empirical distribution. In another example, Aas, Jullum, and L\u00f8land (2019) extend KernelSHAP to work with dependent features, by estimating the conditional probabilities from the empirical distribution.\nCompared to the data distributions considered in the previous sections, the empirical distribution has one key advantage: it has many fewer possible worlds with positive probability -this suggests increased tractability. Unfortunately, in this section, we prove that computing the SHAP explanation over the empirical distribution is #P-hard in general.\nTo simplify the presentation, this section assumes that all features are binary: dom(X j ) = {0, 1}. The probability distribution is given by a 0/1-matrix\nd = (x ij ) i\u2208[m],j\u2208[n] ,\nwhere each row (x i1 , . . . , x in ) is an outcome with probability 1/m. One can think of d as a dataset with n features and m data instances, where each row (x i1 , . . . , x in ) is one data instance. Repeated rows are possible: if a row occurs k times, then its probability is k/m. We denote by X the class of empirical distributions. The predictive function can be any function F : {0, 1} n \u2192 R. As our data distribution is no longer strictly positive, we adopt the standard convention that E[F |X S = 1] = 0 when Pr(X S = 1) = 0.\nRecall from Section 2.2 that, by convention, we compute the SHAP-explanation w.r.t. instance e = (1, 1, . . . , 1), which is without loss of generality. Somewhat surprisingly, the complexity of computing the SHAP-explanation of a function F over the empirical distribution given by a matrix d is related to the problem of computing the expectation of a certain CNF formula associated to d. Definition 4. The positive, partitioned 2CNF formula, PP2CNF, associated to a matrix d \u2208 {0, 1} m\u00d7n is:\n\u03a6 d def = (i,j):xij =0 (U i \u2228 V j ). Thus, a PP2CNF formula is over m + n variables U 1 , . . . , U m , V 1 , . . . , V n ,\nand has only positive clauses. The matrix d dictates which clauses are present. A quasysymmetric probability distribution is a fully factorized distribution over the m + n variables for which there exists two numbers p, q \u2208 [0, 1] such that for every i = 1, m, Pr(U i = 1) = p or Pr(U i = 1) = 1, and for every j = 1, n, Pr(V j = 1) = q or Pr(V j = 1). In other words, all variables U 1 , . . . , U m have the same probability p, or have probability 1, and similarly for the variables V 1 , . . . , V n . We denote by EQS(PP2CNF) the expectation computation problem for PP2CNF over quasi-symmetric probability distributions. EQS(PP2CNF) is #P-hard, because computing E[\u03a6 d ] under the uniform distribution (i.e. Pr(U (Provan and Ball 1983). We prove:\n1 = 1) = \u2022 \u2022 \u2022 = Pr(V n = 1) = 1/2) is #P-hard\nTheorem 11. Let X be the class of empirical distributions, and F be any class of function such that, for each i, it includes some function that depends only on X i . Then, we have that F-SHAP(F, X) \u2261 P EQS(PP2CNF).\nAs a consequence, the problem F-SHAP(F, X) is #P-hard in the size of the empirical distribution.\nThe theorem is surprising, because the set of possible outcomes of an empirical distribution is small. This is unlike all the distributions discussed earlier, for example those mentioned in Corollary 9, which have 2 n possible outcomes, where n is the number of features. In particular, given an empirical distribution d, one can compute the expectation E[F ] in polynomial time for any function F , by doing just one iteration over the data. Yet, computing the SHAP explanation of F is #P-hard.\nTheorem 11 implies hardness of SHAP explanations on the empirical distribution for a large class of functions.\nCorollary 12. The problem F-SHAP(F, X) is #P-hard, when X is the class of empirical distributions, and F is any class such that for each feature X i , the class contains some function that depends only on X i . This includes all the function classes listed in Corollaries 4 and 7.\nFor instance, any class of Boolean function that contains the n single-variable functions F def = X i , for i = 1, n, fall under this corollary. Section 4 showed an example of how the class of logistic regression functions fall under this corollary as well.\nThe proof of Theorem 11 follows from the following technical lemma, which is of independent interest: Lemma 13. We have that:\n1. For every matrix d, F-SHAP(F, d) \u2264 P EQS({\u03a6 d }). 2. EQS(PP2CNF) \u2264 P F-SHAP(F, X).\nThe proof of the Lemma is given in Appendix F and G. The first item says that we can compute the SHAPexplanation in polynomial time using an oracle for computing E[\u03a6 d ] over quasi-symmetric distributions. The oracle is called only on the PP2CNF \u03a6 d associated to the data d, but may perform repeated calls, with different probabilities of the Boolean variables. This is somewhat surprising because the SHAP explanation is over an empirical distribution, while E[\u03a6 d ] is taken over a fully-factorized distribution; there is no connection between these two distributions. This item immediately implies F-SHAP(F, X) \u2264 P EQS(PP2CNF), where X is the class of empirical distributions d, since the formula \u03a6 d is in the class PP2CNF.\nThe second item says that a weak form of converse also holds. It states that we can compute in polynomial time the expectation E[\u03a6] over a quasi-symmetric probability distributions by using an oracle for computing SHAP explanations, over several matrices d, but not necessarily restricted to the matrix associated to \u03a6. Together, the two items of the lemma prove Theorem 11.\nWe end this section with a comment on the TreeSHAP algorithm in Lundberg et al. (2020), which is computed over a distribution defined by a tree-based model. Our result implies that the problem that TreeSHAP tries to solve is #Phard. This follows immediately by observing that every empirical distribution d can be represented by a binary tree of size polynomial in the size of d. The tree examines the attributes in the order X 1 , X 2 , . . . , X n , and each decision node for X i has two branches: X i = 0 and X i = 1. A branch that does not exists in the matrix d will end in a leaf with label 0. A complete branch that corresponds to a row x i1 , x i2 , . . . , x in in d ends in a leaf with label 1/m (or k/m if that row occurs k times in d). The size of this tree is no larger than twice the size of the matrix (because of the extra dead end branches). This concludes our study of SHAP explanations on the empirical distribution.", "publication_ref": ["b8", "b29", "b19", "b0", "b22", "b17"], "figure_ref": [], "table_ref": []}, {"heading": "Perspectives and Conclusions", "text": "We establish the complexity of computing the SHAP explanation in three important settings. First, we consider fullyfactorized data distributions and show that for any prediction model, the complexity of computing the SHAP explanation is the same as the complexity of computing the expected value of the model. It follows that there are commonly used models, such as logistic regression, for which computing SHAP explanations is intractable. Going beyond fullyfactorized distributions, we show that computing SHAP explanations is also intractable for simple functions and simple distributions -naive Bayes and empirical distributions.\nThe recent literature on SHAP explanations predominantly studies tradeoffs of variants of the original SHAP formulation, and relies on approximation algorithms to compute the explanations. These approximation algorithms, however, tend to make simplifying assumptions which can lead to counter-intuitive explanations, see e.g., Slack et al. (2020). We believe that more focus should be given to the computational complexity of SHAP explanations. In particular, which classes of machine learning models can be explained efficiently using the SHAP scores? Our results show that, under the assumption of fully-factorized data distributions, there are classes of models for which the SHAP explanations can be computed in polynomial time. In future work, we plan to explore if there are classes of models for which the complexity of the SHAP explanations is tractable under more complex data distributions, such as the ones defined by tractable probabilistic circuits (Vergari et al. 2020) or tractable symmetric probability spaces (Van den Broeck, Meert, and Darwiche 2014; Beame et al. 2015).\nAlgorithm 1 Algorithm to compute value function v from (Lundberg, Erion, and Lee 2018) procedure EXPVALUE(x, S, tree = {v, a, b, t, r, d})\nprocedure G(j)\nif v j = internal then return v j else if d j \u2286 S then return G(a j ) if x dj \u2264 t j else G(b j ) else return (G(a j ) \u2022 r aj + G(b j ) \u2022 r bj )/r j return G(1)\nA Discussion on the TreeSHAP algorithm Lundberg, Erion, and Lee (2018) propose TreeSHAP, a variant of SHAP explanations for tree-based machine learning models such as decision trees, random forests and gradient boosted trees. The authors claim that, for the case when both the model and probability distribution are defined by a tree-based model, the algorithm can compute the exact SHAP explanations in polynomial time. However, it has been pointed out in Github discussions (e.g., https://github.com/christophM/interpretable-ml-book/issues/142) that the TreeSHAP algorithm does not compute the SHAP explanation as defined in Section 2. In this section, we provide a concrete example of this shortcoming.\nThe main shortcoming of the TreeSHAP algorithm is captured by Algorithm 1. The authors claim that Algorithm 1 computes the conditional expectation E[F | x S ], for a given set of features S and tree-based model F . We first describe the algorithm and then show by example that this algorithm does not accurately compute the conditional expectation.\nAlgorithm 1 takes as input a feature vector x, a set of features S, and a binary tree, which represents the tree-based model. The tree is defined by the following vectors: v is a vector of node values; internal nodes are assigned the value internal. The vectors a and b represent the left and right node indexes for each internal node. The vector t contains the thresholds for each internal node, and d is a vector of indexes of the features used for splitting in internal nodes. The vector r represents the cover of each node (i.e., how many data samples fall in that sub-tree).\nThe algorithm proceeds recursively in a top-down traversal of the tree. For inner nodes, the algorithm follows the decision path for x if the split feature is in S, and takes the weighted average of both branches if the split feature is not in S. For leaf nodes, it returns the value of the node, which corresponds to the prediction of the model.\nThe algorithm does not accurately compute the conditional expectation E[F | x S ], because it does not normalize expectation by the probability of the condition. The following simple example shows that the value returned by Algorithm 1 does not represent the conditional expectation.\nExample 14. We consider the following dataset and decision tree model. The dataset has two binary variables X 1 and X 2 , and each instance (x 1 , x 2 ) is weighted by the occurrence count (i.e., the instance (0,0) occurs twice in the dataset). We want to compute E[F (X 1 , X 2 )|X 2 = 0], where F (X 1 , X 2 ) is the outcome of the decision tree.\nX 1 X 2 # 0 0 2 0 1 1 1 0 1 1 1 2 X 1 X 2 X 2 0 1 F (0, 0) F (0, 1) F (1, 0) F (1, 1) 0 1 0 1\nThe correct value is:\nE[F (X 1 , X 2 ) | X 2 = 0] = 2/3 \u2022 F (0, 0) + 1/3 \u2022 F (1, 0)\nThis is because there are three items with X 2 = 0, and their probabilities are 2/3 and 1/3. Algorithm 1, however, returns:\nG(1) = 1/2 \u2022 F (0, 0) + 1/2 \u2022 F (1, 0), and thus does not compute E[F (X 1 , X 2 ) | X 2 = 0].", "publication_ref": ["b26", "b29", "b2", "b18"], "figure_ref": [], "table_ref": []}, {"heading": "B Proof of Proposition 3", "text": "We start with item (1). Recall that dom(X i ) = {1, 2, 3, . . . , m i }. We denote by p i1 , p i2 , . . . , p imi their probabilities, thus j=1,mi p ij = 1. By definition, the projected distribution is: Pr \u03c0 (X i = 1) def = p i1 , and Pr \u03c0 (X i = 0) = 1 \u2212 p i1 . We denote by E \u03c0 be the corresponding expectation. Our goal is to prove SHAP F,Pr (X j ) = SHAP F\u03c0,Pr\u03c0 (X j ).\nLet e S again denote the event i\u2208S (X i = 1). Note that, by construction, for any set S, Pr(e S ) = Pr \u03c0 (e S ). Recall that for any instance x \u2208 {0, 1} n , we let T (x) denote the event asserting that X j = 1 iff x j = 1; formally,\nT (x) def = j:xj =1 (X j = 1) \u2227 j:xj =0 (X j = 1).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Then, for any instance", "text": "x \u2208 {0, 1} n , Pr(T (x)) = i:xi=1 p i1 \u2022 i:xi=0 (p i2 + p i3 + \u2022 \u2022 \u2022 ) = Pr \u03c0 (x).\nThus, there are 2 n disjoint events T (x), which partition the space X . Therefore, for every set S:\nE[F \u2227 e S ] = x:\u2200i\u2208S,xi=1 E[F |T (x)] Pr(T (x)) = x:\u2200i\u2208S,xi=1 F \u03c0 (x) Pr \u03c0 (x) = E \u03c0 [F \u03c0 \u2227 e S ]\nThis implies that E[F |e S ] = E \u03c0 [F \u03c0 |e S ] for any set S, and SHAP F,Pr (X j ) = SHAP F\u03c0,Pr\u03c0 (X j ) for all j follows from Equation 6.\nWe now prove item (2): we show how to compute E[F \u03c0 ] given an oracle for computing E[F ]. Recall that we want to compute E[F \u03c0 ] on some arbitrary distribution Pr \u2032 \u03c0 on {0, 1} n ; this should not be confused with the probability Pr \u03c0 defined in Eq.11, and used to define the function F \u03c0 . Denote\nq i def = Pr \u2032 \u03c0 (X i = 1), thus Pr \u03c0 (X i = 0) = 1 \u2212 q i .\nTo compute E[F \u03c0 ] we will use the oracle for computing E[F ], on the probability space defined by the numbers p \u2032 ij , i = 1, n, j = 1, m i defined as follows:\nw i def = 1 \u2212 q i q i and Z def = i=1,n q i W def = i=1,n \uf8eb \uf8ed 1 + j=2,mi p ij w i 1 \u2212 p i1 \uf8f6 \uf8f8 p \u2032 i1 def = 1 W i =1, n p \u2032 ij def = p ij w i W (1 \u2212 p i1 ) i =1, n; j = 2, m i\nOne can check that the numbers p \u2032 ij indeed define a probability space on X , in other words p \u2032 ij \u2208 [0, 1] and, for all i = 1, n: j=1,mj p \u2032 ij = 1. We denote by Pr \u2032 the probability space that they define, and denote by E \u2032 [F ] the expectation of F in this space. We prove:\nClaim 3. E \u03c0 [F \u03c0 ] = Z \u2022 W \u2022 E \u2032 [F ]\nThe claim immediately proves item (2) of Proposition 3: we simply invoke the oracle to compute E \u2032 [F ], then multiply with the quantities Z and W , both of which are computable in polynomial time. It remains to prove the claim.\nWe start with some observations and notations. Recall that the projection F \u03c0 depends on both F and on Pr, see Equation 11. We express it here in terms of the probabilities p ij :\nF \u03c0 [x] = E[F |T (x)] = E[F \u2022 T (x)] Pr(T (x)) = \u03c4 \u2208X :x \u22121 (1)=\u03c4 \u22121 (1) F (\u03c4 ) \u2022 i p i\u03c4i i:xi=1 p i1 \u2022 i:xi =1 (1 \u2212 p i1 ) = \u03c4 \u2208X :x \u22121 (1)=\u03c4 \u22121 (1) F (\u03c4 ) \u2022 i:\u03c4i =1 p i\u03c4i 1 \u2212 p i1 .\nWe used the fact that, for every instance x \u2208 X , Pr(x) = i p ixi , and denoted by x \u22121 (1) the set of feature indices for which example x has value 1. We now prove the claim by applying directly the definition of E \u03c0 [F \u03c0 ]:\nE \u03c0 [F \u03c0 ] = \u03b8\u2208{0,1} n F \u03c0 (\u03b8) i:\u03b8i=1 q i i:\u03b8i=0 (1 \u2212 q i ) =Z \u2022 \u03b8\u2208{0,1} n F \u03c0 (\u03b8) i:\u03b8i=0 w i =Z \u2022 \u03b8 \u2208 {0, 1} n \u03c4 \u2208 X \u03b8 \u22121 (1) = \u03c4 \u22121 (1) F (\u03c4 ) i:\u03c4i =1 p i\u03c4i 1 \u2212 p i1 i:\u03b8i=0 w i =Z \u2022 \u03c4 \u2208X F (\u03c4 ) i:\u03c4i =1 p i\u03c4i w i 1 \u2212 p i1 =Z \u2022 W \u2022 \u03c4 \u2208X F (\u03c4 ) i p \u2032 i\u03c4i =Z \u2022 W \u2022 E \u2032 [F ]\nIn line 4 we noticed that the conditions \u03c4 i = 1 and \u03b8 i = 0 are equivalent, because \u03b8 \u22121 (1) = \u03c4 \u22121 (1), and that the assignment \u03c4 \u2208 X uniquely defines \u03b8, hence \u03b8 can be dropped from the summation. This completes the proof of the claim, and of Proposition 3.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C Proof of Theorem 5", "text": "The number partitioning problem, NUMPAR, is the following: given n natural numbers k 1 , . . . , k n , decide whether there exists a subset S \u2286 [n] that partitions the numbers into two sets with equal sums:\ni\u2208S k i = i \u2208S k i .\nNUMPAR is known to be NP-complete. The corresponding counting problem, in notation #NUMPAR, asks for the number of sets S such that i\u2208S k i = i \u2208S k i , and is #P-hard.\nWe show that we can solve the #NUMPAR problem using an oracle for E U [F ], where F is a logistic regression function and U is the uniform probability distribution. This implies that computing the expectation of a logistic regression function is #P-hard.\nFix an instance of NUMPAR, k 1 , . . . , k n , and assume w.l.o.g. that the sum of the numbers k i is even, i k i = 2c for some natural number c. Let\nP def = {S | S \u2286 [n], i\u2208S k i = c} (12)\nFor each set S \u2286 [n], denote byS its complement. Obviously, S \u2208 P iffS \u2208 P , therefore |P | is an even number.\nWe next describe an algorithm that computes |P | using an oracle for E U [F ], where F is a logistic regression function and U is the uniform probability distribution. Let m be a natural number large enough, to be chosen later, and define the following weights:\nw 0 def = \u2212 m 2 \u2212 mc w i def = mk i \u2200i = 1, n Let w = (w 1 , . . . , w n ), then F (x 1 , . . . , x n ) def = \u03c3(w 0 + w \u2022 x)\nis the logistic regression function defined by the weights w 0 , . . . , w n .\nClaim 4. Let \u03b5 def = 1/2 n+3 . If m satisfies both 2\u03c3(\u2212m/2) \u2264 \u03b5 and 1 \u2212 \u03c3(m/2) \u2264 \u03b5, then: |P | = 2 n \u2212 2 n+1 E[F ] 1 \u2212 \u03b5\nThe claim immediately proves the theorem: in order to solve the #NUMPAR problem, compute E[F ] and then use the formula above to derive |P |. To prove the claim, for each set S \u2286 [n] denote by:\nweight(S) def = \u2212 m 2 \u2212 mc + m( i\u2208S k i )\nLet U denote the uniform probability distribution over the domain {0, 1} n . Then, Since \u03b5 = 1/2 n+3 , and m satisfies both 2\u03c3(\u2212m/2) \u2264 \u03b5 and 1 \u2212 \u03c3(m/2) \u2264 \u03b5, we have:\nE U [F ] = 1 2 n x \u03c3(w 0 + w \u2022 x) = 1 2 n x \u03c3(\u2212 m 2 \u2212 mc + m( i\u2208[n] k i x i )) = 1 2 n x \u03c3(\u2212 m 2 \u2212 mc + m( i:xi=1 k i )) = 1 2 n S\u2286[n] \u03c3(weight(S)) = 1 2 n+1 S\u2286[n]\nS \u2208 P : 0 \u2264 \u03c3(weight(S)) + \u03c3(weight(S)) \u2264 \u03b5 S \u2208 P : 1 \u2212 \u03b5 \u2264 \u03c3(weight(S)) + \u03c3(weight(S)) \u2264 1 + \u03b5 This implies: 2 n \u2212 |P | 2 n+1 (1 \u2212 \u03b5) \u2264 E[F ] \u2264 |P | 2 n+1 \u03b5 + 2 n \u2212 |P | 2 n+1 (1 + \u03b5) |P | \u22652 n \u2212 2 n+1 E[F ] 1 \u2212 \u03b5 |P | \u22642 n (1 + \u03b5) \u2212 2 n+1 E[F ]\nThus, we have a lower and an upper bound for |P |. Since E[F ] \u2264 1, the difference between the two bounds is < 1 and there exists at most one integer number between them, hence |P | is equal to the ceiling of the lower bound (and also to the floor of the upper bound), proving the claim.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "D Proof of Theorem 8", "text": "We use a reduction from the decision version of number partitioning problem, NUMPAR, which is NP-complete, see Sec. C.\nAs before we assume w.l.o.g. that the sum of the numbers k i is even, i k i = 2c for some natural number c. Let m be a large natural number to be defined later. We reduce the NUMPAR problem to the D-SHAP({X 0 }, NBN) problem. The Naive Bayes network NBN consists of n + 1 binary random variables X 0 , . . . , X n . Let X i ,X i denote the events X i = 1 and respectively X i = 0. We define the following probabilities of the NBN:\nPr(X 0 ) Pr(X 0 ) =e \u2212 m 2 \u2212mc Pr(X i |X 0 ) Pr(X i |X 0 ) =e mki\nThe probabilities Pr(X 0 ) and Pr(X i |X 0 ) can be chosen arbitrarily (with the obvious constraints Pr(X 0 ) \u2264 e m 2 +mc and Pr(X i |X 0 ) \u2264 e \u2212mki ). As required, our classifier is\nF (X 0 , . . . , X n ) def = X 0 . Let a k def = k!(n\u2212k)! (n+1)!\nand let \u03b5 > 0 be any number such that \u03b5 \u2264 a k for all k = 0, 1, . . . , n. We prove:\nClaim 5. Let \u03b5 be the value defined above. If m satisfies both 2\u03c3(\u2212m/2) \u2264 \u03b5 and 1 \u2212 \u03c3(m/2) \u2264 \u03b5, then NUMPAR has a solution iff SHAP F (X 0 ) \u2265 1/2(1 + \u03b5).\nThe claim implies Theorem 8. To prove the claim, we express the SHAP explanation using Eq. (6). Let X S denote the event i\u2208S (X i = 1). Then, we can write the SHAP explanation as:\nSHAP F (X 0 ) = S\u2286[n] a |S| E[F | X S\u222a{0} ] \u2212 E[F | X S ]\nObviously, E[X 0 | X S\u222a{0} ] = 1. In addition, we have\nS\u2286[n] a |S| = 1, because there are n k sets of size k, hence S\u2286[n] a |S| = k=0,n n k \u2022 k!(n\u2212k)! (n+1)! = 1.\nTherefore SHAP F (X 0 ) = 1 \u2212 D, where:\nD def = S\u2286[n] a |S| \u2022 E[X 0 | X S ](13)\nTo compute D, we expand:\nE[X 0 |X S ] = Pr(X 0 |X S ) = Pr(X 0 , X S ) Pr(X S ) = i\u2208S Pr(X i |X 0 )Pr(X 0 ) i\u2208S Pr(X i |X 0 )Pr(X 0 ) + i\u2208S Pr(X i |X 0 )Pr(X 0 ) = 1 1 + Pr(X 0 )/Pr(X 0 ) \u2022 i\u2208S (Pr(X i |X 0 )/Pr(X i |X 0 )) = \u03c3(weight(S)) where: \u03c3(x) def = 1 1 + e \u2212x weight(S) def = \u2212 m 2 \u2212 mc + m( i\u2208S k i )\nWe compute D in Eq. (13) by grouping each set S with its complementS\ndef = [n] \u2212 S: D = 1 2 S\u2286[n]\na |S| \u03c3(weight(S)) + \u03c3(weight(S))\nIf S is a solution to the number partitioning problem, then: \u03c3(weight(S)) + \u03c3(weight(S)) = 2\u03c3(\u2212m/2)\nOtherwise, one of weight(S), weight(S) is \u2265 m/2 and the other is \u2264 \u22123m/2 and therefore: \u03c3(m/2) \u2264 \u03c3(weight(S)) + \u03c3(weight(S)) \u2264 1 + \u03c3(\u22123m/2) As in Sec. C, we obtain:\nS \u2208 P : 0 \u2264 \u03c3(weight(S)) + \u03c3(weight(S)) \u2264 \u03b5 S \u2208 P : 1 \u2212 \u03b5 \u2264 \u03c3(weight(S)) + \u03c3(weight(S)) \u2264 1 + \u03b5\nTherefore, using the fact that S\u2286[n] a |S| = 1, we derive these bounds for the expression (14) for D:\n\u2022 If the number partitioning problem has no solution, then D \u2265 1/2(1 \u2212 \u03b5), and SHAP F (X 0 ) \u2264 1/2(1 + \u03b5). \u2022 Otherwise, let S be any solution to the NUMPAR problem, and k = |S|, then:\nD \u2264 1 2 (1 + \u03b5) \u2212 a k (1 + \u03b5) + a k \u03b5 \u2264 1 2 \u2212 a k \u2212 \u03b5 2 < 1 2 \u2212 \u03b5 2 and therefore SHAP F (X 0 ) > 1/2(1 + \u03b5).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "E Proof of Corollary 10", "text": "Proof. (Sketch) We use a reduction from the NUMPAR problem, as in the proof of Theorem 8. We start by constructing the NBN with variables X 0 , X 1 , . . . , X n (as for Theorem 8), then add two more variables X n+1 , X n+2 , and edges X 0 \u2192 X n+1 \u2192 X n+2 , and define the random variables X n+1 , X n+2 to be identical to X 0 , i.e. X 0 = X n+1 = X n+2 . The prediction function is F = X n+2 , i.e. it returns the feature X n+2 , and the variables X 0 , X n+1 are latent. Thus, the new BN is identical to the NBN, and, since both models have exactly the same number of non-latent variables, the SHAP-explanation is the same.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "F Proof of Lemma 13 (1)", "text": "Fix a PP2CNF \u03a6 = (U i \u2228 V j ). A symmetric probability space is defined by two numbers p, q \u2208 [0, 1] and consists of the fully-factorized distribution where Pr(U 1 ) = Pr(U 2 ) = \u2022 \u2022 \u2022 = p and Pr(V 1 ) = Pr(V 2 ) = \u2022 \u2022 \u2022 = q. A quasi-symmetric probability space consists of two sets of indices I, J and two numbers p, q such that:\nPr(U i ) = p when i \u2208 I 1 when i \u2208 I Pr(V j ) = q when j \u2208 J 1 when j \u2208 J\nIn this and the following section we prove Lemma 13: computing the SHAP-explanation over an empirical distribution is polynomial time equivalent to computing the expectation of PP2CNF formulas over a (quasi)-symmetric distribution. Provan and Ball (1983) proved that computing the expectation of a PP2CNF over uniform distributions is #P-hard in general. Since uniform distribution are symmetric (namely p = q = 1/2) it follows that computing SHAP-explanations is #P-hard in general.\nIn this section we prove item (1) of Lemma 13. Fix a 0/1-matrix x defining an empirical distribution, and let F be a real-valued prediction function over these features. Let \u03a6 x be the PP2CNF associated to x (see Definition 4). Will assume w.l.o.g. that x has n + 1 features (columns), denoted X 0 , X 1 , . . . , X n . The prediction function F is any function F : {0, 1} n+1 \u2192 R. We prove: Proposition 15. One can compute SHAP F (X 0 ) in polynomial time using an oracle for computing E[\u03a6 x ] over quasisymmetric distributions.", "publication_ref": ["b22"], "figure_ref": [], "table_ref": []}, {"heading": "Denote by y", "text": "i def = F (x i0 , x i1 , . . . , x in ), i = 1\n, m the value of F on the i'th row of the matrix x. Since the only possible outcomes of the probability space are the m rows of the matrix, the quantity SHAP F (X 0 ) depends only on the vector y def = (y 1 , . . . , y m ). Furthermore, by the linearity of the SHAP explanation (Eq. (4)), it suffices to compute the SHAP explanation in the case when y has a single value = 1 and all others are = 0. By permuting the rows of the matrix, we will assume w.l.o.g. that y 1 = 1, and y 2 = y 3 = \u2022 \u2022 \u2022 = y m = 0. In summary, denoting F 1 the function that is 1 on the first row of the matrix x and is 0 on all other rows, our task is to compute SHAP F1 (X 0 ).\nFor that we use the following expression for SHAP (see also Sec. 3):\nSHAP F1 (X 0 ) = k=0,n k!(n \u2212 k)! (n + 1)! S\u2286[n]:|S|=k E[F 1 |X S\u222a{0} = 1] \u2212 E[F 1 |X S = 1](15)\nWe will only show how to compute the quantity\nv F1,k = S\u2286[n]:|S|=k E[F 1 |X S = 1](16)\nusing an oracle to E[\u03a6 x ], because the quantity\nS:|S|=k E[F 1 |X S\u222a{0} = 1\n] is computed similarly, by restricting the matrix x to the rows i where x i0 = 1. The PP2CNF \u03a6 associated to this restricted matrix is obtained from \u03a6 x as follows. Let I def = {i | x i0 = 1} be the set of rows of the matrix where the feature X 0 is 1. Then, we need to remove all clauses of the form (U i \u2228 V j ) for i \u2208 I. This is equivalent to setting U i := 1 in \u03a6 x . Therefore, we can compute the expectation of the restricted \u03a6 by using our oracle for E[\u03a6 x ], and running it over the probability space where we define Pr(U i ) def = 1 for all i \u2208 I. Hence, it suffices to show only how to compute the expression (16). Notice that the quantity v F1,k is the same as what we defined earlier in Eq. (7).\nColumn X 0 of the matrix is not used in expression ( 16), because the set S ranges over subsets of [n]. Hence w.l.o.g. we can drop feature X 0 and denote by x (with some abuse) the matrix that only has the features X 1 , . . . , X n . In other words, x \u2208 {0, 1} m\u00d7n . The PP2CNF formula for the modified matrix is obtained from \u03a6 x by setting V 0 := 1, hence we can compute its expectation by using our oracle for\nE[\u03a6 x ].\nWe introduce the following quantities associated to the matrix x \u2208 {0, 1} m\u00d7n : \u2022 For all S \u2286 [n], \u2113 \u2264 m, k \u2264 n, we define:\ng(S) def = {i | \u2200j \u2208 S, x ij = 1}(17)\na \u2113k def = |{S | |S| = k, |g(S)| = \u2113}|(18)\n\u2022 We define the sequence v k , k = 0, 1, . . . , n:\nv k def = l=1,m a \u2113k \u2113(19)\n\u2022 We define the value V :\nV def = k=0,n k!(n \u2212 k)! (n + 1)! v k(20)\nWe prove that, under a certain condition, the value v k in Eq. ( 19) is equal to Eq. (16); this justifies the notation v k , since it turns out to be the same as v F1,k from Eq. (7).\nDefinition 5. Call the matrix x \"good\" if \u2200i, j, x 1j \u2265 x ij .\nIn other words, the matrix is \"good\" if the first row dominates all others. In general the matrix x need not be \"good\", however we can make it \"good\" by removing all columns where row 1 has a value 0. More precisely, let J (1) def = {j | x 1j = 1} denote the non-zero positions of the first row, and let x (1) denote the sub-matrix of x consisting of the columns J (1) . Obviously, x (1) is \"good\", because its first row is (1, 1, . . . , 1). The following hold:\nIf S \u2286 J (1) : E x [F 1 |X S = 1] =E x (1) [F 1 |X S = 1] If S \u2286 J (1) : E x [F 1 |X S = 1] =0\n(When S \u2286 J (1) then the quantity E x (1) [F 1 |X S = 1] is undefined). Therefore:\nS\u2286[n]:|S|=k E x [F 1 |X S = 1] = S\u2286J (1) :|S|=k E x (1) [F 1 |X S = 1]\nIt follows that, in order to compute the values in Eq. ( 16), we can consider the matrix x (1) instead of x; its associated PP2CNF is obtained from \u03a6 x by setting V j := 1 for all j \u2208 [m] \u2212 J (1) , hence we can compute its expectation over a quasi-symmetric space by using our oracle for computing E[\u03a6 x ] over quasi-symmetric spaces. To simplify the notation, we will still use the name x for the matrix instead of x (1) , and assume w.l.o.g. that the first row of the matrix x is (1, 1, . . . , 1).\nWe prove that, when x is \"good\", then v k is indeed the quantity Eq. ( 16) that we want to compute. This holds for any \"good\" matrix, not just matrices with (1, 1, . . . , 1) in the first row, and we need this more general result later in Sec. G. Claim 6. If the matrix x is \"good\", then, for any k = 0, n:\nv k = S:|S|=k E[F 1 |X S = 1]\nProof. Recall that J (1) def = {j | x 1j = 1}. Let S \u2286 [n] be any set of columns. We consider two cases, depending on whether S is a subset of J (1) or not:\nS \u2286J (1) : |g(S)| >0 E[F 1 |X S = 1] = 1 |g(S)| S \u2286J (1) : |g(S)| =0 E[F 1 |X S = 1] =0\nTherefore: At this point we introduce two polynomials, P and Q. Definition 6. Fix an m \u00d7 n matrix x with 0, 1-entries. The polynomials P (u, v) and Q(u, v) in real variables u, v associated to the matrix x are the following:\nS\u2286[n]:|S|=k E[F 1 |X S = 1] = S\u2286J (1) :|S|=k E[F 1 |X S = 1] = S\u2286J(\nP (u, v) def = S\u2286[n] u |g(S)| v |S| Q(u, v) def = T \u2286 [m], S \u2286 [n] : \u2200(i, j) \u2208 T \u00d7 S : xij = 1 u |T | v |S|\nThe polynomials are defined by summing over exponentially many sets S \u2286 [n], or pairs of sets S \u2286\n[n], T \u2286 [m].\nIn the definition of P , we use the function g(S) associated to the matrix x, see Eq. (17). In the definition of Q(u, v) we sum only those pairs T, S where \u2200i \u2208 T , \u2200j \u2208 S, x ij = 1. While their definition involves exponentially many terms, these polynomials have only (m + 1)(n + 1) terms, because the degrees of the variables u, v are m and n respectively. We claim that these terms are as follows: Claim 7. The following identities hold:\nP (u, v) = \u2113=0,m;k=0,n a \u2113k u \u2113 v k Q(u, v) =P (1 + u, v)\nProof. The identity for P (u, v) follows immediately from the definition of a \u2113k . We prove the identity for Q. From the definition of g(S) in Eq. ( 17) we derive the following equivalence:\n(\u2200i \u2208 T, \u2200j \u2208 S : x ij = 1) \u21d4 T \u2286 g(S)\nWhich implies:\nQ(u, v) = S\u2286[n],T \u2286g(S) u |T | v |S|\nand the claim follows from T \u2286g(S) u\n|T | = (1 + u) |g(S)| .\nThus, in order to compute the quantities v k for k = 0, 1, . . . , n it suffices to compute the coefficients a \u2113k of the polynomial P (u, v), and, for that, it suffices to compute the coefficients of the polynomial Q(u, v). For that, we establish the following important connection between E[\u03a6 x ] and the polynomial Q(u, v). Fix u, v > 0 any two positive real values, and let p def = 1/(1 + u), q def = 1/(1 + v); notice that p, q \u2208 (0, 1). Consider the probability space over independent Boolean variables U 1 , . . . , U m , V 1 , . . . , V n where \u2200i \u2208 [m], Pr(U i ) = p, and \u2200j \u2208 [n], Pr(V j ) = q. Then: Claim 8. Given the notations above, the following identity holds:\nE[\u03a6 x ] = 1 (1 + u) m (1 + v) n Q(u, v)(21)\nProof. A truth assignment for \u03a6 x consists of two assignments, \u03b8 \u2208 {0, 1} m for the variables U i , and \u03c4 \u2208 {0, 1} n for the variables V j . Defining T def = {i | \u03b8(U i ) = 0} and S def = {j | \u03c4 (V j ) = 0}, we observe that \u03a6 x [\u03b8, \u03c4 ] = true iff \u2200i \u2208 T, \u2200j \u2208 S, x ij = 1, and therefore:\nPr(\u03a6 x ) = \u03b8,\u03c4 :\u03a6[\u03b8,\u03c4 ]=1 Pr(\u03b8)Pr(\u03c4 ) = T \u2286 [m], S \u2286 [n] \u2200(i, j) \u2208 T \u00d7 S : xij = 1 p m\u2212|T | (1 \u2212 p) |T | q n\u2212|S| (1 \u2212 q) |S| = p m q n Q((1 \u2212 p)/p, (1 \u2212 q)/q)\nFinally, to prove Lemma 13 (1), it suffices to show how to use an oracle for E[\u03a6 x ] to compute the coefficients of the polynomial Q(u, v). We denote by b \u2113k these coefficients, in other words:\nQ(u, v) = \u2113=0,m;k=0,n b \u2113k u \u2113 v k (22)\nTo compute the coefficients b \u2113k , we proceed as follows.\nChoose m + 1 distinct values u 0 , u 1 , . . . , u m > 0, and choose n + 1 distinct values v 0 , v 1 , . . . , v n > 0, and for all i = 0, m and j = 0, n, use the oracle for E[\u03a6 x ] to compute Q(u i , v j ) as per identity ( 21). This leads to a system of (m + 1)(n + 1) equations whose unknowns are the coefficients b \u2113k (see Eq. ( 22)) and whose coefficients are u \u2113 i v k j . The matrix A of this system of equations is an [(m + 1)(n + 1)] \u00d7 [(m + 1)(n + 1)] matrix, whose rows are indexed by pairs (i, j), and whose columns are indexed by pairs (\u2113, k):\nA (ij),(\u2113k) =u \u2113 i v k j\nWe prove that this matrix is non-singular, and for that we observe that it is the Kronecker product of two Vandermonde matrices. Recall that the t \u00d7 t Vandermonde matrix defined by t numbers z 1 , . . . , z t is:\nV (z 1 , . . . , z t ) = \uf8ee \uf8ef \uf8ef \uf8ef \uf8f0 1 1 . . . 1 z 1 z 2 . . . z t z 2 1 z 2 2 . . . z 2 t . . . z t\u22121 1 z t\u22121 2 . . . z t\u22121 t \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fb\nIt is known that det(V (z 1 , . . . , z t )) = 1\u2264i<j\u2264t (z j \u2212 z i ) and this is = 0 iff the values z 1 , . . . , z t are distinct. We observe that the matrix A is the Kronecker product of two Vandermonde matrices:\nA =V (u 0 , u 1 , . . . , u m ) \u2297 V (v 0 , v 1 , . . . , v n )\nSince we have chosen u 0 , . . . , u m to be distinct, and similarly for v 0 , . . . , v n , it follows that both Vandermonde matrices are non-singular, hence det(A) = 0. Thus, we can solve this linear system of equations in time O ((m + 1)(n + 1))\n3 , and compute all coefficients b \u2113k .\nPutting It Together We prove now Proposition 15. We are given a 0/1 matrix x with n + 1 features X 0 , . . . , X n and m rows. To compute SHAP F (X 0 ) we proceed as follows:\n1. For each i = 1, m, compute SHAP Fi (X 0 ), where F i is the function defined as = 1 on row i of the matrix, and = 0 on all other rows of the matrix. Return SHAP F (X 0 ) = i=1,m y i SHAP Fi (X 0 ), where y i def = F (x i0 , x i1 , . . . , x in ) is the value of F on the i'th row of the matrix.\n2. To compute SHAP Fi (X 0 ), switch rows 1 and i of the matrix, and compute SHAP F1 (X 0 ) on the modified matrix.\n3. To compute SHAP F1 (X 0 ), compute both sums in Eq. (15).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "To compute S\u2286[n]", "text": ":|S|=k E[F 1 |X S = 1], perform steps (5) to (8) below.\n5. Let J (1) = {j | j \u2208 [n], x 1j = 1}; notice that 0 \u2208 J (1) . Let n (1) = |J (1) |. Let \u03a6 \u2032 denote the PP2CNF obtained from \u03a6 x by setting V j := 1 for all j \u2208 J (1) . Thus, \u03a6 \u2032 has m + n (1) variables: U i for i \u2208 [m], and V j for j \u2208 J (1) .\n6. Choose distinct values u 0 , u 1 , . . . , u m \u2208 (0, 1) and distinct values v 0 , v 1 , . . . , v n (1) \u2208 (0, 1). For each fixed combination Claim 8). The value E[\u03a6 \u2032 ] over the probability space where, for all i, j: Pr(U i ) = u \u03b1 , Pr(V j ) = v \u03b2 : this can be done by computing E[\u03a6 x ] over a quasi-symmetric space. Step (4).\nu \u03b1 , v \u03b2 , compute Q(u \u03b1 , v \u03b2 ) = (1 + u \u03b1 ) m (1 + v \u03b2 ) n (1) E[\u03a6 \u2032 ] (see", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "To compute S\u2286[n]", "text": ":|S|=k E[F 1 |X S\u222a{0} = 1], first set U i := 0 for all rows i where x i0 = 0, then repeat steps ( 5) to (8).\n10. This completes Step (3), and we obtain SHAP F1 (X 0 ).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "G Proof of Lemma 13 (2)", "text": "Here we prove item (2) of Lemma 13: one can compute E[\u03a6] over a quasi-symmetric probability space in polynomial time, given an oracle for SHAP on empirical distributions. If the probability space sets Pr(U i ) = 1 for some variable, then we can simply replace \u03a6 with \u03a6[U i := 1], and similarly if Pr(V j ) = 1. Hence, w.l.o.g., we can assume that the probability space is symmetric. More precisely, we fix a PP2CNF formula \u03a6 = (U i \u2228 V j ), and let p = Pr(U 1 ) = \u2022 \u2022 \u2022 = Pr(U m ) and q = Pr(V 1 ) = \u2022 \u2022 \u2022 = Pr(V n ) define a symmetric probability space. Our task is to compute E[\u03a6] over this space, given an oracle for computing SHAP-explanations on empirical distributions. Throughout this section we will use the notations introduced in Sec. F.\nLet x the matrix associated to \u03a6: x ij = 0 iff \u03a6 contains a clause U i \u2228 V j . We describe our algorithm for computing E(\u03a6) in three steps.\nStep 1: E[\u03a6] \u2264 P (v 0 , v 1 , . . . , v k ). More precisely:, we claim that we can compute Pr(\u03a6) using an oracle for computing the quantities v 0 , v 1 , . . . , v n defined in Eq. (19). We have seen in Eq. ( 21) that E\n[\u03a6] = 1 (1+u) m (1+v) n Q(u, v)\nwhere u = (1 \u2212 p)/p and v = (1 \u2212 q)/q. From Claim 7 we know that Q(u, v) = P (1 + u, v), and the coefficients of P (u, v) are the quantities a \u2113k defined in Eq. (18). To complete Step 1, we will describe a polynomial time algorithm that computes the quantities a \u2113k associated to our ma-trix x, with access to an oracle for computing the quantities v 0 , . . . , v k associated to any matrix x \u2032 .\nStarting from the matrix x, construct m + 1 new matrices, denoted by x (1) , x (2) , . . . , x (m+1) , where, for each \u0393 = 1, m + 1, x (\u0393) consists of the matrix x extended with \u0393 rows consisting of (1, 1, . . . , 1). That is, the matrix x (\u0393) has \u0393 + m rows, the first \u0393 rows are (1, . . . , 1), and the remaining m rows are those in x. We run our oracle to compute the quantities v k on each matrix x (\u0393) . We continue to use the notations g(S), a \u2113k , v k introduced in Equations ( 17), ( 18), ( 19) for the matrix x, and add the superscript (\u0393) for the same quantities associated to the matrix x (\u0393) . We observe:\ng (\u0393) =g(S) \u222a {the \u0393 new rows} a (\u0393)\n\u2113+\u0393,k =a \u2113k and therefore:\nv (1) k = 1 1 a 0k + 1 2 a 1k + \u2022 \u2022 \u2022 + 1 m + 1 a mk v (2) k = 1 2 a 0k + 1 3 a 1k + \u2022 \u2022 \u2022 + 1 m + 2 a mk \u2022 \u2022 \u2022 v (m+1) k = 1 m + 2 a 0k + 1 m + 3 a 1k + \u2022 \u2022 \u2022 + 1 2m + 2 a mk\nBy solving this system of equations, we compute the quantities a \u2113k for \u2113 = 0, m. The matrix of this system is a special case of Cauchy's double alternant determinant:\ndet 1 x i + y j = 1\u2264i<j\u2264n (x i \u2212 x j )(y i \u2212 y j )\ni,j (x i + y j ) where x i = i and y j = j \u2212 1, and therefore the matrix of the system is non-singular.\nWe observe that all matrices x (1) , . . . , x (m+1) are \"good\" (see Definition 5), because their first row is (1, . . . , 1).\nStep 2: Let x be a \"good\" matrix (Definition 5). Then: (v 0 , v 1 , . . . , v n ) \u2264 P V (V defined in Eq. ( 20)). In other words, given a matrix x, we claim that we can compute the quantities v 0 , v 1 , . . . , v n associated to x by Eq. (19) in polynomial time, given access to an oracle for computing the quantity V associated to any matrix x \u2032 . The algorithm proceeds as follows. For each \u2206 = 0, 1, . . . , n, construct a new m \u00d7 (2n) matrix x (\u2206) by extending x with \u2206 new columns set to 1 and n \u2212 \u2206 new columns set to 0. Thus, x (\u2206) is: \u2206) is \"good\", for any \u2206. We run the oracle on each matrix x (\u2206) to compute the quantity V (\u2206) . We start by observing the following relationships between the parameters of the matrix x and those of the matrix x (\u2206) :\n\uf8eb \uf8ec \uf8ed x 11 x 12 . . . x 1n 1 1 . . . 1 0 . . . 0 x 21 x 22 . . . x 2n 1 1 . . . 1 0 . . . 0 . . . x m1 x m2 . . . x mn 1 1 . . . 1 0 . . . 0 \uf8f6 \uf8f7 \uf8f8 Notice that x (\ng (\u2206) (S) =g(\u2206 \u2229 [n]) a (\u2206) \u2113p = k=0,min(p,n) \u2206 p \u2212 k a \u2113k v (\u2206) p = k=0,min(p,n) \u2206 p \u2212 k v k\nNotice that, when p > n + \u2206, then v (\u2206) p = 0. We use the oracle to compute the quantity V (\u2206) , which is:\nV (\u2206) = p=0,2n p!(2n \u2212 p)! (2n + 1)! v (\u2206) p = 1 2n + 1 p=0,n+\u2206 1 2n p v \u2206 p = 1 2n + 1 p=0,n+\u2206 k=0,min(p,n) \u2206 p\u2212k 2n p v k = 1 2n + 1 k=0,n p=k,k+\u2206 \u2206 p\u2212k 2n p v k = 1 2n + 1 k=0,n \uf8eb \uf8ed q=0,\u2206 \u2206 q 2n k+q \uf8f6 \uf8f8 v k def = 1 2n + 1 k=0,n A \u2206,k \u2022 v k\nThus, after running the oracle on all matrices x (0) , . . . , x (n) , we obtain a system of n + 1 equations with n + 1 unknowns v 0 , v 1 , . . . , v n . It remains to prove that system's matrix, A \u2206,k , is non-singular matrix. Let us denote following matrices by: It is immediate to verify that A = B \u2022 C, so it suffices to prove det(B) = 0, det(C) = 0. We start with B, and for that consider the Vandermonde matrix\nA\nX def = V (x 0 , x 1 , . . . , x n ), X qt def = x q t . Denoting Y def = B \u2022 X, we have that Y \u2206t = q=0,n B \u2206,q X q,t = q=0,n \u2206 q x q t = (1 + x t ) \u2206\nis also a Vandermonde matrix Y = V (1+x 0 , 1+x 1 , . . . , 1+\nx n ). We have det(Y ) = 0 when x 0 , x 1 , . . . , x n are distinct, proving that det(B) = 0. Finally, we prove det(C) = 0. For that, we prove a slightly more general result. For any N \u2265 2n, denote by C (n,N ) the following (n + 1) \u00d7 (n + 1) matrix:\nC (n,N ) def = \uf8eb \uf8ec \uf8ec \uf8ec \uf8ec \uf8ed 1 ( N 0 ) 1 ( N 1 ) . . . 1 ( N n ) 1 (N 1 ) 1 ( N 2 )\n. . .\n1 ( N n+1 ) . . . 1 ( N n ) 1 ( N n+1 ) . . . 1 ( N 2n ) \uf8f6 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f8\nWe will prove that det(C (n,N ) ) = 0; our claim follows from the special case N = 2n. For the base case, n = 0, det(C (0,N ) ) = 1 because C (0,N ) is a 1 \u00d7 1 matrix equal to 1/ N 0 , hence det(C (0,N ) ) = 1. To show the induction step, we will perform elementary column operations (which preserve the determinant) to make the last row of the resulting matrix consist of zeros, except for the last entry.\nConsider an arbitrary row i, and two adjacent columns j, j + 1 in that row: . . .\n1 ( N i+j ) 1 ( N i+j+1 )\n. . .\nWe use the fact that N i+j = N i+j+1 i+j+1 N \u2212i\u2212j and rewrite the two adjacent elements as:\n. . . 1 ( N i+j+1 ) \u00d7 N \u2212i\u2212j i+j+1 1 ( N i+j+1 )\n. . . Now, for each j = 0, 1, 2, ..., n \u2212 1, we subtract column j + 1, multiplied by N \u2212(n+j) (n+j)+1 , from column j. The last row becomes 0, 0, . . . , 0, 1 ( N 2n )\n, which means that det(C (n,N ) ) is equal to 1 ( N 2n )\ntimes the upper left (n \u00d7 n) minor. Now, we check what happens with element at (i, j). After subtraction, it becomes\n1 N i+j+1 \u00d7 N \u2212 (i + j) (i + j) + 1 \u2212 N \u2212 (n + j) (n + j) + 1\nThis expression can be rewritten as:\n1 N (i+j)+1 \u00d7 N \u2212 (i + j) (i + j) + 1 \u2212 N \u2212 (n + j) (n + j) + 1 = (N \u2212 i \u2212 j \u2212 1)!(i + j + 1)! N ! (N + 1)(n \u2212 i) (i + j + 1)(n + j + 1) = (N \u2212 i \u2212 j \u2212 1)!(i + j)! (N \u2212 1)!N (N + 1)(n \u2212 i) (n + j + 1) = 1 N \u22121 (i+j) (N + 1)(n \u2212 i) N (n + j + 1)\nNote that this expression holds with the whole (n \u00d7 n) upper-left minor of C (n,N ) : the element in the lowerright corner of the matrix remains 1/ N 2n . Observe that the (i, j)-th entry of this minor is precisely the (i, j)-entry of C (n\u22121,N \u22121) , multiplied by (N +1)(n\u2212i) N (n+j+1) . Here N +1 N is a global constant, n \u2212 i is the same constant in the entire row i, and 1 n+j+1 is the same constant in the entire column j. We factor out the global constant N +1 N , factor out n \u2212 i from each row i, and factor out 1 n+j+1 from each column j, and obtain the following recurrence:\ndet(C (n,N ) ) = 1 N 2n N + 1 N n \u00d7 n\u22121 i=0 (n \u2212 i)\nn\u22121 j=0 (n + j + 1) \u00d7 det(C (n\u22121,N \u22121) ) It follows by induction on n that det(C (n,N ) ) = 0.\nStep 3: Let x be a \"good\" matrix (Definition 5). Then V \u2264 P SHAP. More precisely, we claim that we can compute the quantity V associated to a matrix x as defined in Eq. (20) in polynomial time, by using an oracle for computing SHAP F1 (X j ) over any matrix x \u2032 .\nWe modify the matrix x as follows. We add a new attribute X 0 whose value is 1 only in the first row, and let F 1 = X 0 denote the function that returns the value of feature X 0 . We show here the new matrix x \u2032 , augmented with the values of the function We run our oracle to compute SHAP F1 (X 0 ) over the matrix x \u2032 . The value SHAP F1 (X 0 ) is given by Eq. ( 15), but notice that the matrix x \u2032 has n + 1 columns, while Eq. ( 15) is given for a matrix with n columns. Therefore, since E[F 1 |X S\u222a{0} ] = 1 for any set S, we have:\nF 1 : \uf8eb \uf8ec \uf8ec \uf8ec \uf8ed X 0 X 1 X 2 . . . X n\nSHAP F1 (X 0 ) =1 \u2212 k=0,n k!(n \u2212 k)! (n + 1)! E[F 1 |X S = 1]\nSince x is \"good\", so is the new matrix x \u2032 and, by Claim 6, for any k = 0, n\nS:|S|=k E[F 1 |X S = 1] =v k\nThis implies that we can use the value SHAP F1 (X 0 ) returned by the oracle to compute the quantity: \u2022 Construct the 0,1-matrix associated to \u03a6, denote it x.\n\u2022 Construct m + 1 matrices x (\u0393) , \u0393 = 1, m + 1, by adding \u0393 rows (1, 1, . . . , 1) at the beginning of the matrix.\n\u2022 For each matrix x (\u0393) , construct n + 1 matrices x (\u0393,\u2206) , \u2206 = 0, n, by adding n columns, of which the first \u2206 columns are 1, the others are 0.\n\u2022 For each x (\u0393,\u2206) , construct one new matrix (x (\u0393,\u2206) ) \u2032 by adding a column (1, 0, 0, . . . , 0). Call this new column X 0 .\n\u2022 Use the oracle to compute SHAP F1 (X 0 ). From here, compute the value V (\u0393,\u2206) associated with the matrix x (\u0393,\u2206) .\n\u2022 Using the values V (\u0393,0) , V (\u0393,1) , . . . , V (\u0393,n) , compute the values v\n(\u0393) 0 , v (\u0393) 1 , . . . , v(\u0393)\nn associated to the matrix x (\u0393) .\n\u2022 For each k = 0, n, use the values v\n(1)\nk , v(2)\nk , . . . , v\nto compute the coefficients a 0k , a 1k , . . . , a mk associated to the matrix x.\n\u2022 At this point we have all coefficients a \u2113k of the polynomial P (u, v).\n\u2022 Compute the coefficients b \u2113k of the polynomial Q(u, v) = P (1 + u, v).\n\u2022 Finally, return E[\u03a6] = p m q n\n(1\u2212p) m (1\u2212q) n Q( 1\u2212p p , 1\u2212q q ). This concludes the entire proof of Lemma 13.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgements", "text": "This work is partially supported by NSF grants IIS-1907997, IIS-1954222 IIS-1943641, IIS-1956441, CCF-1837129, DARPA grant N66001-17-2-4032, a Sloan Fellowship, and gifts by Intel and Facebook research. Schleich is supported by a RelationalAI fellowship. The authors would like to thank YooJung Choi for valuable discussions on the proof of Theorem 5.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Explaining individual predictions when features are dependent: More accurate approximations to Shapley values", "journal": "", "year": "2019", "authors": "K Aas; M Jullum; A L\u00f8land"}, {"ref_id": "b1", "title": "The Tractability of SHAP-Score-Based Explanations over Deterministic and Decomposable Boolean Circuits", "journal": "", "year": "2020", "authors": "M Arenas; P Barcel\u00f3; L Bertossi; M Monet"}, {"ref_id": "b2", "title": "Symmetric Weighted First-Order Model Counting", "journal": "", "year": "2015-05-31", "authors": "P Beame; G Van Den Broeck; E Gribkoff; D Suciu"}, {"ref_id": "b3", "title": "Causality-Based Explanation of Classification Outcomes", "journal": "Association for Computing Machinery", "year": "2020", "authors": "L Bertossi; J Li; M Schleich; D Suciu; Z Vagena"}, {"ref_id": "b4", "title": "Graph-based algorithms for boolean function manipulation. Computers", "journal": "IEEE Transactions on", "year": "1986", "authors": "R E Bryant"}, {"ref_id": "b5", "title": "On probabilistic inference by weighted model counting", "journal": "Artificial Intelligence", "year": "2008", "authors": "M Chavira; A Darwiche"}, {"ref_id": "b6", "title": "A knowledge compilation map", "journal": "Journal of Artificial Intelligence Research", "year": "2002", "authors": "A Darwiche; P Marquis"}, {"ref_id": "b7", "title": "Algorithmic Transparency via Quantitative Input Influence: Theory and Experiments with Learning Systems", "journal": "", "year": "2016-05-22", "authors": "A Datta; S Sen; Y Zick"}, {"ref_id": "b8", "title": "A tractable and expressive class of marginal contribution nets and its applications", "journal": "", "year": "2008-05-12", "authors": "E Elkind; L A Goldberg; P W Goldberg; M J Wooldridge"}, {"ref_id": "b9", "title": "Treewidth in verification: Local vs", "journal": "Springer", "year": "2005", "authors": "A Ferrara; G Pan; M Y Vardi"}, {"ref_id": "b10", "title": "Explainable AI in Industry", "journal": "Association for Computing Machinery", "year": "2019", "authors": "K Gade; S C Geyik; K Kenthapadi; V Mithal; A Taly"}, {"ref_id": "b11", "title": "Feature relevance quantification in explainable AI: A causal problem", "journal": "Proceedings of Machine Learning Research", "year": "2020", "authors": "D Janzing; L Minorics; P Bloebaum"}, {"ref_id": "b12", "title": "On Tractable Computation of Expected Predictions", "journal": "NeurIPS", "year": "2019", "authors": "P Khosravi; Y Choi; Y Liang; A Vergari; G Van Den Broeck"}, {"ref_id": "b13", "title": "What to Expect of Classifiers? Reasoning about Logistic Regression with Missing Features", "journal": "", "year": "2019-08-10", "authors": "P Khosravi; Y Liang; Y Choi; G V Broeck"}, {"ref_id": "b14", "title": "Handling Missing Data in Decision Trees: A Probabilistic Approach", "journal": "", "year": "2020", "authors": "P Khosravi; A Vergari; Y Choi; Y Liang; G Van Den Broeck"}, {"ref_id": "b15", "title": "Problems with Shapley-value-based explanations as feature importance measures", "journal": "", "year": "2020", "authors": "I E Kumar; S Venkatasubramanian; C Scheidegger; S Friedler"}, {"ref_id": "b16", "title": "Learning Logistic Circuits", "journal": "", "year": "2019", "authors": "Y Liang; G Van Den Broeck"}, {"ref_id": "b17", "title": "From Local Explanations to Global Understanding with Explainable AI for Trees", "journal": "Nature Machine Intelligence", "year": "2020", "authors": "S M Lundberg; G Erion; H Chen; A Degrave; J M Prutkin; B Nair; R Katz; J Himmelfarb; N Bansal; S Lee"}, {"ref_id": "b18", "title": "Consistent individualized feature attribution for tree ensembles", "journal": "", "year": "2018", "authors": "S M Lundberg; G G Erion; S.-I Lee"}, {"ref_id": "b19", "title": "A Unified Approach to Interpreting Model Predictions", "journal": "", "year": "2017", "authors": "S M Lundberg; S Lee"}, {"ref_id": "b20", "title": "The Explanation Game: Explaining Machine Learning Models Using Shapley Values", "journal": "Springer", "year": "2020", "authors": "L Merrick; A Taly"}, {"ref_id": "b21", "title": "On discriminative vs. generative classifiers: A comparison of logistic regression and naive bayes", "journal": "", "year": "2002", "authors": "A Y Ng; M I Jordan"}, {"ref_id": "b22", "title": "The Complexity of Counting Cuts and of Computing the Probability that a Graph is Connected", "journal": "SIAM J. Comput", "year": "1983", "authors": "J S Provan; M O Ball"}, {"ref_id": "b23", "title": "Factorization machines", "journal": "IEEE", "year": "2010", "authors": "S Rendle"}, {"ref_id": "b24", "title": "The Shapley Value: Essays in Honor of Lloyd S. Shapley", "journal": "Cambridge Univ. Press", "year": "1988", "authors": "A E Roth"}, {"ref_id": "b25", "title": "Performing Bayesian inference by weighted model counting", "journal": "", "year": "2005", "authors": "T Sang; P Beame; H A Kautz"}, {"ref_id": "b26", "title": "Explaining prediction models and individual predictions with feature contributions", "journal": "", "year": "2014", "authors": "D Slack; S Hilgard; E Jia; S Singh; H Lakkaraju; ; E Kononenko; I "}, {"ref_id": "b27", "title": "The many Shapley values for model explanation", "journal": "", "year": "2020", "authors": "M Sundararajan; A Najmi"}, {"ref_id": "b28", "title": "Skolemization for Weighted First-Order Model Counting", "journal": "", "year": "2014-07-20", "authors": "G Van Den Broeck; W Meert; A Darwiche"}, {"ref_id": "b29", "title": "Probabilistic Circuits: Representations, Inference, Learning and Applications. AAAI Tutorial", "journal": "", "year": "2020", "authors": "A Vergari; Y Choi; R Peharz; G Van Den Broeck"}, {"ref_id": "b30", "title": "A new approach to model counting", "journal": "Springer", "year": "2005", "authors": "W Wei; B Selman"}], "figures": [{"figure_label": "4", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Corollary 4 .4For the following function classes F, computing SHAP scores F-SHAP(F, IND) is in polynomial time in the size of the representations of function F \u2208 F and fullyfactorized distribution Pr \u2208 IND.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "(\u03c3(weight(S)) + \u03c3(weight(S))) If S is a solution to the number partitioning problem (S \u2208 P ), then: \u03c3(weight(S)) + \u03c3(weight(S)) = 2\u03c3(\u2212m/2) Otherwise, one of weight(S), weight(S) is \u2265 m/2 and the other is \u2264 \u22123m/2 and therefore: \u03c3(m/2) \u2264 \u03c3(weight(S)) + \u03c3(weight(S)) \u2264 1 + \u03c3(\u22123m/2)", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "7.Using the (m+1)(n (1) +1) results from the previous step, form a system of Equations where the unknowns are the coefficients b \u2113k , \u2113 = 0, m, k = 0, n (1) , of the polynomial Q(u, v), see (22). Solve for the coefficients b \u2113k . 8. Compute the coefficients a \u2113k of the polynomial P (u, v) = Q(u \u2212 1, v), see Claim 7, then compute v k = \u2113 a \u2113k /\u2113. By Claim 6, v k = S:|S|=k E[F 1 |X S = 1], completing", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Putting It Together Given a PP2CNF formula \u03a6 = (U i \u2228 V j ), and two probability valuesp = Pr(U 1 ) = \u2022 \u2022 \u2022 = Pr(U m ) and q = Pr(V 1 ) = \u2022 \u2022 \u2022 = Pr(V n ), to compute E[\u03a6]we proceed as follows:", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "F as E Pr [F |x S ] = x\u2208X F (x) Pr(x|x S ).", "formula_coordinates": [2.0, 54.0, 639.69, 173.01, 10.65]}, {"formula_id": "formula_1", "formula_text": "v F,x,Pr (X S ) def = E Pr [F |x S ].", "formula_coordinates": [2.0, 381.24, 117.41, 114.96, 14.05]}, {"formula_id": "formula_2", "formula_text": "c(X, X S ) def = v(X S \u222a {X}) \u2212 v(X S ). (2", "formula_coordinates": [2.0, 360.6, 187.61, 193.57, 13.73]}, {"formula_id": "formula_3", "formula_text": ")", "formula_coordinates": [2.0, 554.17, 191.62, 3.91, 9.03]}, {"formula_id": "formula_4", "formula_text": "SHAP(X) def = 1 n! \u03c0 c(X, \u03c0 <X ).(3)", "formula_coordinates": [2.0, 372.36, 347.25, 185.72, 27.14]}, {"formula_id": "formula_5", "formula_text": "SHAP G (X) = k \u03bb k SHAP F k (X).(4)", "formula_coordinates": [2.0, 367.56, 433.29, 190.52, 20.89]}, {"formula_id": "formula_6", "formula_text": "i SHAP F (X i ) = F (x) \u2212 E[F ].(5)", "formula_coordinates": [2.0, 375.36, 490.29, 182.72, 20.66]}, {"formula_id": "formula_7", "formula_text": "1 = x 1 , . . . , X n = x n ) = i Pr(X i = x i ). Let IND def = n\u22650 IND n .", "formula_coordinates": [3.0, 54.0, 618.21, 238.5, 27.38]}, {"formula_id": "formula_8", "formula_text": "F over n features, E({F }) \u2264 P F-SHAP({F }, IND n ), because E[F ] = F (x) \u2212 i=1,n SHAP F (X i ).", "formula_coordinates": [3.0, 319.56, 82.29, 238.64, 33.85]}, {"formula_id": "formula_9", "formula_text": "F-SHAP({F }, IND n ) \u2261 P E({F }).", "formula_coordinates": [3.0, 319.56, 141.07, 143.28, 11.44]}, {"formula_id": "formula_10", "formula_text": "p i def = Pr(X i = 1), i = 0, n; obviously, Pr(X i = 0) = 1 \u2212 p i .", "formula_coordinates": [3.0, 319.56, 520.61, 238.41, 13.73]}, {"formula_id": "formula_11", "formula_text": "SHAP(X 0 ) = k=0,n k!(n \u2212 k)! (n + 1)! D k , where(6)", "formula_coordinates": [3.0, 328.44, 575.61, 229.64, 27.62]}, {"formula_id": "formula_12", "formula_text": "D k def = S\u2286[n]:|S|=k E F |e S\u222a{0} \u2212 E[F |e S ] . Let F 0 def = F [X 0 := 0] and F 1 def = F [X 0 := 1]", "formula_coordinates": [3.0, 319.56, 608.69, 229.68, 48.37]}, {"formula_id": "formula_13", "formula_text": "E F e S\u222a{0} = E[F 1 |e S ] E[F |e S ] = E[F 0 |e S ] \u2022 (1 \u2212 p 0 ) + E[F 1 |e S ] \u2022 p 0", "formula_coordinates": [3.0, 330.6, 676.05, 215.89, 25.89]}, {"formula_id": "formula_14", "formula_text": "D k = (1 \u2212 p 0 ) S\u2286[n]:|S|=k (E[F 1 |e S ] \u2212 E[F 0 |e S ])", "formula_coordinates": [4.0, 71.64, 78.57, 203.19, 21.25]}, {"formula_id": "formula_15", "formula_text": "v G,k def = S\u2286[n],|S|=k E[G|e S ].(7)", "formula_coordinates": [4.0, 114.96, 153.05, 177.68, 24.65]}, {"formula_id": "formula_16", "formula_text": "j ) = p \u2032 j def = pj +z 1+z , for j = 1, n. Let E z [G] denote E[G] under distribution Pr z . We then have that k=0,n z k \u2022 v k =(1 + z) n \u2022 E z [G].(8)", "formula_coordinates": [4.0, 54.0, 398.69, 238.64, 59.45]}, {"formula_id": "formula_17", "formula_text": "x \u2208 {0, 1} n is Pr(x) = i:xi=1 p i \u2022 i:xi=0 (1 \u2212 p i ), where x i looks up the value of feature X i in instance x. Similarly, Pr z (x) = i:xi=1 p \u2032 i \u2022 i:xi=0 (1 \u2212 p \u2032 i ).", "formula_coordinates": [4.0, 54.0, 546.09, 238.65, 44.77]}, {"formula_id": "formula_18", "formula_text": "Pr(x) i:xi=1 1 + z p i = (1 + z) n \u2022 Pr z (x)(9)", "formula_coordinates": [4.0, 85.92, 607.17, 206.72, 27.38]}, {"formula_id": "formula_19", "formula_text": "E[G|e S ] = 1 i\u2208S p i x:xS=eS G(x) \u2022 Pr(x)(10)", "formula_coordinates": [4.0, 87.96, 674.37, 204.68, 25.68]}, {"formula_id": "formula_20", "formula_text": "k=0,n z k \u2022 v k = k=0,n z k S\u2286[n]:|S|=k E[G|e S ] = S\u2286[n] z |S| \u2022 E[G|e S ] = S\u2286[n] z |S| i\u2208S p i x:xS=eS G(x) \u2022 Pr(x)", "formula_coordinates": [4.0, 334.32, 76.03, 208.71, 87.15]}, {"formula_id": "formula_21", "formula_text": "= x\u2208{0,1} n G(x) \u2022 Pr(x) S:xS =eS z |S| i\u2208S p i = x\u2208{0,1} n G(x) \u2022 Pr(x) i:xi=1 1 + z p i = (1 + z) n x\u2208{0,1} n G(x) \u2022 Pr z (x) = (1 + z) n \u2022 E z [G].", "formula_coordinates": [4.0, 327.48, 229.49, 222.48, 91.11]}, {"formula_id": "formula_22", "formula_text": "F : X ( def = i dom(X i )) \u2192 R,", "formula_coordinates": [4.0, 319.56, 384.29, 132.69, 15.29]}, {"formula_id": "formula_23", "formula_text": "T (x) def = j:xj =1 (X j = 1) \u2227 j:xj =0 (X j = 1).", "formula_coordinates": [4.0, 353.4, 496.61, 170.76, 24.37]}, {"formula_id": "formula_24", "formula_text": "\u2200x \u2208 {0, 1} n , Pr \u03c0 (x) def = Pr(T (x)) F \u03c0 (x) def = E[F | T (x)](11)", "formula_coordinates": [4.0, 337.32, 529.63, 220.88, 34.0]}, {"formula_id": "formula_25", "formula_text": "F \u03c0 (1, 0, 0) =E[F |(X 1 = 1, X 2 = 1, X 3 = 1)] Pr \u03c0 (1, 0, 0) =Pr(X 1 = 1, X 2 = 1, X 3 = 1)", "formula_coordinates": [4.0, 344.04, 612.21, 189.48, 24.57]}, {"formula_id": "formula_26", "formula_text": "F (x) def = \u03c3(w \u2022 x), where w = (w 0 , w 1 , . . . , w n ) is a vector of weights, \u03c3(z) = 1/(1+e \u2212z ) is the logistic function, x def = (1, x 1 , x 2 , . . . , x n ), and w \u2022 x def =", "formula_coordinates": [5.0, 319.56, 501.41, 238.64, 44.05]}, {"formula_id": "formula_27", "formula_text": "Pr(X) = Pr(X 0 ) \u2022 i=1,n Pr(X i |X 0 ).", "formula_coordinates": [6.0, 101.52, 553.29, 143.4, 20.66]}, {"formula_id": "formula_28", "formula_text": "Theorem 8. The decision problem D-SHAP({X 0 }, NBN) is NP-hard.", "formula_coordinates": [6.0, 54.0, 624.81, 238.47, 20.47]}, {"formula_id": "formula_29", "formula_text": "d = (x ij ) i\u2208[m],j\u2208[n] ,", "formula_coordinates": [7.0, 205.44, 300.33, 87.09, 10.69]}, {"formula_id": "formula_30", "formula_text": "\u03a6 d def = (i,j):xij =0 (U i \u2228 V j ). Thus, a PP2CNF formula is over m + n variables U 1 , . . . , U m , V 1 , . . . , V n ,", "formula_coordinates": [7.0, 54.0, 519.65, 238.71, 54.01]}, {"formula_id": "formula_31", "formula_text": "1 = 1) = \u2022 \u2022 \u2022 = Pr(V n = 1) = 1/2) is #P-hard", "formula_coordinates": [7.0, 219.84, 56.49, 223.98, 648.69]}, {"formula_id": "formula_32", "formula_text": "if v j = internal then return v j else if d j \u2286 S then return G(a j ) if x dj \u2264 t j else G(b j ) else return (G(a j ) \u2022 r aj + G(b j ) \u2022 r bj )/r j return G(1)", "formula_coordinates": [10.0, 63.96, 106.05, 183.65, 91.68]}, {"formula_id": "formula_33", "formula_text": "X 1 X 2 # 0 0 2 0 1 1 1 0 1 1 1 2 X 1 X 2 X 2 0 1 F (0, 0) F (0, 1) F (1, 0) F (1, 1) 0 1 0 1", "formula_coordinates": [10.0, 336.12, 95.03, 209.12, 66.49]}, {"formula_id": "formula_34", "formula_text": "E[F (X 1 , X 2 ) | X 2 = 0] = 2/3 \u2022 F (0, 0) + 1/3 \u2022 F (1, 0)", "formula_coordinates": [10.0, 324.84, 186.33, 227.91, 10.66]}, {"formula_id": "formula_35", "formula_text": "G(1) = 1/2 \u2022 F (0, 0) + 1/2 \u2022 F (1, 0), and thus does not compute E[F (X 1 , X 2 ) | X 2 = 0].", "formula_coordinates": [10.0, 319.56, 243.21, 209.37, 28.06]}, {"formula_id": "formula_36", "formula_text": "T (x) def = j:xj =1 (X j = 1) \u2227 j:xj =0 (X j = 1).", "formula_coordinates": [10.0, 353.4, 432.29, 170.76, 24.37]}, {"formula_id": "formula_37", "formula_text": "x \u2208 {0, 1} n , Pr(T (x)) = i:xi=1 p i1 \u2022 i:xi=0 (p i2 + p i3 + \u2022 \u2022 \u2022 ) = Pr \u03c0 (x).", "formula_coordinates": [10.0, 322.56, 464.23, 232.2, 42.15]}, {"formula_id": "formula_38", "formula_text": "E[F \u2227 e S ] = x:\u2200i\u2208S,xi=1 E[F |T (x)] Pr(T (x)) = x:\u2200i\u2208S,xi=1 F \u03c0 (x) Pr \u03c0 (x) = E \u03c0 [F \u03c0 \u2227 e S ]", "formula_coordinates": [10.0, 345.36, 545.61, 186.75, 65.05]}, {"formula_id": "formula_39", "formula_text": "q i def = Pr \u2032 \u03c0 (X i = 1), thus Pr \u03c0 (X i = 0) = 1 \u2212 q i .", "formula_coordinates": [11.0, 54.0, 54.65, 201.09, 14.69]}, {"formula_id": "formula_40", "formula_text": "w i def = 1 \u2212 q i q i and Z def = i=1,n q i W def = i=1,n \uf8eb \uf8ed 1 + j=2,mi p ij w i 1 \u2212 p i1 \uf8f6 \uf8f8 p \u2032 i1 def = 1 W i =1, n p \u2032 ij def = p ij w i W (1 \u2212 p i1 ) i =1, n; j = 2, m i", "formula_coordinates": [11.0, 54.0, 107.49, 246.42, 117.25]}, {"formula_id": "formula_41", "formula_text": "Claim 3. E \u03c0 [F \u03c0 ] = Z \u2022 W \u2022 E \u2032 [F ]", "formula_coordinates": [11.0, 54.0, 296.45, 140.88, 11.69]}, {"formula_id": "formula_42", "formula_text": "F \u03c0 [x] = E[F |T (x)] = E[F \u2022 T (x)] Pr(T (x)) = \u03c4 \u2208X :x \u22121 (1)=\u03c4 \u22121 (1) F (\u03c4 ) \u2022 i p i\u03c4i i:xi=1 p i1 \u2022 i:xi =1 (1 \u2212 p i1 ) = \u03c4 \u2208X :x \u22121 (1)=\u03c4 \u22121 (1) F (\u03c4 ) \u2022 i:\u03c4i =1 p i\u03c4i 1 \u2212 p i1 .", "formula_coordinates": [11.0, 72.24, 397.29, 202.08, 84.1]}, {"formula_id": "formula_43", "formula_text": "E \u03c0 [F \u03c0 ] = \u03b8\u2208{0,1} n F \u03c0 (\u03b8) i:\u03b8i=1 q i i:\u03b8i=0 (1 \u2212 q i ) =Z \u2022 \u03b8\u2208{0,1} n F \u03c0 (\u03b8) i:\u03b8i=0 w i =Z \u2022 \u03b8 \u2208 {0, 1} n \u03c4 \u2208 X \u03b8 \u22121 (1) = \u03c4 \u22121 (1) F (\u03c4 ) i:\u03c4i =1 p i\u03c4i 1 \u2212 p i1 i:\u03b8i=0 w i =Z \u2022 \u03c4 \u2208X F (\u03c4 ) i:\u03c4i =1 p i\u03c4i w i 1 \u2212 p i1 =Z \u2022 W \u2022 \u03c4 \u2208X F (\u03c4 ) i p \u2032 i\u03c4i =Z \u2022 W \u2022 E \u2032 [F ]", "formula_coordinates": [11.0, 54.0, 54.65, 362.64, 652.57]}, {"formula_id": "formula_44", "formula_text": "i\u2208S k i = i \u2208S k i .", "formula_coordinates": [11.0, 440.16, 187.29, 78.45, 12.22]}, {"formula_id": "formula_45", "formula_text": "P def = {S | S \u2286 [n], i\u2208S k i = c} (12)", "formula_coordinates": [11.0, 376.44, 325.97, 181.76, 24.17]}, {"formula_id": "formula_46", "formula_text": "w 0 def = \u2212 m 2 \u2212 mc w i def = mk i \u2200i = 1, n Let w = (w 1 , . . . , w n ), then F (x 1 , . . . , x n ) def = \u03c3(w 0 + w \u2022 x)", "formula_coordinates": [11.0, 319.56, 438.57, 238.38, 53.4]}, {"formula_id": "formula_47", "formula_text": "Claim 4. Let \u03b5 def = 1/2 n+3 . If m satisfies both 2\u03c3(\u2212m/2) \u2264 \u03b5 and 1 \u2212 \u03c3(m/2) \u2264 \u03b5, then: |P | = 2 n \u2212 2 n+1 E[F ] 1 \u2212 \u03b5", "formula_coordinates": [11.0, 319.56, 508.01, 238.38, 55.96]}, {"formula_id": "formula_48", "formula_text": "weight(S) def = \u2212 m 2 \u2212 mc + m( i\u2208S k i )", "formula_coordinates": [11.0, 360.24, 618.57, 156.99, 27.5]}, {"formula_id": "formula_49", "formula_text": "E U [F ] = 1 2 n x \u03c3(w 0 + w \u2022 x) = 1 2 n x \u03c3(\u2212 m 2 \u2212 mc + m( i\u2208[n] k i x i )) = 1 2 n x \u03c3(\u2212 m 2 \u2212 mc + m( i:xi=1 k i )) = 1 2 n S\u2286[n] \u03c3(weight(S)) = 1 2 n+1 S\u2286[n]", "formula_coordinates": [11.0, 330.0, 680.37, 131.3, 25.68]}, {"formula_id": "formula_50", "formula_text": "S \u2208 P : 0 \u2264 \u03c3(weight(S)) + \u03c3(weight(S)) \u2264 \u03b5 S \u2208 P : 1 \u2212 \u03b5 \u2264 \u03c3(weight(S)) + \u03c3(weight(S)) \u2264 1 + \u03b5 This implies: 2 n \u2212 |P | 2 n+1 (1 \u2212 \u03b5) \u2264 E[F ] \u2264 |P | 2 n+1 \u03b5 + 2 n \u2212 |P | 2 n+1 (1 + \u03b5) |P | \u22652 n \u2212 2 n+1 E[F ] 1 \u2212 \u03b5 |P | \u22642 n (1 + \u03b5) \u2212 2 n+1 E[F ]", "formula_coordinates": [12.0, 55.68, 290.01, 235.16, 106.8]}, {"formula_id": "formula_51", "formula_text": "Pr(X 0 ) Pr(X 0 ) =e \u2212 m 2 \u2212mc Pr(X i |X 0 ) Pr(X i |X 0 ) =e mki", "formula_coordinates": [12.0, 83.04, 604.53, 180.73, 24.46]}, {"formula_id": "formula_52", "formula_text": "F (X 0 , . . . , X n ) def = X 0 . Let a k def = k!(n\u2212k)! (n+1)!", "formula_coordinates": [12.0, 54.0, 667.01, 178.29, 16.09]}, {"formula_id": "formula_53", "formula_text": "SHAP F (X 0 ) = S\u2286[n] a |S| E[F | X S\u222a{0} ] \u2212 E[F | X S ]", "formula_coordinates": [12.0, 324.6, 140.25, 223.92, 21.25]}, {"formula_id": "formula_54", "formula_text": "S\u2286[n] a |S| = 1, because there are n k sets of size k, hence S\u2286[n] a |S| = k=0,n n k \u2022 k!(n\u2212k)! (n+1)! = 1.", "formula_coordinates": [12.0, 319.56, 177.19, 238.41, 30.36]}, {"formula_id": "formula_55", "formula_text": "D def = S\u2286[n] a |S| \u2022 E[X 0 | X S ](13)", "formula_coordinates": [12.0, 379.2, 222.41, 179.0, 24.77]}, {"formula_id": "formula_56", "formula_text": "E[X 0 |X S ] = Pr(X 0 |X S ) = Pr(X 0 , X S ) Pr(X S ) = i\u2208S Pr(X i |X 0 )Pr(X 0 ) i\u2208S Pr(X i |X 0 )Pr(X 0 ) + i\u2208S Pr(X i |X 0 )Pr(X 0 ) = 1 1 + Pr(X 0 )/Pr(X 0 ) \u2022 i\u2208S (Pr(X i |X 0 )/Pr(X i |X 0 )) = \u03c3(weight(S)) where: \u03c3(x) def = 1 1 + e \u2212x weight(S) def = \u2212 m 2 \u2212 mc + m( i\u2208S k i )", "formula_coordinates": [12.0, 319.56, 263.97, 237.03, 135.62]}, {"formula_id": "formula_57", "formula_text": "def = [n] \u2212 S: D = 1 2 S\u2286[n]", "formula_coordinates": [12.0, 330.36, 413.57, 97.21, 43.61]}, {"formula_id": "formula_59", "formula_text": "S \u2208 P : 0 \u2264 \u03c3(weight(S)) + \u03c3(weight(S)) \u2264 \u03b5 S \u2208 P : 1 \u2212 \u03b5 \u2264 \u03c3(weight(S)) + \u03c3(weight(S)) \u2264 1 + \u03b5", "formula_coordinates": [12.0, 321.12, 539.85, 235.16, 25.44]}, {"formula_id": "formula_60", "formula_text": "D \u2264 1 2 (1 + \u03b5) \u2212 a k (1 + \u03b5) + a k \u03b5 \u2264 1 2 \u2212 a k \u2212 \u03b5 2 < 1 2 \u2212 \u03b5 2 and therefore SHAP F (X 0 ) > 1/2(1 + \u03b5).", "formula_coordinates": [12.0, 329.52, 643.53, 189.8, 61.65]}, {"formula_id": "formula_61", "formula_text": "Pr(U i ) = p when i \u2208 I 1 when i \u2208 I Pr(V j ) = q when j \u2208 J 1 when j \u2208 J", "formula_coordinates": [13.0, 54.72, 300.45, 225.0, 23.16]}, {"formula_id": "formula_62", "formula_text": "i def = F (x i0 , x i1 , . . . , x in ), i = 1", "formula_coordinates": [13.0, 112.56, 554.69, 127.26, 13.73]}, {"formula_id": "formula_63", "formula_text": "SHAP F1 (X 0 ) = k=0,n k!(n \u2212 k)! (n + 1)! S\u2286[n]:|S|=k E[F 1 |X S\u222a{0} = 1] \u2212 E[F 1 |X S = 1](15)", "formula_coordinates": [13.0, 332.88, 73.53, 225.32, 70.0]}, {"formula_id": "formula_64", "formula_text": "v F1,k = S\u2286[n]:|S|=k E[F 1 |X S = 1](16)", "formula_coordinates": [13.0, 369.72, 172.29, 188.48, 21.25]}, {"formula_id": "formula_65", "formula_text": "S:|S|=k E[F 1 |X S\u222a{0} = 1", "formula_coordinates": [13.0, 330.0, 213.69, 119.94, 11.78]}, {"formula_id": "formula_66", "formula_text": "E[\u03a6 x ].", "formula_coordinates": [13.0, 526.08, 429.09, 28.29, 9.96]}, {"formula_id": "formula_67", "formula_text": "g(S) def = {i | \u2200j \u2208 S, x ij = 1}(17)", "formula_coordinates": [13.0, 372.84, 484.37, 185.36, 13.73]}, {"formula_id": "formula_68", "formula_text": "a \u2113k def = |{S | |S| = k, |g(S)| = \u2113}|(18)", "formula_coordinates": [13.0, 378.96, 503.09, 179.24, 13.73]}, {"formula_id": "formula_69", "formula_text": "v k def = l=1,m a \u2113k \u2113(19)", "formula_coordinates": [13.0, 411.36, 541.05, 146.84, 27.61]}, {"formula_id": "formula_70", "formula_text": "V def = k=0,n k!(n \u2212 k)! (n + 1)! v k(20)", "formula_coordinates": [13.0, 393.0, 594.21, 165.2, 27.61]}, {"formula_id": "formula_71", "formula_text": "If S \u2286 J (1) : E x [F 1 |X S = 1] =E x (1) [F 1 |X S = 1] If S \u2286 J (1) : E x [F 1 |X S = 1] =0", "formula_coordinates": [14.0, 66.24, 134.93, 214.08, 29.17]}, {"formula_id": "formula_72", "formula_text": "S\u2286[n]:|S|=k E x [F 1 |X S = 1] = S\u2286J (1) :|S|=k E x (1) [F 1 |X S = 1]", "formula_coordinates": [14.0, 54.6, 203.13, 237.36, 22.18]}, {"formula_id": "formula_73", "formula_text": "v k = S:|S|=k E[F 1 |X S = 1]", "formula_coordinates": [14.0, 117.72, 412.53, 111.12, 21.25]}, {"formula_id": "formula_74", "formula_text": "S \u2286J (1) : |g(S)| >0 E[F 1 |X S = 1] = 1 |g(S)| S \u2286J (1) : |g(S)| =0 E[F 1 |X S = 1] =0", "formula_coordinates": [14.0, 69.12, 483.09, 207.0, 40.06]}, {"formula_id": "formula_75", "formula_text": "S\u2286[n]:|S|=k E[F 1 |X S = 1] = S\u2286J (1) :|S|=k E[F 1 |X S = 1] = S\u2286J(", "formula_coordinates": [14.0, 55.68, 546.81, 227.76, 54.49]}, {"formula_id": "formula_76", "formula_text": "P (u, v) def = S\u2286[n] u |g(S)| v |S| Q(u, v) def = T \u2286 [m], S \u2286 [n] : \u2200(i, j) \u2208 T \u00d7 S : xij = 1 u |T | v |S|", "formula_coordinates": [14.0, 85.2, 54.65, 441.2, 651.05]}, {"formula_id": "formula_77", "formula_text": "[n], T \u2286 [m].", "formula_coordinates": [14.0, 504.24, 109.53, 53.73, 9.96]}, {"formula_id": "formula_78", "formula_text": "P (u, v) = \u2113=0,m;k=0,n a \u2113k u \u2113 v k Q(u, v) =P (1 + u, v)", "formula_coordinates": [14.0, 376.32, 216.91, 124.11, 37.58]}, {"formula_id": "formula_79", "formula_text": "(\u2200i \u2208 T, \u2200j \u2208 S : x ij = 1) \u21d4 T \u2286 g(S)", "formula_coordinates": [14.0, 339.6, 308.61, 198.39, 10.33]}, {"formula_id": "formula_80", "formula_text": "Q(u, v) = S\u2286[n],T \u2286g(S) u |T | v |S|", "formula_coordinates": [14.0, 374.64, 340.73, 127.64, 23.41]}, {"formula_id": "formula_81", "formula_text": "|T | = (1 + u) |g(S)| .", "formula_coordinates": [14.0, 477.72, 370.73, 80.25, 11.44]}, {"formula_id": "formula_82", "formula_text": "E[\u03a6 x ] = 1 (1 + u) m (1 + v) n Q(u, v)(21)", "formula_coordinates": [14.0, 365.64, 542.13, 192.56, 23.52]}, {"formula_id": "formula_83", "formula_text": "Pr(\u03a6 x ) = \u03b8,\u03c4 :\u03a6[\u03b8,\u03c4 ]=1 Pr(\u03b8)Pr(\u03c4 ) = T \u2286 [m], S \u2286 [n] \u2200(i, j) \u2208 T \u00d7 S : xij = 1 p m\u2212|T | (1 \u2212 p) |T | q n\u2212|S| (1 \u2212 q) |S| = p m q n Q((1 \u2212 p)/p, (1 \u2212 q)/q)", "formula_coordinates": [14.0, 321.36, 641.85, 234.32, 62.85]}, {"formula_id": "formula_84", "formula_text": "Q(u, v) = \u2113=0,m;k=0,n b \u2113k u \u2113 v k (22)", "formula_coordinates": [15.0, 111.36, 141.31, 181.28, 22.48]}, {"formula_id": "formula_85", "formula_text": "A (ij),(\u2113k) =u \u2113 i v k j", "formula_coordinates": [15.0, 139.68, 300.79, 66.51, 12.88]}, {"formula_id": "formula_86", "formula_text": "V (z 1 , . . . , z t ) = \uf8ee \uf8ef \uf8ef \uf8ef \uf8f0 1 1 . . . 1 z 1 z 2 . . . z t z 2 1 z 2 2 . . . z 2 t . . . z t\u22121 1 z t\u22121 2 . . . z t\u22121 t \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fb", "formula_coordinates": [15.0, 79.08, 370.77, 188.32, 57.22]}, {"formula_id": "formula_87", "formula_text": "A =V (u 0 , u 1 , . . . , u m ) \u2297 V (v 0 , v 1 , . . . , v n )", "formula_coordinates": [15.0, 84.0, 486.69, 178.47, 10.66]}, {"formula_id": "formula_88", "formula_text": "u \u03b1 , v \u03b2 , compute Q(u \u03b1 , v \u03b2 ) = (1 + u \u03b1 ) m (1 + v \u03b2 ) n (1) E[\u03a6 \u2032 ] (see", "formula_coordinates": [15.0, 329.52, 174.43, 228.42, 25.6]}, {"formula_id": "formula_89", "formula_text": "[\u03a6] = 1 (1+u) m (1+v) n Q(u, v)", "formula_coordinates": [15.0, 437.55, 635.33, 120.47, 14.42]}, {"formula_id": "formula_90", "formula_text": "g (\u0393) =g(S) \u222a {the \u0393 new rows} a (\u0393)", "formula_coordinates": [16.0, 103.56, 197.57, 139.38, 29.56]}, {"formula_id": "formula_91", "formula_text": "v (1) k = 1 1 a 0k + 1 2 a 1k + \u2022 \u2022 \u2022 + 1 m + 1 a mk v (2) k = 1 2 a 0k + 1 3 a 1k + \u2022 \u2022 \u2022 + 1 m + 2 a mk \u2022 \u2022 \u2022 v (m+1) k = 1 m + 2 a 0k + 1 m + 3 a 1k + \u2022 \u2022 \u2022 + 1 2m + 2 a mk", "formula_coordinates": [16.0, 60.36, 247.65, 225.15, 88.08]}, {"formula_id": "formula_92", "formula_text": "det 1 x i + y j = 1\u2264i<j\u2264n (x i \u2212 x j )(y i \u2212 y j )", "formula_coordinates": [16.0, 77.4, 377.85, 190.47, 25.33]}, {"formula_id": "formula_93", "formula_text": "\uf8eb \uf8ec \uf8ed x 11 x 12 . . . x 1n 1 1 . . . 1 0 . . . 0 x 21 x 22 . . . x 2n 1 1 . . . 1 0 . . . 0 . . . x m1 x m2 . . . x mn 1 1 . . . 1 0 . . . 0 \uf8f6 \uf8f7 \uf8f8 Notice that x (", "formula_coordinates": [16.0, 54.0, 559.89, 241.16, 61.44]}, {"formula_id": "formula_94", "formula_text": "g (\u2206) (S) =g(\u2206 \u2229 [n]) a (\u2206) \u2113p = k=0,min(p,n) \u2206 p \u2212 k a \u2113k v (\u2206) p = k=0,min(p,n) \u2206 p \u2212 k v k", "formula_coordinates": [16.0, 100.68, 54.21, 406.23, 651.49]}, {"formula_id": "formula_95", "formula_text": "V (\u2206) = p=0,2n p!(2n \u2212 p)! (2n + 1)! v (\u2206) p = 1 2n + 1 p=0,n+\u2206 1 2n p v \u2206 p = 1 2n + 1 p=0,n+\u2206 k=0,min(p,n) \u2206 p\u2212k 2n p v k = 1 2n + 1 k=0,n p=k,k+\u2206 \u2206 p\u2212k 2n p v k = 1 2n + 1 k=0,n \uf8eb \uf8ed q=0,\u2206 \u2206 q 2n k+q \uf8f6 \uf8f8 v k def = 1 2n + 1 k=0,n A \u2206,k \u2022 v k", "formula_coordinates": [16.0, 346.2, 115.77, 184.47, 203.06]}, {"formula_id": "formula_96", "formula_text": "A", "formula_coordinates": [16.0, 343.8, 392.25, 7.47, 9.96]}, {"formula_id": "formula_97", "formula_text": "X def = V (x 0 , x 1 , . . . , x n ), X qt def = x q t . Denoting Y def = B \u2022 X, we have that Y \u2206t = q=0,n B \u2206,q X q,t = q=0,n \u2206 q x q t = (1 + x t ) \u2206", "formula_coordinates": [16.0, 319.56, 497.09, 238.42, 67.01]}, {"formula_id": "formula_98", "formula_text": "C (n,N ) def = \uf8eb \uf8ec \uf8ec \uf8ec \uf8ec \uf8ed 1 ( N 0 ) 1 ( N 1 ) . . . 1 ( N n ) 1 (N 1 ) 1 ( N 2 )", "formula_coordinates": [16.0, 350.64, 645.77, 157.82, 45.88]}, {"formula_id": "formula_99", "formula_text": "1 ( N n+1 ) . . . 1 ( N n ) 1 ( N n+1 ) . . . 1 ( N 2n ) \uf8f6 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f8", "formula_coordinates": [16.0, 410.76, 646.78, 116.12, 60.66]}, {"formula_id": "formula_100", "formula_text": "1 ( N i+j ) 1 ( N i+j+1 )", "formula_coordinates": [17.0, 144.12, 163.49, 58.35, 17.41]}, {"formula_id": "formula_101", "formula_text": ". . . 1 ( N i+j+1 ) \u00d7 N \u2212i\u2212j i+j+1 1 ( N i+j+1 )", "formula_coordinates": [17.0, 89.4, 225.29, 144.87, 17.89]}, {"formula_id": "formula_102", "formula_text": "1 N i+j+1 \u00d7 N \u2212 (i + j) (i + j) + 1 \u2212 N \u2212 (n + j) (n + j) + 1", "formula_coordinates": [17.0, 89.4, 341.61, 164.91, 27.25]}, {"formula_id": "formula_103", "formula_text": "1 N (i+j)+1 \u00d7 N \u2212 (i + j) (i + j) + 1 \u2212 N \u2212 (n + j) (n + j) + 1 = (N \u2212 i \u2212 j \u2212 1)!(i + j + 1)! N ! (N + 1)(n \u2212 i) (i + j + 1)(n + j + 1) = (N \u2212 i \u2212 j \u2212 1)!(i + j)! (N \u2212 1)!N (N + 1)(n \u2212 i) (n + j + 1) = 1 N \u22121 (i+j) (N + 1)(n \u2212 i) N (n + j + 1)", "formula_coordinates": [17.0, 61.92, 393.69, 224.31, 113.97]}, {"formula_id": "formula_104", "formula_text": "det(C (n,N ) ) = 1 N 2n N + 1 N n \u00d7 n\u22121 i=0 (n \u2212 i)", "formula_coordinates": [17.0, 63.12, 655.63, 209.91, 30.24]}, {"formula_id": "formula_105", "formula_text": "F 1 : \uf8eb \uf8ec \uf8ec \uf8ec \uf8ed X 0 X 1 X 2 . . . X n", "formula_coordinates": [17.0, 356.88, 166.41, 127.8, 56.64]}, {"formula_id": "formula_106", "formula_text": "SHAP F1 (X 0 ) =1 \u2212 k=0,n k!(n \u2212 k)! (n + 1)! E[F 1 |X S = 1]", "formula_coordinates": [17.0, 334.68, 310.29, 208.44, 27.62]}, {"formula_id": "formula_107", "formula_text": "S:|S|=k E[F 1 |X S = 1] =v k", "formula_coordinates": [17.0, 384.12, 378.93, 108.63, 21.25]}, {"formula_id": "formula_108", "formula_text": "(\u0393) 0 , v (\u0393) 1 , . . . , v(\u0393)", "formula_coordinates": [17.0, 361.92, 691.61, 71.75, 14.77]}, {"formula_id": "formula_109", "formula_text": "k , v(2)", "formula_coordinates": [18.0, 209.88, 54.05, 30.95, 14.81]}], "doi": ""}