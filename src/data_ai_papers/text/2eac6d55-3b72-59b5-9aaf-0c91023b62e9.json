{"title": "Tasks On Molecules in Three Dimensions", "authors": "Raphael J L Townshend; Martin V\u00f6gele; Patricia Suriana; Alexander Derry; Alexander S Powers; Yianni Laloudakis; Sidhika Balachandar; Bowen Jing; Brandon Anderson; Stephan Eismann; Risi Kondor; Russ B Altman; Ron O Dror", "pub_date": "2022-01-15", "abstract": "Computational methods that operate on three-dimensional (3D) molecular structure have the potential to solve important problems in biology and chemistry. Deep neural networks have gained significant attention, but their widespread adoption in the biomolecular domain has been limited by a lack of either systematic performance benchmarks or a unified toolkit for interacting with 3D molecular data. To address this, we present ATOM3D, a collection of both novel and existing benchmark datasets spanning several key classes of biomolecules. We implement several types of 3D molecular learning methods for each of these tasks and show that they consistently improve performance relative to methods based on one-and two-dimensional representations. The choice of architecture proves to be important for performance, with 3D convolutional networks excelling at tasks involving complex geometries, graph networks performing well on systems requiring detailed positional information, and the more recently developed equivariant networks showing significant promise. Our results indicate that many molecular problems stand to gain from 3D molecular learning, and that there is potential for substantial further improvement on many tasks. To lower the barrier to entry and facilitate further developments in the field, we also provide a comprehensive suite of tools for dataset processing, model training, and evaluation in our open-source atom3d Python package. All datasets are available for download from www.atom3d.ai.", "sections": [{"heading": " ", "text": "1\n: Representation choice for molecules. Adding in 3D information consistently improves performance. The depicted 1D representations are the amino acid sequences and SMILES strings [Weininger, 1988] for proteins and small molecules, respectively. 1 Introduction A molecule's three-dimensional (3D) shape is critical to understanding its physical mechanisms of action, and can be used to answer a number of questions relating to drug discovery, molecular design, and fundamental biology. While we can represent molecules using lower-dimensional representations such as linear sequences (1D) or chemical bond graphs (2D), considering the 3D positions of the component atoms-the atomistic geometry-allows for better modeling of 3D shape (Table 1). While previous benchmarking efforts, such as MoleculeNet [Wu et al., 2018] and TAPE [Rao et al., 2019], have examined diverse molecular tasks, they focus on these lower-dimensional representations. In this work, we demonstrate the benefit yielded by learning on 3D atomistic geometry and promote the development of 3D molecular learning by providing a collection of datasets leveraging this representation.\nFurthermore, the atom is emerging as a \"machine learning datatype\" in its own right, deserving focused study much like the pixels that make up images in computer vision or the characters that make up text in natural language processing. All molecules, including proteins, DNA, RNA, and drugs, can be represented as atoms in 3D space. These atoms can only belong to a fixed class of element types (carbon, nitrogen, oxygen, etc.), and all molecules are governed by the same underlying laws of physics that impose rotational, translational, and permutational symmetries. These systems also contain higher-level patterns that are poorly characterized, creating a ripe opportunity for learning them from data: though certain basic components are well understood (e.g. amino acids, nucleotides, functional groups), many others can not easily be defined. These patterns are in turn composed in a hierarchy that itself is only partially elucidated.\nWhile deep learning methods such as graph neural networks (GNNs) and convolutional neural networks (CNNs) seem well suited to atomistic geometry, to date there has been no systematic evaluation of such methods on molecular tasks. Additionally, despite the growing number of 3D structures available in databases such as the Protein Data Bank (PDB) [Berman et al., 2000], they require significant processing before they are useful for machine learning tasks. Inspired by the success of accessible databases such as ImageNet [Deng et al., 2009] and SQuAD [Rajpurkar et al., 2016] in sparking progress in their respective fields, we create and curate benchmark datasets for atomistic tasks, process them into a simple and standardized format, systematically benchmark 3D molecular learning methods, and present a set of best practices for other machine learning researchers interested in entering the field of 3D molecular learning (see Section C). We reveal a number of insights related to 3D molecular learning, including the relative strengths and weaknesses of different methods and the identification of several tasks that provide great opportunities for 3D molecular learning. These are all integrated into the atom3d Python package to lower the barrier to entry and facilitate reproducible research in 3D molecular learning for machine learning practitioners and structural biologists alike.", "publication_ref": ["b74", "b75", "b56", "b10", "b17", "b53"], "figure_ref": [], "table_ref": []}, {"heading": "Related Work", "text": "While three dimensional molecular data have long been pursued as an attractive source of information in molecular learning and chemoinformatics [Swamidass et al., 2005, Azencott et al., 2007, their utility has become increasingly clear in the last couple years. Powered by increases in data availability and methodological advances, 3D molecular learning methods have demonstrated significant impact on tasks such as protein structure prediction [Senior et al., 2020, Jumper et al., 2021, Baek et al., 2021, equilibrium state sampling [No\u00e9 et al., 2019], and RNA structure prediction [Townshend et al., 2021]. At the same time, broader assessments of tasks involving molecular data have focused on either 1D or 2D representations [Wu et al., 2018, Rao et al., 2019. Through ATOM3D, we aim to provide a first benchmark for learning on 3D molecular data. There are a few major classes of algorithms that exist for data in this form.\nGraph neural networks (GNNs) have grown to be a major area of study, providing a natural way of learning from data with complex spatial structure. Many GNN implementations have been motivated by applications to atomic systems, including molecular fingerprinting [Duvenaud et al., 2015], property prediction [Sch\u00fctt et al., 2017, Gilmer et al., 2017, protein interface prediction [Fout et al., 2017], and protein design [Ingraham et al., 2019]. Instead of encoding points in Euclidean space, GNNs encode their pairwise connectivity, capturing a structured representation of atomistic data. We note that some developed GNNs operate only on the chemical bond graph (i.e., 2D GNNs), with their edges representing covalent bonds, whereas others (including the ones we develop) operate on the 3D atomistic geometry (3D GNNs), with their edges representing distances between nearby pairs of atoms.\nThree-dimensional CNNs (3DCNNs) have also become popular as a way to capture these complex 3D geometries. They have been applied to a number of biomolecular applications such as protein model quality assessment [Pag\u00e8s et al., 2019, Derevyanko et al., 2018, protein sequence design [Anand et al., 2020], protein interface prediction [Townshend et al., 2019], and structure-based drug discovery [Wallach et al., 2015, Torng and Altman, 2017, Ragoza et al., 2017, Jim\u00e9nez et al., 2018. These 3DCNNs can encode translational and permutational symmetries, but incur significant computational expense and cannot capture rotational symmetries without data augmentation.\nIn an attempt to address many of the problems of representing atomistic geometries, equivariant neural networks (ENNs) have emerged as a new class of methods for learning from molecular systems. These networks are built such that geometric transformations of their inputs lead to well-defined transformations of their outputs. This setup leads to the neurons of the network learning rules that resemble physical interactions. Tensor field networks [Thomas et al., 2018] and Cormorant [Kondor, 2018, Anderson et al., 2019 have applied these principles to atomic systems and begun to demonstrate promise on larger systems such as proteins and RNA [Eismann et al., 2020, Weiler et al., 2018, Townshend et al., 2021.", "publication_ref": ["b64", "b6", "b62", "b32", "b49", "b68", "b75", "b56", "b19", "b61", "b26", "b22", "b28", "b51", "b18", "b2", "b67", "b66", "b52", "b30", "b65", "b36", "b3", "b20", "b73", "b68"], "figure_ref": [], "table_ref": []}, {"heading": "Datasets for 3D Molecular Learning", "text": "We select 3D molecular learning tasks from structural biophysics and medicinal chemistry that span a variety of molecule types. Several of these datasets are novel, while others are extracted from existing sources (Table 2). We note that these datasets are intended for benchmarking machine learning representations, and do not always correspond to problem settings that would be seen in real-world scenarios. Below, we give a short description of each dataset's impact and source, as well as the metrics used to evaluate them and the splits. The splits were selected to minimize data leakage concerns and ensure generalizability and reproducibility. These datasets are all provided in a standardized format that requires no specialized libraries. Alongside these datasets, we present corresponding best practices (Appendix C) and further dataset-specific details (Appendix D). Taken together, we hope these efforts will lower the barrier to entry for machine learning researchers interested in developing methods for 3D molecular learning and encourage rapid progress in the field.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_2"]}, {"heading": "Small Molecule Properties (SMP)", "text": "Impact -Predicting physico-chemical properties of small molecules is a common task in medicinal chemistry and materials design. Quantum-chemical calculations can determine certain physicochemical properties but are computationally expensive.  [Ruddigkeit et al., 2012] Protein Interface Prediction (PIP) Amino Acid Interaction DIPS [Townshend et al., 2019] DB5 [Vreven et al., 2015] Residue Identity (RES)", "publication_ref": ["b57", "b67"], "figure_ref": [], "table_ref": []}, {"heading": "Amino Acid Identity", "text": "New, created from PDB [Berman et al., 2000] Mutation Stability Prediction (MSP)", "publication_ref": ["b10"], "figure_ref": [], "table_ref": []}, {"heading": "Effect of Mutation", "text": "New, created from SKEMPI [Jankauskait\u0117 et al., 2019] Ligand Binding Affinity (LBA)", "publication_ref": ["b29"], "figure_ref": [], "table_ref": []}, {"heading": "Binding Strength", "text": "PDBBind [Wang et al., 2004] Ligand Efficacy Prediction (LEP)", "publication_ref": ["b71"], "figure_ref": [], "table_ref": []}, {"heading": "Ligand Efficacy", "text": "New, created from PDB [Berman et al., 2000] Protein Structure Ranking (PSR) Ranking CASP-QA [Kryshtafovych et al., 2019] RNA Structure Ranking (RSR) Ranking FARFAR2-Puzzles [Watkins et al., 2020] Source -The QM9 dataset [Ruddigkeit et al., 2012, Ramakrishnan et al., 2014b contains the results of quantum-chemical calculations for 134,000 stable small organic molecules, each made up C, O, N, F, and H and including no more than nine non-hydrogen atoms. For each molecule, the dataset contains the calculated geometry of the ground-state conformation as well as calculated energetic, electronic, and thermodynamic properties. Targets -We predict the molecular properties from the ground-state structure. Split -We split molecules randomly.", "publication_ref": ["b10", "b40", "b72", "b57", "b55"], "figure_ref": [], "table_ref": []}, {"heading": "Protein Interface Prediction (PIP)", "text": "Impact -Proteins interact with each other in many scenarios-for example, antibody proteins recognize diseases by binding to antigens. A critical problem in understanding these interactions is to identify which amino acids of two given proteins will interact upon binding. Source -For training, we use the Database of Interacting Protein Structures (DIPS), a comprehensive dataset of protein complexes mined from the PDB [Townshend et al., 2019]. We predict on the Docking Benchmark 5 [Vreven et al., 2015], a smaller gold standard dataset. Targets -We predict whether two amino acids will contact when their respective proteins bind. Split -We split protein complexes such that no protein in the training dataset has more than 30% sequence identity with any protein in the DIPS test set or the DB5 dataset.", "publication_ref": ["b67"], "figure_ref": [], "table_ref": []}, {"heading": "Residue Identity (RES)", "text": "Impact -Understanding the structural role of individual amino acids is important for engineering new proteins. We can understand this role by predicting the propensity for different amino acids at a given protein site based on the surrounding structural environment [Torng and Altman, 2017]. Source -We generate a novel dataset consisting of local atomic environments centered around individual residues extracted from non-redundant structures in the PDB. Targets -We formulate this as a classification task where we predict the identity of the amino acid in the center of the environment based on all other atoms. Split -We split environments by protein topology class according to the CATH 4.2 [Dawson et al., 2017], such that all environments from proteins in the same class are in the same split dataset.", "publication_ref": ["b66", "b16"], "figure_ref": [], "table_ref": []}, {"heading": "Mutation Stability Prediction (MSP)", "text": "Impact -Identifying mutations that stabilize a protein's interactions is important to the design of new proteins. Experimental techniques for probing such mutations are labor-intensive [Antikainen andMartin, 2005, Lef\u00e8vre et al., 1997], motivating the development of efficient computational methods. Source -We derive a novel dataset by collecting single-point mutations from the SKEMPI database [Jankauskait\u0117 et al., 2019] and model each mutation into the structure to produce a mutated structure. Targets -We formulate this as a binary classification task where we predict whether the stability of the complex increases as a result of the mutation. Split -We split protein complexes such that no protein in the test dataset has more than 30% sequence identity with any protein in the training dataset.", "publication_ref": ["b5", "b29"], "figure_ref": [], "table_ref": []}, {"heading": "Ligand Binding Affinity (LBA)", "text": "Impact -Predicting the strength (affinity) of a candidate drug molecule's interaction with a target protein is a challenging but crucial task for drug discovery applications. Source -We use the PDBBind database [Wang et al., 2004, Liu et al., 2015, a curated database containing protein-ligand complexes from the PDB and their corresponding binding strengths (affinities). Targets -We predict pK = \u2212 log 10 (K), where K is the binding affinity in Molar units. Split -We split protein-ligand complexes such that no protein in the test dataset has more than 30% sequence identity with any protein in the training dataset.", "publication_ref": ["b71", "b46"], "figure_ref": [], "table_ref": []}, {"heading": "Ligand Efficacy Prediction (LEP)", "text": "Impact -Many proteins switch on or off their function by changing shape. Predicting which shape a drug will favor is thus an important task in drug design. Source -We develop a novel dataset by curating proteins from several families with both \"active\" and \"inactive\" state structures, and model in 527 small molecules with known activating or inactivating function using the program Glide [Friesner et al., 2004]. Targets -We formulate this as a binary classification task where we predict whether a molecule bound to the structures will be an activator of the protein's function or not. Split -We split complex pairs by protein target.", "publication_ref": ["b23"], "figure_ref": [], "table_ref": []}, {"heading": "Protein Structure Ranking (PSR)", "text": "Impact -Proteins are one of the primary workhorses of the cell, and knowing their structure is often critical to understanding (and engineering) their function. Source -We use the structural models submitted to the Critical Assessment of Structure Prediction (CASP) [Kryshtafovych et al., 2019], a blind protein structure prediction competition, over the last 18 years. Targets -We formulate this as a regression task, where we predict the global distance test (GDT_TS) of each structural model from the experimentally determined structure. Split -We split structures temporally by competition year.", "publication_ref": ["b40"], "figure_ref": [], "table_ref": []}, {"heading": "RNA Structure Ranking (RSR)", "text": "Impact -Similar to proteins, RNA plays major functional roles (e.g., gene regulation) and can adopt well-defined 3D shapes. Yet the problem is data-poor, with only a few hundred known structures. Source -We use the FARFAR2-Puzzles dataset, which consists of structural models generated by FARFAR2 [Watkins et al., 2020] for 20 RNAs from RNA Puzzles, a blind structure prediction competition for RNA [Cruz et al., 2012]. Targets -We predict the root-mean-squared deviation (RMSD) of each structural model from the experimentally determined structure. Split -We split structures temporally by competition year.", "publication_ref": ["b72", "b15"], "figure_ref": [], "table_ref": []}, {"heading": "Benchmarking Setup", "text": "To assess the benefits of 3D molecular learning, we use a combination of existing and novel 3D molecular learning methods, and implement a number of robust baselines. Our 3D molecular learning methods belong to one of each of the major classes of deep learning algorithms that have been applied to atomistic systems: graph networks, three-dimensional convolutional networks, and equivariant networks. Here we describe the main principles of the core networks used in these models. See Appendix E for task-specific details and hyperparameters.\nFor GNNs, we represent molecular systems as graphs in which each node is an atom. Edges are defined between all atoms separated by less than 4.5 \u00c5, and weighted by the distance between the atoms using an edge weight defined by w i,j = 1 di,j + , where = 10 \u22125 is a small factor added for numerical stability. Node features are one-hot-encoded by atom type. Our core model uses five layers of graph convolutions as defined by Kipf and Welling [2016], each followed by batch normalization and ReLU activation, and finally two fully-connected layers with dropout. For tasks requiring a single output for the entire molecular system, we use global pooling to aggregate over nodes. For tasks requiring predictions for single atoms or amino acids, we extract the relevant node embeddings from each graph after all convolutional layers (see Appendix E).\nFor 3DCNNs, we represent our data as a cube of fixed size (different per task due to the different molecular sizes) in 3D space that is discretized into voxels with resolution of 1 \u00c5 to form a grid (for PSR and RSR, we decrease the grid resolution to 1.3 \u00c5 in order to fit in the GPU memory). Each voxel is associated with a one-hot-encoded vector that denotes the presence or absence of each atom type. Our core model consists of four 3D-convolutional layers, each followed by ReLU activation and max-pooling (for every other convolution layer). Two fully connected layers are applied after the convolutional layers to produce the final prediction.\nFor ENNs, we use SE(3)-equivariant networks that represent each atom of a structure by its coordinates in 3D space and by a one-hot encoding of its atom type. No rotational augmentation is needed due to the rotational symmetry of the network. The core of all architectures in this work is Cormorant, a network of four layers of covariant neurons that use the Clebsch-Gordan transform as nonlinearity, as described and implemented by Anderson et al. [2019].", "publication_ref": ["b3"], "figure_ref": [], "table_ref": []}, {"heading": "Benchmarking Results", "text": "To assess the utility of 3D molecular learning, we evaluate our methods on the ATOM3D datasets and compare performance to state-of-the-art methods using 1D or 2D representations (for a comparison to the overall state-of-the-art, see Table 7). We note that in many cases, 3D molecular learning methods have not been applied to the proposed tasks, and that several of the tasks are novel. In the following sections, we describe the results of our benchmarking and some key insights that can be derived from them. We also aggregate these results along with additional metrics and standard deviations over three replicates in Table 8. For each metric, we bold the best-performing method as well as those within one standard deviation of the best-performing method.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_9", "tab_10"]}, {"heading": "3D representations consistently improve performance", "text": "Our evaluation of 3D methods on the tasks in ATOM3D reveals that incorporating atomistic geometry leads to consistently superior performance compared to 1D and 2D methods. For small molecules,  state-of-the-art methods do not use 1D representations, so we focus instead on comparing to representations at the 2D level, i.e. the chemical bond graph. This is the approach taken by the 2D GNN introduced by [Tsubaki et al., 2019] and the N-gram graph method by , which both obtain similar results (Table 3) on the small-molecule-only dataset SMP. When we add 3D coordinate information as in our ENN implementation, performance improves across all targets in SMP.\nFor tasks involving biopolymers (proteins and RNA), state-of-the-art methods do not use 2D representations, primarily because most of the chemical bond graph can be re-derived from the 1D representation, i.e. the linear sequence that makes up the biopolymer. We thus compare to representations at the 1D level (Table 4). For MSP and RES, both new datasets, we evaluate against the TAPE model [Rao et al., 2019], a transformer architecture that operates on protein sequence and is state-of-the-art amongst 1D methods for many tasks. For PIP, we compare to the sequence-only version of BIPSPI [Sanchez-Garcia et al., 2018], a state-of-the-art boosted decision tree method for protein interaction prediction. We find that 3D methods outperform these 1D methods on all biopolymer-only datasets (PIP, RES, MSP).\nFor tasks involving both biopolymers and small molecules, we compare to DeepDTA [\u00d6zt\u00fcrk et al., 2018]. This network uses a 1D representation via a 1DCNN for both the biopolymer and small molecules. For LBA, we additionally compare to DeepAffinity [Karimi et al., 2019] which uses pairs of ligand SMILES strings and structurally annotated protein sequences. Using a 3D representation for both the ligand and protein leads to improved or comparable performance for the joint protein-small molecule datasets (LBA and LEP, see Table 5).\nThe biopolymer structure ranking tasks (PSR and RSR) are inherently 3D in nature, as they involve evaluating the correctness of different 3D shapes taken on by the same biopolymer. Thus, critically,   [Watkins et al., 2020] a 1D or 2D representation would not be able to differentiate between these different shapes since the linear sequence and chemical bond graph would remain the same. We therefore compare to state-of-the-art 3D methods as shown in Table 6, finding competitive or better results.\nMore generally, we find that learning methods that leverage the 3D geometry of molecules hold state-of-the-art on the majority of tasks on our benchmark (Table 7). These results demonstrate the potential of 3D molecular learning to address a wide range of problems involving molecular structure, and we anticipate that continued development of such models will aid progress in biological and chemical research.", "publication_ref": ["b69", "b56", "b58", "b34", "b72"], "figure_ref": [], "table_ref": ["tab_3", "tab_4", "tab_5", "tab_6", "tab_9"]}, {"heading": "Different tasks benefit from different architectures", "text": "Figure 1: Datasets plotted by their size, as well as the number of atoms in each one of their molecules.\nWhile 3D molecular learning methods outperform their non-3D counterparts and provide a systematic way of representing molecular data, our results also provide evidence that architecture selection plays an important role in performance.\nFor tasks focused on biopolymers and with large amounts of training data (PIP and RES, Figure 1) we observe that 3DCNNs generally outperform standard GNNs. We hypothesize this is due to the ability of 3DCNNs to learn many-body patterns within a single filter, as opposed to GNNs that operate on one-body (node) and two-body (edge) features. Such many-body patterns are especially present in biopolymers, which generally adopt complex 3D geometries. This many-body representation hypothesis implies that 3DCNNs have specific advantages in terms of representational power.\nHowever, as the size of the datasets decrease (Table 9), we see more even performance when comparing 3DCNNs and GNNs. In particular, performance is quite similar on the intermediate-sized PSR and RSR datasets, and GNNs nearly fully supplant 3DCNNs on the small-sized MSP and LEP datasets. On these datasets, ENNs also equal or exceed 3DCNN performance. This is in line with the many-body representation hypothesis, as the increased representational power of 3DCNNs becomes less important in these data-poor regimes.\nA notable exception to this trend is the large SMP dataset, where we see improved performance from GNNs and ENNs. We note, however, that this is the sole dataset involving only small molecules. These molecules generally do not contain as complex of 3D geometries as biopolymers, and therefore do not contain large numbers of many-body patterns. In addition, many of the prediction targets depend instead on the exact positions of each atom relative to its neighbors. While particle-based methods such as GNNs and ENNs can precisely record these distances, volumetric 3DCNNs must instead approximate these positions. While increasing spatial resolution increases precision, it also leads to cubic scaling of complexity that prevents the same level of precision.\nFinally, equivariant networks show significant promise, despite being a recent innovation. One motivation for their use is that they fill a \"happy medium\" where they both represent atom positions precisely and capture the many-body patterns present in complex geometries. On SMP, the only dataset on which we tested ENNs without any limitations, we observed state-of-the-art performance.\nFor other tasks, the performance of the ENN implementation we used limited us to training on a fraction of the data (< 1% for RES) or on a portion of the entire atomic structure (LBA, LEP, MSP), or did not permit us to apply it at all (PIP, PSR, RSR). Faster implementations are now available to allow scaling of ENNs to larger systems [Geiger et al., 2020, Kondor andThiede, 2021].", "publication_ref": ["b37"], "figure_ref": [], "table_ref": ["tab_11"]}, {"heading": "Conclusion", "text": "In this work we present a vision of the atom as a new \"machine learning datatype\" deserving focused study, as 3D molecular learning has the potential to address many unsolved problems in biology and chemistry. In particular, systems of atoms are well-suited to machine learning as they contain several underlying symmetries as well as poorly understood higher-level patterns. With ATOM3D, we take a first step towards this vision by providing a comprehensive suite of benchmark datasets and computational tools for building machine learning models for 3D molecular data.\nWe provide several benchmark datasets and compare the performance of different types of 3D molecular learning models across these tasks. We demonstrate that, for nearly all tasks that can be formulated in lower dimensions, 3D molecular learning yields gains in performance over 1D and 2D methods. We also show that selection of an appropriate architecture is critical for optimal performance on a given task; depending on the structure of the underlying data, a 3DCNN, GNN, or ENN may be most appropriate, especially in light of our many-body representation hypothesis. Equivariant networks in particular are continuing to improve in efficiency and stability, and we expect these to prove effective due to their ability to concisely model physical laws.\nWhile this work demonstrates the potential of 3D structures and provides an initial set of benchmarks, there are some limitations to consider when using these resources. First, the datasets and tasks represented in ATOM3D are inherently biased towards biomolecules with solved structures. Certain classes of molecules (e.g. intrinsically disordered or transmembrane proteins) may therefore be underrepresented or absent, and the performance on these benchmarks will not necessarily generalize to such structures. Second, the benchmark models we report here are designed to be competitive but simple baselines. A bespoke architecture designed specifically for a certain task or molecule class and with comprehensive hyperparameter tuning is expected to outperform many of these baselines, and we encourage the exploration of novel and innovative approaches even within model classes that appear to underperform in these benchmarks (e.g. GNNs for the PIP task).\nThird, several of the benchmark tasks are formulated differently from those that biologists, chemists, and drug designers typically wish to solve. For example, when predicting the binding affinity of a ligand, one would rarely have access to a 3D structure of the ligand bound to the target (as in the LBA benchmark), because determining this structure experimentally would typically be far more expensive and time-consuming than measuring the ligand binding affinity. Likewise, when using machine learning methods to predict small-molecule properties more efficiently than through quantum chemical calculations (as in the SMP benchmark), one would not typically have access to the ground-state structure, because determining that structure requires equally expensive quantum chemical calculations. Although formulated in a somewhat artificial manner for convenience, such benchmarks have proven useful in evaluating general machine learning representations and methods.\nFinally, in addition to the datasets described here, there are many other open areas in biomedical research and molecular science that are ripe for 3D molecular learning, especially as structural data becomes readily available. Such tasks include virtual screening and pose prediction of small molecule drug candidates, as well as the incorporation of conformational ensembles instead of static structures in order to represent more faithfully the entire set of structures a molecule could adopt. Building on our easily extensible framework, we anticipate the addition of new datasets and tasks from across the research community.\nThrough this work, we hope to lower the entry barrier for machine learning practitioners, encourage the development of algorithms focused on 3D atomistic data, and promote an emerging paradigm within the fields of structural biology and medicinal chemistry. ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A Resource Availability and Licensing", "text": "All datasets are available for download from https://www.atom3d.ai. The corresponding code for dataset processing and model training is maintained at https://github.com/drorlab/atom3d, along with instructions for installing our Python package. Further details can be found in the documentation at atom3d.readthedocs.io/en/latest. All datasets are hosted on Zenodo under individual DOIs, and are licensed under Creative Commons (CC) licenses. Full licenses, DOIs, and other details can be found on our website and Github. The authors bear all responsibility in case of violation of rights, and confirm the CC licenses for the included datasets.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B Broader Impact", "text": "The methods and datasets presented here are intended to promote machine learning research that uses molecular structure. We expect that such research can be used in the development of new medicines and materials, as well as lead to a better understanding of human health. At the same time, the systems we propose are inherently complex, and thus can result in a greater degree of difficulty in interpreting their results, as well as preventing and assessing errors. These errors in turn can have severe consequences in both the development of new medicines, as well as in the treatment of patients using advances derived from this work. Careful evaluation of such systems results, as well as further research in increasing our ability to interpret their outputs, can help mitigate these concerns. Additionally, the benchmarks we use focus on molecules that have known structures. This is a biased set of all molecules, specifically in that they are molecules other researchers have chosen to focus on. Thus, we might expect trained methods to reflect these biases, and therefore have better performance in cases that are already being studied by the broader research community. This could lead to neglecting systems that are not as prioritized.\nC Working with 3D Molecular Data Using ATOM3D\nIn order to facilitate the entry of new practitioners to the field of 3D molecular learning, we provide some high-level guidelines for working with the datasets we provide and for curating new ones. We provide computational tools required for these tasks in the atom3d package, and will be continuing to develop and support its functionality moving forward.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C.1 Assembling New Datasets", "text": "Data sources and repositories. The success of deep learning methods strongly depends on the availability of sufficient training data. Unless they have the capabilities to produce the necessary data, most scientists will rely on use public databases. The go-to repository for protein structures is the Protein Data Bank (PDB). 3 RNA structures can be found at the RNA 3D hub of Bowling Green State University. 4 An exhaustive repository for small molecules is ChEMBL, 5 though the 3D structures of small molecules are mostly not directly deposited. They can be generated by expensive quantum-chemical methods or in good approximation by cheminformatics tools such as RDKit. Many more specific databases are out there and worth being explored. atom3d provides methods to mine and convert data from many common formats in the field (e.g. PDB, SDF, XYZ) into our standardized dataset format.\nScope and limitations of the data. Even the most extensive databases cannot capture the large diversity of biological macromolecules or the space of potential drug molecules. It is therefore necessary to think about the scientific problem at hand and whether the available data adequately represents the range of structures that are responsible for the studied effects. An important general limitation of structural data is that molecules change conformation fluidly in real life due to thermal fluctuations and other effects. Additionally, interactions with other molecules, disordered regions, or environmental factors like pH can result in significant differences from their experimentally determined forms.\nIncomplete or corrupted data. Structural data is rarely perfect. Experimental uncertainties are mostly caused by limited resolution of the involved techniques such as X-ray crystallography or electron cryo-microscopy. Computationally generated structures are also prone to flaws in the underlying modeling programs (e.g., molecular force fields).\nThese limitations can lead to problems such as unrealistic conformations, missing or duplicate atoms, non-resolved amino acid side chains, and more. One has to decide whether to keep those structures or to sanitize them using computational tools. Additionally, hydrogen atoms are often not included in the data and, if needed for the task, have to be added when assembling the dataset. The most important guideline here is to be consistent and clear in the way these issues are treated. Sometimes it can be necessary to assemble two different datasets with different treatments of missing data. By providing a standardized format and functions for processing and filtering datasets through atom3d, we hope to simplify this process.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C.2 Developing and Benchmarking New Algorithms", "text": "Reading and preprocessing. Algorithms represent data in various ways and a given dataset is not always compatible with the representation needed for the algorithm. For example, certain structures, residues, or atoms may need to be filtered out. Ideally, these steps are considered as dataset preparation and are separated from the algorithm itself, i.e. not hard-coded into the dataloader. This has two main advantages: (1) it saves time upon multiple reruns of the algorithm as structural data can be large and expensive to process, and (2) saving the preprocessed input dataset separately increases reproducibility, because small differences in preprocessing are often not recorded. We provide our benchmarking datasets in a format that is easy to read for most Python-based algorithms, and a simple interface for applying arbitrary transforms to convert between data formats (e.g. graph representations or voxelized grids).\nComparing algorithms. Predictions can be tested with various metrics. Depending on the prediction problem, some of the metrics grasp the scientific aims of the training better than others. It is usually recommended to stick to the metrics that are common in the field and are given in the benchmarks. As science develops, new metrics for a specific problem might come up. These should be well justified and the old metrics should still be reported alongside them to allow for a comparison. Ideally, the new metrics are calculated for older models, too. To facilitate this in advance, when benchmarking an algorithm, specific predictions should be stored and not only metrics. In atom3d, we provide standardized evaluation classes to calculate the appropriate metrics from the outputs of a given algorithm.\nInterpretation of results. When judging the performance of an algorithm, one should take into account the experimental uncertainties both in the structures but also in the label data. While small molecules can be investigated in much detail, it will rarely be possible to get near perfect performance for tasks involving complex biological macromolecules. Over time, even held-out test sets become part of the selection process for new methods as only those methods that perform better on the test set will prevail. A measured improvement can thus be caused by minor specifics of the test set. As the field matures and performance becomes saturated, the benchmark sets will still be valid as sanity checks for new methods, but harder tasks will be the ones driving new development. We anticipate that new tasks and datasets will be added to ATOM3D as the field evolves.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "D Dataset Preparation", "text": "We present a set of methods to mine task-specific atomic datasets from several large databases (e.g. PDB) as well as to filter them, split them, and convert them to a format suitable for standard machine learning libraries (esp. PyTorch and TensorFlow). We store these datasets in LMDB format, where each atom is stored as a row in a standardized data frame. This data format accurately captures the natural hierarchy of atom subgroups in biomolecules, especially proteins, and enables data loading and processing to be consistent across datasets, tasks, and computational environments. The LMDB format also allows for labels and additional metadata is stored along with the atoms dataframe for each datapoint.\nTo capture hierarchical information in a way that is task-specific but standardized, we define an \"ensemble\" to be the highest-level of structure for each example, e.g. the PDB entry for the protein.\nWithin each ensemble, we define \"subunits\", which represent the specific units of structure used for that task. For example, for the paired tasks (PIP, LEP, MSP), there is one subunit corresponding to each structure in the pair; for RES, there is one subunit for each residue microenvironment, and for structure ranking (PSR, RSR), there is one subunit for each candidate 3D structure. In this way, it is simple to iterate over each dataset and extract each atomistic structure, which can then be augmented and processed into any desired format (e.g. voxelized for the 3DCNN, converted to graphs for the GNN).\nIn the following sections, we describe the specific steps used to mine and process each dataset.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "D.1 Small Molecule Properties (SMP)", "text": "The QM9 dataset is processed from the files provided on Figshare [Ramakrishnan et al., 2014a]. The properties included in QM9 are the following:\n\u2022 \u00b5 -Dipole moment (unit: D)\n\u2022 \u03b1 -Isotropic polarizability (unit: bohr 3 )\n\u2022 HOMO -Highest occupied molecular orbital energy (unit: Ha, reported in eV)\n\u2022 LUMO -Lowest unoccupied molecular orbital energy (unit: Ha, reported in eV)\n\u2022 gap -Gap between HOMO and LUMO (unit: Ha, reported in eV)\n\u2022 R 2 -Electronic spatial extent (unit: bohr 2 )\n\u2022 ZPVE -Zero point vibrational energy (unit: Ha, reported in meV)\n\u2022 U 0 -Internal energy at 0 K (unit: Ha) We report metrics for these quantities in the benchmark.\nAs recommended by the authors of the original dataset, we exclude 3,054 molecules that do not pass a geometrical consistency test [Ramakrishnan et al., 2014b]. Additionally, we excluded all 1,398 molecules that RDKit is unable to process -as in former GNN work [Fey and Lenssen, 2019]. In this way, we ensure that all models in this work can be trained on the same data. Following previous work [Wu et al., 2018, Gilmer et al., 2017, Sch\u00fctt et al., 2017, Anderson et al., 2019, we split the remaining dataset randomly in training, validation, and test set -containing 103547, 12943, and 12943 molecules, respectively.", "publication_ref": ["b54", "b55", "b21", "b75", "b26", "b61", "b3"], "figure_ref": [], "table_ref": []}, {"heading": "D.2 Protein Interface Prediction (PIP)", "text": "For our test set, we download the cleaned PDB files from the DB5 dataset as provided in [Townshend et al., 2019], and convert to our standardized format. Each complex is an ensemble, with the bound/unbound ligand/receptor structures forming 4 distinct subunits of said ensemble. We use the bound forms of each complex to define neighboring amino acids (those with any heavy atoms within 6 \u00c5 of one another), and then map those onto the corresponding amino acids in the unbound forms of the complex (removing those that do not map). These neighbors are then included as the positive examples, with all other pairs being defined as negatives. At prediction time, we attempt to re-predict which possible pairings are positive or negative, downsampling negatives to achieve a 1:1 positive to negative split. We use the unbound subunits as our pair of input structures for testing. We use AUROC of these predictions as our metric to evaluate performance.\nFor our training set, we reproduce the Database of Interacting Protein Structures (DIPS) [Townshend et al., 2019]. Specifically, we take the snapshot of all structures in the PDB from November 20, 2015.\nWe apply a number of filtering operations, removing structures with no protein present, structures with less than 50 amino acids, structures with worse than 3.5 \u00c5 resolution, and structures not solved by X-ray crystallography or Cryo-EM. We then split the dataset into all pairs of interacting chains. These pairs form our ensembles, with each of the two chains being one subunit. We then remove pairs with less than 500 \u00c5 2 buried surface area as measured by the FreeSASA Python library [Mitternacht, 2016] (using total area computed the naccess classifier, including hydrogens and skipping unknown residues). Furthermore, to ensure there is no train/test contamination, we prune this set against the DB5 set defined above, removing any pairs that have a chain with more than 30% sequence identity, using the software BLASTP [Altschul et al., 1990]). We also prune the set based on structural similarity, removing any pairs in DIPS that map to corresponding SCOP [Andreeva et al., 2014] pairs of superfamilies that are also present across a pair in DB5 (i.e., we remove a DIPS pair if the first subunit in that pair has a chain with a SCOP superfamily that is present in an unbound subunit of a DB5 pair, and the second subunit in that DIPS pair also has a SCOP superfamily that is present in the other unbound subunit of that same DB5 pair). Once this pruning is done, we split the DIPS set into a training, validation, and (internal) testing set based on PDB sequence clustering at a 30% identity level, to ensure little contamination between them. We perform a 80%, 10%, 10% split for training, validation, and testing, respectively. Note this internal testing set is not used for performance reporting.", "publication_ref": ["b67", "b67", "b48", "b1", "b4"], "figure_ref": [], "table_ref": []}, {"heading": "D.3 Residue Identity (RES)", "text": "Environments are extracted from a non-redundant subset of high-resolution structures from the PDB. Specifically, we use only X-ray structures with resolution <3.0 \u00c5, and enforce a 60% sequence identity threshold. We then split the dataset by structure based on domain-level CATH 4.2 topology classes [Dawson et al., 2017], as described in [Anand et al., 2020]. This resulted in a total of 21147, 964, and 3319 PDB structures for the train, validation, and test sets, respectively. Rather than train on every residue for each of these structures, we balance the classes in the train set by downsampling to the frequency of the least-common amino acid (cysteine). The original class balance is preserved in the test set. In total, the train, validation, and test sets comprised 3733710, 188530, and 1261342 environments, respectively. We ignore all non-standard residues. We represent the physico-chemical environment around each residue using all C, O, N, S, and P atoms in the protein and any co-crystallized ligands or ions. All non-backbone atoms of the target residue are removed, and each environment is centered around a \"virtual\" C\u03b2 position of the target residue defined using the average C\u03b2 position over the training set.", "publication_ref": ["b16", "b2"], "figure_ref": [], "table_ref": []}, {"heading": "D.4 Mutation Stability Prediction (MSP)", "text": "Mutation data are extracted from the SKEMPI 2.0 database [Jankauskait\u0117 et al., 2019]. Non-point mutations or mutants that cause non-binding of the complex are screened out. Additionally, mutations involving a disulfide bond and mutants from the PDBs 1KBH or 1JCK are ignored due to processing difficulties. A label of 1 is assigned to a mutant if the K d of the mutant protein is less than that of the wild-type protein, indicating better binding, and 0 otherwise. Atoms from the twenty canonical amino acids were extracted from the PDBs provided in SKEMPI using PyMOL [Schr\u00f6dinger, LLC, 2015], and in silico mutagenesis is accomplished using PyRosetta [Chaudhury et al., 2010], where dihedrals within 10 \u00c5 of the mutated residue are repacked. This protocol produces 893 positive examples and 3255 negative examples. For ENN training, we use structures that are reduced to a size that is tractable for the implementation we used. To this end, we only selected the regions within a radius of 6 \u00c5 around the C\u03b1-atom of the mutated residue. For 3DCNNs, we analogously used a radius of 25 \u00c5. GNNs are trained on complete structures. This dataset is split by sequence identity at 30%.", "publication_ref": ["b29", "b60", "b12"], "figure_ref": [], "table_ref": []}, {"heading": "D.5 Ligand Binding Affinity (LBA)", "text": "PDBBind contains X-ray structures of proteins bound to small molecule and peptide ligands. We use the \"refined set\" (v.2019) consisting of 4,852 complexes filtered for various quality metrics, including resolution \u2264 2.5 \u00c5, R-factor \u2264 0.25, lack of steric clashes or covalent bonding, and more [Li et al., 2014]. We further exclude complexes with invalid ligand bonding information. The binding affinity provided in PDBBind is experimentally determined and expressed in terms of inhibition constant (K i ) or dissociation constant (K d ), both in Molar units. As in previous works [Ballester and Mitchell, 2010, Zilian and Sotriffer, 2013, Ragoza et al., 2017, Jim\u00e9nez et al., 2018, we do not make the distinction between K i and K d , and instead predict the negative log-transformed binding affinity, or pK. The majority of prior scoring functions have used the \"core set\" provided by the Critical Assessment of Scoring Functions (CASF) [Su et al., 2019] as a test set for evaluating prediction performance. However, by construction every protein in this test set is at least 90% identical to several proteins in the training set. Thus, performance on this test set does not accurately represent the generalizability of a scoring function, and has been shown to overestimate the performance of machine learning models in particular [Kramer and Gedeck, 2010, Gabel et al., 2014, Li and Yang, 2017. Therefore, to prevent overfitting to specific protein families, we create a new train/validation/test split based on a 30% sequence identity threshold to limit homologous proteins appearing in both train and test sets. Specifically, we use a cluster-based approach to ensure that no protein in the training set has > 30% sequence identity to any protein in the validation or test sets, as calculated by BLASTP. To prevent overrepresentation of any single protein family (i.e. sequence identity cluster), we additionally enforce that no single cluster represents more than 20% of the overall split. Splitting using this procedure resulted in training, validation, and test sets of size 3507, 466, and 490, respectively.\nFor comparison, we provide an additional, less restrictive, split based on a 60% sequence identity threshold (results in Table 8). This leads to training, validation, and test sets of size 3678, 460, and 460, respectively.\nFor the ENN, we use a reduced dataset without hydrogens and only the most abundant heavy elements in the full dataset (C, N, O, S, Zn, Cl, F, P, Mg). From the binding pocket, we only use atoms within a distance of 6 \u00c5 from the ligand and only so many atoms as to not have more than 600 atoms in total (ligand + protein). This limitation of atom numbers is purely technical. The Kronecker products involved in the covariant neurons are memory intensive in the Cormorant implementation we used, and training on larger structures was limited by the memory of the GPUs available to us.", "publication_ref": ["b43", "b9", "b77", "b52", "b30", "b63", "b38", "b24", "b44"], "figure_ref": [], "table_ref": ["tab_10"]}, {"heading": "D.6 Ligand Efficacy Prediction (LEP)", "text": "Each input consists of a ligand bound to both the active and inactive conformation of a specific protein. The goal is to predict the label for this drug/ligand, either an \"activator\" or \"inactivator\" of the protein function. Why include these protein conformations in the input? From a biochemical perspective, if the drug binds much more favorably to the active protein conformation, it will act as an activator of the protein function. The model may then learn this differential binding strength to improve predictions of ligand function.\nPairs of structures for 27 proteins are obtained through manual curation of the Protein Data Bank structures where \"active\" and \"inactive\" conformational states are both available. For example, for ion channels, this means a channel in an open vs. closed state. 527 ligands with known protein binding and labeled function are selected from the IUPHAR database. We label ligands as activators if they are listed as \"agonists\" or \"activators\" and label ligands as inactivators if they are listed as \"inhibitors\" or \"antagonists\". We select up to 15 of both activating and inactivating ligands for each protein.\nWe model the drugs bound to the relevant protein. To prepare protein structures for use in docking, we first prepare structures using the Schr\u00f6dinger suite. All waters are removed, the tautomeric state of the ligand present in the experimentally determined structure is assigned using Epik at pH 7.0 +/-2.0, hydrogen bonds are optimized, and energy minimization is performed with non-hydrogen atoms constrained to an RMSD of less than 0.3 \u00c5 from the initial structure. For ligands to be docked, the tautomeric state is assigned using Epik tool at target pH 7.0. Ligands are docked using default Glide SP. This results in 527 pairs of complexes. These are split into training, validation, and tests sets by protein target to ensure generalizability across proteins.\nFor ENN training, we reduce the structures to a size that is tractable for the Cormorant implementation we used. To this end, we only use the regions within a radius of 5.5 \u00c5 around the ligand. For 3D-CNNs, we use a radius of 25 \u00c5. GNNs were trained on complete structures.\nWe require that efficacy predictions for a given ligand at a given protein not use information about efficacy of other ligands at that protein, to model a case when no such information is available. When efficacy measurements are available for other ligands at the same protein-as is the case for many well-studied drug targets-methods that take advantage of these (e.g., quantitative structure-activity relationship methods) may produce more accurate efficacy predictions.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "D.7 Protein Structure Ranking (PSR)", "text": "The Critical Assessment of Structure Prediction (CASP) [Kryshtafovych et al., 2019] is a longrunning international competition held biennially, of which CASP13 is the most recent, that addresses the protein structure prediction problem by withholding newly solved experimental structures (called targets) and allowing computational groups to make predictions (called decoys), which are then evaluated for their closeness to their targets after submission. Those submissions are then carefully curated and released as decoy sets in two stages (20 decoys per target for Stage 1, 150 decoys per target for Stage 2) for the Model Quality Assessment (MQA), one of the categories in CASP which aims to score a set of decoys of a target based on how closely they are to the target. For the PSR dataset, we compiled those decoys sets released in CASP5-13, then relaxed those structures with the SCWRL4 software [Krivov et al., 2009] to improve side-chain conformations. For all decoys in the dataset, we computed the RMSD, TM-score, GDT_TS, and GDT_HA scores using the TM-score software [Zhang and Skolnick, 2007].\nMirroring the setup of the competition, we split the decoy sets based on target and released year. More specifically, we randomly split the targets in CASP5-10 and randomly sample 50 decoys for each target to generate the training and validation sets (508 targets for training, 56 targets for validation), and use the whole CASP11 Stage 2 as test set (85 targets total, with 150 decoys for each target). We chose CASP11 as test set, as the targets in CASP12-13 are not fully released yet.", "publication_ref": ["b40", "b39", "b76"], "figure_ref": [], "table_ref": []}, {"heading": "D.8 RNA Structure Ranking (RSR)", "text": "The RNA Puzzles competition [Cruz et al., 2012] is a rolling international competition dealing with the RNA structure prediction problem. Similarly to CASP, newly solved experimental structures, referred to as natives, are withheld until computational groups make prediction, referred to as candidates. These candidates are then evaluated by their RMSD from the native. For this task, we use candidate structures created by the state-of-the-art structure generation method, FARFAR2 [Watkins et al., 2020], for each of the 21 first RNA Puzzles. These are made available as part of the FARFAR2 publication. There are an average of 21303 (standard deviation of 13973) candidates generated per puzzles, with a large range of RMSDs. For the RSR dataset we randomly sample 1000 candidates per puzzle. We split temporally, by puzzle, using RNA Puzzles 1-13 for training, 14-17 (excluding 16) for validation, and 18-21 for testing.", "publication_ref": ["b15", "b72"], "figure_ref": [], "table_ref": []}, {"heading": "E Task-Specific Experimental Details", "text": "Below we describe the architectures and hyperparameters used for benchmarking. In general, these are intended to be robust but simple benchmarks for each task, so we did not undertake full tuning of every hyperparameter for every task, which would be very expensive. However, we did tune specific crucial hyperparameters such as learning rate, number of epochs, and 3DCNN grid size/resolution using a grid search methodology. Final models and hyperparameter settings were selected using performance on the validation set, with the held-out test sets only used to report final performance.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "E.1 3DCNNs", "text": "Our base 3DCNN architecture consists of four 3D-convolutional layers with increasing filter size (32, 64, 128, and 256) -each followed by ReLU activation, max-pooling (for every other convolution layer), and dropout -and one fully-connected layer of size 512, followed by ReLU activation and dropout. For single model task (PSR, RSR, LBA, SMP), we add an additional fully-connected layer to transform to the required output dimension size. For paired tasks (PIP, LEP, MSP), we adapt this base architecture into a twin network, add an additional fully-connected layer followed by ReLU activation and dropout to combine the output of each member of the pair, and finally add a final fully-connected layer to transform to the required output dimension size, as in [Townshend et al., 2019].\nFor input to the 3DCNNs, we represent our data as cube in 3D space of certain radius (40 \u00c5 for PSR, RSR; 17 \u00c5 for PIP; 20 \u00c5 for LBA; 7.5 \u00c5 for SMP; 25 \u00c5 for LEP, MSP; 10 \u00c5 for RES) that are discretized into voxels with resolution of 1 \u00c5 to form a grid (for PSR and RSR, we need to decrease the resolution to 1.3 \u00c5 in order to fit them in the GPU memory). For paired tasks (PSR, RSR, and PIP), we form a separate voxel grid for each member of the pair. For most tasks, we use the centroid of each input structure as center of the grid, excluding LBA where we use the centroid of the ligand as center and MSP where we use the mutation point as center. Each grid voxel is associated with a binary feature vector which encodes the presence or absence of each specified atom type in that voxel. For PSR, RSR, PIP, and RES, we encode the presence of heavy atoms C, O, N, and S (P for RSR since S does not exist in RNA structures). For other tasks where hydrogen bonds might play an important role, we encode the hydrogen atom (H) in addition to C, O, N, and few other abundant atoms (F for LBA and SMP; S, Cl, F for LEP; S for MSP). To encode rotational symmetries, we apply a data augmentation strategy in which we apply 20 random rotations to the input grid, as in [Townshend et al., 2019], except for RES, where we instead apply the canonicalization procedure described in [Anand et al., 2020].\nFor binary classification tasks, we use binary cross-entropy weighted by the class distribution (i.e. rarer class is weighted more heavily on mistakes). To address issues with imbalanced datasets, we randomly oversample/undersample the less/more frequent class respectively during training. For regression tasks, we use mean-squared error loss for training. All models were trained with Adam optimizer with default beta parameters and learning rate 0.0005 for SMP; 0.0001 for PSR, RSR, PIP, RES; 0.001 for LBA; and 0.00001 for LEP, MSP. We monitor the loss on the validation set at every epoch. The weights of the best-performing are then used to evaluate on the held-out test set. The models were all trained on 1 Titan X(p) GPU for 4-24 hours depending on the task.", "publication_ref": ["b67", "b67", "b2"], "figure_ref": [], "table_ref": []}, {"heading": "E.2 GNNs", "text": "Our base GNN architecture consists of five layers of graph convolutions as defined by Kipf and Welling [Kipf and Welling, 2016], with increasing hidden dimension (64,128,128,256,256) each followed by batch normalization and ReLU activation. For tasks with paired input structures (PIP, LEP, MSP), we apply this convolutional architecture to each input structure separately in a twin network architecture with tied weights, and then concatenate the outputs before passing through two fully-connected layers of size 256 to transform to an output dimension of one neuron for binary classification. We regularize using dropout with a probability of 0.25 after the first fully-connected layer. Some tasks require classification of an entire structure, and thus are well-suited to graph-level outputs (PSR, RSR, LBA). Here, we apply global mean or addition pooling across all nodes before applying the final two layers. For PIP, RES, and MSP, instead of pooling we instead extract the embedding of the node corresponding to the C\u03b1 atom of the residue in question (interacting residue, deleted residue, and mutated residue, respectively) after the final convolutional layer. For SMP, we use the previously-developed architecture presented in [Gilmer et al., 2017], which is publicly available.\nWe use a very simple featurization scheme for atomic systems. We define edges between all atoms separated by less than 4.5 \u00c5. Edges are weighted by the distance between the atoms, and nodes are featurized by one-hot-encoding all heavy (non-hydrogen) atoms. The only exception is SMP, where we adopt the established featurization scheme used in MoleculeNet [Wu et al., 2018]. For tasks involving protein-ligand binding (LBA and LEP), we distinguish the protein and the ligand by using separate channels in the node features for each. All GNNs were implemented in PyTorch Geometric [Fey and Lenssen, 2019].\nFor binary tasks, we use a binary cross-entropy loss criterion weighted by the class distribution (e.g. a 1:4 positive:negative ratio would result in positive examples being up-weighted four-fold). For regression tasks, we use a mean-squared error criterion. For all models, we train with the Adam optimizer with learning rate 0.0001 (except for PIP, which uses a learning rate of 0.001) and monitor the relevant metrics (see Table 8) on the validation set after every epoch. The weights of the best-performing are then used to evaluate on the held-out test set. Models were all trained using 1 Tesla V100 GPU for 4-48 hours depending on the task.\nCertain tasks involve making a prediction on a specific amino acid (PIP, RES, and MSP; see Table 2), yet GNNs typically rely on summing over all node embeddings to compute a final graph embedding, making it difficult to isolate this amino acid. To remedy this, after our convolutional layers we extract the embedding of only the C\u03b1 atom of the amino acid in question, thereby allowing our GNNs to isolate it.", "publication_ref": ["b35", "b26", "b75", "b21"], "figure_ref": [], "table_ref": ["tab_10", "tab_2"]}, {"heading": "E.3 ENNs", "text": "For the core of all Cormorant architectures in this work, we use a network of four layers of covariant neurons that use the Clebsch-Gordan transform as nonlinearity, with L = 3 as the largest index in the SO(3) representation and 16 channels, followed by a single SO(3)-vector layer with L = 0.\nAn input featurization network encodes the atom types as one-hot vectors. For SMP, input and output are passed through multi-layer perceptrons (MLP) as in [Anderson et al., 2019]. For the input, a weighted adjacency matrix with a learnable cut-off radius is constructed. This mask is passed alongside the input vector through a MLP with a single hidden layer with 256 neurons and ReLU activation. The output network is constructed from a set of scalar invariants that are passed through a network of two MLPs. Each of these MLPs has a single hidden layer of size 256, and the intermediate representation has 96 neurons. For LBA and LEP, input and output layers are a single learnable mixing matrix, as used in the original Cormorant implementation for MD-17 [Anderson et al., 2019]. The twin networks required for LEP and MSP was constructed by training two ENNs that are then connected by concatenating the single-network outputs which are then passed to a MLP analogous to the one described above for SMP. For MSP, the two structures corresponded to the wild-type structure and the mutated one; for LEP to the active and inactive one. We extend the original Cormorant implementation to handle classification problems (binary and multi-class) and the twin network architecture. Our implementation 6 also allows to set a boundary on the Clebsch-Gordan product to eliminate training instabilities from a divergent loss that would otherwise arise occasionally for some of the tasks.\nWe use MSE loss for regression tasks and cross-entropy loss for classification tasks. For all tasks, we used the AMSgrad optimizer with an initial learning rate of 0.001 and a final learning rate of 0.00001, decaying in a cosine function over the training process. We trained SMP and LBA for 150 epochs, LEP and MSP for 50 epochs, and RES for 30 epochs. We monitor the loss for the validation set after every epoch. The weights of the best-performing are then used to evaluate on the held-out test set.\nThe models were all trained on 1 Titan X(p) GPU for 1-5 days depending on the task.", "publication_ref": ["b3", "b3"], "figure_ref": [], "table_ref": []}, {"heading": "F 1D and 2D Baselines", "text": "For each task, we select a baseline that fulfills the following criteria: (1) represents the current state-of-the-art (SOTA) for that task-or as close as possible-using only 1D (sequence only) or 2D (sequence and/or bond connectivity) molecular representations, and (2) either has a publicly available implementation or has reported results for the same task and splitting criteria. For PSR and RSR, which are inherently 3D tasks and have no appropriate 1D or 2D representation, we compare to the state-of-the-art 3D methods instead. Below we describe the choice and implementation of baseline models for each task.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "F.1 SMP", "text": "As a 2D method for predicting molecular properties, we choose molecular GNNs [Tsubaki et al., 2019] which are based on learning representations of subgraphs in molecules. We use an implementation that only uses the SMILES representation of the molecular graph. 7 As an additional 2D baseline, we compare to N-Gram Graph XGB . This method is based on an unsupervised representation called N-gram graph which first embeds the vertices in the molecule graph and then assembles the vertex embeddings in short walks in the graph. This representation is combined with the XGBoost learning method [Chen and Guestrin, 2016]. 8", "publication_ref": ["b69", "b13"], "figure_ref": [], "table_ref": []}, {"heading": "F.2 PIP", "text": "For the PIP task, our non-3D method is the BIPSPI [Sanchez-Garcia et al., 2018] model, a gradientboosted decision tree. We compare to their model that uses only sequence and sequence conservation features and is evaluated on DB5.", "publication_ref": ["b58"], "figure_ref": [], "table_ref": []}, {"heading": "F.3 RES", "text": "As a 1D sequence-based model for predicting residue identity, we choose the transformer architecture TAPE, introduced by [Rao et al., 2019]. We use their reported accuracy on heldout families for language modeling, as that corresponds to a sequence-only version of our RES tasks, with similar stringency in terms of splitting criteria.", "publication_ref": ["b56"], "figure_ref": [], "table_ref": []}, {"heading": "F.4 MSP", "text": "We use the publicly provided implementation of TAPE [Rao et al., 2019] 9 . We modify their sequenceto-sequence head to predict the effect of mutations at specific positions, using the original unmutated protein as the input sequence and writing the output sequence as a one-hot-encoded 20-dimensional vector, indicating if a given mutation would be beneficial or detrimental. Note that the vast majority of positions would be unlabeled and therefore not included in the learning task.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "F.5 LBA", "text": "As a 1D method for predicting ligand binding affinity, we choose DeepDTA [\u00d6zt\u00fcrk et al., 2018] 10 , a 1DCNN based model that takes in pairs of ligand SMILES string and protein sequence as input. We use the same hyperparameters as in the original paper for the baseline.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "F.7 PSR", "text": "We compare our results against the state-of-the-art single-model methods as reported in [Pag\u00e8s et al., 2019]. These include 3DCNN [Hou et al., 2019] and Ornate [Pag\u00e8s et al., 2019], 3DCNN voxel-based methods trained on structural information, and Proq3D [Uziela et al., 2017], a deep-learning based method which employs structural information, Rosetta energy terms [Leaver-Fay et al., 2011], and evolutionary information derived from the amino acid sequence. We exclude ProteinGCN [Sanyal et al., 2020], a recent GNN-based method, from comparison as they do not provide results on CASP11 dataset.", "publication_ref": ["b51", "b27", "b51", "b70", "b41"], "figure_ref": [], "table_ref": []}, {"heading": "F.8 RSR", "text": "For RNA structure ranking, we compare our results against the Rosetta scoring function [Alford et al., 2017]. In past RNA Puzzles competitions, methods using the Rosetta scoring function have been found to most consistently produce the lowest RMSD candidates. This is a physical-and knowledge-based potential specifically tuned for biomolecular structure.\nG State-Of-The-Art Methods\nWhen possible, for tasks in Table 7, we choose 3D methods that fulfill the following criteria: (1) they represent the current state-of-the-art for that task, or as close as possible, and (2) they either have a publicly available implementation or have reported results for the same task and splitting criteria.\nHere our choice of methods is described in more detail if not already discussed in the section above.", "publication_ref": ["b0"], "figure_ref": [], "table_ref": ["tab_9"]}, {"heading": "G.1 SMP", "text": "We compare to the state of the art, i.e., the best achieved prediction on each task, as reported in Anderson et al. [2019]. Many methods have been tested on QM9 and have reached excellent performance which makes them comparably hard to beat for new methods. In general, the best methods for QM9 so far are message passing neural networks Gilmer et al. [2017], continuous-filter convolutional neural networks Sch\u00fctt et al. [2017], and Cormorant Anderson et al. [2019]. Differences in performance between earlier Cormorant studies and this work can be attributed to the different (random) split.", "publication_ref": ["b3", "b26", "b3"], "figure_ref": [], "table_ref": []}, {"heading": "G.2 PIP", "text": "We compare our results against the BIPSPI Sanchez-Garcia et al. [2018] model, a gradient-boosted decision tree. In contrast to the 1D/2D baseline comparison to BIPSPI, in this case we compare against their model that employs both structural-and sequence-based amino acid features.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "G.3 RES", "text": "Since there have been no standardized datasets for this task to date, it is difficult to perform a direct comparison of methods. The closest comparison for a CNN trained on a balanced dataset of residue environments is 0.425, as reported in Torng and Altman [2017]. While higher performance was reported by Anand et al. [2020] (accuracy 0.572), this model was trained on an unbalanced dataset comprising every standard residue environment in all training set PDBs. Similar performance has also been reported with other deep learning architectures Weiler et al. [2018], Boomsma and Frellsen [2017], but these do not describe their training/evaluation data or splitting criteria. In contrast, we restrict our training and evaluation to a balanced subset, downsampled to the frequency of the rarest class, which limits performance slightly. Additionally, to enable fair comparison over three replicates between 3DCNN and GNN, we then trained on only half of these down-sampled environments. The discrepancy in performance we observe on this subset is indicative of the fact that the differences in residue environment are subtle and complex, so simply increasing training data can result in higher performance. This is especially true for common classes such as leucine and glycine, which are over five times as frequent than the least common class, cysteine. Within these common classes, accuracy exceeds 80%, which increases the average accuracy when classes are imbalanced.", "publication_ref": ["b66", "b2", "b73", "b11"], "figure_ref": [], "table_ref": []}, {"heading": "G.4 LEP", "text": "Because this was a novel dataset, we computed initial results a non-deep learning method, Schr\u00f6dinger's Glide, to score each protein-ligand complex. Glide is state-of-the-art for scoring protein-ligand complexes and determining how \"good\" a pose is. This resulted in 2 scores per ligand; the score to the inactive protein structure and the score to the active protein structure. We then performed a binary classification by training an SVM on these two features to predict the ligand activity class. This approach is reasonable from a physical basis: if the ligand binds much better to the active protein structure than the inactive protein structure, then it will be an activator of the protein's function.\nG.5 LBA Many methods have been developed for the prediction of ligand binding affinity using the PDBBind dataset. However, the standard has been to evaluate performance on the so-called \"core set\", as described in Section 3, after training and validating on the remainder of the refined set. The state-ofthe-art reported on this core set has been achieved by the 3DCNN-based KDEEP Jim\u00e9nez et al. [2018], followed closely by the popular random forest-based method RF-score Ballester and Mitchell [2010]. However, because the core set contains only proteins that are also present in the training set, this only measures in-distribution performance, not generalizable scoring ability. Thus, the most comparable baseline for our dataset, which was split at 30% sequence identity, is the performance of the empirical linear regression-based scoring function X-score fitted to complexes with less than 30% identity to the core set, as reported in Li and Yang [2017]. We note that this is not a perfect comparison, since the procedure used in Li and Yang [2017] reduces the size of the training set significantly; however, as an empirical scoring function the performance of X-score is not very sensitive to training set size, compared to RF-score, which was significantly affected.\nH Supplementary Tables   ", "publication_ref": ["b44", "b44"], "figure_ref": [], "table_ref": []}, {"heading": "", "text": "We also compare our results against DeepAffinity [Karimi et al., 2019]  11  . We compare to their unified RNN/RNN-CNN model that takes in pairs of ligand SMILES string and their novel representations of structurally-annotated protein sequences (SPS/Structure Property-annotated Sequence) as input. Per the authors' recommendation, we use the DSSP software [Joosten et al., 2010, Kabsch andSander, 1983] to generate the protein secondary structure and the protein relative solvent accessibility used in the SPS representation directly from the protein 3D structure, rather than the predicted ones by the SSpro/ACCpro software [Magnan and Baldi, 2014, Cheng et al., 2005]  as done in the DeepAffinity paper. We use the same hyperparameters as in the original paper for the baseline, except for the maximum SMILES string and SPS lengths which we increase from 100 and 152 in the paper to 160 and 168, respectively, to accommodate for larger ligands/proteins in the PDBBind dataset. We used the pre-trained seq2seq encoders for proteins and ligands to initialize the joint supervised training of the encoders and CNN, and trained the DeepAffinity models for 1000 epochs. The pre-trained DeepAffinity seq2seq encoders were trained with maximum SMILES string and SPS lengths of 100 and 152, however, there are only 4% of the ligands in the PDBBind dataset with SMILES string length larger than 100, and even much smaller percentage of the proteins (around 0.2%) with SPS length larger than 152, so the input data distribution for PDBBind should still be in the range of that of DeepAffinity.", "publication_ref": ["b34", "b33", "b47"], "figure_ref": [], "table_ref": []}, {"heading": "F.6 LEP", "text": "We train DeepDTA [\u00d6zt\u00fcrk et al., 2018]  10 (with the same hyperparameters as in the original paper) on the LEP dataset as baseline. As the inherent protein sequences and ligand SMILES strings are the same for both the inactive and active structures, the problem is reduced to binary classification task given a pair of protein sequence and the ligand SMILES string, and does not require modifying the DeepDTA architecture to make the twin network as in the GNN, ENN, or 3DCNN case.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "The Rosetta All-Atom Energy Function for Macromolecular Modeling and Design", "journal": "Journal of Chemical Theory and Computation", "year": "2017", "authors": "Rebecca F Alford; Andrew Leaver-Fay; Jeliazko R Jeliazkov; Matthew J O'meara; Frank P Dimaio; Hahnbeom Park; Maxim V Shapovalov; P Douglas Renfrew; K Vikram; Kalli Mulligan; Jason W Kappel; Michael S Labonte; Richard Pacella; Philip Bonneau; Roland L Bradley; Rhiju Dunbrack; David Das; Brian Baker; Tanja Kuhlman; Jeffrey J Kortemme;  Gray"}, {"ref_id": "b1", "title": "Basic local alignment search tool", "journal": "Journal of Molecular Biology", "year": "1990", "authors": "W S F Altschul;  Gish; E W Miller; D J Myers;  Lipman"}, {"ref_id": "b2", "title": "Protein sequence design with a learned potential", "journal": "", "year": "2020-01", "authors": "Namrata Anand; R Raphael; Alexander Eguchi;  Derry; Po-Ssu Russ B Altman;  Huang"}, {"ref_id": "b3", "title": "Cormorant: Covariant Molecular Neural Networks", "journal": "", "year": "2019", "authors": "Brandon Anderson;  Truong-Son; Risi Hy;  Kondor"}, {"ref_id": "b4", "title": "SCOP2 prototype: A new approach to protein structure mining", "journal": "Nucleic Acids Research", "year": "2014", "authors": "Antonina Andreeva; Dave Howorth; Cyrus Chothia; Eugene Kulesha; Alexey G Murzin"}, {"ref_id": "b5", "title": "Altering protein specificity: techniques and applications", "journal": "Bioorganic & medicinal chemistry", "year": "2005", "authors": "M Nina;  Antikainen;  Stephen F Martin"}, {"ref_id": "b6", "title": "One-to four-dimensional kernels for virtual screening and the prediction of physical, chemical, and biological properties", "journal": "Journal of chemical information and modeling", "year": "2007", "authors": "Chlo\u00e9-Agathe Azencott; Alexandre Ksikes; Joshua Swamidass; Jonathan H Chen; Liva Ralaivola; Pierre Baldi"}, {"ref_id": "b7", "title": "", "journal": "", "year": "", "authors": "Minkyung Baek; Frank Dimaio; Ivan Anishchenko; Justas Dauparas; Sergey Ovchinnikov; Jue Gyu Rie Lee; Qian Wang; Lisa N Cong; R Dustin Kinch; Claudia Schaeffer; Hahnbeom Mill\u00e1n; Carson Park; Caleb R Adams; Andy Glassman; Jose H Degiovanni; Andria V Pereira; Alberdina A Rodrigues; Ana C Van Dijk; Diederik J Ebrecht; Theo Opperman; Christoph Sagmeister; Tea Buhlheller; Manoj K Pavkov-Keller; Udit Rathinaswamy; Calvin K Dalwadi; John E Yip"}, {"ref_id": "b8", "title": "Accurate prediction of protein structures and interactions using a three-track neural network", "journal": "Science", "year": "2021", "authors": "K Christopher Burke; Nick V Garcia; Paul D Grishin; Randy J Adams; David Read;  Baker"}, {"ref_id": "b9", "title": "A machine learning approach to predicting protein-ligand binding affinity with applications to molecular docking", "journal": "Bioinformatics", "year": "2010-05", "authors": "J Pedro; John B O Ballester;  Mitchell"}, {"ref_id": "b10", "title": "The protein data bank", "journal": "Nucleic acids research", "year": "2000", "authors": "M Helen; John Berman; Zukang Westbrook; Gary Feng;  Gilliland; N Talapady; Helge Bhat;  Weissig; N Ilya; Philip E Shindyalov;  Bourne"}, {"ref_id": "b11", "title": "Spherical convolutions and their application in molecular modelling", "journal": "Curran Associates, Inc", "year": "2017", "authors": "Wouter Boomsma; Jes Frellsen ; I Guyon; U V Luxburg; H Bengio;  Wallach;  Fergus; R Vishwanathan;  Garnett"}, {"ref_id": "b12", "title": "Pyrosetta: a script-based interface for implementing molecular modeling algorithms using rosetta", "journal": "Bioinformatics", "year": "2010", "authors": "Sidhartha Chaudhury; Sergey Lyskov; Jeffrey J Gray"}, {"ref_id": "b13", "title": "Xgboost: A scalable tree boosting system", "journal": "Association for Computing Machinery", "year": "2016", "authors": "Tianqi Chen; Carlos Guestrin"}, {"ref_id": "b14", "title": "Scratch: a protein structure and structural feature prediction server", "journal": "Nucleic acids research", "year": "2005-08", "authors": "Jianlin Cheng; Arlo Randall; Michael Sweredoski; Pierre Baldi"}, {"ref_id": "b15", "title": "Rnapuzzles: a casp-like evaluation of rna three-dimensional structure prediction", "journal": "Rna", "year": "2012", "authors": "Jos\u00e9 Almeida Cruz; Marc-Fr\u00e9d\u00e9rick Blanchet; Michal Boniecki; M Janusz; Shi-Jie Bujnicki; Song Chen; Rhiju Cao; Feng Das;  Ding; V Nikolay; Samuel Coulbourn Dokholyan;  Flores"}, {"ref_id": "b16", "title": "Cath: an expanded resource to predict protein function through structure and sequence", "journal": "Nucleic acids research", "year": "2017", "authors": "Tony E Natalie L Dawson; Sayoni Lewis; Jonathan G Das; David Lees; Paul Lee; Christine A Ashford; Ian Orengo;  Sillitoe"}, {"ref_id": "b17", "title": "ImageNet: A large-scale hierarchical image database", "journal": "", "year": "2009", "authors": "Jia Deng; Wei Dong; R Socher; Li-Jia Li; Kai Li; Li Fei-Fei"}, {"ref_id": "b18", "title": "Deep convolutional networks for quality assessment of protein folds", "journal": "Bioinformatics", "year": "2018", "authors": "Georgy Derevyanko; Sergei Grudinin; Yoshua Bengio; Guillaume Lamoureux"}, {"ref_id": "b19", "title": "Convolutional networks on graphs for learning molecular fingerprints", "journal": "", "year": "2015", "authors": "Dougal David K Duvenaud; Jorge Maclaurin; Rafael Iparraguirre; Timothy Bombarell; Al\u00e1n Hirzel; Ryan P Aspuru-Guzik;  Adams"}, {"ref_id": "b20", "title": "Hierarchical, rotation-equivariant neural networks to predict the structure of protein complexes. arXiv", "journal": "", "year": "2020", "authors": "Stephan Eismann; J L Raphael; Nathaniel Townshend; Milind Thomas; Bowen Jagota; Ron Jing;  Dror"}, {"ref_id": "b21", "title": "Fast graph representation learning with PyTorch Geometric", "journal": "", "year": "2019", "authors": "Matthias Fey; Jan E Lenssen"}, {"ref_id": "b22", "title": "Protein interface prediction using graph convolutional networks", "journal": "Curran Associates, Inc", "year": "2017", "authors": "Alex Fout; Jonathon Byrd; Basir Shariat; Asa Ben-Hur ; I Guyon; U V Luxburg; H Bengio;  Wallach;  Fergus; R Vishwanathan;  Garnett"}, {"ref_id": "b23", "title": "Glide: a new approach for rapid, accurate docking and scoring. 1. method and assessment of docking accuracy", "journal": "Journal of medicinal chemistry", "year": "2004", "authors": "A Richard; Jay L Friesner;  Banks; B Robert; Thomas A Murphy;  Halgren; J Jasna;  Klicic; T Daniel;  Mainz; P Matthew; Eric H Repasky; Mee Knoll; Jason K Shelley;  Perry"}, {"ref_id": "b24", "title": "Beware of machine learning-based scoring functions-on the danger of developing black boxes", "journal": "J. Chem. Inf. Model", "year": "2014-10", "authors": "Joffrey Gabel; J\u00e9r\u00e9my Desaphy; Didier Rognan"}, {"ref_id": "b25", "title": "Euclidean neural networks: e3nn", "journal": "", "year": "2020", "authors": "Mario Geiger; Tess Smidt; M Alby; Kurt Benjamin; Wouter Miller; Bradley Boomsma; Kostiantyn Dice; Maurice Lapchevskyi; Micha\u0142 Weiler; Simon Tyszkiewicz; Martin Batzner; Jes Uhrin; Nuri Frellsen; Sophia Jung; Josh Sanborn; Michael Rackers;  Bailey"}, {"ref_id": "b26", "title": "Neural message passing for quantum chemistry", "journal": "", "year": "2017", "authors": "Justin Gilmer; Samuel S Schoenholz; Patrick F Riley; Oriol Vinyals; George E Dahl"}, {"ref_id": "b27", "title": "Deep convolutional neural networks for predicting the quality of single protein structural models", "journal": "bioRxiv", "year": "2019", "authors": "Jie Hou; Renzhi Cao; Jianlin Cheng"}, {"ref_id": "b28", "title": "Generative models for Graph-Based protein design", "journal": "", "year": "2019-03", "authors": "John Ingraham; K Vikas; Regina Garg; Tommi Barzilay;  Jaakkola"}, {"ref_id": "b29", "title": "Skempi 2.0: an updated benchmark of changes in protein-protein binding energy, kinetics and thermodynamics upon mutation", "journal": "Bioinformatics", "year": "2019", "authors": "Justina Jankauskait\u0117; Brian Jim\u00e9nez-Garc\u00eda; Justas Dapk\u016bnas; Juan Fern\u00e1ndez-Recio; Iain H Moal"}, {"ref_id": "b30", "title": "KDEEP: Protein-Ligand absolute binding affinity prediction via 3D-Convolutional neural networks", "journal": "J. Chem. Inf. Model", "year": "2018-02", "authors": "Jos\u00e9 Jim\u00e9nez; Miha \u0160kali\u010d; Gerard Mart\u00ednez-Rosell; Gianni De Fabritiis"}, {"ref_id": "b31", "title": "A series of pdb related databases for everyday needs", "journal": "Nucleic acids research", "year": "", "authors": "Robbie Joosten; Tim Beek; Elmar Krieger; Maarten Hekkelman; Rob Hooft; Reinhard Schneider; Chris Sander; Gert Vriend"}, {"ref_id": "b32", "title": "Pushmeet Kohli, and Demis Hassabis. Highly accurate protein structure prediction with AlphaFold", "journal": "Oriol Vinyals, Andrew W. Senior, Koray Kavukcuoglu", "year": "2021", "authors": "John Jumper; Richard Evans; Alexander Pritzel; Tim Green; Michael Figurnov; Olaf Ronneberger; Kathryn Tunyasuvunakool; Russ Bates; Augustin \u017d\u00eddek; Anna Potapenko; Alex Bridgland; Clemens Meyer; A A Simon; Andrew J Kohl; Andrew Ballard; Bernardino Cowie; Stanislav Romera-Paredes; Rishub Nikolov; Jonas Jain; Trevor Adler; Stig Back; David Petersen; Ellen Reiman; Michal Clancy; Martin Zielinski; Michalina Steinegger; Tamas Pacholska; Sebastian Berghammer; David Bodenstein;  Silver"}, {"ref_id": "b33", "title": "Dictionary of protein secondary structure: Pattern recognition of hydrogen-bonded and geometrical features", "journal": "Biopolymers", "year": "1983", "authors": "Wolfgang Kabsch; Christian Sander"}, {"ref_id": "b34", "title": "Deepaffinity: interpretable deep learning of compound-protein affinity through unified recurrent and convolutional neural networks", "journal": "Bioinformatics", "year": "2019", "authors": "Mostafa Karimi; Di Wu; Zhangyang Wang; Yang Shen"}, {"ref_id": "b35", "title": "Semi-supervised classification with graph convolutional networks", "journal": "", "year": "2016", "authors": "N Thomas; Max Kipf;  Welling"}, {"ref_id": "b36", "title": "N-body networks: a covariant hierarchical neural network architecture for learning atomic potentials", "journal": "", "year": "2018", "authors": "Risi Kondor"}, {"ref_id": "b37", "title": "GElib -C++/CUDA library for rotation group operations", "journal": "", "year": "2021", "authors": "Risi Kondor; Erik Henning Thiede"}, {"ref_id": "b38", "title": "Leave-cluster-out cross-validation is appropriate for scoring functions derived from diverse protein data sets", "journal": "J. Chem. Inf. Model", "year": "2010-11", "authors": "Christian Kramer; Peter Gedeck"}, {"ref_id": "b39", "title": "Improved prediction of protein side-chain conformations with scwrl4. Proteins", "journal": "", "year": "2009", "authors": "G G Krivov; M V Shapovalov; R L Dunbrack"}, {"ref_id": "b40", "title": "Critical assessment of methods of protein structure prediction (casp)-round xiii", "journal": "Proteins: Structure, Function, and Bioinformatics", "year": "2019", "authors": "Andriy Kryshtafovych; Torsten Schwede; Maya Topf; Krzysztof Fidelis; John Moult"}, {"ref_id": "b41", "title": "Rosetta3: an object-oriented software suite for the simulation and design of macromolecules", "journal": "Methods in enzymology", "year": "2011-01", "authors": "Andrew Leaver-Fay; Michael Tyka; Steven Lewis; Oliver Lange; James Thompson; Ron Jacak; Kristian Kaufman; P Renfrew; Colin Smith; Will Sheffler; Ian Davis; Seth Cooper; Adrien Treuille; Daniel Mandell; Florian Richter; Yih-En Ban; Sarel Fleishman; Jacob Corn; David Kim; Philip Bradley"}, {"ref_id": "b42", "title": "Alanine-stretch scanning mutagenesis: a simple and efficient method to probe protein structure and function", "journal": "Nucleic acids research", "year": "1997", "authors": "Fabrice Lef\u00e8vre; Marie-H\u00e9l\u00e8ne R\u00e9my; Jean-Michel Masson"}, {"ref_id": "b43", "title": "Comparative assessment of scoring functions on an updated benchmark: 1. compilation of the test set", "journal": "J. Chem. Inf. Model", "year": "2014-06", "authors": "Yan Li; Zhihai Liu; Jie Li; Li Han; Jie Liu; Zhixiong Zhao; Renxiao Wang"}, {"ref_id": "b44", "title": "Structural and sequence similarity makes a significant impact on machinelearning-based scoring functions for protein-ligand interactions", "journal": "Journal of Chemical Information and Modeling", "year": "2017", "authors": "Yang Li; Jianyi Yang"}, {"ref_id": "b45", "title": "N-gram graph: Simple unsupervised representation for graphs, with applications to molecules", "journal": "Curran Associates, Inc", "year": "2019", "authors": "Shengchao Liu; F Mehmet; Yingyu Demirel;  Liang"}, {"ref_id": "b46", "title": "PDB-wide collection of binding data: current status of the PDBbind database", "journal": "Bioinformatics", "year": "2015-02", "authors": "Zhihai Liu; Yan Li; Li Han; Jie Li; Jie Liu; Zhixiong Zhao; Wei Nie; Yuchen Liu; Renxiao Wang"}, {"ref_id": "b47", "title": "Sspro/accpro 5: Almost perfect prediction of protein secondary structure and relative solvent accessibility using profiles, machine learning, and structural similarity", "journal": "Bioinformatics", "year": "2014-05", "authors": "Christophe Magnan; Pierre Baldi"}, {"ref_id": "b48", "title": "FreeSASA: An open source C library for solvent accessible surface area calculations", "journal": "", "year": "2016", "authors": "Simon Mitternacht"}, {"ref_id": "b49", "title": "Boltzmann generators: Sampling equilibrium states of many-body systems with deep learning", "journal": "Science", "year": "2019", "authors": "Frank No\u00e9; Simon Olsson; Jonas K\u00f6hler; Hao Wu"}, {"ref_id": "b50", "title": "DeepDTA: Deep Drug-Target Binding Affinity Prediction", "journal": "", "year": "2018", "authors": "Hakime \u00d6zt\u00fcrk; Elif Ozkirimli; Arzucan \u00d6zg\u00fcr"}, {"ref_id": "b51", "title": "Protein model quality assessment using 3d oriented convolutional neural networks", "journal": "Bioinformatics", "year": "2019", "authors": "Guillaume Pag\u00e8s; Benoit Charmettant; Sergei Grudinin"}, {"ref_id": "b52", "title": "Protein-Ligand scoring with convolutional neural networks", "journal": "J. Chem. Inf. Model", "year": "2017-04", "authors": "Matthew Ragoza; Joshua Hochuli; Elisa Idrobo; Jocelyn Sunseri; David Ryan Koes"}, {"ref_id": "b53", "title": "SQuad: 100,000+ questions for machine comprehension of text", "journal": "", "year": "2016", "authors": "Pranav Rajpurkar; Jian Zhang; Konstantin Lopyrev; Percy Liang"}, {"ref_id": "b54", "title": "Anatole von Lilienfeld. Quantum chemistry structures and properties of 134 kilo molecules", "journal": "", "year": "2014-07", "authors": "Raghunathan Ramakrishnan; Pavlo Dral; Matthias Rupp; O "}, {"ref_id": "b55", "title": "Quantum chemistry structures and properties of 134 kilo molecules", "journal": "Scientific Data", "year": "2014", "authors": "Raghunathan Ramakrishnan; O Pavlo; Matthias Dral; O. Anatole Von Rupp;  Lilienfeld"}, {"ref_id": "b56", "title": "Evaluating protein transfer learning with tape", "journal": "Curran Associates, Inc", "year": "2019", "authors": "Roshan Rao; Nicholas Bhattacharya; Neil Thomas; Yan Duan; Peter Chen; John Canny; Pieter Abbeel; Yun Song"}, {"ref_id": "b57", "title": "Enumeration of 166 Billion Organic Small Molecules in the Chemical Universe Database GDB-17", "journal": "Journal of Chemical Information and Modeling", "year": "2012-11", "authors": "Lars Ruddigkeit;  Ruud Van Deursen; C Lorenz; Jean-Louis Blum;  Reymond"}, {"ref_id": "b58", "title": "BIPSPI: a method for the prediction of partner-specific protein-protein interfaces", "journal": "Bioinformatics", "year": "2018", "authors": "Ruben Sanchez-Garcia; C O S Sorzano; J M Carazo; Joan Segura"}, {"ref_id": "b59", "title": "Proteingcn: Protein model quality assessment using graph convolutional networks", "journal": "bioRxiv", "year": "", "authors": "Soumya Sanyal; Ivan Anishchenko; Anirudh Dagar; David Baker; Partha Talukdar"}, {"ref_id": "b60", "title": "The PyMOL molecular graphics system, version 1.8", "journal": "", "year": "2015-11", "authors": "Llc Schr\u00f6dinger"}, {"ref_id": "b61", "title": "Schnet: A continuous-filter convolutional neural network for modeling quantum interactions", "journal": "", "year": "2017", "authors": "T Kristof; Pieter-Jan Sch\u00fctt; Huziel E Kindermans; Stefan Sauceda; Alexandre Chmiela; Klaus-Robert Tkatchenko;  M\u00fcller"}, {"ref_id": "b62", "title": "Improved protein structure prediction using potentials from deep learning", "journal": "Nature", "year": "2020", "authors": "W Andrew; Richard Senior; John Evans; James Jumper; Laurent Kirkpatrick; Tim Sifre; Chongli Green; Augustin Qin;  \u017d\u00eddek; W R Alexander; Alex Nelson;  Bridgland"}, {"ref_id": "b63", "title": "Comparative assessment of scoring functions: The CASF-2016 update", "journal": "J. Chem. Inf. Model", "year": "2019-02", "authors": "Minyi Su; Qifan Yang; Yu Du; Guoqin Feng; Zhihai Liu; Yan Li; Renxiao Wang"}, {"ref_id": "b64", "title": "Kernels for small molecules and the prediction of mutagenicity, toxicity and anti-cancer activity", "journal": "Bioinformatics", "year": "2005", "authors": "S Joshua Swamidass; Jonathan Chen; Jocelyne Bruand; Peter Phung; Liva Ralaivola; Pierre Baldi"}, {"ref_id": "b65", "title": "Tensor field networks: Rotation-and translation-equivariant neural networks for 3d point clouds", "journal": "CoRR", "year": "2018", "authors": "Nathaniel Thomas; Tess Smidt; Steven M Kearnes; Lusann Yang; Li Li; Kai Kohlhoff; Patrick Riley"}, {"ref_id": "b66", "title": "3D deep convolutional neural networks for amino acid environment similarity analysis", "journal": "BMC Bioinformatics", "year": "2017-06", "authors": "Wen Torng;  Russ B Altman"}, {"ref_id": "b67", "title": "End-to-end learning on 3d protein structure for interface prediction", "journal": "", "year": "2019", "authors": "Raphael Townshend; Rishi Bedi; Patricia Suriana; Ron Dror"}, {"ref_id": "b68", "title": "Geometric Deep Learning of RNA Structure", "journal": "Science", "year": "2021", "authors": "J L Raphael; Stephan Townshend;  Eismann; M Andrew; Ramya Watkins; Maria Rangan; Rhiju Karelina; Ron O Das;  Dror"}, {"ref_id": "b69", "title": "Compound-protein interaction prediction with end-to-end learning of neural networks for graphs and sequences", "journal": "Bioinformatics", "year": "2019", "authors": "Masashi Tsubaki; Kentaro Tomii; Jun Sese"}, {"ref_id": "b70", "title": "ProQ3d: improved model quality assessments using deep learning", "journal": "Bioinformatics", "year": "2017-01", "authors": "Karolis Uziela; David Men\u00e9ndez Hurtado; Nanjiang Shu; Bj\u00f6rn Wallner; Arne Elofsson"}, {"ref_id": "b71", "title": "The pdbbind database: Collection of binding affinities for protein-ligand complexes with known three-dimensional structures", "journal": "Journal of Medicinal Chemistry", "year": "2004", "authors": "Renxiao Wang; Xueliang Fang; Yipin Lu; Shaomeng Wang"}, {"ref_id": "b72", "title": "FARFAR2: Improved De Novo Rosetta Prediction of Complex Global RNA Folds", "journal": "Structure", "year": "2020-08", "authors": "Andrew Martin Watkins; Ramya Rangan; Rhiju Das"}, {"ref_id": "b73", "title": "3D steerable CNNs: Learning rotationally equivariant features in volumetric data", "journal": "", "year": "2018-07", "authors": "Maurice Weiler; Mario Geiger; Max Welling; Wouter Boomsma; Taco Cohen"}, {"ref_id": "b74", "title": "SMILES, a Chemical Language and Information System: 1: Introduction to Methodology and Encoding Rules", "journal": "Journal of Chemical Information and Computer Sciences", "year": "1988", "authors": "David Weininger"}, {"ref_id": "b75", "title": "Moleculenet: a benchmark for molecular machine learning", "journal": "Chem. Sci", "year": "2018", "authors": "Zhenqin Wu; Bharath Ramsundar; Evan N Feinberg; Joseph Gomes; Caleb Geniesse; Aneesh S Pappu; Karl Leswing; Vijay Pande"}, {"ref_id": "b76", "title": "Scoring function for automated assessment of protein structure template quality", "journal": "Proteins", "year": "2007-09", "authors": "Yang Zhang; Jeffrey Skolnick"}, {"ref_id": "b77", "title": "SFCscore(RF): a random forest-based scoring function for improved affinity prediction of protein-ligand complexes", "journal": "J. Chem. Inf. Model", "year": "2013-08", "authors": "David Zilian; Christoph A Sotriffer"}], "figures": [{"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "", "figure_data": ""}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Tasks included in the ATOM3D datasets, along with schematic representations of their inputs. P indicates protein, SM indicates small molecule, R indicates RNA. Lines indicate interaction and a small square within a protein indicates an individual amino acid. New datasets are in bold.", "figure_data": "Name (Task Code)SchematicObjectiveSourceSmall Molecule Properties (SMP)PropertiesQM9"}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "Small molecule results. Metric is mean absolute error (MAE).", "figure_data": "Task Target3DNon-3D3DCNN GNN ENN [Tsubaki et al., 2019] [Liu et al., 2019]\u00b5 [D]0.7540.501 0.0520.4960.520SMP\u03b5gap [eV] 0.5800.137 0.0950.1540.184U at 0 [eV]3.8621.424 0.0250.1820.218"}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "Biopolymer results. AUROC is the area under the receiver operating characteristic curve. Asterisks ( * ) indicate that the exact training data differed (though splitting criteria were the same).", "figure_data": "Task Metric3DNon-3D3DCNNGNNENN[Sanchez-Garcia et al., 2018]PIPAUROC0.844*  0.669-0.841[Rao et al., 2019]RES accuracy0.4510.0820.30MSP AUROC0.5740.6090.5740.554"}, {"figure_label": "5", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "Joint small molecule/biopolymer results. R S is Spearman correlation, R P is Pearson correlation, AUROC is area under the receiver operating characteristic curve, and RMSE is root-mean-squared error.", "figure_data": "Task Metric3DNon-3D3DCNN GNN ENN [\u00d6zt\u00fcrk et al., 2018] [Karimi et al., 2019]LBA RMSE1.4161.601 1.5681.5651.893glob. RP0.5500.545 0.3890.5730.415glob. RS0.5530.533 0.4080.5740.426LEP AUROC0.5890.681 0.6630.696-"}, {"figure_label": "6", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "Structure ranking results. R S is Spearman correlation. Mean measures the correlation for structures corresponding to the same biopolymer, whereas global measures the correlation across all biopolymers.", "figure_data": "Task Metric3D3DCNN GNNSotAPSR mean RS0.4310.4110.432 [Pag\u00e8s et al., 2019]glob. RS0.7890.7500.796 [Pag\u00e8s et al., 2019]RSR mean RS0.2640.234 0.173 [Watkins et al., 2020]glob. RS0.3720.512 0.304"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_7", "figure_caption": "7 AcknowledgmentsWe thank Truong-Son Hy, Maria Karelina, David Liu, L\u00edgia Melo, Joseph Paggi, and Erik Thiede for discussions and advice. We also thank Aditi Krishnapriyan and Nicolas Swenson for pointing out an error in earlier GNN performance numbers. This work was supported by the U.S. RK). Most of the computing for this project was performed on the Sherlock cluster. We thank Stanford University and the Stanford Research Computing Facility for providing computational resources and support that contributed to these research results.Thom Vreven, Iain H. Moal, Anna Vangone, Brian G. Pierce, Panagiotis L. Kastritis, Mieczyslaw Torchala, Raphael Chaleil, Brian Jim\u00e9nez-Garc\u00eda, Paul A. Bates, Juan Fernandez-Recio, Alexandre M.J.J. Bonvin, and Zhiping Weng. Updates to the integrated protein-protein interaction benchmarks: Docking benchmark version 5 and affinity benchmark version 2. Journal of Molecular Biology, 427(19):3031 -3041, 2015. ISSN 0022-2836. doi: https://doi.org/10.1016/j.jmb.2015.07.016. URL http://www.sciencedirect.com/science/article/pii/S0022283615004180. Izhar Wallach, Michael Dzamba, and Abraham Heifets. Atomnet: A deep convolutional neural network for bioactivity prediction in structure-based drug discovery, 2015.", "figure_data": "Department ofEnergy (DOE), Office of Science, Graduate Student Research (SCGSR) program (RJLT); EMBOLong-Term Fellowship ALTF 235-2019 (MV); an NSF Graduate Research Fellowship (PS); NationalLibrary of Medicine training grant LM012409 (AD); a Stanford Bio-X Bowes Fellowship (SE); NIHgrants GM102365 and HG010615 (RBA); the Chan Zuckerberg Biohub (RBA); the DOE, Officeof Science, Scientific Discovery through Advanced Computing (SciDAC) program (ROD); Intel(ROD); and DARPA Agreement No. HR0011-18-9-0038 ("}, {"figure_label": "7", "figure_type": "table", "figure_id": "tab_9", "figure_caption": "Comparison of performance against state-of-the-art methods, where available. The 3DCNN, GNN, and ENN networks achieve state-of-the-art in several tasks; for those where they do not (SMP, PIP, LBA), we note that the competing methods also use the 3D geometry of molecules. Asterisks ( * ) indicate that the exact training data differed (though splitting criteria were the same).", "figure_data": "Task Metric3DSOTA3DCNNGNNENNSMP \u00b5 [D]0.7540.5010.052*  0.030[Gilmer et al., 2017]\u03b5gap [eV]0.5800.1370.095*  0.061[Anderson et al., 2019]U at 0 [eV]3.8621.4240.025*  0.014[Sch\u00fctt et al., 2017]PIPAUROC0.844*  0.669-0.919 [Sanchez-Garcia et al., 2018]RES accuracy0.4510.082*  0.072  *  0.425[Torng and Altman, 2017]MSP AUROC0.5740.6090.574-LBA RMSE1.4161.6011.568*  1.838[Li and Yang, 2017]glob. RP0.5500.5450.389*  0.645[Li and Yang, 2017]glob. RS0.5530.5330.408*  0.697[Li and Yang, 2017]LEP AUROC0.5890.6810.6630.770[Friesner et al., 2004]PSR mean RS0.4310.411-0.432[Pag\u00e8s et al., 2019]glob. RS0.7890.750-0.796[Pag\u00e8s et al., 2019]RSR mean RS0.2640.234-0.173[Alford et al., 2017]glob. RS0.3720.512-0.304[Alford et al., 2017]"}, {"figure_label": "8", "figure_type": "table", "figure_id": "tab_10", "figure_caption": "Complete benchmarking results from Tables3-6, with additional metrics and standard deviations reported over three replicates. R K is Kendall correlation and AUPRC is area under the precision-recall curve. SMP metrics are all mean absolute error (MAE). Asterisks ( * ) indicate that the exact training data differed (though splitting criteria were the same).", "figure_data": ""}, {"figure_label": "9", "figure_type": "table", "figure_id": "tab_11", "figure_caption": "Number of samples for each dataset presented in the benchmark.", "figure_data": "TaskNumber of SamplesTrainValTestSMP1035471294312943PIP873033105015268RES 3820837 192371 648372MSP2864937347LBA3563448452LEP304110104PSR25400280016099RSR1247940004000"}], "formulas": [], "doi": "10.1021/acs.jctc.7b00125"}