{"title": "Privacy Auditing with One (1) Training Run", "authors": "Thomas Steinke; Milad Nasr; Matthew Jagielski", "pub_date": "2023-05-15", "abstract": "We propose a scheme for auditing differentially private machine learning systems with a single training run. This exploits the parallelism of being able to add or remove multiple training examples independently. We analyze this using the connection between differential privacy and statistical generalization, which avoids the cost of group privacy. Our auditing scheme requires minimal assumptions about the algorithm and can be applied in the black-box or white-box setting.", "sections": [{"heading": "Introduction", "text": "Differential privacy (DP) [DMNS06] provides a quantifiable privacy guarantee by ensuring that no person's data significantly affects the probability of any outcome. Formally, a randomized algorithm M satisfies (\u03b5, \u03b4)-DP if, for any pair of inputs x, x differing only by the addition or removal of one person's data and any measurable S, we have\nP [M (x) \u2208 S] \u2264 e \u03b5 \u2022 P [M (x ) \u2208 S] + \u03b4.\n(1)\nA DP algorithm is accompanied by a mathematical proof giving an upper bound on the privacy parameters \u03b5 and \u03b4. In contrast, a privacy audit provides an empirical lower bound on the privacy parameters. Privacy audits allow us to assess the tightness of the mathematical analysis [JUO20; NHSBTJCT23] or, if the lower and upper bounds are contradictory, to detect errors in the analysis or in the algorithm's implementation [TTSSJC22]. Typically, privacy audits obtain a lower bound on the privacy parameters directly from the DP definition (1). That is, we construct a pair of inputs x, x and a set of outcomes S and we estimate the probabilities P [M (x) \u2208 S] and P [M (x ) \u2208 S]. However, estimating these probabilities requires running the algorithm M hundreds of times. This approach to privacy auditing is computationally expensive, which raises the question Can we perform privacy auditing using a single run of the algorithm M? This is the question we address in our work.", "publication_ref": ["b13", "b42"], "figure_ref": [], "table_ref": []}, {"heading": "Our Contributions", "text": "Our approach ( \u00a72): The DP definition (1) considers adding or removing a single person's data to or from the dataset. We consider multiple people's data and the dataset independently includes or excludes each person's data point. Our analysis exploits the parallelism of multiple independent data points in a single run of the algorithm in lieu of multiple independent runs.\nOur auditing procedure operates as follows. We identify m data points (i.e., training examples or \"canaries\") to either include or exclude and we flip m independent unbiased coins to decide which of them to include or exclude. We then run the algorithm on the randomly selected dataset. Based on the output of the algorithm, the auditor \"guesses\" whether or not each data point was included or excluded (or it can abstain from guessing for some data points). We obtain a lower bound on the privacy parameters from the fraction of guesses that were correct.\nIntuitively, if the algorithm is (\u03b5, 0)-DP, then the auditor can correctly guess each inclusion/exclusion coin flip with probability at most e \u03b5 e \u03b5 +1 . Thus DP implies a high-probability upper bound on the fraction of correct guesses and, conversely, a large fraction of correct guesses implies a high-probability lower bound on the privacy parameters.\nOur analysis ( \u00a75): Na\u00efvely, analyzing the addition or removal of multiple data elements would rely on group privacy; but this does not exploit the fact that the data items were included or excluded independently. Instead, we leverage the connection between DP and generalization [DFHPRR15b; DFHPRR15a; BNSSSU16; RRST16; JLNRSMS19; SZ20]. Our main theoretical contribution is an improved analysis of this connection that is tailored to yield nearly tight bounds in our setting.\nInformally, if we run a DP algorithm on i.i.d. samples from some distribution, then, conditioned on the output of the algorithm, the samples are still \"close\" to being i.i.d. samples from that distribution. There is some technicality in making this precise, but, roughly speaking, we show that including or excluding m data points independently for one run is essentially as good as having m independent runs (as long as \u03b4 is small).\nOur results ( \u00a76): We implement our new auditing framework to audit DP-SGD training on a WideResNet model, trained on the CIFAR10 dataset across multiple configurations. Our approach successfully achieves an empirical lower bound of \u03b5 \u2265 1.8, compared to a theoretical upper bound of \u03b5 \u2264 4 in the white-box setting. The m examples we insert for auditing (known in the literature as \"canaries\") do not significantly impact the accuracy of the final model (less than a 5% decrease in accuracy) and our procedure only requires a single end-to-end training run. Such results were previously unattainable in the setting where only one model could be trained. Namely, if S i = 1, then x i is in x IN ; and, if S i = \u22121, then x i is in x OUT . 5: Run A on input x IN with appropriate parameters, outputting w. 6: Compute the vector of scores Y = (Score(x i , w) : i \u2208 [m]) \u2208 R m . 7: Sort the scores Y . Let T \u2208 {\u22121, 0, +1} m be +1 for the largest k + scores and \u22121 for the smallest k \u2212 scores. 8: (I.e., T \u2208 {\u22121, 0, +1} m maximizes m i T i \u2022 Y i subject to m i |T i | = k + + k \u2212 and m i T i = k + \u2212 k \u2212 .) 9: Return: The vector S \u2208 {\u22121, +1} m indicating the true selection and the guesses T \u2208 {\u22121, 0, +1} m .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Our Auditing Procedure", "text": "We now present our auditing procedure in Algorithm 1. We independently include each of the first m examples with 50% probability and exclude it otherwise. 1 Our approach is applicable to both white-box auditing in the sense that the adversary has access to all intermediate values of the model weights and black-box auditing in the sense that the adversary only sees the final model weights (or can only query the final model). In both cases we compute a \"score\" for each example and \"guess\" whether the example is included or excluded based on these scores. Specifically, we guess that the examples with the k + highest scores are included and the examples with the k \u2212 lowest scores are excluded, and we abstain from guessing for the remaining m \u2212 k + \u2212 k \u2212 auditing examples; the setting of these parameters will depend on the application. Note that we only randomize the first m examples x 1 , \u2022 \u2022 \u2022 , x m (which we refer to as \"auditing examples\" or \"canaries\"); the last n\u2212m examples x m+1 , \u2022 \u2022 \u2022 , x n are always included and, thus, we do not make any guesses about them. To get the strongest auditing results we would set m = n, but we usually want to set m < n. For example, computing the score of all n examples may be computationally prohibitive, so we only compute the scores of m examples. Also we may wish to artificially construct m examples to be easy to identify (i.e., canaries), but still include n \u2212 m \"real\" examples to ensure that A still produces a useful model. (I.e., having more training examples improves the performance of the model.)\n1 Alternatively, we could also consider a different probability of inclusion; our theoretical results can handle this (see Proposition 5.7). However, this seems unlikely to be useful, as it intuitively lowers the signal-tonoise ratio. Another alternative is to non-independently choose which points to include to ensure x IN has a fixed size; see Appendix A.\nIntuitively, the vector of scores Y should be correlated with the true selection S, but too strong a correlation would violate DP. This is the basis of our audit. Specifically, the auditor computes T from Y which is a \"guess\" at S. By the postprocessing property of DP, the guesses T are a differentially private function of the true S, which means that they cannot be too accurate.\nTo obtain a lower bound on the DP parameters, in Section 5, we show that DP implies a high-probability upper bound on the number of correct guesses W := m i max{0, T i \u2022 S i }. The observed value of W then yields a high-probability lower bound on the DP parameters. To be more precise, we have the following guarantee.\nTheorem 2.1 (Informal version of Theorem 5.2). Let (S, T ) \u2208 {\u22121, +1} m \u00d7 {\u22121, 0, +1} m be the output of Algorithm 1. Assume the algorithm to audit A satisfies (\u03b5, \u03b4)-DP. Let r := k + + k \u2212 = T 1 be the number of guesses. Then, for all v \u2208 R,\nP S\u2190{\u22121,+1} m T \u2190M (S) m i max{0, T i \u2022 S i } \u2265 v \u2264 P W \u2190Binomial(r, e \u03b5 e \u03b5 +1 ) W \u2265 v + O(\u03b4).(2)\nIf we ignore \u03b4 for the moment, Theorem 2.1 says that the number of correct guesses is stochastically dominated by Binomial r, e \u03b5 e \u03b5 +1 , where r = k + + k \u2212 is the total number of guesses. This binomial distribution is precisely the distribution of correct guesses we would get if T was obtained by independently performing (\u03b5, 0)-DP randomized response on r bits of S. In other words, the theorem says that (\u03b5, 0)-DP randomized response is the worst-case algorithm in terms of the number of correct guesses. In particular, this means the theorem is tight (when \u03b4 = 0)\nThe binomial distribution is well-concentrated. In particular, for all \u03b2 \u2208 (0, 1), we have\nP W \u2190Binomial(r, e \u03b5 e \u03b5 +1 ) \uf8ee \uf8ef \uf8ef \uf8f0W \u2265 r \u2022 e \u03b5 e \u03b5 + 1 + 1 2 \u2022 r \u2022 log(1/\u03b2) =v \uf8f9 \uf8fa \uf8fa \uf8fb \u2264 \u03b2.(3)\nThere is an additional O(\u03b4) term in the guarantee (2). The exact expression for this term is somewhat complex. It is always \u2264 2m\u03b4, but it is much smaller than this for reasonable parameter values. In particular, for v as in Equation 3 with \u03b2 \u2264 1/r 4 , this term is \u2264 O( m r \u03b4).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Theorem 2.1 gives us a hypothesis test: If", "text": "A is (\u03b5, \u03b4)-DP, then the number of correct guesses W is \u2264 r\u2022e \u03b5 e \u03b5 +1 + O( \u221a r)\nwith high probability. Thus, if the observed number of correct guesses v is larger than this, we can reject the hypothesis that A satisfies (\u03b5, \u03b4)-DP. We can convert this hypothesis test into a confidence interval (i.e., a lower bound on \u03b5) by finding the largest \u03b5 that we can reject at a desired level of confidence; see Section 4.3.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Related Work", "text": "The goal of privacy auditing is to empirically estimate the privacy provided by an algorithm, typically to accompany a formal privacy guarantee. Early work on auditing has often been motivated by trying to identify bugs in the implementations of differentially private data analysis algorithms [DWWZK18;BGDCTV18].\nTechniques for auditing differentially private machine learning typically rely on conducting some form of membership inference attack [SSSS17]; 2 these attacks are designed to detect the presence or absence of an individual example in the training set. Essentially, a membership inference attack which achieves some true positive rate (TPR) and false positive rate (FPR) gives a lower bound on the privacy parameter \u03b5 \u2265 log e (TPR/FPR) (after ensuring statistical validity of the TPR and FPR estimates).\nJayaraman and Evans [JE19] use standard membership inference attacks to evaluate different privacy analysis algorithms. Jagielski, Ullman, and Oprea [JUO20] consider inferring membership of worst-case \"poisoning\" examples to conduct stronger membership inference attacks and understand the tightness of privacy analysis. Nasr, Song, Thakurta, Papernot, and Carlini [NSTPC21] measure the tightness of privacy analysis under a variety of threat models, including showing that the DP-SGD analysis is tight in the threat model assumed by the standard DP-SGD analysis.\nImprovements to auditing have been made in a variety of directions. For example, Nasr, Hayes, Steinke, Balle, Tram\u00e8r, Jagielski, Carlini, and Terzis [NHSBTJCT23] and Maddock, Sablayrolles, and Stock [MSS22] take advantage of the iterative nature of DP-SGD, auditing individual steps to understand privacy of the end-to-end algorithm. Improvements have also been made to the basic statistical techniques for estimating the \u03b5 parameter, for example by using Log-Katz confidence intervals [LMFLZWRFT22], Bayesian techniques [ZBWT-SRPNK22], or auditing algorithms in different privacy definitions [NHSBTJCT23]. Andrew, Kairouz, Oh, Oprea, McMahan, and Suriyakumar [AKOOMS23] build on the observation that, when performing membership inference, analyzing the case where the data is not included does not require re-running the algorithm; instead we can re-sample the excluded data point; if the data points are i.i.d. from a nice distribution, this permits closed-form analysis of the excluded case.\nA recent heuristic proposed to improve the efficiency of auditing is performing membership inference on multiple examples simultaneously. This heuristic was proposed by Malek Esmaeili, Mironov, Prasad, Shilov, and Tramer [MEMPST21], and evaluated more rigorously by Zanella-B\u00e9guelin, Wutschitz, Tople, Salem, R\u00fchle, Paverd, Naseri, and K\u00f6pf [ZBWTSRPNK22]. However, this heuristic is not theoretically justified, as the TPR and FPR estimates are not based on independent samples. In our work, we provide a proof of the validity of this heuristic. In fact, with this proof, we show for the first time that standard membership inference attacks, which attack multiple examples per training run, can be used for auditing analysis; prior work using these attacks must make an independence assumption. As a result, auditing can take advantage of progress in the membership inference field [CCNSTT22; WBKBGGG22].", "publication_ref": ["b17", "b2", "b38", "b35", "b34", "b31", "b28", "b34", "b29", "b46"], "figure_ref": [], "table_ref": []}, {"heading": "Background", "text": "We briefly review some standard background material. Readers may wish to skip to the next section and revisit this only if necessary.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Differential Privacy", "text": "They We recite the definitions of differential privacy and some relevant relaxations. For detailed background, see the tutorial by Vadhan [Vad17] or the textbook by Dwork and Roth [DR14]. Definition 4.1 (Differential Privacy [DMNS06; DKMMN06]). Let M : X * \u2192 Y be a randomized algorithm, where X * = n\u22650 X n . We say M is (\u03b5, \u03b4)-differentially private ((\u03b5, \u03b4)-DP) if, for all x, x \u2208 X * differing only by the addition or removal of one element, we have\n\u2200S \u2282 Y P [M (x) \u2208 S] \u2264 e \u03b5 \u2022 P [M (x ) \u2208 S] + \u03b4. Definition 4.2 (R\u00e9nyi Differential Privacy [Mir17]). We say M : X * \u2192 Y is (\u03b1,\u03b5)-R\u00e9nyi differentially private ((\u03b1,\u03b5)-RDP)\nif, for all x, x \u2208 X * differing only by the addition or removal of one element, we have\nD \u03b1 (M (x) M (x )) \u2264\u03b5,\nwhere\nD \u03b1 (P Q) := 1 \u03b1\u22121 log E Y \u2190P P (Y ) Q(Y ) \u03b1\u22121\ndenotes the R\u00e9nyi divergence of order \u03b1.", "publication_ref": ["b14"], "figure_ref": [], "table_ref": []}, {"heading": "Definition 4.3 (Concentrated Differential Privacy [DR16; BS16]", "text": "). We say M : X * \u2192 Y is \u03c1-zero concentrated differentially private (\u03c1-zCDP) if, for all x, x \u2208 X * differing only by the addition or removal of one element, we have\n\u2200\u03b1 > 1 D \u03b1 (M (x) M (x )) \u2264 \u03b1 \u2022 \u03c1.\nRemark 4.4. In this paper, we focus on to the addition or removal notion of DP, rather than replacement. (In Appendix A, we consider replacement.) Note that, in our theoretical analysis, we consider DP algorithms of the form M : {0, 1} m \u2192 Y. In this case, DP is with respect to flipping one of the input bits, as each bit indicates whether some example is included or excluded.\nThe main property of DP that we use is invariance under postprocessing. That is, if M : X * \u2192 Y satisfies DP and F : Y \u2192 Z is an arbitrary function, then F \u2022 M : X * \u2192 Z also satisfies DP with the same parameters.\nGaussian Mechanism A common method for achieving DP is Gaussian noise addition. The following gives the optimal DP guarantee for the Gaussian mechanism.\nLemma 4.5 ([BW18, Theorem 8]). Let q : X * \u2192 R be a function with sensitivity \u2206 := sup x,x |q(x)\u2212q(x )|. (In the supremum x, x \u2208 X * are restricted to differ only by the addition or removal of one element.) Fix \u03c3 2 > 0 and let \u03c1 := \u2206 2 /2\u03c3 2 . Define M : X * \u2192 R by M (x) = N (q(x), \u03c3 2 ). Then, for any \u03b5 \u2265 0, the algorithm M satisfies (\u03b5, \u03b4)-DP with\n\u03b4 = \u03a6 \u03b5 \u2212 \u03c1 \u221a 2\u03c1 \u2212 e \u03b5 \u2022 \u03a6 \u03b5 + \u03c1 \u221a 2\u03c1 ,\nwhere \u03a6(z) := P\nZ\u2190N (0,1) [Z > z] = 1 \u221a 2\u03c0 \u221e z exp(\u2212x 2 /2)dx. Furthermore, M satisfies \u03c1-zCDP.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "DP-SGD -Differentially Private Stochastic Gradient Descent", "text": "The algorithm whose privacy we are most interested in auditing is Differentially Private Stochastic Gradient Descent (DP-SGD, Algorithm 2). This is the workhorse of private machine learning both in theory [BST14] and in practice [ACGMMTZ16].\nAlgorithm 2 DP-SGD -Differentially Private Stochastic Gradient Descent 1: Input: x \u2208 X n 2: Model: Loss function f : R d \u00d7 X \u2192 R. Sample S t \u2286 [n] where each i \u2208 [n] is included independently with probability q.", "publication_ref": ["b6", "b0"], "figure_ref": [], "table_ref": []}, {"heading": "7:", "text": "Compute g t i = \u2207 w t\u22121 f (w t\u22121 , x i ) \u2208 R d for all i \u2208 S t .\n8:\nClip\u011d t i = min 1, c g t i 2\n\u2022 g t i \u2208 R d for all i \u2208 S t .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "9:", "text": "Sample \u03be t \u2208 R d from N (0, \u03c3 2 c 2 I).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "10:", "text": "Sumg t = \u03be t + i\u2208S t\u011d t i \u2208 R d .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "11:", "text": "Update w t = w t\u22121 \u2212 \u03b7 \u2022g t \u2208 R d . 12: end for 13: Output: w 0 , w 1 , \u2022 \u2022 \u2022 , w . DP-SGD satisfies differential privacy. Much ink has been spilled precisely quantifying its privacy properties [MTZ19; WBK19; KJH20; GLW21; ZDW22, etc.]. A simple guarantee is the following. \n\u03b5 = \u2022 log 1 + q 2 \u2022 exp(1/\u03c3 2 ) \u2212 1 \u2248 \u2022 q 2 \u2022 1 \u03c3 2 .\nIf\u03b5 \u2264 1, then DP-SGD should provide meaningful privacy protection. In particular, (2,\u03b5)-RDP implies that membership inference has a maximum accuracy (in the balanced case) of\n1 2 + 1 2 e\u03b5 \u2212 1 e\u03b5 + 3 \u2248 1 2 + 1 4 \u221a\u03b5 . (4\n)\nOur goal is to audit this guarantee.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Hypothesis Testing & Statistical Estimation", "text": "Our goal is to estimate the privacy parameters of the algorithm that we are auditing. As prior work has noted [DWWZK18; JUO20], this task can be framed as statistical estimation, with a goal of outputting a statistical lower bound on the privacy parameters. These lower bounds will have a corresponding confidence level, roughly representing the probability that the lower bound could have been produced even when analyzing an algorithm with perfect privacy. As empirical methods, it is impossible to have 100% confidence in our methods, so we will generally use 95% confidence in our experiments, comparable to the use of p < 0.05 in science literature.\nTo be precise, our auditor runs the algorithm M and outputs \u03b5 LB \u2265 0 with the following guarantee. If M satisfies (\u03b5 true , \u03b4)-DP, then, with probability at least 1 \u2212 \u03b2, we have \u03b5 LB \u2264 \u03b5 true . Here 1 \u2212 \u03b2 is the confidence level and \u03b4 \u2265 0 is fixed. Note that this is a frequentist guarantee, rather than a Bayesian guarantee. That is, the probability is with respect to our auditing procedure, rather than a statement about our beliefs about M .\nWe can also view this in terms of hypothesis testing. Here we start with a \"null hypothesis\" that M satisfies (\u03b5 null , \u03b4)-DP and the auditor's goal is to test this hypothesis by running M . If the auditor rejects this null hypothesis, then this gives us a lower bound \u03b5 LB = \u03b5 null .\nThe difference between hypothesis testing and statistical estimation is that a hypothesis test starts with a given \u03b5 null and outputs a binary decision to reject or not, while an estimator outputs a number \u03b5 LB . However, we can convert between these: Lemma 4.7. For each M , let A M \u2208 \u2126 be a random variable and let\nP M \u2208 R be a fixed number. For each \u03b5, \u03b2 > 0, let T \u03b5,\u03b2 \u2282 \u2126 satisfy \u2200M (P M = \u03b5 =\u21d2 P [A M \u2208 T \u03b5,\u03b2 ] \u2264 \u03b2) . (5\n)\nFurther suppose that, if \u03b5 1 \u2264 \u03b5 2 , then T \u03b5 1 ,\u03b2 \u2283 T \u03b5 2 ,\u03b2 .\nThen, for all M and all \u03b2 > 0,\nP [P M \u2265 sup {\u03b5 > 0 : A M \u2208 T \u03b5,\u03b2 }] \u2265 1 \u2212 \u03b2.(6)\nProof. Fix a realization of A M and suppose P M < sup {\u03b5 > 0 :\nA M \u2208 T \u03b5,\u03b2 }.\nThen there exists some \u03b5 \u2265 P M with A M \u2208 T \u03b5,\u03b2 and, hence,\nA M \u2208 \u03b5\u2265P M T \u03b5,\u03b2 = T P M ,\u03b2 .\nThe equality above follows from our monotonicity assumption on T . Thus\nP [P M < sup {\u03b5 > 0 : A M \u2208 T \u03b5,\u03b2 }] \u2264 P [A M \u2208 T P M ,\u03b2 ] \u2264 \u03b2, as required.\nTo interpret Lemma 4.7, M is an algorithm and P M is the \"true\" privacy parameter \u03b5 that it satisfies. (We're considering \u03b4 to be fixed.) The random variable A M is the output of our auditing procedure applied to M . (This is our test statistic in the language of hypothesis testing.) The hypothesis test's rejection set is T \u03b5,\u03b2 and Equation 5 guarantees that, if M is indeed (\u03b5, \u03b4)-DP (i.e., the null hypothesis is true), then the probability that we reject the null hypothesis is at most \u03b2. Equation 6 then shows how to estimate the true privacy parameter P M from A M ; we simply take the largest \u03b5 for which we can reject the corresponding null hypothesis.\nNote that Lemma 4.7 needs to make a technical monotonicity assumption. In our setting this simply means that, if a given realization of the test statistic A M allows us to reject the null hypothesis that M is (\u03b5 2 , \u03b4)-DP and \u03b5 1 \u2264 \u03b5 2 , then we can also reject the null hypothesis that M is (\u03b5 1 , \u03b4)-DP.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Stochastic Dominance", "text": "In our theoretical analysis we use the concept of stochastic dominance. Specifically, we use this to formalize the \"worst-case\" DP algorithm for auditing. Definition 4.8 (Stochastic Dominance). Let X, Y \u2208 R be random variables. We say X is stochastically dominated by Y (or Y stochastically dominates X) if P [X > t] \u2264 P [Y > t] for all t \u2208 R. Equivalently, X is stochastically dominated by Y if there exists a coupling (i.e., a joint distribution that matches the marginal distributions of X and Y ) such that P\n[X \u2264 Y ] = 1.\nStochastic dominance is preserved under sums/convolutions: Lemma 4.9. Suppose X 1 is stochastically dominated by Y 1 . Suppose that, for all x \u2208 R, the conditional distribution X 2 |X 1 = x is stochastically dominated by Y 2 . Assume that Y 1 and Y 2 are independent. Then X 1 + X 2 is stochastically dominated by\nY 1 + Y 2 .\nProof. For all t \u2208 R, we have To analyze the results of our audit, we leverage the connection between DP and generalization [DFHPRR15b; DFHPRR15a; BNSSSU16; RRST16; JLNRSMS19; SZ20]. Unfortunately, directly applying the existing results from the literature is unlikely to yield meaningful results, as the constants are not optimal. Thus we provide an analysis of DP's generalization guarantees that is suitable for our application and which has sharp constants.\nP [X 1 + X 2 > t] = E X 1 P X 2 [X 2 > t \u2212 X 1 |X 1 ] \u2264 E X 1 P Y 2 [Y 2 > t \u2212 X 1 ] (Y 2 dominates X 2 |X 1 ) = E Y 2 P X 1 [X 1 > t \u2212 Y 2 ] \u2264 E Y 2 P Y 1 [Y 1 > t \u2212 Y 2 ] (Y 1 dominates X 1 & independence) = P [Y 1 + Y 2 > t].\nWe consider the following formalism. The algorithm M : {\u22121, +1} m \u2192 R m takes in a vector of bits and outputs a vector of \"guesses\". Each input bit indicates whether or not a particular example is included in or excluded from the dataset. In particular, the DP guarantee ensures that the outputs are indistinguishable if we flip one bit, which corresponds to adding or removing the corresponding data point. Each coordinate of the output is a guess for the corresponding input bit; the sign of the score should match the corresponding input bit, while the magnitude is a reflection of the confidence.\nThe algorithm M represents both the \"real\" algorithm (e.g., DP-SGD) and the auditor which postprocesses the output of the real algorithm into guesses. In this formalism, the examples themselves are considered fixed and not part of the input -i.e., the examples are \"hardcoded\" into M . The algorithm M is an abstraction for our analysis, rather than a realistic system. For comparison, we plot the ideal \u03b5 that gives 100 \u2022 e \u03b5 e \u03b5 +1 correct guesses.\nWe evaluate the quantity\nW := m i max{0, T i \u2022 S i },\nwhere S is uniform on {\u22121, +1} m and T = M (S). If T i and S i disagree in sign (i.e., the guess is wrong), then max{0, T i \u2022 S i } = 0; if they agree (i.e., the guess is right), then max{0,\nT i \u2022 S i } = |T i |.\nThat is, W increases when we guess correctly and the increase is proportional to how much \"weight\" we placed on that guess. The auditor seeks to maximize W and then we compare it to a baseline that is consistent with DP. (The analysis in this section focuses on computing this baseline.) Incorrect guesses do not increase W , but they do increase the baseline. Note that we can guess T i = 0, which amounts to abstaining from making a guess; this doesn't increase W , but also doesn't increase the baseline.\nOur formalism is inspired by that of Steinke and Zakynthinou [SZ20], who also restrict to binary inputs. In contrast, most of the work connecting DP and generalization does not do this. The benefit of restricting to binary inputs which represent inclusion or exclusion of a data point is that it simplifies our analysis.", "publication_ref": ["b40"], "figure_ref": [], "table_ref": []}, {"heading": "Pure DP Analysis", "text": "We first consider the pure DP (\u03b4 = 0) case, as it is considerably simpler than the general case. We follow the analysis of Jung, Ligett, Neel, Roth, Sharifi-Malvajerdi, and Shenfeld Here we plot the ideal \u03b5 on the horizontal axis, so that the number of correct guesses is 1000 \u2022 e \u03b5 e \u03b5 +1 .\n[JLNRSMS19] with some refinement. Specifically, rather than relying on a Hoeffding bound, we show that it is stochastically dominated by a Binomial distribution. This result is tight -i.e., if M independently performs a randomized response for each input bit, then the inequality becomes an equality.\nProposition 5.1 (Pure DP Version of Main Result). Let M : {\u22121, +1} m \u2192 R m satisfy (\u03b5, 0)-DP. Let S \u2208 {\u22121, +1} m be uniformly random. Let T = M (S) \u2208 R m .\nThen, for all v \u2208 R and all t \u2208 R m in the support of T , 3\nP S\u2190{\u22121,1} m T \u2190M (S) m i max{0, T i \u2022 S i } \u2265 v T = t \u2264 P S\u2190Bernoulli( e \u03b5 e \u03b5 +1 ) m m i\u0160 i \u2022 |t i | \u2265 v =: \u03b2(m, \u03b5, v, t).\nProposition 5.1 is Bayesian: We condition on the output and then consider the probability that each guess was right. The vector\u0160 should be seen as indicating whether each guess was right. The proposition says that, in the worst case, each guess is correct independently with probability e \u03b5 e \u03b5 +1 .\nHow do we use this result? Suppose we have conducted an audit and observed s and t as the output of Algorithm 3. Let v = m i max{0, s i \u2022 t i }. Following Lemma 4.7, we choose a desired confidence 1 \u2212 \u03b2 < 1 (e.g., \u03b2 = 0.05) and then we choose \u03b5 \u2265 0 so that \u03b2(m, \u03b5, v, t) = \u03b2. Then this value of \u03b5 is our lower bound.\nIn the language of hypothesis testing, W = m i max{0, T i \u2022 S i } is the test statistic and our null hypothesis is that M is \u03b5-DP. Under the null hypothesis we have P\n[W \u2265 v] \u2264 \u03b2(m, \u03b5, v, t).\nThus, if v is the observed value of the test statistic, then \u03b2(m, \u03b5, v, t) is our p-value. And we can reject the null hypothesis if, say, \u03b2(m, \u03b5, v) \u2264 0.05.\nProof. Fix some t \u2208 R m . We now analyze the distribution of S conditioned on M (S) = t. Note that the unconditional distribution of S is uniform on {\u22121, +1} m and M is (\u03b5, 0)-DP.\nWe perform the analysis one bit at a time. Fix some i \u2208 [m] and s <i \u2208 {\u22121, +1} i\u22121 . By Bayes' law and (\u03b5, 0)-DP,\nP [S i = 1|M (S) = t, S <i = s <i ] = P [M (S) = t|S i = 1, S <i = s <i ] \u2022 P [S i = 1|S <i = s <i ] P [M (S) = t|S <i = s <i ] = P [M (S) = t|S i = 1, S <i = s <i ] \u2022 P [S i = 1] P [M (S) = t|S i = 1, S <i = s <i ] \u2022 P [S i = 1] + P [M (S) = t|S i = \u22121, S <i = s <i ] \u2022 P [S i = \u22121] = P [M (S) = t|S i = 1, S <i = s <i ] \u2022 1 2 P [M (S) = t|S i = 1, S <i = s <i ] \u2022 1 2 + P [M (S) = t|S i = \u22121, S <i = s <i ] \u2022 1 2 = 1 1 + P [M (S) = t|S i = \u22121, S <i = s <i ]/P [M (S) = t|S i = 1, S <i = s <i ] \u2208 1 1 + e \u03b5 , 1 1 + e \u2212\u03b5 . Thus P [S i = sign(T i )|T = t, S <i = s <i ] \u2264 1 1+e \u2212\u03b5 = e \u03b5 e \u03b5 +1 .\nWith this in hand, we can prove the result by induction. We assume inductively that\nW m\u22121 := m\u22121 i max{0, T i \u2022 S i } is stochatiscally dominated byW m\u22121 := m\u22121 i\u0160 i \u2022 |t i | where\u0160 \u2190 Bernoulli e \u03b5 e \u03b5 +1 m\u22121 . As above, conditioned on the value of W m\u22121 , the variable max{0, T m \u2022S m } = |T m |\u2022I[S m = sign(T m )] is stochastically dominated by |T m |\u2022Bernoulli e \u03b5 e \u03b5 +1 . By Lemma 4.9, W m = W m\u22121 + max{0, T m \u2022 S m } is stochastically dominated byW m := m i\u0160 i \u2022 |t i | where\u0160 \u2190 Bernoulli e \u03b5 e \u03b5 +1 m .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Approximate DP Analysis", "text": "We extend the pure DP analysis ( \u00a75.1) to approximate DP (\u03b4 > 0). This becomes quite messy. In the pure DP case, we can condition on an arbitrary output t. In the approximate DP case, some outputs are \"bad\" in the sense that the privacy loss is unbounded. To handle this we do two things: First, we require the guesses to be bounded (i.e., T \u2208 [\u22121, +1] m instead of T \u2208 R m ), which ensures that bad outputs cannot skew things too much. Second, the guarantees we prove have an additional failure probability that depends on \u03b4.\nOur analysis most closely resembles that of Rogers, Roth, Smith, and Thakkar [RRST16]. Essentially, we repeat the analysis for the pure DP case, but add some failure events, and carefully account for how much they can distort the results.\nTheorem 5.2 (Main Result). Let M : {\u22121, +1} m \u2192 [\u22121, +1] m satisfy (\u03b5, \u03b4)-DP. Let S \u2208 {\u22121, +1} m be uniformly random. Let T = M (S) \u2208 [\u22121, +1] m . Then, for all v \u2208 R, P S\u2190{\u22121,+1} m T \u2190M (S) m i max{0, T i \u2022 S i } \u2265 v \u2264 \u03b2 + \u03b1 \u2022 2m \u2022 \u03b4,(7)\nwhere\n\u03b2 = P W * W * \u2265 v ,(8)\n\u03b1 = max 1 i P W * W * \u2265 v \u2212 i \u2212 \u03b2 : i \u2208 {1, 2, \u2022 \u2022 \u2022 , m} . (9\n)\nHereW * is any distribution on R that stochastically dominatesW (t) :\n= m i\u0160 i |t i | for\u0160 \u2190 Bernoulli e \u03b5 e \u03b5 +1\nm for all t in the support of T .\nTo evaluate the bound of Theorem 5.2, we need to identifyW * and compute its distribution. We can set P\nW * W * \u2265 v = sup t\u2208support(T ) P W W (t) \u2265 v\n. This can be difficult to compute, depending on what we know about the support of T . If the support of T is nice, we can compute this explicitly; e.g., see Corollary 5.4. There are other things we can do. For example, if we have bounds on sup t\u2208support(T ) t 2 and sup t\u2208support(T ) t 1 , then we can use a concentration inequality to bound sup t\u2208support(T ) P W W (t) \u2265 v and then use this bound as the distribution ofW * . This yields the following corollary.", "publication_ref": ["b36"], "figure_ref": [], "table_ref": []}, {"heading": "Corollary 5.3 (Analytic Version of Main Result", "text": "). Let M : {\u22121, +1} m \u2192 [\u22121, +1] m satisfy (\u03b5, \u03b4)-DP. Let S \u2208 {\u22121, +1} m be uniformly random. Let T = M (S) \u2208 [\u22121, +1] m . Suppose P [ T 2 \u2264 r 2 ] = 1 and P [ T 1 \u2264 r 1 ] = 1. Then, for all v \u2265 e \u03b5 e \u03b5 +1 \u2022 r 1 + 2, we have P S\u2190{\u22121,+1} m T \u2190M (S) m i max{0, T i \u2022 S i } \u2265 v \u2264 f (v) + 2m \u2022 \u03b4 \u2022 max f (v \u2212 i) \u2212 f (v) i : i \u2208 [m] (10) \u2264 f (v) + 2m\u03b4 \u2022 max 2 v \u2212 e \u03b5 e \u03b5 +1 r 1 , f 1 2 v + e \u03b5 e \u03b5 + 1 r 1 ,(11)\nwhere\nf (v) := exp \u22122 r 2 2 v \u2212 e \u03b5 e \u03b5 +1 r 1 2 if v \u2265 e \u03b5 e \u03b5 +1 r 1 1 if v < e \u03b5 e \u03b5 +1 r 1 .\nIn particular, if we substitute v = e \u03b5 e \u03b5 +1 r 1 + r 2 \u2022 1 2 log(1/\u03b2) into Equation 11, we get\nP S\u2190{\u22121,+1} m T \u2190M (S) m i max{0, T i \u2022 S i } \u2265 v \u2264 \u03b2 + 2m \u2022 \u03b4 \u2022 max \uf8f1 \uf8f2 \uf8f3 1 r 2 1 2 log(1/\u03b2) , \u03b2 1/4 \uf8fc \uf8fd \uf8fe .(12)\nProof. Fix an arbitrary t the support of T . DefineW (t) :\n= m i\u0160 i |t i | for\u0160 \u2190 Bernoulli e \u03b5 e \u03b5 +1 m .\nThen E W (t) = e \u03b5 e \u03b5 +1 t 1 . By Hoeffding's inequality, for all \u03bb \u2265 0,\nP W (t) \u2265 e \u03b5 e \u03b5 + 1 t 1 + \u03bb \u2264 exp \u22122\u03bb 2 t 2 2 . Now defineW * by P W * \u2265 v := f (v) := exp \u22122 r 2 2 v \u2212 e \u03b5 e \u03b5 +1 r 1 2 if v \u2265 e \u03b5 e \u03b5 +1 r 1 1 if v < e \u03b5 e \u03b5 +1 r 1 .\nSinceW * stochastically dominatesW (t) for all t in the support of T , we can apply Theorem 5.2 to obtain the first part of the result (10).\nNext, for any c \u2265 1, we have\nmax f (v \u2212 i) \u2212 f (v) i : i \u2208 [m] \u2264 max f (v \u2212 x) x : x \u2208 [1, \u221e) (f (v) \u2265 0 and [m] \u2282 [1, \u221e)) = max max f (v \u2212 x) x : x \u2208 [1, c] , max f (v \u2212 x) x : x \u2208 [c, \u221e) \u2264 max max f (v \u2212 x) 1 : x \u2208 [1, c] , max 1 x : x \u2208 [c, \u221e) = max f (v \u2212 c), 1 c . Setting c = 1 2 v \u2212 e \u03b5 e \u03b5\n+1 r 1 yields the second part of the result (11) In the next corollary we restrict M to ternary outputs, so it must either guess (T i = \u00b11) or abstain (T i = 0). We bound the number of guesses by r. In this case the dominating distributionW * is a binomial distribution, which is relatively easy to compute. This is the form of Theorem 5.2 that we use in all of our experimental results. We provide pseudocode in Appendix D.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Corollary 5.4 (Ternary Guesses). Let", "text": "M : {\u22121, +1} m \u2192 {\u22121, 0, +1} m satisfy (\u03b5, \u03b4)- DP. Let S \u2208 {\u22121, +1} m be uniformly random. Let T = M (S) \u2208 {\u22121, 0, +1} m . Suppose P [ T 1 \u2264 r] = 1. Then, for all v \u2208 R, P S\u2190{\u22121,+1} m T \u2190M (S) m i max{0, T i \u2022 S i } \u2265 v \u2264 f (v)+2m\u2022\u03b4\u2022max f (v \u2212 i) \u2212 f (v) i : i \u2208 {1, 2, \u2022 \u2022 \u2022 , m} ,\nwhere\nf (v) := P W \u2190Binomial(r, e \u03b5 e \u03b5 +1 ) W \u2265 v .\nNow we delve into the proof of Theorem 5.2. We use a decomposition result of Kairouz, Oh, and Viswanath [KOV15] (see also [MV15] & [Ste22, Corollary 24]).\nLemma 5.5. Let P and Q be probability distributions over Y. Fix \u03b5, \u03b4 \u2265 0. Suppose that, for all measurable S \u2282 Y, we have P (S) \u2264 e \u03b5 \u2022 Q(S) + \u03b4 and Q(S) \u2264 e \u03b5 P (S) + \u03b4.\nThen there exist \u03b4 \u2208 [0, \u03b4] and distributions P , Q , P , and Q over Y such that the following three properties are all satisfied. First, we can express P and Q as convex combinations:\nP = (1 \u2212 \u03b4 )P + \u03b4 P , Q = (1 \u2212 \u03b4 )Q + \u03b4 Q .\nSecond, for all measurable S \u2282 Y, we have e \u2212\u03b5 P (S) \u2264 Q (S) \u2264 e \u03b5 P (S). Third, there exist measurable S, T \u2282 Y such that P (S) = 1, Q (T ) = 1, \u2200S \u2282 S P (S ) \u2265 Q(S ), and \u2200T \u2282 T Q(T ) \u2265 P (T ).\nProof. This proof follows that of Steinke [Ste22]. We begin with some formalities: Fix some base measure such that P and Q are absolutely continuous with respect to the base measure. (If P and Q are discrete distributions, this can be the counting measure. If they are continuous distributions, this can be the Lebesgue measure. In general, P + Q serves as such a measure.) For y \u2208 Y, let P (y) and Q(y) denote the Radon-Nikodym derivative of P and, respectively, Q with respect to this base measure.\nIf e \u2212\u03b5 \u2022 Q(S) \u2264 P (S) \u2264 e \u03b5 \u2022 Q(S) for all measurable S, then the result follows trivially by setting \u03b4 = 0, P = P and Q = Q, and choosing P and Q to be arbitrary distributions supported on S = {y \u2208 Y : P (y) \u2265 Q(y)} and T = {y \u2208 Y : P (y) \u2264 Q(y)} respectively. Thus we assume that this is not the case and, hence, that \u03b4 > 0 and d TV (P, Q) > 0.\nSimilarly, if \u03b4 \u2265 1 and d TV (P, Q) = 1, then the result follows trivially by setting \u03b4 = 1, P = P , Q = Q, and P = Q arbitrary. Thus we assume that min{\u03b4, d TV (P, Q)} < 1.\nFix \u03b5 1 , \u03b5 2 \u2208 [0, \u03b5] to be determined later. Define distributions P , P , Q , and Q (in terms of their Radon-Nikodym derivatives) as follows. For all points y \u2208 Y,\nP (y) = min{P (y), e \u03b5 1 \u2022 Q(y)} 1 \u2212 \u03b4 1 , P (y) = P (y) \u2212 (1 \u2212 \u03b4 1 )P (y) \u03b4 1 = max{0, P (y) \u2212 e \u03b5 1 \u2022 Q(y)} \u03b4 1 , Q (y) = min{Q(y), e \u03b5 2 \u2022 P (y)} 1 \u2212 \u03b4 2 , Q (y) = Q(y) \u2212 (1 \u2212 \u03b4 2 )Q (y) \u03b4 2 = max{0, Q(y) \u2212 e \u03b5 2 \u2022 P (y)} \u03b4 2 ,\nwhere \u03b4 1 , \u03b4 2 \u2208 (0, 1) are appropriate normalizing constants. (We will choose \u03b5 1 to avoid \u03b4 1 \u2208 {0, 1} and, likewise, we will choose \u03b5 2 to avoid \u03b4 2 \u2208 {0, 1}.) By construction, (1 \u2212 \u03b4 1 )P + \u03b4 1 P = P and (1 \u2212 \u03b4 2 )Q + \u03b4 2 Q = Q, so the first property is satisfied. Note that P is supported on S = {y \u2208 Y : P (y) > e \u03b5 1 \u2022 Q(y)} and Q is supported on T = {y \u2208 Y : Q(y) > e \u03b5 2 \u2022 P (y)}, which implies the third property.\nIf 0 < \u03b4 1 = \u03b4 2 \u2264 \u03b4, then we have the appropriate decomposition (with \u03b4 = \u03b4 1 = \u03b4 2 ) and, for all y \u2208 Y, we have\ne \u2212\u03b5 \u2264 e \u2212\u03b5 2 \u2264 P (y) Q (y) = min{P (y), e \u03b5 1 \u2022 Q(y)} min{Q(y), e \u03b5 2 \u2022 P (y)} \u2264 e \u03b5 1 \u2264 e \u03b5 ,\nas required for the second property.\nIt only remains to show that we can ensure that 0\n< \u03b4 1 = \u03b4 2 \u2264 \u03b4 by appropriately setting \u03b5 1 , \u03b5 2 \u2208 [0, \u03b5]. We have \u03b4 1 = Y max{0, P (y) \u2212 e \u03b5 1 \u2022 Q(y)}dy = S P (y) \u2212 e \u03b5 1 \u2022 Q(y)dy = P (S) \u2212 e \u03b5 1 Q(S), where S = {y \u2208 Y : P (y) \u2265 e \u03b5 1 \u2022 Q(y)}. If \u03b5 1 = \u03b5, then \u03b4 1 \u2264 \u03b4 by assumption. If \u03b5 1 = 0, then \u03b4 1 = d TV (P, Q) > 0. By decreasing \u03b5 1 , we continuously increase \u03b4 1 . Thus, by starting at \u03b5 1 = \u03b5 and decreasing \u03b5 1 until either \u03b5 1 = 0 or \u03b4 1 = \u03b4, we can pick \u03b5 1 \u2208 [0, \u03b5] such that \u03b4 1 = min{\u03b4, d TV (P, Q)} \u2208 (0, 1). Similarly, we can pick \u03b5 2 \u2208 [0, \u03b5], such that \u03b4 2 = min{\u03b4, d TV (P, Q)}.\nWe need a Bayesian version of this decomposition. I.e., suppose we observe a sample from either P or Q and we have a prior on these two possibilities, what is the posterior distribution on possibilities? The following gives such a result. However, it introduces an event E P,Q . Intuitively, when E P,Q (Y ) = 1, then we get the result we would get under pure DP. But E P,Q (Y ) = 0 with probability \u03b4, in which case things can fail arbitrarily.\nKasiviswanathan and Smith [KS14, Lemma 3.4] provide a similar result. Ours improves the constant factors and is also stated slightly differently.\nLemma 5.6. Let P and Q be probability distributions over Y. Fix \u03b5, \u03b4 \u2265 0. Suppose that, for all measurable S \u2282 Y, we have P (S) \u2264 e \u03b5 \u2022 Q(S) + \u03b4 and Q(S) \u2264 e \u03b5 P (S) + \u03b4.\nThen there exists a randomized function E P,Q : Y \u2192 {0, 1} with the following properties. Fix p \u2208 [0, 1] and suppose X \u2190 Bernoulli(p). If X = 1, sample Y \u2190 P ; and, if X = 0, sample Y \u2190 Q. Then, for all y \u2208 Y, we have\nP X\u2190Bernoulli(p) Y \u2190XP +(1\u2212X)Q [X = 1 \u2227 E P,Q (Y ) = 1|Y = y] \u2264 p p + (1 \u2212 p)e \u2212\u03b5 .\nFurthermore,\nE Y \u2190P [E P,Q (Y )] \u2265 1 \u2212 \u03b4 and E Y \u2190Q [E P,Q (Y )] \u2265 1 \u2212 \u03b4.\nProof. We apply the decomposition from Lemma 5.5: There exist distributions P , Q , P , and Q over Y and \u03b4 \u2208 [0, \u03b4] such that\nP = (1 \u2212 \u03b4 )P + \u03b4 P , Q = (1 \u2212 \u03b4 )Q + \u03b4 Q ,\nand, for all y \u2208 Y, e \u2212\u03b5 P (y) \u2264 Q (y) \u2264 e \u03b5 P (y) and P (y) > 0 =\u21d2 P (y) \u2265 Q(y) and Q (y) > 0 =\u21d2 P (y) \u2264 Q(y). (Here P (\u2022) denotes the Radon-Nikodym derivative of the distribution P with respect to some appropriate base measure and similarly for the other distributions.)\nWe define E P,Q : Y \u2192 {0, 1} by\nP [E P,Q (y) = 1] = (1 \u2212 \u03b4 ) \u2022 P (y) P (y) = 1 \u2212 \u03b4 \u2022 P (y) P (y) .\nClearly, E\nY \u2190P,E P,Q [E P,Q (Y )] = Y P (y)P [E P,Q (Y ) = 1]dy = Y (1 \u2212 \u03b4)P (y)dy = 1 \u2212 \u03b4 \u2265 1 \u2212 \u03b4. Also E Y \u2190Q [E P,Q (Y )] = 1 \u2212 \u03b4 E Y \u2190Q P (y) P (y) = 1 \u2212 \u03b4 Y Q(y) P (y) \u2022 P (y)dy \u2265 1 \u2212 \u03b4 Y P (y)dy = 1 \u2212 \u03b4 \u2265 1 \u2212 \u03b4,\nsince P (y) > 0 =\u21d2 P (y) \u2265 Q(y). For any y \u2208 Y, we have\nP [X = 1 \u2227 E P,Q (Y ) = 1|Y = y] = P [X = 1|Y = y] \u2022 P [E P,Q (y) = 1] = P [Y = y|X = 1] \u2022 P [X = 1] P [Y = y] \u2022 P [E P,Q (y) = 1] = P (y) \u2022 p pP (y) + (1 \u2212 p)Q(y) \u2022 P [E P,Q (y) = 1] = p(1 \u2212 \u03b4 )P (y) + p\u03b4 P (y) p(1 \u2212 \u03b4 )P (y) + p\u03b4 P (y) + (1 \u2212 p)(1 \u2212 \u03b4 )Q (y) + (1 \u2212 p)\u03b4 Q (y) \u2022 P [E P,Q (y) = 1] = p + p \u03b4 P (y) (1\u2212\u03b4 )P (y) p + p \u03b4 P (y) (1\u2212\u03b4 )P (y) + (1 \u2212 p) Q (y) P (y) + (1 \u2212 p) \u03b4 Q (y)\n(1\u2212\u03b4 )P (y)\n\u2022\nP [E P,Q (y) = 1] = p + p \u03b4 1\u2212\u03b4 P (y) P (y) p + (1 \u2212 p) Q (y) P (y) + \u03b4 1\u2212\u03b4 \u2022 pP (y)+(1\u2212p)Q (y) P (y) \u2022 P [E P,Q (y) = 1] \u2264 p + p \u03b4 1\u2212\u03b4 P (y) P (y) p + (1 \u2212 p)e \u2212\u03b5 + 0 \u2022 P [E P,Q (y) = 1] = p p + (1 \u2212 p)e \u2212\u03b5 \u2022 1 + \u03b4 1 \u2212 \u03b4 P (y) P (y) \u2022 P [E P,Q (y) = 1] = p p + (1 \u2212 p)e \u2212\u03b5 \u2022 P (y) (1 \u2212 \u03b4 )P (y) \u2022 P [E P,Q (y) = 1] = p p + (1 \u2212 p)e \u2212\u03b5 .\nNow we can prove an analog of Proposition 5.1 for the (\u03b5, \u03b4)-DP setting.\nProposition 5.7 (General Form of Main Result). Let M : {\u22121, +1} m \u2192 [\u22121, +1] m sat- isfy (\u03b5, \u03b4)-DP. Let S \u2208 {\u22121, +1} m be m independent samples from 2Bernoulli(p)\u22121 -i.e., P [S i = 1] = p independently for each i \u2208 [m]. Let T = M (S) \u2208 [\u22121, +1] m . Then, for all v \u2208 R and all t \u2208 [\u22121, +1] m , P S\u2190(2Bernoulli(p)\u22121) m , T \u2190M (S) m i max{0, T i \u2022 S i } \u2265 v T = t \u2264 P S + \u2190Bernoulli ( p\u2022e \u03b5 p\u2022e \u03b5 +1\u2212p ) m S \u2212 \u2190Bernoulli ( (1\u2212p)\u2022e \u03b5 (1\u2212p)\u2022e \u03b5 +p ) m ,F \uf8ee \uf8f0 F (t) + i\u2208[m]:t i >0 t i \u2022\u0160 + i + i\u2208[m]:t i <0 \u2212t i \u2022\u0160 \u2212 i \u2265 v \uf8f9 \uf8fb ,\nwhere\nF : [\u22121, 1] m \u2192 {0, 1, \u2022 \u2022 \u2022 , m} is independent from\u0160 + and\u0160 \u2212 and satisfies E T,F [F (T )] \u2264 2m \u2022 \u03b4. Proof. For i \u2208 [m] \u222a {0} and s \u2264i \u2208 {\u22121, 1} i , let M (s \u2264i ) denote the distribution on [\u22121, 1] m\nobtained by conditioning M (S) on S \u2264i = s \u2264i . We can express this as a convex combination:\nM (s \u2264i ) = s >i \u2208{\u22121,1} m\u2212i M (s \u2264i , s >i ) \u2022 P S >i \u2190(2Bernoulli(p)\u22121) m\u2212i [S >i = s >i ].\nFor distributions P and Q on [\u22121, 1] m , let E P,Q : [\u22121, 1] m \u2192 {0, 1} be the randomized function promised by Lemma 5.6. In our analysis, the internal randomness of E P,Q is independent from everything else -i.e., the only dependence is induced by its input. Specifically, for all i \u2208 [m], all s <i \u2208 {\u22121, 1} i\u22121 , and all t \u2208 [\u22121, 1] m , we have\nP S\u2190(2Bernoulli(p)\u22121) n , T \u2190M (S),E S i = 1 \u2227 E M (s <i ,1),M (s <i ,\u22121) (T ) = 1 S <i = s <i , T = t \u2264 p \u2022 e \u03b5 p \u2022 e \u03b5 + 1 \u2212 p , E S\u2190(2Bernoulli(p)\u22121) n , T \u2190M (S),E E M (s <i ,1),M (s <i ,\u22121) (T ) S \u2264i = (s <i , 1) \u2265 1 \u2212 \u03b4, E S\u2190(2Bernoulli(p)\u22121) n , T \u2190M (S),E E M (s <i ,1),M (s <i ,\u22121) (T ) S \u2264i = (s <i , \u22121) \u2265 1 \u2212 \u03b4.\nSymmetrically, for all i \u2208 [m], all s <i \u2208 {\u22121, 1} i\u22121 , and all t \u2208 [\u22121, 1] m , we have\nP S\u2190(2Bernoulli(p)\u22121) n , T \u2190M (S),E S i = \u22121 \u2227 E M (s <i ,\u22121),M (s <i ,1) (T ) = 1 S <i = s <i , T = t \u2264 (1 \u2212 p) \u2022 e \u03b5 (1 \u2212 p) \u2022 e \u03b5 + p , E S\u2190(2Bernoulli(p)\u22121) n , T \u2190M (S),E E M (s <i ,\u22121),M (s <i ,1) (T ) S \u2264i = (s <i , \u22121) \u2265 1 \u2212 \u03b4, E S\u2190(2Bernoulli(p)\u22121) n , T \u2190M (S),E E M (s <i ,\u22121),M (s <i ,1) (T ) S \u2264i = (s <i , 1) \u2265 1 \u2212 \u03b4.\nFor simplicity, we define a symmetric event: E Q P (y) = E P Q (y) := E P,Q (y) \u2022 E Q,P (y), where the internal randomnesses are again independent. Combining these, we have, for all\ni \u2208 [m], all s <i \u2208 {\u22121, 1} i\u22121 , and all t \u2208 [\u22121, 1] m , P S\u2190(2Bernoulli(p)\u22121) n , T \u2190M (S),E S i = sign(T i )\u2227E M (s <i ,\u22121) M (s <i ,1) (T ) = 1 T = t, S <i = s <i \u2264 p\u2022e \u03b5 p\u2022e \u03b5 +1\u2212p if t i > 0 (1\u2212p)\u2022e \u03b5 (1\u2212p)\u2022e \u03b5 +p if t i < 0 and, for b \u2208 {\u22121, 1}, we have E S\u2190(2Bernoulli(p)\u22121) n , T \u2190M (S),E E M (s <i ,1) M (s <i ,\u22121) (T ) S \u2264i = (s <i , b) \u2265 1 \u2212 2\u03b4. For k \u2208 [m], s \u2208 {\u22121, 1} m , and t \u2208 [\u22121, 1] m , define W k (s, t) := i\u2208[k] max{0, t i \u2022 s i } \u2022 E M (s <i ,\u22121) M (s <i ,1) (t) = i\u2208[k] |t i | \u2022 I[s i = sign(t i ) \u2227 E M (s <i ,\u22121) M (s <i ,1) (t) = 1] andW k (t) = i\u2208[k]\u0160 i (t) \u2022 |t i |,\nwhere, for each\ni \u2208 [k] independently,\u0160(t) i \u2190 Bernoulli( p\u2022e \u03b5 p\u2022e \u03b5 +1\u2212p ) if t i > 0 and\u0160(t) i \u2190 Bernoulli( (1\u2212p)\u2022e \u03b5\n(1\u2212p)\u2022e \u03b5 +p ) if t i < 0. By induction and Lemma 4.9, for any k \u2208 [m] and t \u2208 [\u22121, 1] m , the conditional distribution ( W k (S, t)|M (S) = t) where S \u2190 (2Bernoulli(p) \u2212 1) m is stochastically dominated by W k (t).\nFor\ns \u2208 {\u22121, 1} m and t \u2208 [\u22121, 1] m , define F (s, t) := m i I E M (s <i ,\u22121) M (s <i ,1) (t) = 0 , so that W m (s, t) := i\u2208[m] max{0, t i \u2022 s i } \u2264 W m (s, t) + F (s, t). Since the conditional distribution ( W k (S, t)|M (S) = t) where S \u2190 (2Bernoulli(p) \u2212 1) m is stochastically dominated byW k (t), W m is stochastically dominated by the convolutio\u0148 W m (T ) + F (S, T ). Finally F (s, t) is supported on {0, 1, \u2022 \u2022 \u2022 , m} and E [F (s, t)] = m i P E M (s <i ,\u22121) M (s <i ,1) (T ) = 0 \u2264 2m \u2022 \u03b4.\nSinceW m (T ) does not depend on S, the input S does not contribute to the dependence between F (S, T ) andW m (T ), so we can elide this input in the statement -i.e., F (T ) = F (S, T ) for S drawn from an appropriate distribution.\nProposition 5.7 is rather unwieldy. It can be simplified by setting p = 1 2 and identifying the optimal distribution F (T ), which yields Theorem 5.2.", "publication_ref": ["b26", "b33", "b39"], "figure_ref": [], "table_ref": []}, {"heading": "Proof of Theorem 5.2. Let", "text": "M : {\u22121, 1} m \u2192 [\u22121, 1] m satisfy (\u03b5, \u03b4)-DP. Let S \u2208 {\u22121, 1} m be uniformly random. Let T = M (S) \u2208 [\u22121, 1] m . Setting p = 1\n2 in Proposition 5.7 and averaging over T , we have, for all v \u2208 Z,\nP S\u2190{\u22121,1} m T \u2190M (S) m i max{0, T i \u2022 S i } \u2265 v \u2264 P S\u2190{\u22121,1} m ,T \u2190M (S), S\u2190Bernoulli ( e \u03b5 e \u03b5 +1 ) m ,F F (T ) + m i\u0160 i \u2022 |T i | \u2265 v ,\nwhere F is arbitrary -but independent from\u0160 -except for the constraints that F (T ) is supported on {0, 1, \u2022 \u2022 \u2022 , m} and E [F (T )] \u2264 2m \u2022 \u03b4.\nGiven these constraints, we can formulate finding the optimal distribution F (t) for a given t \u2208 [\u22121, 1] m and v \u2208 R as a linear program:\nmaximize P W ,F W (t) + F (t) \u2265 v = m i=0 P F [F (t) = i] \u2022 P W W (t) \u2265 v \u2212 i subject to E F [F (t)] = m i=0 P F [F (t) = i] \u2022 i \u2264 2m \u2022 \u03b4, m i=0 P F\n[F (t) = i] = 1, and\nP F [F (t) = i] \u2265 0 \u2200i \u2208 {0, 1, \u2022 \u2022 \u2022 , m}, whereW (t) := m i\u0160 i |t i | for\u0160 \u2190 Bernoulli e \u03b5 e \u03b5 +1 m .\nBy strong duality, the linear program above has the same value as its dual:\nminimize 2m\u03b4\u03b1 + \u03b2 subject to \u03b1 \u2022 i + \u03b2 \u2265 P W W (t) \u2265 v \u2212 i \u2200i \u2208 {0, 1, \u2022 \u2022 \u2022 , m}, \u03b1 \u2265 0.\nAny feasible solution to the dual gives an upper bound on the primal. So, in particular, we can use the solution given by\n\u03b2 = P W * W * \u2265 v , \u03b1 = max {0} \u222a 1 i P W * W * \u2265 v \u2212 i \u2212 \u03b2 : i \u2208 {1, 2, \u2022 \u2022 \u2022 , m} ,\nwhereW * is a distribution on R that satisfies P\nW * W * \u2265 v \u2212 i \u2265 P W W (t) \u2265 v \u2212 i for all i \u2208 {0, 1, \u2022 \u2022 \u2022\n, m} and all t in the support of T .\nTheorem 5.2 gives a worst-case bound in terms of T . Specifically,W * must uniformly boundW (t) for all t in the support of T . Proposition 5.7 is more general than this. Thus we give another corollary that allows us to have the bound adjust to T . In particular, this result allows the auditing procedure (Algorithm 1 or 3) to dynamically choose the number of guesses r = k + + k \u2212 .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Corollary 5.8 (Variant of Main Result", "text": "). Let M : {\u22121, +1} m \u2192 [\u22121, +1] m satisfy (\u03b5, \u03b4)- DP. Let S \u2208 {\u22121, +1} m be uniformly random. Let T = M (S) \u2208 [\u22121, +1] m . Then, for all \u03b3 \u2208 [0, 1] and \u03c4 > 0, P S\u2190{\u22121,+1} m T \u2190M (S) m i max{0, T i \u2022 S i } \u2265 g m,\u03b5 (T, \u03b3) + \u03c4 \u2264 \u03b3 + 2m\u03b4 \u03c4 , where g m,\u03b5 : [\u22121, +1] m \u00d7 [0, 1] \u2192 R is an arbitrary function satisfying \u2200t \u2208 [\u22121, 1] m \u2200\u03b3 \u2208 [0, 1] P S\u2190Bernoulli( e \u03b5 e \u03b5 +1 ) m m i |t i | \u2022\u0160 i \u2265 g m,\u03b5 (t, \u03b3) \u2264 \u03b3.\nProof. Setting p = 1 2 in Proposition 5.7 yields\n\u2200v \u2208 R \u2200t \u2208 [\u22121, +1] m P S\u2190{\u22121,+1} m T \u2190M (S) m i max{0, T i \u2022 S i } \u2265 v T = t \u2264 P S\u2190Bernoulli( e \u03b5 e \u03b5 +1 ),F F (t) + m i |t i | \u2022\u0160 i \u2265 v ,\nwhere\nF : [\u22121, 1] m \u2192 {0, 1, \u2022 \u2022 \u2022 , m} satisfies E S\u2190{\u22121,+1} m T \u2190M (S),F [F (T )] \u2264 2m\u03b4.\nBy a union bound and Markov's inequality, we have, for all t \u2208 [\u22121, 1] m , all \u03b3 \u2208 [0, 1], and all \u03c4 > 0,\nP S\u2190Bernoulli( e \u03b5 e \u03b5 +1 ),F F (t) + m i |t i | \u2022\u0160 i \u2265 g m,\u03b5 (t, \u03b3) + \u03c4 \u2264 P S\u2190Bernoulli( e \u03b5 e \u03b5 +1 ),F \u03c4 + m i |t i | \u2022\u0160 i \u2265 g m,\u03b5 (t, \u03b3) + \u03c4 + P F [F (t) > \u03c4 ] \u2264 P S\u2190Bernoulli( e \u03b5 e \u03b5 +1 ),F m i |t i | \u2022\u0160 i \u2265 g m,\u03b5 (t, \u03b3) + E F [F (t)] \u03c4 \u2264 \u03b3 + E F [F (t)]\n\u03c4 .\nWe combine inequalities, set v = g m,\u03b5 (t, \u03b3) + \u03c4 , and average over T to obtain\n\u2200\u03b3 \u2208 [0, 1] \u2200\u03c4 > 0 P S\u2190{\u22121,+1} m T \u2190M (S) m i max{0, T i \u2022 S i } \u2265 g m,\u03b5 (T, \u03b3) + \u03c4 \u2264 \u03b3 + E S\u2190{\u22121,+1} m T \u2190M (S),F [F (T )] \u03c4 \u2264 \u03b3 + 2m\u03b4 \u03c4 .\nAlgorithm 3 DP-SGD Auditor (Instantiation of Algorithm 1) \nFor i \u2208 [m] sample S i \u2208 {\u22121, +1} independently with E [S i ] = 0. Set S i = 1 for all i \u2208 [n] \\ [m]. 4: Split x into x IN \u2208 X nIN and x OUT \u2208 X nOUT according to S, where n IN + n OUT = n. Namely, if S i = 1,\nthen x i is in x IN ; and, if S i = \u22121, then x i is in x OUT . 5: Run DP-SGD (Algorithm 2) on input x IN with appropriate parameters. 6: Let be the number of iterations and let f : R d \u00d7 X \u2192 R be the loss. 7: Let w 0 , \u2022 \u2022 \u2022 , w \u2208 R d be the output of DP-SGD. 8: if audit-type = black-box then 9:\nDefine Score(x i , w ) = (w 0 , x i ) \u2212 (w , x i ) for all i \u2208 [m]. 10:\nCompute the vector of scores Y = Score(x i , w ) : i \u2208 [m] \u2208 R m . 11: else if audit-type = white-box then 12:\nprocedure Score(x * , w 1 , \u2022 \u2022 \u2022 , w ) 13:\nfor t = 1, \u2022 \u2022 \u2022 , do 14:\nCompute g t = \u2207 wt\u22121 (w t\u22121 , x * ) \u2208 R d .\n15:\nClip\u011d t = min 1, c g t 2 \u2022 g t \u2208 R d .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "16:", "text": "Let v t = w t\u22121 \u2212 w t ,\u011d t \u2208 R.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "17:", "text": "end for 18:\nReturn t=1 v t \u2208 R.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "19:", "text": "end procedure 20:\nCompute the vector of scores Y = Score(x i , w \n0 , w 1 , \u2022 \u2022 \u2022 , w ) : i \u2208 [m] \u2208 R m . 21: end if 22: Sort the scores Y . Let T \u2208 {\u22121, 0, +1} m be", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Experiments", "text": "Experiment Setup Our contributions are focused on improved analysis of an existing privacy attack, and are therefore orthogonal to the design of an attack. As a result, we rely on the experimental setup of the recent auditing procedure of Nasr, Hayes, Steinke, Balle, Tram\u00e8r, Jagielski, Carlini, and Terzis [NHSBTJCT23].\nWe run DP-SGD on the CIFAR-10 dataset with Wide ResNet (WRN-16) [ZK16], we followed the experimental setup from Nasr et al. [NHSBTJCT23]. Our experiments reach 76% test accuracy at (\u03b5 = 8, \u03b4 = 10 \u22125 )-DP, which is comparable with the state-of-theart [DBHSB22]. Unless specified otherwise, all lower bounds are presented with 95% confidence. Following Nasr et al. [NHSBTJCT23], we refer to the setting where the adversary has access to all intermediate steps as \"white-box\" and when the adversary can only see the last iteration as \"black-box.\" We experiment with both settings.\nAlgorithm 3 summarizes our approach for auditing DP-SGD. The results are converted into lower bounds on the privacy parameters using Theorem 5.2 / Corollary 5.4.\nWe also experiment with both the gradient and input attacks proposed by Nasr et al. [NHSBTJCT23]. In particular, for the gradient attack we use the strongest attack they proposed -the \"Dirac canary\" approach -which sets all gradients to zero except at a single random index. In our setting where we need to create multiple auditing examples (canaries) we make sure the indices selected in our experiments do not have any repetitions. To compute the score for gradient space attacks, we use the dot product between the gradient update and auditing gradient. When auditing in input space, we leverage two different types of injected examples as:\n1. Mislabeled example: We select a random subset of the test set and randomly relabel them (ensuring the new label is not the same as the original label).\n2. In-distribution example: We select a random subset of the test set.\nFor input space audits, we use the loss of the input example as the score. In our experiments we report the attack with the highest lower bound.\nIn our experiments, we evaluate different values of k + and k \u2212 and only report the highest auditing results. Since this is doing multiple hypothesis testing on the same data, we are reducing the confidence value of our results. However, this is commonly used in the previous works [ZBWTSRPNK22; MSS22] and can be easily improved by using a different set of observations to select the parameters for the auditing and another set of the data for the auditing itself (see also Corollary 5.8).", "publication_ref": ["b34", "b34", "b9", "b34", "b34"], "figure_ref": [], "table_ref": []}, {"heading": "Gradient Space attacks", "text": "We start with the strongest attack: We assume white-box access -i.e., the auditor sees all intermediate iterates of DP-SGD -and that the auditor can insert examples with arbitrary gradients into the training procedure. First, we evaluate the effect of the number of the auditing example on the tightness. Figure 4  Our auditing framework can achieve meaningful empirical privacy lower bounds for SoTA models.\nincreases, the auditing becomes tighter. However, the impact of the additional examples eventually diminishes. Intriguingly, adding more non-auditing training examples (resulting in a larger n compared to m) does not seem to influence the tightness of the auditing, as depicted in Figure 5. This can be primarily due to the fact that gradient attacks proposed in prior studies can generate near-worst-case datasets, irrespective of the presence of other data points.\nAnother parameter that might affect the auditing results is the number of iterations in the DP-SGD algorithm. As shown in Figure 6 we compare the extreme setting of having one iteration to multiple iterations and we do not observe any significant difference in the auditing when auditing for the equivalent privacy guarantees (by increasing the noise). The results confirm the tightness of composition and that the number of iterations does not have significant effect on auditing in white-box setting. Now we directly use the parameters used in the training CIFAR10 models. Figure 7 summarizes results for the CIFAR10 models. We used m = 5000 and all of the training dataset from CIFAR10 (n = 50, 000) for the attack. We were able to achieve 76% accuracy for \u03b5 = 8 (\u03b4 = 10 \u22125 , compared to 78% when not auditing). We are able to achieve an empirical lower bound of 0.7, 1.2, 1.8, 3.5 for theoretical epsilon of 1, 2, 4, 8 respectively. While our results are not as tight as the prior works, we only require a single run of training which is not possible using the existing techniques. In the era of exponentially expanding machine learning models, the computational and financial costs of training these colossal architectures even once are significant. Expecting any individual or entity to shoulder the burden of training such models thousands of times for the sake of auditing or experimental purposes is both unrealistic and economically infeasible. Our method offers a unique advantage by facilitating the auditing of these models, allowing for an estimation of privacy leakage in a white-box setting without significantly affecting performance.", "publication_ref": [], "figure_ref": ["fig_13"], "table_ref": []}, {"heading": "Input Space Attacks", "text": "Now we evaluate the effect of input space attacks in the black-box setting. In this attack, the auditor can only insert actual images into the training procedure and cannot control any of the aspects of the training. Then, the adversary can observe the final model as mentioned in Algorithm 3. This is the weakest attack setting.\nFor simplicity we start with the setting where m = n; in other words, all of the examples used to train the model are randomly included or excluded and can be used for auditing. Figure 8 illustrates the result of this setting. As we see from the figure, unlike the white-box attack we do not observe a monotonic relationship between the number of auditing examples and the tightness of the auditing. Intuitively, when the number of auditing examples are low then we do not have enough observations to have high confidence lower bounds for epsilon. On the other hand, when the number of auditing examples are high, the model does not have enough capacity to \"memorize\" all of the auditing examples which reduces the tightness of the auditing. However, this can be improved by designing better black-box attacks which we reiterate in the next section.\nWe also evaluate the effect of adding additional training data to the auditing in Figure 9. We see that adding superfluous training data significantly reduces the effectiveness of auditing. The observed reduction in auditing effectiveness with the addition of more training data could be attributed to several factors. One interpretation could be that the theoretical privacy analysis in a black-box setting tends to be considerably more loose when the adversary is constrained to this setting. This could potentially result in an overestimation of the privacy bounds. Conversely, it is also plausible that the results are due to the weak black-box attacks and can be improved in the future.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Discussion", "text": "Our main contribution is showing that we can audit the differential privacy guarantees of an algorithm with a single run. In contrast, prior methods require hundreds -if not thousands -of runs, which is computationally prohibitive for all but the simplest algorithms. Our experimental results demonstrate that in practical settings our methods are able to give meaningful lower bounds on the privacy parameter \u03b5.\nHowever, while we win on computational efficiency, we lose on tightness of our lower bounds. We now illustrate the limitations of our approach and discuss the extent to which this is inherent, and what lessons we can learn.\nBut, first, we illustrate that our method can give tight lower bounds. In Figure 10, we consider an idealized setting where the number of guesses changes and the fraction that are correct is fixed at e \u03b5 e \u03b5 +1 for \u03b5 = 4 -i.e., 98.2% of guesses are correct. 4 This is the maximum expected fraction of correct guesses compatible with (4, 0)-DP. In this setting the lower bound on \u03b5 does indeed come close to 4. With 10,000 guesses we get \u03b5 \u2265 3.87 with 95% confidence.\nNote that the lower bound in Figure 10 improves as we increase the number of guesses. This is simply accounting for sampling error -to get a lower bound with 95% confidence, we must underestimate to account for the fact that the number of correct guesses may have been inflated by chance. As we get more guesses, the relative size of chance deviations reduces.\nLimitations: Next we consider a different idealized setting -one that is arguably more realistic -where our method does not give tight lower bounds. Suppose S i \u2208 {\u22121, +1} indicates whether example i \u2208 [n] is included or excluded. In Figure 11, we consider Gaussian noise addition. That is, we release a sample from N (S i , 4). (In contrast, Figure 10 considers randomized response on S i .) Lemma 4.5 gives an upper bound of (4.38, 10 \u22125 )-DP. Unlike for randomized response, abstentions matter here. We consider 100,000 examples, each of which has a score sampled from N (S i , 4), where S i \u2208 {\u22121, +1} is uniformly random. We pick the largest r/2 scores and guess S i = +1. Similarly we guess S i = \u22121 for the smallest r/2 scores. We abstain for the remaining 100, 000 \u2212 r examples. If we make more guesses (i.e., increase r), then the accuracy goes down and so does our lower bound. We must trade off between more guesses being less accurate on average and more guesses having smaller relative sampling error.\nIn Figure 11, the highest value of the lower bound is \u03b5 \u2265 2.675 for \u03b4 = 10 \u22125 , which is attained by 1439 correct guesses out of 1510. In contrast, the upper bound is \u03b5 = 4.38 for \u03b4 = 10 \u22125 . To get a matching upper bound of \u03b5 \u2264 2.675 we would need to set \u03b4 = 0.0039334. In other words, the gap between the upper and lower bounds is a factor of 393\u00d7 in \u03b4.\nFigure 12 considers the same idealized setting as Figure 11, but we fix the number of guesses to 1,500 out of 100,000 (of which 1,429 are correct); instead we vary \u03b4 and consider There are no abstentions. different confidence levels.\nAre these limitations inherent? Figures 11 & 12 illustrate the limitations of our approach. They also hint at the causes: The number of guesses versus abstentions, the \u03b4 parameter, and the confidence all have a large effect on the tightness of our lower bound.\nOur theoretical analysis is fairly tight; there is little room to improve Theorem 5.2. We argue that the inherent problem is a mismatch between \"realistic\" DP algorithms and the \"pathological\" DP algorithms for which our analysis is nearly tight. This mismatch makes our lower bound much more sensitive to \u03b4 than it \"should\" be.\nTo be concrete about what we consider pathological, consider M : {\u22121, +1} m \u2192 {\u22121, 0, +1} m defined by Algorithm 4. This algorithm satisfies (\u03b5, \u03b4)-DP and makes r guesses with m\u2212r abstentions. In the X = 1 case, the expected fraction of correct guesses is m\u03b4 r\u03b2 + 1 \u2212 m\u03b4 r\u03b2 \u2022 e \u03b5 e \u03b5 +1 . This is higher than the average fraction of correct guesses, but if we want confidence 1 \u2212 \u03b2 in our lower bound, we must consider this case, as X = 1 happens with probability \u03b2.\nIntuitively, the contribution from \u03b4 to the fraction of correct guesses should be negligible. However, we see that \u03b4 is multiplied by m/r\u03b2. That is to say, in the settings we consider, \u03b4 is multiplied by a factor on the order of 100\u00d7 or 1000\u00d7, which means \u03b4 = 10 \u22125 makes a non-negligible contribution to the fraction of correct guesses.\nIt is tempting to try to circumvent this problem by simply setting \u03b4 to be very small. However, as shown in Figure 12, the upper bound on \u03b5 also increases as \u03b4 \u2192 0.\nUnfortunately, there is no obvious general way to rule out algorithms that behave like Algorithm 4. The fundamental issue is that the privacy losses of the m examples are not Figure 11: Comparison of upper and lower bounds for idealized setting with varying number of guesses. For each example i \u2208 [m], we release S i +\u03be i , where \u03be i \u2190 N (0, 4) and S i \u2208 {\u22121, +1} is independently uniformly random and indicates whether the sample is included/excluded. For the upper bound, we compute the exact (4.38, 10 \u22125 )-DP guarantee for the Gaussian mechanism (Lemma 4.5). For the lower bound, we plot the bound of Theorem 5.2 with 95% confidence for varying numbers of guesses r. We consider a total of m = 100, 000 randomized examples; we guess T i = +1 for the largest r/2 scores and we guess T i = \u22121 for the smallest r/2 scores; we guess T i = 0 for the remaining m \u2212 r examples. The number of correct guesses is set to r \u2022 P [S i = +1|S i + \u03be i > c] , where c is a threshold such that P\n[S i + \u03be i > c] = r 2m .\nindependent; we shouldn't expect them to be independent, but we also shouldn't expect them to be pathologically dependent in reality. Directions for further work: Our work highlights several questions for further exploration:\n\u2022 Improved attacks: Our experimental evaluation uses existing attack methods. Any improvements to membership inference attacks could be combined with our results to yield improved privacy auditing.\nOne limitation of our attacks is that some examples may be \"harder\" than others and the scores we compute do not account for this. When we have many runs, we can account for the hardness of individual examples [CCNSTT22], but in our setting it is not obvious how to do this.\n\u2022 Algorithm-specific analyses: Our methods are generic -they can be applied to essentially any DP algorithm. This is a strength, but there is also the possibility that we could obtain stronger results by exploiting the structure of specific algorithms. A For each example i \u2208 [m], we release S i + \u03be i , where \u03be i \u2190 N (0, 4) and S i \u2208 {\u22121, +1} is independently uniformly random and indicates whether the sample is included/excluded. For the upper bound, we compute the exact (4.38, 10 \u22125 )-DP guarantee for the Gaussian mechanism (Lemma 4.5). For the lower bound, we plot the bound of Theorem 5.2 with 75%, 95%, and 99% confidence. We consider m = 100, 000 randomized examples and 1,500 guesses of which 1,429 are correct. This corresponds to guessing T i = +1 for the largest 750 scores, T i = \u22121 for the smallest 750 scores, and T i = 0 for the remaining 98,500 examples.\nnatural example of such structure is the iterative nature of DP-SGD. That is, we can view one run of DP-SGD as the composition of multiple independent DP algorithms which are run sequentially. \u2022 Other measures of privacy: Our theoretical analysis is tailored to the standard definition of differential privacy. But there are other definitions of differential privacy such as R\u00e9nyi DP. And, in particular, many of the upper bounds (e.g., Proposition 4.6) are stated in this language. Hence it would make sense for the lower bounds also to be stated in this language.\n\u2022 Beyond lower bounds: Privacy auditing produces empirical lower bounds on the Set T i = 0 for all i / \u2208 U . 5: Sample X \u2190 Bernoulli(\u03b2). 6: if X = 1 then 7:\nfor i \u2208 U do 8:\nIndependently sample T i \u2208 {\u22121, +1} with P [T i = s i ] = m\u03b4 r\u03b2 + 1 \u2212 m\u03b4 r\u03b2\n\u2022 e \u03b5 e \u03b5 +1 .", "publication_ref": ["b8"], "figure_ref": ["fig_0", "fig_0", "fig_0", "fig_0", "fig_0", "fig_0", "fig_0", "fig_0", "fig_0"], "table_ref": []}, {"heading": "9:", "text": "end for 10: else if X = 0 then 11:\nfor i \u2208 U do 12:\nIndependently sample T i \u2208 {\u22121, +1} with P [T i = s i ] = e \u03b5 e \u03b5 +1 .\n13:\nend for 14: end if 15: Output: T \u2208 {\u22121, 0, +1} m . privacy parameters. In contrast, mathematical analysis produces upper bounds. Both are necessarily conservative, which leaves a large gap between the upper and lower bounds. A natural question is to find some middle ground -an estimate which is neither a lower nor upper bound, but provides some meaningful estimate of the \"true\" privacy loss. However, it is unclear what kind of guarantee such an estimate should satisfy, or what interpretation the estimate should permit.\nRecall that our auditing framework starts with m examples x 1 , \u2022 \u2022 \u2022 , x m and then samples S \u2208 {\u22121, +1} m uniformly at random. Then each example x i is included in the dataset if S i = +1 and excluded if S i = \u22121. Thus flipping S i corresponds to adding or removing x i .\nInstead we can start with 2m examples x 1 , \u2022 \u2022 \u2022 , x 2m and then sample S \u2208 {\u22121, +1} m uniformly. Now, if S i = +1, we include x 2i in the dataset and, if S i = \u22121, we include x 2i\u22121 instead. Thus flipping S i corresponds to replacing x 2i with x 2i\u22121 or vice versa.\nThis alternative approach ensures that we always include m out of the 2m examples -i.e., the dataset size is not random. This still fits the formalism of our theoretical analysis ( \u00a75). However, the DP guarantee of the algorithm being audited (e.g., DP-SGD) must now be with respect to replacement of one example, rather than addition or removal. 5 The auditor also needs to change slightly; rather than being given x i and needing to guess whether or not it is included in the datsets, the auditor is given both x 2i and x 2i\u22121 and must guess which of the two is included.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B Generalization from Differential Privacy", "text": "Our analysis builds on the connection between DP and generalization [DFHPRR15b; DFH-PRR15a; BNSSSU16; FS17; JLNRSMS19]. We now extend our theoretical results ( \u00a75) to this setting. The main difference between our analysis in Section 5 and the prior work on DP and generalization is that we restrict to i.i.d. binary inputs with a uniform distribution, while prior work considers i.i.d. inputs from an arbitrary set with an arbitrary distribution. Thus the prior work is more general, but, as we now show, we can reduce the general case to the binary case. Then, for all \u03b3 \u2265 3 2 \u03b7 \u2265 0, we have\nP X\u2190P n Y \u2190A(X) [q(Y, X) \u2212 q(Y, P ) \u2265 \u03b3] \u2264 P W \u2265 (1+\u03b3\u2212 3 2 \u03b7)n 2 + 2 \u2022 e \u2212n\u03b7 2 /2 + max i\u2208[n] 2n\u03b4 i P (1+\u03b3\u2212 3 2 \u03b7)n 2 >W \u2265 (1+\u03b3\u2212 3 2 \u03b7)n 2 \u2212 i , whereW \u2190 Binomial n, e \u03b5 e \u03b5 +1\n. The proof of Theorem B.1 relies on the following technical lemma. This is using what is known as the \"ghost samples\" symmetrization technique [SZ20, Footnote 2].\nLemma B.2. Let x + , x \u2212 \u2208 X n . For s \u2208 {\u22121, +1} n , define x s \u2208 X n by x s i = x + i if s i = +1 and x s i = x \u2212 i if s i = \u22121. Let A : X n \u2192 Y be (\u03b5, \u03b4)-DP (for replacement). Let q : Y \u00d7 X \u2192 [0, 1], and denote q(y, x) = 1 n n i q(y, x i ) \u2208 [0, 1] for y \u2208 Y and x \u2208 X n .\nLet S \u2208 {\u22121, +1} be uniform. Then, for all v, r \u2265 0, x for all x \u2208 [\u22121, 1]. We define M : {\u22121, +1} n \u2192 {\u22121, +1} n as follows. The inputs x + , x \u2212 \u2208 X n are \"hardcoded\" into M and, for this analysis, we do not consider them private. Instead the input is s \u2208 {\u22121, +1} n . The algorithm M (s) first runs A(x s ) and then postprocesses the output using the hardcoded information. Specifically, given A(s) = y, the output M (s) \u2208 {\u22121, +1} n has a product distribution with M (s) i = R(q(y,\nP S\u2190{\u22121,+1} n Y \u2190A(x S ) q(Y, x S ) \u2212 q(Y, x \u2212S ) \u2265 v n \u2264 P W \u2265 v \u2212 r + n 2 + max i\u2208[n] 2n\u03b4 i P v \u2212 r + n 2 >W \u2265 v \u2212 r + n 2 \u2212 i + e \u2212r 2 /\nx + i ) \u2212 q(y, x \u2212 i )) \u2208 {\u22121, +1} for all y \u2208 Y and all i \u2208 [n]. That is, for each coordinate i \u2208 [n], we independently randomly round q(y, x + i ) \u2212 q(y, x \u2212 i ) \u2208 [\u22121, +1] to {\u22121, +1}\n, where y is the output of A(x s ). By postprocessing, M is (\u03b5, \u03b4)-DP. Thus we can apply Theorem 5.2 to M . We have, for all r, v \u2265 0,\nP S\u2190{\u22121,+1} n Y \u2190A(x S ) q(Y, x S ) \u2212 q(Y, x \u2212S ) \u2265 v n = P S\u2190{\u22121,+1} n Y \u2190A(x S ) n i q(Y, x S i ) \u2212 q(Y, x \u2212S i ) \u2265 v = P S\u2190{\u22121,+1} n Y \u2190A(x S ) n i (q(Y, x + i ) \u2212 q(Y, x \u2212 i )) \u2022 S i \u2265 v = P S\u2190{\u22121,+1} n Y \u2190A(x S ) E R n i R(q(Y, x + i ) \u2212 q(Y, x \u2212 i )) \u2022 S i \u2265 v \u2264 P S\u2190{\u22121,+1} n Y \u2190A(x S ),R n i R(q(Y, x + i ) \u2212 q(Y, x \u2212 i )) \u2022 S i \u2265 v \u2212 r + e \u2212r 2 /2n (Hoeffding & union) = P S\u2190{\u22121,+1} n T \u2190M (S) n i T i \u2022 S i \u2265 v \u2212 r + e \u2212r 2 /2n = P S\u2190{\u22121,+1} n T \u2190M (S) n i 2 max{0, T i \u2022 S i } \u2212 |T i | \u2265 v \u2212 r + e \u2212r 2 /2n (S i \u2208 {\u22121, +1}) = P S\u2190{\u22121,+1} n T \u2190M (S) n i max{0, T i \u2022 S i } \u2265 v \u2212 r + n 2 + e \u2212r 2 /2n (|T i | = 1) \u2264 P W \u2265 v \u2212 r + n 2 + max i\u2208[n] 2n\u03b4 i P v \u2212 r + n 2 >W \u2265 v \u2212 r + n 2 \u2212 i + e \u2212r 2 /2n ,\nwhereW \u2190 Binomial n, e \u03b5 e \u03b5 +1 . Note that Theorem 5.2 applies with any distributionW * satisfying\n\u2200v \u2208 R P W * > v \u2265 sup t\u2208support(M (s)) P S\u2190Bernoulli( e \u03b5 e \u03b5 +1 ) n n i\u0160 i \u2022 |t i | > v .\nIf t \u2208 support(M (s)), then |t i | = 1 for all i \u2208 [n], which impliesW satisfies this requirement. In the analysis above, we used Hoeffding's inequality to show that the sum of randomized roundings is close to (within r of) the unrounded sum with high probability and we carry this failure probability e \u2212r 2 /2n into the final result.\nProposition B.3. Let A : X n \u2192 Y be (\u03b5, \u03b4)-DP (with respect to replacement). Let q : Y \u00d7 X \u2192 [0, 1], and denote q(y, x) = 1 n n i q(y, x i ) \u2208 [0, 1] for y \u2208 Y and x \u2208 X n . Let P be a distribution on X . Then, for all \u03b3, \u03b7 \u2265 0, we have\nP X, X\u2190P n Y \u2190A(X) q(Y, X) \u2212 q(Y, X) \u2265 \u03b3 \u2264 P W \u2265 (1 + \u03b3 \u2212 \u03b7)n 2 + max i\u2208[n] 2n\u03b4 i P (1 + \u03b3 \u2212 \u03b7)n 2 >W \u2265 (1 + \u03b3 \u2212 \u03b7)n 2 \u2212 i + e \u2212n\u03b7 2 /2 , whereW \u2190 Binomial n, e \u03b5 e \u03b5 +1 .\nProof. The proof relies on Lemma B.2, which considers x + , x \u2212 \u2208 X n to be fixed. We now average the lemma over these being i.i.d. samples from P , which gives\nE X + ,X \u2212 \u2190P n \uf8ee \uf8f0 P S\u2190{\u22121,+1} n Y \u2190A(X S ) q(Y, X S ) \u2212 q(Y, X \u2212S ) \u2265 v n \uf8f9 \uf8fb \u2264 P W \u2265 v \u2212 r + n 2 + max i\u2208[n] 2n\u03b4 i P v \u2212 r + n 2 >W \u2265 v \u2212 r + n 2 \u2212 i + e \u2212r 2 /2n ,\nwhereW \u2190 Binomial n, e \u03b5 e \u03b5 +1 . Since the samples from P are independent, the coordinates of X + and X \u2212 are interchangeable, so\nP X, X\u2190P n Y \u2190A(X) q(Y, X) \u2212 q(Y, X) \u2265 \u03b3 = E X + ,X \u2212 \u2190P n \uf8ee \uf8f0 P S\u2190{\u22121,+1} n Y \u2190A(X S ) q(Y, X S ) \u2212 q(Y, X \u2212S ) \u2265 v n \uf8f9 \uf8fb for v = \u03b3n \u2265 0. Setting r = n\u03b7 yields the result.\nProof of Theorem B.1. Let X, X \u2190 P n be two independent samples. Let Y \u2190 A(X). Le\u0165 W \u2190 Binomial n, e \u03b5 e \u03b5 +1 . By Proposition B.3, for all \u03b3, \u03b7 \u2265 0, we have\nP X, X\u2190P n Y \u2190A(X) q(Y, X) \u2212 q(Y, X) \u2265 \u03b3 \u2264 P W \u2265 (1 + \u03b3 \u2212 \u03b7)n 2 + max i\u2208[n] 2n\u03b4 i P (1 + \u03b3 \u2212 \u03b7)n 2 >W \u2265 (1 + \u03b3 \u2212 \u03b7)n 2 \u2212 i + e \u2212n\u03b7 2 /2 ,\nBy Hoeffding's inequality, for all \u03b7 \u2265 0, we have\n\u2200y \u2208 Y P X\u2190P n q(y, X) \u2212 q(y, P ) \u2265 \u03b7 2 \u2264 exp(\u2212n\u03b7 2 /2).\nBy a union bound, for all \u03b3 \u2265 \u03b7 \u2265 0, we have\nP X\u2190P n Y \u2190A(X) [q(Y, X) \u2212 q(Y, P ) \u2265 \u03b3] \u2264 P X, X\u2190P n Y \u2190A(X) q(Y, X) \u2212 q(Y, P ) \u2265 \u03b3 \u2212 \u03b7/2 + P X, X\u2190P n Y \u2190A(X) q(Y, X) \u2212 q(Y, X) \u2265 \u03b7/2 .\nCombining inequalities yields the result: Note that the prior work is focused on the setting of adaptive data analysis, while we are focused on the setting of auditing. This difference is mostly cosmetic, but there is a material difference when the prior results are applied to our setting: In addition to outputting guesses, the prior works assume that the algorithm outputs a differentially private estimate of the number of correct guesses. The guarantee then is that this differentially private estimate is close to the distributional average (i.e., only half of the guesses being correct). In contrast, for auditing, we want the true number of correct guesses to be close to the distributional average and don't produce a DP estimate. We can convert between these two settings using the triangle inequality.\nP X\u2190P n Y \u2190A(X) [q(Y, X) \u2212 q(Y, P ) \u2265 \u03b3] \u2264 P W \u2265 (1 + \u03b3 \u2212 \u03b7/2 \u2212 \u03b7)n 2 + 2 \u2022 e \u2212n\u03b7 2 /2 + max i\u2208[n] 2n\u03b4 i P (1 + \u03b3 \u2212 \u03b7/2 \u2212 \u03b7)n 2 >W \u2265 (1 + \u03b3 \u2212 \u03b7/2 \u2212 \u03b7)n 2 \u2212 i .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B.1 Comparison to Prior Work on DP & Generalization", "text": "Below we state the accuracy guarantee that we compare against, followed by a corollary of Theorem B.1 that applies the triangle inequality and a union bound to ensure that it is directly comparable.\nTheorem B.4 ([JLNRSMS19, Theorem 3.5]). Let A : X n \u2192 Y \u00d7 [0, 1] be (\u03b5, \u03b4)-DP (with respect to replacement). Let P be a distribution on X . Let q :\nY \u00d7 X \u2192 [0, 1]. For x \u2208 X n and y \u2208 Y, denote q(y, x) = 1 n n i q(y, x i ) \u2208 [0, 1] and q(y, P ) = E X\u2190P [q(y, X)] \u2208 [0, 1]. Suppose P X\u2190P n (Y,Z)\u2190A(X) [|Z \u2212 q(Y, X)| \u2265 \u03b1] \u2264 \u03b2.\nThen, for any c, d > 0, we have\nP X\u2190P n (Y,Z)\u2190A(X) [|Z \u2212 q(Y, P )| > \u03b1 + e \u03b5 \u2212 1 + c + 2d] \u2264 \u03b2 c + \u03b4 d .(13)\nCorollary B.5 (Theorem B.1, triangle inequality, & union bound). Let A : X n \u2192 Y \u00d7 [0, 1] be (\u03b5, \u03b4)-DP (with respect to replacement). Let P be a distribution on X . Let q :\nY \u00d7 X \u2192 [0, 1]. For x \u2208 X n and y \u2208 Y, denote q(y, x) = 1 n n i q(y, x i ) \u2208 [0, 1] and q(y, P ) = E X\u2190P [q(y, X)] \u2208 [0, 1]. Suppose P X\u2190P n (Y,Z)\u2190M (X) [|Z \u2212 q(Y, X)| \u2265 \u03b1] \u2264 \u03b2.\nThen, for all \u03b3 \u2265 3 2 \u03b7 \u2265 0, we have\nP X\u2190P n (Y,Z)\u2190A(X) [|Z \u2212 q(Y, P )| \u2265 \u03b1 + \u03b3] \u2264 \u03b2 + P W \u2265 (1+\u03b3\u2212 3 2 \u03b7)n 2 + 2 \u2022 e \u2212n\u03b7 2 /2 + max i\u2208[n] 2n\u03b4 i P (1+\u03b3\u2212 3 2 \u03b7)n 2 >W \u2265 (1+\u03b3\u2212 3 2 \u03b7)n 2 \u2212 i , (14) whereW \u2190 Binomial n, e \u03b5 e \u03b5 +1\n. Equations 13 and 14 are directly comparable, but it is not immediately obvious how they compare. By setting \u03b4 = 0, \u03b3 = e \u03b5 \u22121 e \u03b5 +1 + c, \u03b7 = 2 5 c, and applying Hoeffding's inequality toW , we can simplify Equation 14 to\nP X\u2190P n (Y,Z)\u2190A(X) |Z \u2212 q(Y, P )| \u2265 \u03b1 + e \u03b5 \u2212 1 e \u03b5 + 1 + c \u2264 \u03b2 + 3 \u2022 e \u2212n 2 25 c 2 (15)\nFor comparison, setting \u03b4 = 0 in Equation 13gives\nP X\u2190P n (Y,Z)\u2190A(X) [|Z \u2212 q(Y, P )| > \u03b1 + e \u03b5 \u2212 1 + c] \u2264 \u03b2 c .(16)\nNow we can compare the results more easily. The e \u03b5 \u2212 1 term in the accuracy bound of Jung, Ligett, Neel, Roth, Sharifi-Malvajerdi, and Shenfeld [JLNRSMS19] is improved to e \u03b5 \u22121 e \u03b5 +1 in our result, which is an improvement by a factor of at least two. This is (arguably) the dominant term, so our result is a significant improvement. In particular, if \u03b5 \u2265 log 2, then Equation 13 gives a vacuous bound (since the value of q is always in [0, 1] anyway), while our bound can be non-vacuous for any value of \u03b5 (as e \u03b5 \u22121 e \u03b5 +1 < 1). However, there is another term in the accuracy bound -i.e., c. The failure probability either has a 1/c multiplicative factor or a 3 \u2022 e \u2212n 2 25 c 2 additive factor. How these compare depends on the value of \u03b2. To give a concrete comparison, suppose \u03b5 = 1/3, n = 2000, \u03b2 = \u03b4 = 10 \u22125 , and we want a final failure probability of 0.05; then Theorem B.4 gives an error guarantee of \u03b1 + 0.397, while Corollary B.5 gives \u03b1 + 0.308.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C Mutual Information Bounds from DP", "text": "Our framework for the theoretical analysis ( \u00a75) is inspired by that of Steinke and Zakynthinou [SZ20]. In this appendix, we use our analysis to also improve one of their results. Specifically, they show that if M : {\u22121, 1} m \u2192 Y satisfies (\u03b5, \u03b4)-DP and S \u2208 {\u22121, 1} m is uniformly random, then\nI(S; M (S)) \u2264 (e \u03b5 \u2212 1 + \u03b4) \u2022 m \u2022 log e,(17)\nwhere I(\u2022; \u2022) denotes the mutual information. 6 Prior work [DFHPRR15a;BS16] showed that, if M : X m \u2192 Y satisfies (\u03b5, 0)-DP and S \u2208 X m has as product distribution, then\nI(S; M (S)) \u2264 1 2 \u03b5 2 \u2022 m \u2022 log e. (18\n)\nThe latter result is numerically better than the former result, but only holds for pure DP.\n(The latter result is also not restricted to binary inputs. However, if we do not restrict the input at all, then it is not possible to prove bounds under approximate DP.)\nWe improve the bound to the following. 6 Throughout this paper we use natural logarithms (so log e = 1), including when defining informationtheoretic quantities like mutual information. However, it is common to use base-2 logarithms in information theory (i.e., log 2 e \u2248 1.44). To avoid confusion, the statements (outside proofs) in this section are stated in a redundant way so that they would be correct regardless of the base of the logarithm, as long as we are consistent. Since M is (\u03b5, \u03b4)-DP, we have Q t (S) \u2264 e \u03b5 \u2022 Q 1\u2212t (S) + \u03b4 for all measurable S \u2282 Y and t \u2208 {0, 1}. Thus we can apply Lemma 5.5: There exist distributions Q 0 , Q 0 , Q 1 , Q 1 on Y such that Q 0 = (1\u2212\u03b4)\u2022Q 0 +\u03b4 \u2022Q 0 and Q 1 = (1\u2212\u03b4)\u2022Q 1 +\u03b4 \u2022Q 1 and e \u2212\u03b5 \u2022Q 0 (S) \u2264 Q 1 (S) \u2264 e \u03b5 \u2022Q 0 (S) for all measurable S \u2282 Y.\nIf M : {\u22121, 1} m \u2192 Y satisfies (\u03b5, \u03b4)-DP and S \u2208 {\u22121, 1} m is uniformly random, then I(S; M (S)) \u2264 1 8 \u03b5 2 \u2022 m \u2022 log e + \u03b4 \u2022 m \u2022 log 2. (19\n)\nDefine distributions\nR 0 := e \u03b5 \u2022 Q 0 \u2212 Q 1 e \u03b5 \u2212 1 and R 1 := e \u03b5 \u2022 Q 1 \u2212 Q 0 e \u03b5 \u2212 1 , so that Q 0 = e \u03b5 \u2022R 0 +R 1 e \u03b5 +1\nand Q 1 = e \u03b5 \u2022R 1 +R 0 e \u03b5 +1 . Hence\nQ 0 = e \u03b5 (1 \u2212 \u03b4) e \u03b5 + 1 \u2022 R 0 + 1 \u2212 \u03b4 e \u03b5 + 1 \u2022 R 1 + \u03b4 \u2022 Q 0 and Q 1 = e \u03b5 (1 \u2212 \u03b4) e \u03b5 + 1 \u2022 R 1 + 1 \u2212 \u03b4 e \u03b5 + 1 \u2022 R 0 + \u03b4 \u2022 Q 1 .\nThis decomposition (which was first used by Kairouz, Oh, and Viswanath [KOV15]) states that we can view Q s i = M (s i , s \u2212i ) as a postprocessing of an (\u03b5, \u03b4)-DP randomized response on the bit s i . That is, with probability \u03b4, we output the bit s i with a flag indicating certainty; with probability e \u03b5 (1\u2212\u03b4) e \u03b5 +1 , we output s i with an uncertain flag; and, with probability \nQ 0 = e \u03b5 (1 \u2212 \u03b4) e \u03b5 + 1 , 1 \u2212 \u03b4 e \u03b5 + 1 , \u03b4, 0 , Q 1 = 1 \u2212 \u03b4 e \u03b5 + 1 , e \u03b5 (1 \u2212 \u03b4) e \u03b5 + 1 , 0, \u03b4 .\nDefine the a randomized postprocessing function F : [4] \u2192 Y by F (1) = R 0 , F (2) = R 1 , F (3) = Q 0 , and F (4) = Q 1 . Then we have F ( Q 0 ) = Q 0 and F ( Q 1 ) = Q 1 . Now we use the postprocessing property (a.k.a. the data processing inequality):\nI(S i ; M (S)|S \u2212i = s \u2212i ) = pD 1 (Q 1 Q p ) + (1 \u2212 p)D 1 (Q 0 Q p ) \u2264 pD 1 Q 1 Q p + (1 \u2212 p)D 1 Q 0 Q p .\nA tedious calculation now yields the bound: Combining inequalities and summing over i \u2208 [n] yields the first part of the result. The final part of the result is the bound\npD 1 Q 1 Q p + (1 \u2212 p)D 1 Q 0 Q p = p 1 \u2212 \u03b4 e \u03b5 +\n\u2200\u03b5 \u2265 0 g(\u03b5) := log 2 \u2212 log(1 + e \u2212\u03b5 ) \u2212 \u03b5 e \u03b5 + 1 \u2264 \u03b5 2 8 ,\nwhich can be verified by showing that g(0) = g (0) = 0 and \u2200\u03b5 \u2265 0 g (\u03b5) \u2264 1 4 (or by plotting it).", "publication_ref": ["b40", "b10", "b4", "b26"], "figure_ref": [], "table_ref": []}, {"heading": "D Implementation of Theorem 5.2", "text": "On the next page is Python pseudocode implementing Corollary 5.4. Some example usage:\n\u2022 Suppose the auditor correctly guesses v = 75 out of m = r = 100 examples, with no abstentions. We have 75 100 = 3 4 = e log 3 e log 3 +1 . So we would expect this to correspond roughly to \u03b5 = log 3 \u2248 1.09. Theorem 5.2 gives p-value of 0.553 for the null hypothesis \u03b5 \u2264 log 3 and \u03b4 = 0; to obtain this result call p value DP audit(100,100,75,math.log(3),0) in the code below. If we want 95% confidence, we obtain the lower bound \u03b5 \u2265 0.702 by calling get eps audit(100,100,75,0,0.05). If we set \u03b4 = 10 \u22124 , we obtain the weaker lower bound \u03b5 \u2265 0.699 by calling get eps audit(100,100,75,1e-4,0.05).\n\u2022 Suppose the auditor correctly guesses v = 75 out of r = 100 guesses, but with a total of m = 1000 examples. I.e., the auditor abstains on m \u2212 r = 900 examples. We obtain a lower bound of \u03b5 \u2265 0.673 for \u03b4 = 10 \u22124 and 95% confidence. (This is slightly weaker than the \u03b5 \u2265 0.699 lower bound we get when there are no abstentions.) This is obtained by calling get eps audit(1000,100,75,1e-4,0.05).\n# m = number of examples, each included independently with probability 0.5 # r = number of guesses (i.e. excluding abstentions) # v = number of correct guesses by auditor # eps,delta = DP guarantee of null hypothesis # output: p-value = probability of >=v correct guesses under null hypothesis def p_value_DP_audit(m, r, v, eps, delta): assert 0 <= v <= r <= m assert eps >= 0 assert 0 <= delta <= 1 q = 1/(1+math.exp(-eps)) # accuracy of eps-DP randomized response beta = scipy.stats.binom.sf(v-1, r, q) # = P[Binomial(r, q) >= v] alpha = 0 sum = 0 # = P[v > Binomial(r, q) >= v -i] for i in range(1, v + 1): sum = sum + scipy.stats.binom.pmf(v -i, r, q) if sum > i * alpha: alpha = sum / i p = beta + alpha * delta * 2 * m return min(p, 1) # m = number of examples, each included independently with probability 0.5 # r = number of guesses (i.e. excluding abstentions) # v = number of correct guesses by auditor # p = 1-confidence e.g. p=0.05 corresponds to 95% # output: lower bound on eps i.e. algorithm is not (eps,delta)-DP def get_eps_audit(m, r, v, delta, p): assert 0 <= v <= r <= m assert 0 <= delta <= 1 assert 0 < p < 1 eps_min = 0 # maintain p_value_DP(eps_min) < p eps_max = 1 # maintain p_value_DP(eps_max) >= p while p_value_DP_audit(m, r, v, eps_max, delta) < p: eps_max = eps_max + 1 for _ in range(30): # binary search eps = (eps_min + eps_max) / 2 if p_value_DP_audit(m, r, v, eps, delta) < p: eps_min = eps else: eps_max = eps return eps_min", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Deep learning with differential privacy", "journal": "", "year": "2016", "authors": "M Abadi; A Chu; I Goodfellow; H B Mcmahan; I Mironov; K Talwar; L Zhang"}, {"ref_id": "b1", "title": "One-shot Empirical Privacy Estimation for Federated Learning", "journal": "", "year": "2023", "authors": "G Andrew; P Kairouz; S Oh; A Oprea; H B Mcmahan; V Suriyakumar"}, {"ref_id": "b2", "title": "Dp-finder: Finding differential privacy violations by sampling and optimization", "journal": "", "year": "2018", "authors": "B Bichsel; T Gehr; D Drachsler-Cohen; P Tsankov; M Vechev"}, {"ref_id": "b3", "title": "Algorithmic stability for adaptive data analysis", "journal": "", "year": "2016", "authors": "R Bassily; K Nissim; A Smith; T Steinke; U Stemmer; J Ullman"}, {"ref_id": "b4", "title": "Concentrated differential privacy: Simplifications, extensions, and lower bounds", "journal": "Springer", "year": "2016-11-03", "authors": "M Bun; T Steinke"}, {"ref_id": "b5", "title": "Collusion-secure fingerprinting for digital data", "journal": "IEEE Transactions on Information Theory", "year": "1998", "authors": "D Boneh; J Shaw"}, {"ref_id": "b6", "title": "Private empirical risk minimization: Efficient algorithms and tight error bounds", "journal": "IEEE", "year": "2014", "authors": "R Bassily; A Smith; A Thakurta"}, {"ref_id": "b7", "title": "Improving the gaussian mechanism for differential privacy: Analytical calibration and optimal denoising", "journal": "", "year": "2018", "authors": "B Balle; Y.-X Wang"}, {"ref_id": "b8", "title": "Membership inference attacks from first principles", "journal": "", "year": "", "authors": "N Carlini; S Chien; M Nasr; S Song; A Terzis; F Tramer"}, {"ref_id": "b9", "title": "Unlocking high-accuracy differentially private image classification through scale", "journal": "", "year": "2022", "authors": "S De; L Berrada; J Hayes; S L Smith; B Balle"}, {"ref_id": "b10", "title": "Generalization in adaptive data analysis and holdout reuse", "journal": "Advances in Neural Information Processing Systems", "year": "2015", "authors": "C Dwork; V Feldman; M Hardt; T Pitassi; O Reingold; A Roth"}, {"ref_id": "b11", "title": "Preserving statistical validity in adaptive data analysis", "journal": "", "year": "2015", "authors": "C Dwork; V Feldman; M Hardt; T Pitassi; O Reingold; A L Roth"}, {"ref_id": "b12", "title": "Our data, ourselves: Privacy via distributed noise generation", "journal": "", "year": "2006-06-01", "authors": "C Dwork; K Kenthapadi; F Mcsherry; I Mironov; M Naor"}, {"ref_id": "b13", "title": "Calibrating noise to sensitivity in private data analysis", "journal": "", "year": "2006-03-04", "authors": "C Dwork; F Mcsherry; K Nissim; A Smith"}, {"ref_id": "b14", "title": "The algorithmic foundations of differential privacy", "journal": "Foundations and Trends\u00ae in Theoretical Computer Science", "year": "2014", "authors": "C Dwork; A Roth"}, {"ref_id": "b15", "title": "Concentrated differential privacy", "journal": "", "year": "2016", "authors": "C Dwork; G N Rothblum"}, {"ref_id": "b16", "title": "Robust traceability from trace amounts", "journal": "IEEE", "year": "2015", "authors": "C Dwork; A Smith; T Steinke; J Ullman; S Vadhan"}, {"ref_id": "b17", "title": "Detecting violations of differential privacy", "journal": "", "year": "2018", "authors": "Z Ding; Y Wang; G Wang; D Zhang; D Kifer"}, {"ref_id": "b18", "title": "Generalization for adaptively-chosen estimators via stable median", "journal": "", "year": "2017", "authors": "V Feldman; T Steinke"}, {"ref_id": "b19", "title": "Calibrating noise to variance in adaptive data analysis", "journal": "", "year": "2018", "authors": "V Feldman; T Steinke"}, {"ref_id": "b20", "title": "Numerical composition of differential privacy", "journal": "", "year": "2021", "authors": "S Gopi; Y T Lee; L Wutschitz"}, {"ref_id": "b21", "title": "Resolving individuals contributing trace amounts of DNA to highly complex mixtures using high-density SNP genotyping microarrays", "journal": "PLoS genetics", "year": "2008", "authors": "N Homer; S Szelinger; M Redman; D Duggan; W Tembe; J Muehling; J V Pearson; D A Stephan; S F Nelson; D W Craig"}, {"ref_id": "b22", "title": "Evaluating differentially private machine learning in practice", "journal": "", "year": "", "authors": "B Jayaraman; D Evans"}, {"ref_id": "b23", "title": "A new analysis of differential privacy's generalization guarantees", "journal": "", "year": "2019", "authors": "C Jung; K Ligett; S Neel; A Roth; S Sharifi-Malvajerdi; M Shenfeld"}, {"ref_id": "b24", "title": "Auditing differentially private machine learning: How private is private sgd", "journal": "Advances in Neural Information Processing Systems", "year": "2020", "authors": "M Jagielski; J Ullman; A Oprea"}, {"ref_id": "b25", "title": "Computing tight differential privacy guarantees using fft", "journal": "", "year": "", "authors": "A Koskela; J J\u00e4lk\u00f6; A Honkela"}, {"ref_id": "b26", "title": "The composition theorem for differential privacy", "journal": "", "year": "2015", "authors": "P Kairouz; S Oh; P Viswanath"}, {"ref_id": "b27", "title": "On the'semantics' of differential privacy: A bayesian formulation", "journal": "Journal of Privacy and Confidentiality", "year": "2014", "authors": "S P Kasiviswanathan; A Smith"}, {"ref_id": "b28", "title": "A General Framework for Auditing Differentially Private Machine Learning", "journal": "", "year": "2022", "authors": "F Lu; J Munoz; M Fuchs; T Leblond; E Zaresky-Williams; E Raff; F Ferraro; B Testa"}, {"ref_id": "b29", "title": "Antipodes of label differential privacy: Pate and alibi", "journal": "Advances in Neural Information Processing Systems", "year": "2021", "authors": "M Malek Esmaeili; I Mironov; K Prasad; I Shilov; F Tramer"}, {"ref_id": "b30", "title": "R\u00e9nyi differential privacy", "journal": "", "year": "2017", "authors": "I Mironov"}, {"ref_id": "b31", "title": "CANIFE: Crafting Canaries for Empirical Privacy Measurement in Federated Learning", "journal": "", "year": "2022", "authors": "S Maddock; A Sablayrolles; P Stock"}, {"ref_id": "b32", "title": "R\\'enyi differential privacy of the sampled gaussian mechanism", "journal": "", "year": "2019", "authors": "I Mironov; K Talwar; L Zhang"}, {"ref_id": "b33", "title": "The complexity of computing the optimal composition of differential privacy", "journal": "Springer", "year": "2015", "authors": "J Murtagh; S Vadhan"}, {"ref_id": "b34", "title": "Tight Auditing of Differentially Private Machine Learning", "journal": "", "year": "2023", "authors": "M Nasr; J Hayes; T Steinke; B Balle; F Tram\u00e8r; M Jagielski; N Carlini; A Terzis"}, {"ref_id": "b35", "title": "Adversary instantiation: Lower bounds for differentially private machine learning", "journal": "", "year": "", "authors": "M Nasr; S Song; A Thakurta; N Papernot; N Carlini"}, {"ref_id": "b36", "title": "Max-information, differential privacy, and post-selection hypothesis testing", "journal": "IEEE", "year": "2016", "authors": "R Rogers; A Roth; A Smith; O Thakkar"}, {"ref_id": "b37", "title": "Genomic privacy and limits of individual detection in a pool", "journal": "Nature genetics", "year": "2009", "authors": "S Sankararaman; G Obozinski; M I Jordan; E Halperin"}, {"ref_id": "b38", "title": "Membership inference attacks against machine learning models", "journal": "IEEE", "year": "2017", "authors": "R Shokri; M Stronati; C Song; V Shmatikov"}, {"ref_id": "b39", "title": "Composition of Differential Privacy & Privacy Amplification by Subsampling", "journal": "", "year": "2022", "authors": "T Steinke"}, {"ref_id": "b40", "title": "Reasoning about generalization via conditional mutual information", "journal": "", "year": "", "authors": "T Steinke; L Zakynthinou"}, {"ref_id": "b41", "title": "Optimal probabilistic fingerprint codes", "journal": "Journal of the ACM (JACM)", "year": "2008", "authors": "G Tardos"}, {"ref_id": "b42", "title": "Debugging differential privacy: A case study for privacy auditing", "journal": "", "year": "2022", "authors": "F Tramer; A Terzis; T Steinke; S Song; M Jagielski; N Carlini"}, {"ref_id": "b43", "title": "The complexity of differential privacy", "journal": "", "year": "2017", "authors": "S Vadhan"}, {"ref_id": "b44", "title": "Subsampled r\u00e9nyi differential privacy and analytical moments accountant", "journal": "", "year": "", "authors": "Y.-X Wang; B Balle; S P Kasiviswanathan"}, {"ref_id": "b45", "title": "Canary in a Coalmine: Better Membership Inference with Ensembled Adversarial Queries", "journal": "", "year": "2022", "authors": "Y Wen; A Bansal; H Kazemi; E Borgnia; M Goldblum; J Geiping; T Goldstein"}, {"ref_id": "b46", "title": "Bayesian estimation of differential privacy", "journal": "", "year": "2022", "authors": "S Zanella-B\u00e9guelin; L Wutschitz; S Tople; A Salem; V R\u00fchle; A Paverd; M Naseri; B K\u00f6pf"}, {"ref_id": "b47", "title": "Optimal accounting of differential privacy via characteristic function", "journal": "", "year": "", "authors": "Y Zhu; J Dong; Y.-X Wang"}, {"ref_id": "b48", "title": "Wide residual networks", "journal": "", "year": "2016", "authors": "S Zagoruyko; N Komodakis"}, {"ref_id": "b49", "title": "This means that the size of the dataset is random. This may be undesirable. Fortunately, we can fix this, without changing our theoretical analysis. But it does require more examples and it requires changing the definition of DP to consider pairs of datasets differing by the replacement of one person's data, rather than the addition or removal of one person's data (cf", "journal": "", "year": "", "authors": ""}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Algorithm 11Auditor with One Training Run 1: Data: x \u2208 X n consisting of m auditing examples (a.k.a. canaries) and n\u2212m non-auditing examples. 2: Parameters: Algorithm to audit A, number of examples to randomize m, number of positive k + and negative k \u2212 guesses. 3: For i \u2208 [m] sample S i \u2208 {\u22121, +1} independently with E [S i ] = 0. Set S i = 1 for all i \u2208 [n] \\ [m]. 4: Partition x into x IN \u2208 X n IN and x OUT \u2208 X n OUT according to S, where n IN + n OUT = n.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "3 :3Parameters: Number of iterations \u2265 1, clipping threshold c > 0, noise multiplier \u03c3 > 0, sampling probability q \u2208 (0, 1], learning rate \u03b7 > 0. 4: Initialize w 0 \u2208 R d . 5: for t = 1, \u2022 \u2022 \u2022 do 6:", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Proposition 4.6 ([MTZ19; Ste22]). DP-SGD (Algorithm 2) satisfies (2,\u03b5)-RDP fo\u0159", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 1 :1Figure 1: Theorem 5.2's p-value as the number of correct guesses changes for fixed \u03b5 = log 3 (i.e., ideally 75% of guesses correct). The total number of examples and guesses is 100.", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 2 :2Figure 2: Lower bound on the privacy parameter \u03b5 given by Theorem 5.2 with 95% confidence as the number of correct guesses changes. The total number of examples and guesses is 100.For comparison, we plot the ideal \u03b5 that gives 100 \u2022 e \u03b5 e \u03b5 +1 correct guesses.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Figure 3 :3Figure3: Lower bound on the privacy parameter \u03b5 given by Theorem 5.2 with 95% confidence as the number of correct guesses changes. The total number of examples and guesses is 1000 (with no abstentions). Here we plot the ideal \u03b5 on the horizontal axis, so that the number of correct guesses is 1000 \u2022 e \u03b5 e \u03b5 +1 .", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "+1 for the largest k + scores and \u22121 for the smallest k \u2212 scores. 23: (I.e., T \u2208 {\u22121, 0, +1} m maximizes m i T i \u2022 Y i subject to m i |T i | = k + + k \u2212 and m i T i = k + \u2212 k \u2212 .) 24: Return: The vector S \u2208 {\u22121, +1} m indicating the true selection and the guesses T \u2208 {\u22121, 0, +1} m .", "figure_data": ""}, {"figure_label": "45", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "Figure 4 :Figure 5 :45Figure 4: Effect of the number of auditing examples (m) in the white-box setting. By increasing the number of the auditing examples we are able to achieve tighter empirical lower bounds.", "figure_data": ""}, {"figure_label": "67", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "Figure 6 :Figure 7 :67Figure6: Effect of number of iterations in the white-box setting. Increasing the number of the steps (while keeping the same overall privacy by increasing the added noise) will not effect the auditing results.", "figure_data": ""}, {"figure_label": "89", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "Figure 8 :Figure 9 :89Figure 8: Effect of the number of auditing examples (m) in the black-box setting. Black-box auditing is very sensitive to the number of auditing examples.", "figure_data": ""}, {"figure_label": "10", "figure_type": "figure", "figure_id": "fig_10", "figure_caption": "Figure 10 :10Figure 10: Comparison of upper and lower bounds for idealized setting with varying number of guesses. The fraction of correct guesses is always e \u03b5 e \u03b5 +1 for \u03b5 = 4 (i.e., 98.2%).", "figure_data": ""}, {"figure_label": "12", "figure_type": "figure", "figure_id": "fig_12", "figure_caption": "Figure 12 :12Figure 12: Comparison of upper and lower bounds for idealized setting with varying \u03b4.For each example i \u2208 [m], we release S i + \u03be i , where \u03be i \u2190 N (0, 4) and S i \u2208 {\u22121, +1} is independently uniformly random and indicates whether the sample is included/excluded. For the upper bound, we compute the exact (4.38, 10 \u22125 )-DP guarantee for the Gaussian mechanism (Lemma 4.5). For the lower bound, we plot the bound of Theorem 5.2 with 75%, 95%, and 99% confidence. We consider m = 100, 000 randomized examples and 1,500 guesses of which 1,429 are correct. This corresponds to guessing T i = +1 for the largest 750 scores, T i = \u22121 for the smallest 750 scores, and T i = 0 for the remaining 98,500 examples.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_13", "figure_caption": "Algorithm 44Pathological Algorithm1: Input: s \u2208 {\u22121, +1} m 2: Parameters: r \u2208 [m], \u03b5, \u03b4 \u2265 0, \u03b2 \u2208 [0, 1]. Assume 0 < m\u03b4 \u2264 r\u03b2. 3: Select U \u2282 [m]of size |U | = r uniformly at random. 4:", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_14", "figure_caption": "Theorem B.1 (DP implies Generalization). LetA : X n \u2192 Y \u00d7 [0, 1] be (\u03b5,\u03b4)-DP (with respect to replacement). Let P be a distribution on X . Let q : Y \u00d7 X \u2192 [0, 1]. For x \u2208 X n and y \u2208 Y, denote q(y, x) = 1 n n i q(y, x i ) \u2208 [0, 1] and q(y, P ) = E X\u2190P [q(y, X)] \u2208 [0, 1].", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_15", "figure_caption": "2n , whereW \u2190 Binomial n, e \u03b5 e \u03b5 +1 . Proof. Let R : [\u22121, +1] \u2192 {\u22121, +1} denote the randomized rounding function. I.e., E [R(x)] =", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_16", "figure_caption": "We now briefly compare our results to the prior work on the connection between DP and generalization [DFHPRR15b; DFHPRR15a; BNSSSU16; FS17; JLNRSMS19]. We focus on the work of Jung, Ligett, Neel, Roth, Sharifi-Malvajerdi, and Shenfeld[JLNRSMS19] as it has the sharpest results in the literature.", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_17", "figure_caption": "Proposition C. 1 .1Let M : {0, 1} n \u2192 Y satisfy (\u03b5, \u03b4)-DP. Let S \u2208 {0, 1} n be sampled from Bernoulli(p) n . Then I(S; M (S)) \u2264 n\u03b4h(p) + n(1 \u2212 \u03b4)h p \u2022 e \u03b5 + 1 \u2212 p e \u03b5 + 1 \u2212 n(1 \u2212 \u03b4) \u2022 log(1 + e \u2212\u03b5 ) + log(e \u03b5 ) e \u03b5 + 1 , where h(p) := p log(1/p) + (1 \u2212 p) log(1/(1 \u2212 p))is the binary Entropy function.In particular, if p = 1 2 , thenI(S; M (S)) \u2264 n\u03b4 log 2 + n(1 \u2212 \u03b4) \u2022 log 2 \u2212 log(1 + e \u2212\u03b5 ) \u2212 log(e \u03b5 ) e \u03b5 + 1 \u2264 n\u03b4 log 2 + n(1 \u2212 \u03b4) \u03b5 2 8 log e.Proof. We apply the chain rule and convexity of KL divergence [FS18, Lemma 3.7]: I(S; M (S)) = n i I(S i ; M (S)|S <i ) \u2264 n i I(S i ; M (S)|S \u2212i ).", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_18", "figure_caption": "Fixi \u2208 [n] and fix s \u2212i \u2208 {0, 1} n\u22121 . Now we must analyzeI(S i ; M (S)|S \u2212i = s \u2212i ) = I(S i ; M (S i , s \u2212i )) = pD 1 (M (1, s \u2212i ) pM (1, s \u2212i ) + (1 \u2212 p)M (0, s \u2212i )) + (1 \u2212 p)D 1 (M (1, s \u2212i ) pM (1, s \u2212i ) + (1 \u2212 p)M (0, s \u2212i )) = pD 1 (Q 1 Q p ) + (1 \u2212 p)D 1 (Q 0 Q p ) ,whereQ t := tM (1, s \u2212i ) + (1 \u2212 t)M (0, s \u2212i ) for t \u2208 [0, 1].", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_19", "figure_caption": "\u03b5 +1 , we output 1 \u2212 s i with the uncertain flag. We can postprocess this to generate a sample from Q s i = M (s i , s \u2212i ) as follows. If we receive b \u2208 {0, 1} with the uncertain flag, then output a sample from R b . If we receive b \u2208 {0, 1} with the certain flag, then output a sample from Q b .To be formal, define two distributions on the set [4] = {1, 2, 3, 4} by", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_20", "figure_caption": "e \u03b5 +1 + (1 \u2212 p) e \u03b5 (1\u2212\u03b4) e \u03b5 +1 + e \u03b5 (1 \u2212 \u03b4) e \u03b5 + 1 log e \u03b5 (1\u2212\u03b4) e \u03b5 +1 p e \u03b5 (1\u2212\u03b4) e \u03b5 +1 + (1 \u2212 p) 1\u2212\u03b4 e \u03b5 +1 + \u03b4 log \u03b4 p\u03b4 + (1 \u2212 p) e \u03b5 (1 \u2212 \u03b4) e \u03b5 + 1 log e \u03b5 (1\u2212\u03b4) e \u03b5 +1 p 1\u2212\u03b4 e \u03b5 +1 +(1\u2212p) e \u03b5 (1\u2212\u03b4) 1 \u2212 p)e \u03b5 + e \u03b5 log e \u03b5 pe \u03b5 + (1 \u2212 p) + (1 \u2212 p) 1 \u2212 \u03b4 e \u03b5 + 1 e \u03b5 log e \u03b5 p + (1 \u2212 p)e \u03b5 + log 1 pe \u03b5 + (1 \u2212 p) + \u03b4 (p log(1/p) + (1 \u2212 p) log(1/(1 \u2212 p))) = 1 \u2212 \u03b4 e \u03b5 + 1 (p + (1 \u2212 p)e \u03b5 ) log 1 p + (1 \u2212 p)e \u03b5 + (1 \u2212 p)e \u03b5 \u03b5 + (pe \u03b5 + 1 \u2212 p) log 1 pe \u03b5 + 1 \u2212 p + pe \u03b5 \u03b5 + \u03b4h(p) = (1 \u2212 \u03b4) p + (1 \u2212 p)e \u03b5 e \u03b5 + 1 log e \u03b5 + 1 p + (1 \u2212 p)e \u03b5 + pe \u03b5 + 1 \u2212 p e \u03b5 + 1 log e \u03b5 + 1 pe \u03b5 + 1 \u2212 p \u2212 log(e \u03b5 + 1) + e \u03b5 \u03b5 e \u03b5 + 1 + \u03b4h(p) = (1 \u2212 \u03b4) h p + (1 \u2212 p)e \u03b5 e \u03b5 + 1 \u2212 log(e \u03b5 + 1) + e \u03b5 \u03b5 e \u03b5 + 1 + \u03b4h(p) = (1 \u2212 \u03b4) h pe \u03b5 + (1 \u2212 p) e \u03b5 + 1 \u2212 log(1 + e \u2212\u03b5 )\u2212 \u03b5 e \u03b5 + 1 + \u03b4h(p).", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "Data: x \u2208 X n consisting of m auditing examples (a.k.a. canaries) and n \u2212 m non-auditing examples. 2: Parameters: Number of examples to randomize m for audit, number of positive k + and negative k \u2212 guesses audit-type (either black-box or white-box).", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "Multiple runs & multiple examples: Our method performs auditing by including or excluding multiple examples in a single training run, while most prior work performs multiple training runs with a single example example included or excluded. Can we get the best of both worlds? If we use multiple examples and multiple runs, we should be able to get tighter results with fewer runs.", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "P [M (x) \u2208 S] \u2264 e \u03b5 \u2022 P [M (x ) \u2208 S] + \u03b4.", "formula_coordinates": [1.0, 209.43, 438.33, 193.13, 13.37]}, {"formula_id": "formula_1", "formula_text": "P S\u2190{\u22121,+1} m T \u2190M (S) m i max{0, T i \u2022 S i } \u2265 v \u2264 P W \u2190Binomial(r, e \u03b5 e \u03b5 +1 ) W \u2265 v + O(\u03b4).(2)", "formula_coordinates": [4.0, 122.76, 263.66, 417.25, 35.77]}, {"formula_id": "formula_2", "formula_text": "P W \u2190Binomial(r, e \u03b5 e \u03b5 +1 ) \uf8ee \uf8ef \uf8ef \uf8f0W \u2265 r \u2022 e \u03b5 e \u03b5 + 1 + 1 2 \u2022 r \u2022 log(1/\u03b2) =v \uf8f9 \uf8fa \uf8fa \uf8fb \u2264 \u03b2.(3)", "formula_coordinates": [4.0, 161.43, 432.51, 378.57, 57.24]}, {"formula_id": "formula_3", "formula_text": "A is (\u03b5, \u03b4)-DP, then the number of correct guesses W is \u2264 r\u2022e \u03b5 e \u03b5 +1 + O( \u221a r)", "formula_coordinates": [4.0, 72.0, 543.95, 468.0, 28.28]}, {"formula_id": "formula_4", "formula_text": "\u2200S \u2282 Y P [M (x) \u2208 S] \u2264 e \u03b5 \u2022 P [M (x ) \u2208 S] + \u03b4. Definition 4.2 (R\u00e9nyi Differential Privacy [Mir17]). We say M : X * \u2192 Y is (\u03b1,\u03b5)-R\u00e9nyi differentially private ((\u03b1,\u03b5)-RDP)", "formula_coordinates": [6.0, 72.0, 279.73, 468.0, 53.55]}, {"formula_id": "formula_5", "formula_text": "D \u03b1 (M (x) M (x )) \u2264\u03b5,", "formula_coordinates": [6.0, 247.96, 363.64, 116.08, 11.5]}, {"formula_id": "formula_6", "formula_text": "D \u03b1 (P Q) := 1 \u03b1\u22121 log E Y \u2190P P (Y ) Q(Y ) \u03b1\u22121", "formula_coordinates": [6.0, 105.03, 389.04, 190.22, 25.02]}, {"formula_id": "formula_7", "formula_text": "\u2200\u03b1 > 1 D \u03b1 (M (x) M (x )) \u2264 \u03b1 \u2022 \u03c1.", "formula_coordinates": [6.0, 211.26, 483.49, 189.48, 11.5]}, {"formula_id": "formula_8", "formula_text": "\u03b4 = \u03a6 \u03b5 \u2212 \u03c1 \u221a 2\u03c1 \u2212 e \u03b5 \u2022 \u03a6 \u03b5 + \u03c1 \u221a 2\u03c1 ,", "formula_coordinates": [7.0, 219.68, 183.17, 172.64, 26.94]}, {"formula_id": "formula_9", "formula_text": "Z\u2190N (0,1) [Z > z] = 1 \u221a 2\u03c0 \u221e z exp(\u2212x 2 /2)dx. Furthermore, M satisfies \u03c1-zCDP.", "formula_coordinates": [7.0, 147.55, 222.37, 391.93, 21.44]}, {"formula_id": "formula_10", "formula_text": "Clip\u011d t i = min 1, c g t i 2", "formula_coordinates": [7.0, 109.46, 475.84, 112.25, 18.11]}, {"formula_id": "formula_11", "formula_text": "\u03b5 = \u2022 log 1 + q 2 \u2022 exp(1/\u03c3 2 ) \u2212 1 \u2248 \u2022 q 2 \u2022 1 \u03c3 2 .", "formula_coordinates": [7.0, 181.02, 663.65, 249.96, 26.77]}, {"formula_id": "formula_12", "formula_text": "1 2 + 1 2 e\u03b5 \u2212 1 e\u03b5 + 3 \u2248 1 2 + 1 4 \u221a\u03b5 . (4", "formula_coordinates": [8.0, 236.65, 117.95, 298.36, 29.06]}, {"formula_id": "formula_13", "formula_text": ")", "formula_coordinates": [8.0, 535.01, 128.33, 4.99, 10.48]}, {"formula_id": "formula_14", "formula_text": "P M \u2208 R be a fixed number. For each \u03b5, \u03b2 > 0, let T \u03b5,\u03b2 \u2282 \u2126 satisfy \u2200M (P M = \u03b5 =\u21d2 P [A M \u2208 T \u03b5,\u03b2 ] \u2264 \u03b2) . (5", "formula_coordinates": [8.0, 72.0, 494.87, 468.0, 52.35]}, {"formula_id": "formula_15", "formula_text": ")", "formula_coordinates": [8.0, 535.01, 535.72, 4.99, 10.48]}, {"formula_id": "formula_16", "formula_text": "Further suppose that, if \u03b5 1 \u2264 \u03b5 2 , then T \u03b5 1 ,\u03b2 \u2283 T \u03b5 2 ,\u03b2 .", "formula_coordinates": [8.0, 72.0, 562.12, 259.43, 12.23]}, {"formula_id": "formula_17", "formula_text": "P [P M \u2265 sup {\u03b5 > 0 : A M \u2208 T \u03b5,\u03b2 }] \u2265 1 \u2212 \u03b2.(6)", "formula_coordinates": [8.0, 198.06, 588.52, 341.94, 11.5]}, {"formula_id": "formula_18", "formula_text": "A M \u2208 T \u03b5,\u03b2 }.", "formula_coordinates": [8.0, 387.32, 614.92, 60.88, 11.5]}, {"formula_id": "formula_19", "formula_text": "A M \u2208 \u03b5\u2265P M T \u03b5,\u03b2 = T P M ,\u03b2 .", "formula_coordinates": [8.0, 243.54, 658.22, 124.92, 24.68]}, {"formula_id": "formula_20", "formula_text": "P [P M < sup {\u03b5 > 0 : A M \u2208 T \u03b5,\u03b2 }] \u2264 P [A M \u2208 T P M ,\u03b2 ] \u2264 \u03b2, as required.", "formula_coordinates": [9.0, 72.0, 95.64, 378.08, 30.33]}, {"formula_id": "formula_21", "formula_text": "[X \u2264 Y ] = 1.", "formula_coordinates": [9.0, 81.3, 442.81, 67.68, 10.48]}, {"formula_id": "formula_22", "formula_text": "Y 1 + Y 2 .", "formula_coordinates": [9.0, 410.33, 509.28, 41.05, 11.5]}, {"formula_id": "formula_23", "formula_text": "P [X 1 + X 2 > t] = E X 1 P X 2 [X 2 > t \u2212 X 1 |X 1 ] \u2264 E X 1 P Y 2 [Y 2 > t \u2212 X 1 ] (Y 2 dominates X 2 |X 1 ) = E Y 2 P X 1 [X 1 > t \u2212 Y 2 ] \u2264 E Y 2 P Y 1 [Y 1 > t \u2212 Y 2 ] (Y 1 dominates X 1 & independence) = P [Y 1 + Y 2 > t].", "formula_coordinates": [9.0, 118.81, 554.12, 421.19, 134.99]}, {"formula_id": "formula_24", "formula_text": "W := m i max{0, T i \u2022 S i },", "formula_coordinates": [11.0, 241.76, 405.98, 128.48, 35.77]}, {"formula_id": "formula_25", "formula_text": "T i \u2022 S i } = |T i |.", "formula_coordinates": [11.0, 110.87, 481.09, 76.53, 11.5]}, {"formula_id": "formula_26", "formula_text": "Proposition 5.1 (Pure DP Version of Main Result). Let M : {\u22121, +1} m \u2192 R m satisfy (\u03b5, 0)-DP. Let S \u2208 {\u22121, +1} m be uniformly random. Let T = M (S) \u2208 R m .", "formula_coordinates": [12.0, 72.0, 468.56, 468.0, 27.22]}, {"formula_id": "formula_27", "formula_text": "P S\u2190{\u22121,1} m T \u2190M (S) m i max{0, T i \u2022 S i } \u2265 v T = t \u2264 P S\u2190Bernoulli( e \u03b5 e \u03b5 +1 ) m m i\u0160 i \u2022 |t i | \u2265 v =: \u03b2(m, \u03b5, v, t).", "formula_coordinates": [12.0, 73.2, 523.04, 475.05, 35.77]}, {"formula_id": "formula_28", "formula_text": "[W \u2265 v] \u2264 \u03b2(m, \u03b5, v, t).", "formula_coordinates": [13.0, 72.0, 148.02, 468.0, 24.93]}, {"formula_id": "formula_29", "formula_text": "P [S i = 1|M (S) = t, S <i = s <i ] = P [M (S) = t|S i = 1, S <i = s <i ] \u2022 P [S i = 1|S <i = s <i ] P [M (S) = t|S <i = s <i ] = P [M (S) = t|S i = 1, S <i = s <i ] \u2022 P [S i = 1] P [M (S) = t|S i = 1, S <i = s <i ] \u2022 P [S i = 1] + P [M (S) = t|S i = \u22121, S <i = s <i ] \u2022 P [S i = \u22121] = P [M (S) = t|S i = 1, S <i = s <i ] \u2022 1 2 P [M (S) = t|S i = 1, S <i = s <i ] \u2022 1 2 + P [M (S) = t|S i = \u22121, S <i = s <i ] \u2022 1 2 = 1 1 + P [M (S) = t|S i = \u22121, S <i = s <i ]/P [M (S) = t|S i = 1, S <i = s <i ] \u2208 1 1 + e \u03b5 , 1 1 + e \u2212\u03b5 . Thus P [S i = sign(T i )|T = t, S <i = s <i ] \u2264 1 1+e \u2212\u03b5 = e \u03b5 e \u03b5 +1 .", "formula_coordinates": [13.0, 72.0, 269.81, 476.07, 204.38]}, {"formula_id": "formula_30", "formula_text": "W m\u22121 := m\u22121 i max{0, T i \u2022 S i } is stochatiscally dominated byW m\u22121 := m\u22121 i\u0160 i \u2022 |t i | where\u0160 \u2190 Bernoulli e \u03b5 e \u03b5 +1 m\u22121 . As above, conditioned on the value of W m\u22121 , the variable max{0, T m \u2022S m } = |T m |\u2022I[S m = sign(T m )] is stochastically dominated by |T m |\u2022Bernoulli e \u03b5 e \u03b5 +1 . By Lemma 4.9, W m = W m\u22121 + max{0, T m \u2022 S m } is stochastically dominated byW m := m i\u0160 i \u2022 |t i | where\u0160 \u2190 Bernoulli e \u03b5 e \u03b5 +1 m .", "formula_coordinates": [13.0, 72.0, 486.16, 468.0, 80.59]}, {"formula_id": "formula_31", "formula_text": "Theorem 5.2 (Main Result). Let M : {\u22121, +1} m \u2192 [\u22121, +1] m satisfy (\u03b5, \u03b4)-DP. Let S \u2208 {\u22121, +1} m be uniformly random. Let T = M (S) \u2208 [\u22121, +1] m . Then, for all v \u2208 R, P S\u2190{\u22121,+1} m T \u2190M (S) m i max{0, T i \u2022 S i } \u2265 v \u2264 \u03b2 + \u03b1 \u2022 2m \u2022 \u03b4,(7)", "formula_coordinates": [14.0, 72.0, 127.23, 468.0, 76.18]}, {"formula_id": "formula_32", "formula_text": "\u03b2 = P W * W * \u2265 v ,(8)", "formula_coordinates": [14.0, 156.51, 240.14, 383.49, 21.75]}, {"formula_id": "formula_33", "formula_text": "\u03b1 = max 1 i P W * W * \u2265 v \u2212 i \u2212 \u03b2 : i \u2208 {1, 2, \u2022 \u2022 \u2022 , m} . (9", "formula_coordinates": [14.0, 156.26, 266.6, 378.76, 26.82]}, {"formula_id": "formula_34", "formula_text": ")", "formula_coordinates": [14.0, 535.01, 274.69, 4.99, 10.48]}, {"formula_id": "formula_35", "formula_text": "= m i\u0160 i |t i | for\u0160 \u2190 Bernoulli e \u03b5 e \u03b5 +1", "formula_coordinates": [14.0, 72.0, 306.16, 468.0, 31.37]}, {"formula_id": "formula_36", "formula_text": "W * W * \u2265 v = sup t\u2208support(T ) P W W (t) \u2265 v", "formula_coordinates": [14.0, 189.67, 361.32, 214.59, 21.75]}, {"formula_id": "formula_37", "formula_text": "). Let M : {\u22121, +1} m \u2192 [\u22121, +1] m satisfy (\u03b5, \u03b4)-DP. Let S \u2208 {\u22121, +1} m be uniformly random. Let T = M (S) \u2208 [\u22121, +1] m . Suppose P [ T 2 \u2264 r 2 ] = 1 and P [ T 1 \u2264 r 1 ] = 1. Then, for all v \u2265 e \u03b5 e \u03b5 +1 \u2022 r 1 + 2, we have P S\u2190{\u22121,+1} m T \u2190M (S) m i max{0, T i \u2022 S i } \u2265 v \u2264 f (v) + 2m \u2022 \u03b4 \u2022 max f (v \u2212 i) \u2212 f (v) i : i \u2208 [m] (10) \u2264 f (v) + 2m\u03b4 \u2022 max 2 v \u2212 e \u03b5 e \u03b5 +1 r 1 , f 1 2 v + e \u03b5 e \u03b5 + 1 r 1 ,(11)", "formula_coordinates": [14.0, 72.0, 473.38, 489.87, 162.15]}, {"formula_id": "formula_38", "formula_text": "f (v) := exp \u22122 r 2 2 v \u2212 e \u03b5 e \u03b5 +1 r 1 2 if v \u2265 e \u03b5 e \u03b5 +1 r 1 1 if v < e \u03b5 e \u03b5 +1 r 1 .", "formula_coordinates": [14.0, 170.35, 660.8, 271.3, 36.0]}, {"formula_id": "formula_39", "formula_text": "P S\u2190{\u22121,+1} m T \u2190M (S) m i max{0, T i \u2022 S i } \u2265 v \u2264 \u03b2 + 2m \u2022 \u03b4 \u2022 max \uf8f1 \uf8f2 \uf8f3 1 r 2 1 2 log(1/\u03b2) , \u03b2 1/4 \uf8fc \uf8fd \uf8fe .(12)", "formula_coordinates": [15.0, 91.57, 100.96, 448.43, 43.98]}, {"formula_id": "formula_40", "formula_text": "= m i\u0160 i |t i | for\u0160 \u2190 Bernoulli e \u03b5 e \u03b5 +1 m .", "formula_coordinates": [15.0, 358.43, 152.15, 191.02, 18.12]}, {"formula_id": "formula_41", "formula_text": "P W (t) \u2265 e \u03b5 e \u03b5 + 1 t 1 + \u03bb \u2264 exp \u22122\u03bb 2 t 2 2 . Now defineW * by P W * \u2265 v := f (v) := exp \u22122 r 2 2 v \u2212 e \u03b5 e \u03b5 +1 r 1 2 if v \u2265 e \u03b5 e \u03b5 +1 r 1 1 if v < e \u03b5 e \u03b5 +1 r 1 .", "formula_coordinates": [15.0, 72.0, 193.16, 408.04, 94.26]}, {"formula_id": "formula_42", "formula_text": "max f (v \u2212 i) \u2212 f (v) i : i \u2208 [m] \u2264 max f (v \u2212 x) x : x \u2208 [1, \u221e) (f (v) \u2265 0 and [m] \u2282 [1, \u221e)) = max max f (v \u2212 x) x : x \u2208 [1, c] , max f (v \u2212 x) x : x \u2208 [c, \u221e) \u2264 max max f (v \u2212 x) 1 : x \u2208 [1, c] , max 1 x : x \u2208 [c, \u221e) = max f (v \u2212 c), 1 c . Setting c = 1 2 v \u2212 e \u03b5 e \u03b5", "formula_coordinates": [15.0, 72.0, 344.41, 468.0, 181.59]}, {"formula_id": "formula_43", "formula_text": "M : {\u22121, +1} m \u2192 {\u22121, 0, +1} m satisfy (\u03b5, \u03b4)- DP. Let S \u2208 {\u22121, +1} m be uniformly random. Let T = M (S) \u2208 {\u22121, 0, +1} m . Suppose P [ T 1 \u2264 r] = 1. Then, for all v \u2208 R, P S\u2190{\u22121,+1} m T \u2190M (S) m i max{0, T i \u2022 S i } \u2265 v \u2264 f (v)+2m\u2022\u03b4\u2022max f (v \u2212 i) \u2212 f (v) i : i \u2208 {1, 2, \u2022 \u2022 \u2022 , m} ,", "formula_coordinates": [15.0, 72.0, 609.85, 480.42, 85.4]}, {"formula_id": "formula_44", "formula_text": "f (v) := P W \u2190Binomial(r, e \u03b5 e \u03b5 +1 ) W \u2265 v .", "formula_coordinates": [16.0, 218.95, 87.21, 174.09, 25.43]}, {"formula_id": "formula_45", "formula_text": "P = (1 \u2212 \u03b4 )P + \u03b4 P , Q = (1 \u2212 \u03b4 )Q + \u03b4 Q .", "formula_coordinates": [16.0, 248.23, 247.68, 115.54, 27.92]}, {"formula_id": "formula_46", "formula_text": "P (y) = min{P (y), e \u03b5 1 \u2022 Q(y)} 1 \u2212 \u03b4 1 , P (y) = P (y) \u2212 (1 \u2212 \u03b4 1 )P (y) \u03b4 1 = max{0, P (y) \u2212 e \u03b5 1 \u2022 Q(y)} \u03b4 1 , Q (y) = min{Q(y), e \u03b5 2 \u2022 P (y)} 1 \u2212 \u03b4 2 , Q (y) = Q(y) \u2212 (1 \u2212 \u03b4 2 )Q (y) \u03b4 2 = max{0, Q(y) \u2212 e \u03b5 2 \u2022 P (y)} \u03b4 2 ,", "formula_coordinates": [16.0, 152.98, 555.9, 306.04, 122.51]}, {"formula_id": "formula_47", "formula_text": "e \u2212\u03b5 \u2264 e \u2212\u03b5 2 \u2264 P (y) Q (y) = min{P (y), e \u03b5 1 \u2022 Q(y)} min{Q(y), e \u03b5 2 \u2022 P (y)} \u2264 e \u03b5 1 \u2264 e \u03b5 ,", "formula_coordinates": [17.0, 164.04, 185.09, 283.91, 28.39]}, {"formula_id": "formula_48", "formula_text": "< \u03b4 1 = \u03b4 2 \u2264 \u03b4 by appropriately setting \u03b5 1 , \u03b5 2 \u2208 [0, \u03b5]. We have \u03b4 1 = Y max{0, P (y) \u2212 e \u03b5 1 \u2022 Q(y)}dy = S P (y) \u2212 e \u03b5 1 \u2022 Q(y)dy = P (S) \u2212 e \u03b5 1 Q(S), where S = {y \u2208 Y : P (y) \u2265 e \u03b5 1 \u2022 Q(y)}. If \u03b5 1 = \u03b5, then \u03b4 1 \u2264 \u03b4 by assumption. If \u03b5 1 = 0, then \u03b4 1 = d TV (P, Q) > 0. By decreasing \u03b5 1 , we continuously increase \u03b4 1 . Thus, by starting at \u03b5 1 = \u03b5 and decreasing \u03b5 1 until either \u03b5 1 = 0 or \u03b4 1 = \u03b4, we can pick \u03b5 1 \u2208 [0, \u03b5] such that \u03b4 1 = min{\u03b4, d TV (P, Q)} \u2208 (0, 1). Similarly, we can pick \u03b5 2 \u2208 [0, \u03b5], such that \u03b4 2 = min{\u03b4, d TV (P, Q)}.", "formula_coordinates": [17.0, 72.0, 241.68, 468.01, 149.43]}, {"formula_id": "formula_49", "formula_text": "P X\u2190Bernoulli(p) Y \u2190XP +(1\u2212X)Q [X = 1 \u2227 E P,Q (Y ) = 1|Y = y] \u2264 p p + (1 \u2212 p)e \u2212\u03b5 .", "formula_coordinates": [17.0, 153.75, 592.31, 305.7, 30.94]}, {"formula_id": "formula_50", "formula_text": "E Y \u2190P [E P,Q (Y )] \u2265 1 \u2212 \u03b4 and E Y \u2190Q [E P,Q (Y )] \u2265 1 \u2212 \u03b4.", "formula_coordinates": [17.0, 159.84, 664.28, 292.32, 17.15]}, {"formula_id": "formula_51", "formula_text": "P = (1 \u2212 \u03b4 )P + \u03b4 P , Q = (1 \u2212 \u03b4 )Q + \u03b4 Q ,", "formula_coordinates": [18.0, 248.23, 116.64, 115.54, 27.92]}, {"formula_id": "formula_52", "formula_text": "P [E P,Q (y) = 1] = (1 \u2212 \u03b4 ) \u2022 P (y) P (y) = 1 \u2212 \u03b4 \u2022 P (y) P (y) .", "formula_coordinates": [18.0, 177.59, 243.52, 256.82, 26.77]}, {"formula_id": "formula_53", "formula_text": "Y \u2190P,E P,Q [E P,Q (Y )] = Y P (y)P [E P,Q (Y ) = 1]dy = Y (1 \u2212 \u03b4)P (y)dy = 1 \u2212 \u03b4 \u2265 1 \u2212 \u03b4. Also E Y \u2190Q [E P,Q (Y )] = 1 \u2212 \u03b4 E Y \u2190Q P (y) P (y) = 1 \u2212 \u03b4 Y Q(y) P (y) \u2022 P (y)dy \u2265 1 \u2212 \u03b4 Y P (y)dy = 1 \u2212 \u03b4 \u2265 1 \u2212 \u03b4,", "formula_coordinates": [18.0, 72.0, 285.38, 468.0, 151.09]}, {"formula_id": "formula_54", "formula_text": "P [X = 1 \u2227 E P,Q (Y ) = 1|Y = y] = P [X = 1|Y = y] \u2022 P [E P,Q (y) = 1] = P [Y = y|X = 1] \u2022 P [X = 1] P [Y = y] \u2022 P [E P,Q (y) = 1] = P (y) \u2022 p pP (y) + (1 \u2212 p)Q(y) \u2022 P [E P,Q (y) = 1] = p(1 \u2212 \u03b4 )P (y) + p\u03b4 P (y) p(1 \u2212 \u03b4 )P (y) + p\u03b4 P (y) + (1 \u2212 p)(1 \u2212 \u03b4 )Q (y) + (1 \u2212 p)\u03b4 Q (y) \u2022 P [E P,Q (y) = 1] = p + p \u03b4 P (y) (1\u2212\u03b4 )P (y) p + p \u03b4 P (y) (1\u2212\u03b4 )P (y) + (1 \u2212 p) Q (y) P (y) + (1 \u2212 p) \u03b4 Q (y)", "formula_coordinates": [19.0, 88.22, 97.58, 435.56, 169.24]}, {"formula_id": "formula_55", "formula_text": "P [E P,Q (y) = 1] = p + p \u03b4 1\u2212\u03b4 P (y) P (y) p + (1 \u2212 p) Q (y) P (y) + \u03b4 1\u2212\u03b4 \u2022 pP (y)+(1\u2212p)Q (y) P (y) \u2022 P [E P,Q (y) = 1] \u2264 p + p \u03b4 1\u2212\u03b4 P (y) P (y) p + (1 \u2212 p)e \u2212\u03b5 + 0 \u2022 P [E P,Q (y) = 1] = p p + (1 \u2212 p)e \u2212\u03b5 \u2022 1 + \u03b4 1 \u2212 \u03b4 P (y) P (y) \u2022 P [E P,Q (y) = 1] = p p + (1 \u2212 p)e \u2212\u03b5 \u2022 P (y) (1 \u2212 \u03b4 )P (y) \u2022 P [E P,Q (y) = 1] = p p + (1 \u2212 p)e \u2212\u03b5 .", "formula_coordinates": [19.0, 91.54, 242.63, 342.19, 198.59]}, {"formula_id": "formula_56", "formula_text": "Proposition 5.7 (General Form of Main Result). Let M : {\u22121, +1} m \u2192 [\u22121, +1] m sat- isfy (\u03b5, \u03b4)-DP. Let S \u2208 {\u22121, +1} m be m independent samples from 2Bernoulli(p)\u22121 -i.e., P [S i = 1] = p independently for each i \u2208 [m]. Let T = M (S) \u2208 [\u22121, +1] m . Then, for all v \u2208 R and all t \u2208 [\u22121, +1] m , P S\u2190(2Bernoulli(p)\u22121) m , T \u2190M (S) m i max{0, T i \u2022 S i } \u2265 v T = t \u2264 P S + \u2190Bernoulli ( p\u2022e \u03b5 p\u2022e \u03b5 +1\u2212p ) m S \u2212 \u2190Bernoulli ( (1\u2212p)\u2022e \u03b5 (1\u2212p)\u2022e \u03b5 +p ) m ,F \uf8ee \uf8f0 F (t) + i\u2208[m]:t i >0 t i \u2022\u0160 + i + i\u2208[m]:t i <0 \u2212t i \u2022\u0160 \u2212 i \u2265 v \uf8f9 \uf8fb ,", "formula_coordinates": [19.0, 72.0, 490.9, 468.0, 162.17]}, {"formula_id": "formula_57", "formula_text": "F : [\u22121, 1] m \u2192 {0, 1, \u2022 \u2022 \u2022 , m} is independent from\u0160 + and\u0160 \u2212 and satisfies E T,F [F (T )] \u2264 2m \u2022 \u03b4. Proof. For i \u2208 [m] \u222a {0} and s \u2264i \u2208 {\u22121, 1} i , let M (s \u2264i ) denote the distribution on [\u22121, 1] m", "formula_coordinates": [19.0, 72.0, 660.85, 468.0, 31.58]}, {"formula_id": "formula_58", "formula_text": "M (s \u2264i ) = s >i \u2208{\u22121,1} m\u2212i M (s \u2264i , s >i ) \u2022 P S >i \u2190(2Bernoulli(p)\u22121) m\u2212i [S >i = s >i ].", "formula_coordinates": [20.0, 134.4, 118.88, 343.2, 25.34]}, {"formula_id": "formula_59", "formula_text": "P S\u2190(2Bernoulli(p)\u22121) n , T \u2190M (S),E S i = 1 \u2227 E M (s <i ,1),M (s <i ,\u22121) (T ) = 1 S <i = s <i , T = t \u2264 p \u2022 e \u03b5 p \u2022 e \u03b5 + 1 \u2212 p , E S\u2190(2Bernoulli(p)\u22121) n , T \u2190M (S),E E M (s <i ,1),M (s <i ,\u22121) (T ) S \u2264i = (s <i , 1) \u2265 1 \u2212 \u03b4, E S\u2190(2Bernoulli(p)\u22121) n , T \u2190M (S),E E M (s <i ,1),M (s <i ,\u22121) (T ) S \u2264i = (s <i , \u22121) \u2265 1 \u2212 \u03b4.", "formula_coordinates": [20.0, 91.55, 224.21, 430.09, 93.29]}, {"formula_id": "formula_60", "formula_text": "P S\u2190(2Bernoulli(p)\u22121) n , T \u2190M (S),E S i = \u22121 \u2227 E M (s <i ,\u22121),M (s <i ,1) (T ) = 1 S <i = s <i , T = t \u2264 (1 \u2212 p) \u2022 e \u03b5 (1 \u2212 p) \u2022 e \u03b5 + p , E S\u2190(2Bernoulli(p)\u22121) n , T \u2190M (S),E E M (s <i ,\u22121),M (s <i ,1) (T ) S \u2264i = (s <i , \u22121) \u2265 1 \u2212 \u03b4, E S\u2190(2Bernoulli(p)\u22121) n , T \u2190M (S),E E M (s <i ,\u22121),M (s <i ,1) (T ) S \u2264i = (s <i , 1) \u2265 1 \u2212 \u03b4.", "formula_coordinates": [20.0, 82.35, 356.72, 448.49, 93.29]}, {"formula_id": "formula_61", "formula_text": "i \u2208 [m], all s <i \u2208 {\u22121, 1} i\u22121 , and all t \u2208 [\u22121, 1] m , P S\u2190(2Bernoulli(p)\u22121) n , T \u2190M (S),E S i = sign(T i )\u2227E M (s <i ,\u22121) M (s <i ,1) (T ) = 1 T = t, S <i = s <i \u2264 p\u2022e \u03b5 p\u2022e \u03b5 +1\u2212p if t i > 0 (1\u2212p)\u2022e \u03b5 (1\u2212p)\u2022e \u03b5 +p if t i < 0 and, for b \u2208 {\u22121, 1}, we have E S\u2190(2Bernoulli(p)\u22121) n , T \u2190M (S),E E M (s <i ,1) M (s <i ,\u22121) (T ) S \u2264i = (s <i , b) \u2265 1 \u2212 2\u03b4. For k \u2208 [m], s \u2208 {\u22121, 1} m , and t \u2208 [\u22121, 1] m , define W k (s, t) := i\u2208[k] max{0, t i \u2022 s i } \u2022 E M (s <i ,\u22121) M (s <i ,1) (t) = i\u2208[k] |t i | \u2022 I[s i = sign(t i ) \u2227 E M (s <i ,\u22121) M (s <i ,1) (t) = 1] andW k (t) = i\u2208[k]\u0160 i (t) \u2022 |t i |,", "formula_coordinates": [20.0, 72.0, 481.88, 468.0, 210.02]}, {"formula_id": "formula_62", "formula_text": "i \u2208 [k] independently,\u0160(t) i \u2190 Bernoulli( p\u2022e \u03b5 p\u2022e \u03b5 +1\u2212p ) if t i > 0 and\u0160(t) i \u2190 Bernoulli( (1\u2212p)\u2022e \u03b5", "formula_coordinates": [21.0, 72.0, 122.1, 468.0, 32.82]}, {"formula_id": "formula_63", "formula_text": "s \u2208 {\u22121, 1} m and t \u2208 [\u22121, 1] m , define F (s, t) := m i I E M (s <i ,\u22121) M (s <i ,1) (t) = 0 , so that W m (s, t) := i\u2208[m] max{0, t i \u2022 s i } \u2264 W m (s, t) + F (s, t). Since the conditional distribution ( W k (S, t)|M (S) = t) where S \u2190 (2Bernoulli(p) \u2212 1) m is stochastically dominated byW k (t), W m is stochastically dominated by the convolutio\u0148 W m (T ) + F (S, T ). Finally F (s, t) is supported on {0, 1, \u2022 \u2022 \u2022 , m} and E [F (s, t)] = m i P E M (s <i ,\u22121) M (s <i ,1) (T ) = 0 \u2264 2m \u2022 \u03b4.", "formula_coordinates": [21.0, 72.0, 203.75, 809.03, 227.45]}, {"formula_id": "formula_64", "formula_text": "M : {\u22121, 1} m \u2192 [\u22121, 1] m satisfy (\u03b5, \u03b4)-DP. Let S \u2208 {\u22121, 1} m be uniformly random. Let T = M (S) \u2208 [\u22121, 1] m . Setting p = 1", "formula_coordinates": [21.0, 72.0, 534.72, 467.5, 26.55]}, {"formula_id": "formula_65", "formula_text": "P S\u2190{\u22121,1} m T \u2190M (S) m i max{0, T i \u2022 S i } \u2265 v \u2264 P S\u2190{\u22121,1} m ,T \u2190M (S), S\u2190Bernoulli ( e \u03b5 e \u03b5 +1 ) m ,F F (T ) + m i\u0160 i \u2022 |T i | \u2265 v ,", "formula_coordinates": [21.0, 101.69, 589.21, 409.82, 41.41]}, {"formula_id": "formula_66", "formula_text": "maximize P W ,F W (t) + F (t) \u2265 v = m i=0 P F [F (t) = i] \u2022 P W W (t) \u2265 v \u2212 i subject to E F [F (t)] = m i=0 P F [F (t) = i] \u2022 i \u2264 2m \u2022 \u03b4, m i=0 P F", "formula_coordinates": [22.0, 120.4, 113.32, 366.22, 112.95]}, {"formula_id": "formula_67", "formula_text": "P F [F (t) = i] \u2265 0 \u2200i \u2208 {0, 1, \u2022 \u2022 \u2022 , m}, whereW (t) := m i\u0160 i |t i | for\u0160 \u2190 Bernoulli e \u03b5 e \u03b5 +1 m .", "formula_coordinates": [22.0, 72.0, 231.85, 298.86, 45.75]}, {"formula_id": "formula_68", "formula_text": "minimize 2m\u03b4\u03b1 + \u03b2 subject to \u03b1 \u2022 i + \u03b2 \u2265 P W W (t) \u2265 v \u2212 i \u2200i \u2208 {0, 1, \u2022 \u2022 \u2022 , m}, \u03b1 \u2265 0.", "formula_coordinates": [22.0, 147.93, 304.42, 316.13, 53.65]}, {"formula_id": "formula_69", "formula_text": "\u03b2 = P W * W * \u2265 v , \u03b1 = max {0} \u222a 1 i P W * W * \u2265 v \u2212 i \u2212 \u03b2 : i \u2208 {1, 2, \u2022 \u2022 \u2022 , m} ,", "formula_coordinates": [22.0, 131.91, 411.41, 348.18, 53.28]}, {"formula_id": "formula_70", "formula_text": "W * W * \u2265 v \u2212 i \u2265 P W W (t) \u2265 v \u2212 i for all i \u2208 {0, 1, \u2022 \u2022 \u2022", "formula_coordinates": [22.0, 72.0, 477.58, 468.0, 33.68]}, {"formula_id": "formula_71", "formula_text": "). Let M : {\u22121, +1} m \u2192 [\u22121, +1] m satisfy (\u03b5, \u03b4)- DP. Let S \u2208 {\u22121, +1} m be uniformly random. Let T = M (S) \u2208 [\u22121, +1] m . Then, for all \u03b3 \u2208 [0, 1] and \u03c4 > 0, P S\u2190{\u22121,+1} m T \u2190M (S) m i max{0, T i \u2022 S i } \u2265 g m,\u03b5 (T, \u03b3) + \u03c4 \u2264 \u03b3 + 2m\u03b4 \u03c4 , where g m,\u03b5 : [\u22121, +1] m \u00d7 [0, 1] \u2192 R is an arbitrary function satisfying \u2200t \u2208 [\u22121, 1] m \u2200\u03b3 \u2208 [0, 1] P S\u2190Bernoulli( e \u03b5 e \u03b5 +1 ) m m i |t i | \u2022\u0160 i \u2265 g m,\u03b5 (t, \u03b3) \u2264 \u03b3.", "formula_coordinates": [22.0, 72.0, 604.54, 468.0, 90.72]}, {"formula_id": "formula_72", "formula_text": "\u2200v \u2208 R \u2200t \u2208 [\u22121, +1] m P S\u2190{\u22121,+1} m T \u2190M (S) m i max{0, T i \u2022 S i } \u2265 v T = t \u2264 P S\u2190Bernoulli( e \u03b5 e \u03b5 +1 ),F F (t) + m i |t i | \u2022\u0160 i \u2265 v ,", "formula_coordinates": [23.0, 127.85, 176.83, 356.31, 76.9]}, {"formula_id": "formula_73", "formula_text": "F : [\u22121, 1] m \u2192 {0, 1, \u2022 \u2022 \u2022 , m} satisfies E S\u2190{\u22121,+1} m T \u2190M (S),F [F (T )] \u2264 2m\u03b4.", "formula_coordinates": [23.0, 105.82, 265.62, 319.36, 24.47]}, {"formula_id": "formula_74", "formula_text": "P S\u2190Bernoulli( e \u03b5 e \u03b5 +1 ),F F (t) + m i |t i | \u2022\u0160 i \u2265 g m,\u03b5 (t, \u03b3) + \u03c4 \u2264 P S\u2190Bernoulli( e \u03b5 e \u03b5 +1 ),F \u03c4 + m i |t i | \u2022\u0160 i \u2265 g m,\u03b5 (t, \u03b3) + \u03c4 + P F [F (t) > \u03c4 ] \u2264 P S\u2190Bernoulli( e \u03b5 e \u03b5 +1 ),F m i |t i | \u2022\u0160 i \u2265 g m,\u03b5 (t, \u03b3) + E F [F (t)] \u03c4 \u2264 \u03b3 + E F [F (t)]", "formula_coordinates": [23.0, 133.57, 331.84, 344.85, 145.54]}, {"formula_id": "formula_75", "formula_text": "\u2200\u03b3 \u2208 [0, 1] \u2200\u03c4 > 0 P S\u2190{\u22121,+1} m T \u2190M (S) m i max{0, T i \u2022 S i } \u2265 g m,\u03b5 (T, \u03b3) + \u03c4 \u2264 \u03b3 + E S\u2190{\u22121,+1} m T \u2190M (S),F [F (T )] \u03c4 \u2264 \u03b3 + 2m\u03b4 \u03c4 .", "formula_coordinates": [23.0, 132.57, 522.01, 338.56, 109.53]}, {"formula_id": "formula_76", "formula_text": "For i \u2208 [m] sample S i \u2208 {\u22121, +1} independently with E [S i ] = 0. Set S i = 1 for all i \u2208 [n] \\ [m]. 4: Split x into x IN \u2208 X nIN and x OUT \u2208 X nOUT according to S, where n IN + n OUT = n. Namely, if S i = 1,", "formula_coordinates": [24.0, 76.21, 127.66, 463.8, 21.61]}, {"formula_id": "formula_77", "formula_text": "Compute g t = \u2207 wt\u22121 (w t\u22121 , x * ) \u2208 R d .", "formula_coordinates": [24.0, 134.54, 269.55, 165.95, 11.23]}, {"formula_id": "formula_78", "formula_text": "Clip\u011d t = min 1, c g t 2 \u2022 g t \u2208 R d .", "formula_coordinates": [24.0, 134.54, 285.02, 148.93, 14.08]}, {"formula_id": "formula_79", "formula_text": "0 , w 1 , \u2022 \u2022 \u2022 , w ) : i \u2208 [m] \u2208 R m . 21: end if 22: Sort the scores Y . Let T \u2208 {\u22121, 0, +1} m be", "formula_coordinates": [24.0, 72.0, 349.08, 375.73, 34.22]}, {"formula_id": "formula_80", "formula_text": "[S i + \u03be i > c] = r 2m .", "formula_coordinates": [30.0, 439.84, 435.84, 93.89, 15.82]}, {"formula_id": "formula_81", "formula_text": "Independently sample T i \u2208 {\u22121, +1} with P [T i = s i ] = m\u03b4 r\u03b2 + 1 \u2212 m\u03b4 r\u03b2", "formula_coordinates": [32.0, 127.02, 189.74, 353.36, 15.82]}, {"formula_id": "formula_82", "formula_text": "P X\u2190P n Y \u2190A(X) [q(Y, X) \u2212 q(Y, P ) \u2265 \u03b3] \u2264 P W \u2265 (1+\u03b3\u2212 3 2 \u03b7)n 2 + 2 \u2022 e \u2212n\u03b7 2 /2 + max i\u2208[n] 2n\u03b4 i P (1+\u03b3\u2212 3 2 \u03b7)n 2 >W \u2265 (1+\u03b3\u2212 3 2 \u03b7)n 2 \u2212 i , whereW \u2190 Binomial n, e \u03b5 e \u03b5 +1", "formula_coordinates": [38.0, 72.0, 499.82, 448.93, 72.81]}, {"formula_id": "formula_83", "formula_text": "Lemma B.2. Let x + , x \u2212 \u2208 X n . For s \u2208 {\u22121, +1} n , define x s \u2208 X n by x s i = x + i if s i = +1 and x s i = x \u2212 i if s i = \u22121. Let A : X n \u2192 Y be (\u03b5, \u03b4)-DP (for replacement). Let q : Y \u00d7 X \u2192 [0, 1], and denote q(y, x) = 1 n n i q(y, x i ) \u2208 [0, 1] for y \u2208 Y and x \u2208 X n .", "formula_coordinates": [38.0, 72.0, 619.83, 468.01, 44.95]}, {"formula_id": "formula_84", "formula_text": "P S\u2190{\u22121,+1} n Y \u2190A(x S ) q(Y, x S ) \u2212 q(Y, x \u2212S ) \u2265 v n \u2264 P W \u2265 v \u2212 r + n 2 + max i\u2208[n] 2n\u03b4 i P v \u2212 r + n 2 >W \u2265 v \u2212 r + n 2 \u2212 i + e \u2212r 2 /", "formula_coordinates": [39.0, 90.38, 91.16, 419.61, 65.63]}, {"formula_id": "formula_85", "formula_text": "x + i ) \u2212 q(y, x \u2212 i )) \u2208 {\u22121, +1} for all y \u2208 Y and all i \u2208 [n]. That is, for each coordinate i \u2208 [n], we independently randomly round q(y, x + i ) \u2212 q(y, x \u2212 i ) \u2208 [\u22121, +1] to {\u22121, +1}", "formula_coordinates": [39.0, 72.0, 255.78, 468.01, 43.89]}, {"formula_id": "formula_86", "formula_text": "P S\u2190{\u22121,+1} n Y \u2190A(x S ) q(Y, x S ) \u2212 q(Y, x \u2212S ) \u2265 v n = P S\u2190{\u22121,+1} n Y \u2190A(x S ) n i q(Y, x S i ) \u2212 q(Y, x \u2212S i ) \u2265 v = P S\u2190{\u22121,+1} n Y \u2190A(x S ) n i (q(Y, x + i ) \u2212 q(Y, x \u2212 i )) \u2022 S i \u2265 v = P S\u2190{\u22121,+1} n Y \u2190A(x S ) E R n i R(q(Y, x + i ) \u2212 q(Y, x \u2212 i )) \u2022 S i \u2265 v \u2264 P S\u2190{\u22121,+1} n Y \u2190A(x S ),R n i R(q(Y, x + i ) \u2212 q(Y, x \u2212 i )) \u2022 S i \u2265 v \u2212 r + e \u2212r 2 /2n (Hoeffding & union) = P S\u2190{\u22121,+1} n T \u2190M (S) n i T i \u2022 S i \u2265 v \u2212 r + e \u2212r 2 /2n = P S\u2190{\u22121,+1} n T \u2190M (S) n i 2 max{0, T i \u2022 S i } \u2212 |T i | \u2265 v \u2212 r + e \u2212r 2 /2n (S i \u2208 {\u22121, +1}) = P S\u2190{\u22121,+1} n T \u2190M (S) n i max{0, T i \u2022 S i } \u2265 v \u2212 r + n 2 + e \u2212r 2 /2n (|T i | = 1) \u2264 P W \u2265 v \u2212 r + n 2 + max i\u2208[n] 2n\u03b4 i P v \u2212 r + n 2 >W \u2265 v \u2212 r + n 2 \u2212 i + e \u2212r 2 /2n ,", "formula_coordinates": [39.0, 93.06, 330.49, 446.95, 358.78]}, {"formula_id": "formula_87", "formula_text": "\u2200v \u2208 R P W * > v \u2265 sup t\u2208support(M (s)) P S\u2190Bernoulli( e \u03b5 e \u03b5 +1 ) n n i\u0160 i \u2022 |t i | > v .", "formula_coordinates": [40.0, 127.02, 110.14, 357.96, 35.77]}, {"formula_id": "formula_88", "formula_text": "P X, X\u2190P n Y \u2190A(X) q(Y, X) \u2212 q(Y, X) \u2265 \u03b3 \u2264 P W \u2265 (1 + \u03b3 \u2212 \u03b7)n 2 + max i\u2208[n] 2n\u03b4 i P (1 + \u03b3 \u2212 \u03b7)n 2 >W \u2265 (1 + \u03b3 \u2212 \u03b7)n 2 \u2212 i + e \u2212n\u03b7 2 /2 , whereW \u2190 Binomial n, e \u03b5 e \u03b5 +1 .", "formula_coordinates": [40.0, 72.0, 275.12, 474.33, 83.21]}, {"formula_id": "formula_89", "formula_text": "E X + ,X \u2212 \u2190P n \uf8ee \uf8f0 P S\u2190{\u22121,+1} n Y \u2190A(X S ) q(Y, X S ) \u2212 q(Y, X \u2212S ) \u2265 v n \uf8f9 \uf8fb \u2264 P W \u2265 v \u2212 r + n 2 + max i\u2208[n] 2n\u03b4 i P v \u2212 r + n 2 >W \u2265 v \u2212 r + n 2 \u2212 i + e \u2212r 2 /2n ,", "formula_coordinates": [40.0, 89.89, 399.22, 432.22, 74.88]}, {"formula_id": "formula_90", "formula_text": "P X, X\u2190P n Y \u2190A(X) q(Y, X) \u2212 q(Y, X) \u2265 \u03b3 = E X + ,X \u2212 \u2190P n \uf8ee \uf8f0 P S\u2190{\u22121,+1} n Y \u2190A(X S ) q(Y, X S ) \u2212 q(Y, X \u2212S ) \u2265 v n \uf8f9 \uf8fb for v = \u03b3n \u2265 0. Setting r = n\u03b7 yields the result.", "formula_coordinates": [40.0, 72.0, 520.0, 454.93, 62.54]}, {"formula_id": "formula_91", "formula_text": "P X, X\u2190P n Y \u2190A(X) q(Y, X) \u2212 q(Y, X) \u2265 \u03b3 \u2264 P W \u2265 (1 + \u03b3 \u2212 \u03b7)n 2 + max i\u2208[n] 2n\u03b4 i P (1 + \u03b3 \u2212 \u03b7)n 2 >W \u2265 (1 + \u03b3 \u2212 \u03b7)n 2 \u2212 i + e \u2212n\u03b7 2 /2 ,", "formula_coordinates": [40.0, 73.2, 636.32, 472.28, 57.29]}, {"formula_id": "formula_92", "formula_text": "\u2200y \u2208 Y P X\u2190P n q(y, X) \u2212 q(y, P ) \u2265 \u03b7 2 \u2264 exp(\u2212n\u03b7 2 /2).", "formula_coordinates": [41.0, 159.43, 96.73, 293.15, 27.56]}, {"formula_id": "formula_93", "formula_text": "P X\u2190P n Y \u2190A(X) [q(Y, X) \u2212 q(Y, P ) \u2265 \u03b3] \u2264 P X, X\u2190P n Y \u2190A(X) q(Y, X) \u2212 q(Y, P ) \u2265 \u03b3 \u2212 \u03b7/2 + P X, X\u2190P n Y \u2190A(X) q(Y, X) \u2212 q(Y, X) \u2265 \u03b7/2 .", "formula_coordinates": [41.0, 109.53, 166.05, 394.13, 54.95]}, {"formula_id": "formula_94", "formula_text": "P X\u2190P n Y \u2190A(X) [q(Y, X) \u2212 q(Y, P ) \u2265 \u03b3] \u2264 P W \u2265 (1 + \u03b3 \u2212 \u03b7/2 \u2212 \u03b7)n 2 + 2 \u2022 e \u2212n\u03b7 2 /2 + max i\u2208[n] 2n\u03b4 i P (1 + \u03b3 \u2212 \u03b7/2 \u2212 \u03b7)n 2 >W \u2265 (1 + \u03b3 \u2212 \u03b7/2 \u2212 \u03b7)n 2 \u2212 i .", "formula_coordinates": [41.0, 123.08, 262.02, 367.05, 88.43]}, {"formula_id": "formula_95", "formula_text": "Y \u00d7 X \u2192 [0, 1]. For x \u2208 X n and y \u2208 Y, denote q(y, x) = 1 n n i q(y, x i ) \u2208 [0, 1] and q(y, P ) = E X\u2190P [q(y, X)] \u2208 [0, 1]. Suppose P X\u2190P n (Y,Z)\u2190A(X) [|Z \u2212 q(Y, X)| \u2265 \u03b1] \u2264 \u03b2.", "formula_coordinates": [41.0, 393.81, 674.72, 145.69, 12.1]}, {"formula_id": "formula_96", "formula_text": "P X\u2190P n (Y,Z)\u2190A(X) [|Z \u2212 q(Y, P )| > \u03b1 + e \u03b5 \u2212 1 + c + 2d] \u2264 \u03b2 c + \u03b4 d .(13)", "formula_coordinates": [42.0, 164.02, 154.76, 375.98, 30.47]}, {"formula_id": "formula_97", "formula_text": "Y \u00d7 X \u2192 [0, 1]. For x \u2208 X n and y \u2208 Y, denote q(y, x) = 1 n n i q(y, x i ) \u2208 [0, 1] and q(y, P ) = E X\u2190P [q(y, X)] \u2208 [0, 1]. Suppose P X\u2190P n (Y,Z)\u2190M (X) [|Z \u2212 q(Y, X)| \u2265 \u03b1] \u2264 \u03b2.", "formula_coordinates": [42.0, 72.0, 209.09, 468.01, 75.96]}, {"formula_id": "formula_98", "formula_text": "P X\u2190P n (Y,Z)\u2190A(X) [|Z \u2212 q(Y, P )| \u2265 \u03b1 + \u03b3] \u2264 \u03b2 + P W \u2265 (1+\u03b3\u2212 3 2 \u03b7)n 2 + 2 \u2022 e \u2212n\u03b7 2 /2 + max i\u2208[n] 2n\u03b4 i P (1+\u03b3\u2212 3 2 \u03b7)n 2 >W \u2265 (1+\u03b3\u2212 3 2 \u03b7)n 2 \u2212 i , (14) whereW \u2190 Binomial n, e \u03b5 e \u03b5 +1", "formula_coordinates": [42.0, 72.0, 314.49, 468.0, 73.73]}, {"formula_id": "formula_99", "formula_text": "P X\u2190P n (Y,Z)\u2190A(X) |Z \u2212 q(Y, P )| \u2265 \u03b1 + e \u03b5 \u2212 1 e \u03b5 + 1 + c \u2264 \u03b2 + 3 \u2022 e \u2212n 2 25 c 2 (15)", "formula_coordinates": [42.0, 155.08, 439.71, 384.92, 32.08]}, {"formula_id": "formula_100", "formula_text": "P X\u2190P n (Y,Z)\u2190A(X) [|Z \u2212 q(Y, P )| > \u03b1 + e \u03b5 \u2212 1 + c] \u2264 \u03b2 c .(16)", "formula_coordinates": [42.0, 188.65, 498.27, 351.35, 30.47]}, {"formula_id": "formula_101", "formula_text": "I(S; M (S)) \u2264 (e \u03b5 \u2212 1 + \u03b4) \u2022 m \u2022 log e,(17)", "formula_coordinates": [43.0, 212.69, 157.64, 327.31, 12.7]}, {"formula_id": "formula_102", "formula_text": "I(S; M (S)) \u2264 1 2 \u03b5 2 \u2022 m \u2022 log e. (18", "formula_coordinates": [43.0, 233.19, 218.21, 301.6, 26.77]}, {"formula_id": "formula_103", "formula_text": ")", "formula_coordinates": [43.0, 534.8, 226.3, 5.2, 10.48]}, {"formula_id": "formula_104", "formula_text": "If M : {\u22121, 1} m \u2192 Y satisfies (\u03b5, \u03b4)-DP and S \u2208 {\u22121, 1} m is uniformly random, then I(S; M (S)) \u2264 1 8 \u03b5 2 \u2022 m \u2022 log e + \u03b4 \u2022 m \u2022 log 2. (19", "formula_coordinates": [43.0, 72.0, 297.02, 468.0, 66.02]}, {"formula_id": "formula_105", "formula_text": ")", "formula_coordinates": [43.0, 534.8, 344.35, 5.2, 10.48]}, {"formula_id": "formula_106", "formula_text": "R 0 := e \u03b5 \u2022 Q 0 \u2212 Q 1 e \u03b5 \u2212 1 and R 1 := e \u03b5 \u2022 Q 1 \u2212 Q 0 e \u03b5 \u2212 1 , so that Q 0 = e \u03b5 \u2022R 0 +R 1 e \u03b5 +1", "formula_coordinates": [44.0, 72.0, 258.85, 364.59, 51.15]}, {"formula_id": "formula_107", "formula_text": "Q 0 = e \u03b5 (1 \u2212 \u03b4) e \u03b5 + 1 \u2022 R 0 + 1 \u2212 \u03b4 e \u03b5 + 1 \u2022 R 1 + \u03b4 \u2022 Q 0 and Q 1 = e \u03b5 (1 \u2212 \u03b4) e \u03b5 + 1 \u2022 R 1 + 1 \u2212 \u03b4 e \u03b5 + 1 \u2022 R 0 + \u03b4 \u2022 Q 1 .", "formula_coordinates": [44.0, 72.0, 316.63, 341.47, 72.01]}, {"formula_id": "formula_108", "formula_text": "Q 0 = e \u03b5 (1 \u2212 \u03b4) e \u03b5 + 1 , 1 \u2212 \u03b4 e \u03b5 + 1 , \u03b4, 0 , Q 1 = 1 \u2212 \u03b4 e \u03b5 + 1 , e \u03b5 (1 \u2212 \u03b4) e \u03b5 + 1 , 0, \u03b4 .", "formula_coordinates": [44.0, 226.13, 529.55, 159.74, 61.07]}, {"formula_id": "formula_109", "formula_text": "I(S i ; M (S)|S \u2212i = s \u2212i ) = pD 1 (Q 1 Q p ) + (1 \u2212 p)D 1 (Q 0 Q p ) \u2264 pD 1 Q 1 Q p + (1 \u2212 p)D 1 Q 0 Q p .", "formula_coordinates": [44.0, 146.76, 652.11, 318.49, 33.57]}, {"formula_id": "formula_110", "formula_text": "pD 1 Q 1 Q p + (1 \u2212 p)D 1 Q 0 Q p = p 1 \u2212 \u03b4 e \u03b5 +", "formula_coordinates": [45.0, 72.0, 102.93, 166.0, 48.32]}, {"formula_id": "formula_111", "formula_text": "\u2200\u03b5 \u2265 0 g(\u03b5) := log 2 \u2212 log(1 + e \u2212\u03b5 ) \u2212 \u03b5 e \u03b5 + 1 \u2264 \u03b5 2 8 ,", "formula_coordinates": [45.0, 170.78, 478.41, 270.43, 28.39]}], "doi": ""}