{"title": "Sustainable Operation and Management of Data Center Chillers using Temporal Data Mining", "authors": "Debprakash Patnaik; Manish Marwah; Ratnesh Sharma; Naren Ramakrishnan", "pub_date": "", "abstract": "Motivation: Data centers are a critical component of modern IT infrastructure but are also among the worst environmental offenders through their increasing energy usage and the resulting large carbon footprints. Efficient management of data centers, including power management, networking, and cooling infrastructure, is hence crucial to sustainability. In the absence of a \"first-principles\" approach to manage these complex components and their interactions, datadriven approaches have become attractive and tenable. Results: We present a temporal data mining solution to model and optimize performance of data center chillers, a key component of the cooling infrastructure. It helps bridge raw, numeric, time-series information from sensor streams toward higher level characterizations of chiller behavior, suitable for a data center engineer. To aid in this transduction, temporal data streams are first encoded into a symbolic representation, next run-length encoded segments are mined to form frequent motifs in time series, and finally these metrics are evaluated by their contributions to sustainability. A key innovation in our application is the ability to intersperse \"don't care\" transitions (e.g., transients) in continuous-valued time series data, an advantage we inherit by the application of frequent episode mining to symbolized representations of numeric time series. Our approach provides both qualitative and quantitative characterizations of the sensor streams to the data center engineer, to aid him in tuning chiller operating characteristics. This system is currently being prototyped for a data center managed by HP and experimental results from this application reveal the promise of our approach.", "sections": [{"heading": "INTRODUCTION", "text": "Data centers have become a ubiquitous element of modern IT infrastructure, especially in the services sector that requires \"always-on\" capability. Practically every large IT organization hosts a data center, either in-house or outsourced to major vendors. Furthermore, the recent emergence of the software as a service (SaaS) paradigm or more generically cloud computing, coupled with emerging web-based business, social networking and media applications and services have led to a tremendous growth in the number, size, and power densities of data centers.\nRecently, data centers have become an object of scorn for environmentalists, due to their increasing energy usage and the resulting large carbon footprints. For instance, a recent study [25] claims that a web search uses half the equivalent energy of boiling a kettle of water! The US EPA estimates that energy usage at data centers is experiencing successive doubling every five years, and that the annual electricity cost at these centers can amount to $7.4 billion by 2011, with 10% of this amount being borne by the government. Furthermore, to meet the projected growth in demand would require the construction of 10 power plants! Sustainable data center research is hence becoming acknowledged as an important problem with the foremost of implications for future energy consumption and its environmental impact [14].\nA key goal is to adaptively manage demands on power, cooling, and energy efficiency without compromising reliability and performance constraints. State-of-the-art data centers today provide capabilities for adaptive, configurable operation at the level of each subsystem such as power distribution, cooling, and compute server racks. The traditional approach to perform such adaptation is to conduct detailed computational fluid dynamics (CFD)-based modeling of air and temperature flows [19] through a data center. However, such methods are computationally intensive, and even for a small data center (say, about 3000 sq. ft.), it can easily take several hours for a model of reasonable accuracy to converge! The computational infeasibility of such large-scale simulations coupled with the relative ease of gathering real-time data from sensors has led researchers to deploy sensor networks to track environmental data (e.g. temperature, humidity), operational state of systems and devices (e.g. utilization), and workload information (e.g. user requests). Since the sheer volume of such data precludes manual inspection, automated data mining and knowledge discovery techniques are important to glean vital information. Furthermore, to close the loop between instrumentation and control/management leading to energy efficiency, what is required are high-level capabilities to transduce the data streams into actionable knowledge for the data center administrator.\nWhile data centers constitute a mix of computing elements, networking infrastructure, storage systems along with power management and cooling capabilities, all of which contribute to energy usage and sources of inefficiency, in this paper we primarily focus on the cooling infrastructure, especially chillers, as a case study for illustrating the importance of data mining solutions. In particular, we show how temporal data mining can bridge the gap between low-level, raw, sensor streams, and the high-level operating regions needed for an engineer to efficiently manage the data center.\nThis paper makes the following contributions:\n\u2022 We present a three-stage solution for mining data center chiller data involving (i) change point detection, (ii) motif mining, and (iii) sustainability evaluation. This design helps data center administrators to impart significant domain knowledge in the algorithms underlying each stage.\n\u2022 Our notion of motifs can accommodate \"don't care\" transitions (e.g., transients), an advantage we inherit by the application of frequent episode mining to symbolized representations of multivariate numeric data. They also help characterize sustainability metrics that serve as a handle for future tuning and management of data center operations.\n\u2022 We present our algorithms in the context of managing the chiller subsystem of a data center managed by HP in Bangalore, India. To the best of our knowledge, our work is the first to use temporal data mining techniques to bear upon the cooling infrastructure of a production data center. Our KDD approach on this data center demonstrates that it is, in fact, possible to have sustainable operation as well as economical advantages, thus demonstrating that these are not conflicting objectives.", "publication_ref": ["b24", "b13", "b18"], "figure_ref": [], "table_ref": []}, {"heading": "BACKGROUND", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Data Centers", "text": "Figure 1 shows a data center consisting of IT equipment (servers, storage, networking) fitted in racks arranged as rows. A large data center could contain thousands of racks occupying several tens of thousands of square feet of space. Also shown in the figure are computer room air conditioning (CRAC) units that cool the exhaust hot air from the IT racks. Energy consumption in data center cooling comprises work done to distribute the cool air and to extract heat from the hot exhaust air. A refrigerated or chilled water cooling coil in a CRAC unit extracts the heat from the air and cools it within a range of 10 \u2022 C to 18 \u2022 C. The cooling infrastructure of a data center is shown in Figure 2.\nKey elements of this infrastructure include CRAC units, plumbing and pumps for chilled water distribution, chiller units and cooling towers. Heat dissipated from IT equipment is extracted by CRAC units and transferred to the chilled water distribution system. Chillers extract heat from the chilled water system and reject it to the environment through cooling towers or heat exchangers. In addition to the IT equipment, the data center cooling infrastructure can account for up to 50% of the total power demand [2]. The CRAC units provide two actuators that can be controlled. The variable frequency drive (VFD) controls the blower speed and the chilled water value regulates the amount of chilled water flowing into a unit (between 0% and 100%). These built-in flexibilities allow the units to be adjusted according to the workload demand in the data center. The demand is detected via temperature sensors installed on the racks throughout a data center.\nC R A C u n it 1 C R A C u n it 2 C R A C u n it 3 C R A C u n it 6 C R A C u n it 4 C R A C u n it 5", "publication_ref": ["b1"], "figure_ref": ["fig_6"], "table_ref": []}, {"heading": "Data Center Chillers", "text": "The focus of this paper is on chiller units that receive warm water (at temperature, Tin) from the CRAC units, extract heat from it and recirculate the chilled water (at temperature, Tout) back to the CRAC units. ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Stopping Starting", "text": "Stopped Running Power On", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Chiller Architecture and Operation", "text": "Each chiller is composed of four basic components, namely, evaporator, multi-stage centrifugal compressor, economizer and water-cooled or air-cooled condenser. Liquid refrigerant is distributed along the length of the evaporator to absorb enough heat from the water returning from the data center and circulated through the evaporator tubes to vaporize. The gaseous refrigerant is then drawn into the first stage of compressor. Compressed gas passes from the multi-stage compressor into the condenser. Cooling tower water circulated through the condenser tubes absorbs heat from the refrigerant, causing it to condense. The liquid refrigerant then passes through an orifice plate into the economizer. Flashed gases enter the compressor while the liquid flows into the evaporator to complete the circuit. Starting and stopping a chiller is a complex, multi-step process. Fig. 3 shows the operational state diagram of a typical chiller. On power-on, the chiller waits for the compressors to start, after a prescribed delay. On startup, the chiller utilization varies to match the cooling load. Based on chiller technology, chiller compressors can throttle in discrete stages or continuously. Feedback control is used to maintain the outlet temperature, Tout, close to a userspecified set-point temperature.", "publication_ref": [], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "Terminology and Metrics", "text": "Here we define some terms used in context of a data center chiller unit. IT cooling load. This is the amount of heat that is generated (and thus needs to be dissipated) at a data center. It is approximately equivalent to the power consumed by the equipment since almost all of it is dissipated as heat. It is commonly specified in kilowatts (KW). COP. The coefficient of performance (COP) of a chiller unit indicates how efficiently the unit provides cooling, and, is defined as the ratio between the cooling provided and the power consumed, i.e.,\nCOPi = Li Pi (1)\nwhere Li is the cooling load on the ith chiller unit and Pi is the power consumed by it.\nChiller utilization. This is the percentage of the total capacity of a chiller unit that is in use. It depends on a variety of factors, mainly, the mass flow rate of water that passes through a chiller and the degree of cooling provided, that is, the difference between the inlet and outlet temperatures (Tin \u2212 Tout). For a particular Tout, an administrator can control the utilization at a chiller through power capping or by changing the mass flow rate of water. Chiller power consumption. This is simply the power consumed by a chiller unit. Although power meters that measure aggregate power consumption of data center infrastructure elements are usually available, meters that measure power consumed by an individual entity or a specific group (e.g. chillers) may not always be installed. In such cases, if the capacity of the unit and average COP are known, they, together with unit utilization, can be used to estimate power consumed.\nPi = Ui * Ci 100 * COPi (2\n)\nwhere Pi is the power consumed, Ui the utilization, and Ci the capacity, all pertaining to the ith chiller unit.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Ensembles of Chiller Units", "text": "The number of chiller units required depend on the size and thermal density of a data center. While one unit may be sufficient for a small data center, several units operating as an ensemble may be required to satisfy the cooling demand of a large data center. Figure 4 shows an ensemble of chiller units that collectively provide cooling for a data center. Out of the five units shown, three are air-cooled while the remaining two are water-cooled. Also, to provide a highly available data center and ensure business continuity, sufficient spare capacity is usually provisioned to meet the cooling demand in the event of one or more units becoming unavailable as a result of failure or required maintenance. ", "publication_ref": [], "figure_ref": ["fig_2"], "table_ref": []}, {"heading": "Operational Challenges", "text": "Although operating curves for individual chiller units exist, no model is available for operation of an ensemble, especially one consisting of heterogeneous units. Additionally, shift and/or drift of response characteristics with time further complicate their management. The operational goals are to satisfy the cooling requirements while minimizing the total power consumption of the ensemble and maximizing the average lifespan of the units. While multiple factors impact the lifespan of a chiller unit, an important one is: rapid and large oscillations in utilization value. High amplitude and frequent variations in utilization due to varying load or some failure condition result in decreased lifespan, and, thus, need to be minimized.\nWhy are rapid oscillations bad? Frequent start and stop cycles lead to fatigue of mechanical parts due to high torque requirements, and, deterioration of electrical circuitry due to high inrush current. Moreover, load fluctuations due to cycling can also lead to drop in power factor and potential penalties from the utility. In case of data centers with on-site generation, such fluctuations can lead to reliability issues at the generators as well. Downstream of chillers, pump performance and cooling tower efficiency can also be adversely affected. Typically chillers have an MTBF (mean time between failure) of 20,000 hours or more, which can reduce exponentially due to oscillations.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "How can data mining help?", "text": "While administration of a single chiller unit is not complicated, configuring an ensemble of chillers for optimal performance is a challenging task, especially in the presence of a dynamically varying cooling load [3]. Typically, heuristics and rules-of-thumb are used to make decisions regarding:\n\u2022 Which chiller unit(s) should be turned on/off, and when?\n\u2022 What utilization range should a particular unit be operated at?\n\u2022 How should the ensemble react to an increase or decrease in cooling demand?\nAny guidance regarding questions posed above while maintaining performance and optimizing the above stated goals will be invaluable to a data center facilities administrator.", "publication_ref": ["b2"], "figure_ref": [], "table_ref": []}, {"heading": "PRIOR WORK", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Mining Systems and Installations", "text": "Many researchers have explored the use of data mining to optimize computer system design. For instance, modeling of rack-level temperature data specifically in relation to CRAC layout has been undertaken in [1,23]. Optimization opportunities at multiple levels of smart center architecture have also been studied in [24]. More recent work [16] focuses on sensor data mining to identify anomalous and deviant behavior. Other related work includes the InteMon system from CMU [7,6] that dynamically tracks correlations among multiple time series [18]. Interactive visualizations for system management have also been investigated [17]. Beyond these projects, most research at the intersection of data mining and high performance systems has focused on compute clusters, not necessarily data centers. For instance, failure prediction in IBM Blue Gene systems by analyzing event logs has been explored [10]. While these works constitute important strides in analytics, in order to support high-level knowledge discovery capabilities, we must raise the level of abstraction at which we study and infer patterns from sensor data streams.", "publication_ref": ["b0", "b22", "b23", "b15", "b6", "b5", "b17", "b16", "b9"], "figure_ref": [], "table_ref": []}, {"heading": "Approaches to model time series data", "text": "There are numerous formalisms available to model time series data and good surveys are in [5,12]. One broad class of representations conducts global decompositions of the time series (e.g., PCA, DFT, wavelets) and aims to use only the most significant components to model the series.\nAlternatively, piecewise representations are easier to compute and also lend themselves to a streaming mode of operation. Representations like SAX [13] first perform a piecewise aggregate approximation (the aggregate refers to the notion of modeling the given, single, time series by a linear combination of multiple time series, each expressed as a box basis function) and symbolize the resulting representation so that techniques from discrete algorithms can be adapted toward querying, matching, and mining the time series. In our work, we seek to design representations for multivariate time series data (the works surveyed here focus on a single series) and also to enjoy the benefits of symbolization of series for ease and flexibility of analysis, as described below.", "publication_ref": ["b4", "b11", "b12"], "figure_ref": [], "table_ref": []}, {"heading": "Finding motifs in time series", "text": "Motif mining is the task of finding approximately repeated subsequences in time series, and studied in various works, e.g., [4,11,19,27]. Mining motifs in symbolized representations of the time series can drawn upon the rich body of literature in bioinformatics, where motifs have been used to characterized regulatory regions in the genome. As the work closest to ours, we explicitly focus on the SAX representation, which also provides some significant advantages for mining motifs. First, a random projection algorithm is used to hash segments of the original time-series into a map. If two segments are hashed into the same bucket, they are considered as candidate motifs. In a refinement step all candidate motif subsequences are compared using a distance metric to find the set of motifs with the highest number of non-trivial matches. A contrasting framework, referred to as frequent episode discovery, is an event based framework that is most applicable to symbolic data that is not uniformly sampled [8,9,15,20]. This enables the introduction of junk, or \"don't care\" states, into the definition of what constitutes a frequent episode.", "publication_ref": ["b3", "b10", "b18", "b26", "b7", "b8", "b14", "b19"], "figure_ref": [], "table_ref": []}, {"heading": "ALGORITHMS", "text": "Our primary goal is to link the multivariate, numeric, time series temperature data gathered from chiller units to high level sustainability characterizations. We decompose this goal into change point detection, motif mining, and sustainability characterization, thus using motifs as a crucial intermediate representation to aid in data reduction. The algorithms presented here, while being natural generalizations and combinations of prior work, have not been proposed before.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Change point detection", "text": "Prior work in multivariate change point detection (e.g., see [26] has posited statistical models for behavior within a segment and tracks changes in model parameters to denote qualitative change points. Our task is exacerbated by the lack of adequate models to characterize chiller behavior and also because of the varying interpretations that are attachable to multivariate data.\nFirst, a motif or a trend can manifest in a single series or in multiple series. Second, even when it manifests in multiple series, the specificity with which it manifests can be fixed or variable. For instance, a motif can be 'three chiller units show oscillatory behavior' versus 'first three chiller units show oscillatory behavior.' Since we seek to mine motifs so that their presence/absence can be cross-correlated with the chiller design (e.g., air cooled versus water cooled), we seek motifs of the latter form.\nA multivariate time series T = t1, . . . , tm is an ordered set of real-valued vectors of a particular variable. Each realvalued vector t i captures the utilizations across all the chiller units. Although a streaming algorithm would be more suitable in the context of time series data, the current implementation is intended more as a diagnostic tool than for prediction. We first perform a k-means clustering on these vectors and use the cluster labels as symbols to encode the time series. Observe that the multivariate series is now encoded as a single symbol sequence. This sequence of cluster labels is then analyzed to detect the change points. See Fig. 5 for an illustration of this approach.", "publication_ref": ["b25"], "figure_ref": ["fig_5"], "table_ref": []}, {"heading": "Motif mining", "text": "Already we have suitably raised the representation from multivariate numeric data. We raise the level of abstraction further by doing a run-length encoding of the symbol sequence and noting where transitions from one symbol to another occur. This gives us a sequence of events for input to serial episode mining as illustrated below.  Frequent episode mining is now conducted over this sequence of transitions. We adopt the framework of serial episodes with inter-event constraints. The structure of a serial episode \u03b1 is given as:\n\u03b1 = E1 (0,d 1 ] \u2192 E2 . . . (0,d n\u22121 ] \u2192 En (3)\nHere E1, . . . , En are the event-types participating in the episode \u03b1 and, for our domain, these event types are cluster symbol indices. Note that a serial episode requires a total order among the events. Each pair of event-types in \u03b1 is associated with an inter-event constraint. For example the pair E1 \u2192 E2, is associated with (0, d1] such that in an occurrence of \u03b1 event E2 occurs no later than time d1 of event E1.\nThe mining process follows the level-wise procedure ala Apriori, i.e., candidate generation followed by counting.\nThe candidate generation scheme is based on matching the n\u22121 size suffix of one n-node frequent episode with the n\u22121 size prefix of the another n-node frequent episode at a given level to generate candidates for the next level. The time complexity of the candidate generation process is O(m 2 n), where n is the size of each frequent episode in the given level, m is the number of frequent episodes in that level, since all pairs of frequent episodes need to be compared for a prefix-suffix match.\nThe algorithm for counting the set of candidates episodes is given in Algorithm 1. The count or frequency measure is based on non-overlapped occurrences [8]. Two occurrences of an episode are said to be non-overlapped if the events in one occurrence appear between the events in the other occurrence. This notion most naturally eliminates the problem of trivial matches highlighted in [19] where a match is found between two slightly shifted segments of the time series. Algorithm 1 takes as input the event-sequence and a set of candidate episodes and returns the set of frequent episodes for a given frequency threshold \u03b8. The algorithm counts the maximum number of non-overlapped occurrences of each episode with the inter-event time constraint (0, T ]. This approach also allows repeated symbols or events in the episodes.\nThe worst case time complexity of the counting algorithm is give by O(lnm), where l is the number of events in the data sequence, m is number of candidate episodes and n is the size of the episode. The algorithm makes one pass of all the events in the event sequence and every time an event that belongs to an episode is seen the data structure s for the episode is updated. A hash map is used to efficiently locate only a subset of relevant episodes for each event seen in the event sequence. Since our method allows repeated symbols, in the case of such episodes the same event can update s structure at most n times. Therefore if the levelwise growth of candidates is sufficiently arrested by a suitable choice threshold, the algorithm scales linearly with data size.\nRecall here that the events in mined frequent episodes correspond to transitions from one symbol to another. Our hypothesis here is that if motif occurrences are matched at transitions under an inter-transition gap constraint, then the corresponding time series subsequences will match under a suitable distance metric. In addition the episode mining framework allows for robustness to noise and scaling. The distance metric under which such motifs can be shown to be similar needs further investigation. None-the-less this technique is found to be very effective in unearthing similar time series subsequences in real data sets.", "publication_ref": ["b7", "b18"], "figure_ref": [], "table_ref": []}, {"heading": "Sustainability Characterization", "text": "It is difficult (and subjective) to compare two motifs in terms of their sustainability impact by inspecting them visually. Therefore, it is necessary to quantify the sustainability of all motifs by computing a sustainability metric for them. This would enable quantitative comparisons between motifs; their categorization as 'good' or 'bad' from the sustainability metric point-of-view; and, furthermore, this information\nR1 R2 R3 R4 R5", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Sequence of cluster labels iiiiiiiiiiiiiiii i i i i i i i i iiiii i i ii ii i i i i i ii ii iiiiiiiiiiiiiiiiiiii", "text": "Sequence of transition events  could be used to provide guidance to an administrator or a management system regarding the most 'sustainable' configurations of the chiller ensemble under a particular load.\nThere are several sustainability metrics, such as, power consumed, carbon footprint, and exergy loss [22]. Note that typically optimizing a sustainability metric, such as power consumed, also minimizes the total cost of operation. \nS = {(Ei, ti)}. Output: Frequent episodes F : \u03b1 \u2208 F if \u03b1.count \u2265 \u03b8 /*Initialize*/ waits = \u03c6 for all \u03b1 \u2208 C do \u03b1.count = 0 s = Array of size N , each cell initialized to -\u221e for i = 1 to|\u03b1| do waits[E \u03b1(i) ].append(\u03b1, s, i) for all (E k , t k ) \u2208 S do for all (\u03b1, s, i) \u2208 waits[E k ] do if (i = 1) or (t k \u2212 s[i \u2212 1] \u2264 T ) then /*First event or Satisfies the time constraint*/ if (i = |\u03b1|) then \u03b1.count = \u03b1.count + 1 Reinitialize all elements of s to \u2212\u221e else s[i] = t k Output F = {\u03b1 : \u03b1 \u2208 C such that \u03b1.count \u2265 \u03b8}\nIn this paper, we estimate two sustainability metrics for each motif: (1) the average COP of the motif; and, (2) a metric reflecting the frequency and amplitude of oscillations in utilization values. The average COP is calculated using Eqn. 1, where the load during motif i, averaged over all its occurrences, is used as Li, and, the averaged power consumption of the motif as Pi. The power is estimated using Eqn. 2 with a COP of 3.5 for the air-cooled and 6 for the water-cooled chillers. The COP of a motif quantifies the cooling effectiveness of the ensemble during that motif. In order to estimate the frequency of oscillations of a motif, we compute the number of mean-crossings, that is, the number of times the utilization crosses the mean value. This is very similar to number of zero-crossings that is commonly used in speech processing for estimation of frequency. This, together with standard deviation of a motif, allows oscillatory behavior to be compared.", "publication_ref": ["b21"], "figure_ref": [], "table_ref": []}, {"heading": "EXPERIMENTAL RESULTS", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Datasets", "text": "We applied our motif mining methodology to chiller data obtained from a large HP production data center covering 70,000 square feet with 2000 racks of IT equipment. Its cooling demand is met by an ensemble of five chiller units. The ensemble consists of two types of chillers -three are aircooled and the remaining two are water-cooled. The data is spread over three different time periods: ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Motifs", "text": "In all, 22 motifs were discovered in the chiller utilization data whose qualitative properties are summarized in Table 3 (more on this later). From a quantitative point of view these motifs can be clustered into groups based on load. One such group (Group II) is depicted in Table 1   . This information provides key insights to an administrator regarding motifs that are more energy efficient compared to others. Furthermore, this information could be codified into rules for setting chiller ensemble configuration based on the current load.\nTable 2 shows the most efficient and the least efficient motifs for Group II based on power consumption, determined by the motif's COP value. Also shown are the potential power savings assuming that the least efficient motif could be transformed into the most efficient one.\nTable 3 provides a qualitative description of all the motifs. They are grouped together manually based on similar utilization behavior of each of the chillers in the ensemble. Two factors are considered -the average utilization during the motif, and, the oscillatory behavior. The utilization level is labeled as low (L), medium (M) or high (H) based on the average utilization ranges of (0, 35), (35, 65) or (65, 100), respectively. The oscillatory behavior is marked (1) none (N) -which indicates steady values with minor variations; (2) small (S) -which indicates the values show oscillations that have a small amplitude; and finally, (3) large (L) -which indicates oscillations with a large amplitude. Furthermore, units that are not operating are marked 'OFF'.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_3", "tab_2"]}, {"heading": "Comparing motifs 5 and 8", "text": "We investigate now in more detail the differences between motifs 5 and 8 of Group II. While both motifs 5 and 8 have three chillers turned on, they are of different types. In motif 8, all three operating chillers (C1, C2 and C3) are air-cooled. In motif 5, two air-cooled (C1 and C2) and one water-cooled chiller (C4) are running. The qualitative behavior of the chillers in the two motifs are show in Table 3. In motif 5, one chiller runs at high utilization (C4 at 66.5%), while the other two run at low utilizations (11.3% and 33.8%). In motif 8, one chiller runs at low utilization (17.63) while the other two operate at the medium range (49.1% and 44.3%). The amount of oscillatory behavior in the two motifs is about the same as indicated by the average rate of mean-crossings and standard deviation in Table 1. In both the motifs, one air-cooled chiller show large oscillations.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_3"]}, {"heading": "Economical incentives for sustainable operation", "text": "Business growth is an important factor in planning for investment in infrastructure. Chillers, of the kind described in this paper, can cost upwards of $150k and typically, depreciate over 15-20 years. In the absence of intelligent management, the annual operating cost, even at 50% load, can be equally high. Maximizing utilization and efficiency is crucial to achieve a favorable return on investment. Operating chillers among favorable motifs that satisfy these conditions will enable IT administrators to sustain growth in business without major capital or maintenance costs. It will not only prolong the useful life of the existing equipment but postpone expensive retrofits and further infrastructure investments.\nThe cost savings by operating in favorable motif regimes can be quite easily characterized by multiplying the kW savings by 0.11\u00d724\u00d7365 to obtain the annual savings in dollars ($). Here, $0.11 is assumed to be the cost per KWh (kilo watt hour) of electricity. In this case switching from motif 8 to motif 5 gives us a nearly $40,000 in annual savings! Extrapolating this cost saving to other similar motifs gives us an idea of the utility of data mining algorithms in helping achieve cost effectiveness. Observe that this is just the operational footprint; there is also an \"embedded carbon footprint\" of the chiller unit (as added in its manufacturing process). By maximizing operational life and utilization, we are managing this embedded carbon in the equipment as well. In other words, we are limiting the increase in embedded carbon in the environment while delivering the cooling required.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Carbon footprint calculation", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "DISCUSSION", "text": "We have demonstrated a powerful approach to data mining for data centers that helps situate trends gathered from sensor streams in the context of sustainability metrics useful for the data center engineer. Our future work is in several categories. First, we seek to perform streaming analysis of the chiller data to provide real-time actionable input to manage the operational state of chillers. Second, we seek to explore the co-existence possibility of both short (i.e., lasting at most a few hours) and longer motifs (e.g., spanning half a day to possibly multiple days) and use this information to perform higher order minings of motifs [21], i.e., to detect patterns composed of motifs themselves. Third, we seek to use other sustainability metrics to characterize the    MC -number of mean-crossings per minute N -number of occurrences of the motif motifs; for instance, through lifetime analysis to convert the loss in a chiller's lifetime into a power number. Eventually, we would like to use temporal data mining to uncover a complete model of the data center which can then be tuned/controlled/optimized, thus making data mining an integral part of the data center architecture. To achieve this, we need to model the transfer function in a way that encapsulates workload changes, manual steering of chiller operation, and other intermittent transients and recoverable faults. We propose to use our motifs as a handle to redescribe time series data so that significant portions of time series progression can be captured via state transition diagrams. Control strategies can then be assessed by superimposing their likely trajectories over the state transition diagrams and quantifying their stability characterizations. This will enable us to use data mining not simply as a post-processing data interpretation phase but to actually form dynamic models of data center chillers and their control strategies.", "publication_ref": ["b20"], "figure_ref": [], "table_ref": []}, {"heading": "REPEATABILITY", "text": "We are committed to repeatability of our results. Datasets and source codes used in this paper are available at: http://neural-code.cs.vt.edu/chiller", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgments", "text": "This work was supported in part by the Institute for Critical Technology and Applied Science (ICTAS), Virginia Tech. The authors also wish to thank Mohandas Mekanapurath and Vaibhav Bhatia for their support in data collection from a production data center environment.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Analysis of environmental data in datacenters", "journal": "", "year": "2007", "authors": "L Bautista; R Sharma"}, {"ref_id": "b1", "title": "In the data center, power and cooling costs more than the IT equipment it supports", "journal": "Electronics Cooling", "year": "2007-02", "authors": "C L Belady"}, {"ref_id": "b2", "title": "Viability of dynamic cooling control in a data center environment. Electronic Packaging", "journal": "", "year": "2006-06", "authors": "T Boucher"}, {"ref_id": "b3", "title": "Probabilistic discovery of time series motifs", "journal": "ACM", "year": "2003", "authors": "B Chiu; E Keogh; S Lonardi"}, {"ref_id": "b4", "title": "Querying and mining of time series data: experimental comparison of representations and distance measures", "journal": "VLDB J", "year": "2008", "authors": "H Ding"}, {"ref_id": "b5", "title": "Intemon: Continuous mining of sensor data in large-scale self-infrastructures", "journal": "SIGOPS Oper. Syst. Rev", "year": "2006", "authors": "E Hoke"}, {"ref_id": "b6", "title": "Intemon: Intelligent system monitoring on large clusters", "journal": "", "year": "2006", "authors": "E Hoke; J Sun; C Faloutsos"}, {"ref_id": "b7", "title": "Discovering frequent episodes and learning hidden markov models: A formal connection", "journal": "IEEE TKDE", "year": "2005", "authors": "S Laxman; P S Sastry; K P Unnikrishnan"}, {"ref_id": "b8", "title": "Stream prediction using a generative model based on frequent episodes in event sequences", "journal": "", "year": "2008-08", "authors": "S Laxman; V Tankasali; R W White"}, {"ref_id": "b9", "title": "Failure Prediction in IBM BlueGene/L Event Logs", "journal": "", "year": "2007", "authors": "Y Liang"}, {"ref_id": "b10", "title": "Finding motifs in time series", "journal": "", "year": "2002", "authors": "J Lin"}, {"ref_id": "b11", "title": "A symbolic representation of time series, with implications for streaming algorithms", "journal": "ACM", "year": "2003", "authors": "J Lin"}, {"ref_id": "b12", "title": "Experiencing SAX: A Novel Symbolic Representation of Time Series", "journal": "Data Min. Knowl. Discov", "year": "2007", "authors": "J Lin"}, {"ref_id": "b13", "title": "Demand for data puts engineers in spotlight", "journal": "New York Times", "year": "2008-06-17", "authors": "S Lohr"}, {"ref_id": "b14", "title": "Discovery of frequent episodes in event sequences", "journal": "Data Mining and Knowledge Discovery", "year": "1997", "authors": "H Mannila; H Toivonen; A I Verkamo"}, {"ref_id": "b15", "title": "Stream mining of sensor data for anomalous behavior detection in data centers", "journal": "", "year": "2008", "authors": "M Marwah"}, {"ref_id": "b16", "title": "Interactive visual exploration of system management time-series data", "journal": "ACM", "year": "2008", "authors": "P Mclachlan"}, {"ref_id": "b17", "title": "Streaming Pattern Discovery in Multiple Time-series", "journal": "VLDB Endowment", "year": "2005", "authors": "S Papadimitriou; J Sun; C Faloutsos"}, {"ref_id": "b18", "title": "Mining Motifs in Massive Time Series Databases", "journal": "", "year": "2002", "authors": "P Patel"}, {"ref_id": "b19", "title": "Inferring neuronal network connectivity from spike data: A temporal data mining approach", "journal": "Scientific Programming", "year": "2008", "authors": "D Patnaik; P S Sastry; K P Unnikrishnan"}, {"ref_id": "b20", "title": "Higher order mining", "journal": "SIGKDD Explor. Newsl", "year": "2008", "authors": "J F Roddick"}, {"ref_id": "b21", "title": "Exergy analysis of data center thermal management systems", "journal": "Journal of Heat Transfer", "year": "2008", "authors": "A J Shah"}, {"ref_id": "b22", "title": "Application of exploratory data analysis (eda) techniques to temperature data in a conventional data center", "journal": "", "year": "2007", "authors": "R Sharma"}, {"ref_id": "b23", "title": "On building next generation data centers: Energy flow in the information technology stack", "journal": "", "year": "2008", "authors": "R Sharma"}, {"ref_id": "b24", "title": "Revealed: The environmental impact of google searches. The Sunday Times", "journal": "", "year": "2009-01-11", "authors": "A Wissner-Gross"}, {"ref_id": "b25", "title": "Modeling Changing Dependency Structure in Multivariate Time Series", "journal": "ACM", "year": "2007", "authors": "X Xuan; K Murphy"}, {"ref_id": "b26", "title": "Detecting Time Series Motifs under Uniform Scaling", "journal": "ACM", "year": "2007", "authors": "D Yankov"}], "figures": [{"figure_label": "12", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 :Figure 2 :12Figure 1: Thermal map of a data center showing racks arranged in rows and CRAC units.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 3 :3Figure 3: Operational state diagram of a chiller unit.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 4 :4Figure 4: Five chiller units work in tandem to provide cooling for a large data center.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Symbol Sequence : d d d b a c c d d d d c b \u21d3 Event Sequence : (d-b, 4), (b-a, 5), (a-c, 6), (c-d, 8), (d-c, 12), (c-b, 13) Counting episode: B\u2212>A\u2212>B\u2212>A Motif occurrences on original time series", "figure_data": ""}, {"figure_label": "6", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 6 :6Figure 6: Illustration of motif mining in a single time-series using frequent episodes", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Figure 5 :5Figure 5: (left) Illustration of change detection in multi-variate time series data. (right) Our overall methodology of using frequent motifs for sustainability characterization.", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Algorithm 11Counting occurrences of serial episodes with inter-event time constraint [0, T ) Input: Candidate episodes C = {\u03b11, . . . , \u03b1m}, where \u03b1i = E \u03b1 i (1) \u2192 . . . E \u03b1 i (N ) is a N -node episode, Inter-event time constraint T and frequency threshold \u03b8, Event sequence", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "( 1 )1July 2, 2008 to July 7, 2008; (2) November 27, 2008 to November 30, 2008; and (3) December 16, 2008 to December 26, 2008; totaling over 480 hours.", "figure_data": ""}, {"figure_label": "7", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "Figure 7 :7Figure 7: Characterization of operating states of the ensemble of chillers using clustering", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "Saving 1kWh of energy is equivalent to preventing release of 0.8 kg of carbon dioxide into the atmosphere. Based on the energy savings number, we can calculate the reduced carbon footprint. Saved Power = 41kW Saved Energy (annually) = 41kW \u00d7 8760 hrs Reduction in Carbon footprint = 41kW \u00d7 8760 \u00d7 0.8 = 287328 kg CO 2", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_10", "figure_caption": "in Group II Most Efficient Motif in Group II 7/3/2008 00:24:00 7/3/2008 06:28:00 7/3/2008 20:47:00 7/4/2008 02:40:00 7/3/2008 13:37:00", "figure_data": ""}, {"figure_label": "8", "figure_type": "figure", "figure_id": "fig_11", "figure_caption": "Figure 8 :8Figure 8: Two motifs with similar load but widely varying levels of efficiency. Observe how the least efficient motif transitions to the most efficient motif in the given time period.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "with other quantitative measures. Although each group has very similar load levels, the COP within a group varies with the motifs. In Group II, for instance, motif 8 has a COP of 4.87, while", "figure_data": "ClusterPowerAvg UtilDev.#Samples ColorID(in tons)(in %)4944.38 185.34187.8868114859.10 168.60204.3569920832.14 163.31151.5878118829.87 162.86151.0977212768.14 150.7547.68148519706.24 138.60166.9813821666.01 130.71109.986535659.68 129.47115.7812998597.20 117.2040.7137236583.26 114.47143.876679479.3794.0881.3894916464.3091.12164.4156217456.8489.6671.88150415431.8684.7580.5497511395.6577.65215.8212507348.9268.4859.9723303326.9264.1658.0343132325.9363.9750.96228013312.7761.38164.5197010268.8952.7721.081388"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "The most and least efficient motif for each group and the potential power savings if the operational state of the chiller ensemble could be transformed from the least to the most efficient motif.Load (KW) Most Efficient Least Efficient Potential Power SavingsAve.", "figure_data": "StdMotifMotifKW%Group II 20893558419.83%"}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "Summary of the quantitative measures associated with motifs. Shown here are statistics for motif in one of the load groups.", "figure_data": "Load PowerSpanMotif (KW) (KW) COP MCStd (min) NGroup II820284174.87 .042 5.055010220734005.18.048 4.2811317520763845.4.048 4.254935420833875.38.048 4.318223621194225.02.044 4.085123321214145.13.042 4.3111911121233955.38.046 4.3917210"}], "formulas": [{"formula_id": "formula_0", "formula_text": "C R A C u n it 1 C R A C u n it 2 C R A C u n it 3 C R A C u n it 6 C R A C u n it 4 C R A C u n it 5", "formula_coordinates": [2.0, 332.85, 68.36, 207.81, 120.5]}, {"formula_id": "formula_1", "formula_text": "COPi = Li Pi (1)", "formula_coordinates": [3.0, 149.67, 642.47, 143.23, 19.74]}, {"formula_id": "formula_2", "formula_text": "Pi = Ui * Ci 100 * COPi (2", "formula_coordinates": [3.0, 401.61, 206.73, 150.38, 19.74]}, {"formula_id": "formula_3", "formula_text": ")", "formula_coordinates": [3.0, 551.99, 212.53, 3.93, 7.86]}, {"formula_id": "formula_4", "formula_text": "\u03b1 = E1 (0,d 1 ] \u2192 E2 . . . (0,d n\u22121 ] \u2192 En (3)", "formula_coordinates": [5.0, 109.01, 649.49, 183.9, 12.25]}, {"formula_id": "formula_5", "formula_text": "R1 R2 R3 R4 R5", "formula_coordinates": [6.0, 89.06, 68.19, 3.69, 125.65]}, {"formula_id": "formula_6", "formula_text": "S = {(Ei, ti)}. Output: Frequent episodes F : \u03b1 \u2208 F if \u03b1.count \u2265 \u03b8 /*Initialize*/ waits = \u03c6 for all \u03b1 \u2208 C do \u03b1.count = 0 s = Array of size N , each cell initialized to -\u221e for i = 1 to|\u03b1| do waits[E \u03b1(i) ].append(\u03b1, s, i) for all (E k , t k ) \u2208 S do for all (\u03b1, s, i) \u2208 waits[E k ] do if (i = 1) or (t k \u2212 s[i \u2212 1] \u2264 T ) then /*First event or Satisfies the time constraint*/ if (i = |\u03b1|) then \u03b1.count = \u03b1.count + 1 Reinitialize all elements of s to \u2212\u221e else s[i] = t k Output F = {\u03b1 : \u03b1 \u2208 C such that \u03b1.count \u2265 \u03b8}", "formula_coordinates": [6.0, 53.8, 463.84, 225.93, 196.16]}], "doi": ""}