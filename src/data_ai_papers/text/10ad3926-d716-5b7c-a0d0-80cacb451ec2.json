{"title": "Multi-camera Scene Reconstruction via Graph Cuts", "authors": "Vladimir Kolmogorov; Ramin Zabih", "pub_date": "", "abstract": "We address the problem of computing the 3-dimensional shape of an arbitrary scene from a set of images taken at known viewpoints. Multi-camera scene reconstruction is a natural generalization of the stereo matching problem. However, it is much more difficult than stereo, primarily due to the difficulty of reasoning about visibility. In this paper, we take an approach that has yielded excellent results for stereo, namely energy minimization via graph cuts. We first give an energy minimization formulation of the multi-camera scene reconstruction problem. The energy that we minimize treats the input images symmetrically, handles visibility properly, and imposes spatial smoothness while preserving discontinuities. As the energy function is NP-hard to minimize exactly, we give a graph cut algorithm that computes a local minimum in a strong sense. We handle all camera configurations where voxel coloring can be used, which is a large and natural class. Experimental data demonstrates the effectiveness of our approach.", "sections": [{"heading": "Introduction", "text": "Reconstructing an object's 3-dimensional shape from a set of cameras is a classic vision problem. In the last few years, it has attracted a great deal of interest, partly due to a number of new applications both in vision and in graphics that require good reconstructions. While the problem can be viewed as a natural generalization of stereo, it is considerably harder. The major reason for this is the difficulty of reasoning about visibility. In stereo matching, most scene elements are visible from both cameras, and it is possible to obtain good results without addressing visibility constraints. In the more general scene reconstruction problem, however, very few scene elements are visible from every camera, so the issue of visibility cannot be ignored.\nIn this paper, we approach the scene reconstruction problem from the point of view of energy minimization. Energy minimization has several theoretical advantages, but has generally been viewed as too slow for early vision to be practical. Our approach is motivated by some recent work in early vision, where fast energy minimization algorithms have been developed based on graph cuts [6,7,12,14,20,21]. These methods give strong experimental results in practice, as documented in two recent evaluations of stereo algorithms using real imagery with dense ground truth [22,27].\nThe energy that we minimize has three important properties:\nit treats the input images symmetrically, it handles visibility properly, and it imposes spatial smoothness while also preserving discontinuities.\nWe begin with a review of related work. In section 3 we give a precise definition of the problem that we wish to solve, and define the energy that we will minimize. Section 4 describes how we use graph cuts to compute a strong local minimum of this energy. Experimental data is presented in section 5. Some details of the graph cut construction are deferred to the appendix, along with a proof that computing the global minimum of the energy is NP-hard.", "publication_ref": ["b5", "b6", "b11", "b13", "b19", "b20", "b21", "b26"], "figure_ref": [], "table_ref": []}, {"heading": "Related work", "text": "The problem of reconstructing a scene from multiple cameras has received a great deal of attention in the last few years. One extensively-explored approach to this problem is voxel occupancy. In voxel occupancy [18,25] the scene is represented as a set of 3-dimensional voxels, and the task is to label the individual voxels as filled or empty. Voxel occupancy is typically solved using silhouette intersection, usually from multiple cameras but sometimes from a single camera with the object placed on a turntable [8]. It is known that the output of silhouette intersection even without noise is not the actual 3-dimensional shape, but rather an approximation called the visual hull [17].", "publication_ref": ["b17", "b24", "b7", "b16"], "figure_ref": [], "table_ref": []}, {"heading": "Voxel coloring and space carving", "text": "Voxel occupancy, however, fails to exploit the consistent appearance of a scene element between different cameras. This constraint, called photo-consistency, is obviously quite powerful. Two well-known recent algorithms that have used photo-consistency are voxel coloring [23] and space carving [16].\nVoxel coloring makes a single pass through voxel space, first computing the visibility of each voxel and then its color. There is a constraint on the camera geometry, namely that no scene point is allowed to be within the convex hull of the camera centers. As we will see in section 3, our approach handles all the camera configurations where voxel coloring can be used. Space carving is another voxel-oriented approach that uses the photo-consistency constraint to prune away empty voxels from the volume. Space carving has the advantage of allowing arbitrary camera geometry.\nOne major limitation of voxel coloring and space carving is that they lack a way of imposing spatial coherence. This is particularly problematic because the image data is almost always ambiguous. Another (related) limitation comes from the fact that these methods traverse the volume making \"hard\" decisions concerning the occupancy of each voxel they analyze. Because the data is ambiguous, such a decision can easily be incorrect, and there is no easy way to undo such a decision later on.", "publication_ref": ["b22", "b15"], "figure_ref": [], "table_ref": []}, {"heading": "Energy minimization approaches", "text": "Our approach to the scene reconstruction problem is to generalize some recently developed techniques that give strong results for stereo matching. It is well known that stereo, like many problems in early vision, can be elegantly stated in terms of energy minimization [19]. The energy minimization problem has traditionally been solved via simulated annealing [2,11], which is extremely slow in practice.\nIn the last few years powerful energy minimization algorithms have been developed based on graph cuts [6,7,12,14,21]. These methods are fast enough to be practical, and yield quite promising experimental results for stereo [22,27]. Unlike simulated annealing, graph cut methods cannot be applied to an arbitrary energy function; instead, for each energy function to be minimized, a careful graph construction must be developed. In this paper, instead of building a special purpose graph we will use some recent results [15] that give graph constructions for a quite general class of energy functions.\nWhile energy minimization has been widely used for stereo, only a few papers [13,20,24] have used it for scene reconstruction. The energy minimization formalism has several advantages. It allows a clean specification of the problem to be solved, as opposed to the algorithm used to solve it. In addition, energy minimization naturally allows the use of soft constraints, such as spatial coherence. In an energy minimization framework, it is possible to cause ambiguities to be resolved in a manner that leads to a spatially smooth answer. Finally, energy minimization avoids being trapped by early hard decisions.\nAlthough [20] and [24] use energy minimization via graph cuts, their focus is quite different from ours. [20] uses an energy function whose global minimum can be computed efficiently via graph cuts; however, the spatial smoothness term is not discontinuity preserving, and so the results tend to be oversmoothed. Visibility constraints are not used. [24] computes the global minimum of a different energy function as an alternative to silhouette intersection (i.e., to determine voxel occupancy). Their approach does not deal with photoconsistency at all, nor do they reason about visibility.\nOur method is perhaps closest to the work of [13], which also relies on graph cuts. They extend the work of [7], which focused on traditional stereo matching, to allow an explicit label for occluded pixels. While the energy function that they use is of a similar general form to ours, they do not treat the input images symmetrically. While we effectively compute a disparity map with respect to each camera, they compute a disparity map only with respect to a single camera.\n[26] also proposed the use of disparity maps for each camera, in an energy minimization framework. Their optimization scheme did not rely on graph cuts, and their emphasis was on the two-camera stereo problem. They also focused on handling transparency, which is an issue that we do not address.\nAnother approach is to formulate the problem in terms of level sets, and to solve a system of partial differential equations using numerical techniques [9]. The major distinction between this approach and our work is that their problem formulation is continuous while ours is discrete. The discrete energy minimization approach is known to lead to strong results for two-camera stereo [22,27], and is therefore worth investigating for multiple cameras.\nIn [14] we proposed a (two camera) stereo algorithm that shares a number of properties with the present work. That method treats the input images symmetrically, and is based on graph cuts for energy minimization. It properly handles the limited form of visibility constraint that arises with two cameras (namely, occlusions). The major difference is that [14] is limited to the case of two cameras, while the multi-camera problem is much more difficult.", "publication_ref": ["b18", "b1", "b10", "b5", "b6", "b11", "b13", "b20", "b21", "b26", "b14", "b12", "b19", "b23", "b19", "b23", "b19", "b23", "b12", "b6", "b8", "b21", "b26", "b13", "b13"], "figure_ref": [], "table_ref": []}, {"heading": "Problem formulation", "text": "Suppose we are given n calibrated images of the same scene taken from different viewpoints (or at different moments of time). Let P i be the set of pixels in the camera i, and let P = P 1 \u222a . . . \u222a P n be the set of all pixels. A pixel p \u2208 P corresponds to a ray in 3D-space. Consider the point of the first intersection of this ray with an object in the scene. Our goal is to find the depth of this point for all pixels in all images. Thus, we want to find a labeling f : P \u2192 L where L is a discrete set of labels corresponding to different depths. In the current implementation of our method, labels correspond to increasing depth from a fixed camera.\nA pair p, l where p \u2208 P, l \u2208 L corresponds to some point in 3D-space. We will refer to such pairs as 3D-points.\nThe limitation of our method is that there must exist a function D : R 3 \u2192 R such that for all scene points P and Q, P occludes Q in a camera i only if D(P ) < D(Q). This is exactly the constraint used in voxel coloring [23]. If such a function exists then labels correspond to level sets of this function. In our current implementation, we make a slightly more specific assumption, which is that the cameras must lie in one semiplane looking at the other semiplane. The interpretation of labels will be as follows: each label corresponds to a plane in 3D-space, and a 3D-point p, l is the intersection of the ray corresponding to the pixel p and the plane l.\nLet us introduce the set of interactions I consisting of (unordered) pairs of 3D-points p 1 , l 1 , p 2 , l 2 \"close\" to each other in 3D-space. We will discuss several criteria for \"closeness\" later. In general, I can be an arbitrary set of pairs of 3D-points satisfying the following constraint:\n-Only 3D-points at the same depth can interact, i.e.if { p 1 , l 1 , p 2 , l 2 } \u2208 I then l 1 = l 2 .\nNow we will define the energy function that we minimize. It will consist of three terms:\nE(f ) = E data (f ) + E smoothness (f ) + E visibility (f ) ( 1 )\nThe data term will impose photo-consistency. It is\nE data (f ) = p,f (p) , q,f (q) \u2208I D(p, q)\nwhere D(p, q) is a non-positive value depending on intensities of pixels p and q. It can be, for example,\nD(p, q) = min{0, (Intensity(p) \u2212 Intensity(q)) 2 \u2212 K}\nfor some constant K > 0.\nSince we minimize the energy, terms D(p, q) that we sum will be small. These terms are required to be non-negative for technical reasons that will be described in section 4.2. Thus, pairs of pixels p, q which come from the same scene point according to the configuration f will have similar intensities, which causes photo-consistency.\nThe smoothness term involves a notion of neighborhood; we assume that there is a neighborhood system on pixels\nN \u2282 {{p, q} | p, q \u2208 P}\nThis can be the usual 4-neighborhood system: pixels p = (p x , p y ) and q = (q x , q y ) are neighbors if they are in the same image and |p x \u2212 q x | + |p y \u2212 q y | = 1. We will write the smoothness term as\nE smoothess (f ) = {p,q}\u2208N V {p,q} (f (p), f(q))\nWe will require the term V {p,q} to be a metric. This imposes smoothness while preserving discontinuities, as long as we pick an appropriate robust metric. For example, we can use the robustified\nL 1 distance V (l 1 , l 2 ) = min(|l 1 \u2212 l 2 |, K) for constant K.\nThe last term will encode the visibility constraint: it will be zero if this constraint is satisfied, and infinity otherwise. We can write this using another set of interactions I vis which contains pairs of 3D-points violating the visibility constraint:\nE visibility (f ) = p,f (p) , q,f (q) \u2208Ivis \u221e\nWe require the set I vis to meet following condition:\n-Only 3D-points at different depths can interact, i.e. if { p 1 , l 1 , p 2 , l 2 } \u2208 I vis then l 1 = l 2 .\nThe visibility constraint says that if a 3D-point p, l is present in a configuration f (i.e. l = f (p)) then it \"blocks\" views from other cameras: if a ray corresponding to a pixel q goes through (or close to) p, l then its depth is at most l. Again, we need a definition of \"closeness\". We will use the set I this part of the construction of I vis . The set I vis can then be defined as follows: it will contain all pairs of 3D-points p, l , q, l such that p, l and q, l interact (i.e. they are in I) and l > l.\nAn important issue is the choice of the sets of interactions I. This basically defines a discretization. It can consist, for example, of pairs of 3D-points { p, l , q, l } such that the distance in 3D-space between these points is less than some threshold. However, with this definition of closeness the number of interactions per pixel may vary greatly from pixel to pixel. Instead, we chose the following criterion: if p is a pixel in the image i, q is a pixel in the image j and i < j then the 3D-points p, l , q, l interact if the closest pixel to the projection of p, l onto the image j is q. Of course, we can include only interactions between certain images, for example, taken by neighboring cameras. Note that it makes sense to include interactions only between different cameras.\nAn example of our problem formulation in action is shown in figure 1. There are two cameras C1 and C2. There are 5 labels shown as black vertical lines. As in our current implementation, labels are distributed by increasing distance from a fixed camera. Two pixels, p from C1 and q from C2 are shown, along with the red round 3D-point q, 2 and the blue round 3D-point p, 2 . These points share the same label, and interact (i.e., { p, 2 , q, 2 } \u2208 I). So there is a photoconsistency term between them. The green square point q, 3 is at a different label (greater depth), but is behind the red round point. The pair of 3D-points { p, 2 , q, 3 } is in I vis . So if the ray p from camera C1 sees the red round point p, 2 , the ray q from C2 cannot see the green square point q, 3 .\nWe show in the appendix that minimizing our energy is an NP-hard problem. Our approach, therefore, is to constuct an approximation algorithm based on graph cuts that finds a strong local minimum.", "publication_ref": ["b22"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Graph construction", "text": "We now show how to efficiently minimize E among all configurations using graph cuts. The output of our method will be a local minimum in a strong sense. In particular, consider an input configuration f and a disparity \u03b1. Another configuration f is defined to be within a single \u03b1-expansion of f when for all pixels p \u2208 P either f (p) = f (p) or f (p) = \u03b1. This notion of an expansion was proposed by [7], and forms the basis for several very effective stereo algorithms [3,7,13,14].\nOur algorithm is very straightforward; we simply select (in a fixed order or at random) a disparity \u03b1, and we find the unique configuration within a single \u03b1-expansion move (our local improvement step). If this decreases the energy, then we go there; if there is no \u03b1 that decreases the energy, we are done. Except for the problem formulation and the choice of energy function, this algorithm is identical to the methods of [7,14].\nOne restriction on the algorithm is that the initial configuration must satisfy the visibility constraint. This will guarantee that all subsequent configurations will satisfy this constraint as well, since we minimize the energy, and configurations that do not satisfy the visibility constraint have infinite energy.\nThe critical step in our method is to efficiently compute the \u03b1-expansion with the smallest energy. In this section, we show how to use graph cuts to solve this problem.", "publication_ref": ["b6", "b2", "b6", "b12", "b13", "b6", "b13"], "figure_ref": [], "table_ref": []}, {"heading": "Graph cuts", "text": "Let G = V, E be a weighted graph with two distinguished terminal vertices {s, t} called the source and sink. A cut C = V s , V t is a partition of the vertices into two sets such that s \u2208 V s and t \u2208 V t . (Note that a cut can also be equivalently defined as the set of edges between the two sets.) The cost of the cut, denoted |C|, equals the sum of the weights of the edges between a vertex in V s and a vertex in V t .\nThe minimum cut problem is to find the cut with the smallest cost. This problem can be solved very efficiently by computing the maximum flow between the terminals, according to a theorem due to Ford and Fulkerson [10]. There are a large number of fast algorithms for this problem (see [1], for example). The worst case complexity is low-order polynomial; however, in practice the running time is nearly linear for graphs with many short paths between the source and the sink, such as the one we will construct.\nWe will use a result from [15] which says that for energy functions of binary variables of the form\nE(x 1 , . . . , x n ) = i<j E i,j (x i , x j ) ( 2 )\nit is possible to construct a graph for minimizing it if and only if each term E i,j satisfies the following condition:\nE i,j (0, 0) + E i,j (1, 1) \u2264 E i,j (0, 1) + E i,j (1, 0) (3)\nIf these conditions are satisfied then the graph G is constructed as follows. We add a node v i for each variable x i . For each term E i,j (x i , x j ) we add edges which are given in the appendix.\nEvery cut on such a graph corresponds to some configuration x = (x 1 , . . . , x n ), and vice versa: if v i \u2208 V s then x i = 0, otherwise x i = 1. Edges on a graph were added in such a way that the cost of any cut is equal to the energy of the corresponding configuration plus a constant. Thus, the minimum cut on G yields the configuration that minimizes the energy.", "publication_ref": ["b9", "b0", "b14"], "figure_ref": [], "table_ref": []}, {"heading": "\u03b1-expansion", "text": "In this section we will show how to convert our energy function into the form of equation 2. Note that it is not necessary to use only terms E i,j for which i < j since we can swap the variables if necessary without affecting condition 3.\nAlthough pixels can have multiple labels and in general cannot be represented by binary variables, we can do it for the \u03b1-expansion operation. Indeed, any configuration f within a single \u03b1-expansion of the initial configuration f can be encoded by a binary vector x = {x p |p \u2208 P} where f (p) = f (p) if x p = 0, and f (p) = \u03b1 if x p = 1. Let us denote a configuration defined by a vector x as f x . Thus, we have the energy of binary variables:\nE(x) =\u1ebc data (x) +\u1ebc smoothness (x) +\u1ebc visibility (x) where\u1ebc data (x) = E data (f x ), E smoothness (x) = E smoothness (f x ), E visibility (x) = E visibility (f x ).\nLet's consider each term separately, and show that each satisfies condition (3).\n1. Data term.\nE data (x) = p,f x (p) , q,f x (q) \u2208I D(p, q) = p,l , q,l \u2208I T (f x (p) = f x (q) = l) \u2022 D(p, q)\nwhere T (\u2022) is 1 if its argument is true and 0 otherwise. Let's consider a single term\nE p,q (x p , x q ) = T (f x (p) = f x (q) = l) \u2022 D(p, q). Two cases are possible: 1A. l = \u03b1. If at least one of the labels f (p), f (q) is not l then E p,q \u2261 0. Suppose that f (p) = f (q) = l. Then E(x p , x q ) is equal to D(p, q), if x p = x q =\n0, and is zero otherwise. We assumed that D(p, q) is non-positive, thus, condition (3) holds:\nE p,q (0, 0) + E p,q (1, 1) = D(p, q) \u2264 0 = E p,q (0, 1) + E p,q (1, 0) 1B. l = \u03b1.\nIf at least one of the labels f (p), f (q) is \u03b1 then E p,q depends only on at most one variable so condition (3) holds. (Suppose, for example, that f (q) = \u03b1, then f x (q) = \u03b1 for any value of x q and, thus,\nE p,q (x p , 0) = E p,q (x p , 1) and E p,q (0, 0) + E p,q (1, 1) = E p,q (0, 1) + E p,q (1, 0).)\nNow suppose that both labels f (p), f (q) are not \u03b1. Then E(x p , x q ) is equal to D(p, q), if x p = x q = 1, and is zero otherwise. We assumed that D(p, q) is non-positive, thus, condition (3) holds:\nE p,q (0, 0) + E p,q (1, 1) = D(p, q) \u2264 0 = E p,q (0, 1) + E p,q (1, 0) 2. Smoothness term. E smoothness (x) = {p,q}\u2208N V {p,q} (f x (p), f x (q)). Let's consider a single term E p,q (x p , x q ) = V {p,q} (f x (p), f x (q)). We assumed that V {p,q} is a metric; thus, V {p,q} (\u03b1, \u03b1) = 0 and V {p,q} (f (p), f(q)) \u2264 V {p,q} (f (p), \u03b1)+ V {p,q} (\u03b1, f (q)), or E p,q (1, 1) = 0 and E p,q (0, 0) \u2264 E p,q (0, 1) + E p,q (1, 0). There- fore, condition (3) holds. 3. Visibility term.\u1ebc visibility (x) = p,f x (p) , q,f x (q) \u2208Ivis \u221e = p,lp , q,lq \u2208Ivis T (f x (p) = l p \u2227 f x (q) = l q ) \u2022 \u221e. Let's consider a single term E p,q (x p , x q ) = T (f x (p) = l p \u2227 f x (q) = l q ) \u2022 \u221e.\nE p,q (0, 0) must be zero since it corresponds to the visibility cost of the initial configuration and we assumed that the initial configuration satisfies the visibility constraint. Also E p,q (1, 1) is zero (if x p = x q = 1, then f x (p) = f x (q) = \u03b1 and, thus, the conditions f x (p) = l p and f x (q) = l q cannot both be true since I vis includes only pairs of 3D-points at different depths). Therefore, condition (3) holds since E p,q (0, 1) and E p,q (1, 0) are non-negative.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Experimental results", "text": "Some details of our implementation are below. The planes for labels were chosen to be orthogonal to the main axis of the middle camera, and to increase with depth. The labels are distributed so that disparities depend on labels approximately linearly. The depth difference between planes was chosen in such a way that a label change by one results in disparity change by at most one both in x and y directions. We selected the labels \u03b1 in random order, and kept this order for all iterations. We performed three iterations. (The number of iterations until convergence was at most five but the result was practically the same). We started with an initial solution in which all pixels are assigned to the label having the largest depth.\nFor our data term D we made use of the method of Birchfield and Tomasi [4] to handle sampling artifacts, with a slight variation: we compute intensity intervals for each band (R,G,B) using four neighbors, and then take the average data penalty. (We used color images; results for grayscale images are slightly worse). The constant K for the data term was chosen to be 30.\nWe used a simple Potts model for the smoothness term:\nV {p,q} (l p , l q ) = U {p,q} if l p = l q 0 ot h e rw i se (4)\nThe choice of U {p,q} was designed to make it more likely that a pair of adjacent pixels in one image with similar intensities would end up with similar disparities. For pixels {p, q} \u2208 N the term U {p,q} was implemented as an empirically selected decreasing function of \u2206I(p, q) as follows:\nU {p,q} = 3\u03bb if \u2206I(p, q) < 5 \u03bb otherwise (5\n)\nwhere \u2206I(p, q) is the average of values |Intensity(p) \u2212 Intensity(q)| for all three bands (R,G,B). Thus, the energy depends only on one parameter \u03bb. For different images we picked \u03bb empirically.\nWe performed experiments on three datasets: the 'head and lamp' image from Tsukuba University, the flower garden sequence and the Dayton sequence. We used 5 images for the Tsukuba dataset (center, left, right, top, bottom), 8 images for the flower garden sequence and 5 images for the Dayton sequence. For the Tsukuba dataset we performed two experiments: in the first one we used four pairs of interacting cameras (center-left, center-right, center-top, center-bottom), and in the second one we used all 10 possible pairs. For the flower garden and Dayton sequences we used 7 and 4 interacting pairs, respectively (only adjacent cameras interact). The table below show image dimensions and running times obtained on 450MHz UltraSPARC II processor. We used the max flow algorithm of [5], which is specifically designed for the kinds of graphs that arise in vision. Source code for this algorithm is available on the web from http://www.cs.cornell.edu/People/vnk. We have computed the error statistics for the Tsukuba dataset, which are shown in the table below. We determined the percentage of the pixels where the algorithm did not compute the correct disparity (the \"Errors\" column), or a disparity within \u00b11 of the correct disparity (\"Gross errors\"). For comparison, we have included the results from the best known algorithm for stereo reported in [27], which is the method of [7].\nThe images are shown in 2, along with the areas where we differ from ground truth (black is no difference, gray is a difference of \u00b11, and white is a larger difference). Inspecting the image shows that we in general achieve greater accuracy at discontinuities; for example, the camera in the background and the lamp are more accurate. The major weakness of our output is in the top right corner, which is an area of low texture. The behavior of our method in the presence of low texture needs further investigation.\nErrors Gross errors 4 interactions 6.13% 2.75% 10 interactions 4.53% 2.30% Boykov-Veksler-Zabih [7] 9.76% 3.99%\nWe have also experimented with the parameter sensitivity of our method for the Tsukuba dataset using 10 interactions. Since there is only one parameter, namely \u03bb in equation 5, it is easy to experimentally determine the algorithm's sensitivity. The table below shows that our method is relatively insensitive to the exact choice of \u03bb. ", "publication_ref": ["b3", "b4", "b26", "b6"], "figure_ref": [], "table_ref": []}, {"heading": "Extensions", "text": "It would be interesting to extend our approach to more general camera geometries, for example the case when cameras look at the object in the center from all directions. Labels could then correspond to spheres. More precisely, there would be two labels per sphere corresponding to the closest and farthest intersection points.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgements", "text": "This research was supported by NSF grants IIS-9900115 and CCR-0113371, and by a grant from Microsoft Research. We also thank Rick Szeliski for providing us with some of the imagery used in section 5.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Appendix: Edges for terms E i,j", "text": "In this section we show how to add edges for a term E i,j in the equation 2 assuming that condition (3) holds. This is a special case of a more general construction given in [15].\nif E(1, 0) > E(0, 0) then we add an edge (s, v i ) with the weight E(1, 0) \u2212 E(0, 0), otherwise we add an edge (v i , t) with the weight E(0, 0) \u2212 E(1, 0); if E(1, 0) > E(1, 1) then we add an edge (v j , t) with the weight E(1, 0) \u2212 E(1, 1), otherwise we add an edge (s, v j ) with the weight E(1, 1) \u2212 E(1, 0); the last edge that we add is (v i , v j ) with the weight E(0, 1) + E(1, 0) \u2212 E(0, 0) \u2212 E(1, 1).\nWe have omitted indices i, j in E i,j for simplicity of notation. Of course it is not necessary to add edges with zero weights. Also, when several edges are added from one node to another, it is possible to replace them with one edge with the weight equal to the sum of weights of individiual edges.", "publication_ref": ["b14"], "figure_ref": [], "table_ref": []}, {"heading": "Center image", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Ground truth", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Our results -4 interactions", "text": "Our results -10 interactions Boykov-Veksler-Zabih results [7] Comparison of our results with ground truth ", "publication_ref": ["b6"], "figure_ref": [], "table_ref": []}, {"heading": "Appendix: Minimizing our energy function is NP-hard", "text": "It is shown in [7] that the following problem, referred to as Potts energy minimization, is NP-hard. We are given as input a set of pixels S with a neighborhood system N \u2282 S \u00d7S, and a set of label values L and a non-negative function C : S \u00d7 L \u2192 + . We seek the labeling f : S \u2192 L that minimizes\nWe now sketch a proof that an arbitrary instance of the Potts energy minimization problem can be encoded as a problem minimizing the energy E defined in equation 1. This shows that the problem of minimizing E is also NP-hard. We start with a Potts energy minimization problem consisting of S, V, N and C. We will create a new instance of our energy minimization problem as follows. There will be |L| + 1 images. The first one will be the original image S, and for each each label l \u2208 L there will be an image P l . For each pixel p \u2208 S there will be a pixel in P l which we will denote as p l ; thus, |P l | = |S| for all labels l \u2208 L.\nThe set of labels L, the neighborhood system N and the smoothness function V {p,q} will be the same as in the Potts energy minimization problem:\nThe set of interactions I will include all pairs { p, l , p l , l }, where p \u2208 S, l \u2208 L. The corresponding cost will be\nwhere K p is a constant which ensures that all costs D(p, p l ) are non-positive (for example, K p = max l\u2208L C(p, l)). There will be no visibility term (i.e. the set of interactions I vis will be empty). The instance of our minimization problem is now completely specified.\nAny labeling f : S \u2192 L can be extended to the labelingf : P \u2192 L if we set f (p l ) = l, p l \u2208 P l . It is easy to check that E(f ) = E P (f ) \u2212 K where K = p\u2208S K p is a constant. Moreover, there is no labelingf : P \u2192 L with the smaller value of the energy E such thatf (p) =f (p) for all pixels p \u2208 S. Thus, the global minimumf of the energy E will yield the global minimum of the Potts energy E P (we need to take the restriction off on S).", "publication_ref": ["b6"], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Network Flows: Theory, Algorithms, and Applications", "journal": "Prentice Hall", "year": "1993", "authors": "K Ravindra; Thomas L Ahuja; James B Magnanti;  Orlin"}, {"ref_id": "b1", "title": "Stochastic stereo matching over scale", "journal": "International Journal of Computer Vision", "year": "1989", "authors": "Stephen Barnard"}, {"ref_id": "b2", "title": "Multiway cut for stereo and motion with slanted surfaces", "journal": "", "year": "1999", "authors": "S Birchfield; C Tomasi"}, {"ref_id": "b3", "title": "A pixel dissimilarity measure that is insensitive to image sampling", "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": "1998-04", "authors": "Stan Birchfield; Carlo Tomasi"}, {"ref_id": "b4", "title": "An experimental comparison of mincut/max-flow algorithms for energy minimization in computer vision", "journal": "Springer-Verlag", "year": "2001", "authors": "Yuri Boykov; Vladimir Kolmogorov"}, {"ref_id": "b5", "title": "Markov Random Fields with efficient approximations", "journal": "", "year": "1998", "authors": "Yuri Boykov; Olga Veksler; Ramin Zabih"}, {"ref_id": "b6", "title": "Fast approximate energy minimization via graph cuts", "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": "2001-11", "authors": "Yuri Boykov; Olga Veksler; Ramin Zabih"}, {"ref_id": "b7", "title": "Surface shape from the deformation of apparent contours", "journal": "International Journal of Computer Vision", "year": "1992-11", "authors": "R Cipolla; A Blake"}, {"ref_id": "b8", "title": "Complete dense stereovision using level set methods", "journal": "", "year": "1998", "authors": "O D Faugeras; R Keriven"}, {"ref_id": "b9", "title": "Flows in Networks", "journal": "Princeton University Press", "year": "1962", "authors": "L Ford; D Fulkerson"}, {"ref_id": "b10", "title": "Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images", "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": "1984", "authors": "S Geman; D Geman"}, {"ref_id": "b11", "title": "Occlusions, discontinuities, and epipolar lines in stereo", "journal": "", "year": "1998", "authors": "H Ishikawa; D Geiger"}, {"ref_id": "b12", "title": "Handling occlusions in dense multi-view stereo", "journal": "", "year": "2001", "authors": "S B Kang; R Szeliski; J Chai"}, {"ref_id": "b13", "title": "Visual correspondence with occlusions using graph cuts", "journal": "", "year": "2001", "authors": "Vladimir Kolmogorov; Ramin Zabih"}, {"ref_id": "b14", "title": "What energy functions can be minimized via graph cuts", "journal": "", "year": "2002", "authors": "Vladimir Kolmogorov; Ramin Zabih"}, {"ref_id": "b15", "title": "A theory of shape by space carving", "journal": "International Journal of Computer Vision", "year": "2000-07", "authors": "K N Kutulakos; S M Seitz"}, {"ref_id": "b16", "title": "The visual hull concept for silhouette-based image understanding", "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": "1994-02", "authors": "A Laurentini"}, {"ref_id": "b17", "title": "Volumetric descriptions of objects from multiple views", "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": "1983-03", "authors": "W N Martin; J K Aggarwal"}, {"ref_id": "b18", "title": "Computational vision and regularization theory", "journal": "Nature", "year": "1985", "authors": "Tomaso Poggio; Vincent Torre; Christof Koch"}, {"ref_id": "b19", "title": "Stereo without epipolar lines: A maximum flow formulation", "journal": "International Journal of Computer Vision", "year": "1999", "authors": "S Roy"}, {"ref_id": "b20", "title": "A maximum-flow formulation of the n-camera stereo correspondence problem", "journal": "", "year": "1998", "authors": "S Roy; I Cox"}, {"ref_id": "b21", "title": "A taxonomy and evaluation of dense twoframe stereo correspondence algorithms", "journal": "", "year": "2001", "authors": "Daniel Scharstein; Richard Szeliski"}, {"ref_id": "b22", "title": "Photorealistic scene reconstruction by voxel coloring", "journal": "International Journal of Computer Vision", "year": "1999-11", "authors": "S M Seitz; C R Dyer"}, {"ref_id": "b23", "title": "Exact voxel occupancy with graph cuts", "journal": "", "year": "2000", "authors": "Dan Snow; Paul Viola; Ramin Zabih"}, {"ref_id": "b24", "title": "Rapid octree construction from image sequences. Computer Vision, Graphics and Image Processing", "journal": "", "year": "1993-07", "authors": "R Szeliski"}, {"ref_id": "b25", "title": "Stereo matching with transparency and matting", "journal": "", "year": "1998", "authors": "R Szeliski; P Golland"}, {"ref_id": "b26", "title": "An experimental comparison of stereo algorithms", "journal": "Springer-Verlag", "year": "1999-09", "authors": "Richard Szeliski; Ramin Zabih"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Fig. 1 .1Fig. 1. Example of pixel interactions. There is a photo-consistency constraint between the red round point and the blue round point, both of which are at the same depth (l = 2). The red round point blocks camera C2's view of the green square point at depth l = 3. Color figures are available in the electronic version of this paper.", "figure_data": ""}, {"figure_label": "234", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Fig. 2 .Fig. 3 .Fig. 4 .234Fig. 2. Results on Tsukuba dataset.", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "-Only 3D-points at the same depth can interact, i.e.if { p 1 , l 1 , p 2 , l 2 } \u2208 I then l 1 = l 2 .", "formula_coordinates": [4.0, 141.0, 544.23, 338.82, 22.65]}, {"formula_id": "formula_1", "formula_text": "E(f ) = E data (f ) + E smoothness (f ) + E visibility (f ) ( 1 )", "formula_coordinates": [4.0, 200.16, 610.08, 280.48, 9.97]}, {"formula_id": "formula_2", "formula_text": "E data (f ) = p,f (p) , q,f (q) \u2208I D(p, q)", "formula_coordinates": [4.0, 232.68, 646.08, 150.04, 20.89]}, {"formula_id": "formula_3", "formula_text": "D(p, q) = min{0, (Intensity(p) \u2212 Intensity(q)) 2 \u2212 K}", "formula_coordinates": [5.0, 189.24, 149.27, 236.94, 11.92]}, {"formula_id": "formula_4", "formula_text": "N \u2282 {{p, q} | p, q \u2208 P}", "formula_coordinates": [5.0, 255.12, 276.51, 105.19, 9.96]}, {"formula_id": "formula_5", "formula_text": "E smoothess (f ) = {p,q}\u2208N V {p,q} (f (p), f(q))", "formula_coordinates": [5.0, 217.68, 342.84, 179.92, 20.89]}, {"formula_id": "formula_6", "formula_text": "L 1 distance V (l 1 , l 2 ) = min(|l 1 \u2212 l 2 |, K) for constant K.", "formula_coordinates": [5.0, 134.76, 397.95, 345.91, 21.96]}, {"formula_id": "formula_7", "formula_text": "E visibility (f ) = p,f (p) , q,f (q) \u2208Ivis \u221e", "formula_coordinates": [5.0, 229.68, 481.59, 156.0, 21.7]}, {"formula_id": "formula_8", "formula_text": "-Only 3D-points at different depths can interact, i.e. if { p 1 , l 1 , p 2 , l 2 } \u2208 I vis then l 1 = l 2 .", "formula_coordinates": [5.0, 141.0, 528.87, 338.92, 22.53]}, {"formula_id": "formula_9", "formula_text": "E(x 1 , . . . , x n ) = i<j E i,j (x i , x j ) ( 2 )", "formula_coordinates": [7.0, 239.28, 594.35, 241.36, 22.45]}, {"formula_id": "formula_10", "formula_text": "E i,j (0, 0) + E i,j (1, 1) \u2264 E i,j (0, 1) + E i,j (1, 0) (3)", "formula_coordinates": [7.0, 210.0, 653.99, 270.64, 11.44]}, {"formula_id": "formula_11", "formula_text": "E(x) =\u1ebc data (x) +\u1ebc smoothness (x) +\u1ebc visibility (x) where\u1ebc data (x) = E data (f x ), E smoothness (x) = E smoothness (f x ), E visibility (x) = E visibility (f x ).", "formula_coordinates": [8.0, 134.76, 367.79, 366.05, 77.65]}, {"formula_id": "formula_12", "formula_text": "E data (x) = p,f x (p) , q,f x (q) \u2208I D(p, q) = p,l , q,l \u2208I T (f x (p) = f x (q) = l) \u2022 D(p, q)", "formula_coordinates": [8.0, 134.76, 483.71, 345.88, 23.05]}, {"formula_id": "formula_13", "formula_text": "E p,q (x p , x q ) = T (f x (p) = f x (q) = l) \u2022 D(p, q). Two cases are possible: 1A. l = \u03b1. If at least one of the labels f (p), f (q) is not l then E p,q \u2261 0. Suppose that f (p) = f (q) = l. Then E(x p , x q ) is equal to D(p, q), if x p = x q =", "formula_coordinates": [8.0, 134.76, 528.83, 345.85, 47.53]}, {"formula_id": "formula_14", "formula_text": "E p,q (0, 0) + E p,q (1, 1) = D(p, q) \u2264 0 = E p,q (0, 1) + E p,q (1, 0) 1B. l = \u03b1.", "formula_coordinates": [8.0, 149.76, 597.11, 289.71, 32.44]}, {"formula_id": "formula_15", "formula_text": "E p,q (x p , 0) = E p,q (x p , 1) and E p,q (0, 0) + E p,q (1, 1) = E p,q (0, 1) + E p,q (1, 0).)", "formula_coordinates": [8.0, 134.76, 642.59, 345.87, 22.84]}, {"formula_id": "formula_16", "formula_text": "E p,q (0, 0) + E p,q (1, 1) = D(p, q) \u2264 0 = E p,q (0, 1) + E p,q (1, 0) 2. Smoothness term. E smoothness (x) = {p,q}\u2208N V {p,q} (f x (p), f x (q)). Let's consider a single term E p,q (x p , x q ) = V {p,q} (f x (p), f x (q)). We assumed that V {p,q} is a metric; thus, V {p,q} (\u03b1, \u03b1) = 0 and V {p,q} (f (p), f(q)) \u2264 V {p,q} (f (p), \u03b1)+ V {p,q} (\u03b1, f (q)), or E p,q (1, 1) = 0 and E p,q (0, 0) \u2264 E p,q (0, 1) + E p,q (1, 0). There- fore, condition (3) holds. 3. Visibility term.\u1ebc visibility (x) = p,f x (p) , q,f x (q) \u2208Ivis \u221e = p,lp , q,lq \u2208Ivis T (f x (p) = l p \u2227 f x (q) = l q ) \u2022 \u221e. Let's consider a single term E p,q (x p , x q ) = T (f x (p) = l p \u2227 f x (q) = l q ) \u2022 \u221e.", "formula_coordinates": [9.0, 134.76, 163.07, 345.93, 230.05]}, {"formula_id": "formula_17", "formula_text": "U {p,q} = 3\u03bb if \u2206I(p, q) < 5 \u03bb otherwise (5", "formula_coordinates": [10.0, 241.56, 242.52, 234.82, 21.28]}, {"formula_id": "formula_18", "formula_text": ")", "formula_coordinates": [10.0, 476.38, 247.32, 4.25, 8.85]}], "doi": ""}