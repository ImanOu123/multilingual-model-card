{"title": "What Camera Motion Reveals About Shape With Unknown BRDF", "authors": "Manmohan Chandraker", "pub_date": "", "abstract": "Psychophysical studies show motion cues inform about shape even with unknown reflectance. Recent works in computer vision have considered shape recovery for an object of unknown BRDF using light source or object motions. This paper addresses the remaining problem of determining shape from the (small or differential) motion of the camera, for unknown isotropic BRDFs. Our theory derives a differential stereo relation that relates camera motion to depth of a surface with unknown isotropic BRDF, which generalizes traditional Lambertian assumptions. Under orthographic projection, we show shape may not be constrained in general, but two motions suffice to yield an invariant for several restricted (still unknown) BRDFs exhibited by common materials. For the perspective case, we show that three differential motions suffice to yield surface depth for unknown isotropic BRDF and unknown directional lighting, while additional constraints are obtained with restrictions on BRDF or lighting. The limits imposed by our theory are intrinsic to the shape recovery problem and independent of choice of reconstruction method. We outline with experiments how potential reconstruction methods may exploit our theory. We illustrate trends shared by theories on shape from motion of light, object or camera, relating reconstruction hardness to imaging complexity.", "sections": [{"heading": "Introduction", "text": "Image formation is an outcome of the interaction between shape, lighting and camera, governed by material reflectance. Motion of the object, light source or camera are important cues for recovering object shape from images. Each of those cues have been extensively studied in computer vision, under the umbrellas of optical flow for object motion [7,9], photometric stereo for light source motion [19] and multiview stereo for motion of the camera [15]. Due to the complex and often unknown nature of the bidirectional reflectance distribution function (BRDF) that determines material behavior, simplifying assumptions like brightness constancy and Lambertian reflectance are often employed.\nHowever, psychophysical studies have established that complex reflectance does not impede shape perception [16]. Correspondingly, recent works in computer vision show that differential motion of the light source [2] or the object [4] inform about shape even with unknown BRDFs. This paper solves the remaining problem of characterizing shape recovery for unknown BRDFs, using differential motion of the camera.\nWe begin in Sec. 3 by proposing a differential stereo relation that relates depth to camera motion, while accounting for general material behavior in the form of an isotropic BRDF. Diffuse photoconsistency of traditional Lambertian stereo follows as a special case. Surprisingly, it can be shown that considering a sequence of motions allows eliminating the BRDF dependence of differential stereo.\nThe mathematical basis for differential stereo is outwardly similar to differential flow for object motion [4]. However, while BRDFs are considered black-box functions in [4], our analysis explicitly considers the angular dependencies of isotropic BRDFs to derive additional insights. A particular benefit is to show that ambiguities exist for the case of camera motion, which render shape recovery more difficult.\nConsequently, for orthographic projection, Sec. 4 shows a negative result whereby constraints on the shape of a surface with general isotropic BRDF may not be derived using camera motion as a cue. But we show the existence of an orthographic invariant for several restricted isotropic BRDFs, exhibited by common materials like plastics, metals, some paints and fabrics. The invariant is characterized as a quasilinear partial differential equation (PDE), which specifies the topological class up to which reconstruction may be performed.\nUnder perspective projection, Sec. 5 shows that depth for a surface with unknown isotropic BRDF, under unknown directional lighting, may be obtained using differential stereo relations from three or more camera motions. Further, we show that an additional linear constraint on the surface gradient is available for the above restricted families of BRDFs. These results substantially generalize Lambertian stereo, since depth information is obtained without assuming diffuse photoconsistency, while a weak assumption on material type yields even richer surface information. Table 1 summarizes the main theoretical results of this paper.\nFinally, Sec. 6 explores relationships between differential theories pertaining to motion of the object, light source or camera. We discuss their shared traits that allow shape recovery and common trends relating hardness of surface reconstruction to complexity of imaging setup. Those perspectives on shape from motion are summarized in Table 2.", "publication_ref": ["b6", "b8", "b18", "b14", "b15", "b1", "b3", "b3", "b3", "b4"], "figure_ref": [], "table_ref": []}, {"heading": "Related Work", "text": "Relating shape to intensity variations due to differential motion has a significant history in computer vision, dating to studies in optical flow [7,9]. The limitations of the Lambertian assumption have been recognized by early works [11,18]. Table 1. Summary of main results of this paper. Note that k camera motions result in k + 1 images. BRDF is described by angular dependences and functional form. In general, more constrained BRDF or lighting yields richer shape information. Also, see discussion in Sec. 6.\nSeveral stereo methods have been developed for non-Lambertian materials. Zickler et al. exploit Helmholtz reciprocity for reconstruction with arbitrary BRDFs [20]. Reference shapes of known geometry and various material types are used in example-based methods [17]. Savarese et al. study stereo reconstructions for specular surfaces [14]. In contrast, this paper explores how an image sequence derived from camera motion informs about shape with unknown isotropic BRDFs, regardless of reconstruction method.\nLight source and object motions have also been used to understand shape with unknown BRDFs. Photometric stereo based on small light source motions is presented by [5], while generalized notions of optical flow are considered in [6,12]. An isometric relationship between changes in normals and radiance profiles under varying light source is used by Sato et al. to recover shape with unknown reflectance [13].\nClosely related to this paper are the works of Chandraker et al. that derive topological classes up to which reconstruction can be performed for unknown BRDFs, using differential motion of the source [2] or object [4]. This paper derives limits on shape recovery using the third cue, namely camera motion. The similarities and differences between the frameworks are explored throughout this paper and summarized in Sec. 6.", "publication_ref": ["b6", "b8", "b10", "b17", "b19", "b16", "b13", "b4", "b5", "b11", "b12", "b1", "b3"], "figure_ref": [], "table_ref": []}, {"heading": "Differential Stereo for General BRDFs", "text": "In this section, we state our assumptions and derive the relationship between camera motion and surface depth, for unknown isotropic BRDFs. We also provide some intuition into that relationship, which will be used for subsequent shape recovery results. To facilitate presentation, we will occasionally point the reader to an extended version [1] for details.", "publication_ref": ["b0"], "figure_ref": [], "table_ref": []}, {"heading": "Derivation of the Differential Stereo Relation", "text": "Assumptions and setup We assume static object and lighting, while the camera moves. For rigid body motion, our analysis equivalently considers a fixed camera, with the object and light source undergoing the inverse motion. The illumination is assumed directional and distant. The object BRDF is assumed to be homogeneous and isotropic, with unknown functional form. We make a technical assumption that the camera direction is constant over the entire object. 1 Global illumination effects are assumed negligible.\nLet the focal length of the camera be f . The camera model is perspective for finite values of f and approaches orthographic as f \u2192 \u221e. The principal point on the image plane is defined as the origin of the 3D coordinate system, with the camera center at (0, 0, \u2212f ) . Denoting \u03b2 = f \u22121 , a 3D point x = (x, y, z) is imaged at u = (u, v) , where\n(1 + \u03b2z)u = x , (1 + \u03b2z)v = y.(1)\nMotion field Let the camera undergo a rigid body rotation R and translation \u03c4 . We equivalently assume that the object and light source undergo a rotation R = R \u22121 and translation \u03c4 = R \u22121 \u03c4 , with a fixed camera. For differential motion, we approximate R \u2248 I + [\u03c9] \u00d7 , where \u03c9 = (\u03c9 1 , \u03c9 2 , \u03c9 3 ) . The motion field, \u00b5 = (u,v) , is the differential motion of the image obtained by differentiating (1). We refer the reader to prior works like [11,4] for a derivation and simply express the motion field here in a form similar to [4]:\nPerspective: \u00b5 = \u03b1 1 + \u03b1 2 + \u03c9 2 z 1 + \u03b2z , \u03b1 3 + \u03b1 4 \u2212 \u03c9 1 z 1 + \u03b2z ,(2)\nOrthographic: \u00b5 = (\u03b1 5 + \u03c9 2 z, \u03b1 6 \u2212 \u03c9 1 z) ,(3)\nwhere \u03b1 i , i = 1, \u2022 \u2022 \u2022 , 6, are known functions of \u03c9, \u03c4 , u and \u03b2, whose algebraic forms are shown in [1].\nDifferential stereo relation Let s be the light source direction and v = (0, 0, \u22121) be the camera direction. For a 3D point x = (x, y, z(x, y)) on the surface, the unit normal is\nn = (n 1 , n 2 , n 3 ) = (z 2 x + z 2 y + 1) \u2212 1 2 (z x , z y , \u22121) ,(4)\nwhere \u2207z = (z x , z y ) is the surface gradient. For a homogeneous isotropic BRDF \u03c1, with distant light source, the image intensity at pixel u of a 3D point x is assumed to be\nI(u, t) = \u03c3(x)\u03c1(x, n, s, v),(5)\nwhere \u03c3 is the albedo and the cosine fall-off is absorbed in \u03c1. This is a reasonable imaging model that subsumes traditional ones like Lambertian and allows general isotropic BRDFs modulated by spatially varying albedo. We do not make any assumptions on the functional form of \u03c1, except smoothness. Taking the total derivative on both sides of (5), we get\nI uu + I vv + I t = \u03c3 d dt \u03c1(x, n, s, v) + \u03c1 d\u03c3 dt . (6\n)\nSince \u03c3 is intrinsically defined on the surface coordinates, its total derivative vanishes. For the rigid body motion we consider,\u1e45 = \u03c9 \u00d7 n and\u1e61 = \u03c9 \u00d7 s, while the camera direction remains unchanged. Using chain rule differentiation and noting that \u00b5 = (u,v) is the motion field, we have\n(\u2207 u I) \u00b5 + I t = \u03c3 [ (\u2207 x \u03c1) \u03bd + (\u2207 n \u03c1) (\u03c9 \u00d7 n) + (\u2207 s \u03c1) (\u03c9 \u00d7 s) ] ,(7)\nwhere \u03bd =\u1e8b is the linear velocity. While the above discussion gives intuition for the differential relation in ( 7), we refer the reader to [1] for a rigorous derivation.\nFor distant lighting and homogeneous reflectance in our setup, we may assume that \u2207 x \u03c1 is negligible. Further, dividing the two sides of ( 7) with those of (5), we get\n(\u2207 u E) \u00b5 + E t = (n \u00d7 \u2207 n log \u03c1 + s \u00d7 \u2207 s log \u03c1) \u03c9 (8)\nwhere we use the notation E = log I and the identities (\u2207 a \u03c1) (\u03c9 \u00d7 a) = (a \u00d7 \u2207 a \u03c1) \u03c9 and \u2207 a log \u03c1 = \u03c1 \u22121 \u2207 a \u03c1, for some a \u2208 R 3 . We call (8) the differential stereo relation.", "publication_ref": ["b0", "b0", "b10", "b3", "b3", "b0", "b0"], "figure_ref": [], "table_ref": []}, {"heading": "Understanding the Differential Stereo Relation", "text": "Generalization of Lambertian stereo Initial intuition into the differential stereo relation of ( 8) may be derived by noting how it generalizes traditional Lambertian stereo. For two images I 1 and I 2 related by a known motion, Lambertian stereo seeks the depth z that best satisfies brightness constancy:\nI 1 (u) = I 2 (u + \u00b5(z)). Substituting a Lambertian reflectance \u03c1(n, s, v) = n s in (8), we get (\u2207 u E) \u00b5 + E t = n \u00d7 (n s) \u22121 s + s \u00d7 (n s) \u22121 n \u03c9 = 0 \u03c9 = 0,(9)\nwhich is precisely brightness constancy (total derivative of image intensity is zero). Thus, diffuse photoconsistency imposed by traditional stereo is a special case of our theory.\nRelation to object motion For object motion, a differential flow relation is derived in [4]. The differential stereo relation of ( 8) has an additional dependence on BRDF derivatives with respect to the light source. This stands to reason, since both the object and lighting move relative to camera in the case of camera motion, while only the object moves in the case of object motion. Thus, intuitively, camera motion leads to a harder reconstruction problem. Indeed, as we will see next, the dependence of ( 8) on lighting leads to a somewhat surprising additional ambiguity.\nAmbiguity for camera motion Now we derive some additional insights by making a crucial departure from the analysis of [4]. Namely, instead of treating isotropic BRDFs as entirely black box functions, we explicitly consider their physical property in the form of angular dependencies between the normal, light source and camera directions. We define\n\u03c0 = n \u00d7 \u2207 n log \u03c1 + s \u00d7 \u2207 s log \u03c1,(10)\nwhich allows rewriting the differential stereo relation ( 8) as:\n(\u2207 u E) \u00b5 + E t = \u03c9 \u03c0.(11)\nThe entity \u03c0 is central to our theory, since it captures the dependence of differential stereo on BRDF. Its practical significance is that any shape recovery method that seeks invariance to material behavior must either accurately model \u03c0, or eliminate it. Our work adopts the latter approach. This definition of \u03c0 leads to an observation intrinsic to shape recovery with isotropic BRDFs: Proposition 1. The BRDF dependence of differential stereo is captured by a 2D vector in the principal plane of the camera.\nProof. Since an isotropic BRDF depends on the three angles between normal, camera and light directions, we may writ\u1ebd\n\u03c1(n s, s v, n v) = log \u03c1(n, s, v).(12)\nDenote \u03b8 = n s, \u03c6 = s v and \u03c8 = n v. Then, applying chain-rule differentiation, we may write ( 10) as\n\u03c0 = n \u00d7 \u2207 n\u03c1 + s \u00d7 \u2207 s\u03c1 =\u03c1 \u03b8 (n \u00d7 s) +\u03c1 \u03c8 (n \u00d7 v) +\u03c1 \u03b8 (s \u00d7 n) +\u03c1 \u03c6 (s \u00d7 v) =\u03c1 \u03c8 (n \u00d7 v) +\u03c1 \u03c6 (s \u00d7 v).(13)\nFrom the form of \u03c0 in ( 13), it is evident that \u03c0 v = 0. For our choice of coordinate system, v = (0, 0, \u22121) . Thus,\n\u03c0 3 = 0.(14)\nIt follows that the BRDF-dependent entity \u03c0 = (\u03c0 1 , \u03c0 2 , 0) lies on the principal plane of the camera.\nThis is an important result that limits the extent to which shape may be recovered from differential stereo. The following sections explore the precise nature of those limits.", "publication_ref": ["b3", "b3"], "figure_ref": [], "table_ref": []}, {"heading": "Orthographic Projection", "text": "Estimating the motion field, \u00b5, is equivalent to determining dense correspondence and thereby, object shape. In this section, we consider shape recovery with unknown BRDF under orthographic projection, using a sequence of differential motions. Our focus will continue to be on providing intuitions, while refering the reader to [1] for details.", "publication_ref": ["b0"], "figure_ref": [], "table_ref": []}, {"heading": "Rank Deficiency and Depth Ambiguities", "text": "It is clear that just one differential motion of the camera is insufficient to extract depth, since (11) is a linear relation in the multiple unknowns {z, \u03c0}. Consequently, we consider a sequence of differential motions. We start by observing that, in the case of orthography, a rank deficiency similar to the case of object motion exists for camera motion too.\nUnder orthography, the motion field \u00b5 is given by (3). Noting the \u00b5 1 and \u00b5 2 are linear in z, we observe that the differential stereo relation of ( 11) reduces to:\npz + q = \u03c9 \u03c0 (15\n)\nwhere, using (3), p and q are known entities given by\np = \u03c9 2 E u \u2212 \u03c9 1 E v (16) q = \u03b1 5 E u + \u03b1 6 E v + E t .(17)\nConsider m > 0 differential motions of the camera about a base position, given by {\u03c9 i , \u03c4 i }, for i = 1, \u2022 \u2022 \u2022 , m. Let E 0 = log I 0 be the logarithm of the base image, with E i being the log-image for each motion {\u03c9 i , \u03c4 i }. Note that the spatial gradient of the image is independent of motion and corresponds to the derivative of E 0 with respect to u. We will simply denote it as \u2207 u E = (E u , E v ) . The temporal derivative, E t , as well as p and q, depend on the motion.\nTo recover the unknown depth z, an initial approach may consider m \u2265 3 relations of the form (11) as a linear system:\nA \uf8ee \uf8f0 z \u03c0 1 \u03c0 2 \uf8f9 \uf8fb = q, with\u00c3 = \uf8ee \uf8ef \uf8f0 \u2212p 1 \u03c9 1 1 \u03c9 1 2 . . . . . . \u2212p m \u03c9 m 1 \u03c9 m 2 \uf8f9 \uf8fa \uf8fb , (18\n)\nwhere q = (q 1 , \u2022 \u2022 \u2022 , q m ) . Note that Proposition 1 allows us to drop any dependence on \u03c9 3 , since \u03c0 3 = 0 is not an unknown. But observe the form of 16), which makes\u00c3 rank-deficient. Thus, we have shown: Proposition 2. Under orthographic projection, surface depth under unknown BRDF may not be unambiguously recovered using solely camera motion as the cue.\np i = \u03c9 i 2 E u \u2212 \u03c9 i 1 E v from (\nWhile depth cannot be directly recovered from differential stereo under orthography, a natural next step is to consider the possibility of any constraints on the depth. However, the result of Proposition 1 makes this challenging for the case of camera motion. To see this, we note that the null vector of the rank-deficient matrix\u00c3 is (1, \u2212E v , E u ) . With\u00c3 + denoting the Moore-Penrose pseudoinverse of\u00c3, for any k = 0, we have a parameterized solution to (18):\n\uf8ee \uf8f0 z \u03c0 1 \u03c0 2 \uf8f9 \uf8fb = \u03b3 + k \uf8ee \uf8f0 1 \u2212E v E u \uf8f9 \uf8fb ,(19)\nwhere \u03b3 = (\u03b3 1 , \u03b3 2 , \u03b3 3 ) =\u00c3 + q. From the first equation in the above system, we have k = z \u2212 \u03b3 1 . Thereby, we get the following two relations between z and \u03c0:\n\u03c0 1 = (\u03b3 2 + E v \u03b3 1 ) \u2212 E v z (20) \u03c0 2 = (\u03b3 3 \u2212 E u \u03b3 1 ) + E u z (21)\nNow, any relationship between \u03c0 1 and \u03c0 2 gives a constraint on the depth, z. But from Prop. 1, \u03c0 is an arbitrary vector in the principal plane. That is, from (13), \u03c0 1 and \u03c0 2 depend on two unknown BRDF derivatives\u03c1 \u03c8 and\u03c1 \u03c6 . It follows that without imposing any external constraint on\u03c1 \u03c8 and\u03c1 \u03c6 , one may not derive a constraint on surface depth. Thus, we state: Proposition 3. Under orthographic projection, for unknown isotropic BRDF, an unambiguous constraint on surface depth may not be derived using solely camera motion as the cue.\nThe above is an example of the comparative limits on shape recovery with object or camera motion. For object motion, only the relative motion between camera and object must be accounted. Thus, the definition of \u03c0 = n \u00d7 \u2207 n log \u03c1 in [4] depends only on the BRDF-derivative with respect to surface normal. For camera motion, both object and lighting move relative to the camera. Additional dependence of \u03c0 in (10) on BRDF-derivative with respect to lighting makes it indeterminate without further restrictions on BRDF or lighting.\nWhile Prop. 3 is a negative result, its development provides valuable insight. An m \u00d7 3 rank-deficient matrix\u00c3 constructed using m differential motions, for any m \u2265 2, determines \u03b3 =\u00c3 + q. From ( 14), ( 20) and (21), it follows: Corollary 1. Under orthography, two differential motions of the camera suffice to constrain \u03c0 to a linear relation in z.\nThis fact will now be used, along with some restrictions on the BRDF, to derive BRDF-invariant constraints on depth.", "publication_ref": ["b17", "b3"], "figure_ref": [], "table_ref": []}, {"heading": "BRDF-Invariance for Certain Material Types", "text": "The result of Prop. 3 immediately suggests a possibility to constrain z: consider a BRDF whose dependence on \u03c8 and \u03c6 is restricted in a way that introduces a constraint on \u03c0. Note that the functional form of the BRDF, \u03c1(\u2022), remains unknown.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "BRDFs Dependent on View Angle", "text": "Some reflectances depend on the angles subtended by the normal on the source and view directions. Such BRDFs can explain the darkening near image edges for materials like fabrics. Another well-known example is the Minnaert BRDF for lunar reflectance [10]. In such cases, we may defin\u0113 \u03c1(n s, n v) = log \u03c1(n, s, v).\n(\n)22\nAgain denoting \u03b8 = n s and \u03c8 = n v, we get from (10):\n\u03c0 = n \u00d7 \u2207 n\u03c1 + s \u00d7 \u2207 s\u03c1 = n \u00d7 (\u03c1 \u03b8 s +\u03c1 \u03c8 v) + s \u00d7\u03c1 \u03b8 n =\u03c1 \u03c8 n \u00d7 v. (23\n)\nNoting that n \u00d7 v = (\u2212n 2 , n 1 , 0) , one may eliminate the BRDF-dependent term\u03c1 \u03c8 using ( 20) and ( 21) to obtain a relationship between depths and normals:\n\u03c0 1 \u03c0 2 = \u2212n 2 n 1 = (\u03b3 2 + E v \u03b3 1 ) \u2212 E v z (\u03b3 3 \u2212 E u \u03b3 1 ) + E u z .(24)\nUsing (4) to relate the normal to the gradient, this reduces to\n[(\u03b3 2 + E v \u03b3 1 ) \u2212 E v z]z x + [(\u03b3 3 \u2212 E u \u03b3 1 ) + E u z]z y = 0, (25)\nwhich is a constraint on surface depth and gradient that is independent of both the BRDF and lighting. We note that m \u2265 2 differential motions of the camera suffice to determine \u03b3 from (19) and yield the constraint in (25). Thus, we state:\nRemark 1. Under orthography, for a BRDF of unknown functional form that depends on light and view directions, two differential motions of the camera suffice to yield a constraint on surface depth independent of BRDF and lighting.", "publication_ref": ["b9", "b18"], "figure_ref": [], "table_ref": []}, {"heading": "BRDFs Dependent on Half-angle", "text": "For many common materials like metals or plastics, it is reasonable to assume that reflectance depends on the angle between the surface normal and the half-angle between the source and view directions. For a surface of such material type, we can show that a sequence of differential stereo relations yields a BRDF-invariant constraint on surface depth. For this case, we assume a known light source direction.\nProposition 4. Under orthographic projection, for a BRDF of unknown functional form that depends on known light and half-angle directions, two differential motions of the camera suffice to yield a BRDF-invariant constraint on surface depth.\nProof. For a BRDF that depends on half-angle h, we define\nlog \u03c1(n, s, v) =\u03c1(n s, n h), where h = s + v s + v . (26\n)\nThe definition of \u03c0 in ( 10) may now be rewritten as\n\u03c0 = n \u00d7 \u2207 n\u03c1 + s \u00d7 \u2207 s\u03c1 .(27)\nWe again denote \u03b8 = n s, \u03c6 = s v and define \u03b7 = n h. Then, using the definition of h in (26), we have after some algebraic simplification:\n\u03c0 =\u03c1 \u03b7 n \u00d7 v s + v \u2212 (n h)s \u00d7 v s + v 2 . (28\n)\nThe symmetry of \u03c0 with respect to n and s means it is independent of \u03c1 \u03b8 . Recall that \u03c0 3 = 0 from (14). After some algebra and using (4) to relate n to gradient, we get from (28):\n\u03c0 1 \u03c0 2 = a n b n = a 1 z x + a 2 z y \u2212 a 3 b 1 z x + b 2 z y \u2212 b 3 , (29\n)\nwhere\na 1 = s 2 h 1 , a 2 = s 2 h 2 \u2212 2(1 + \u03c6), a 3 = s 2 h 3 and b 1 = 2(1 + \u03c6) \u2212 s 1 h 1 , b 2 = \u2212s 1 h 2 , b 3 = \u2212s 1 h 3 . Thus,\nwe have obtained a relationship on \u03c0 independent of\u03c1 \u03b7 . Finally, for m \u2265 2 differential camera motions, we have from Corollary 1 that \u03c0 1 and \u03c0 2 are linear in z. Substituting their expressions from (20) and ( 21) into (29), we get\n(\u03bb 1 + \u03bb 2 z)z x + (\u03bb 3 + \u03bb 4 )z y + \u03bb 5 = 0,(30)\nwhere \u03bb i , for i = 1, \u2022 \u2022 \u2022 , 5, are known entities. Complete expressions for \u03bb i are provided in [1]. Here, it suffices to note that the \u03bb i are independent of\u03c1, thus, (30) is a BRDFinvariant constraint on surface depth.\nIntuitively, the ambiguity of Prop. 3 exists since one cannot constrain \u03c0 1 and \u03c0 2 if they depend on two independent unknowns \u03c1 \u03c6 and \u03c1 \u03c8 . Considering an appropriate BRDF, such as a half-angle one, allows expressing \u03c0 in terms of a single unknown \u03c1 \u03b7 . The linearity of differentiation eliminates \u03c1 \u03b7 to yield a BRDF-invariant constraint on \u03c0. Thus, Prop. 4 can derive an invariant purely in terms of depth and gradient.\nNote that Proposition 1 is a basic property of isotropic BRDFs under camera motion. So, it may be verified that it holds true even in the restricted case of half-angle BRDFs, that is, \u03c0 v = \u2212\u03c0 3 = 0 even for the \u03c0 defined by (28).", "publication_ref": ["b13", "b19", "b0"], "figure_ref": [], "table_ref": []}, {"heading": "Dependence on Arbitrary Angle in {s, v}-Plane", "text": "Recent works on empirical analysis of measured BRDFs show that reflectance functions often depend on the angles the surface normal makes with the light source and another direction in the plane defined by the source and camera directions [3]. In such cases, we may write log \u03c1(n, s, v) =\u03c1(n s, n y), with y = s + \u03bav s + \u03bav ,\nfor some \u03ba \u2208 R. Note that half-angle BRDFs for materials like plastics and metals considered in Section 4.2.2 are a special case with \u03ba = 1. The BRDFs considered in Section 4.2.1 may also be considered a limit case with \u03ba 1. Empirical examples for BRDFs with finite \u03ba = 1 are shown for materials like paints and fabrics in [3]. We may now state: Proposition 5. Under orthographic projection, for a BRDF of unknown functional form that depends on light source and an arbitrary direction in the source-view plane, two differential motions of the camera suffice to yield a BRDF-invariant constraint on surface depth.\nProof. The proof directly generalizes the development in Proposition 4. We refer the reader to [1] for complete details. We only note here that we obtain:\n\u03c0 = \u03ba\u03c1 n y 1 + \u03ba 2 + 2\u03ba\u03c6 (1 + \u03ba 2 + 2\u03ba\u03c6) 1 2 n \u2212 (n y)s \u00d7 v,(32)\nthus, dependence on \u03c1 may be eliminated similar to (29) using \u03c0 3 = 0 and considering the ratio of \u03c0 1 and \u03c0 2 . We then invoke Corollary 1 to constrain \u03c0 1 and \u03c0 2 to linear functions in z using m \u2265 2 differential motions, yielding an invariant:\n(\u03bb 1 + \u03bb 2 z)z x + (\u03bb 3 + \u03bb 4 )z y + \u03bb 5 = 0, (33\n)\nwhere \u03bb i , for i = 1, \u2022 \u2022 \u2022 , 5, are again known entities.\nWe urge the reader to observe that the constraint (33) is invariant to the functional form of the BRDF, but is not independent of \u03ba. However, note that \u03ba can be estimated from image data without requiring a full BRDF estimation, for instance, using the methods proposed in [3]. Also, we again note that Proposition 1 is an intrinsic property of isotropic BRDFs and \u03c0 3 = 0 continues to hold even for the \u03c0 in (32).", "publication_ref": ["b2", "b2", "b0", "b2"], "figure_ref": [], "table_ref": []}, {"heading": "Results on Surface Estimation", "text": "Recall that Sec. 4.1 establishes that, for general unknown isotropic BRDFs, one may neither estimate the surface depth, nor derive any BRDF-invariant constraints on it. However, Sec. 4.2 derives constraints on depth and gradient for restricted (but unknown) BRDFs. Here, we characterize the PDE defined by those constraints, which directly informs the extent to which shape may be recovered.\nFor a BRDF of the form ( 22), an invariant of the form (25) is obtained. We note that (25) is characterized as a homogeneous first-order quasilinear PDE [8]. For a surface level curve z(x, y) = z 0 , the solution to (25) from PDE theory is: \nz = z 0 , dy dx = (\u03b3 3 \u2212 E u \u03b3 1 ) + E u z 0 (\u03b3 2 + E v \u03b3 1 ) \u2212 E v z 0 . (34\n)\nThat is, given the depth at a point, the ODE (34) defines a step in the tangent direction, thereby tracing out the level curve through that point. We refer the reader to [1] for a formal proof, while only stating the result here: Proposition 6. Under orthography, two or more differential motions of the camera yield level curves of depth for a surface with BRDF dependent on light source and view angles.\nFor half-angle BRDFs given by (26), a BRDF-invariant constraint on surface depth is obtained as (30). We note that it is characterized as an inhomogeneous first-order quasilinear PDE, whose solution is also available from PDE theory [8].\nHere, with \u03bb i as defined in (30), we again state the result while referring the reader to [1] for a proof: Proposition 7. Under orthography, for a surface with halfangle BRDF, two or more differential camera motions yield characteristic surface curves C(x(s), y(s), z(s)) defined by\n1 \u03bb 1 + \u03bb 2 z dx ds = 1 \u03bb 3 + \u03bb 4 z dy ds = \u22121 \u03bb 5 dz ds(35)\ncorresponding to depths at some (possibly isolated) points.\nFinally, for a BRDF dependent on an arbitrary angle in the source-view plane given by (31), the invariant (33) is also an inhomogeneous quasilinear PDE. So, as a direct generalization of Prop. 7, differential stereo also yields characteristic curves for this case, with \u03bb i of (33) instead of \u03bb i .\nShape recovery Given depths at a few points on a surface with unknown BRDF, the above propositions yield depths along certain characteristic curves. For a smooth surface, one may interpolate the depths between the curves, in order to recover depth for the whole surface. The procedure is shown for synthetic data in Fig. 1 for a BRDF that depends on source and view angles (unknown lighting) and in Fig. 2 for unknown half-angle BRDFs (known lighting). Depth is assumed known at the green points to yield characteristic curves shown in red. We note that reconstruction methods in practice may use tracked feature points as seeds.  ", "publication_ref": ["b7", "b0", "b7", "b0"], "figure_ref": ["fig_2"], "table_ref": []}, {"heading": "Perspective Projection", "text": "In this section, we consider shape recovery from differential stereo under perspective projection. In particular, we show that unlike the orthographic case, depth may be unambiguously recovered in the perspective case, even when both the BRDF and lighting are unknown.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Depth from Differential Stereo", "text": "In the perspective case, the motion field \u00b5 is given by (2). Substituting for \u00b5 in the differential stereo relation (8), we obtain its expression for the perspective case:\np z 1 + \u03b2z + r 1 1 + \u03b2z + q = \u03c9 \u03c0,(36)\nwhere \u03c0 is defined as before by (10) and\np = E u \u03c9 2 \u2212 E v \u03c9 1 , q = \u03b1 1 E u + \u03b1 3 E v + E t and r = \u03b1 2 E u + \u03b1 4 E v are known entities.\nUnlike the orthographic case, the differential stereo relation is not linear in {z, \u03c0} for perspective projection.\nWe are now in a position to show depth recovery: Proposition 8. Under perspective projection, three differential motions of the camera suffice to yield depth of a surface with unknown isotropic BRDF and unknown light source.\nProof. For m \u2265 3, let images E 1 , \u2022 \u2022 \u2022 , E m be related to a base image E 0 by known differential motions {\u03c9 i , \u03c4 i }. Then, we obtain from (36) a sequence of differential stereo relations:\n(p i + \u03b2q i )z \u2212 ((1 + \u03b2z)\u03c0) \u03c9 i + (q i + r i ) = 0, (37\n) for i = 1, \u2022 \u2022 \u2022 , m. LetC = c 1 , \u2022 \u2022 \u2022 , c m be the m \u00d7 3 matrix with rows c i = [\u2212(p i + \u03b2q i ), \u03c9 i 1 , \u03c9 i 2 ] . Further, let q = [q 1 , \u2022 \u2022 \u2022 , q m ] and r = [r 1 , \u2022 \u2022 \u2022 , r m ] .\nThen, the system of differential stereo relations (37) may be written as\nC \uf8ee \uf8f0 z (1 + \u03b2z)\u03c0 1 (1 + \u03b2z)\u03c0 2 \uf8f9 \uf8fb = q + r ,(38)\nsince \u03c0 3 = 0, from Prop. 1. WithC + as the Moore-Penrose pseudoinverse ofC, let = ( 1 , 2 , 3 ) =C + (q + r ).\nThen, (38) has the solution:\n[z, (1 + \u03b2z)\u03c0 1 , (1 + \u03b2z)\u03c0 2 ] = . (39\n)\nIt follows that z = 1 yields the surface depth.\nThus, Prop. 8 yields surface depth from differential stereo when both the BRDF and lighting are unknown. Again, a comparison is merited to the case of object motion in [4]. With object motion, depth and an additional constraint on the gradient are recovered with unknown BRDF and lighting. While camera motion also recovers depth, following Prop. 1, it is likely that further information on the gradient is recoverable only with additional constraints on the BRDF or lighting.", "publication_ref": ["b1", "b7", "b9", "b3"], "figure_ref": [], "table_ref": []}, {"heading": "Additional Constraints for Certain Materials", "text": "As indicated above, now we show that additional constraints on the gradient are available for several material types. Proposition 9. Under perspective projection, three or more differential motions of the camera suffice to yield both depth and a linear constraint on the gradient for a surface with BRDF dependent on known light and half-angle directions.\nProof. Prop. 8 already shows depth recovery from m \u2265 3 differential motions of the camera. Further, from the form of \u03c0 for half-angle BRDFs in (28) and using (39), we have\n\u03c0 1 \u03c0 2 = a n b n = 2 3 ,(40)\nwhere a and b are known entities dependent on light, defined by (29). Finally, using (4) yields a linear PDE in depth:\nl 1 z x + l 2 z y + l 3 = 0, (41\n)\nwith l 1 = 2 b 1 \u2212 3 a 1 , l 2 = 2 b 2 \u2212 3 a 2 , l 3 = 3 a 3 \u2212 2 b 3 .\nThus, we obtain a linear constraint on the gradient.\nIt is evident from the above result that materials for which a relation between \u03c0 1 and \u03c0 2 may be derived independent of derivatives of the BRDF \u03c1, yield an additional constraint on the surface gradient. The form of this constraint will mirror the relationship between \u03c0 1 and \u03c0 2 , since their ratio is a measurable quantity from (40). In particular, it follows that a linear constraint may also be derived for the more general case considered in Section 4.2.3: Remark 2. Under perspective projection, three differential motions of the camera suffice to yield both depth and a linear constraint on the gradient for a BRDF dependent on known light and an arbitrary direction in the source-view plane.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Shape Recovery", "text": "From Prop. 8, depth is directly available in the perspective case for unknown lighting and unknown BRDF. Fig. 3 illustrates this for synthetic data, where the object is imaged under an unknown light source. The object has diameter 20cm and is placed 1.5m away from the camera of focal length 10cm. Three random motions, of approximately 2 \u2022 rotation and 5mm translation are imparted to the camera. The recovered shape using the theory of Sec. 5.1 is shown in Fig. 3. No prior knowledge of the BRDF, lighting or depth are required.  For evaluation with real data, images of the plastic sphere in Fig. 4(a) are obtained against a textured background under unknown directional lighting. Note the clear non-Lambertian effects. The camera focal length is 55mm and the object is approximately 80cm away. Five small motions (and several large ones for stable pose optimization) are imparted to the camera and estimated using bundle adjustment. The surface depth obtained from Prop. 8 is shown in Fig. 4(b) and (c).\nWhile we do not explore the direction in this paper, note that with known lighting, one may use the constraint (41) to solve a joint depth and gradient optimization weighted by \u03bb:\nmin z (z \u2212 1 ) 2 + \u03bb(l 1 z x + l 2 z y + l 3 ) 2 . (42\n)\nWith standard differencing, the above is a highly sparse linear system in z which may be solved efficiently.", "publication_ref": [], "figure_ref": ["fig_3", "fig_3", "fig_4", "fig_4"], "table_ref": []}, {"heading": "Perspectives on Shape from Motion Theories", "text": "We now provide a unified perspective on shape from motion theories corresponding to light, object or camera motions. Despite the apparent complexity of material behavior, differential motion of light, object or camera allows shape recovery with unknown BRDF and often unknown lighting. More importantly, theoretical limits on shape from motion are also derivable in these frameworks. Prior works have presented theories for light [2] and object [4] motions. This paper has studied camera motion to complete the differential analysis framework for shape recovery with unknown BRDFs.\nIn Table 2, we summarize a few results from each theory. In each case, the theories generalize well-known special cases that assume Lambertian BRDF or brightness constancy. Only orthographic projection for light motion (generalizing photometric stereo) and perspective projection for object or camera motion (generalizing optical flow and multiview stereo, respectively) are shown. A complete table is provided in [1].\nA few important traits are shared by these theories: Table 2. A unified look at BRDF-invariant frameworks on shape recovery from motions of light source, object or camera. In each case, PDE invariants specify precise topological limits on shape recovery. More general BRDFs or imaging setups require greater number of motions to derive the reconstruction invariant. More restricted BRDFs require fewer motions or yield richer shape information. For comparison, the traditional diffuse equivalents are also shown. Only the perspective cases are shown for object and camera motion (the full table is in [1]).\n\u2022 They all rely on the linearity of chain rule differentiation to eliminate the BRDF from a system of equations. \u2022 The invariant in each case can be characterized as a PDE amenable to solution through standard analysis tools. \u2022 The involved PDEs provide intrinsic limits on the topological class upto which shape may be recovered from each motion cue, regardless of reconstruction method. \u2022 More general imaging setups require greater number of motions for shape recovery. For instance, colocated lighting requires less motions than general lighting, or perspective projections require more motions than orthographic. \u2022 Constraining the BRDF either reduces the minimum requirement on number of motions (colocated or general BRDFs for object motion), or provides richer shape information (half-angle or general BRDFs for camera motion).\nThe cases of object and camera motion are more closely related, but with important differences due to additional ambiguities entailed by camera motion. Qualitatively, this leads to a harder problem for the case of camera motion. The practical manifestation of this hardness is requiring a more restricted BRDF (although still unknown) to obtain the same shape information. For instance, a half-angle BRDF yields depth and a gradient constraint with camera motion, while the same can be obtained with general BRDFs for object motion. Allowing a general BRDF means only depth may be obtained for camera motion, while object motion yields an additional gradient constraint. Throughout this paper, we have highlighted such distinctions and their impact on shape recovery.\nFuture work Our theory focuses on shape recovery, but some BRDF information may also be recovered as a byproduct. For instance, with perspective projection, Props. 8 and 1 completely define \u03c0. That is, from (39), \u03c0 = (1 + \u03b2 1 ) \u22121 ( 2 , 3 , 0) .\n(43) Fig. 3 shows an example recovery of \u03c0. In turn, this places constraints on the derivative of BRDF. An avenue for future work is to characterize the extents to which BRDF may be recovered using motions of the light source, object or camera. Further, while [2,4] and this paper together provide limits on shape recovery from motions corresponding to each imaging element, an interesting problem is to achieve similar limits when lighting, object and camera all undergo simultaneous motion. We also anticipate robust estimation methods that exploit our theory to extend traditional implementations of optical flow and multiview stereo to handle general BRDFs.", "publication_ref": ["b1", "b3", "b0", "b0", "b1", "b3"], "figure_ref": ["fig_3"], "table_ref": []}], "references": [{"ref_id": "b0", "title": "What camera motion reveals about shape with unknown BRDF", "journal": "", "year": "2014", "authors": "M Chandraker"}, {"ref_id": "b1", "title": "A theory of differential photometric stereo for unknown isotropic BRDFs", "journal": "", "year": "2011", "authors": "M Chandraker; J Bai; R Ramamoorthi"}, {"ref_id": "b2", "title": "What an image reveals about material reflectance", "journal": "", "year": "2011", "authors": "M Chandraker; R Ramamoorthi"}, {"ref_id": "b3", "title": "What object motion reveals about shape with unknown BRDF and lighting", "journal": "", "year": "2013", "authors": "M Chandraker; D Reddy; Y Wang; R Ramamoorthi"}, {"ref_id": "b4", "title": "Active photometric stereo", "journal": "", "year": "1992", "authors": "J Clark"}, {"ref_id": "b5", "title": "Computing optical flow with physical models of brightness variation", "journal": "PAMI", "year": "2001", "authors": "H W Haussecker; D J Fleet"}, {"ref_id": "b6", "title": "Determining optical flow", "journal": "Artificial Intelligence", "year": "1981", "authors": "B Horn; B Schunck"}, {"ref_id": "b7", "title": "", "journal": "Partial Differential Equations. App. Math. Sci", "year": "1981", "authors": "F John"}, {"ref_id": "b8", "title": "An iterative image registration technique with an application to stereo vision", "journal": "", "year": "1981", "authors": "B Lucas; T Kanade"}, {"ref_id": "b9", "title": "The reciprocity principle in lunar photometry", "journal": "Astrophysical Journal", "year": "1941", "authors": "M Minnaert"}, {"ref_id": "b10", "title": "On a constraint equation for the estimation of displacement rates in image sequences", "journal": "PAMI", "year": "1989", "authors": "H.-H Nagel"}, {"ref_id": "b11", "title": "Revised definition of optical flow: Integration of radiometric and geometric cues for dynamic scene analysis", "journal": "PAMI", "year": "1998", "authors": "S Negahdaripour"}, {"ref_id": "b12", "title": "Shape reconstruction based on similarity in radiance changes under varying illumination", "journal": "", "year": "2007", "authors": "I Sato; T Okabe; Q Yu; Y Sato"}, {"ref_id": "b13", "title": "Local shape from mirror reflections", "journal": "IJCV", "year": "2005", "authors": "S Savarese; M Chen; P Perona"}, {"ref_id": "b14", "title": "A comparison and evaluation of multiview stereo reconstruction algorithms", "journal": "", "year": "2006", "authors": "S Seitz; B Curless; J Diebel; D Scharstein; R Szeliski"}, {"ref_id": "b15", "title": "Effects of texture, illumination and surface reflectance on stereoscopic shape perception", "journal": "Perception", "year": "1997", "authors": "J T Todd; J F Norman; J J Koenderink; A M L Kappers"}, {"ref_id": "b16", "title": "Example-based stereo with general BRDFs", "journal": "", "year": "2004", "authors": "A Treuille; A Hertzmann; S Seitz"}, {"ref_id": "b17", "title": "Motion field and optical flow: Qualitative properties. PAMI", "journal": "", "year": "1989", "authors": "A Verri; T Poggio"}, {"ref_id": "b18", "title": "Photometric method for determining surface orientation from multiple images", "journal": "Opt. Engg", "year": "1980", "authors": "P Woodham"}, {"ref_id": "b19", "title": "Helmholtz stereopsis: Exploiting reciprocity for surface reconstruction", "journal": "IJCV", "year": "2002", "authors": "T Zickler; P Belhumeur; D Kriegman"}], "figures": [{"figure_label": "", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1. (a) One of three simulated orthographic images (two motions), with unknown lighting and arbitrary non-Lambertian BRDF dependent on source and view angles. (b) Level curves estimated using Prop. 6. (c) Surface reconstructed after interpolation.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "(a) Input [1 of 3] (b) Characteristics (c) Reconstruction", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 2 .2Figure 2. (a) One of three synthetic images (two motions), with unknown half-angle BRDF and known lighting, under orthographic projection. (b) Characteristic curves estimated using Prop. 7. (c) Surface reconstructed after interpolation.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 3 .3Figure 3. (a) One of four synthetic images (three motions), with arbitrary non-Lambertian BRDF and unknown lighting, under perspective projection. (b,c) \u03c01 and \u03c02 recovered using (43), as discussed in Sec. 6. (d) Depth estimated using Prop. 8.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 4 .4Figure 4. Reconstruction for a non-Lambertian ball with an unknown BRDF, under unknown light source, using Proposition 8.", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "(1 + \u03b2z)u = x , (1 + \u03b2z)v = y.(1)", "formula_coordinates": [2.0, 358.46, 262.43, 195.65, 8.96]}, {"formula_id": "formula_1", "formula_text": "Perspective: \u00b5 = \u03b1 1 + \u03b1 2 + \u03c9 2 z 1 + \u03b2z , \u03b1 3 + \u03b1 4 \u2212 \u03c9 1 z 1 + \u03b2z ,(2)", "formula_coordinates": [2.0, 314.43, 395.14, 239.68, 22.31]}, {"formula_id": "formula_2", "formula_text": "Orthographic: \u00b5 = (\u03b1 5 + \u03c9 2 z, \u03b1 6 \u2212 \u03c9 1 z) ,(3)", "formula_coordinates": [2.0, 314.43, 425.15, 239.68, 9.68]}, {"formula_id": "formula_3", "formula_text": "n = (n 1 , n 2 , n 3 ) = (z 2 x + z 2 y + 1) \u2212 1 2 (z x , z y , \u22121) ,(4)", "formula_coordinates": [2.0, 318.34, 517.74, 235.77, 13.99]}, {"formula_id": "formula_4", "formula_text": "I(u, t) = \u03c3(x)\u03c1(x, n, s, v),(5)", "formula_coordinates": [2.0, 377.48, 582.79, 176.63, 8.99]}, {"formula_id": "formula_5", "formula_text": "I uu + I vv + I t = \u03c3 d dt \u03c1(x, n, s, v) + \u03c1 d\u03c3 dt . (6", "formula_coordinates": [2.0, 346.05, 677.19, 204.19, 22.31]}, {"formula_id": "formula_6", "formula_text": ")", "formula_coordinates": [2.0, 550.24, 684.25, 3.87, 8.64]}, {"formula_id": "formula_7", "formula_text": "(\u2207 u I) \u00b5 + I t = \u03c3 [ (\u2207 x \u03c1) \u03bd + (\u2207 n \u03c1) (\u03c9 \u00d7 n) + (\u2207 s \u03c1) (\u03c9 \u00d7 s) ] ,(7)", "formula_coordinates": [3.0, 58.19, 117.19, 232.68, 26.21]}, {"formula_id": "formula_8", "formula_text": "(\u2207 u E) \u00b5 + E t = (n \u00d7 \u2207 n log \u03c1 + s \u00d7 \u2207 s log \u03c1) \u03c9 (8)", "formula_coordinates": [3.0, 52.43, 239.11, 238.43, 9.68]}, {"formula_id": "formula_9", "formula_text": "I 1 (u) = I 2 (u + \u00b5(z)). Substituting a Lambertian reflectance \u03c1(n, s, v) = n s in (8), we get (\u2207 u E) \u00b5 + E t = n \u00d7 (n s) \u22121 s + s \u00d7 (n s) \u22121 n \u03c9 = 0 \u03c9 = 0,(9)", "formula_coordinates": [3.0, 50.11, 380.19, 240.75, 60.04]}, {"formula_id": "formula_10", "formula_text": "\u03c0 = n \u00d7 \u2207 n log \u03c1 + s \u00d7 \u2207 s log \u03c1,(10)", "formula_coordinates": [3.0, 100.74, 699.33, 190.12, 9.68]}, {"formula_id": "formula_11", "formula_text": "(\u2207 u E) \u00b5 + E t = \u03c9 \u03c0.(11)", "formula_coordinates": [3.0, 381.85, 75.13, 172.26, 9.68]}, {"formula_id": "formula_12", "formula_text": "\u03c1(n s, s v, n v) = log \u03c1(n, s, v).(12)", "formula_coordinates": [3.0, 360.97, 244.43, 193.14, 8.99]}, {"formula_id": "formula_13", "formula_text": "\u03c0 = n \u00d7 \u2207 n\u03c1 + s \u00d7 \u2207 s\u03c1 =\u03c1 \u03b8 (n \u00d7 s) +\u03c1 \u03c8 (n \u00d7 v) +\u03c1 \u03b8 (s \u00d7 n) +\u03c1 \u03c6 (s \u00d7 v) =\u03c1 \u03c8 (n \u00d7 v) +\u03c1 \u03c6 (s \u00d7 v).(13)", "formula_coordinates": [3.0, 322.4, 291.45, 231.71, 39.57]}, {"formula_id": "formula_14", "formula_text": "\u03c0 3 = 0.(14)", "formula_coordinates": [3.0, 418.15, 373.07, 135.96, 9.65]}, {"formula_id": "formula_15", "formula_text": "pz + q = \u03c9 \u03c0 (15", "formula_coordinates": [3.0, 402.86, 698.51, 147.11, 8.99]}, {"formula_id": "formula_16", "formula_text": ")", "formula_coordinates": [3.0, 549.96, 698.86, 4.15, 8.64]}, {"formula_id": "formula_17", "formula_text": "p = \u03c9 2 E u \u2212 \u03c9 1 E v (16) q = \u03b1 5 E u + \u03b1 6 E v + E t .(17)", "formula_coordinates": [4.0, 119.18, 75.16, 171.68, 24.6]}, {"formula_id": "formula_18", "formula_text": "A \uf8ee \uf8f0 z \u03c0 1 \u03c0 2 \uf8f9 \uf8fb = q, with\u00c3 = \uf8ee \uf8ef \uf8f0 \u2212p 1 \u03c9 1 1 \u03c9 1 2 . . . . . . \u2212p m \u03c9 m 1 \u03c9 m 2 \uf8f9 \uf8fa \uf8fb , (18", "formula_coordinates": [4.0, 58.04, 236.19, 228.67, 42.7]}, {"formula_id": "formula_19", "formula_text": ")", "formula_coordinates": [4.0, 286.71, 253.43, 4.15, 8.64]}, {"formula_id": "formula_20", "formula_text": "p i = \u03c9 i 2 E u \u2212 \u03c9 i 1 E v from (", "formula_coordinates": [4.0, 49.78, 310.49, 241.08, 22.49]}, {"formula_id": "formula_21", "formula_text": "\uf8ee \uf8f0 z \u03c0 1 \u03c0 2 \uf8f9 \uf8fb = \u03b3 + k \uf8ee \uf8f0 1 \u2212E v E u \uf8f9 \uf8fb ,(19)", "formula_coordinates": [4.0, 111.3, 487.91, 179.56, 35.13]}, {"formula_id": "formula_22", "formula_text": "\u03c0 1 = (\u03b3 2 + E v \u03b3 1 ) \u2212 E v z (20) \u03c0 2 = (\u03b3 3 \u2212 E u \u03b3 1 ) + E u z (21)", "formula_coordinates": [4.0, 117.99, 576.74, 172.87, 24.6]}, {"formula_id": "formula_23", "formula_text": ")22", "formula_coordinates": [4.0, 541.66, 458.16, 12.45, 8.64]}, {"formula_id": "formula_24", "formula_text": "\u03c0 = n \u00d7 \u2207 n\u03c1 + s \u00d7 \u2207 s\u03c1 = n \u00d7 (\u03c1 \u03b8 s +\u03c1 \u03c8 v) + s \u00d7\u03c1 \u03b8 n =\u03c1 \u03c8 n \u00d7 v. (23", "formula_coordinates": [4.0, 327.34, 489.39, 222.62, 24.63]}, {"formula_id": "formula_25", "formula_text": ")", "formula_coordinates": [4.0, 549.96, 504.68, 4.15, 8.64]}, {"formula_id": "formula_26", "formula_text": "\u03c0 1 \u03c0 2 = \u2212n 2 n 1 = (\u03b3 2 + E v \u03b3 1 ) \u2212 E v z (\u03b3 3 \u2212 E u \u03b3 1 ) + E u z .(24)", "formula_coordinates": [4.0, 361.73, 562.48, 192.38, 23.22]}, {"formula_id": "formula_27", "formula_text": "[(\u03b3 2 + E v \u03b3 1 ) \u2212 E v z]z x + [(\u03b3 3 \u2212 E u \u03b3 1 ) + E u z]z y = 0, (25)", "formula_coordinates": [4.0, 315.02, 608.84, 239.09, 9.65]}, {"formula_id": "formula_28", "formula_text": "log \u03c1(n, s, v) =\u03c1(n s, n h), where h = s + v s + v . (26", "formula_coordinates": [5.0, 56.79, 249.78, 229.93, 22.34]}, {"formula_id": "formula_29", "formula_text": ")", "formula_coordinates": [5.0, 286.71, 256.87, 4.15, 8.64]}, {"formula_id": "formula_30", "formula_text": "\u03c0 = n \u00d7 \u2207 n\u03c1 + s \u00d7 \u2207 s\u03c1 .(27)", "formula_coordinates": [5.0, 116.93, 293.97, 173.93, 9.68]}, {"formula_id": "formula_31", "formula_text": "\u03c0 =\u03c1 \u03b7 n \u00d7 v s + v \u2212 (n h)s \u00d7 v s + v 2 . (28", "formula_coordinates": [5.0, 96.99, 349.82, 189.72, 22.34]}, {"formula_id": "formula_32", "formula_text": ")", "formula_coordinates": [5.0, 286.71, 356.91, 4.15, 8.64]}, {"formula_id": "formula_33", "formula_text": "\u03c0 1 \u03c0 2 = a n b n = a 1 z x + a 2 z y \u2212 a 3 b 1 z x + b 2 z y \u2212 b 3 , (29", "formula_coordinates": [5.0, 97.88, 420.45, 188.83, 23.26]}, {"formula_id": "formula_34", "formula_text": ")", "formula_coordinates": [5.0, 286.71, 427.53, 4.15, 8.64]}, {"formula_id": "formula_35", "formula_text": "a 1 = s 2 h 1 , a 2 = s 2 h 2 \u2212 2(1 + \u03c6), a 3 = s 2 h 3 and b 1 = 2(1 + \u03c6) \u2212 s 1 h 1 , b 2 = \u2212s 1 h 2 , b 3 = \u2212s 1 h 3 . Thus,", "formula_coordinates": [5.0, 50.11, 448.57, 241.99, 23.0]}, {"formula_id": "formula_36", "formula_text": "(\u03bb 1 + \u03bb 2 z)z x + (\u03bb 3 + \u03bb 4 )z y + \u03bb 5 = 0,(30)", "formula_coordinates": [5.0, 90.1, 525.89, 200.77, 9.65]}, {"formula_id": "formula_38", "formula_text": "\u03c0 = \u03ba\u03c1 n y 1 + \u03ba 2 + 2\u03ba\u03c6 (1 + \u03ba 2 + 2\u03ba\u03c6) 1 2 n \u2212 (n y)s \u00d7 v,(32)", "formula_coordinates": [5.0, 315.73, 365.84, 238.39, 32.78]}, {"formula_id": "formula_39", "formula_text": "(\u03bb 1 + \u03bb 2 z)z x + (\u03bb 3 + \u03bb 4 )z y + \u03bb 5 = 0, (33", "formula_coordinates": [5.0, 338.06, 451.74, 211.9, 9.65]}, {"formula_id": "formula_40", "formula_text": ")", "formula_coordinates": [5.0, 549.96, 452.06, 4.15, 8.64]}, {"formula_id": "formula_41", "formula_text": "z = z 0 , dy dx = (\u03b3 3 \u2212 E u \u03b3 1 ) + E u z 0 (\u03b3 2 + E v \u03b3 1 ) \u2212 E v z 0 . (34", "formula_coordinates": [6.0, 90.92, 203.84, 195.8, 23.22]}, {"formula_id": "formula_42", "formula_text": ")", "formula_coordinates": [6.0, 286.71, 210.9, 4.15, 8.64]}, {"formula_id": "formula_43", "formula_text": "1 \u03bb 1 + \u03bb 2 z dx ds = 1 \u03bb 3 + \u03bb 4 z dy ds = \u22121 \u03bb 5 dz ds(35)", "formula_coordinates": [6.0, 85.74, 465.19, 205.13, 23.22]}, {"formula_id": "formula_44", "formula_text": "p z 1 + \u03b2z + r 1 1 + \u03b2z + q = \u03c9 \u03c0,(36)", "formula_coordinates": [6.0, 333.17, 353.18, 220.94, 22.31]}, {"formula_id": "formula_45", "formula_text": "p = E u \u03c9 2 \u2212 E v \u03c9 1 , q = \u03b1 1 E u + \u03b1 3 E v + E t and r = \u03b1 2 E u + \u03b1 4 E v are known entities.", "formula_coordinates": [6.0, 313.36, 384.81, 241.99, 32.87]}, {"formula_id": "formula_46", "formula_text": "(p i + \u03b2q i )z \u2212 ((1 + \u03b2z)\u03c0) \u03c9 i + (q i + r i ) = 0, (37", "formula_coordinates": [6.0, 320.98, 536.46, 228.99, 12.44]}, {"formula_id": "formula_47", "formula_text": ") for i = 1, \u2022 \u2022 \u2022 , m. LetC = c 1 , \u2022 \u2022 \u2022 , c m be the m \u00d7 3 matrix with rows c i = [\u2212(p i + \u03b2q i ), \u03c9 i 1 , \u03c9 i 2 ] . Further, let q = [q 1 , \u2022 \u2022 \u2022 , q m ] and r = [r 1 , \u2022 \u2022 \u2022 , r m ] .", "formula_coordinates": [6.0, 313.36, 540.26, 241.0, 51.63]}, {"formula_id": "formula_48", "formula_text": "C \uf8ee \uf8f0 z (1 + \u03b2z)\u03c0 1 (1 + \u03b2z)\u03c0 2 \uf8f9 \uf8fb = q + r ,(38)", "formula_coordinates": [6.0, 369.5, 611.07, 184.61, 35.13]}, {"formula_id": "formula_49", "formula_text": "[z, (1 + \u03b2z)\u03c0 1 , (1 + \u03b2z)\u03c0 2 ] = . (39", "formula_coordinates": [6.0, 359.5, 698.62, 190.47, 9.65]}, {"formula_id": "formula_50", "formula_text": ")", "formula_coordinates": [6.0, 549.96, 698.94, 4.15, 8.64]}, {"formula_id": "formula_51", "formula_text": "\u03c0 1 \u03c0 2 = a n b n = 2 3 ,(40)", "formula_coordinates": [7.0, 134.37, 327.93, 156.49, 23.25]}, {"formula_id": "formula_52", "formula_text": "l 1 z x + l 2 z y + l 3 = 0, (41", "formula_coordinates": [7.0, 127.1, 387.43, 159.62, 9.65]}, {"formula_id": "formula_53", "formula_text": ")", "formula_coordinates": [7.0, 286.71, 387.75, 4.15, 8.64]}, {"formula_id": "formula_54", "formula_text": "with l 1 = 2 b 1 \u2212 3 a 1 , l 2 = 2 b 2 \u2212 3 a 2 , l 3 = 3 a 3 \u2212 2 b 3 .", "formula_coordinates": [7.0, 49.75, 407.11, 242.85, 9.65]}, {"formula_id": "formula_55", "formula_text": "min z (z \u2212 1 ) 2 + \u03bb(l 1 z x + l 2 z y + l 3 ) 2 . (42", "formula_coordinates": [7.0, 354.32, 436.22, 195.65, 16.21]}, {"formula_id": "formula_56", "formula_text": ")", "formula_coordinates": [7.0, 549.96, 438.61, 4.15, 8.64]}], "doi": ""}