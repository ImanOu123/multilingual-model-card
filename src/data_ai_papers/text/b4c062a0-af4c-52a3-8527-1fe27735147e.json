{"title": "Sublabel-Accurate Relaxation of Nonconvex Energies", "authors": "Thomas M\u00f6llenhoff; T U M\u00fcnchen; Emanuel Laude; Michael Moeller; Jan Lellmann; Daniel Cremers", "pub_date": "", "abstract": "We propose a novel spatially continuous framework for convex relaxations based on functional lifting. Our method can be interpreted as a sublabel-accurate solution to multilabel problems. We show that previously proposed functional lifting methods optimize an energy which is linear between two labels and hence require (often infinitely) many labels for a faithful approximation. In contrast, the proposed formulation is based on a piecewise convex approximation and therefore needs far fewer labels -see Fig. 1. In comparison to recent MRF-based approaches, our method is formulated in a spatially continuous setting and shows less grid bias. Moreover, in a local sense, our formulation is the tightest possible convex relaxation. It is easy to implement and allows an efficient primal-dual optimization on GPUs. We show the effectiveness of our approach on several computer vision problems.", "sections": [{"heading": "Introduction", "text": "Energy minimization methods have become the central paradigm for solving practical problems in computer vision. The energy functional can often be written as the sum of a data fidelity and a regularization term. One of the most popular regularizers is the total variation (T V ) due to its many favorable properties [4]. Hence, an important class of optimization problems is given as min u:\u2126\u2192\u0393 \u2126 \u03c1(x, u(x)) dx + \u03bb T V (u),\nFigure 1. We propose a convex relaxation for the variational model (1), which opposed to existing functional lifting methods [17,18] allows continuous label spaces even after discretization. Our method (here applied to stereo matching) avoids label space discretization artifacts, while saving on memory and runtime.\ndefined for functions u with finite total variation, arbitrary, possibly nonconvex dataterms \u03c1 : \u2126 \u00d7 \u0393 \u2192 R, label spaces \u0393 which are closed intervals in R, \u2126 \u2282 R d , and \u03bb \u2208 R + . The multilabel interpretation of the dataterm is that \u03c1(x, u(x)) represents the costs of assigning label u(x) to point x. For (weakly) differentiable functions T V (u) equals the integral over the norm of the derivative, and therefore favors a spatially coherent label configuration. The difficultly of minimizing the nonconvex energy (1) has motivated researchers to develop convex reformulations.\nConvex representations of (1) and more general related energies have been studied in the context of the calibration method for the Mumford-Shah functional [1]. Based on these works, relaxations for the piecewise constant [15] and piecewise smooth Mumford-Shah functional [16] have been proposed. Inspired by Ishikawa's graph-theoretic globally optimal solution to discrete variants of (1), continuous analogues have been considered by Pock et al. in [17,18]. Continuous relaxations for multilabeling problems with finite label spaces \u0393 have also been studied in [11].\nInterestingly, the discretization of the aforementioned continuous relaxations is very similar to the linear programming relaxations proposed for MAP inference in the Markov Random Field (MRF) community [10,22,24,26]. Both approaches ultimately discretize the range \u0393 into a finite set of labels. A closer analysis of these relaxations reveals, however, that they are not well-suited to represent the continuous valued range that we face in most computer vision problems such as stereo matching or optical flow. More specifically, the above relaxations are not designed to assign meaningful cost values to non-integral configurations. As a result, a large number of labels is required to achieve a faithful approximation. Solving real-world vision problems therefore entails large optimization problems with high memory and runtime requirement. To address this problem, Zach and Kohli [27], Zach [25] and Fix and Agarwal [7] introduced MRF-based approaches which retain continuous label spaces after discretization. For manifoldvalued labels, this issue was addressed by Lellmann et al. [12], however with the sole focus on the regularizer.", "publication_ref": ["b3", "b0", "b16", "b18", "b0", "b14", "b15", "b16", "b18", "b10", "b9", "b22", "b24", "b26", "b27", "b25", "b6", "b11"], "figure_ref": [], "table_ref": []}, {"heading": "Contributions", "text": "We propose the first sublabel-accurate convex relaxation of nonconvex problems in a spatially continuous setting. It exhibits several favorable properties:\n\u2022 In contrast to existing spatially continuous lifting approaches [17,18], the proposed method provides substantially better solutions with far fewer labels -see Fig. 1. This provides savings in runtime and memory.\n\u2022 In Sec. 3 we show that the functional lifting methods [17,18] are a special case of the proposed framework.\n\u2022 In Sec. 3 we show that, in a local sense, our formulation is the tightest convex relaxation which takes dataterm and regularizer into account separately. It is unknown whether this \"local convex envelope\" property also holds for the discrete approach [27].\n\u2022 Our formulation is compact and requires only half the amount of variables for the dataterm than the formulation in [27]. We prove that the sublabel-accurate total The main idea behind our approach is the finite dimensional representation of the graph at every x \u2208 \u2126 by means of u : \u2126 \u2192 R k (here k = 4).\nvariation can be represented in a very simple way, introducing no overhead compared to [17,18]. In contrast, the regularizer in [27] is much more involved.\n\u2022 Since our method is derived in a spatially continuous setting, the proposed approach easily allows different gradient discretizations. In contrast to [25,27] the regularizer is isotropic leading to noticeably less grid bias.", "publication_ref": ["b16", "b18", "b16", "b18", "b27", "b27", "b16", "b18", "b27", "b25", "b27"], "figure_ref": [], "table_ref": []}, {"heading": "Notation and Mathematical Preliminaries", "text": "We make heavy use of the convex conjugate, which is given as f * (y) = sup x\u2208R n y, x \u2212 f (x) for functions f : R n \u2192 R \u222a {\u221e}. The biconjugate f * * denotes its convex envelope, i.e. the largest lower-semicontinuous convex under-approximation of f . For a set C we denote by \u03b4 C the function which maps any element from C to 0 and is \u221e otherwise. For a comprehensive introduction to convex analysis, we refer the reader to [19]. Vector valued functions u : \u2126 \u2192 R k are written in bold symbols. If it is clear from the context, we will drop the x \u2208 \u2126 inside the functions, e.g., we write \u03c1(u) for \u03c1(x, u(x)), or \u03b1 for \u03b1(x).", "publication_ref": ["b19"], "figure_ref": [], "table_ref": []}, {"heading": "Functional Lifting", "text": "To derive a convex representation of (1), we rely on the framework of functional lifting. The idea is to reformulate the optimization problem in a higher dimensional space. We numerically show in Sec. 5 that considering the convex envelope of the dataterm and regularizer in this higher dimensional space leads to a better approximation of the original nonconvex energy. We start by sampling the range Figure 3. We show the nonconvex energy \u03c1(u) at a fixed point x \u2208 \u2126 (red dashed line in both plots) from the stereo matching experiment in Fig. 9 over the full range of 270 disparities. The black dots indicate the positions of the labels and the black curves show the approximations used by the respective methods. Fig. 3a: The baseline lifting method [17] uses a piecewise linear approximation with labels as nodes. Fig. 3b: The proposed method uses an optimal piecewise convex approximation. As we can see, the piecewise convex approximation is closer to the original nonconvex energy and therefore more accurate.\n\u0393 at L = k + 1 labels \u03b3 1 < . . . < \u03b3 L \u2208 \u0393. This par- titions the range into k intervals \u0393 i = [\u03b3 i , \u03b3 i+1 ] so that \u0393 = \u0393 1 \u222a . . . \u222a \u0393 k .\nFor any value in the range of u : \u2126 \u2192 \u0393 there exist a label index\n1 \u2264 i \u2264 k and \u03b1 \u2208 [0, 1] such that u(x) = \u03b3 \u03b1 i := \u03b3 i + \u03b1(\u03b3 i+1 \u2212 \u03b3 i ).(2)\nWe represent a value in the range \u0393 by a vector in R k\nu(x) = 1 \u03b1 i := \u03b11 i + (1 \u2212 \u03b1)1 i\u22121 ,(3)\nwhere 1 i denotes a vector starting with i ones followed by k \u2212 i zeros. We call u : \u2126 \u2192 R k the lifted representation of u, representing the graph of u. This notation is depicted in Fig. 2 for k = 4. Back-projecting the lifted u(x) to the range of u using the layer cake formula yields a one-to-one correspondence between u(x) = \u03b3 \u03b1 i and u(x) = 1 \u03b1 i via\nu(x) = \u03b3 1 + k i=1 u i (x)(\u03b3 i+1 \u2212 \u03b3 i ).(4)\nWe write problem (1) in terms of such graph functions, a technique that is used in the theory of Cartesian currents [8].", "publication_ref": ["b16", "b7"], "figure_ref": ["fig_7", "fig_0"], "table_ref": []}, {"heading": "Convexification of the Dataterm", "text": "For now, we consider a fixed x \u2208 \u2126. Then the dataterm from ( 1) is a possibly nonconvex real-valued function (cf. Fig. 3) that we seek to minimize over a compact interval \u0393:\nmin u\u2208\u0393 \u03c1(u).(5)\nDue to the one-to-one correspondence between \u03b3 \u03b1 i and 1 \u03b1 i it is clear that solving problem ( 5) is equivalent to finding a minimizer of the lifted energy:\n\u03c1(u) = min 1\u2264i\u2264k \u03c1 i (u),(6)\n\u03c1 i (u) = \uf8f1 \uf8f2 \uf8f3 \u03c1(\u03b3 \u03b1 i ), if u = 1 \u03b1 i , \u03b1 \u2208 [0, 1], \u221e, else.(7)\nNote that the constraint in ( 7) is essentially the nonconvex special ordered set of type 2 (SOS2) constraint [3]. More precisely, we demand that the \"derivative\" in label direction (\u2202 \u03b3 u) i := u i+1 \u2212 u i is zero, except for two neighboring elements, which add up to one. In the following proposition, we derive the tightest convex relaxation of \u03c1.\nProposition 1. The convex envelope of ( 6) is given as:\n\u03c1 * * (u) = sup v\u2208R k u, v \u2212 max 1\u2264i\u2264k \u03c1 * i (v),(8)\nwhere the conjugate of the individual \u03c1 i is\n\u03c1 * i (v) = c i (v) + \u03c1 * i v i \u03b3 i+1 \u2212 \u03b3 i , (9\n)\nwith c i (v) = 1 i\u22121 , v \u2212 \u03b3i \u03b3i+1\u2212\u03b3i v i and \u03c1 i = \u03c1 + \u03b4 \u0393i .\nProof. See supplementary material.\nThe above proposition reveals that the convex relaxation implicitly convexifies the dataterm \u03c1 on each interval \u0393 i . The equality \u03c1 * i = \u03c1 * * * i implies that starting with \u03c1 i yields exactly the same convex relaxation as starting with \u03c1 * * i .\nCorollary 1. If \u03c1 is linear on each \u0393 i , then the convex envelopes of \u03c1(u) and \u03c3(u) coincide, where the latter is:\n\u03c3(u) = \uf8f1 \uf8f2 \uf8f3 \u03c1(\u03b3 \u03b1 i ), if \u2203i : u = 1 \u03b1 i , \u03b1 \u2208 {0, 1}, \u221e, else. (10\n)\nProof. Consider an additional constraint \u03b4 {\u03b3i,\u03b3i+1} for each \u03c1 i , which corresponds to selecting \u03b1 \u2208 {0, 1} in (7). The fact that our relaxation is independent of whether we choose \u03c1 i or \u03c1 * * i , along with the fact that the convex hull of two points is a line, yields the assertion.\nFor the piecewise linear case, it is possible to find an explicit form of the biconjugate. Proposition 2. Let us denote by r \u2208 R k the vector with\nr i = \u03c1(\u03b3 i+1 ) \u2212 \u03c1(\u03b3 i ), 1 \u2264 i \u2264 k. (11\n)\nUnder the assumptions of Prop. 1, one obtains:\n\u03c3 * * (u) = \uf8f1 \uf8f2 \uf8f3 \u03c1(\u03b3 1 ) + u, r , if u i \u2265 u i+1 , u i \u2208 [0, 1], \u221e, else. (12\n)\nProof. See supplementary material.\nUp to an offset (which is irrelevant for the optimization), one can see that (12) coincides with the dataterm of [15], the discretizations of [17,18], and -after a change of variable -with [11]. This not only proves that the latter is optimizing a convex envelope, but also shows that our method naturally generalizes the work from piecewise linear to arbitrary piecewise convex energies. Fig. 3a and Fig. 3b illustrate the difference of \u03c3 * * and \u03c1 * * on the example of a nonconvex stereo matching cost.\nBecause our method allows arbitrary convex functions on each \u0393 i , we can prove that, for the two label case, our approach optimizes the convex envelope of the dataterm. Proposition 3. In the case of binary labeling, i.e., L = 2, the convex envelope of (6) reduces to\n\u03c1 * * (u) = \u03c1 * * (\u03b3 1 + u(\u03b3 2 \u2212 \u03b3 1 )) , with u \u2208 [0, 1]. (13)\nProof. See supplementary material.", "publication_ref": ["b2", "b6", "b11", "b14", "b16", "b18", "b10"], "figure_ref": [], "table_ref": []}, {"heading": "A Lifted Representation of the Total Variation", "text": "We now want to find a lifted convex formulation that emulates the total variation regularization in (1). We follow [5] and define an appropriate integrand of the functional\nT V (u) = \u2126 \u03a6(x, Du),(14)\nwhere the distributional derivative Du is a finite R k\u00d7dvalued Radon measure [2]. We define\n\u03a6(g) = min 1\u2264i\u2264j\u2264k \u03a6 i,j (g). (15\n)\nThe individual \u03a6 i,j : R k\u00d7d \u2192 R \u222a {\u221e} are given by:\n\u03a6 i,j (g) = \uf8f1 \uf8f2 \uf8f3 \u03b3 \u03b1 i \u2212 \u03b3 \u03b2 j \u2022 |\u03bd| 2 , if g = (1 \u03b1 i \u2212 1 \u03b2 j ) \u03bd T , \u221e, else,(16)\n\u03c1 * i epi(\u03c1 * i ) \u03b3 i \u03b3 i+1 v i (x)/(\u03b3 i+1 \u2212 \u03b3 i ) z i (x)/(\u03b3 i+1 \u2212 \u03b3 i ) (a) \u03c1 * i epi(\u03c1 * i ) \u03b3 i \u00b5 2 \u03b3 i+1 \u00b5 1 v i (x)/(\u03b3 i+1 \u2212 \u03b3 i ) z i (x)/(\u03b3 i+1 \u2212 \u03b3 i ) (b)\nFigure 4. Illustration of the epigraph projection. In the left subfigure the projection onto the epigraph of the conjugate of a convex quadratic \u03c1i is shown. In the right subfigure the piecewise linear case is illustrated. In the both cases all points that lie in the gray sets are orthogonally projected onto the respective linear parts whereas the points that lie in the green sets are projected onto the parabolic part (in the quadratic case) respectively the kinks (in the piecewise linear case). In the piecewise linear case the green sets are normal cones. The red dashed lines correspond to the boundary cases. \u03b3i, \u03b3i+1, \u00b51, \u00b52 are the slopes of the segments of \u03c1 * i respectively the (sub-)label positions of \u03c1i.\nfor some \u03b1, \u03b2 \u2208 [0, 1] and \u03bd \u2208 R d . The intuition is that \u03a6 i,j penalizes a jump from \u03b3 \u03b1 i to \u03b3 \u03b2 j in the direction of \u03bd. Since \u03a6 is nonconvex we compute the convex envelope. \nwhere K \u2282 R k\u00d7d is given as:\nK = p \u2208 R k\u00d7d p T (1 \u03b1 i \u2212 1 \u03b2 j ) 2 \u2264 \u03b3 \u03b1 i \u2212 \u03b3 \u03b2 j , \u2200 1 \u2264 i \u2264 j \u2264 k, \u2200\u03b1, \u03b2 \u2208 [0, 1] .(18)\nProof. See supplementary material.\nThe set K from Eq. (18) involves infinitely many constraints which makes numerical optimization difficult. As the following proposition reveals, the infinite number of constraints can be reduced to only linearly many, allowing to enforce the constraint p \u2208 K exactly. Proposition 5. If the labels are ordered (\u03b3 1 < \u03b3 2 < . . . < \u03b3 L ) then the constraint set K from Eq. (18) is equal to\nK = {p \u2208R k\u00d7d | |p i | 2 \u2264 \u03b3 i+1 \u2212 \u03b3 i , \u2200i}.(19)\nProof. See supplementary material. We compare the proposed method to the baseline method [17] on the convex ROF problem. We show the time in seconds required for each method to produce a solution within a certain energy gap to the optimal solution. As the baseline method optimizes a piecewise linear approximation of the quadratic dataterm, it fails to reach that optimality gap even for L = 256 (indicated by t = \u221e). In contrast, while the proposed lifting method can solve a large class of non-convex problems, it is almost as efficient as direct methods on convex problems.\nThis shows that the proposed regularizer coincides with the total variation from [5], where it has been derived based on (16) for \u03b1 and \u03b2 restricted to {0, 1}. Prop. 5 together with Prop. 3 show that for k = 1 our formulation amounts to unlifted T V optimization with a convexified dataterm.", "publication_ref": ["b4", "b1", "b16", "b4", "b15"], "figure_ref": ["fig_2"], "table_ref": []}, {"heading": "Numerical Optimization", "text": "Discretizing \u2126 \u2282 R d as a d-dimensional Cartesian grid, the relaxed energy minimization problem becomes\nmin u:\u2126\u2192R k x\u2208\u2126 \u03c1 * * (x, u(x)) + \u03a6 * * (x, \u2207u(x)),(20)\nwhere \u2207 denotes a forward-difference operator with \u2207u : \u2126 \u2192 R k\u00d7d . We rewrite the dataterm given in equation ( 8) by replacing the pointwise maximum over the conjugates \u03c1 * i with a maximum over a real number q \u2208 R and obtain  The top row shows the input image along with the result obtained by our approach for a varying number of labels L. The bottom row illustrates the results obtained by the baseline method [17].\nThe energy of the final solution as well as the total runtime are given below each image.\nthe following saddle point formulation of problem (20):\nmin u:\u2126\u2192R k max (v,q)\u2208C p:\u2126\u2192K u, v \u2212 x\u2208\u2126 q(x) + p, \u2207u ,(21)\nC = {(v, q) : \u2126 \u2192 R k \u00d7 R | q(x) \u2265 \u03c1 * i (v(x)), \u2200x, \u2200i}.(22)\nWe numerically compute a minimizer of problem (21) using a first-order primal-dual method [6,16] with diagonal preconditioning [14] and adaptive steps [9]. It alternates between a gradient descent step in the primal variable and a gradient ascent step in the dual variable. Subsequently the dual variables are orthogonally projected onto the sets C respectively K. In the following we give some hints on the implementation of the individual steps. For a detailed discussion we refer to [9]. The projection onto the set K is a simple \u2113 2 -ball projection. To simplify the projection onto C, we transform the k-dimensional epigraph constraints in ( 22) into 1-dimensional scaled epigraph constraints by introducing an additional variable z : \u2126 \u2192 R k with: Comparison to the MRF approach presented in [27].\nz i (x) = [q(x) \u2212 c i (v(x))] (\u03b3 i+1 \u2212 \u03b3 i ) . (23\n)\nE = 279394 E = 208432 E = 196803 E = 194855 E = 278108 E = 208112 E = 196810 E = 194845 E = 277970 E = 208493 E = 196979 E = 194836\nThe first row shows DC-Linear, second row DC-MRF and third row our results for 4, 8, 16 and 32 convex pieces on the truncated quadratic energy (26). Below the figures we show the final nonconvex energy. We achieve competitive results while using a more compact representation and generalizing to isotropic regularizers.\nUsing equation ( 9) we can write the constraints in ( 22) as\nz i (x) \u03b3 i+1 \u2212 \u03b3 i \u2265 \u03c1 * i v i (x) \u03b3 i+1 \u2212 \u03b3 i . (24\n)\nWe implement the newly introduced equality constraints ( 23) introducing a Lagrange multiplier s : \u2126 \u2192 R k . It remains to discuss the orthogonal projections onto the epigraphs of the conjugates \u03c1 * i . Currently we support quadratic and piecewise linear convex pieces \u03c1 i . For the piecewise linear case, the conjugate \u03c1 * i is a piecewise linear function with domain R. The slopes correspond to the xpositions of the sublabels and the intercepts correspond to the function values at the sublabel positions.\nThe conjugates as well as the epigraph projections of both, a quadratic and a piecewise linear piece are depicted in Fig. 4. For the quadratic case, the projection onto the epigraph of a parabola is computed using [23, Appendix B.2].", "publication_ref": ["b16", "b5", "b15", "b13", "b8", "b8", "b27", "b26"], "figure_ref": ["fig_2"], "table_ref": []}, {"heading": "Experiments", "text": "We implemented the primal-dual algorithm in CUDA to run on GPUs. 1 For d = 2, our implementation of the func-Figure 8. We compare the proposed relaxation with anistropic regularizer to isotropic regularization on the stereo matching example. Using an anisotropic formulation as in [27] leads to grid bias. tional lifting framework [17], which will serve as a baseline method, requires 4N (L \u2212 1) optimization variables, while the proposed method requires 6N (L \u2212 1) + N variables, where N is the number of points used to discretize the domain \u2126 \u2282 R d . As we will show, our method requires much fewer labels to yield comparable results, thus, leading to an improvement in accuracy, memory usage, and speed.", "publication_ref": ["b0", "b27", "b16"], "figure_ref": ["fig_9"], "table_ref": []}, {"heading": "Rudin-Osher-Fatemi Model", "text": "As a proof of concept, we first evaluate the novel relaxation on the well-known Rudin-Osher-Fatemi (ROF) model [20]. It corresponds to (1) with the following dataterm:\n\u03c1(x, u(x)) = (u(x) \u2212 f (x)) 2 ,(25)\nwhere f : \u2126 \u2192 R denotes the input data. While there is no practical use in applying convex relaxation methods to an already convex problem such as the ROF model, the purpose of this is two-fold. Firstly, it allows us to measure the overhead introduced by our method by comparing it to standard convex optimization methods which do not rely on functional lifting. Secondly, we can experimentally verify that the relaxation is tight for a convex dataterm. In Fig. 5 we solve (25) directly using the primal-dual algorithm [9], using the baseline functional lifting method [17] and using our proposed algorithm. First, the globally optimal energy was computed using the direct method with a very high number of iterations. Then we measure how long each method took to reach this global optimum to a fixed tolerance.\nThe baseline method fails to reach the global optimum even for 256 labels. While the lifting framework introduces a certain overhead, the proposed method finds the same globally optimal energy as the direct unlifted optimization approach and generalizes to nonconvex energies. We compare the proposed method to the baseline method on the example of stereo matching. The first column shows one of the two input images and below the baseline method with the full number of labels. The proposed relaxation requires much fewer labels to reach a smooth depth map. Even for L = 32, the label space discretization of the baseline method is strongly visible, while the proposed method yields a smooth result already for L = 8.", "publication_ref": ["b20", "b8", "b16"], "figure_ref": ["fig_3"], "table_ref": []}, {"heading": "Robust Truncated Quadratic Dataterm", "text": "The quadratic dataterm in ( 25) is often not well suited for real-world data as it comes from a pure Gaussian noise assumption and does not model outliers. We now consider a robust truncated quadratic dataterm:\n\u03c1(x, u(x)) = \u03b1 2 min (u(x) \u2212 f (x)) 2 , \u03bd .(26)\nTo implement ( 26), we use a piecewise polynomial approximation of the dataterm. In Fig. 6 we degraded the input image with additive Gaussian and salt and pepper noise. The parameters in (26) were chosen as \u03b1 = 25, \u03bd = 0.025 and \u03bb = 1. It can be seen that the proposed method requires fewer labels to find lower energies than the baseline.", "publication_ref": ["b26"], "figure_ref": ["fig_5"], "table_ref": []}, {"heading": "Comparison to the Method of Zach and Kohli", "text": "We remark that Prop. 4 and Prop. 5 hold for arbitrary convex one-homogeneous functionals \u03c6(\u03bd) instead of |\u03bd| 2 in equation (16). In particular, they hold for the anisotropic total variation \u03c6(\u03bd) = |\u03bd| 1 . This generalization allows us to directly compare our convex relaxation to the MRF approach of Zach and Kohli [27].\nIn Fig. 7 we show the results of optimizing the two models entitled \"DC-Linear\" and \"DC-MRF\" proposed in [27], and of our proposed method with anisotropic regularization on the robust truncated denoising energy (26). We picked the parameters as \u03b1 = 0.2, \u03bd = 500, and \u03bb = 1. The label space is also chosen as \u0393 = [0, 256] as described in [27].\nNote that overall, all the energies are better than the ones reported in [27]. It can be seen from Fig. 7 that the proposed relaxation is competitive to the one pro-posed by Zach and Kohli. In addition, the proposed relaxation uses a more compact representation and extends to isotropic and convex one-homogeneous regularizers. To illustrate the advantages of isotropic regularizations, Fig. 8a and Fig. 8b show a comparison of our proposed method for isotropic and anisotropic regularization for the example of stereo matching discussed in the next section.", "publication_ref": ["b15", "b27", "b27", "b26", "b27", "b27"], "figure_ref": ["fig_6", "fig_6", "fig_9", "fig_9"], "table_ref": []}, {"heading": "Stereo Matching", "text": "Given a pair of rectified images, the task of finding a correspondence between the two images can be formulated as an optimization problem over a scalar field u : \u2126 \u2192 \u0393 where each point u(x) \u2208 \u0393 denotes the displacement along the epipolar line associated with each x \u2208 \u2126. The overall cost functional fits Eq. (1). In our experiments, we computed \u03c1(x, u(x)) for 270 disparities on the Middlebury stereo benchmark [21] in a 4\u00d74 patch using a truncated sum of absolute gradient differences. We convexify the matching cost \u03c1 in each range \u0393 i by numerically computing the convex envelope using the gift wrapping algorithm.\nThe first row in Fig. 9 shows the result of the proposed relaxation using the convexified energy between two labels. The second row shows the baseline approach using the same amount of labels. Even for L = 2, the proposed method produces a reasonable depth map while the baseline approach basically corresponds to a two region segmentation. ing on the circle S 1 . Here we consider the task of total variation regularized unwrapping. As is shown on the left in Fig. 11, the dataterm is a nonconvex function where each minimum corresponds to a phase shift by 2\u03c0:", "publication_ref": ["b21"], "figure_ref": ["fig_7"], "table_ref": []}, {"heading": "Phase Unwrapping", "text": "\u03c1 (x, u(x)) = d S 1 (u(x), f (x)) 2 .(27)\nFor the experiments, we approximated the nonconvex energy by quadratic pieces as depicted in Fig. 11. The label space is chosen as \u0393 = [0, 4\u03c0] and the regularization parameter was set to \u03bb = 0.005. Again, it is visible in Fig. 11 that the baseline method shows label space discretization and fails to unwrap the depth map correctly if the number of labels is chosen too low. The proposed method yields a smooth unwrapped result using only 8 labels.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Depth From Focus", "text": "In depth from focus the task is to recover the depth of a scene, given a stack of images each taken from a constant position but in a different focal setting, so that in each image only the objects of a certain depth are sharp. images. We compute the dataterm cost \u03c1 by using the modified Laplacian function [13] as a contrast measure.\nSimilar to the stereo experiments, we convexify the cost on each label range by computing the convex hull. The results are shown in Fig. 10. While the baseline method clearly shows the label space discretization, the proposed approach yields a smooth depth map. Since the proposed method uses a convex lower bound of the lifted energy, the regularizer has slightly more influence on the final result. This explains why the resulting depth maps in Fig. 10  Figure 11. We show the piecewise convex approximation of the phase unwrapping energy, followed by the cyclic input image and the unwrapped ground truth. With only 8 labels, the proposed method already yields a smooth reconstruction. The baseline method fails to unwrap the heightmap correctly using 8 labels, and for 16 and 32 labels, the discretization is still noticable.", "publication_ref": ["b12"], "figure_ref": ["fig_8", "fig_8"], "table_ref": []}, {"heading": "Conclusion", "text": "In this work we proposed a tight convex relaxation that can be interpreted as a sublabel-accurate formulation of classical multilabel problems. The final formulation is a simple saddle-point problem that admits fast primal-dual optimization. Our method maintains sublabel accuracy even after discretization and for that reason outperforms existing spatially continuous methods. Interesting directions for future work include higher dimensional label spaces, manifold valued data and more general regularizers.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "", "text": "Acknowledgement This work was supported by the ERC Starting Grant \"ConvexVision\". We greatly acknowledge NVIDIA for providing us a Titan X GPU.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "The calibration method for the Mumford-Shah functional and freediscontinuity problems", "journal": "Calc. Var. Partial Dif", "year": "2003", "authors": "G Alberti; G Bouchitt\u00e9; G D Maso"}, {"ref_id": "b1", "title": "Functions of Bounded Variation and Free Discontinuity Problems", "journal": "Oxford University Press", "year": "2000", "authors": "L Ambrosio; N Fusco; D Pallara"}, {"ref_id": "b2", "title": "Special facilities in a general mathematical programming system for nonconvex problems using ordered sets of variables", "journal": "", "year": "1970", "authors": "E Beale; J Tomlin"}, {"ref_id": "b3", "title": "An introduction to total variation for image analysis. Theoretical foundations and numerical methods for sparse recovery", "journal": "", "year": "2010", "authors": "A Chambolle; V Caselles; D Cremers; M Novaga; T Pock"}, {"ref_id": "b4", "title": "A convex approach to minimal partitions", "journal": "SIAM Journal on Imaging Sciences", "year": "2012", "authors": "A Chambolle; D Cremers; T Pock"}, {"ref_id": "b5", "title": "A general framework for a class of first order primal-dual algorithms for convex optimization in imaging science", "journal": "SIAM Journal on Imaging Sciences", "year": "2010", "authors": "E Esser; X Zhang; T Chan"}, {"ref_id": "b6", "title": "Duality and the continuous graphical model", "journal": "Springer International Publishing", "year": "2014", "authors": "A Fix; S Agarwal"}, {"ref_id": "b7", "title": "Cartesian currents in the calculus of variations I, II", "journal": "Springer-Verlag", "year": "1998", "authors": "M Giaquinta; G Modica; J Sou\u010dek"}, {"ref_id": "b8", "title": "Adaptive Primal-Dual Hybrid Gradient Methods for Saddle-Point Problems", "journal": "", "year": "2013", "authors": "T Goldstein; E Esser; R Baraniuk"}, {"ref_id": "b9", "title": "Exact optimization for Markov random fields with convex priors", "journal": "IEEE Trans. Pattern Analysis and Machine Intelligence", "year": "2003", "authors": "H Ishikawa"}, {"ref_id": "b10", "title": "Continuous multiclass labeling approaches and algorithms", "journal": "SIAM J. Imaging Sciences", "year": "2004", "authors": "J Lellmann; C Schn\u00f6rr"}, {"ref_id": "b11", "title": "Total variation regularization for functions with values in a manifold", "journal": "", "year": "2013-12", "authors": "J Lellmann; E Strekalovskiy; S Koetter; D Cremers"}, {"ref_id": "b12", "title": "Shape from focus", "journal": "IEEE Trans. Pattern Anal. Mach. Intell", "year": "1994-08", "authors": "S K Nayar; Y Nakagawa"}, {"ref_id": "b13", "title": "Diagonal preconditioning for first order primal-dual algorithms in convex optimization", "journal": "", "year": "2011", "authors": "T Pock; A Chambolle"}, {"ref_id": "b14", "title": "A convex relaxation approach for computing minimal partitions", "journal": "", "year": "2009", "authors": "T Pock; A Chambolle; H Bischof; D Cremers"}, {"ref_id": "b15", "title": "An algorithm for minimizing the piecewise smooth Mumford-Shah functional", "journal": "", "year": "2009", "authors": "T Pock; D Cremers; H Bischof; A Chambolle"}, {"ref_id": "b16", "title": "Global solutions of variational models with convex regularization", "journal": "", "year": "", "authors": "T Pock; D Cremers; H Bischof; A Chambolle"}, {"ref_id": "b17", "title": "", "journal": "SIAM J. Imaging Sci", "year": "2006", "authors": ""}, {"ref_id": "b18", "title": "A convex formulation of continuous multi-label problems", "journal": "", "year": "2004", "authors": "T Pock; T Schoenemann; G Graber; H Bischof; D Cremers"}, {"ref_id": "b19", "title": "Convex Analysis", "journal": "Princeton University Press", "year": "1996", "authors": "R T Rockafellar"}, {"ref_id": "b20", "title": "Nonlinear total variation based noise removal algorithms", "journal": "Physica D: Nonlinear Phenomena", "year": "1992", "authors": "L I Rudin; S Osher; E Fatemi"}, {"ref_id": "b21", "title": "High-resolution stereo datasets with subpixel-accurate ground truth", "journal": "Springer", "year": "2014", "authors": "D Scharstein; H Hirschm\u00fcller; Y Kitajima; G Krathwohl; N Nei; X Wang; P Westling"}, {"ref_id": "b22", "title": "Sintaksicheskiy analiz dvumernykh zritelnikh signalov v usloviyakh pomekh (Syntactic analysis of two-dimensional visual signals in noisy conditions)", "journal": "", "year": "1976", "authors": "M Schlesinger"}, {"ref_id": "b23", "title": "Convex relaxation of vectorial problems with coupled regularization", "journal": "SIAM Journal on Imaging Sciences", "year": "2014", "authors": "E Strekalovskiy; A Chambolle; D Cremers"}, {"ref_id": "b24", "title": "A linear programming approach to max-sum problem: A review", "journal": "IEEE Trans. Pattern Anal. Mach. Intell", "year": "2002", "authors": "T Werner"}, {"ref_id": "b25", "title": "Dual decomposition for joint discrete-continuous optimization", "journal": "", "year": "2013", "authors": "C Zach"}, {"ref_id": "b26", "title": "What is optimized in tight convex relaxations for multi-label problems", "journal": "", "year": "2012", "authors": "C Zach; C Hane; M Pollefeys"}, {"ref_id": "b27", "title": "A convex discrete-continuous approach for markov random fields", "journal": "Springer", "year": "2006", "authors": "C Zach; P Kohli"}], "figures": [{"figure_label": "2", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 2 .2Figure2. Lifted representation. Instead of optimizing over the function u : \u2126 \u2192 \u0393, we optimize over all possible graph functions (here shaded in green) on \u2126 \u00d7 \u0393. The main idea behind our approach is the finite dimensional representation of the graph at every x \u2208 \u2126 by means of u : \u2126 \u2192 R k (here k = 4).", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Proposition 4 .4The convex envelope of (15) is\u03a6 * * (g) = sup p\u2208K p, g ,", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 5 .5Figure5. Denoising comparison. We compare the proposed method to the baseline method[17] on the convex ROF problem. We show the time in seconds required for each method to produce a solution within a certain energy gap to the optimal solution. As the baseline method optimizes a piecewise linear approximation of the quadratic dataterm, it fails to reach that optimality gap even for L = 256 (indicated by t = \u221e). In contrast, while the proposed lifting method can solve a large class of non-convex problems, it is almost as efficient as direct methods on convex problems.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Baseline (L = 256), E = 18660, t = 1001s Baseline (L = 5), E = 23864, t = 4.7s Baseline (L = 10), E = 19802, t = 6.3s Baseline (L = 20), E = 18876, t = 12.8s", "figure_data": ""}, {"figure_label": "6", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Figure 6 .6Figure 6. Denoising using a robust truncated quadratic dataterm.The top row shows the input image along with the result obtained by our approach for a varying number of labels L. The bottom row illustrates the results obtained by the baseline method[17]. The energy of the final solution as well as the total runtime are given below each image.", "figure_data": ""}, {"figure_label": "7", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Figure 7 .7Figure7. Comparison to the MRF approach presented in[27]. The first row shows DC-Linear, second row DC-MRF and third row our results for 4, 8, 16 and 32 convex pieces on the truncated quadratic energy(26). Below the figures we show the final nonconvex energy. We achieve competitive results while using a more compact representation and generalizing to isotropic regularizers.", "figure_data": ""}, {"figure_label": "9", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "Figure 9 .9Figure9. Stereo comparison. We compare the proposed method to the baseline method on the example of stereo matching. The first column shows one of the two input images and below the baseline method with the full number of labels. The proposed relaxation requires much fewer labels to reach a smooth depth map. Even for L = 32, the label space discretization of the baseline method is strongly visible, while the proposed method yields a smooth result already for L = 8.", "figure_data": ""}, {"figure_label": "10", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "Figure 10 .10Figure10. Depth from focus comparison. We compare our method to the baseline approach on the problem of depth from focus. First column: one of the 374 differently focused input images and the baseline method for full number of labels. Following columns: proposed relaxation (top row) vs. baseline (bottom row) for 2, 4, 8, 16 and 32 labels each.", "figure_data": ""}, {"figure_label": "8", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "= 8 )8and Fig. 9 look overall less noisy. Baseline (L = 16) Baseline (L = 32) Proposed (L = 8)", "figure_data": ""}], "formulas": [{"formula_id": "formula_1", "formula_text": "\u0393 at L = k + 1 labels \u03b3 1 < . . . < \u03b3 L \u2208 \u0393. This par- titions the range into k intervals \u0393 i = [\u03b3 i , \u03b3 i+1 ] so that \u0393 = \u0393 1 \u222a . . . \u222a \u0393 k .", "formula_coordinates": [3.0, 50.11, 220.52, 236.25, 39.4]}, {"formula_id": "formula_2", "formula_text": "1 \u2264 i \u2264 k and \u03b1 \u2208 [0, 1] such that u(x) = \u03b3 \u03b1 i := \u03b3 i + \u03b1(\u03b3 i+1 \u2212 \u03b3 i ).(2)", "formula_coordinates": [3.0, 99.91, 263.56, 186.45, 32.79]}, {"formula_id": "formula_3", "formula_text": "u(x) = 1 \u03b1 i := \u03b11 i + (1 \u2212 \u03b1)1 i\u22121 ,(3)", "formula_coordinates": [3.0, 97.27, 326.08, 189.09, 12.98]}, {"formula_id": "formula_4", "formula_text": "u(x) = \u03b3 1 + k i=1 u i (x)(\u03b3 i+1 \u2212 \u03b3 i ).(4)", "formula_coordinates": [3.0, 96.46, 439.72, 189.9, 30.62]}, {"formula_id": "formula_5", "formula_text": "min u\u2208\u0393 \u03c1(u).(5)", "formula_coordinates": [3.0, 148.0, 583.03, 138.36, 15.39]}, {"formula_id": "formula_6", "formula_text": "\u03c1(u) = min 1\u2264i\u2264k \u03c1 i (u),(6)", "formula_coordinates": [3.0, 124.86, 655.84, 161.51, 15.71]}, {"formula_id": "formula_7", "formula_text": "\u03c1 i (u) = \uf8f1 \uf8f2 \uf8f3 \u03c1(\u03b3 \u03b1 i ), if u = 1 \u03b1 i , \u03b1 \u2208 [0, 1], \u221e, else.(7)", "formula_coordinates": [3.0, 80.72, 679.72, 205.64, 32.87]}, {"formula_id": "formula_8", "formula_text": "\u03c1 * * (u) = sup v\u2208R k u, v \u2212 max 1\u2264i\u2264k \u03c1 * i (v),(8)", "formula_coordinates": [3.0, 349.43, 337.09, 195.69, 19.75]}, {"formula_id": "formula_9", "formula_text": "\u03c1 * i (v) = c i (v) + \u03c1 * i v i \u03b3 i+1 \u2212 \u03b3 i , (9", "formula_coordinates": [3.0, 355.3, 391.44, 185.94, 21.07]}, {"formula_id": "formula_10", "formula_text": ")", "formula_coordinates": [3.0, 541.24, 395.96, 3.87, 8.91]}, {"formula_id": "formula_11", "formula_text": "with c i (v) = 1 i\u22121 , v \u2212 \u03b3i \u03b3i+1\u2212\u03b3i v i and \u03c1 i = \u03c1 + \u03b4 \u0393i .", "formula_coordinates": [3.0, 308.86, 421.26, 219.58, 14.29]}, {"formula_id": "formula_12", "formula_text": "\u03c3(u) = \uf8f1 \uf8f2 \uf8f3 \u03c1(\u03b3 \u03b1 i ), if \u2203i : u = 1 \u03b1 i , \u03b1 \u2208 {0, 1}, \u221e, else. (10", "formula_coordinates": [3.0, 320.32, 568.29, 220.65, 32.87]}, {"formula_id": "formula_13", "formula_text": ")", "formula_coordinates": [3.0, 540.96, 582.38, 4.15, 8.91]}, {"formula_id": "formula_14", "formula_text": "r i = \u03c1(\u03b3 i+1 ) \u2212 \u03c1(\u03b3 i ), 1 \u2264 i \u2264 k. (11", "formula_coordinates": [4.0, 99.16, 97.0, 183.05, 10.46]}, {"formula_id": "formula_15", "formula_text": ")", "formula_coordinates": [4.0, 282.21, 97.74, 4.15, 8.91]}, {"formula_id": "formula_16", "formula_text": "\u03c3 * * (u) = \uf8f1 \uf8f2 \uf8f3 \u03c1(\u03b3 1 ) + u, r , if u i \u2265 u i+1 , u i \u2208 [0, 1], \u221e, else. (12", "formula_coordinates": [4.0, 54.49, 137.8, 227.72, 46.23]}, {"formula_id": "formula_17", "formula_text": ")", "formula_coordinates": [4.0, 282.21, 175.12, 4.15, 8.91]}, {"formula_id": "formula_18", "formula_text": "\u03c1 * * (u) = \u03c1 * * (\u03b3 1 + u(\u03b3 2 \u2212 \u03b3 1 )) , with u \u2208 [0, 1]. (13)", "formula_coordinates": [4.0, 58.21, 430.89, 228.15, 12.57]}, {"formula_id": "formula_19", "formula_text": "T V (u) = \u2126 \u03a6(x, Du),(14)", "formula_coordinates": [4.0, 117.91, 557.83, 168.45, 18.29]}, {"formula_id": "formula_20", "formula_text": "\u03a6(g) = min 1\u2264i\u2264j\u2264k \u03a6 i,j (g). (15", "formula_coordinates": [4.0, 115.67, 621.39, 166.55, 15.71]}, {"formula_id": "formula_21", "formula_text": ")", "formula_coordinates": [4.0, 282.21, 622.12, 4.15, 8.91]}, {"formula_id": "formula_22", "formula_text": "\u03a6 i,j (g) = \uf8f1 \uf8f2 \uf8f3 \u03b3 \u03b1 i \u2212 \u03b3 \u03b2 j \u2022 |\u03bd| 2 , if g = (1 \u03b1 i \u2212 1 \u03b2 j ) \u03bd T , \u221e, else,(16)", "formula_coordinates": [4.0, 58.1, 666.94, 228.26, 46.23]}, {"formula_id": "formula_23", "formula_text": "\u03c1 * i epi(\u03c1 * i ) \u03b3 i \u03b3 i+1 v i (x)/(\u03b3 i+1 \u2212 \u03b3 i ) z i (x)/(\u03b3 i+1 \u2212 \u03b3 i ) (a) \u03c1 * i epi(\u03c1 * i ) \u03b3 i \u00b5 2 \u03b3 i+1 \u00b5 1 v i (x)/(\u03b3 i+1 \u2212 \u03b3 i ) z i (x)/(\u03b3 i+1 \u2212 \u03b3 i ) (b)", "formula_coordinates": [4.0, 317.91, 80.38, 208.24, 109.63]}, {"formula_id": "formula_25", "formula_text": "K = p \u2208 R k\u00d7d p T (1 \u03b1 i \u2212 1 \u03b2 j ) 2 \u2264 \u03b3 \u03b1 i \u2212 \u03b3 \u03b2 j , \u2200 1 \u2264 i \u2264 j \u2264 k, \u2200\u03b1, \u03b2 \u2208 [0, 1] .(18)", "formula_coordinates": [4.0, 317.74, 479.57, 227.37, 34.61]}, {"formula_id": "formula_26", "formula_text": "K = {p \u2208R k\u00d7d | |p i | 2 \u2264 \u03b3 i+1 \u2212 \u03b3 i , \u2200i}.(19)", "formula_coordinates": [4.0, 328.24, 669.87, 216.87, 12.96]}, {"formula_id": "formula_27", "formula_text": "min u:\u2126\u2192R k x\u2208\u2126 \u03c1 * * (x, u(x)) + \u03a6 * * (x, \u2207u(x)),(20)", "formula_coordinates": [5.0, 70.37, 628.82, 215.99, 23.0]}, {"formula_id": "formula_28", "formula_text": "min u:\u2126\u2192R k max (v,q)\u2208C p:\u2126\u2192K u, v \u2212 x\u2208\u2126 q(x) + p, \u2207u ,(21)", "formula_coordinates": [5.0, 329.22, 444.5, 215.89, 24.66]}, {"formula_id": "formula_29", "formula_text": "C = {(v, q) : \u2126 \u2192 R k \u00d7 R | q(x) \u2265 \u03c1 * i (v(x)), \u2200x, \u2200i}.(22)", "formula_coordinates": [5.0, 310.52, 479.35, 234.59, 25.48]}, {"formula_id": "formula_30", "formula_text": "z i (x) = [q(x) \u2212 c i (v(x))] (\u03b3 i+1 \u2212 \u03b3 i ) . (23", "formula_coordinates": [5.0, 347.07, 703.91, 193.89, 10.46]}, {"formula_id": "formula_31", "formula_text": ")", "formula_coordinates": [5.0, 540.96, 704.27, 4.15, 8.91]}, {"formula_id": "formula_32", "formula_text": "E = 279394 E = 208432 E = 196803 E = 194855 E = 278108 E = 208112 E = 196810 E = 194845 E = 277970 E = 208493 E = 196979 E = 194836", "formula_coordinates": [6.0, 59.72, 143.61, 220.48, 148.53]}, {"formula_id": "formula_33", "formula_text": "z i (x) \u03b3 i+1 \u2212 \u03b3 i \u2265 \u03c1 * i v i (x) \u03b3 i+1 \u2212 \u03b3 i . (24", "formula_coordinates": [6.0, 105.94, 407.58, 176.27, 24.03]}, {"formula_id": "formula_34", "formula_text": ")", "formula_coordinates": [6.0, 282.21, 415.06, 4.15, 8.91]}, {"formula_id": "formula_35", "formula_text": "\u03c1(x, u(x)) = (u(x) \u2212 f (x)) 2 ,(25)", "formula_coordinates": [6.0, 365.58, 407.07, 179.53, 12.73]}, {"formula_id": "formula_36", "formula_text": "\u03c1(x, u(x)) = \u03b1 2 min (u(x) \u2212 f (x)) 2 , \u03bd .(26)", "formula_coordinates": [7.0, 73.37, 362.46, 212.99, 23.2]}, {"formula_id": "formula_37", "formula_text": "\u03c1 (x, u(x)) = d S 1 (u(x), f (x)) 2 .(27)", "formula_coordinates": [8.0, 101.56, 323.57, 184.8, 13.75]}], "doi": ""}