{"title": "Hogwild!: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent", "authors": "Feng Niu; Benjamin Recht; Christopher R\u00e9; Stephen J Wright", "pub_date": "2011-11-11", "abstract": "Stochastic Gradient Descent (SGD) is a popular algorithm that can achieve state-of-the-art performance on a variety of machine learning tasks. Several researchers have recently proposed schemes to parallelize SGD, but all require performance-destroying memory locking and synchronization. This work aims to show using novel theoretical analysis, algorithms, and implementation that SGD can be implemented without any locking. We present an update scheme called Hogwild! which allows processors access to shared memory with the possibility of overwriting each other's work. We show that when the associated optimization problem is sparse, meaning most gradient updates only modify small parts of the decision variable, then Hogwild! achieves a nearly optimal rate of convergence. We demonstrate experimentally that Hogwild! outperforms alternative schemes that use locking by an order of magnitude.", "sections": [{"heading": "Introduction", "text": "With its small memory footprint, robustness against noise, and rapid learning rates, Stochastic Gradient Descent (SGD) has proved to be well suited to data-intensive machine learning tasks [3,5,26]. However, SGD's scalability is limited by its inherently sequential nature; it is difficult to parallelize. Nevertheless, the recent emergence of inexpensive multicore processors and mammoth, web-scale data sets has motivated researchers to develop several clever parallelization schemes for SGD [4,10,12,16,30]. As many large data sets are currently pre-processed in a MapReduce-like parallel-processing framework, much of the recent work on parallel SGD has focused naturally on MapReduce implementations. MapReduce is a powerful tool developed at Google for extracting information from huge logs (e.g., \"find all the urls from a 100TB of Web data\") that was designed to ensure fault tolerance and to simplify the maintenance and programming of large clusters of machines [9]. But MapReduce is not ideally suited for online, numerically intensive data analysis. Iterative computation is difficult to express in MapReduce, and the overhead to ensure fault tolerance can result in dismal throughput. Indeed, even Google researchers themselves suggest that other systems, for example Dremel, are more appropriate than MapReduce for data analysis tasks [21].\nFor some data sets, the sheer size of the data dictates that one use a cluster of machines. However, there are a host of problems in which, after appropriate preprocessing, the data necessary for statistical analysis may consist of a few terabytes or less. For such problems, one can use a single inexpensive work station as opposed to a hundred thousand dollar cluster. Multicore systems have significant performance advantages, including (1) low latency and high throughput shared main memory (a processor in such a system can write and read the shared physical memory at over 12GB/s with latency in the tens of nanoseconds); and (2) high bandwidth off multiple disks (a thousand-dollar RAID can pump data into main memory at over 1GB/s). In contrast, a typical MapReduce setup will read incoming data at rates less than tens of MB/s due to frequent checkpointing for fault tolerance. The high rates achievable by multicore systems move the bottlenecks in parallel computation to synchronization (or locking) amongst the processors [2,13]. Thus, to enable scalable data analysis on a multicore machine, any performant solution must minimize the overhead of locking.\nIn this work, we propose a simple strategy for eliminating the overhead associated with locking: run SGD in parallel without locks, a strategy that we call Hogwild!. In Hogwild!, processors are allowed equal access to shared memory and are able to update individual components of memory at will. Such a lock-free scheme might appear doomed to fail as processors could overwrite each other's progress. However, when the data access is sparse, meaning that individual SGD steps only modify a small part of the decision variable, we show that memory overwrites are rare and that they introduce barely any error into the computation when they do occur. We demonstrate both theoretically and experimentally a near linear speedup with the number of processors on commonly occurring sparse learning problems.\nIn Section 2, we formalize a notion of sparsity that is sufficient to guarantee such a speedup and provide canonical examples of sparse machine learning problems in classification, collaborative filtering, and graph cuts. Our notion of sparsity allows us to provide theoretical guarantees of linear speedups in Section 4. As a by-product of our analysis, we also derive rates of convergence for algorithms with constant stepsizes. We demonstrate that robust 1/k convergence rates are possible with constant stepsize schemes that implement an exponential back-off in the constant over time. This result is interesting in of itself and shows that one need not settle for 1/ \u221a k rates to ensure robustness in SGD algorithms.\nIn practice, we find that computational performance of a lock-free procedure exceeds even our theoretical guarantees. We experimentally compare lock-free SGD to several recently proposed methods. We show that all methods that propose memory locking are significantly slower than their respective lock-free counterparts on a variety of machine learning applications.", "publication_ref": ["b2", "b4", "b25", "b3", "b9", "b11", "b15", "b29", "b8", "b20", "b1", "b12"], "figure_ref": [], "table_ref": []}, {"heading": "Sparse Separable Cost Functions", "text": "Our goal throughout is to minimize a function f :\nX \u2286 R n \u2192 R of the form f (x) = e\u2208E f e (x e ) .\n(2.1)\nHere e denotes a small subset of {1, . . . , n} and x e denotes the values of the vector x on the coordinates indexed by e. The key observation that underlies our lock-free approach is that the natural cost functions associated with many machine learning problems of interest are sparse in the sense that |E| and n are both very large but each individual f e acts only on a very small number of components of x. That is, each subvector x e contains just a few components of x. Sparse SVM. Suppose our goal is to fit a support vector machine to some data pairs E = {(z 1 , y 1 ), . . . , (z |E| , y |E| )} where z \u2208 R n and y is a label for each (z, y) \u2208 E.\nminimize x \u03b1\u2208E max(1 \u2212 y \u03b1 x T z \u03b1 , 0) + \u03bb x 2 2 , (2.2)\nand we know a priori that the examples z \u03b1 are very sparse (see for example [14]). To write this cost function in the form of Matrix Completion. In the matrix completion problem, we are provided entries of a low-rank, n r \u00d7 n c matrix Z from the index set E. Such problems arise in collaborative filtering, Euclidean distance estimation, and clustering [8,17,24]. Our goal is to reconstruct Z from this sparse sampling of data. A popular heuristic recovers the estimate of Z as a product LR * of factors obtained from the following minimization:\nminimize (L,R) (u,v)\u2208E (L u R * v \u2212 Z uv ) 2 + \u00b5 2 L 2 F + \u00b5 2 R 2 F , (2.4)\nwhere L is n r \u00d7 r, R is n c \u00d7 r and L u (resp. R v ) denotes the uth (resp. vth) row of L (resp. R) [17,24,27]. To put this problem in sparse form, i.e., as (2.1), we write (2.4) as\nminimize (L,R) (u,v)\u2208E (L u R * v \u2212 Z uv ) 2 + \u00b5 2|E u\u2212 | L u 2 F + \u00b5 2|E \u2212v | R v 2 F\nwhere E u\u2212 = {v : (u, v) \u2208 E} and E \u2212v = {u : (u, v) \u2208 E}.\nGraph Cuts. Problems involving minimum cuts in graphs frequently arise in machine learning (see [6] for a comprehensive survey). In such problems, we are given a sparse, nonnegative matrix W which indexes similarity between entities. Our goal is to find a partition of the index set {1, . . . , n} that best conforms to this similarity matrix. Here the graph structure is explicitly determined by the similarity matrix W ; arcs correspond to nonzero entries in W . We want to match each string to some list of D entities. Each node is associated with a vector x i in the D-dimensional simplex\nS D = {\u03b6 \u2208 R D : \u03b6 v \u2265 0 D v=1 \u03b6 v = 1}.\nHere, two-way cuts use D = 2, but multiway-cuts with tens of thousands of classes also arise in entity resolution problems [18]. For example, we may have a list of n strings, and W uv might index the similarity of each string. Several authors (e.g., [7]) propose to minimize the cost function\nminimize x (u,v)\u2208E w uv x u \u2212 x v 1 subject to x v \u2208 S D for v = 1, . . . , n .\n(2.5)\nIn all three of the preceding examples, the number of components involved in a particular term f e is a small fraction of the total number of entries. We formalize this notion by defining the following statistics of the hypergraph G:\n\u2126 := max e\u2208E |e|, \u2206 := max 1\u2264v\u2264n |{e \u2208 E : v \u2208 e}| |E| , \u03c1 := max e\u2208E |{\u00ea \u2208 E :\u00ea \u2229 e = \u2205}| |E| . (2.6)\nThe quantity \u2126 simply quantifies the size of the hyper edges. \u03c1 determines the maximum fraction of edges that intersect any given edge. \u2206 determines the maximum fraction of edges that intersect any variable. \u03c1 is a measure of the sparsity of the hypergraph, while \u2206 measures the node-regularity.\nFor our examples, we can make the following observations about \u03c1 and \u2206.\n1. Sparse SVM. \u2206 is simply the maximum frequency that any feature appears in an example, while \u03c1 measures how clustered the hypergraph is. If some features are very common across the data set, then \u03c1 will be close to one. . This follows from a coupon collector argument [8].\n3. Graph Cuts. \u2206 is the maximum degree divided by |E|, and \u03c1 is at most 2\u2206.\nWe now describe a simple protocol that achieves a linear speedup in the number of processors when \u2126, \u2206, and \u03c1 are relatively small.", "publication_ref": ["b13", "b7", "b16", "b23", "b16", "b23", "b26", "b5", "b17", "b6", "b7"], "figure_ref": [], "table_ref": []}, {"heading": "The Hogwild! Algorithm", "text": "Here we discuss the parallel processing setup. We assume a shared memory model with p processors. The decision variable x is accessible to all processors. Each processor can read x, and can contribute an update vector to x. The vector x is stored in shared memory, and we assume that the componentwise addition operation is atomic, that is Sample e uniformly at random from E 3:\nx v \u2190 x v + a\nRead current state x e and evaluate G e (x)\n4: for v \u2208 e do x v \u2190 x v \u2212 \u03b3b T\nv G e (x) 5: end loop can be performed atomically by any processor for a scalar a and v \u2208 {1, . . . , n}. This operation does not require a separate locking structure on most modern hardware: such an operation is a single atomic instruction on GPUs and DSPs, and it can be implemented via a compare-andexchange operation on a general purpose multicore processor like the Intel Nehalem. In contrast, the operation of updating many components at once requires an auxiliary locking structure.\nEach processor then follows the procedure in Algorithm 1. To fully describe the algorithm, let b v denote one of the standard basis elements in R n , with v ranging from 1, . . . , n. That is, b v is equal to 1 on the vth component and 0 otherwise. Let P v denote the Euclidean projection matrix onto the vth coordinate, i.e., P v = b v b T v . P v is a diagonal matrix equal to 1 on the vth diagonal and zeros elsewhere. Let G e (x) \u2208 R n denote a gradient or subgradient of the function f e multiplied by |E|. That is, we extend f e from a function on the coordinates of e to all of R n simply by ignoring the components in \u00ace (i.e., not in e). Then\n|E| \u22121 G e (x) \u2208 \u2202f e (x).\nHere, G e is equal to zero on the components in \u00ace. Using a sparse representation, we can calculate G e (x), only knowing the values of x in the components indexed by e. Note that as a consequence of the uniform random sampling of e from E, we have\nE[G e (x e )] \u2208 \u2202f (x) .\nIn Algorithm 1, each processor samples an term e \u2208 E uniformly at random, computes the gradient of f e at x e , and then writes\nx v \u2190 x v \u2212 \u03b3b T v G e (x), for each v \u2208 e (3.1)\nImportantly, note that the processor modifies only the variables indexed by e, leaving all of the components in \u00ace (i.e., not in e) alone. We assume that the stepsize \u03b3 is a fixed constant. Even though the processors have no knowledge as to whether any of the other processors have modified x, we define x j to be the state of the decision variable x after j updates have been performed 1 . Since two processors can write to x at the same time, we need to be a bit careful with this definition, but we simply break ties at random. Note that x j is generally updated with a stale gradient, which is based on a value of x read many clock cycles earlier. We use x k(j) to denote the value of the decision variable used to compute the gradient or subgradient that yields the state\nx j .\nIn what follows, we provide conditions under which this asynchronous, incremental gradient algorithm converges. Moreover, we show that if the hypergraph induced by f is isotropic and sparse, then this algorithm converges in nearly the same number of gradient steps as its serial counterpart. Since we are running in parallel and without locks, this means that we get a nearly linear speedup in terms of the number of processors.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Fast Rates for Lock-Free Parallelism", "text": "We now turn to our theoretical analysis of Hogwild! protocols. To make the analysis tractable, we assume that we update with the following \"with replacement\" procedure: each processor samples an edge e uniformly at random and computes a subgradient of f e at the current value of the decision variable. Then it chooses an v \u2208 e uniformly at random and updates\nx v \u2190 x v \u2212 \u03b3|e|b T v G e (x)\nNote that the stepsize is a factor |e| larger than the step in (3.1). Also note that this update is completely equivalent to\nx \u2190 x \u2212 \u03b3|e|P T v G e (x) . (4.1)\nThis notation will be more convenient for the subsequent analysis. This with replacement scheme assumes that a gradient is computed and then only one of its components is used to update the decision variable. Such a scheme is computationally wasteful as the rest of the components of the gradient carry information for decreasing the cost. Consequently, in practice and in our experiments, we perform a modification of this procedure. We partition out the edges without replacement to all of the processors at the beginning of each epoch. The processors then perform full updates of all of the components of each edge in their respective queues. However, we emphasize again that we do not implement any locking mechanisms on any of the variables. We do not analyze this \"without replacement\" procedure because no one has achieved tractable analyses for SGD in any without replacement sampling models. Indeed, to our knowledge, all analysis of without-replacement sampling yields rates that are comparable to a standard subgradient descent algorithm which takes steps along the full gradient of (2.1) (see, for example [22]). That is, these analyses suggest that without-replacement sampling should require a factor of |E| more steps than with-replacement sampling. In practice, this worst case behavior is never observed. In fact, it is conventional wisdom in machine learning that without-replacement sampling in stochastic gradient descent actually outperforms the with-replacement variants on which all of the analysis is based.\nTo state our theoretical results, we must describe several quantities that important in the analysis of our parallel stochastic gradient descent scheme. We follow the notation and assumptions of Nemirovski et al [23]. To simplify the analysis, we will assume that each f e in (2.1) is a convex function. We assume Lipschitz continuous differentiability of f with Lipschitz constant L:\n\u2207f (x ) \u2212 \u2207f (x) \u2264 L x \u2212 x , \u2200 x , x \u2208 X. (4.2)\nWe also assume f is strongly convex with modulus c. By this we mean that\nf (x ) \u2265 f (x) + (x \u2212 x) T \u2207f (x) + c 2 x \u2212 x 2 , for all x , x \u2208 X. (4.3)\nWhen f is strongly convex, there exists a unique minimizer x and we denote f = f (x ). We additionally assume that there exists a constant M such that G e (x e ) 2 \u2264 M almost surely for all x \u2208 X . (4.4)\nWe assume throughout that \u03b3c < 1. (Indeed, when \u03b3c > 1, even the ordinary gradient descent algorithms will diverge.) Our main results are summarized by the following Proposition 4.1 Suppose in Algorithm 1 that the lag between when a gradient is computed and when it is used in step j -namely, j \u2212 k(j) -is always less than or equal to \u03c4 , and \u03b3 is defined to be\n\u03b3 = \u03d1 c 2LM 2 \u2126 1 + 6\u03c1\u03c4 + 4\u03c4 2 \u2126\u2206 1/2 .\n(4.5)\nfor some > 0 and \u03d1 \u2208 (0, 1). Define D 0 := x 0 \u2212 x 2 and let k be an integer satisfying\nk \u2265 2LM 2 \u2126 1 + 6\u03c4 \u03c1 + 6\u03c4 2 \u2126\u2206 1/2 log(LD 0 / ) c 2 \u03d1 . (4.6)\nThen after k component updates of x, we have\nE[f (x k ) \u2212 f ] \u2264 .\nIn the case that \u03c4 = 0, this reduces to precisely the rate achieved by the serial SGD protocol. A similar rate is achieved if \u03c4 = o(n 1/4 ) as \u03c1 and \u2206 are typically both o(1/n). In our setting, \u03c4 is proportional to the number of processors, and hence as long as the number of processors is less n 1/4 , we get nearly the same recursion as in the linear rate.\nWe prove Proposition 4.1 in two steps in the Appendix. First, we demonstrate that the sequence\na j = 1 2 E[ x j \u2212 x 2 ] satisfies a recursion of the form a j \u2264 (1 \u2212 c r \u03b3)(a j+1 \u2212 a \u221e ) + a \u221e\nfor some constant a \u221e that depends on many of the algorithm parameters but not on the state, and some constant c r < c. This c r is an \"effective curvature\" for the problem which is smaller that the true curvature c because of the errors introduced by our update rule. Using the fact that c r \u03b3 < 1, we will show in Section 5 how to determine an upper bound on k for which a k \u2264 /L. Proposition 4.1\nthen follows because E[f (x k ) \u2212 f (x )] \u2264 La k since the gradient of f is Lipschitz. A full proof is provided in the appendix.\nNote that up to the log(1/ ) term in (4.6), our analysis nearly provides a 1/k rate of convergence for a constant stepsize SGD scheme, both in the serial and parallel cases. Moreover, note that our rate of convergence is fairly robust to error in the value of c; we pay linearly for our underestimate of the curvature of f . In contrast, Nemirovski et al demonstrate that when the stepsize is inversely proportional to the iteration counter, an overestimate of c can result in exponential slow-down [23]! We now turn to demonstrating that we can eliminate the log term from (4.6) by a slightly more complicated protocol where the stepsize is slowly decreased after a large number of iterations.\n5 Robust 1/k rates.\nSuppose we run Algorithm 1 for a fixed number of gradient updates K with stepsize \u03b3 < 1/c. Then, we wait for the threads to coalesce, reduce \u03b3 by a constant factor \u03b2 \u2208 (0, 1), and run for \u03b2 \u22121 K iterations. In some sense, this piecewise constant stepsize protocol approximates a 1/k diminishing stepsize. The main difference with the following analysis from previous work is that our stepsizes are always less than 1/c in contrast to beginning with very large stepsizes. Always working with small stepsizes allows us to avoid the possible exponential slow-downs that occur with standard diminishing stepsize schemes.\nTo be precise, suppose a k is any sequence of real numbers satisfying\na k+1 \u2264 (1 \u2212 c r \u03b3)(a k \u2212 a \u221e (\u03b3)) + a \u221e (\u03b3) (5.1)\nwhere a \u221e is some non-negative function of \u03b3 satisfying a \u221e (\u03b3) \u2264 \u03b3B and c r and B are constants. This recursion underlies many convergence proofs for SGD where a k denotes the distance to the optimal solution after k iterations. We will derive appropriate constants for Hogwild! in the Appendix. We will also discuss below what these constants are for standard stochastic gradient descent algorithms.\nFactoring out the dependence on \u03b3 will be useful in what follows. Unwrapping (5.1) we have\na k \u2264 (1 \u2212 c r \u03b3) k (a 0 \u2212 a \u221e (\u03b3)) + a \u221e (\u03b3) .\nSuppose we want this quantity to be less than . It is sufficient that both terms are less than /2. For the second term, this means that it is sufficient to set\n\u03b3 \u2264 2B . (5.2)\nFor the first term, we then need To eliminate the log factor, we can implement a backoff scheme where we reduce the stepsize by a constant factor after several iterations. This backoff scheme will have two phases: the first phase will consist of converging to the ball about x of squared radius less than 2B cr at an exponential rate. Then we will converge to x by shrinking the stepsize.\n(1 \u2212 \u03b3c r ) k a 0 \u2264 /2 which holds if k \u2265 log(2a 0 / ) \u03b3c r . (5\nTo calculate the number of iterates required to get inside a ball of squared radius 2B cr , suppose the initial stepsize is chosen as \u03b3 = \u03d1 cr (0 < \u03d1 < 1). This choice of stepsize guarantees that the a k converge to a \u221e . We use the parameter \u03d1 to demonstrate that we do not suffer much for underestimating the optimal stepsize (i.e., \u03d1 = 1) in our algorithms. Using (5.3) we find that\nk \u2265 \u03d1 \u22121 log a 0 c r \u03d1B (5.4)\niterations are sufficient to converge to this ball. Note that this is a linear rate of convergence. Now assume that a 0 < 2\u03d1B cr . Let's reduce the stepsize by a factor of \u03b2 each epoch. This reduces the achieved by a factor of \u03b2. Thus, after log \u03b2 (a 0 / ) epochs, we will be at accuracy . The total number of iterations required is then the sum of terms with the form (5.3), with a 0 set to be the radius achieved by the previous epoch and set to be \u03b2 times this a 0 . Hence, for epoch number \u03bd, the initial distance is \u03b2 \u03bd\u22121 a 0 and the final radius is \u03b2 \u03bd . Summing over all of the epochs (except for the initial phase) gives\nlog \u03b2 (a 0 / ) k=1 log(2/\u03b2) \u03d1\u03b2 k = log(2/\u03b2) \u03d1 log \u03b2 (a 0 / ) k=1 \u03b2 \u2212k = log(2/\u03b2) \u03d1 \u03b2 \u22121 (a 0 / ) \u2212 1 \u03b2 \u22121 \u2212 1 \u2264 a 0 \u03d1 log(2/\u03b2) 1 \u2212 \u03b2 \u2264 2B c r log(2/\u03b2) 1 \u2212 \u03b2 .\n(5.5)\nThis expression is minimized by selecting a backoff parameter \u2248 0.37. Also, note that when we reduce the stepsize by \u03b2, we need to run for \u03b2 \u22121 more iterations. Combining (5.4) and (5.5), we estimate a total number of iterations equal to\nk \u2265 \u03d1 \u22121 log a 0 c r \u03d1B + 2B c r log(2/\u03b2) 1 \u2212 \u03b2 are sufficient to guarantee that a k \u2264 .\nRearranging terms, the following two expressions give in terms of all of the algorithm parameters:\n\u2264 2 log(2/\u03b2) 1 \u2212 \u03b2 \u2022 B c r \u2022 1 k \u2212 \u03d1 \u22121 log a 0 cr \u03d1B .\n(5.6)", "publication_ref": ["b21", "b22", "b22"], "figure_ref": [], "table_ref": []}, {"heading": "Consequences for serial SGD", "text": "Let us compare the results of this constant step-size protocol to one where the stepsize at iteration k is set to be \u03b3 0 /k for some initial step size \u03b3 for the standard (serial) incremental gradient algorithm applied to (2.1). Nemirovski et al [23] show that the expected squared distance to the optimal solution, a k , satisfies\na k+1 \u2264 (1 \u2212 2c\u03b3 k )a k + 1 2 \u03b3 2 k M 2 .\nWe can put this recursion in the form (5.1) by setting \u03b3 k = \u03b3, c r = 2c, B = M 2 4c , and a \u221e = \u03b3M 2 4c . The authors of [23] demonstrate that a large step size:\n\u03b3 k = \u0398 2ck with \u0398 > 1 yields a bound a k \u2264 1 k max M 2 c 2 \u2022 \u0398 2 4\u0398 \u2212 4 , D 0\nOn the other hand, a constant step size protocol achieves\na k \u2264 log(2/\u03b2) 4(1 \u2212 \u03b2) \u2022 M 2 c 2 \u2022 1 k \u2212 \u03d1 \u22121 log 4D 0 c 2 \u03d1M 2 .\nThis bound is obtained by plugging the algorithm parameters into (5.6) and letting D 0 = 2a 0 . Note that both bounds have asymptotically the same dependence on M , c, and k. The expression log(2/\u03b2)\n4(1 \u2212 \u03b2)\nis minimized when \u03b2 \u2248 0.37 and is equal to 1.34. The expression \u0398 2 4\u0398 \u2212 4 is minimized when \u0398 = 2 and is equal to 1 at this minimum. So the leading constant is slightly worse in the constant stepsize protocol when all of the parameters are set optimally. However, if D 0 \u2265 M 2 /c 2 , the 1/k protocol has error proportional to D 0 , but our constant stepsize protocol still has only a logarithmic dependence on the initial distance. Moreover, the constant stepsize scheme is much more robust to overestimates of the curvature parameter c. For the 1/k protocols, if one overestimates the curvature (corresponding to a small value of \u0398), one can get arbitrarily slow rates of convergence. An simple, one dimensional example in [23] shows that \u0398 = 0.2 can yield a convergence rate of k \u22121/5 . In our scheme, \u03d1 = 0.2 simply increases the number of iterations by a factor of 5.\nThe proposed fix in [23] for the sensitivity to curvature estimates results in asymptotically slower convergence rates of 1/ \u221a k. It is important to note that we need not settle for these slower rates and can still achieve robust convergence at 1/k rates.", "publication_ref": ["b22", "b22", "b22", "b22"], "figure_ref": [], "table_ref": []}, {"heading": "Parallel Implementation of a Backoff Scheme", "text": "The scheme described about results in a 1/k rate of convergence for Hogwild! with the only synchronization overhead occurring at the end of each \"round\" or \"epoch\" of iteration. When implementing a backoff scheme for Hogwild!, the processors have to agree on when to reduce the stepsize. One simple scheme for this is to run all of the processors for a fixed number of iterations, wait for all of the threads to complete, and then globally reduce the stepsize in a master thread. We note that one can eliminate the need for the threads to coalesce by sending out-of-band messages to the processors to signal when to reduce \u03b3. This complicates the theoretical analysis as there may be times when different processors are running with different stepsizes, but in practice could allow one to avoid synchronization costs. We do not implement this scheme, and so do not analyze this idea further.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Related Work", "text": "Most schemes for parallelizing stochastic gradient descent are variants of ideas presented in the seminal text by Bertsekas and Tsitsiklis [4]. For instance, in this text, they describe using stale gradient updates computed across many computers in a master-worker setting and describe settings where different processors control access to particular components of the decision variable. They prove global convergence of these approaches, but do not provide rates of convergence (This is one way in which our work extends this prior research). These authors also show that SGD convergence is robust to a variety of models of delay in computation and communication in [29].\nWe also note that constant stepsize protocols with backoff procedures are canonical in SGD practice, but perhaps not in theory. Some theoretical work which has at least demonstrated convergence of these protocols can be found in [20,28]. These works do not establish the 1/k rates which we provided above.\nRecently, a variety of parallel schemes have been proposed in a variety of contexts. In MapReduce settings, Zinkevich et al proposed running many instances of stochastic gradient descent on  different machines and averaging their output [30]. Though the authors claim this method can reduce both the variance of their estimate and the overall bias, we show in our experiments that for the sorts of problems we are concerned with, this method does not outperform a serial scheme. Schemes involving the averaging of gradients via a distributed protocol have also been proposed by several authors [10,12]. While these methods do achieve linear speedups, they are difficult to implement efficiently on multicore machines as they require massive communication overhead. Distributed averaging of gradients requires message passing between the cores, and the cores need to synchronize frequently in order to compute reasonable gradient averages.\nThe work most closely related to our own is a round-robin scheme proposed by Langford et al [16]. In this scheme, the processors are ordered and each update the decision variable in order. When the time required to lock memory for writing is dwarfed by the gradient computation time, this method results in a linear speedup, as the errors induced by the lag in the gradients are not too severe. However, we note that in many applications of interest in machine learning, gradient computation time is incredibly fast, and we now demonstrate that in a variety of applications, Hogwild! outperforms such a round-robin approach by an order of magnitude.", "publication_ref": ["b3", "b28", "b19", "b27", "b29", "b9", "b11", "b15"], "figure_ref": [], "table_ref": []}, {"heading": "Experiments", "text": "We ran numerical experiments on a variety of machine learning tasks, and compared against a round-robin approach proposed in [16] and implemented in Vowpal Wabbit [15]. We refer to this approach as RR. To be as fair as possible to prior art, we hand coded RR to be nearly identical to the Hogwild! approach, with the only difference being the schedule for how the gradients are updated. One notable change in RR from the Vowpal Wabbit software release is that we optimized RR's locking and signaling mechanisms to use spinlocks and busy waits (there is no need for generic signaling to implement round robin). We verified that this optimization results in nearly an order of magnitude increase in wall clock time for all problems that we discuss.\nWe also compare against a model which we call AIG which can be seen as a middle ground between RR and Hogwild!. AIG runs a protocol identical to Hogwild! except that it locks all of the variables in e in before and after the for loop on line 4 of Algorithm 1. Our experiments demonstrate that even this fine-grained locking induces undesirable slow-downs.\nAll of the experiments were coded in C++ are run on an identical configuration: a dual Xeon X650 CPUs (6 cores each x 2 hyperthreading) machine with 24GB of RAM and a software RAID-0 over 7 2TB Seagate Constellation 7200RPM disks. The kernel is Linux 2.6.18-128. We never use more than 2GB of memory. All training data is stored on a seven-disk raid 0. We implemented a custom file scanner to demonstrate the speed of reading data sets of disk into small shared memory. This allows us to read data from the raid at a rate of nearly 1GB/s.\nAll of the experiments use a constant stepsize \u03b3 which is diminished by a factor \u03b2 at the end of each pass over the training set. We run all experiments for 20 such passes, even though less epochs are often sufficient for convergence. We show results for the largest value of the learning rate \u03b3 which converges and we use \u03b2 = 0.9 throughout. We note that the results look the same across a large range of (\u03b3, \u03b2) pairs and that all three parallelization schemes achieve train and test errors within a few percent of one another. We present experiments on the classes of problems described in Section 2.\nSparse SVM. We tested our sparse SVM implementation on the Reuters RCV1 data set on the binary text classification task CCAT [19] In this example, \u03c1 = 0.44 and \u2206 = 1.0-large values that suggest a bad case for Hogwild!. Nevertheless, in Figure 3(a), we see that Hogwild! is able to achieve a factor of 3 speedup with while RR gets worse as more threads are added. Indeed, for fast gradients, RR is worse than a serial implementation.\nFor this data set, we also implemented the approach in [30] which runs multiple SGD runs in parallel and averages their output. In Figure 5(b), we display at the train error of the ensemble average across parallel threads at the end of each pass over the data. We note that the threads only communicate at the very end of the computation, but we want to demonstrate the effect of parallelization on train error. Each of the parallel threads touches every data example in each pass. Thus, the 10 thread run does 10x more gradient computations than the serial version. Here, the error is the same whether we run in serial or with ten instances. We conclude that on this problem, there is no advantage to running in parallel with this averaging scheme.\nMatrix Completion. We ran Hogwild! on three very large matrix completion problems. The Netflix Prize data set has 17,770 rows, 480,189 columns, and 100,198,805 revealed entries. The KDD Cup 2011 (task 2) data set has 624,961 rows, 1,000,990, columns and 252,800,275 revealed entries. We also synthesized a low-rank matrix with rank 10, 1e7 rows and columns, and 2e9 revealed entries. We refer to this instance as \"Jumbo.\" In this synthetic example, \u03c1 and \u2206 are both around 1e-7. These values contrast sharply with the real data sets where \u03c1 and \u2206 are both on the order of 1e-3.\nFigure 5(a) shows the speedups for these three data sets using Hogwild!. Note that the Jumbo and KDD examples do not fit in our allotted memory, but even when reading data off disk, Hogwild! attains a near linear speedup. The Jumbo problem takes just over two and a half hours to complete. Speedup graphs comparing Hogwild! to AIG and RR on the three matrix completion experiments are provided in Figure 4. Similar to the other experiments with quickly computable gradients, RR does not show any improvement over a serial approach. In fact, with 10 threads, RR is 12% slower than serial on KDD Cup and 62% slower on Netflix. In fact, it is too slow to complete the Jumbo experiment in any reasonable amount of time, while the 10-way parallel Hogwild! implementation solves this problem in under three hours.\nGraph Cuts. Our first cut problem was a standard image segmentation by graph cuts problem popular in computer vision. We computed a two-way cut of the abdomen data set [1]. This data set consists of a volumetric scan of a human abdomen, and the goal is to segment the image into organs. The image has 512 \u00d7 512 \u00d7 551 voxels, and the associated graph is 6-connected with maximum capacity 10. Both \u03c1 and \u2206 are equal to 9.2e-4 We see that Hogwild! speeds up the cut problem by more than a factor of 4 with 10 threads, while RR is twice as slow as the serial version.\nOur second graph cut problem sought a mulit-way cut to determine entity recognition in a large database of web data. We created a data set of clean entity lists from the DBLife website and of entity mentions from the DBLife Web Crawl [11]. The data set consists of 18,167 entities and 180,110 mentions and similarities given by string similarity. In this problem each stochastic gradient step must compute a Euclidean projection onto a simplex of dimension 18,167. As a result, the individual stochastic gradient steps are quite slow. Nonetheless, the problem is still very sparse with \u03c1=8.6e-3 and \u2206=4.2e-3. Consequently, in Figure 3, we see the that Hogwild! achieves a ninefold speedup with 10 cores. Since the gradients are slow, RR is able to achieve a parallel speedup for this problem, however the speedup with ten processors is only by a factor of 5. That is, even in this case where the gradient computations are very slow, Hogwild! outperforms a round-robin scheme.\nWhat if the gradients are slow? As we saw with the DBLIFE data set, the RR method does get a nearly linear speedup when the gradient computation is slow. This raises the question whether RR ever outperforms Hogwild! for slow gradients. To answer this question, we ran the RCV1 experiment again and introduced an artificial delay at the end of each gradient computation to simulate a slow gradient. In Figure 5(c), we plot the wall clock time required to solve the SVM problem as we vary the delay for both the RR and Hogwild! approaches. Notice that Hogwild! achieves a greater decrease in computation time across the board. The speedups for both methods are the same when the delay is few milliseconds. That is, if a gradient takes longer than one millisecond to compute, RR is on par with Hogwild! (but not better). At this rate, one is only able to compute about a million stochastic gradients per hour, so the gradient computations must be very labor intensive in order for the RR method to be competitive.", "publication_ref": ["b15", "b14", "b18", "b29", "b0", "b10"], "figure_ref": ["fig_1", "fig_8", "fig_8", "fig_7", "fig_1", "fig_8"], "table_ref": []}, {"heading": "Conclusions", "text": "Our proposed Hogwild! algorithm takes advantage of sparsity in machine learning problems to enable near linear speedups on a variety of applications. Empirically, our implementations outperform our theoretical analysis. For instance, \u03c1 is quite large in the RCV1 SVM problem, yet we still obtain significant speedups. Moreover, our algorithms allow parallel speedup even when the gradients are computationally intensive.\nOur Hogwild! schemes can be generalized to problems where some of the variables occur quite frequently as well. We could choose to not update certain variables that would be in particularly high contention. For instance, we might want to add a bias term to our Support Vector Machine, and we could still run a Hogwild! scheme, updating the bias only every thousand iterations or so.\nFor future work, it would be of interest to enumerate structures that allow for parallel gradient computations with no collisions at all. That is, it may be possible to bias the SGD iterations to completely avoid memory contention between processors. For example, recent work proposed a biased ordering of the stochastic gradients in matrix completion problems that completely avoids memory contention between processors [25]. An investigation into how to generalize this approach to other structures and problems would enable even faster computation of machine learning problems.", "publication_ref": ["b24"], "figure_ref": [], "table_ref": []}, {"heading": "A.1 Developing the recursion", "text": "For 1 \u2264 v \u2264 n, let P v denote the projection onto the vth component of R n . (P v is a diagonal matrix with a 1 in the vth diagonal position and zeros elsewhere.) Similarly, for e \u2208 E, we let P e denote the projection onto the components indexed by e -a diagonal matrix with ones in the positions indexed by e and zeros elsewhere.\nWe start with the update formula (4.1). Recall that k(j) is the state of the decision variable's counter when the update to x j was read. We have\nx j+1 = x j \u2212 \u03b3|e j |P v j G e j (x k(j) ) .\nBy subtracting x from both sides, taking norms, we have 1 2\nx j+1 \u2212 x 2 2 = 1 2 x j \u2212 x 2 2 \u2212 \u03b3|e j |(x j \u2212 x ) T P v j G e j (x k(j) ) + 1 2 \u03b3 2 |e j | 2 P v j G e j (x k(j) ) 2 = 1 2 x j \u2212 x 2 2 \u2212 \u03b3|e j |(x j \u2212 x k(j) ) T P v j G e j (x j ) \u2212 \u03b3|e j |(x j \u2212 x k(j) ) T P v j (G e j (x k(j) ) \u2212 G e j (x j )) \u2212 \u03b3|e j |(x k(j) \u2212 x ) T P v j G e j (x k(j) ) + 1 2 \u03b3 2 |e j | 2 P v j G e j (x k(j) ) 2 Let a j = 1 2 E[ x j \u2212 x 2 2 ]\n. By taking expectations of both sides and using the bound (4.4), we obtain\na j+1 \u2264 a j \u2212 \u03b3E[(x j \u2212 x k(j) ) T G e j (x j )] \u2212 \u03b3E[(x j \u2212 x k(j) ) T (G e j (x k(j) ) \u2212 G e j (x j ))] \u2212 \u03b3E[(x k(j) \u2212 x ) T G e j (x k(j) )] + 1 2 \u03b3 2 \u2126M 2 . (A.3)\nwhere we recall that \u2126 = max e\u2208E |e|. Here, in several places, we used the useful identity: for any function \u03b6 of x 1 , . . . , x j and any i \u2264 j, we have\nE[|e j |P v j G e j (x i ) T \u03b6(x 1 , . . . , x j )] = E E |e j |P v j G e j (x i ) T \u03b6(x 1 , . . . , x j ) | e 1 , . . . , e j , v 1 , . . . , v j\u22121 = E G e j (x i ) T \u03b6(x 1 , . . . , x j ) .\nWe will perform many similar calculations throughout, so, before proceeding, we denote\ne [i] := (e 1 , e 2 , . . . , e i , v 1 , v 2 , . . . , v i ),\nto be the tuple of all edges and vertices selected in updates 1 through i. Note that x l depends on e [l\u22121] but not on e j or v j for any j \u2265 l. We next consider the three expectation terms in this expression.\nLet's first bound the third expectation term in (A.3). Since x k(j) is independent of e j we have\nE (x k(j) \u2212 x ) T G e j (x k(j) ) = E E (x k(j) \u2212 x ) T G e j (x k(j) )|e [k(j)\u22121] = E (x k(j) \u2212 x ) T E G e j (x k(j) )|e [k(j)\u22121] = E (x k(j) \u2212 x ) T \u2207f (x k(j) ) ,\nwhere \u2207f denotes an element of \u2202f . It follows from (A.2) that E (x k(j) \u2212 x ) T \u2207f (x k(j) ) \u2265 ca k(j) .\n(A.4)\nThe first expectation can be treated similarly:\nE[(x j \u2212 x k(j) ) T G e j (x j )] = E E[(x j \u2212 x k(j) ) T G e j (x j ) | e [j\u22121] ] = E (x j \u2212 x k(j) ) T E[G e j (x j ) | e [j\u22121] ] = E[(x j \u2212 x k(j) ) T \u2207f (x j )] \u2265 E[f (x j ) \u2212 f (x k(j) )] + c 2 E[ x j \u2212 x k(j) 2 ] (A.5)\nwhere the final inequality is from (A.1). Moreover, we can estimate the difference between f (x j ) and f (x k(j) ) as\nE[f (x k(j) ) \u2212 f (x j )] = j\u22121 i=k(j) E[f (x i ) \u2212 f (x i+1 )] = j\u22121 i=k(j) e\u2208E E[f e (x i ) \u2212 f e (x i+1 )] \u2264 \u03b3 |E| j\u22121 i=k(j) e\u2208E E[G e (x i ) T G e i (x i )] \u2264 \u03b3\u03c4 \u03c1M 2 . (A.6)\nHere we use the inequality\nf e (x i ) \u2212 f e (x i+1 ) \u2264 1 |E| G e (x i ) T (x i \u2212 x i+1 ) = \u03b3 |E| G e (x i ) T G e i (x i )\nwhich follows because f e is convex. By combining (A.5) and (A.6), we obtain\nE[(x j \u2212 x k(j) ) T G e j (x j )] \u2265 \u2212\u03b3\u03c4 \u03c1M 2 + c 2 E[ x j \u2212 x k(j) 2 ] . (A.7)\nWe turn now to the second expectation term in (A. To complete the argument, we need to bound the remaining expectation in (A.9). We expand out the expression multiplied by c\u03b3 in (A.9) to find\na k(j) + 1 2 E[ x j \u2212 x k(j) 2 = a j \u2212 E (x j \u2212 x k(j) ) T (x k(j) \u2212 x ) = a j \u2212 E \uf8ee \uf8f0 j\u22121 i=k(j) (x i+1 \u2212 x i ) T (x k(j) \u2212 x ) \uf8f9 \uf8fb = a j \u2212 E \uf8ee \uf8f0 j\u22121 i=k(j) \u03b3|e i |G e i (x k(i) ) T P v i (x k(j) \u2212 x ) \uf8f9 \uf8fb .\nLet e [\u00aci] denote the set of all sampled edges and vertices except for e i and v i . Since E E e i ,v i (x k(j) \u2212 x )\nT P v i (x k(j) \u2212 x ) | e [\u00aci] 1/2 =\u03b3\u2126M j\u22121 i=k(j) E (x k(j) \u2212 x ) T E e,v [P v ](x k(j) \u2212 x ) 1/2 \u2264\u03c4 \u03b3\u2126M E (x k(j) \u2212 x ) T E e,v [P v ](x k(j) \u2212 x ) 1/2 \u2264\u03c4 \u03b3\u2126M \u2206 1/2 E[ x k(j) \u2212 x 2 ] \u2264\u03c4 \u03b3\u2126M \u2206 1/2 (E[ x j \u2212 x 2 ] + \u03c4 \u03b3\u2126M ) \u2264\u03c4 \u03b3\u2126M \u2206 1/2 ( \u221a 2a 1/2 j + \u03c4 \u03b3\u2126M ) ,\nwhere \u2206 is defined in (2.6). The first inequality is Cauchy-Schwartz. The next inequality is Jensen.\nThe second to last inequality follows from our definition of x j , and the final inequality is Jensen again.\nPlugging the last two expressions into (A.9), we obtain\na j+1 \u2264 (1 \u2212 c\u03b3)a j + \u03b3 2 \u221a 2c\u2126M \u03c4 \u2206 1/2 a 1/2 j + 1 2 M 2 \u03b3 2 Q (A.10)\nwhere\nQ = \u2126 + 2\u03c4 \u03c1 + 4\u2126\u03c1\u03c4 + 2\u03c4 2 \u2126 2 \u2206 1/2 .\nHere we use the fact that c\u03b3 < 1 to get a simplified form for Q. This recursion only involves constants involved with the structure of f , and the nonnegative sequence a j . To complete the analysis, we will perform a linearization to put this recursion in a more manageable form.\nTo find the steady state, we must solve the equation\na \u221e = (1 \u2212 c\u03b3)a \u221e + \u03b3 2 \u221a 2c\u2126M \u03c4 \u2206 1/2 a 1/2 \u221e + M 2 \u03b3 2 2 Q . (A.11)\nThis yields the fixed point\na \u221e = M 2 \u03b3 2 2 \u2126\u03c4 \u2206 1/2 + \u2126 2 \u03c4 2 \u2206 + Q c\u03b3 2 \u2264 M 2 \u03b3 2c\n\u2126\u03c4 \u2206 1/2 + \u2126 2 \u03c4 2 \u2206 + Q = \u2126 2 \u03c4 2 \u2206 \u2022\n1 + 1 + Q \u2126 2 \u03c4 2 \u2206 2 1 \u2212 1 1+ 1+ Q \u2126 2 \u03c4 2 \u2206 = \u2126 2 \u03c4 2 \u2206 \u2022 1 + 1 + Q \u2126 2 \u03c4 2 \u2206 2 1 + Q \u2126 2 \u03c4 2 \u2206 \u2264 8\u2126 2 \u03c4 2 \u2206 + 2Q = 8\u2126 2 \u03c4 2 \u2206 + 2\u2126 + 4\u03c4 \u03c1 + 8\u2126\u03c1\u03c4 + 4\u03c4 2 \u2126 2 \u2206 1/2 \u2264 2\u2126(1 + 6\u03c4 \u03c1 + 6\u03c4 2 \u2126\u2206 1/2 ) .\nHere,the second to last inequality follows because\n1 + \u221a 1 + x 3 \u221a 1 + x \u2264 8 + 2x\nfor all x \u2265 0. Plugging this bound into (A.14) completes the proof.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgements", "text": "BR is generously supported by ONR award N00014-11-1-0723 and NSF award CCF-1139953. CR is generously supported by the Air Force Research Laboratory (AFRL) under prime contract no. FA8750-09-C-0181, the NSF CAREER award under IIS-1054009, ONR award N000141210041, and gifts or research awards from Google, LogicBlox, and Johnson Controls, Inc. SJW is generously supported by NSF awards DMS-0914524 and DMS-0906818 and DOE award de-sc0002283. Any opinions, findings, and conclusion or recommendations expressed in this work are those of the authors and do not necessarily reflect the views of any of the above sponsors including DARPA, AFRL, or the US government.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A Analysis of Hogwild!", "text": "It follows by rearrangement of (4.3) that\nIn particular, by setting x = x (the minimizer) we have\nWe will make use of these identities frequently in what follows.\nNote that for \u03c1 and \u2206 sufficiently small, C(\u03c4, \u03c1, \u2206, \u2126) \u2248 1.\nSince the square root is concave, we can linearize (A.10) about the fixed point a \u221e to yield\nHere \u03b4 = 1\nTo summarize, we have shown that the sequence a j of squared distances satisfies\nIn the case that \u03c4 = 0 (the serial case), C(\u03c4, \u03c1, \u2206, \u2126) = \u2126 and \u03b4(\u03c4, \u03c1, \u2206, \u2126) = 0. Note that if \u03c4 is non-zero, but \u03c1 and \u2206 are o(1/n) and o(1/ \u221a n) respectively, then as long as \u03c4 = o(n 1/4 ), C(\u03c4, \u03c1, \u2206, \u2126) = O(1). In our setting, \u03c4 is proportional to the number of processors, and hence as long as the number of processors is less n 1/4 , we get nearly the same recursion as in the linear rate.\nIn the next section, we show that (A.13) is sufficient to yield a 1/k convergence rate. Since we can run p times faster in our parallel setting, we get a linear speedup.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A.2 Proof of Proposition 4.1: Final Steps", "text": "Since \u2207f is Lipschitz, we have\nfor all k. To ensure the left hand side is less than , it suffices to guarantee that a k \u2264 /L.\nTo complete the proof of Proposition 4.1, we use the results of Section 4. We wish to achieve a target accuracy of /L. To apply (5.3), choose a \u221e as in (A.12) and the values\nBy (A.12), we have a \u221e \u2264 \u03b3B. Choose \u03b3 satisfying (4.5). With this choice, we automatically have", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Max-flow problem instances in vision", "journal": "", "year": "", "authors": ""}, {"ref_id": "b1", "title": "The landscape of parallel computing research: A view from berkeley", "journal": "", "year": "2006", "authors": "K Asanovic"}, {"ref_id": "b2", "title": "Nonlinear Programming", "journal": "Athena Scientific", "year": "1999", "authors": "D P Bertsekas"}, {"ref_id": "b3", "title": "", "journal": "Tsitsiklis. Parallel and Distributed Computation: Numerical Methods. Athena Scientific", "year": "1997", "authors": "D P Bertsekas; J N "}, {"ref_id": "b4", "title": "The tradeoffs of large scale learning", "journal": "", "year": "2008", "authors": "L Bottou; O Bousquet"}, {"ref_id": "b5", "title": "An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision", "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": "2004", "authors": "Y Boykov; V Kolmogorov"}, {"ref_id": "b6", "title": "An improved approximation algorithm for multiway cut", "journal": "", "year": "1998", "authors": "G C\u0203linescu; H Karloff; Y Rabani"}, {"ref_id": "b7", "title": "Exact matrix completion via convex optimization", "journal": "Foundations of Computational Mathematics", "year": "2009", "authors": "E Cand\u00e8s; B Recht"}, {"ref_id": "b8", "title": "MapReduce: simplified data processing on large clusters", "journal": "Communications of the ACM", "year": "2008", "authors": "J Dean; S Ghemawat"}, {"ref_id": "b9", "title": "Optimal distributed online prediction using mini-batches", "journal": "", "year": "2011", "authors": "O Dekel; R Gilad-Bachrach; O Shamir; L Xiao"}, {"ref_id": "b10", "title": "", "journal": "", "year": "", "authors": "A Doan"}, {"ref_id": "b11", "title": "Distributed dual averaging in networks", "journal": "", "year": "2010", "authors": "J Duchi; A Agarwal; M J Wainwright"}, {"ref_id": "b12", "title": "The Future of Computing Performance: Game Over or Next Level. Committee on Sustaining Growth in Computing Performance", "journal": "The National Academies Press", "year": "2011", "authors": "S H Fuller; L I Millett"}, {"ref_id": "b13", "title": "Training linear svms in linear time", "journal": "", "year": "2006", "authors": "T Joachims"}, {"ref_id": "b14", "title": "", "journal": "", "year": "", "authors": "J Langford"}, {"ref_id": "b15", "title": "Slow learners are fast", "journal": "", "year": "2009", "authors": "J Langford; A J Smola; M Zinkevich"}, {"ref_id": "b16", "title": "Practical large-scale optimization for max-norm regularization", "journal": "", "year": "2010", "authors": "J Lee; B Recht; N Srebro; R R Salakhutdinov; J A Tropp"}, {"ref_id": "b17", "title": "Web scale entity resolution using relational evidence", "journal": "", "year": "2011", "authors": "T Lee; Z Wang; H Wang; S Hwang"}, {"ref_id": "b18", "title": "RCV1: A new benchmark collection for text categorization research", "journal": "Journal of Machine Learning Research", "year": "2004", "authors": "D Lewis; Y Yang; T Rose; F Li"}, {"ref_id": "b19", "title": "Analysis of an approximate gradient projection method with applications to the backpropagation algorithm", "journal": "Optimization Methods and Software", "year": "1994", "authors": "Z Q Luo; P Tseng"}, {"ref_id": "b20", "title": "Dremel: Interactive analysis of web-scale datasets", "journal": "", "year": "2010", "authors": "S Melnik; A Gubarev; J J Long; G Romer; S Shivakumar; M Tolton; T Vassilakis"}, {"ref_id": "b21", "title": "Convergence rate of incremental subgradient algorithms", "journal": "Kluwer Academic Publishers", "year": "2000", "authors": "A Nedic; D P Bertsekas"}, {"ref_id": "b22", "title": "Robust stochastic approximation approach to stochastic programming", "journal": "SIAM Journal on Optimization", "year": "2009", "authors": "A Nemirovski; A Juditsky; G Lan; A Shapiro"}, {"ref_id": "b23", "title": "Guaranteed minimum rank solutions of matrix equations via nuclear norm minimization", "journal": "SIAM Review", "year": "2010", "authors": "B Recht; M Fazel; P Parrilo"}, {"ref_id": "b24", "title": "Parallel stochastic gradient algorithms for large-scale matrix completion. Submitted for publication", "journal": "", "year": "2011", "authors": "B Recht; C R\u00e9"}, {"ref_id": "b25", "title": "SVM Optimization: Inverse dependence on training set size", "journal": "", "year": "2008", "authors": "S Shalev-Shwartz; N Srebro"}, {"ref_id": "b26", "title": "Maximum margin matrix factorization", "journal": "", "year": "2004", "authors": "N Srebro; J Rennie; T Jaakkola"}, {"ref_id": "b27", "title": "An incremental gradient(-projection) method with momentum term and adaptive stepsize rule", "journal": "SIAM Joural on Optimization", "year": "1998", "authors": "P Tseng"}, {"ref_id": "b28", "title": "Distributed asynchronous deterministic and stochastic gradient optimization algorithms", "journal": "IEEE Transactions on Automatic Control", "year": "1986", "authors": "J Tsitsiklis; D P Bertsekas; M Athans"}, {"ref_id": "b29", "title": "Parallelized stochastic gradient descent", "journal": "", "year": "2010", "authors": "M Zinkevich; M Weimer; A Smola; L Li"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 :1Figure 1: Example graphs induced by cost function. (a) A sparse SVM induces a hypergraph where each hyperedge corresponds to one example. (b) A matrix completion example induces a bipartite graph between the rows and columns with an edge between two nodes if an entry is revealed. (c) The induced hypergraph in a graph-cut problem is simply the graph whose cuts we aim to find.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "3 )3(2.1), let e \u03b1 denote the components which are non-zero in z \u03b1 and let d u denote the number of training examples which are non-zero in component u (u = 1, 2, . . . , n). Then we can rewrite (2.2) as minimize x \u03b1\u2208E max(1 \u2212 y \u03b1 x T z \u03b1 , 0) + \u03bb Each term in the sum (2.3) depends only on the components of x indexed by the set e \u03b1 .", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Algorithm 11Hogwild! update for individual processors 1: loop 2:", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": ". 3 )3By (5.2), we should pick \u03b3 = \u03d1 2B for \u03d1 \u2208 (0, 1]. Combining this with (5.3) tells us that after k \u2265 2B log(2a 0 / ) \u03d1 c r iterations we will have a k \u2264 . This right off the bat almost gives us a 1/k rate, modulo the log(1/ ) factor.", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 2 :2Figure 2: Comparison of wall clock time across of Hogwild! and RR. Each algorithm is run for 20 epochs and parallelized over 10 cores.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Figure 3 :3Figure 3: Total CPU time versus number of threads for (a) RCV1, (b) Abdomen, and (c) DBLife.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": ". There are 804,414 examples split into 23,149 training and 781,265 test examples, and there are 47,236 features. We swapped the training set and the test set for our experiments to demonstrate the scalability of the parallel multicore algorithms.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "Figure 4 :4Figure 4: Total CPU time versus number of threads for the matrix completion problems (a) Netflix Prize, (b) KDD Cup 2011, and (c) the synthetic Jumbo experiment.", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "Figure 5 :5Figure 5: (a) Speedup for the three matrix completion problems with Hogwild!. In all three cases, massive speedup is achieved via parallelism. (b) The training error at the end of each epoch of SVM training on RCV1 for the averaging algorithm [30]. (c) Speedup achieved over serial method for various levels of delays (measured in nanoseconds).", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "e3). We have E (x j \u2212 x k(j) ) T (G e j (x k(j) ) \u2212 G e j (x j )) \u2212x i ) T (G e j (x k(j) ) \u2212 G e j (x j )) \u03b3|e i |G e i (x k(i) ) T (G e j (x k(j) ) \u2212 G e j (x j )) i \u2229e j =\u2205 \u03b3|e i |G e i (x k(i) ) T (G e j (x k(j) ) \u2212 G e j (x j )) e i \u2229e j =\u2205 \u03b3|e i | G e i (x k(i) ) G e j (x k(j) ) \u2212 G e j (x j ) \u03c1 is defined by (2.6).Here, the third line follows from our definition of the gradient update. The fourth line is tautological: only the edges where e i and e j intersect nontrivially factor into the sum. The subsequent inequality is Cauchy-Schwarz, and the following line follows from(4.4).By substituting (A.4), (A.7), and (A.8) into (A.3), we obtain the following bound:a j+1 \u2264 a j \u2212 c\u03b3 a k(j) + 1 2 E[ x j \u2212 x k(j) 2 ] + M 2 \u03b3 2 2(\u2126 + 2\u03c4 \u03c1 + 4\u2126\u03c1\u03c4 ) . (A.9)", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_10", "figure_caption": "e i and v i are both independent of x k(j) , we can proceed to bound\u03b3|e i |G e i (x k(i) ) T P v i (x k(j) \u2212 x ) \u03b3\u2126M P v i (x k(j) \u2212 x ) i ,v i P e i ,v i (x k(j) \u2212 x ) 2 | e [\u00aci]", "figure_data": ""}, {"figure_label": "21", "figure_type": "figure", "figure_id": "fig_11", "figure_caption": "2 =\u221a 1 +21C(\u03c4, \u03c1, \u2206, \u2126) M 2 \u03b3 2c .x) 2 \u2264 4 + 2x for all x \u2265 0. Substituting this value of \u03b3 into (5.3), we see thatk \u2265 LM 2 log(LD 0 / ) c 2 \u2022 C(\u03c4, \u03c1, \u2206, \u2126) 1 \u2212 \u03b4(\u03c4, \u03c1, \u2206, \u2126) (A.14)iterations suffice to achieve a k \u2264 /L. Now observe that C(\u03c4, \u03c1, \u2206, \u2126) 1 \u2212 \u03b4(\u03c4, \u03c1, \u2206, \u2126)", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "X \u2286 R n \u2192 R of the form f (x) = e\u2208E f e (x e ) .", "formula_coordinates": [2.0, 262.21, 552.31, 170.48, 49.74]}, {"formula_id": "formula_1", "formula_text": "minimize x \u03b1\u2208E max(1 \u2212 y \u03b1 x T z \u03b1 , 0) + \u03bb x 2 2 , (2.2)", "formula_coordinates": [3.0, 201.45, 346.39, 338.55, 24.76]}, {"formula_id": "formula_2", "formula_text": "minimize (L,R) (u,v)\u2208E (L u R * v \u2212 Z uv ) 2 + \u00b5 2 L 2 F + \u00b5 2 R 2 F , (2.4)", "formula_coordinates": [3.0, 167.95, 579.08, 372.05, 25.81]}, {"formula_id": "formula_3", "formula_text": "minimize (L,R) (u,v)\u2208E (L u R * v \u2212 Z uv ) 2 + \u00b5 2|E u\u2212 | L u 2 F + \u00b5 2|E \u2212v | R v 2 F", "formula_coordinates": [3.0, 139.31, 647.47, 324.44, 25.72]}, {"formula_id": "formula_4", "formula_text": "S D = {\u03b6 \u2208 R D : \u03b6 v \u2265 0 D v=1 \u03b6 v = 1}.", "formula_coordinates": [4.0, 72.0, 153.78, 196.68, 15.24]}, {"formula_id": "formula_5", "formula_text": "minimize x (u,v)\u2208E w uv x u \u2212 x v 1 subject to x v \u2208 S D for v = 1, . . . , n .", "formula_coordinates": [4.0, 131.46, 222.98, 349.08, 22.79]}, {"formula_id": "formula_6", "formula_text": "\u2126 := max e\u2208E |e|, \u2206 := max 1\u2264v\u2264n |{e \u2208 E : v \u2208 e}| |E| , \u03c1 := max e\u2208E |{\u00ea \u2208 E :\u00ea \u2229 e = \u2205}| |E| . (2.6)", "formula_coordinates": [4.0, 89.36, 317.75, 450.64, 24.43]}, {"formula_id": "formula_7", "formula_text": "x v \u2190 x v + a", "formula_coordinates": [4.0, 276.82, 677.21, 58.35, 10.63]}, {"formula_id": "formula_8", "formula_text": "4: for v \u2208 e do x v \u2190 x v \u2212 \u03b3b T", "formula_coordinates": [5.0, 77.92, 129.87, 155.5, 12.59]}, {"formula_id": "formula_9", "formula_text": "|E| \u22121 G e (x) \u2208 \u2202f e (x).", "formula_coordinates": [5.0, 255.48, 346.78, 101.03, 13.13]}, {"formula_id": "formula_10", "formula_text": "E[G e (x e )] \u2208 \u2202f (x) .", "formula_coordinates": [5.0, 260.35, 416.73, 91.3, 10.63]}, {"formula_id": "formula_11", "formula_text": "x v \u2190 x v \u2212 \u03b3b T v G e (x), for each v \u2208 e (3.1)", "formula_coordinates": [5.0, 211.07, 468.13, 328.93, 14.19]}, {"formula_id": "formula_12", "formula_text": "x j .", "formula_coordinates": [5.0, 470.61, 585.65, 13.65, 10.63]}, {"formula_id": "formula_13", "formula_text": "x v \u2190 x v \u2212 \u03b3|e|b T v G e (x)", "formula_coordinates": [6.0, 251.5, 162.06, 108.99, 14.19]}, {"formula_id": "formula_14", "formula_text": "x \u2190 x \u2212 \u03b3|e|P T v G e (x) . (4.1)", "formula_coordinates": [6.0, 252.09, 213.21, 287.91, 14.19]}, {"formula_id": "formula_15", "formula_text": "\u2207f (x ) \u2212 \u2207f (x) \u2264 L x \u2212 x , \u2200 x , x \u2208 X. (4.2)", "formula_coordinates": [6.0, 204.6, 517.0, 335.41, 9.57]}, {"formula_id": "formula_16", "formula_text": "f (x ) \u2265 f (x) + (x \u2212 x) T \u2207f (x) + c 2 x \u2212 x 2 , for all x , x \u2208 X. (4.3)", "formula_coordinates": [6.0, 155.15, 559.37, 384.85, 24.43]}, {"formula_id": "formula_17", "formula_text": "\u03b3 = \u03d1 c 2LM 2 \u2126 1 + 6\u03c1\u03c4 + 4\u03c4 2 \u2126\u2206 1/2 .", "formula_coordinates": [7.0, 219.65, 111.18, 172.7, 25.02]}, {"formula_id": "formula_18", "formula_text": "k \u2265 2LM 2 \u2126 1 + 6\u03c4 \u03c1 + 6\u03c4 2 \u2126\u2206 1/2 log(LD 0 / ) c 2 \u03d1 . (4.6)", "formula_coordinates": [7.0, 192.03, 165.49, 347.97, 27.08]}, {"formula_id": "formula_19", "formula_text": "E[f (x k ) \u2212 f ] \u2264 .", "formula_coordinates": [7.0, 297.39, 200.33, 85.41, 10.77]}, {"formula_id": "formula_20", "formula_text": "a j = 1 2 E[ x j \u2212 x 2 ] satisfies a recursion of the form a j \u2264 (1 \u2212 c r \u03b3)(a j+1 \u2212 a \u221e ) + a \u221e", "formula_coordinates": [7.0, 72.0, 285.97, 421.66, 15.05]}, {"formula_id": "formula_21", "formula_text": "then follows because E[f (x k ) \u2212 f (x )] \u2264 La k since the gradient of f is Lipschitz. A full proof is provided in the appendix.", "formula_coordinates": [7.0, 72.0, 356.01, 468.0, 23.12]}, {"formula_id": "formula_22", "formula_text": "a k+1 \u2264 (1 \u2212 c r \u03b3)(a k \u2212 a \u221e (\u03b3)) + a \u221e (\u03b3) (5.1)", "formula_coordinates": [7.0, 213.98, 639.24, 326.01, 10.77]}, {"formula_id": "formula_23", "formula_text": "a k \u2264 (1 \u2212 c r \u03b3) k (a 0 \u2212 a \u221e (\u03b3)) + a \u221e (\u03b3) .", "formula_coordinates": [8.0, 214.6, 151.72, 182.8, 13.27]}, {"formula_id": "formula_24", "formula_text": "\u03b3 \u2264 2B . (5.2)", "formula_coordinates": [8.0, 284.84, 218.42, 255.16, 17.05]}, {"formula_id": "formula_25", "formula_text": "(1 \u2212 \u03b3c r ) k a 0 \u2264 /2 which holds if k \u2265 log(2a 0 / ) \u03b3c r . (5", "formula_coordinates": [8.0, 72.0, 255.97, 454.55, 57.72]}, {"formula_id": "formula_26", "formula_text": "k \u2265 \u03d1 \u22121 log a 0 c r \u03d1B (5.4)", "formula_coordinates": [8.0, 260.37, 526.84, 279.63, 24.43]}, {"formula_id": "formula_27", "formula_text": "log \u03b2 (a 0 / ) k=1 log(2/\u03b2) \u03d1\u03b2 k = log(2/\u03b2) \u03d1 log \u03b2 (a 0 / ) k=1 \u03b2 \u2212k = log(2/\u03b2) \u03d1 \u03b2 \u22121 (a 0 / ) \u2212 1 \u03b2 \u22121 \u2212 1 \u2264 a 0 \u03d1 log(2/\u03b2) 1 \u2212 \u03b2 \u2264 2B c r log(2/\u03b2) 1 \u2212 \u03b2 .", "formula_coordinates": [9.0, 202.65, 98.09, 207.33, 125.19]}, {"formula_id": "formula_28", "formula_text": "k \u2265 \u03d1 \u22121 log a 0 c r \u03d1B + 2B c r log(2/\u03b2) 1 \u2212 \u03b2 are sufficient to guarantee that a k \u2264 .", "formula_coordinates": [9.0, 72.0, 281.91, 314.75, 46.11]}, {"formula_id": "formula_29", "formula_text": "\u2264 2 log(2/\u03b2) 1 \u2212 \u03b2 \u2022 B c r \u2022 1 k \u2212 \u03d1 \u22121 log a 0 cr \u03d1B .", "formula_coordinates": [9.0, 219.83, 353.53, 179.79, 28.21]}, {"formula_id": "formula_30", "formula_text": "a k+1 \u2264 (1 \u2212 2c\u03b3 k )a k + 1 2 \u03b3 2 k M 2 .", "formula_coordinates": [9.0, 232.17, 469.47, 147.65, 15.26]}, {"formula_id": "formula_31", "formula_text": "\u03b3 k = \u0398 2ck with \u0398 > 1 yields a bound a k \u2264 1 k max M 2 c 2 \u2022 \u0398 2 4\u0398 \u2212 4 , D 0", "formula_coordinates": [9.0, 228.67, 505.48, 295.74, 50.36]}, {"formula_id": "formula_32", "formula_text": "a k \u2264 log(2/\u03b2) 4(1 \u2212 \u03b2) \u2022 M 2 c 2 \u2022 1 k \u2212 \u03d1 \u22121 log 4D 0 c 2 \u03d1M 2 .", "formula_coordinates": [9.0, 204.31, 587.54, 203.37, 33.72]}, {"formula_id": "formula_33", "formula_text": "4(1 \u2212 \u03b2)", "formula_coordinates": [9.0, 286.26, 685.41, 39.47, 9.57]}, {"formula_id": "formula_34", "formula_text": "x j+1 = x j \u2212 \u03b3|e j |P v j G e j (x k(j) ) .", "formula_coordinates": [17.0, 231.06, 187.09, 149.89, 11.46]}, {"formula_id": "formula_35", "formula_text": "x j+1 \u2212 x 2 2 = 1 2 x j \u2212 x 2 2 \u2212 \u03b3|e j |(x j \u2212 x ) T P v j G e j (x k(j) ) + 1 2 \u03b3 2 |e j | 2 P v j G e j (x k(j) ) 2 = 1 2 x j \u2212 x 2 2 \u2212 \u03b3|e j |(x j \u2212 x k(j) ) T P v j G e j (x j ) \u2212 \u03b3|e j |(x j \u2212 x k(j) ) T P v j (G e j (x k(j) ) \u2212 G e j (x j )) \u2212 \u03b3|e j |(x k(j) \u2212 x ) T P v j G e j (x k(j) ) + 1 2 \u03b3 2 |e j | 2 P v j G e j (x k(j) ) 2 Let a j = 1 2 E[ x j \u2212 x 2 2 ]", "formula_coordinates": [17.0, 72.0, 230.18, 435.45, 143.53]}, {"formula_id": "formula_36", "formula_text": "a j+1 \u2264 a j \u2212 \u03b3E[(x j \u2212 x k(j) ) T G e j (x j )] \u2212 \u03b3E[(x j \u2212 x k(j) ) T (G e j (x k(j) ) \u2212 G e j (x j ))] \u2212 \u03b3E[(x k(j) \u2212 x ) T G e j (x k(j) )] + 1 2 \u03b3 2 \u2126M 2 . (A.3)", "formula_coordinates": [17.0, 107.19, 382.85, 432.81, 42.16]}, {"formula_id": "formula_37", "formula_text": "E[|e j |P v j G e j (x i ) T \u03b6(x 1 , . . . , x j )] = E E |e j |P v j G e j (x i ) T \u03b6(x 1 , . . . , x j ) | e 1 , . . . , e j , v 1 , . . . , v j\u22121 = E G e j (x i ) T \u03b6(x 1 , . . . , x j ) .", "formula_coordinates": [17.0, 83.12, 469.19, 436.16, 31.96]}, {"formula_id": "formula_38", "formula_text": "e [i] := (e 1 , e 2 , . . . , e i , v 1 , v 2 , . . . , v i ),", "formula_coordinates": [17.0, 224.96, 535.26, 162.08, 11.22]}, {"formula_id": "formula_39", "formula_text": "E (x k(j) \u2212 x ) T G e j (x k(j) ) = E E (x k(j) \u2212 x ) T G e j (x k(j) )|e [k(j)\u22121] = E (x k(j) \u2212 x ) T E G e j (x k(j) )|e [k(j)\u22121] = E (x k(j) \u2212 x ) T \u2207f (x k(j) ) ,", "formula_coordinates": [17.0, 201.26, 621.51, 198.07, 68.16]}, {"formula_id": "formula_40", "formula_text": "E[(x j \u2212 x k(j) ) T G e j (x j )] = E E[(x j \u2212 x k(j) ) T G e j (x j ) | e [j\u22121] ] = E (x j \u2212 x k(j) ) T E[G e j (x j ) | e [j\u22121] ] = E[(x j \u2212 x k(j) ) T \u2207f (x j )] \u2265 E[f (x j ) \u2212 f (x k(j) )] + c 2 E[ x j \u2212 x k(j) 2 ] (A.5)", "formula_coordinates": [18.0, 151.11, 146.54, 388.9, 76.12]}, {"formula_id": "formula_41", "formula_text": "E[f (x k(j) ) \u2212 f (x j )] = j\u22121 i=k(j) E[f (x i ) \u2212 f (x i+1 )] = j\u22121 i=k(j) e\u2208E E[f e (x i ) \u2212 f e (x i+1 )] \u2264 \u03b3 |E| j\u22121 i=k(j) e\u2208E E[G e (x i ) T G e i (x i )] \u2264 \u03b3\u03c4 \u03c1M 2 . (A.6)", "formula_coordinates": [18.0, 179.83, 271.31, 360.17, 135.16]}, {"formula_id": "formula_42", "formula_text": "f e (x i ) \u2212 f e (x i+1 ) \u2264 1 |E| G e (x i ) T (x i \u2212 x i+1 ) = \u03b3 |E| G e (x i ) T G e i (x i )", "formula_coordinates": [18.0, 153.6, 442.52, 304.8, 24.43]}, {"formula_id": "formula_43", "formula_text": "E[(x j \u2212 x k(j) ) T G e j (x j )] \u2265 \u2212\u03b3\u03c4 \u03c1M 2 + c 2 E[ x j \u2212 x k(j) 2 ] . (A.7)", "formula_coordinates": [18.0, 171.79, 499.62, 368.21, 24.43]}, {"formula_id": "formula_44", "formula_text": "a k(j) + 1 2 E[ x j \u2212 x k(j) 2 = a j \u2212 E (x j \u2212 x k(j) ) T (x k(j) \u2212 x ) = a j \u2212 E \uf8ee \uf8f0 j\u22121 i=k(j) (x i+1 \u2212 x i ) T (x k(j) \u2212 x ) \uf8f9 \uf8fb = a j \u2212 E \uf8ee \uf8f0 j\u22121 i=k(j) \u03b3|e i |G e i (x k(i) ) T P v i (x k(j) \u2212 x ) \uf8f9 \uf8fb .", "formula_coordinates": [19.0, 130.71, 537.92, 350.58, 99.11]}, {"formula_id": "formula_45", "formula_text": "T P v i (x k(j) \u2212 x ) | e [\u00aci] 1/2 =\u03b3\u2126M j\u22121 i=k(j) E (x k(j) \u2212 x ) T E e,v [P v ](x k(j) \u2212 x ) 1/2 \u2264\u03c4 \u03b3\u2126M E (x k(j) \u2212 x ) T E e,v [P v ](x k(j) \u2212 x ) 1/2 \u2264\u03c4 \u03b3\u2126M \u2206 1/2 E[ x k(j) \u2212 x 2 ] \u2264\u03c4 \u03b3\u2126M \u2206 1/2 (E[ x j \u2212 x 2 ] + \u03c4 \u03b3\u2126M ) \u2264\u03c4 \u03b3\u2126M \u2206 1/2 ( \u221a 2a 1/2 j + \u03c4 \u03b3\u2126M ) ,", "formula_coordinates": [20.0, 155.55, 232.98, 295.25, 152.13]}, {"formula_id": "formula_46", "formula_text": "a j+1 \u2264 (1 \u2212 c\u03b3)a j + \u03b3 2 \u221a 2c\u2126M \u03c4 \u2206 1/2 a 1/2 j + 1 2 M 2 \u03b3 2 Q (A.10)", "formula_coordinates": [20.0, 171.81, 452.68, 368.19, 26.61]}, {"formula_id": "formula_47", "formula_text": "Q = \u2126 + 2\u03c4 \u03c1 + 4\u2126\u03c1\u03c4 + 2\u03c4 2 \u2126 2 \u2206 1/2 .", "formula_coordinates": [20.0, 221.47, 497.86, 169.07, 12.06]}, {"formula_id": "formula_48", "formula_text": "a \u221e = (1 \u2212 c\u03b3)a \u221e + \u03b3 2 \u221a 2c\u2126M \u03c4 \u2206 1/2 a 1/2 \u221e + M 2 \u03b3 2 2 Q . (A.11)", "formula_coordinates": [20.0, 172.94, 578.37, 367.06, 26.61]}, {"formula_id": "formula_49", "formula_text": "a \u221e = M 2 \u03b3 2 2 \u2126\u03c4 \u2206 1/2 + \u2126 2 \u03c4 2 \u2206 + Q c\u03b3 2 \u2264 M 2 \u03b3 2c", "formula_coordinates": [20.0, 160.42, 631.28, 195.79, 66.42]}, {"formula_id": "formula_50", "formula_text": "1 + 1 + Q \u2126 2 \u03c4 2 \u2206 2 1 \u2212 1 1+ 1+ Q \u2126 2 \u03c4 2 \u2206 = \u2126 2 \u03c4 2 \u2206 \u2022 1 + 1 + Q \u2126 2 \u03c4 2 \u2206 2 1 + Q \u2126 2 \u03c4 2 \u2206 \u2264 8\u2126 2 \u03c4 2 \u2206 + 2Q = 8\u2126 2 \u03c4 2 \u2206 + 2\u2126 + 4\u03c4 \u03c1 + 8\u2126\u03c1\u03c4 + 4\u03c4 2 \u2126 2 \u2206 1/2 \u2264 2\u2126(1 + 6\u03c4 \u03c1 + 6\u03c4 2 \u2126\u2206 1/2 ) .", "formula_coordinates": [22.0, 242.54, 158.84, 208.75, 161.67]}, {"formula_id": "formula_51", "formula_text": "1 + \u221a 1 + x 3 \u221a 1 + x \u2264 8 + 2x", "formula_coordinates": [22.0, 254.67, 351.47, 108.85, 34.45]}], "doi": ""}