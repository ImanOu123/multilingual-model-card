{"title": "PiCO+: Contrastive Label Disambiguation for Robust Partial Label Learning", "authors": "Haobo Wang; Ruixuan Xiao; Yixuan Li; Lei Feng; Gang Niu; Gang Chen; Junbo Zhao", "pub_date": "", "abstract": "Partial label learning (PLL) is an important problem that allows each training example to be labeled with a coarse candidate set, which well suits many real-world data annotation scenarios with label ambiguity. Despite the promise, the performance of PLL often lags behind the supervised counterpart. In this work, we bridge the gap by addressing two key research challenges in PLL-representation learning and label disambiguation-in one coherent framework. Specifically, our proposed framework PiCO consists of a contrastive learning module along with a novel class prototype-based label disambiguation algorithm. PiCO produces closely aligned representations for examples from the same classes and facilitates label disambiguation. Theoretically, we show that these two components are mutually beneficial, and can be rigorously justified from an expectation-maximization (EM) algorithm perspective. Moreover, we study a challenging yet practical noisy partial label learning setup, where the ground-truth may not be included in the candidate set. To remedy this problem, we present an extension PiCO+ that performs distance-based clean sample selection and learns robust classifiers by a semi-supervised contrastive learning algorithm. Extensive experiments demonstrate that our proposed methods significantly outperform the current state-of-the-art approaches in standard and noisy PLL tasks and even achieve comparable results to fully supervised learning.", "sections": [{"heading": "INTRODUCTION", "text": "T HE training of modern deep neural networks typically requires massive labeled data, which imposes formidable obstacles in data collection. Of a particular challenge, data annotation in the real-world can naturally be subject to inherent label ambiguity and noise. For example, as shown in Figure 1, identifying an Alaskan Malamute from a Siberian Husky can be difficult for a human annotator. The issue of labeling ambiguity is prevalent yet often overlooked in many applications, such as web mining [1] and automatic image annotation [2]. This gives rise to the importance of partial label learning (PLL) [3], [4], where each training example is equipped with a set of candidate labels instead of the exact ground-truth label. This stands in contrast to its supervised counterpart where one label must be chosen as the \"gold\". Arguably, the PLL problem is deemed more common and practical in various situations due to its relatively lower cost to annotations.\nDespite the promise, a core challenge in PLL is label disambiguation, i.e., identifying the ground-truth label from the candidate label set. Existing methods typically require a\n\u2022 Haobo Wang, Ruixuan Xiao, Gang Chen and Junbo Zhao are with Key Lab of Intelligent Computing Based Big Data of Zhejiang Province, Zhejiang University, Hangzhou, China, 310027. E-mail:{wanghaobo, xiaoruixuan, cg, j.zhao}@zju.edu.cn.\n\u2022 Yixuan Li is with Department of Computer Sciences, University of WisconsinMadison, Madison, WI, United States, 53706. E-mail: sharonli@cs.wisc.edu.\n\u2022 Lei Feng is with the College of Computer Science, Chongqing University, Chongqing, China, 400044. E-mail: lfeng@cqu.edu.cn.\n\u2022 Gang Niu is with RIKEN Center for Advanced Intelligence Project, Tokyo, Japan. E-mail: gang.niu.ml@gmail.com.\n\u2022 Junbo Zhao is the corresponding author. good feature representation [5], [6], [7], and operate under the assumption that data points closer in the feature space are more likely to share the same ground-truth label. However, the reliance on representations has led to a non-trivial dilemma-the inherent label uncertainty can undesirably manifest in the representation learning process-the quality of which may, in turn, prevent effective label disambiguation. To date, few efforts have been made to resolve this. This paper bridges the gap by reconciling the intrinsic tension between the two highly dependent problemsrepresentation learning and label disambiguation-in one coherent and synergistic framework. Our framework, Partial label learning with COntrastive label disambiguation (dubbed PiCO), produces closely aligned representations for examples from the same classes and facilitates label disambiguation. Specifically, PiCO encapsulates two key components. First, we leverage contrastive learning (CL) [8] to partial label learning, which is unexplored in previous PLL literature. To mitigate the key challenge of constructing positive pairs, we employ the classifier's output and generate pseudo positive pairs for contrastive comparison arXiv:2201.08984v3 [cs.LG] 30 Nov 2022 (Section 3.1). Second, based on the learned embeddings, we propose a novel prototype-based label disambiguation strategy (Section 3.2). Key to our method, we gradually update the pseudo target for classification, based on the closest class prototype. By alternating the two steps above, PiCO converges to a solution with a highly distinguishable representation for accurate classification. Empirically, PiCO establishes state-of-the-art performance on three benchmark datasets, outperforming the baselines by a significant margin (Section 5) and obtains results that are competitive with fully supervised learning.\nTheoretically, we demonstrate that our contrastive representation learning and prototype-based label disambiguation are mutually beneficial, and can be rigorously interpreted from an Expectation-Maximization (EM) algorithm perspective (Section 6). First, the refined pseudo labeling improves contrastive learning by selecting pseudo positive examples accurately. This can be analogous to the E-step, where we utilize the classifier's output to assign each data example to one label-specific cluster. Second, better contrastive performance in turn improves the quality of representations and thus the effectiveness of label disambiguation. This can be reasoned from an M-step perspective, where the contrastive loss partially maximizes the likelihood by clustering similar data examples. Finally, the training data will be mapped to a mixture of von Mises-Fisher distributions on the unit hypersphere, which facilitates label disambiguation by using the component-specific label.\nWe have presented preliminary results of this work in [9]. While the earlier version focuses on the standard PLL setup, it holds a strong assumption that the gold labels are ensured to be included in the candidate sets. However, lacking domain knowledge, it is likely the annotators take the wrong set of labels as the candidates and dismiss the true one. Lv et al. [10] formalize this problem as noisy partial label learning (noisy PLL). But, they focus on analyzing the theoretical robustness of existing PLL methods instead of providing new solutions. Experimentally, we find that current best-performing PLL algorithms, including PiCO, display degenerated performance in the noisy PLL setup (Section 5.3), e.g. the accuracy of PRODEN drops \u221210.62% on CIFAR-10 with 20% wrong candidate sets. The main reason is that the label disambiguation procedure of current PLL methods is restricted to the candidate labels, which causes severe overfitting on wrong labels.\nIn this work, we propose PiCO+, an extension of PiCO, to tackle the noisy PLL problem. PiCO+ additionally incorporates two mechanisms. First, we present a novel distancebased clean sample detection technique that chooses nearprototype examples as clean. Second, to handle the remaining noisy examples, we develop a semi-supervised contrastive learning framework that generalizes the two PiCO modules by (i)-contrastive learning: construct the positive set by noisy prediction and nearest neighbor embeddings; (ii)label disambiguation: guess the prototype-based soft target for noisy samples. Through extensive experiments, PiCO+ exhibits significant improvement to state-of-the-art PLL approaches on noisy PLL datasets.\nOur main contributions are summarized as follows: 1 (Methodology). To the best of our knowledge, our paper pioneers the exploration of contrastive learning for partial label learning and proposes a novel framework termed PiCO. As an integral part of our algorithm, we also introduce a new prototype-based label disambiguation mechanism, that leverages the contrastively learned embeddings.\n2 (Practicality). Additionally, we propose PiCO+, an extension of PiCO, that targets to mitigate noisy candidate label sets. It further integrates a distance-based clean sample detection mechanism along with a semi-supervised contrastive learning module. We believe our work makes a serious attempt at improving the practicality of PLL in open-world environments.\n3 (Experiments). Empirically, our proposed PiCO framework establishes the state-of-the-art performance on three PLL tasks. Moreover, we make the first attempt to conduct experiments on fine-grained classification datasets, where we show classification performance improvement by up to 9.61% compared with the best baseline on the CUB-200 dataset. We also evaluate our new PiCO+ framework on the noisy variants of these datasets, where PiCO+ outperforms the best baseline by up to 12.52% on the noisy PLL version of the CIFAR-10 dataset.\n4 (Theory). We theoretically interpret our framework from the expectation-maximization perspective. Our derivation is also generalizable to other CL methods and shows the alignment property in CL [11] mathematically equals the M-step in center-based clustering algorithms.", "publication_ref": ["b0", "b1", "b2", "b3", "b4", "b5", "b6", "b7", "b8", "b9", "b10"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "BACKGROUND", "text": "The problem of partial label learning (PLL) is defined using the following setup. Let X be the input space, and Y = {1, 2, ..., C} be the output label space. We consider a training dataset D = {(x i , Y i )} n i=1 , where each tuple comprises of an image x i \u2208 X and a candidate label set Y i \u2282 Y. Identical to the supervised learning setup, the goal of PLL is to obtain a functional mapping that predicts the one true label associated with the input. Yet differently, the PLL setup bears significantly more uncertainty in the label space. A basic assumption of PLL is that the groundtruth label y i is concealed in its candidate set, i.e., y i \u2208 Y i , and is invisible to the learner. For this reason, the learning process can suffer from inherent ambiguity, compared with the supervised learning task with explicit ground-truth.\nThe key challenge of PLL is to identify the groundtruth label from the candidate label set. During training, we assign each image x i a normalized vector s i \u2208 [0, 1] C as the pseudo target, whose entries denote the probability of labels being the ground-truth. The total probability mass of 1 is allocated among candidate labels in Y i . Note that s i will be updated during the training procedure. Ideally, s i should put more probability mass on the (unknown) ground-truth label y i over the course of training. We train a classifier f : X \u2192 [0, 1] C using cross-entropy loss, with s i being the target prediction. The per-sample loss is given by:\nL cls (f ; x i , Y i ) = C j=1 \u2212s i,j log(f j (x i )) s.t. j\u2208Yi s i,j = 1 and s i,j = 0, \u2200j / \u2208 Y i ,(1)\nwhere j denotes the indices of labels. s i,j denotes the jth pseudo target of x i . Here f is the softmax output of the networks and we denote f j as its j-th entry. In the remainder of this paper, we omit the sample index i when the context is clear. We proceed by describing our proposed framework.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "THE PICO FRAMEWORK", "text": "In this section, we describe our novel Partial label learning with COntrastive label disambiguation (PiCO) framework in detail. In a nutshell, PiCO comprises two key components tackling the representation quality (Section 3.1) and label ambiguity respectively (Section 3.2). The two components systematically work as a whole and reciprocate each other. We further rigorously provide a theoretical interpretation of PiCO from an EM perspective in Section 6.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Contrastive Representation Learning for PLL", "text": "The uncertainty in the label space posits a unique obstacle for learning effective representations. In PiCO, we couple the classification loss in Eq. (1) with a contrastive term that facilitates a clustering effect in the embedding space. While contrastive learning has been extensively studied in recent literature, it remains untapped in the domain of PLL. The main challenge lies in the construction of a positive sample set. In conventional supervised CL frameworks, the positive sample pairs can be easily drawn according to the groundtruth labels [8]. However, this is not straightforward in the setting of PLL. Training Objective. To begin with, we describe the standard contrastive loss term. We adopt the most popular setups by closely following MoCo [12] and SupCon [8]. Given each sample (x, Y ), we generate two views-a query view and a key view-by way of randomized data augmentation Aug(x). The two images are then fed into a query network g(\u2022) and a key network g (\u2022), yielding a pair of L 2 -normalized embeddings q = g(Aug q (x)) and k = g (Aug k (x)). In implementations, the query network shares the same convolutional blocks as the classifier, followed by a prediction head (see Figure 2). Following MoCo, the key network uses a momentum update with the query network. We additionally maintain a queue storing the most current key embeddings k, and we update the queue chronologically. To this end, we have the following contrastive embedding pool:\nA = B q \u222a B k \u222a queue,(2)\nwhere B q and B k are vectorial embeddings corresponding to the query and key views of the current mini-batch. Given an example x, the per-sample contrastive loss is defined by contrasting its query embedding with the remainder of the pool A,\nL cont (g; x, \u03c4, A) = \u2212 1 |P (x)| k+\u2208P (x) log exp(q k + /\u03c4 ) k \u2208A(x) exp(q k /\u03c4 ) ,(3)\nwhere P (x) is the positive set and A(x) = A\\{q}. \u03c4 \u2265 0 is the temperature.\nPositive Set Selection. As mentioned earlier, the crucial challenge is how to construct the positive set P (x). We propose utilizing the predicted label\u1ef9 = arg max j\u2208Y f j (Aug q (x)) from the classifier. Note that we restrict the predicted label to be in the candidate set Y . The positive examples are then selected as follows,\nP (x) = {k |k \u2208 A(x),\u1ef9 =\u1ef9}.(4)\nwhere\u1ef9 is the predicted label for the corresponding training example of k . For computational efficiency, we also maintain a label queue to store past predictions. In other words, we define the positive set of x to be those examples carrying the same approximated label prediction\u1ef9. Despite its simplicity, we show that our selection strategy can be theoretically justified (Section 6) and also lead to superior empirical results (Section 5). Note that more sophisticated selection strategies can be explored, for which we discuss in Appendix B.3. Putting it all together, we jointly train the classifier as well as the contrastive network. The overall loss function is:\nL pico = L cls + \u03bbL cont .(5)\nStill, our goal of learning high-quality representation by CL relies on accurate classifier prediction for positive set selection, which remains unsolved in the presence of label ambiguity. To this end, we further propose a novel label disambiguation mechanism based on contrastive embeddings and show that these two components are mutually beneficial.", "publication_ref": ["b7", "b11", "b7"], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "Prototype-based Label Disambiguation", "text": "As we mentioned (and later theoretically prove in Section 6), the contrastive loss poses a clustering effect in the embedding space. As a collaborative algorithm, we introduce our novel prototype-based label disambiguation strategy. Importantly, we keep a prototype embedding vector \u00b5 c corresponding to each class c \u2208 {1, 2, ..., C}, which can be deemed as a set of representative embedding vectors. Categorically, a naive version of the pseudo target assignment is to find the nearest prototype of the current embedding vector. Notably this primitive resembles a clustering step. We additionally soften this hard label assignment version by using a moving-average style formula. To this end, we may posit intuitively that the employment of the prototype builds a connection with the clustering effect in the embedding space brought by the contrastive term (Section 3.1). We provide a more rigorous justification in Section 6. Pseudo Target Updating. We propose a softened and moving-average style strategy to update the pseudo targets. Specifically, we first initialize the pseudo targets with a uniform distribution, s j = 1 |Y | I(j \u2208 Y ). We then iteratively update it by the following moving-average mechanism,\ns = \u03c6s + (1 \u2212 \u03c6)z, z c =\n1 if c = arg max j\u2208Y q \u00b5 j , 0 else (6) where \u03c6 \u2208 (0, 1) is a positive constant, and \u00b5 j is a prototype corresponding to the j-th class. The intuition is that fitting uniform pseudo targets results in a good initialization for the classifier since the contrastive embeddings are less distinguishable at the beginning. The moving-average style strategy then smoothly updates the pseudo targets towards the correct ones, and meanwhile ensures stable dynamics of training; see Appendix B.1. With more rigorous validation provided later in Section 6, we provide an explanation for the prototype as follows: (i)-for a given input x, the closest prototype is indicative of its ground-truth class label. At each step, s has the tendency to slightly move toward the one-hot distribution defined by z based on Eq. (6); (ii)-if an example consistently points to one prototype, the pseudo target s can converge (almost) to a one-hot vector with the least ambiguity.\nPrototype Updating. The most canonical way to update the prototype embeddings is to compute it in every iteration of training. However, this would extract a heavy computational toll and in turn cause unbearable training latency. As a result, we update the class-conditional prototype vector similarly in a moving-average style:\n\u00b5 c = Normalize(\u03b3\u00b5 c + (1 \u2212 \u03b3)q), if c = arg max j\u2208Y f j (Aug q (x))),(7)\nwhere the momentum prototype \u00b5 c of class c is defined by the moving-average of the normalized query embeddings Algorithm 1: Pseudo-code of PiCO (one epoch). \nBq = {qi = g(Aug q (xi))|xi \u2208 B} 5 B k = {ki = g (Aug k (xi))|xi \u2208 B} 6 A = Bq \u222a B k \u222a queue 7 for xi \u2208 B do // classifier prediction 8\u1ef9i = arg maxj\u2208Y i f j (Aug q (xi))\n// momentum prototype updating q whose predicted class conforms to c. \u03b3 is a tunable hyperparameter.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Synergy between Contrastive Learning and Label Disambiguation", "text": "While seemingly separated from each other, the two key components of PiCO work in a collaborative fashion. First, as the contrastive term favorably manifests a clustering effect in the embedding space, the label disambiguation module further leverages via setting more precise prototypes. Second, a set of well-polished label disambiguation results may, in turn, reciprocate the positive set construction which serves as a crucial part in the contrastive learning stage. The entire training process converges when the two components perform satisfactorily. We further rigorously draw a resemblance of PiCO with a classical EM-style clustering algorithm in Section 6. Our experiments, particularly the ablation study displayed in Section 5.2.2, further justify the mutual dependency of the synergy between the two components. The pseudo-code of our complete algorithm is shown in Algorithm 1.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "PICO+ FOR NOISY PARTIAL LABELS", "text": "In this section, we investigate a more practical setup called noisy partial label learning [10], where the true label potentially lies outside the candidate set, i.e., y i / \u2208 Y i . Empirically, we observe that the current PLL methods, including PiCO, exhibit a significant performance drop on noisy PLL datasets (Section 5.3). One main reason is that these methods mostly rely on a within-set pseudo-label updating step, but the noisy candidate sets in noisy PLL can mislead them towards overfitting on a wrong label.\nTo this end, we propose PiCO+, an extension of PiCO, which learns robust classifiers from noisy partial labels. First, we introduce a distance-based sample selection mechanism that detects clean examples whose candidate sets contain the ground-truth labels. Then, we develop a semisupervised contrastive PLL framework to handle data with noisy candidates. In what follows, we elaborate on our novel PiCO+ framework in detail.", "publication_ref": ["b9"], "figure_ref": [], "table_ref": []}, {"heading": "Distance-based Clean Example Detection", "text": "To remedy overfitting on noisy candidates, we would like to select those reliable candidates, which contain the true labels, to run the PiCO method. In the noisy label learning regime, a widely-adopted strategy is to employ the smallloss selection criterion [13], which is based on the observation that noisy examples typically demonstrate a large loss. However, in the noisy PLL problem, the loss values are less informative since examples with more candidate labels can also incur a larger loss, even if the candidate sets are reliable.\nTo address this problem, we propose a distance-based selection mechanism as follows,\nD clean = {(x i , Y i )|q i \u00b5\u1ef9 i > \u03ba \u03b4 },(8)\nwhere\u1ef9 i = arg max j\u2208Yi f j (Aug q (x i ))) is the classifier prediction. \u03ba \u03b4 is the (100\u2212\u03b4)-percentile of the consine similarity between the query embedding and the\u1ef9 i -th prototype. For example, when \u03b4 = 60, it means 60% of examples are above the threshold. Our motivation is that the clustering effect of contrastive learning makes the clean examples dominate the prototype calculation and thus they are distributed close to at least one prototype inside the candidate set. On the other hand, the noisy candidates mostly deviate from all candidate prototypes as their true labels are not contained in their candidate sets.", "publication_ref": ["b12"], "figure_ref": [], "table_ref": []}, {"heading": "Semi-supervised Contrastive Learning", "text": "While leveraging the clean examples to run a PiCO model is straightforward, the low data utility restricts it from better performance. Consequently, we regard noisy examples as unlabeled ones and develop a semi-supervised learning framework to learn from the two sets. On clean datasets, we assume the true labels are included in the candidate and run our PiCO method. It should be particularly noted that we also restrict the positive set construction and prototype updating procedures to merely employ clean examples. But, the pseudo-target updating is performed over all data points. On the noisy dataset, which is denoted by D noisy = D\\D clean , we follow our design patterns in PiCO to synergetically train the contrastive branch as well as the classifier.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "It is achieved by the following components:", "text": "Neighbor-Augmented Contrastive Learning. Recall that the crucial step for designing contrastive loss is to construct the positive set, which is challenging for noisy samples as their candidate sets are unreliable. To this end, we first propose a label-driven construction approach. By regarding noisy samples as unlabeled data, it is intuitive to treat all labels as candidates. This gives rise to the following noisy positive set,\nP noisy (x) = {k |k \u2208 A(x),\u0177 =\u0177}, where\u0177 = \uf8f1 \uf8f2 \uf8f3 arg max 1\u2264j\u2264L f j (Aug q (x))) if x \u2208 D noisy , arg max j\u2208Y f j (Aug q (x))) else.(9)\nThat is, we choose the within-set classifier prediction for clean examples and choose the full-label prediction for the remaining. We apply this noisy positive set to all data in D and calculate a noisy contrastive loss L n-cont by Eq. (3). This objective serves as our ultimate goal of semi-supervised training that recovers the PiCO algorithm on clean PLL data and noisy unlabeled data.\nNevertheless, as we are less knowledgeable of noisy examples, our estimation on P noisy (x) can be inaccurate and assigns wrong cluster centers. To this end, we incorporate a data-driven technique to regularize the noisy contrastive loss. In specific, we collect the nearest neighbors of noisy samples to be positive peers,\nP knn (x) = {k |k \u2208 A(x) \u2229 N k (x)},(10)\nwhere L as in PiCO, since the data separation procedure dynamically changes during training. To this end, we leverage the class prototypes to guess their pseudo-targets s by,\nN k (x)\ns j = exp(q \u00b5 j /\u03c4 ) L t=1 exp(q \u00b5 t /\u03c4 ) , \u22001 \u2264 j \u2264 L.(11)\nWe calculate the cross-entropy loss on D noisy as defined in Eq. (1), which is term as L n-cls .\nMixup Training. Recently, the mixup regularization technique has widely adopted to improve the robustness of weakly-supervised learning algorithms [14], [15]. Therefore, we also incorporate it into PiCO+ for boosted performance. Formally, given a pair of images x i and x j , we create a virtual training example by linearly interpolating both,\nx m = \u03c3Aug q (x i ) + (1 \u2212 \u03c3)Aug q (x j ), s m = \u03c3\u015d i + (1 \u2212 \u03c3)\u015d j ,(12)\nwhere \u03c3 \u223c Beta(\u03c2, \u03c2) and \u03c2 is a hyperparameter. Here, we take the pseudo-target of PiCO on clean examples, and the guessed label on noisy examples, i.e.,\u015d = s if x \u2208 D clean els\u00ea s = s . We define the mixup loss L mix as the cross-entropy on x m and s m . \nL pico+ = L mix + \u03b1L clean + \u03b2(L n-cont + L knn + L n-cls ), (13\n)\nwhere L clean is the PiCO loss on clean examples. Note that over-trusting the guessed labels and positive sets on noisy samples may cause confirmation bias [16] and makes the model overfit on wrong labels. Empirically, we set a larger \u03b1 and a smaller \u03b2 (e.g. \u03b1 = 2, \u03b2 = 0.1), and thus, the clean samples dominate the learning procedure to ensure favorable noisy example detection ability.", "publication_ref": ["b13", "b14", "b15"], "figure_ref": [], "table_ref": []}, {"heading": "EXPERIMENTS", "text": "In this section, we present our main results and part of ablation results to show the effectiveness of PiCO and PiCO+ methods. We refer readers to Appendix B for more experimental results and analysis. Code and data are available at: https://github.com/hbzju/PiCO.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Setup", "text": "Datasets. First, we evaluate PiCO on two commonly used benchmarks -CIFAR-10 and CIFAR-100 [17]. Adopting the identical experimental settings in previous work [18], [19], we generate conventional partially labeled datasets by flipping negative labels\u0233 = y to false positive labels with a probability q = P (\u0233 \u2208 Y |\u0233 = y). In other words, all C \u2212 1 negative labels have a uniform probability to be false positive and we aggregate the flipped ones with the ground-truth to form the candidate set. We consider q \u2208 {0.1, 0.3, 0.5} for CIFAR-10 and q \u2208 {0.01, 0.05, 0.1} for CIFAR-100. In Section 5.4, we further evaluate our method on fine-grained classification tasks, where label disambiguation can be more challenging.\nFor the noisy PLL task, we introduce a noise controlling parameter \u03b7 = 1 \u2212 P (y \u2208 Y |y) that controls the probability of the ground-truth label not being selected as a candidate.\nAs it is possible that some instances are not assigned any candidate and we simply re-generate the candidate set until it has at least one candidate label. We select \u03b7 \u2208 {0.1, 0.2} for both datasets; results with stronger noisy ratios are shown in Section 5.3.3.", "publication_ref": ["b16", "b17", "b18"], "figure_ref": [], "table_ref": []}, {"heading": "Baselines.", "text": "We choose the five best-performed partial label learning algorithms to date: 1) LWS [19] weights the risk function by means of a trade-off between losses on candidate labels and the remaining; 2) PRODEN [18] iteratively updates the latent label distribution in a self-training style; 3) CC [20] is a classifier-consistent method that assumes setlevel uniform data generation process; 4) MSE and EXP [21] are two simple baselines that adopt mean square error and exponential loss as the risks. For the noisy PLL task, we additionally incorporate one baseline method GCE [10], [22] that generalizes the cross-entropy loss via negative Box-Cox transformation. The hyperparameters are tuned according to the original methods. For all experiments, we report the mean and standard deviation based on 5 independent runs (with different random seeds). Implementation Details. Following the standard experimental setup in PLL [19], [20], we split a clean validation set (10% of training data) from the training set to select the hyperparameters. After that, we transform the validation set back to its original PLL form and incorporate it into the training set to accomplish the final model training. We use an 18-layer ResNet as the backbone for feature extraction. Most of experimental setups for the contrastive network follow previous works [8], [12]. The projection head of the contrastive network is a 2-layer MLP that outputs 128dimensional embeddings. We use two data augmentation modules SimAugment [8] and RandAugment [23] for query and key data augmentation respectively. Empirically, we find that even weak augmentation for key embeddings also leads to good results. The size of the queue that stores key embeddings is fixed to be 8192. The momentum coefficients are set as 0.999 for contrastive network updating and \u03b3 = 0.99 for prototype calculation. For pseudo target Ablation study of PiCO on standard partial label learning datasets CIFAR-10 (q = 0.5) and CIFAR-100 (q = 0.05).", "publication_ref": ["b18", "b17", "b19", "b20", "b9", "b21", "b18", "b19", "b7", "b11", "b7", "b22"], "figure_ref": [], "table_ref": []}, {"heading": "Ablation", "text": "L  updating, we linearly ramp down \u03c6 from 0.95 to 0.8. The temperature parameter is set as \u03c4 = 0.07. The loss weighting factor is set as \u03bb = 0.5. The model is trained by a standard SGD optimizer with a momentum of 0.9 and the batch size is 256. We train the model for 800 epochs with cosine learning rate scheduling. We also empirically find that classifier warm up leads to better performance when there are many candidates. Hence, we disable contrastive learning in the first 100 epoch for CIFAR-100 with q = 0.1 and 1 epoch for the remaining experiments. For PiCO+, we basically follow the original PiCO method. The clean sample selection ratio parameter \u03b4 is set as 0.8/0.6 for noisy ratio 0.1/0.2, respectively. For neighbor augmentation, we set k = 16 for CIFAR-10 and a smaller k = 5 for CIFAR-100. In the beginning, the embeddings can be less meaningful and thus, we enable kNN augmentation after the first 100 epochs. We fix the shape parameter of the Beta distribution to \u03c2 = 4 for mixup training. We set the loss weighting factor \u03b1 = 2 and \u03b2 = 0.1. Similar to the standard PLL setup, we warm up the model by fitting uniform targets for 5 and 50 epochs on CIFAR-10 and CIFAR-100 datasets respectively.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Experimental Results on standard PLL", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Main Results", "text": "PiCO achieves SOTA results on standard PLL task. As shown in Table 1, PiCO significantly outperforms all the rivals by a significant margin on all datasets. Specifically, on CIFAR-10 dataset, we improve upon the best baseline by 4.09%, 4.80%, and 5.80% where q is set to 0.1, 0.3, 0.5 respectively. Moreover, PiCO consistently achieves superior results as the size of the candidate set increases, while the baselines demonstrate a significant performance drop.\nBesides, it is worth pointing out that previous works [18], [19] are typically evaluated on datasets with a small label space (C = 10). We challenge this by showing additional results on CIFAR-100. When q = 0.1, all the baselines fail to obtain satisfactory performance, whereas PiCO remains competitive. Moreover, we observe that PiCO achieves results that are comparable to the fully supervised contrastive learning model (in Table 2), showing that disambiguation is sufficiently accomplished. The comparison highlights the superiority of our label disambiguation strategy. Lastly, we evaluated the PiCO+ method in the standard PLL setup, which equals a PiCO model with mixup training. It can be shown that PiCO+ further improves PiCO by a notable margin, validating the robustness of the PiCO+ method.\nPiCO learns more distinguishable representations. We visualize the image representation produced by the feature encoder using t-SNE [24] in Figure 3. Different colors represent different ground-truth class labels. We use the CIFAR-10 dataset with q = 0.5. We contrast the t-SNE embeddings of three approaches: (a) a model trained with uniform pseudo targets, i.e., s j = 1/|Y | (j \u2208 Y ), (b) the best baseline PRODEN, and (c) our method PiCO. We can observe that the representation of the uniform model is indistinguishable since its supervision signals suffer from high uncertainty. The features of PRODEN are improved, yet with some class overlapping (e.g., blue and purple). In contrast, PiCO produces well-separated clusters and more distinguishable representations, which validates its effectiveness in learning high-quality representation.", "publication_ref": ["b17", "b18", "b23"], "figure_ref": ["fig_3"], "table_ref": ["tab_2", "tab_3"]}, {"heading": "Ablation Studies of PiCO", "text": "Effect of L cont and label disambiguation. We ablate the contributions of two key components of PiCO: contrastive Accuracy comparisons on noisy PLL datasets. Bold indicates superior results.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Dataset", "text": "Method q = 0.3 q = 0.5    2, we can observe that variant 1 substantially outperforms variant 2 (e.g., +8.04% on CIFAR-10), which signifies the importance of contrastive learning for producing better representations. Moreover, with label disambiguation, PiCO obtains results close to fully supervised setting, which verifies the ability of PiCO in identifying the ground-truth.\n\u03b7 = 0.1 \u03b7 = 0.2 \u03b7 = 0.1 \u03b7 = 0.2 CIFAR-\n\u03b7 = 0.1 \u03b7 = 0.2 \u03b7 = 0.1 \u03b7 = 0.2 CIFAR-", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_3"]}, {"heading": "Different disambiguation strategy.", "text": "Based on the contrastive prototypes, various strategies can be used to disambiguate the labels, which corresponds to the E-step in our theoretical analysis. We choose the following variants:\n1) One-hot Prototype always assigns a one-hot pseudo target s = z by using the nearest prototype (\u03c6 = 0); 2) Soft Prototype Probs follows [25] and uses a soft class probability s i = exp(q \u00b5i/\u03c4 ) j\u2208Y exp(q \u00b5j /\u03c4 ) as the pseudo target (\u03c6 = 0); 3) MA Soft Prototype Probs gradually updates pseudo target from uniform by using the soft probabilities in a movingaverage style. From Table 2, we can see that directly using either soft or hard prototype-based label assignment leads to competitive results. This corroborates our theoretical analysis in Section 6, since center-based class probability estimation is common in clustering algorithms. However, MA Soft Prototype Probs displays degenerated performance, suggesting soft label assignment is less reliable in identifying the ground-truth. Finally, PiCO outperforms the best variant by \u2248 2% in accuracy on both datasets, showing the superiority of our label disambiguation strategy. Ablation study of PiCO on noisy partial label learning datasets CIFAR-10 (q = 0.5, \u03b7 = 0.2) and CIFAR-100 (q = 0.05, \u03b7 = 0.2).", "publication_ref": ["b24"], "figure_ref": [], "table_ref": ["tab_3"]}, {"heading": "Ablation", "text": "L  Effect of moving-average factor \u03c6. We then explore the effect of pseudo target updating factor \u03c6 on PiCO performance. Figure 4 (a) shows the learning curves of PiCO on CIFAR-100 (q = 0.05). We can see that the best result is achieved at \u03c6 = 0.9 and the performance drops when \u03c6 takes a smaller value, particularly on the early stage. When \u03c6 = 0, PiCO obtains a competitive result but is much lower than \u03c6 = 0.9. This confirms that trusting the uniform pseudo targets at the early stage is crucial in obtaining superior performance. At the other extreme value \u03c6 = 1, uniform pseudo targets are used, and PiCO demonstrates a degenerated performance and severe overfitting phenomena. In general, PiCO performs well when \u03c6 \u2248 0.9.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Main Empirical Results on Noisy PLL", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Main Results", "text": "PiCO+ achieves SOTA results on noisy PLL task. In Table 3, we compare PiCO+ with competitive PLL methods on CIFAR datasets, where PiCO+ significantly outperforms baselines. In specific, on CIFAR-10 dataset with q = 0.5, PiCO+ improves upon the best competitor by 6.66% and 12.52% when \u03b7 is set to 0.1, 0.2 respectively. Notably, under the noisy PLL setup, even when only 10% examples have wrong candidate sets, the baseline algorithms (including PiCO) exhibit severe performance degradation. This is further aggravated on CIFAR-100 with a larger label space, while PiCO+ consistently retains its great robustness.\nPiCO+ learns compact and distinguishable features. In Figure 5, we visualize the feature representations of PiCO+ on the noisy PLL CIFAR-10 dataset with q = 0.5, \u03b7 = 0.2. It can be shown that PiCO generates compact representations even with noisy candidate sets, which further supports the clustering effect of contrastive learning. However, both PiCO and PRODEN exhibit severe overfitting on wrong labels. Instead, the features of our PiCO+ is both compact and distinguishable.   We note that the mixup training technique also improves the fully-supervised model (e.g. +1.05% on CIFAR-10). But the performance improvement is more substantial on the noisy PLL tasks (e.g. +2.92% on CIFAR-10), indicating its robustness on noisy data. Lastly, Figure 4 (b) shows the influence of neighbor number k, where PiCO+ works well in a wide range of k values. Nevertheless, a too large k may collect many noisy positive peers and slightly drops the performance. Effect of loss weighting factor \u03b2. Figure 4 reports the performance of PiCO+ with varying \u03b2 values. On the CIFAR-10 dataset, we observe a severe performance degradation with \u03b2 being larger. The variance becomes increasingly larger as well. Similar trends can also be observed on CIFAR-100, though the results are much stabler. It suggests that the usage of noisy examples should be careful as they may result in confirmation bias.", "publication_ref": [], "figure_ref": ["fig_5"], "table_ref": ["tab_5"]}, {"heading": "Ablation Studies of PiCO+", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "The Robustness of PiCO+ with Severe Noise", "text": "Finally, we conduct experiments on noisy PLL datasets that contain much more severe noise to show the robustness of our PiCO+ method. In particular, we choose \u03b7 \u2208 {0.3, 0.4} and \u03b7 \u2208 {0.3, 0.4, 0.5} for CIFAR-10 and CIFAR-100 respectively. Accordingly, we adjust the selection ratio to \u03b4 = 0.5, 0.4 when \u03b7 = 0.4, 0.5, without changing other setups.  impressive performance. For example, the gaps between PiCO+ and the best baseline are 41.50% and 24.99% on CIFAR-10 with \u03b7 = 0.4 and CIFAR-100 with \u03b7 = 0.5.\nWe conclude that PiCO+ is indeed much more robust than existing PLL algorithms.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Further Extension: Fine-Grained Partial Label Learning", "text": "Recall the dog example highlighted in Section 2, where semantically similar classes are more likely to cause label ambiguity. It begs the question of whether PiCO is effective on the challenging fine-grained image classification tasks.\nTo verify this, we conduct experiments on two datasets: 1) CUB-200 dataset [26] contains 200 bird species; 2) CIFAR-100 with hierarchical labels (CIFAR-100-H), where we generate candidate labels that belong to the same superclass 1 . We set q = 0.05 for CUB-200 and q = 0.5 for CIFAR-100 with hierarchical labels. In Table 6, we compare PiCO with baselines, where PiCO outperforms the best method PRO-DEN by a large margin (+9.61% on CUB-200 and +11.15% on CIFAR-100-H). In addition, we test the performance of PiCO+ on both standard and noisy PLL versions of finegrained datasets. For the noisy version, we set the number of neighbors by k = 3 for CUB-200 and \u03b7 = 0.2 for both.\nThe results are listed in Table 6 and 7, where PiCO+ achieves substantially better performance than all the baselines. Our results validate the effectiveness of our framework, even in the presence of strong label ambiguity.", "publication_ref": ["b25", "b0"], "figure_ref": [], "table_ref": ["tab_11", "tab_11"]}, {"heading": "WHY PICO IMPROVES PARTIAL LABEL LEARN-ING?", "text": "In this section, we provide theoretical justification on why the contrastive prototypes help disambiguate the groundtruth label. We show that the alignment property in contrastive learning [11] intrinsically minimizes the intraclass covariance in the embedding space, which coincides with the objective of classical clustering algorithms. It motivates us to interpret PiCO through the lens of the expectationmaximization algorithm. To see this, we consider an ideal setting: in each training step, all data examples are accessible and the augmentation copies are also included in the training set, i.e., A = D. Then, the contrastive loss is calculated as,\nLcont(g; \u03c4, D) = 1 n x\u2208D \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 \u2212 1 |P (x)| k + \u2208P(x) log exp(q k+/\u03c4 ) k \u2208A(x) exp(q k /\u03c4 ) \uf8fc \uf8f4 \uf8fd \uf8f4 \uf8fe = 1 n x\u2208D \uf8f1 \uf8f2 \uf8f3 \u2212 1 |P (x)| k + \u2208P (x) (q k+/\u03c4 ) \uf8fc \uf8fd \uf8fe (a) + 1 n x\u2208D \uf8f1 \uf8f2 \uf8f3 log k \u2208A(x) exp(q k /\u03c4 ) \uf8fc \uf8fd \uf8fe (b) . (14\n)\nWe focus on analyzing the first term (a), which is often dubbed as the alignment term [11]. The main functionality of this term is to optimize the tightness of the clusters in the embedding space. In this work, we connect it with classical clustering algorithms. We first split the dataset to C subsets S j \u2208 D C (1 \u2264 j \u2264 C), where each subset contains examples possessing the same predicted labels. In effect, our selection strategy in Eq. (4) constructs the positive set by selecting examples from the same subset. Therefore, we have,\n(a) = 1 n x\u2208D 1 |P (x)| k+\u2208P (x) (||q \u2212 k + || 2 \u2212 2)/(2\u03c4 ) \u2248 1 2\u03c4 n Sj \u2208D C 1 |S j | x,x \u2208Sj ||g(x) \u2212 g(x )|| 2 + K = 1 \u03c4 n Sj \u2208D C x\u2208Sj ||g(x) \u2212 \u00b5 j || 2 + K, (15\n)\nwhere K is a constant and \u00b5 j is the mean center of S j . Here we approximate\n1 |Sj | \u2248 1 |Sj |\u22121 = 1 |P (x)|\nsince n is usually large. We omitted the augmentation operation for simplicity. The uniformity term (b) can benefit information-preserving, and has been analyzed in [11].\nWe are now ready to interpret the PiCO algorithm as an expectation-maximization algorithm that maximizes the likelihood of a generative model. At the E-step, the classifier assigns each data example to one specific cluster. At the M-step, the contrastive loss concentrates the embeddings to their cluster mean direction, which is achieved by minimizing Eq. (15). Finally, the training data will be mapped to a mixture of von Mises-Fisher distributions on the unit hypersphere.\nEM Perspective. Recall that the candidate label set is a noisy version of the ground-truth. To estimate the likelihood P (Y i , x i ), we need to establish the relationship between the candidate and the ground-truth label. Following [5], we make a mild assumption, Assumption 1. All labels y i in the candidate label set have the same probability of generating Y i , but no label outside of Y i can generate Y i , i.e. P (Y i |y i ) = (Y i ) if y i \u2208 Y i else 0. Here (\u2022) is some function making it a valid probability distribution.\nThen, we show that the PiCO implicitly maximizes the likelihood as follows, E-Step. First, we introduce some distributions over all examples and the candidates \u03c0\nj i \u2265 0 (1 \u2264 i \u2264 n, 1 \u2264 j \u2264 C) such that \u03c0 j i = 0 if j / \u2208 Y i and j\u2208Yi \u03c0 j i = 1.\nLet \u03b8 be the parameters of g. Our goal is to maximize the likelihood below, arg max\n\u03b8 n i=1 log P (Y i , x i |\u03b8) = argmax \u03b8 n i=1 log yi\u2208Yi P (x i , y i |\u03b8)+ n i=1 log( (Y i )) = argmax \u03b8 n i=1 log yi\u2208Yi \u03c0 yi i P (x i , y i |\u03b8) \u03c0 yi i \u2265 argmax \u03b8 n i=1 yi\u2208Yi \u03c0 yi i log P (x i , y i |\u03b8) \u03c0 yi i . (16\n)\nThe last step of the derivation uses Jensen's inequality. By using the fact that log(\u2022) function is concave, the inequality holds with equality when\nP (xi,yi|\u03b8) \u03c0 y i i\nis some constant. Therefore,\n\u03c0 yi i = P (x i , y i |\u03b8) yi\u2208Yi P (x i , y i |\u03b8) = P (x i , y i |\u03b8) P (x i |\u03b8) = P (y i |x i , \u03b8),(17)\nwhich is the posterior class probability. In PiCO, it is estimated by using the classifier's output. To estimate P (y i |x i , \u03b8), classical unsupervised clustering methods intuitively assign the data examples to the cluster centers, e.g. k-means. As in the supervised learning setting, we can directly use the ground-truth. However, under the setting of PLL, the supervision signals are situated between the supervised and unsupervised setups. Based on empirical findings, the candidate labels are more reliable for posterior estimation at the beginning; yet alongside the training process, the prototypes tend to become more trustful. This empirical observation has motivated us to update the pseudo targets in a moving-average style. Thereby, we have a good initialization in estimating class posterior, and it will be smoothly refined during the training procedure. This is verified in our empirical studies; see Section 5.2.2 and Appendix B.1. Finally, we take one-hot prediction\u1ef9 i = arg max j\u2208Y f j (x i ) since each example inherently belongs to exactly one label and hence, we have \u03c0 j i = I(\u1ef9 i = j). M-Step. At this step, we aim at maximizing the likelihood under the assumption that the posterior class probability is known. We show that under mild assumptions, minimizing Eq. (15) also maximizes a lower bound of likelihood in Eq. (16). Theorem 1. Assume data from the same class in the contrastive output space follow a d-variate von Mises-Fisher (vMF) distribution whose probabilistic density is given by f (x|\u03bc i , \u03ba) = c d (\u03ba)e \u03ba\u03bc i g(x) , where\u03bc i = \u00b5 i /||\u00b5 i || is the mean direction, \u03ba is the concentration parameter, and c d (\u03ba) is the normalization factor. We further assume a uniform class prior P (y i = j) = 1/C. Let n j = |S j |. Then, optimizing Eq. (15) and Eq. ( 16) equal to maximize R 1 and R 2 below, respectively.\nR 1 = Sj \u2208D C n j n ||\u00b5 j || 2 \u2264 Sj \u2208D C n j n ||\u00b5 j || = R 2 . (18\n)\nThe proof can be found in the Appendix A. Theorem 1 indicates that minimizing Eq. ( 15) also maximizes a lower bound of the likelihood in Eq. (16). The lower bound is tight when ||\u00b5 j || is close to 1, which in effect means a strong intraclass concentration on the hypersphere. Intuitively, when the hypothesis space is rich enough, it is possible to achieve a low intraclass covariance in the Euclidean space, resulting in a large norm of the mean vector ||\u00b5 j ||. Then, normalized embeddings in the hypersphere also have an intraclass concentration in a strong sense, because a large ||\u00b5 j || also results in a large \u03ba [27]. Regarding the visualized representation in Figure 3, we note that PiCO is indeed able to learn compact clusters. Therefore, we have that minimizing the contrastive loss also partially maximizes the likelihood defined in Eq. (16).", "publication_ref": ["b10", "b10", "b10", "b14", "b4", "b15", "b26"], "figure_ref": ["fig_3"], "table_ref": []}, {"heading": "RELATED WORKS", "text": "Partial Label Learning (PLL) allows each training example to be annotated with a candidate label set, in which the ground-truth is guaranteed to be included. The most intuitive solution is average-based methods [3], [4], [28], which treat all candidates equally. However, the key and obvious drawback is that the predictions can be severely misled by false positive labels. To disambiguate the groundtruth from the candidates, identification-based methods [29], which regard the ground-truth as a latent variable, have recently attracted increasing attention; representative approaches include maximum margin-based methods [30], [31], graph-based methods [6], [7], [32], [33], and clusteringbased approaches [5]. Recently, self-training methods [18], [19], [20] have achieved state-of-the-art results on various benchmark datasets, which disambiguate the candidate label sets by means of the model outputs themselves. But, few efforts have been made to learn high-quality representations to reciprocate label disambiguation.\nContrastive Learning (CL) [12], [34] is a framework that learns discriminative representations through the use of instance similarity/dissimilarity. A plethora of works has explored the effectiveness of CL in unsupervised representation learning [12], [34], [35]. Recently, [8] propose supervised contrastive learning (SCL), an approach that aggregates data from the same class as the positive set and obtains improved performance on various supervised learning tasks. The success of SCL has motivated a series of works to apply CL to a number of weakly supervised learning tasks, including noisy label learning [25], [36], semi-supervised learning [37], [38], etc. Despite promising empirical results, however, these works, lack theoretical understanding. [11] theoretically show that the CL favors alignment and uniformity, and thoroughly analyzed the properties of uniformity. But, to date, the terminology alignment remains confusing; we show it inherently maps data points to a mixture of vMF distributions.\nNoisy Label Learning (NLL) [39] aims at mitigating overfitting on mislabeled samples. One popular strategy is to design robust risk functions, including but does not limit to robust cross-entropy losses [22], [40], [41], sample re-weighting [42], [43], [44] and noise transition matrixbased loss correction [45], [46], [47]. Another active line of research relies on selecting clean samples from noisy ones [48]. Most of them adopt the small-loss selection criterion [13], [49] which is motivated by the fact that deep neural networks tend to memorize easy patterns first [50]. Based on that, the state-of-the-art NLL algorithms [15], [25], [51] regard the unchosen samples as unlabeled and incorporate semi-supervised learning (SSL) for boosted performance. Inspired by these works, PiCO+ incorporates a new distancebased selection criterion and extends the contrastive learning framework to facilitate SSL training. The most related one to our work is [10] which theoretically analyzes the robustness of average-based loss functions for the noisy PLL task. But, [10] does not provide a new empirically strong solution. Instead, our PiCO+ framework establishes promising results against label noise that makes the PLL problem more practical for open-world applications.", "publication_ref": ["b2", "b3", "b27", "b28", "b29", "b30", "b5", "b6", "b31", "b32", "b4", "b17", "b18", "b19", "b11", "b33", "b11", "b33", "b34", "b7", "b24", "b35", "b36", "b37", "b10", "b38", "b21", "b39", "b40", "b41", "b42", "b43", "b44", "b45", "b46", "b47", "b12", "b48", "b49", "b14", "b24", "b50", "b9", "b9"], "figure_ref": [], "table_ref": []}, {"heading": "CONCLUSION", "text": "In this work, we propose a novel partial label learning framework PiCO. The key idea is to identify the groundtruth from the candidate set by using contrastively learned embedding prototypes. Empirically, we conducted extensive experiments and show that PiCO establishes state-of-theart performance. Our results are competitive with the fully supervised setting, where the ground-truth label is given explicitly. Theoretical analysis shows that PiCO can be interpreted from an EM-algorithm perspective. Additionally, we extend the PiCO framework to PiCO+ which is able to learn robust classifiers from noisy partial labels. Applications of multi-class classification with ambiguous labeling can benefit from our method, and we anticipate further research in PLL to extend this framework to tasks beyond image classification. We hope our work will draw more attention from the community toward a broader view of using contrastive prototypes for partial label learning.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "2nj", "text": "x,x \u2208Sj ||g(x) \u2212 g(x )|| 2 =\nx\u2208Sj ||g(x) \u2212 \u00b5 j || 2 = RHS. We have,\nLHS = 1 2n j x\u2208Sj x \u2208Sj (||g(x)|| 2 \u2212 2g(x) g(x ) + ||g(x )|| 2 ) = 1 n j x\u2208Sj (n j \u2212 g(x) ( x \u2208Sj g(x ))) = 1 n j x\u2208Sj (n j \u2212 g(x) (n j \u00b5 j ))) = n j \u2212 ( x\u2208Sj g(x)) \u00b5 j ) = n j (1 \u2212 ||\u00b5 j || 2 ).(19)\nOn the other hand,\nRHS = x\u2208Sj (||g(x)|| 2 \u2212 2g(x) \u00b5 j + ||\u00b5 j || 2 ) = (n j \u2212 2( x\u2208Sj g(x)) \u00b5 j + n j ||\u00b5 j || 2 ) = n j (1 \u2212 ||\u00b5 j || 2 ) = LHS. (20\n)\nProof of Theorem 1. By regarding \u03c0 j i as constants w.r.t = arg max\n\u03b8 Sj \u2208D C n j n ||\u00b5 j || (21\n)\nwhere n j = |S j |. Here we ignore the constant factor \u2212 n i=1 yi\u2208Yi \u03c0 yi i log \u03c0 yi i w.r.t. \u03b8 in the first equality. In the last equality, we use the fact that \u00b5 j = 1 nj x\u2208Sj g(x) and \u00b5 j is the unit directional vector of \u00b5 j . From Eq. (15), we have that,\narg min \u03b8 Sj \u2208D C x\u2208Sj ||g(x) \u2212 \u00b5 j || 2 = arg min \u03b8 Sj \u2208D C x\u2208Sj (||g(x)|| 2 \u2212 2g(x) \u00b5 j + ||\u00b5 j || 2 ) = arg min \u03b8 Sj \u2208D C (n j \u2212 n j ||\u00b5 j || 2 ) = arg max \u03b8 Sj \u2208D C n j n ||\u00b5 j || 2 . (22\n)\nNote that the contrastive embeddings are distributed on the hypersphere S d\u22121 and thus ||\u00b5 j || \u2208 [0, 1]. It can be directly derived that,\nR 1 = Sj \u2208D C n j n ||\u00b5 j || 2 \u2264 Sj \u2208D C n j n ||\u00b5 j || = R 2 . (23\n)\nTherefore, maximizing the intraclass covariance in Eq. ( 15) is equivalent to maximizing a lower bound of the likelihood in Eq. (16). It can also be shown that (R 2 ) 2 \u2264 R 1 followed by the convexity of the squared function. Since arg max R 2 = arg max(R 2 ) 2 , we have that the contrastive loss also maximizes an upper bound of R 2 .\nUnfortunately, there is no guarantee that the lower bound is tight without further assumptions. To see this, assume that we have two classes y \u2208 {1, 2} with equalsized samples and their mean vectors have the norm of ||\u00b5 1 || = 0.5 and ||\u00b5 1 || = 1. We have that R 1 = 0.625 and R 2 = 0.75, which demonstrates a large discrepancy. It is interesting to see that when the norm of the mean vectors are the same, i.e. ||\u00b5 j || = ||\u00b5 k || for all 1 \u2264 j \u2264 k \u2264 C, we have (R 2 ) 2 = R 1 by the Jensen's inequality, making the upper bound tight. But, it is not a trivial condition.\nTo obtain a tight lower bound, what we need is a rich enough hypothesis space to achieve a low intraclass covariance in Eq. (15), and hence a large R 1 . We show that it inherently produces compact vMF distributions. To see this, it should be noted that the concentration parameter \u03ba Fig. 6. A large norm of Euclidean's mean vector also leads to a strong concentration of unit vectors to its mean direction.\nof a vMF distribution is given by the inverse of the ratio of Bessel functions of mean vector \u00b5 j . Though it is not possible to obtain an analytic solution of \u03ba, we have the following well-known approximation [27],\n\u03ba \u2248 d \u2212 1 2(1 \u2212 ||\u00b5 j ||)\n, valid for large ||\u00b5 j ||,\n\u03ba \u2248 d||\u00b5 j || 1 + d d + 2 ||\u00b5 j || 2 + d 2 (d + 8) (d + 2) 2 (d + 4) ||\u00b5 j || 4 ,\nvalid for small ||\u00b5 j ||.\nThe above approximations show that a larger norm of Euclidean's mean \u00b5 j typically leads to a stronger concentration on the hypersphere. By Eq. ( 22), we know that contrastive loss encourages a large norm of \u00b5 j , and thus also tightly clusters the embeddings on the hypersphere; see Figure 6.\nWe further note that we do not include a k-means process in our PiCO method. PiCO is related to centerbased clustering algorithms in our theoretical analysis. Since we restrict the gold label to be included in the candidate set, we believe that this piece of information could largely help avoid the bad optimum problem that occurs in a pure unsupervised setup. For the convergence properties of our PiCO algorithm, we did not empirically find any issues with PiCO converging to a (perhaps locally) optimal point. However, we want to refer the readers to the proof of kmeans clustering in [52] for the convergence analysis.\nDiscussion. Regarding our empirical results where PiCO does indeed learn compact representations for each class, we can conclude that PiCO implicitly clusters data points in the contrastive embeddings space as a mixture of vMF distributions. In each iteration, our algorithm can be viewed as alternating the two steps until convergence, though different in detail. First, it is intractable to handle the whole training dataset, and thus we accelerate via a MoCostyle dictionary and MA-updated prototypes. Second, the contrastive loss also encourages the uniformity of the embeddings to maximally preserve information, which serves as a regularizer and typically leads to better representation. Finally, we use two copies of data examples such that data are also aligned in its local region. Moreover, our theoretical result also answers why merely taking the pseudo-labels to select positive examples also leads to superior results, since the selected positive set will be refined as the training procedure proceeds.\nOur theoretical results are also generalizable to other contrastive learning methods. For example, the classical unsupervised contrastive learning [12] actually assumes nprototypes to cluster all locally augmented data; prototypical contrastive learning [53] directly assigns the data Training accuracy of pseudo targets on CIFAR-10 and CIFAR-100.  examples to one cluster to get the posterior, since there are no supervision signals; supervised contrastive learning [8] chooses the known ground-truth as the posterior. In our problem, we follow two extreme settings to progressively obtain an accurate posterior estimation. Finally, it is also noteworthy that the objective in Eq. (15) has a close connection to the intraclass deviation [54], minimizing which is proven to be beneficial in obtaining tighter generalization error bound on downstream tasks. It should further be noted that our work differs from existing clustering-based CL methods [53], [55], which explicitly involves clustering to aggregate the embeddings; instead, our results are derived from the loss itself.", "publication_ref": ["b15", "b14", "b26", "b51", "b11", "b52", "b7", "b53", "b52", "b54"], "figure_ref": [], "table_ref": []}, {"heading": "APPENDIX B MORE EXPERIMENTAL RESULTS", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B.1 Ablation Studies", "text": "Moving-average updating factor \u03c6. We first present more ablation results about the effect of pseudo target updating factor \u03c6 on PiCO performance. Figure 7 (a) shows the results on two datasets CIFAR-10 (q = 0.5) and CIFAR-100 (q = 0.05). The overall trends on both datasets follow our arguments in Section 5.2.2. Specifically, performance on CIFAR-100 achieves the best result when \u03c6 = 0.7, and slight drops when \u03c6 = 0.9. Therefore, in practice, we may achieve a better result with careful fine-tuning on \u03c6 value. In contrast, PiCO works well in a wide range of \u03c6 values on CIFAR-10. The reason might be that CIFAR-10 is a simpler  version of CIFAR-100, and thus the prototypes can be highquality quickly. But, setting \u03c6 to either 0 or 1 leads to a worse result, which has been discussed earlier.\nLoss weight \u03bb. Figure 7 (b) reports the performance of PiCO with varying \u03bb values that trade-off the classification and contrastive losses. \u03bb is selected from {0.01, 0.1, 0.5, 5, 50}. We can observe that on CIFAR-10, the performance is stable, but on CIFAR-100, the best performance is obtained at \u03bb = 5. When \u03bb = 50, PiCO shows inferior results on both two datasets. In general, a relatively small \u03bb (< 10) usually leads to good performance than a much larger value. When \u03bb is large, the contrastive network tends to fit noisy labels at the early stage of training.\nPrototype updating factor \u03b3. Then, we show the effect of \u03b3 that controls the speed of prototype updating and the results are listed in Table 8. On the CIFAR-10 dataset, the performance is stable with varying \u03b3. But, on CIFAR-100, it can be seen that too large \u03bb leads to a significant performance drop, which may be caused by insufficient label disambiguation.\nThe disambiguation ability of PiCO. Next, we evaluate the disambiguation ability of the proposed PiCO. To see this, we calculate the max confidence to represent the uncertainty of an example, which has been widely used in recent works [56]. If one example is uncertain about its ground-truth, then it typically associates with low max confidence max j s j . To represent the uncertainty of the whole training dataset, we calculate the mean max confidence (MMC) score. In Figure 8, we plot the MMC scores of different label disambiguation Performance of PiCO+ with varying \u03b1 on CIFAR-10 (q = 0.5, \u03b7 = 0.2) and CIFAR-100 (q = 0.05, \u03b7 = 0.2).   9, we can find that the pseudo targets achieve high training accuracy. Combined with the fact that the mean max confidence score of the pseudo target is close to 1, the training examples finally become near supervised ones. Thus, the proposed PiCO is able to achieve near-supervised learning performance, especially when the label ambiguity is not too high. These results verify that PiCO has a strong label disambiguation ability to handle the PLL problem.\nClean loss weight \u03b1 for PiCO+. Lastly, we show the effect of clean loss weight \u03b1 for PiCO+ in Table 11. With a too large \u03b1, the performance of PiCO+ typically drops since the regularization effect of mixup training and semi-supervised learning becomes weak. When \u03b1 is too small, we observe that PiCO+ exhibits degenerated performance on CIFAR-10. The reason is that the clean examples are dominated by unreliable samples, resulting in severe confirmation bias ", "publication_ref": ["b55"], "figure_ref": ["fig_9", "fig_9", "fig_10"], "table_ref": ["tab_14", "tab_2"]}, {"heading": "B.2 Additional Results on Fine-Grained Classification", "text": "In the sequel, we show the full setups and experimental results on fine-grained classification datasets. In particular, on CUB-200, we set the length of the momentum queue as 4192. For CUB-200, we set the input image resolution as 224 \u00d7 224 and select q \u2208 {0.01, 0.05, 0.1}. When q = 0.05/0.1, we warm up for 20/100 epochs and train the model for 200/300 epochs, respectively. For CIFAR-100-H, we select q \u2208 {0.1, 0.5, 0.8} and warm up the model for 100 epochs when q = 0.8. Other hyperparameters are the same as our default setting. The baselines are also fine-tuned to achieve their best results. From Table 10, we can observe that PiCO significantly outperforms all the baselines on all the datasets. Moreover, as the size of candidate sets grows larger, PiCO consistently leads by an even wider margin. For example, on CIFAR-100-H, compared with the best baseline, performance improvement reaches 9.50%, 11.15% and 22.53% in accuracy when q = 0.1, 0.5, 0.8, respectively. The comparison emerges the dominance of our label disambiguation strategy among semantically similar classes.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_2"]}, {"heading": "B.3 Strategies for Positive Selection", "text": "While our positive set selection strategy is simple and effective, one may still explore more complicated strategies to boost performance. We have empirically tested two strategies: 1) Filter-based: we set a filter |Yi\u2229Yj | |Yi\u222aYj | \u2264 \u03c1 (\u03c1 = 0.5) to remove example pairs who have dissimilar candidate sets at the early stage. 2) Threshold-based: we set a threshold max f j (Aug q (x)) \u2264 \u03b4 (\u03b4 = 0.95) to remove those uncertain examples at the end of training, which has been widely used in semi-supervised learning [57]. Our basic principle is that contrastive learning is robust to noisy negative pairs and thus, we can flip those less reliable positive pairs to negative. Unfortunately, we did not observe statistically significant improvement to our vanilla strategy in experiments. These negative results suggest that the proposed PiCO has a strong error correction ability, which corroborates our theoretical analysis.", "publication_ref": ["b56"], "figure_ref": [], "table_ref": []}, {"heading": "B.4 The Influence of Data Generation", "text": "In practice, some labels may be more analogous to the true label than others, which makes their probability of label flipping q larger than others. In other words, the data generation procedure is non-uniform. In Section 5.4, we have shown one such case on CIFAR-100-H, where semantically similar labels have a larger probability of being a false positive. Moreover, we follow [19] to conduct empirical comparisons on data with alternative generation processes. In particular, we test two commonly used cases on CIFAR-10 with the following flipping matrix, respectively: \n(1) = \uf8ee \uf8ef \uf8ef \uf8ef \uf8f0 1 0.5 0 \u2022 \u2022 \u2022 0 0 1 0.5 \u2022 \u2022 \u2022 0 . . . \u2022 \u2022 \u2022 . . . 0.5 0 0 \u2022 \u2022 \u2022 1 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fb ,(2)\n\u2022 \u2022 \u2022 1 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fb\nwhere each entry denotes the probability of a label being a candidate. As shown in Table 12, PiCO outperforms other baselines in both cases. It is worth noting that in Case (2), each ground-truth label has a maximum probability of 0.9 of being coupled with the same false positive label. In such a challenging setup, PiCO still achieves promising results that are competitive with the supervised performance, which further verifies its strong disambiguation ability.", "publication_ref": ["b18"], "figure_ref": [], "table_ref": ["tab_2"]}, {"heading": "B.5 The Influence of Prototype Calculation", "text": "There are several ways to calculate the prototypes and hence, we further test a variant of PiCO that re-computes ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "APPENDIX A THEORETICAL ANALYSIS", "text": "Derivation of Eq. (15). We provide the derivation of the second equality in Eq. (15). It suffices to show that LHS =", "publication_ref": ["b14"], "figure_ref": [], "table_ref": []}, {"heading": "APPENDIX C PSEUDO-CODE OF PICO+", "text": "We summarize the pseudo-code of our PiCO+ method in Algorithm 2.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "APPENDIX D THE LITERATURE OF PROTOTYPE LEARNING", "text": "Prototype learning (PL) aims to learn a metric space where examples are enforced to be closer to its class prototype. PL is typically more robust in handling few-shot learning [58], zero-shot learning [59], and out-of-distribution samples [60]. Recently, PL has demonstrated promising results in weaklysupervised learning, such as semi-supervised learning [61], noisy-label learning [25], etc. For example, USADTM [61] shows that informative class prototypes usually lead to better pseudo-labels for semi-supervised learning than classical pseudo-labeling algorithms [57] which reuse classifier outputs. Motivated by this, we also employ contrastive prototypes for label disambiguation.", "publication_ref": ["b57", "b58", "b59", "b60", "b24", "b60", "b56"], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Learning from candidate labeling sets", "journal": "Curran Associates, Inc", "year": "2010", "authors": "J Luo; F Orabona"}, {"ref_id": "b1", "title": "Learning from ambiguously labeled face images", "journal": "IEEE Trans. Pattern Anal. Mach. Intell", "year": "2018", "authors": "C Chen; V M Patel; R Chellappa"}, {"ref_id": "b2", "title": "Learning from ambiguously labeled examples", "journal": "Intell. Data Anal", "year": "2006", "authors": "E H\u00fcllermeier; J Beringer"}, {"ref_id": "b3", "title": "Learning from partial labels", "journal": "J. Mach. Learn. Res", "year": "2011", "authors": "T Cour; B Sapp; B Taskar"}, {"ref_id": "b4", "title": "A conditional multinomial mixture model for superset label learning", "journal": "NeurIPS", "year": "2012", "authors": "L Liu; T G Dietterich"}, {"ref_id": "b5", "title": "Partial label learning via featureaware disambiguation", "journal": "KDD", "year": "2016", "authors": "M Zhang; B Zhou; X Liu"}, {"ref_id": "b6", "title": "GM-PLL: graph matching based partial label learning", "journal": "IEEE Trans. Knowl. Data Eng", "year": "2021", "authors": "G Lyu; S Feng; T Wang; C Lang; Y Li"}, {"ref_id": "b7", "title": "", "journal": "", "year": "2020", "authors": "P Khosla; P Teterwak; C Wang; A Sarna; Y Tian; P Isola; A Maschinot; C Liu; D Krishnan"}, {"ref_id": "b8", "title": "Pico: Contrastive label disambiguation for partial label learning", "journal": "", "year": "2022", "authors": "H Wang; R Xiao; Y Li; L Feng; G Niu; G Chen; J Zhao"}, {"ref_id": "b9", "title": "On the robustness of average losses for partial-label learning", "journal": "CoRR", "year": "2021", "authors": "J Lv; L Feng; M Xu; B An; G Niu; X Geng; M Sugiyama"}, {"ref_id": "b10", "title": "Understanding contrastive representation learning through alignment and uniformity on the hypersphere", "journal": "PMLR", "year": "2020", "authors": "T Wang; P Isola"}, {"ref_id": "b11", "title": "Momentum contrast for unsupervised visual representation learning", "journal": "IEEE", "year": "2020", "authors": "K He; H Fan; Y Wu; S Xie; R B Girshick"}, {"ref_id": "b12", "title": "Co-teaching: Robust training of deep neural networks with extremely noisy labels", "journal": "NeurIPS", "year": "2018", "authors": "B Han; Q Yao; X Yu; G Niu; M Xu; W Hu; I W Tsang; M Sugiyama"}, {"ref_id": "b13", "title": "Mixmatch: A holistic approach to semi-supervised learning", "journal": "NeurIPS", "year": "2019", "authors": "D Berthelot; N Carlini; I J Goodfellow; N Papernot; A Oliver; C Raffel"}, {"ref_id": "b14", "title": "Dividemix: Learning with noisy labels as semi-supervised learning", "journal": "", "year": "2020", "authors": "J Li; R Socher; S C H Hoi"}, {"ref_id": "b15", "title": "Pseudo-labeling and confirmation bias in deep semisupervised learning", "journal": "", "year": "", "authors": "E Arazo; D Ortego; P Albert; N E O'connor; K Mcguinness"}, {"ref_id": "b16", "title": "Learning multiple layers of features from tiny images", "journal": "", "year": "2009", "authors": "A Krizhevsky; G Hinton"}, {"ref_id": "b17", "title": "Progressive identification of true labels for partial-label learning", "journal": "PMLR", "year": "2020", "authors": "J Lv; M Xu; L Feng; G Niu; X Geng; M Sugiyama"}, {"ref_id": "b18", "title": "Leveraged weighted loss for partial label learning", "journal": "PMLR", "year": "2021", "authors": "H Wen; J Cui; H Hang; J Liu; Y Wang; Z Lin"}, {"ref_id": "b19", "title": "Provably consistent partial-label learning", "journal": "", "year": "2020", "authors": "L Feng; J Lv; B Han; M Xu; G Niu; X Geng; B An; M Sugiyama"}, {"ref_id": "b20", "title": "Learning with multiple complementary labels", "journal": "PMLR", "year": "2020", "authors": "L Feng; T Kaneko; B Han; G Niu; B An; M Sugiyama"}, {"ref_id": "b21", "title": "Generalized cross entropy loss for training deep neural networks with noisy labels", "journal": "NeurIPS", "year": "2018", "authors": "Z Zhang; M R Sabuncu"}, {"ref_id": "b22", "title": "Randaugment: Practical data augmentation with no separate search", "journal": "CoRR", "year": "1909", "authors": "E D Cubuk; B Zoph; J Shlens; Q V Le"}, {"ref_id": "b23", "title": "Visualizing data using t-sne", "journal": "Journal of machine learning research", "year": "2008", "authors": "L Van Der Maaten; G Hinton"}, {"ref_id": "b24", "title": "Mopro: Webly supervised learning with momentum prototypes", "journal": "", "year": "2021", "authors": "J Li; C Xiong; S C H Hoi"}, {"ref_id": "b25", "title": "Caltech-UCSD Birds 200", "journal": "", "year": "2010", "authors": "P Welinder; S Branson; T Mita; C Wah; F Schroff; S Belongie; P Perona"}, {"ref_id": "b26", "title": "Clustering on the unit hypersphere using von mises-fisher distributions", "journal": "J. Mach. Learn. Res", "year": "2005", "authors": "A Banerjee; I S Dhillon; J Ghosh; S Sra"}, {"ref_id": "b27", "title": "Solving the partial label learning problem: An instance-based approach", "journal": "AAAI Press", "year": "2015", "authors": "M Zhang; F Yu"}, {"ref_id": "b28", "title": "Learning with multiple labels", "journal": "MIT Press", "year": "2002", "authors": "R Jin; Z Ghahramani"}, {"ref_id": "b29", "title": "Classification with partial labels", "journal": "ACM", "year": "2008", "authors": "N Nguyen; R Caruana"}, {"ref_id": "b30", "title": "Online partial label learning", "journal": "Springer", "year": "2020", "authors": "H Wang; Y Qiang; C Chen; W Liu; T Hu; Z Li; G Chen"}, {"ref_id": "b31", "title": "Adaptive graph guided disambiguation for partial label learning", "journal": "ACM", "year": "2019", "authors": "D Wang; L Li; M Zhang"}, {"ref_id": "b32", "title": "Partial label learning via label enhancement", "journal": "AAAI Press", "year": "2019", "authors": "N Xu; J Lv; X Geng"}, {"ref_id": "b33", "title": "Representation learning with contrastive predictive coding", "journal": "", "year": "2018", "authors": "A Van Den Oord; Y Li; O Vinyals"}, {"ref_id": "b34", "title": "A simple framework for contrastive learning of visual representations", "journal": "PMLR", "year": "2020", "authors": "T Chen; S Kornblith; M Norouzi; G E Hinton"}, {"ref_id": "b35", "title": "NGC: A unified framework for learning with open-world noisy data", "journal": "CoRR", "year": "2021", "authors": "Z Wu; T Wei; J Jiang; C Mao; M Tang; Y Li"}, {"ref_id": "b36", "title": "Comatch: Semi-supervised learning with contrastive graph regularization", "journal": "", "year": "2011", "authors": "J Li; C Xiong; S C H Hoi"}, {"ref_id": "b37", "title": "Semisupervised contrastive learning with similarity co-calibration", "journal": "CoRR", "year": "2021", "authors": "Y Zhang; X Zhang; R C Qiu; J Li; H Xu; Q Tian"}, {"ref_id": "b38", "title": "A survey of label-noise representation learning: Past, present and future", "journal": "CoRR", "year": "2011", "authors": "B Han; Q Yao; T Liu; G Niu; I W Tsang; J T Kwok; M Sugiyama"}, {"ref_id": "b39", "title": "Symmetric cross entropy for robust learning with noisy labels", "journal": "IEEE", "year": "2019", "authors": "Y Wang; X Ma; Z Chen; Y Luo; J Yi; J Bailey"}, {"ref_id": "b40", "title": "Can cross entropy loss be robust to label noise?", "journal": "", "year": "2020", "authors": "L Feng; S Shu; Z Lin; F Lv; L Li; B An"}, {"ref_id": "b41", "title": "Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels", "journal": "PMLR", "year": "2018", "authors": "L Jiang; Z Zhou; T Leung; L Li; L Fei-Fei"}, {"ref_id": "b42", "title": "Learning to reweight examples for robust deep learning", "journal": "PMLR", "year": "2018", "authors": "M Ren; W Zeng; B Yang; R Urtasun"}, {"ref_id": "b43", "title": "Metaweight-net: Learning an explicit mapping for sample weighting", "journal": "NeurIPS", "year": "2019", "authors": "J Shu; Q Xie; L Yi; Q Zhao; S Zhou; Z Xu; D Meng"}, {"ref_id": "b44", "title": "Learning with noisy labels", "journal": "", "year": "2013", "authors": "N Natarajan; I S Dhillon; P Ravikumar; A Tewari"}, {"ref_id": "b45", "title": "Making deep neural networks robust to label noise: A loss correction approach", "journal": "IEEE Computer Society", "year": "2017", "authors": "G Patrini; A Rozza; A K Menon; R Nock; L Qu"}, {"ref_id": "b46", "title": "Dual T: reducing estimation error for transition matrix in labelnoise learning", "journal": "", "year": "2020", "authors": "Y Yao; T Liu; B Han; M Gong; J Deng; G Niu; M Sugiyama"}, {"ref_id": "b47", "title": "Sample selection with uncertainty of losses for learning with noisy labels", "journal": "", "year": "2022", "authors": "X Xia; T Liu; B Han; M Gong; J Yu; G Niu; M Sugiyama"}, {"ref_id": "b48", "title": "Combating noisy labels by agreement: A joint training method with co-regularization", "journal": "", "year": "", "authors": "H Wei; L Feng; X Chen; B An"}, {"ref_id": "b49", "title": "Understanding deep learning requires rethinking generalization", "journal": "", "year": "2017", "authors": "C Zhang; S Bengio; M Hardt; B Recht; O Vinyals"}, {"ref_id": "b50", "title": "SELF: learning to filter noisy labels with selfensembling", "journal": "", "year": "2020", "authors": "D T Nguyen; C K Mummadi; T Ngo; T H P Nguyen; L Beggel; T Brox"}, {"ref_id": "b51", "title": "Convergence properties of the k-means algorithms", "journal": "MIT Press", "year": "1994", "authors": "L Bottou; Y Bengio"}, {"ref_id": "b52", "title": "Prototypical contrastive learning of unsupervised representations", "journal": "", "year": "2021", "authors": "J Li; P Zhou; C Xiong; S C H Hoi"}, {"ref_id": "b53", "title": "A theoretical analysis of contrastive unsupervised representation learning", "journal": "PMLR", "year": "2019", "authors": "N Saunshi; O Plevrakis; S Arora; M Khodak; H Khandeparkar"}, {"ref_id": "b54", "title": "Unsupervised learning of visual features by contrasting cluster assignments", "journal": "", "year": "2020", "authors": "M Caron; I Misra; J Mairal; P Goyal; P Bojanowski; A Joulin"}, {"ref_id": "b55", "title": "A baseline for detecting misclassified and out-of-distribution examples in neural networks", "journal": "", "year": "2017", "authors": "D Hendrycks; K Gimpel"}, {"ref_id": "b56", "title": "Fixmatch: Simplifying semisupervised learning with consistency and confidence", "journal": "", "year": "2020", "authors": "K Sohn; D Berthelot; N Carlini; Z Zhang; H Zhang; C Raffel; E D Cubuk; A Kurakin; C Li"}, {"ref_id": "b57", "title": "Prototypical networks for few-shot learning", "journal": "", "year": "2017", "authors": "J Snell; K Swersky; R S Zemel"}, {"ref_id": "b58", "title": "Attribute prototype network for zero-shot learning", "journal": "", "year": "2020-12-06", "authors": "W Xu; Y Xian; J Wang; B Schiele; Z Akata"}, {"ref_id": "b59", "title": "Attention-based prototypical learning towards interpretable, confident and robust deep neural networks", "journal": "CoRR", "year": "1902", "authors": "S \u00d6 Arik; T Pfister"}, {"ref_id": "b60", "title": "Unsupervised semantic aggregation and deformable template matching for semi-supervised learning", "journal": "", "year": "", "authors": "T Han; J Gao; Y Yuan; Q Wang"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Fig. 1 .1Fig. 1. An input image with three candidate labels, where the ground-truth is Malamute.", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Fig. 2 .2Fig. 2. Illustration of PiCO. The classifier's output is used to determine the positive peers for contrastive learning. The contrastive prototypes are then used to gradually update the pseudo target. The momentum embeddings are maintained by a queue structure. '//' means stop gradient.", "figure_data": ""}, {"figure_label": "9101718", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "9 \u00b5c= 10 P 17 momentum update g by using g 18 enqueue9101718Normalize(\u03b3\u00b5c + (1 \u2212 \u03b3)qi), if\u1ef9i = c // positive set generation (xi) = {k |k \u2208 A(xi),\u1ef9 =\u1ef9i} 11 end // prototype-based label disambiguation 12 for qi \u2208 Bq do 13 zi = OneHot(arg maxj\u2208Y i q i \u00b5j) 14 si = \u03c6si + (1 \u2212 \u03c6)zi 15 end // network updating 16 minimize loss L pico = L cls + \u03bbLcont // update the key network and momentum queue B k and classifier predictions and dequeue 19 end", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Fig. 3 .3Fig. 3. T-SNE visualization of the image representation on CIFAR-10 (q = 0.5). Different colors represent the corresponding classes.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Fig. 4. (a) Performance of PiCO with varying moving-average factor \u03c6 on CIFAR-100 (q = 0.05). (c) Performance of PiCO+ with varying neighbor number k on CIFAR-10 (q = 0.5, \u03b7 = 0.2) and CIFAR-100 (q = 0.05, \u03b7 = 0.2). (b) Performance of PiCO+ with varying semi-supervised loss weighting factor \u03b2 on CIFAR-10 (q = 0.5, \u03b7 = 0.2).", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Fig. 5 .5Fig. 5. T-SNE visualization of the image representation on noisy PLL version of CIFAR-10 (q = 0.5, \u03b7 = 0.2). Different colors represent the corresponding classes.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Effect of sample selection. We first study the effectiveness of our distance-based selection mechanism by comparing PiCO+ with two variants: 1) PiCO+ with Small Loss selects clean examples by sorting cross-entropy losses; 2) PiCO+ with Only Clean employs the clean samples to run a simple PiCO method. As reported in Table 4, PiCO+ with only clean data exhibits better performance than the vanilla PiCO method (e.g. +7.56%) on CIFAR-10, indicates the selected examples enjoy high purity. Moreover, PiCO+ with Small Loss underperforms PiCO+, which verifies that the loss values are indeed less informative in the presence of candidate labels and that our strategy is a better alternative. Effect of semi-supervised contrastive training. Next, we explore the effect of each component in SSL training. We compare PiCO+ with three variants: 1) PiCO+ w/o L n-cls removes the label guessing technique; 2) PiCO+ w/o L n-cont removes the label-driven contrastive loss; 3) PiCO+ w/o kNN disables the neighbor-augmented contrastive loss;", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "\u03b8,we can get the following derivation from Eq. (16), log P (x i |y i , \u03b8)P (yi ) i = y i ) log P (x i |y i , \u03b8) = arg max \u03b8 Sj \u2208D C x\u2208Sj log P (x|y = j, \u03b8) = arg max \u03b8 Sj \u2208D C x\u2208Sj (\u03ba\u03bc j g(x) + log(c d (\u03ba)))", "figure_data": ""}, {"figure_label": "7", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "Fig. 7 .7Fig. 7. More ablation results on CIFAR-10 (q = 0.5) and CIFAR-100 (q = 0.05). (a) Performance of PiCO with varying \u03c6. (b) Performance of PiCO with varying \u03bb.", "figure_data": ""}, {"figure_label": "8", "figure_type": "figure", "figure_id": "fig_10", "figure_caption": "Fig. 8 .8Fig. 8. The mean max confidence curves of different label disambiguation strategies.", "figure_data": ""}, {"figure_label": "2891113141722", "figure_type": "figure", "figure_id": "fig_12", "figure_caption": "Algorithm 2 : 8 B 9 run 11 P 13 for 14 P 17 for 22 calculate2891113141722Pseudo-code of PiCO+. 1 Input: Training dataset D, selection ratio \u03b4, number of nearest neighbors k, beta distribution shape parameter \u03c2, loss weighting factors \u03b1, \u03b2. 2 warm up by running PiCO on D 3 for epoch = 1, 2, . . . , do 4 split a clean set by D clean = {(xi, Yi)|q i \u00b5\u1ef9 i > \u03ba \u03b4 } 5 set D noisy = D\\D clean 6 for iter = 1, 2, . . . , do 7 sample a mini-batch B from D clean = B \u2229 D clean , B noisy = B \u2229 D noisy PiCO on B clean to get loss L clean 10 for xi \u2208 B do // label-driven positive set noisy (xi) = {k |k \u2208 A(xi),\u0177 i =\u0177i} 12 end xi \u2208 B noisy do // neighbors-based positive set knn (xi) = {k |k \u2208 A(xi) \u2229 N k (xi)} // label guessing 15 s ij = exp(q i \u00b5 j /\u03c4 ) L t=1 exp(q i \u00b5 t /\u03c4 ) , \u22001 \u2264 j \u2264 L 16 end (xi, (xj) \u2208 B do 18 \u03c3 \u223c Beta(\u03c2, \u03c2) // mixup samples and pseudo-targets 19 x m ij = \u03c3Aug q (xi) + (1 \u2212 \u03c3)Aug q (xj) 20 s m ij = \u03c3\u015di + (1 \u2212 \u03c3)\u015dj 21 end Ln-cont, L knn , L n-cls , L mix 23 minimize loss L pico+ = L mix +\u03b1L clean +\u03b2(Ln-cont +L knn +L n-cls )", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "Training dataset D, classifier f , query network g, key network g , momentum queue, uniform pseudo-labels si associated with xi in D, class prototypes \u00b5j (1 \u2264 j \u2264 C). 2 for iter = 1, 2, . . . , do 3 sample a mini-batch B from D // query and key embeddings generation", "figure_data": "4"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "Similarly, we would also like to identify the true labels on noisy examples to enhance the classifier training. Although the noisy examples are treated as unlabeled, it is not appropriate to directly set their labels to uniform labels1 ", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Accuracy comparisons on standard PLL datasets. Bold indicates superior results. Notably, PiCO+ achieves comparable results to the fully supervised learning (less than 1% in accuracy with \u2248 1 false candidate).", "figure_data": "DatasetMethodq = 0.1q = 0.3q = 0.5PiCO+ (ours)95.99 \u00b1 0.03%95.73 \u00b1 0.10%95.33 \u00b1 0.06%PiCO (ours)94.39 \u00b1 0.18%94.18 \u00b1 0.12%93.58 \u00b1 0.06%LWS90.30 \u00b1 0.60%88.99 \u00b1 1.43%86.16 \u00b1 0.85%CIFAR-10PRODEN90.24 \u00b1 0.32%89.38 \u00b1 0.31%87.78 \u00b1 0.07%CC82.30 \u00b1 0.21%79.08 \u00b1 0.07%74.05 \u00b1 0.35%MSE79.97 \u00b1 0.45%75.64 \u00b1 0.28%67.09 \u00b1 0.66%EXP79.23 \u00b1 0.10%75.79 \u00b1 0.21%70.34 \u00b1 1.32%DatasetMethodq = 0.01q = 0.05q = 0.1PiCO+ (ours)76.29 \u00b1 0.42%76.17 \u00b1 0.18%75.55 \u00b1 0.21%PiCO (ours)73.09 \u00b1 0.34%72.74 \u00b1 0.30%69.91 \u00b1 0.24%LWS65.78 \u00b1 0.02%59.56 \u00b1 0.33%53.53 \u00b1 0.08%CIFAR-100PRODEN62.60 \u00b1 0.02%60.73 \u00b1 0.03%56.80 \u00b1 0.29%CC49.76 \u00b1 0.45%47.62 \u00b1 0.08%35.72 \u00b1 0.47%MSE49.17 \u00b1 0.05%46.02 \u00b1 1.82%43.81 \u00b1 0.49%EXP44.45 \u00b1 1.50%41.05 \u00b1 1.40%29.27 \u00b1 2.81%Finally, we aggregate the above losses together,"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "", "figure_data": ""}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "", "figure_data": ""}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_8", "figure_caption": "", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_9", "figure_caption": "These supervised results are evaluated with mixup like PiCO+ and thus are different from Table2. It is slightly smaller than PiCO+ in Table1(q = 0.1) because of randomized running, but they have no statistically significant difference.", "figure_data": "n-clsL n-contkNNMixupCIFAR-10CIFAR-100PiCO+All Data92.5972.98PiCO+ with Small LossAll Data91.2272.54PiCO+ with Only CleanOnly Clean87.6370.72PiCO+ w/o L n-clsAll Data91.1471.98PiCO+ w/o L n-contAll Data90.8772.89PiCO+ w/o kNNAll Data87.4371.19PiCO+ w/o MixupNo Mixup89.6768.51Fully-Supervised+  \u2020---All Data95.9676.36\u2020 (a) PRODEN features(b) PiCO features(c) PiCO+ features (ours)"}, {"figure_label": "5", "figure_type": "table", "figure_id": "tab_10", "figure_caption": "Accuracy comparisons on noisy PLL datasets with more noisy samples. Bold indicates superior results.", "figure_data": "MethodCIFAR-10 (q = 0.5)CIFAR-100 (q = 0.05)\u03b7 = 0.3\u03b7 = 0.4\u03b7 = 0.3\u03b7 = 0.4\u03b7 = 0.5PiCO+ (ours)90.12 \u00b1 0.51%76.09 \u00b1 3.62%70.46 \u00b1 0.51%66.41 \u00b1 0.58%60.50 \u00b1 0.99%PiCO (ours)64.79 \u00b1 2.08%34.59 \u00b1 7.26%52.18 \u00b1 0.52%44.17 \u00b1 0.08%35.51 \u00b1 1.14%PRODEN50.32 \u00b1 1.07%29.68 \u00b1 13.29%39.19 \u00b1 0.20%33.64 \u00b1 0.82%26.91 \u00b1 0.83%"}, {"figure_label": "6", "figure_type": "table", "figure_id": "tab_11", "figure_caption": "Accuracy comparisons on fine-grained classification datasets with standard PLL labels.", "figure_data": "MethodCUB-200 (q = 0.05)CIFAR-100-H (q = 0.5)PiCO+72.05 \u00b1 0.80%75.38 \u00b1 0.52%PiCO72.17 \u00b1 0.72%72.04 \u00b1 0.31%LWS39.74 \u00b1 0.47%57.25 \u00b1 0.02%PRODEN62.56 \u00b1 0.10%60.89 \u00b1 0.03%CC55.61 \u00b1 0.02%42.60 \u00b1 0.11%MSE22.07 \u00b1 2.36%39.52 \u00b1 0.28%EXP9.44 \u00b1 2.32%35.08 \u00b1 1.71%"}, {"figure_label": "5", "figure_type": "table", "figure_id": "tab_12", "figure_caption": "", "figure_data": ""}, {"figure_label": "7", "figure_type": "table", "figure_id": "tab_13", "figure_caption": "Accuracy comparisons on fine-grained classification datasets with noisy PLL labels.", "figure_data": "MethodCUB-200 (q = 0.05, \u03b7 = 0.2)CIFAR-100-H (q = 0.5, \u03b7 = 0.2)PiCO+60.65 \u00b1 0.79%68.31 \u00b1 0.47%PiCO53.05 \u00b1 2.03%59.81 \u00b1 0.25%LWS18.65 \u00b1 2.15%22.18 \u00b1 6.12%PRODEN44.74 \u00b1 2.47%48.03 \u00b1 0.47%CC26.98 \u00b1 1.16%34.57 \u00b1 0.99%MSE20.92 \u00b1 1.20%35.20 \u00b1 1.03%EXP2.81 \u00b1 14.46%20.80 \u00b1 4.62%GCE5.13 \u00b1 38.65%33.21 \u00b1 2.03%"}, {"figure_label": "8", "figure_type": "table", "figure_id": "tab_14", "figure_caption": "Performance of PiCO with varying \u03b3 on CIFAR-10 (q = 0.5) and CIFAR-100 (q = 0.05).", "figure_data": "Dataset\u03b3 = 0.10.50.90.990.999CIFAR-1093.6193.51 93.52 93.5893.66CIFAR-10072.8773.09 72.54 72.7467.33TABLE 9"}, {"figure_label": "10", "figure_type": "table", "figure_id": "tab_15", "figure_caption": "Accuracy comparisons on fine-grained datasets. Bold indicates superior results. \u00b1 0.23% LWS 62.41 \u00b1 0.03% 57.25 \u00b1 0.02% 20.64 \u00b1 0.48% PRODEN 62.91 \u00b1 0.01% 60.89 \u00b1 0.03% 43.64 \u00b1 1.82% CC 50.40 \u00b1 0.20% 42.60 \u00b1 0.11% 37.80 \u00b1 0.09% MSE 46.05 \u00b1 0.17% 39.52 \u00b1 0.28% 15.18 \u00b1 0.", "figure_data": "DatasetMethodq = 0.1q = 0.5q = 0.8CIFAR-100-HPiCO (ours)73.41 \u00b1 0.27%72.04 \u00b1 0.31%66.17 73%EXP45.73 \u00b1 0.22%35.08 \u00b1 1.71%22.31 \u00b1 0.39%DatasetMethodq = 0.01q = 0.05q = 0.1PiCO (ours)74.14 \u00b1 0.24%72.17 \u00b1 0.72%62.02 \u00b1 1.16%LWS73.74 \u00b1 0.23%39.74 \u00b1 0.47%12.30 \u00b1 0.77%PRODEN72.34 \u00b1 0.04%62.56 \u00b1 0.10%35.89 \u00b1 0.05%CUB-200CC56.63 \u00b1 0.01%55.61 \u00b1 0.02%17.01 \u00b1 1.44%MSE61.12 \u00b1 0.51%22.07 \u00b1 2.36%11.40 \u00b1 2.42%EXP55.62 \u00b1 2.25%9.44 \u00b1 2.32%7.3 \u00b1 0.99%Fully Supervised76.02 \u00b1 0.19%1.00.3 0.4 0.5 0.6 0.7 0.8 0.9 Mean Max ConfidencePiCO One-Hot Prototype Soft Prototype Probs MA Soft Prototype Probs0.2Epoch 0 100 200 300 400 500 600 700 800"}, {"figure_label": "11", "figure_type": "table", "figure_id": "tab_16", "figure_caption": "", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_17", "figure_caption": "training epochs. First, we can observe the MMC score of PiCO smoothly increases and finally achieves near 1 results, which means most of the labels are well disambiguated. In contrast, the Soft Prototype Probs strategy oscillates at the beginning, and then also increases to a certain value, which means that directly adopting the soft class probability also helps disambiguation. But, it is worth noting that it ends with a smaller MMC score compared with PiCO. The reason might be that the cosine distances to non-ground-truth prototypes are still at a scale. Hence, the Soft Prototype Probs strategy always holds a certain degree of ambiguity. Finally, we can see that the MA Soft Prototype Probs strategy fails to achieve great disambiguation ability. Compared with the non-movingaverage version, it fails to get rid of severe label ambiguity and will finally converge to uniform pseudo targets again.Furthermore, we evaluated the accuracy of the pseudo targets over training examples. From Table", "figure_data": "CIFAR-1067.4176.16 92.77 92.59 90.92CIFAR-10075.4674.83 73.93 72.98 69.75strategies in different"}, {"figure_label": "12", "figure_type": "table", "figure_id": "tab_18", "figure_caption": "Accuracy comparisons with different data generation processes on CIFAR-10. \u00b1 0.08% 94.11 \u00b1 0.25% LWS 90.78 \u00b1 0.01% 68.37 \u00b1 0.04% PRODEN 90.53 \u00b1 0.01% 87.02 \u00b1 0.02% CC 75.81 \u00b1 0.13% 66.51 \u00b1 0.11% MSE 68.11 \u00b1 0.23% 39.49 \u00b1 0.41% EXP 71.62 \u00b1 0.79% 48.87 \u00b1 2.32% and wrong selection.", "figure_data": "MethodCase (1)Case (2)PiCO94.49"}, {"figure_label": "13", "figure_type": "table", "figure_id": "tab_19", "figure_caption": "Training time (min/epoch) and accuracy of different prototype calculation methods. averaging embeddings of all training examples at the end of each epoch. We train the models using one Quadro P5000 GPU respectively and evaluate the average training time per epoch. From Table 13, we can observe that the Re-Compute variant achieves competitive results, but is much slower than PiCO.", "figure_data": "DatasetMethodTime AccuracyCIFAR-10PiCO0.9493.58(q = 0.5)Re-Compute 1.3993.55CIFAR-100PiCO0.9672.74(q = 0.05)Re-Compute 1.4072.35the prototypes by"}], "formulas": [{"formula_id": "formula_0", "formula_text": "L cls (f ; x i , Y i ) = C j=1 \u2212s i,j log(f j (x i )) s.t. j\u2208Yi s i,j = 1 and s i,j = 0, \u2200j / \u2208 Y i ,(1)", "formula_coordinates": [2.0, 352.48, 680.06, 211.52, 39.29]}, {"formula_id": "formula_1", "formula_text": "A = B q \u222a B k \u222a queue,(2)", "formula_coordinates": [3.0, 390.02, 353.31, 173.98, 9.65]}, {"formula_id": "formula_2", "formula_text": "L cont (g; x, \u03c4, A) = \u2212 1 |P (x)| k+\u2208P (x) log exp(q k + /\u03c4 ) k \u2208A(x) exp(q k /\u03c4 ) ,(3)", "formula_coordinates": [3.0, 312.22, 431.61, 251.78, 41.78]}, {"formula_id": "formula_3", "formula_text": "P (x) = {k |k \u2208 A(x),\u1ef9 =\u1ef9}.(4)", "formula_coordinates": [3.0, 371.09, 573.25, 192.91, 9.67]}, {"formula_id": "formula_4", "formula_text": "L pico = L cls + \u03bbL cont .(5)", "formula_coordinates": [3.0, 393.5, 735.65, 170.5, 10.18]}, {"formula_id": "formula_5", "formula_text": "s = \u03c6s + (1 \u2212 \u03c6)z, z c =", "formula_coordinates": [4.0, 52.73, 405.92, 111.91, 9.68]}, {"formula_id": "formula_6", "formula_text": "\u00b5 c = Normalize(\u03b3\u00b5 c + (1 \u2212 \u03b3)q), if c = arg max j\u2208Y f j (Aug q (x))),(7)", "formula_coordinates": [4.0, 101.45, 694.09, 198.55, 26.44]}, {"formula_id": "formula_7", "formula_text": "Bq = {qi = g(Aug q (xi))|xi \u2208 B} 5 B k = {ki = g (Aug k (xi))|xi \u2208 B} 6 A = Bq \u222a B k \u222a queue 7 for xi \u2208 B do // classifier prediction 8\u1ef9i = arg maxj\u2208Y i f j (Aug q (xi))", "formula_coordinates": [4.0, 318.77, 131.4, 160.8, 61.45]}, {"formula_id": "formula_8", "formula_text": "D clean = {(x i , Y i )|q i \u00b5\u1ef9 i > \u03ba \u03b4 },(8)", "formula_coordinates": [5.0, 106.99, 339.47, 193.02, 10.65]}, {"formula_id": "formula_9", "formula_text": "P noisy (x) = {k |k \u2208 A(x),\u0177 =\u0177}, where\u0177 = \uf8f1 \uf8f2 \uf8f3 arg max 1\u2264j\u2264L f j (Aug q (x))) if x \u2208 D noisy , arg max j\u2208Y f j (Aug q (x))) else.(9)", "formula_coordinates": [5.0, 321.22, 86.18, 242.79, 48.91]}, {"formula_id": "formula_10", "formula_text": "P knn (x) = {k |k \u2208 A(x) \u2229 N k (x)},(10)", "formula_coordinates": [5.0, 362.08, 302.24, 201.92, 10.18]}, {"formula_id": "formula_11", "formula_text": "N k (x)", "formula_coordinates": [5.0, 340.48, 322.87, 27.39, 9.65]}, {"formula_id": "formula_12", "formula_text": "s j = exp(q \u00b5 j /\u03c4 ) L t=1 exp(q \u00b5 t /\u03c4 ) , \u22001 \u2264 j \u2264 L.(11)", "formula_coordinates": [5.0, 352.23, 526.15, 211.77, 26.07]}, {"formula_id": "formula_13", "formula_text": "x m = \u03c3Aug q (x i ) + (1 \u2212 \u03c3)Aug q (x j ), s m = \u03c3\u015d i + (1 \u2212 \u03c3)\u015d j ,(12)", "formula_coordinates": [5.0, 357.44, 655.34, 206.56, 27.22]}, {"formula_id": "formula_14", "formula_text": "L pico+ = L mix + \u03b1L clean + \u03b2(L n-cont + L knn + L n-cls ), (13", "formula_coordinates": [6.0, 57.95, 333.1, 238.1, 10.17]}, {"formula_id": "formula_15", "formula_text": ")", "formula_coordinates": [6.0, 296.04, 333.63, 3.96, 9.14]}, {"formula_id": "formula_16", "formula_text": "\u03b7 = 0.1 \u03b7 = 0.2 \u03b7 = 0.1 \u03b7 = 0.2 CIFAR-", "formula_coordinates": [8.0, 92.81, 97.29, 414.88, 66.57]}, {"formula_id": "formula_17", "formula_text": "\u03b7 = 0.1 \u03b7 = 0.2 \u03b7 = 0.1 \u03b7 = 0.2 CIFAR-", "formula_coordinates": [8.0, 90.44, 227.96, 417.26, 66.57]}, {"formula_id": "formula_18", "formula_text": "Lcont(g; \u03c4, D) = 1 n x\u2208D \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 \u2212 1 |P (x)| k + \u2208P(x) log exp(q k+/\u03c4 ) k \u2208A(x) exp(q k /\u03c4 ) \uf8fc \uf8f4 \uf8fd \uf8f4 \uf8fe = 1 n x\u2208D \uf8f1 \uf8f2 \uf8f3 \u2212 1 |P (x)| k + \u2208P (x) (q k+/\u03c4 ) \uf8fc \uf8fd \uf8fe (a) + 1 n x\u2208D \uf8f1 \uf8f2 \uf8f3 log k \u2208A(x) exp(q k /\u03c4 ) \uf8fc \uf8fd \uf8fe (b) . (14", "formula_coordinates": [11.0, 51.43, 198.48, 245.14, 155.68]}, {"formula_id": "formula_19", "formula_text": ")", "formula_coordinates": [11.0, 296.25, 345.5, 3.75, 8.66]}, {"formula_id": "formula_20", "formula_text": "(a) = 1 n x\u2208D 1 |P (x)| k+\u2208P (x) (||q \u2212 k + || 2 \u2212 2)/(2\u03c4 ) \u2248 1 2\u03c4 n Sj \u2208D C 1 |S j | x,x \u2208Sj ||g(x) \u2212 g(x )|| 2 + K = 1 \u03c4 n Sj \u2208D C x\u2208Sj ||g(x) \u2212 \u00b5 j || 2 + K, (15", "formula_coordinates": [11.0, 52.73, 471.5, 243.31, 82.97]}, {"formula_id": "formula_21", "formula_text": ")", "formula_coordinates": [11.0, 296.04, 545.34, 3.96, 9.14]}, {"formula_id": "formula_22", "formula_text": "1 |Sj | \u2248 1 |Sj |\u22121 = 1 |P (x)|", "formula_coordinates": [11.0, 122.42, 572.71, 96.75, 13.47]}, {"formula_id": "formula_23", "formula_text": "j i \u2265 0 (1 \u2264 i \u2264 n, 1 \u2264 j \u2264 C) such that \u03c0 j i = 0 if j / \u2208 Y i and j\u2208Yi \u03c0 j i = 1.", "formula_coordinates": [11.0, 312.0, 169.72, 252.0, 25.77]}, {"formula_id": "formula_24", "formula_text": "\u03b8 n i=1 log P (Y i , x i |\u03b8) = argmax \u03b8 n i=1 log yi\u2208Yi P (x i , y i |\u03b8)+ n i=1 log( (Y i )) = argmax \u03b8 n i=1 log yi\u2208Yi \u03c0 yi i P (x i , y i |\u03b8) \u03c0 yi i \u2265 argmax \u03b8 n i=1 yi\u2208Yi \u03c0 yi i log P (x i , y i |\u03b8) \u03c0 yi i . (16", "formula_coordinates": [11.0, 318.9, 221.2, 241.14, 104.68]}, {"formula_id": "formula_25", "formula_text": ")", "formula_coordinates": [11.0, 560.04, 316.74, 3.96, 9.14]}, {"formula_id": "formula_26", "formula_text": "P (xi,yi|\u03b8) \u03c0 y i i", "formula_coordinates": [11.0, 422.93, 355.32, 36.61, 16.97]}, {"formula_id": "formula_27", "formula_text": "\u03c0 yi i = P (x i , y i |\u03b8) yi\u2208Yi P (x i , y i |\u03b8) = P (x i , y i |\u03b8) P (x i |\u03b8) = P (y i |x i , \u03b8),(17)", "formula_coordinates": [11.0, 322.5, 387.42, 241.5, 35.25]}, {"formula_id": "formula_28", "formula_text": "R 1 = Sj \u2208D C n j n ||\u00b5 j || 2 \u2264 Sj \u2208D C n j n ||\u00b5 j || = R 2 . (18", "formula_coordinates": [12.0, 53.76, 104.01, 242.29, 22.31]}, {"formula_id": "formula_29", "formula_text": ")", "formula_coordinates": [12.0, 296.04, 111.85, 3.96, 9.14]}, {"formula_id": "formula_30", "formula_text": "LHS = 1 2n j x\u2208Sj x \u2208Sj (||g(x)|| 2 \u2212 2g(x) g(x ) + ||g(x )|| 2 ) = 1 n j x\u2208Sj (n j \u2212 g(x) ( x \u2208Sj g(x ))) = 1 n j x\u2208Sj (n j \u2212 g(x) (n j \u00b5 j ))) = n j \u2212 ( x\u2208Sj g(x)) \u00b5 j ) = n j (1 \u2212 ||\u00b5 j || 2 ).(19)", "formula_coordinates": [14.0, 48.02, 452.41, 251.98, 126.86]}, {"formula_id": "formula_31", "formula_text": "RHS = x\u2208Sj (||g(x)|| 2 \u2212 2g(x) \u00b5 j + ||\u00b5 j || 2 ) = (n j \u2212 2( x\u2208Sj g(x)) \u00b5 j + n j ||\u00b5 j || 2 ) = n j (1 \u2212 ||\u00b5 j || 2 ) = LHS. (20", "formula_coordinates": [14.0, 80.06, 639.95, 215.98, 64.94]}, {"formula_id": "formula_32", "formula_text": ")", "formula_coordinates": [14.0, 296.04, 668.15, 3.96, 9.14]}, {"formula_id": "formula_33", "formula_text": "\u03b8 Sj \u2208D C n j n ||\u00b5 j || (21", "formula_coordinates": [14.0, 365.44, 146.31, 194.61, 91.96]}, {"formula_id": "formula_34", "formula_text": ")", "formula_coordinates": [14.0, 560.04, 146.31, 3.96, 9.14]}, {"formula_id": "formula_35", "formula_text": "arg min \u03b8 Sj \u2208D C x\u2208Sj ||g(x) \u2212 \u00b5 j || 2 = arg min \u03b8 Sj \u2208D C x\u2208Sj (||g(x)|| 2 \u2212 2g(x) \u00b5 j + ||\u00b5 j || 2 ) = arg min \u03b8 Sj \u2208D C (n j \u2212 n j ||\u00b5 j || 2 ) = arg max \u03b8 Sj \u2208D C n j n ||\u00b5 j || 2 . (22", "formula_coordinates": [14.0, 324.55, 311.07, 235.49, 116.99]}, {"formula_id": "formula_36", "formula_text": ")", "formula_coordinates": [14.0, 560.04, 418.92, 3.96, 9.14]}, {"formula_id": "formula_37", "formula_text": "R 1 = Sj \u2208D C n j n ||\u00b5 j || 2 \u2264 Sj \u2208D C n j n ||\u00b5 j || = R 2 . (23", "formula_coordinates": [14.0, 331.98, 471.56, 228.07, 26.97]}, {"formula_id": "formula_38", "formula_text": ")", "formula_coordinates": [14.0, 560.04, 482.81, 3.96, 9.14]}, {"formula_id": "formula_39", "formula_text": "\u03ba \u2248 d \u2212 1 2(1 \u2212 ||\u00b5 j ||)", "formula_coordinates": [15.0, 53.35, 213.03, 72.43, 23.23]}, {"formula_id": "formula_40", "formula_text": "\u03ba \u2248 d||\u00b5 j || 1 + d d + 2 ||\u00b5 j || 2 + d 2 (d + 8) (d + 2) 2 (d + 4) ||\u00b5 j || 4 ,", "formula_coordinates": [15.0, 53.35, 238.88, 241.29, 23.89]}, {"formula_id": "formula_42", "formula_text": "(1) = \uf8ee \uf8ef \uf8ef \uf8ef \uf8f0 1 0.5 0 \u2022 \u2022 \u2022 0 0 1 0.5 \u2022 \u2022 \u2022 0 . . . \u2022 \u2022 \u2022 . . . 0.5 0 0 \u2022 \u2022 \u2022 1 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fb ,(2)", "formula_coordinates": [17.0, 326.78, 490.1, 136.1, 86.85]}, {"formula_id": "formula_43", "formula_text": "\u2022 \u2022 \u2022 1 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fb", "formula_coordinates": [17.0, 516.32, 546.13, 32.9, 50.69]}], "doi": ""}