{"title": "Globally-Optimal Inlier Set Maximisation for Simultaneous Camera Pose and Feature Correspondence", "authors": "Dylan Campbell; Lars Petersson; Laurent Kneip; Hongdong Li", "pub_date": "2017-09-27", "abstract": "Estimating the 6-DoF pose of a camera from a single image relative to a pre-computed 3D point-set is an important task for many computer vision applications. Perspective-n-Point (PnP) solvers are routinely used for camera pose estimation, provided that a good quality set of 2D-3D feature correspondences are known beforehand. However, finding optimal correspondences between 2D key-points and a 3D point-set is non-trivial, especially when only geometric (position) information is known. Existing approaches to the simultaneous pose and correspondence problem use local optimisation, and are therefore unlikely to find the optimal solution without a good pose initialisation, or introduce restrictive assumptions. Since a large proportion of outliers are common for this problem, we instead propose a globally-optimal inlier set cardinality maximisation approach which jointly estimates optimal camera pose and optimal correspondences. Our approach employs branchand-bound to search the 6D space of camera poses, guaranteeing global optimality without requiring a pose prior. The geometry of SE(3) is used to find novel upper and lower bounds for the number of inliers and local optimisation is integrated to accelerate convergence. The evaluation empirically supports the optimality proof and shows that the method performs much more robustly than existing approaches, including on a large-scale outdoor data-set. * This research is supported by an Australian Government Research Training Program (RTP) Scholarship. (a) 3D point-set (grey and green), 3D features (black dots) and groundtruth (black), RANSAC (red) and our (blue) camera poses. The groundtruth and our camera poses coincide, whereas the RANSAC pose has a translation offset and a 180 \u2022 rotation offset. Best viewed in colour. (b) Panoramic photograph and extracted 2D features (top), building points projected onto the image using the RANSAC camera pose (middle) and building points projected using our camera pose (bottom).", "sections": [{"heading": "Introduction", "text": "Estimating the pose of a calibrated camera given a set of 2D points in the camera frame and a set of 3D points in the world frame, as shown in Figure 1, is a fundamental part of the general 2D-3D registration problem of aligning an image with a 3D scene or model. When correspondences are known, this becomes the Perspectiven-Point (PnP) problem for which many solutions exist [16,26,23,18,22]. Applications include camera localisation and tracking [13,38,24], augmented reality [34], motion segmentation [39] and object recognition [19,36,2]. Figure 1. Estimating the pose of a calibrated camera from a single image within a large-scale, unorganised 3D point-set captured by vehicle-mounted laser scanner. Our method solves the absolute pose problem while simultaneously finding feature correspondences, using a globally-optimal branch-and-bound approach with tight novel bounds on the cardinality of the inlier set.\nWhile hypothesise-and-test frameworks like RANSAC [13] can mitigate the sensitivity of PnP solvers to outliers in the correspondence set, few approaches are able to handle the case where 2D-3D correspondences are not known in advance. Unknown correspondences arise in many circumstances, including the general case of aligning an image with a textureless 3D point-set or CAD model. While feature extraction techniques provide a relatively robust and reproducible way to detect interest points such as edges or corners within each modality, finding correspondences across the two modalities is much more challenging. Even when the point-set has sufficient visual information associated with it, such as colour or SIFT features [32], repetitive features, occlusions and perspective distortion make the correspondence problem non-trivial. Moreover, appear-ance and thus visual features may change significantly between viewpoints, lighting conditions, weather and seasons, whereas scene geometry is often less affected. When relocalising a camera in a previously mapped environment or bootstrapping a tracking algorithm, we contend that geometry is often more reliable. Therefore, there is a need for methods that solve for both pose and correspondences.\nEfficient local optimisation algorithms for solving this joint problem have been proposed [9,35]. However, they require a pose prior, search only for local optima and do not provide an optimality guarantee, yielding erroneous pose estimates without a reliable means of detecting failure. Hypothesise-and-test approaches such as RANSAC [13], when applied to the correspondence-free problem [15], are global methods that are not reliant on pose priors but quickly become computationally intractable as the number of points and outliers increase and do not provide an optimality guarantee. More recently, a global andsuboptimal method has been proposed [5], which uses a branch-and-bound approach to find a camera pose whose trimmed geometric error is within of the global minimum.\nThis work is the first to propose a global and optimal inlier set cardinality maximisation solution to the simultaneous pose and correspondence problem. The approach employs the branch-and-bound framework to guarantee global optimality without requiring a pose prior, ensuring that it is not susceptible to local optima. We use a parametrisation of SE(3) space that facilitates branching and derive novel bounds on the objective function. In addition, we also apply local optimisation whenever the algorithm finds a better transformation, to accelerate convergence without voiding the optimality guarantee. Cardinality maximisation allows an exact optimiser to be found, unlike the -suboptimality inherent to the continuous objective function used in [5]. More critically, cardinality maximisation is inherently robust to 2D and 3D outliers, while avoiding the problems associated with trimming. The latter requires the user to specify the inlier fraction, which can rarely be known and is less intuitive to select than a geometrically meaningful inlier threshold. If the inlier fraction is over-or under-estimated, this approach may converge to the wrong pose, without a means to detect failure. Figure 2 demonstrates how the global optimum of a trimmed objective function, as used by [5,49], may not occur at the true pose, a problem that is exacerbated when the inlier fraction is guessed incorrectly.", "publication_ref": ["b16", "b27", "b24", "b18", "b23", "b12", "b39", "b25", "b35", "b40", "b19", "b37", "b1", "b12", "b33", "b8", "b36", "b12", "b15", "b4", "b4", "b4", "b52"], "figure_ref": [], "table_ref": []}, {"heading": "Related Work", "text": "A large body of work exists for solving the 2D-3D registration problem when correspondences are provided. When the correspondences are known perfectly, Perspective-n-Point (PnP) solvers [16,26,23,18,22] are able to estimate the pose of a camera given a set of noisy image points and their corresponding 3D points. When outliers are present in Figure 2. Two zero-error but incorrect 1D alignments of 2 pointsets with 8 trimmed 'outliers'. With noise, the global optimum of a trimmed objective function may not occur at the true pose, particularly if an incorrect trimming fraction is selected. The problem is exacerbated with higher dimensions and degrees of freedom.\nthe correspondence set, the RANSAC framework [13,8] or robust global optimisation [27,11,1,48,12,47] can be used to find the inlier set. Alternatively, outlier removal schemes can make the problem more tractable [46,40,50,7]. Other methods develop sophisticated matching strategies to avoid outlier correspondences at the outset [30,44,45,29]. However, these methods require some correct correspondences. For this reason, they are often only practical for 3D models that have been constructed using stereopsis or Structurefrom-Motion (SfM). These models associate an image feature with each 3D point, facilitating inter-modality feature matching. Generic point-sets do not have this property; a point may lie anywhere on the underlying surfaces in a laser scan, not just where strong image gradients occur.\nWhen correspondences are unknown, the problem becomes more challenging. For the 2D-2D case, problems such as correspondence-free rigid registration [3,4], SfM [10,33,31] and relative camera pose [14] have been addressed. For the 2D-3D case, solution have been proposed for registering a collection of images [43] or multiple cameras [42] to a 3D point-set. The more general problem, however, is pose estimation from a single image. David et al. [9] proposed the SoftPOSIT algorithm, which alternates correspondence assignment with an iterative pose update algorithm. Moreno-Noguer et al. [35] proposed the BlindPnP algorithm, which represents the pose prior as a Gaussian mixture model from which a Kalman filter is initialised for matching. It outperformed SoftPOSIT when large amounts of clutter, occlusions and repetitive patterns were present. However, both are susceptible to local optima, require a pose prior and cannot guarantee global optimality.\nGrimson [15] applied a RANSAC-like approach to the correspondence-free case, removing the need for a pose prior, but the method is not optimal and quickly becomes intractable as the number of points increase. In contrast, globally-optimal methods find a camera pose that is guaranteed to be an optimiser of an error function without requiring a pose prior, but tractability remains a challenge. A Branch-and-Bound (BB) [25] strategy may be applied in these cases, for which bounds need to be derived. For example, Breuel [4] used BB for 2D-2D registration problems, Hartley and Kahl [17] for optimal relative pose estimation by bounding the group of 3D rotations, Li and Hartley [28] for rotation-only 3D-3D registration, Olsson et al. [41] for 3D-3D registration with known correspondences, Yang et al. [49] for full 3D-3D registration and Campbell and Petersson [6] for robust 3D-3D registration. While not optimal, Jurie [20] used an approach similar to BB for 2D-3D alignment with a linear approximation of perspective projection. Brown et al. [5] proposed a global and -suboptimal method using BB. It finds a camera pose whose trimmed geometric error, the sum of angular distances between the bearings and their rotationally-closest 3D points, is within of the global minimum. While not susceptible to local minima, it requires the inlier fraction to be specified, which can rarely be known in advance, in order to trim outliers.\nOur work is the first globally-optimal inlier set cardinality maximisation solution to the simultaneous pose and correspondence problem. It is guaranteed to find the exact global optimum without requiring a pose prior and is robust to 2D and 3D outliers while avoiding the distortion of trimming. The rest of the paper is organised as follows: we introduce the problem formulation in Section 3, develop a parametrisation of the domain of 3D motions, a branching strategy and a derivation of the bounds in Section 4, propose an algorithm for globally-optimal pose and correspondence in Section 5 and evaluate its performance in Section 6.", "publication_ref": ["b16", "b27", "b24", "b18", "b23", "b12", "b7", "b28", "b10", "b0", "b51", "b11", "b50", "b49", "b41", "b53", "b6", "b31", "b46", "b47", "b30", "b2", "b3", "b9", "b34", "b32", "b13", "b44", "b43", "b8", "b36", "b15", "b26", "b3", "b17", "b29", "b42", "b52", "b5", "b20", "b4"], "figure_ref": [], "table_ref": []}, {"heading": "Inlier Set Cardinality Maximisation", "text": "Let p \u2208 R 3 be a 3D point and f \u2208 R 3 be a bearing vector with unit norm, corresponding to a 2D point imaged by a calibrated camera. That is, f \u221d K \u22121x where K is the matrix of intrinsic camera parameters andx is the homogeneous image point. Given a set of points P = {p j } M j=1 and bearing vectors F = {f i } N i=1 and an inlier threshold \u03b8, the objective is to find a rotation R \u2208 SO(3) and translation t \u2208 R 3 that maximises the cardinality \u03bd of the inlier set S I\n\u03bd * = max R, t |S I |(1)\nS I = {f \u2208 F | \u2203p \u2208 P : \u2220(f , R(p \u2212 t)) \u03b8} (2)\nwhere \u2220(\u2022, \u2022) denotes the angular distance between vectors. An equivalent formulation is given by\n\u03bd * = max R, t f (R, t)(3)\nf (R, t) = f \u2208F max p\u2208P 1 \u03b8 \u2212 \u2220(f , R(p \u2212 t))(4)\nwhere 1(x) 1 R \u22650 (x) is the indicator function that has the value 1 for all elements of the non-negative real numbers and the value 0 otherwise. The optimal transformation parameters R * and t * allow us to find all correspondences (f i , p j ) with respect to \u03b8 by identifying all pairs for which \u2220(f i , R * (p j \u2212 t * ))\n\u03b8. We maximise the cardinality of the set of bearing vector inliers, not the set of 3D point inliers, to avoid the degenerate case of all points sharing the same bearing vector inlier, which occurs when the camera is translated far away from the point-set. ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Branch-and-Bound", "text": "To solve the highly non-convex cardinality maximisation problem (1), the global optimisation technique of Branchand-Bound (BB) [25] may be applied. To do so, a suitable means of parametrising and branching (partitioning) the function domain must be found, as well as an efficient way to calculate upper and lower bounds of the function for each branch which converge as the size of the branch tends to zero. While the bounds need to be computationally efficient to calculate, the time and memory efficiency of the algorithm also depends on how tight the bounds are, since tighter bounds reduce the search space quicker by allowing suboptimal branches to be pruned.", "publication_ref": ["b26"], "figure_ref": [], "table_ref": []}, {"heading": "Parametrising and Branching the Domain", "text": "To find a globally-optimal solution, the cardinality of the inlier set S I must be maximised over the domain of 3D motions, that is, the group SE(3) = SO(3)\u00d7R 3 . However, the space of these transformations is unbounded, therefore we restrict the space of translations to be within the bounded set \u2126 t in order to use BB. For a suitably large \u2126 t , it is reasonable to assume that the camera centre lies within \u2126 t . That is, we can assume that the camera is a finite distance from the 3D points. The domains are shown in Figure 3.\nRotation space SO( 3) is minimally parametrised with angle-axis 3-vectors r with rotation angle r and rotation axis r/ r . The notation R r \u2208 SO(3) is used to denote the rotation matrix obtained from the matrix exponential map of the skew-symmetric matrix [r] \u00d7 induced by r. The Rodrigues' rotation formula can be used to efficiently calculate this mapping. Using this parametrisation, the space of all 3D rotations can be represented as a solid ball of radius \u03c0 in R 3 . The mapping is one-to-one on the interior of the \u03c0-ball and two-to-one on the surface. For ease of manipulation, we use the 3D cube circumscribing the \u03c0-ball as the rotation domain \u2126 r [28]. Translation space R 3 is parametrised with 3-vectors in a bounded domain chosen as the cuboid \u2126 t containing the bounding box of P. If the camera is known to be inside the 3D scene, \u2126 t can be set to the bounding box, otherwise it is set to an expansion of the bounding box. During BB, the domain is branched into sub-cuboids using nested octree data structures. They are defined as\nC(c, \u03b4) = {x \u2208 R 3 | e i (x\u2212c) \u2208 [\u2212\u03b4 i , \u03b4 i ], i = 1, 2, 3} (5)\nwhere e i is the i th standard basis vector. To simplify the notation, we use C r = C(r 0 , \u03b4 r ) and C t = C(t 0 , \u03b4 t ).\nThe uncertainty angle induced by a rotation and translation sub-cuboid on a point p is shown in Figure 4. The transformed point may lie anywhere within an uncertainty cone, with aperture angle equal to the sum of the rotation and translation uncertainty angles.", "publication_ref": ["b29"], "figure_ref": ["fig_0", "fig_1"], "table_ref": []}, {"heading": "Bounding the Branches", "text": "The success of a BB algorithm is predicated on the quality of its bounds. For inlier set maximisation, the objective function (4) needs to be bounded within a transformation domain. Some preparatory material is now presented.\nTo bound the uncertainty angle due to rotation, Lemmas 1 and 2 from [17] are used. For reference, the relevant parts are merged into Lemma 1, as in [49]. The lemma indicates that the angle between two rotated vectors is less than or equal to the Euclidean distance between their rotations' angle-axis representations in R 3 . Lemma 1. For an arbitrary vector p and two rotations, represented as R r1 and R r2 in matrix form and r 1 and r 2 in angle-axis form,\n\u2220(R r1 p, R r2 p) r 1 \u2212 r 2 . (6\n)\nFrom this, the maximum angle between a vector p rotated by r 0 and p rotated by r \u2208 C r can be found as follows.\nLemma 2. (Weak rotation uncertainty angle) Given a 3D point p and a rotation cube C r of half side-length \u03b4 r centred at r 0 , then \u2200r \u2208 C r , \u2220(R r p, R r0 p) min( \u221a 3\u03b4 r , \u03c0) \u03c8 w r (C r ).\nProof. Inequality ( 7) can be derived as follows:\n\u2220(R r p, R r0 p) min( r \u2212 r 0 , \u03c0) (8) min( \u221a 3\u03b4 r , \u03c0)(9)\nwhere ( 8) follows from Lemma 1 and the maximum possible angle and ( 9) follows from max r \u2212 r 0 = \u221a 3\u03b4 r (the half space diagonal of the rotation cube) for r \u2208 C r .\nHowever, a tighter bound can be found by observing that a point rotated about an axis parallel to the point is not displaced. To exploit this, we maximise the angle \u2220(R r p, R r0 p) over the surface S r of the cube C r .\nLemma 3. (Rotation uncertainty angle) Given a 3D point p and a rotation cube C r centred at r 0 with surface S r , then\n\u2200r \u2208 C r , \u2220(R r p, R r0 p) min(max r\u2208Sr \u2220(R r p, R r0 p), \u03c0) \u03c8 r (p, C r ).(10)\nProof. Inequality (10) can be derived as follows:\n\u2220(R r p, R r0 p) min(max r\u2208Cr \u2220(R r p, R r0 p), \u03c0)(11)\n= min(max\nr\u2208Sr \u2220(R r p, R r0 p), \u03c0)(12)\nwhere ( 12) is a consequence of the order-preserving mapping, with respect to the radial angle, from the convex cube of angle-axis vectors to the spherical surface patch (see Figure 4a), since the mapping is obtained by projecting from the centre of the sphere to the surface of the sphere. See the appendix for further details.\nThe uncertainty angle due to translation can be bounded by observing that the translated points form a cube (Figure 4b). When the cube does not contain the origin, the angle can be found by maximising over the cube vertices. \nV t , then \u2200t \u2208 C t , \u2220(p \u2212 t, p \u2212 t 0 ) max t\u2208Vt \u2220(p \u2212 t, p \u2212 t 0 ) if p / \u2208 C t \u03c0 else \u03c8 t (p, C t ).(13)\nProof. Observe that for p \u2208 C t , the cube containing all translated points p \u2212 t also contains the origin. Therefore p \u2212 t can be proportional to \u2212(p \u2212 t 0 ) and thus the maximum angle is \u03c0. For p / \u2208 C t , where (15) follows from the convexity of the angle function in this domain. The maximum of a convex function over a convex set must occur at one of its extreme points (the vertices). Geometrically, the cube p \u2212 t projects to a spherical hexagon on the unit sphere. The maximum geodesic from a point in the hexagon to any other is to a vertex.\n\u2220(p \u2212 t, p \u2212 t 0 ) max t\u2208Ct \u2220(p \u2212 t, p \u2212 t 0 ) (14) = max t\u2208Vt \u2220(p \u2212 t, p \u2212 t 0 )(15\nTo avoid the non-physical case where a 3D point is located within a very small value \u03b6 of the camera centre we restrict the translation domain such that \u2126 t = \u2126 t \u2229 {t \u2208 R 3 | p \u2212 t \u03b6, \u2200p \u2208 P}. The translation bound from [5] encloses a translation cube with a sphere of radius \u03c1 t = \u221a 3\u03b4 t and is given by\n\u03c8 w t (p, C t ) arcsin \u03c1t p\u2212t0 if \u03c1 t p \u2212 t 0 \u03c0 else. (16\n)\nOur bound is tighter with a maximum difference of 117 \u2022 for cubes and greater for cuboids. Figure 5 compares both translation bounds across a range of values.\nThe preceding lemmas are used to bound the objective function (4) within a transformation domain C r \u00d7 C t . For brevity, we use the notation p r t R r (p \u2212 t), p t p \u2212 t and f r (R r ) \u22121 f . Theorem 1. (Lower bound) For the domain C r \u00d7 C t centred at (r 0 , t 0 ), the lower bound of the inlier set cardinality can be chosen asf (R r , t) f (R r0 , t 0 ).\nProof. The validity of the lower bound follows from\nmax r, t f (R r , t) f (R r0 , t 0 ).(18)\nThat is, the function value at a specific point within the domain is less than or equal to the maximum.\nTheorem 2. (Upper bound) For the domain C r \u00d7 C t centred at (r 0 , t 0 ), the upper bound of the inlier set cardinality can be chosen as Proof. Observe that \u2200(r, t) \u2208 (C r \u00d7 C t ),\nf (R r , t) f \u2208F max p\u2208P 1 \u03b8\u2212\u2220(f , p r0 t0 )+\u03c8 r (f , C r )+\u03c8 t (p, C t ) .(19)\n\u2220(f , p r t ) \u2220(f , p r0 t0 ) \u2212 \u2220(f r , f r0 ) \u2212 \u2220(p t , p t0 ) (20) \u2220(f , p r0 t0 ) \u2212 \u03c8 r (f , C r ) \u2212 \u03c8 t (p, C t )(21)\nwhere (20) follows from the triangle inequality in spherical geometry (see Figure 6) and ( 21) follows from Lemmas 3 and 4. Substituting ( 21) into (4) completes the proof.\nBy inspecting the translation component of Theorem 2, a tighter upper bound may be found by removing one of the two applications of the triangle inequality. A similar approach cannot be taken for the rotation component since R r p is a complex surface due to the nonlinear conversion from angle-axis to rotation matrix representations. To reduce computation, it is only necessary to evaluate this tighter bound when \u2220(f , p r0 t0 ) \u03b8 + \u03c8 r (f , C r ) + \u03c8 t (p, C t ), since otherwise the point is definitely an outlier and does not need to be investigated further. Theorem 3. (Tighter upper bound) For the domain C r \u00d7 C t centred at (r 0 , t 0 ), the upper bound of the inlier set cardinality can be chosen as\nf (R r , t) f \u2208F max p\u2208P \u0393(f , p)(22)\n\u0393(f , p) = max t\u2208Ct 1 \u03b8 \u2212 \u2220(f , p r0 t ) + \u03c8 r (f , C r ) .(23)\nProof. Observe that \u2200(r, t) \u2208 (C r \u00d7 C t ),\n1 \u03b8\u2212\u2220(f , p r t ) 1 \u03b8 \u2212 \u2220(f , p r0 t ) + \u2220(f r , f r0 )(24)\nmax t\u2208Ct 1 \u03b8 \u2212 \u2220(f , p r0 t ) + \u03c8 r (f , C r ) (25)\nwhere (24) follows from the triangle inequality in spherical geometry and (25) follows from Lemma 3 and maximising over t. Substituting ( 25) into (4) completes the proof.\n\u0393 may be evaluated by observing that the minimum angle between a ray f and a cube p r0 t is zero if the ray passes through the cube and is otherwise the angle between the ray and the point on the skeleton of the cube (vertices and edges) with least angular displacement from f . Thus, for the translation domain C t with skeleton Sk t ,\n\u0393 = max t\u2208Skt 1 \u03b8 \u2212 \u2220(f , p r0 t ) + \u03c8 r if \u2220(f , p r0 t0 ) > \u03c8 t 1 else.(26)", "publication_ref": ["b17", "b52", "b15", "b4", "b20", "b25"], "figure_ref": ["fig_1", "fig_1", "fig_3", "fig_4"], "table_ref": []}, {"heading": "The GOPAC Algorithm", "text": "The Globally-Optimal Pose And Correspondences (GOPAC) algorithm for a calibrated camera is outlined in Algorithms 1 and 2. As in [49], we employ a nested branchand-bound structure for computational efficiency. In the outer breadth-first BB search, upper and lower bounds are found for each translation cuboid C t \u2208 \u2126 t by running an inner BB search over rotation space SO(3) (denoted RBB). The upper bound\u03bd \u03bd t (19) of C t is found by running RBB until convergence with the following bounds\n\u03bd r f \u2208F max p\u2208P 1 \u03b8 \u2212 \u2220(f , p r0 t0 ) + \u03c8 t (p)(27)\n\u03bd r f \u2208F max p\u2208P 1 \u03b8 \u2212 \u2220(f , p r0 t0 ) + \u03c8 t (p) + \u03c8 r (f ) . (28\n)\nThe tighter upper bound ( 22) instead uses\n\u03bd r f \u2208F max p\u2208P,t\u2208Ct 1 \u03b8 \u2212 \u2220(f , p r0 t )(29)\n\u03bd r f \u2208F max p\u2208P,t\u2208Ct 1 \u03b8 \u2212 \u2220(f , p r0 t ) + \u03c8 r (f ) . (30\n)\nThe lower bound\u03bd \u03bd t ( 17) is found by running RBB using bounds ( 27) and ( 28) with \u03c8 t set to zero.\nThe nested structure has better memory and computational efficiency than directly branching over 6D transformation space, since it maintains a queue for each 3D subproblem, rather than one for the entire 6D problem. This requires significantly fewer simultaneously enqueued subcubes. Moreover, with rotation search nested inside translation search, \u03c8 t only has to be calculated once per translation t, not once per pose (r, t), and F can be rotated (by R \u22121 ) instead of P which typically has more elements. This makes it possible to precompute the rotated bearing vectors and rotation bounds for the top five levels of the rotation octree to reduce the amount of computation required in the inner BB subroutine.\nLine 9 of Algorithm 1 shows how local optimisation is incorporated to refine the camera pose, in a similar manner to [49,5]. Whenever the BB algorithm finds a sub-cube pair (C r , C t ) with a greater lower bound\u03bd than half the bestso-far cardinality \u03bd * , the PnP problem is solved, with correspondences given by the inlier pairs at the pose (r 0 , t 0 ). We use nonlinear optimisation [21], minimising the sum of angular distances between corresponding bearing vectors and points, and update \u03bd * if a larger \u03bd is found. In this way, BB and PnP collaborate, with PnP finding the best pose given correspondences and BB guiding the search for correspondences. PnP accelerates convergence since the faster \u03bd * is increased, the sooner sub-cubes (with\u03bd \u03bd * ) can be culled (Alg. 1 Line 11). SoftPOSIT [9] is also applied at this stage to jump to the nearest local maxima.\nAlgorithm 1 GOPAC: a branch-and-bound algorithm for globally-optimal camera pose & correspondence estimation Input: bearing vector set F, point set P, inlier threshold \u03b8, initial domains \u2126 r and \u2126 t Output: optimal number of inliers \u03bd * , camera pose (r * , t * ) and 2D-3D correspondences 1: \u03bd * \u2190 0 2: Add translation domain \u2126 t to priority queue Q t 3: loop 4:\nUpdate greatest upper bound\u03bd t from Q t 5:\nGet cuboid C t with greatest width \u03b4 tx from Q t 6:\nif \u03bd * \u03bd t then terminate 7:\nfor all sub-cuboids C ti \u2208 C t do 8:\n(\u03bd ti , r) \u2190 RBB(\u03bd * , t 0i , \u03c8 t = 0) 9: if \u03bd * < 2\u03bd ti then (\u03bd * , r * , t * ) \u2190 PnP(r, t 0i ) 10:\u03bd ti \u2190 RBB(\u03bd * , t 0i , \u03c8 t ) 11:\nif \u03bd * <\u03bd ti then add C ti to queue Q t Algorithm 2 RBB: a rotation search subroutine for GOPAC Input: bearing vector set F, point set P, inlier threshold \u03b8, initial domain \u2126 r , best-so-far cardinality \u03bd * , translation t 0 , translation uncertainty \u03c8 t Output: optimal number of inliers \u03bd * r and rotation R * 1: \u03bd * r \u2190 \u03bd * 2: Add rotation domain \u2126 r to priority queue Q r 3: loop for all sub-cubes C ri \u2208 C r do if \u03bd * r <\u03bd ri then \u03bd * r \u2190\u03bd ri , r * \u2190 r 0", "publication_ref": ["b52", "b52", "b4", "b21", "b8"], "figure_ref": [], "table_ref": []}, {"heading": "9:", "text": "Calculate\u03bd ri by (28) or (30) 10:\nif \u03bd * r <\u03bd ri then add C ri to queue Q r\nAs just observed, a large \u03bd * reduces runtime. Therefore, if the user knows a lower bound on the number of 2D inliers, \u03bd * can be initialised to this value. However, this is rarely known. Instead, our algorithm implements an optional guess-and-verify approach, without loss of optimality or objective function distortion, which provides especial benefit when 2D outliers are rare: set \u03bd * = n; run GOPAC; stop if an optimality guarantee is found, otherwise n \u2190 max(n \u2212 s, 0) and repeat. We initialise n = N \u2212 1 and s = 0.1N .\nWe also provide a multi-threaded implementation, where the initial translation domain is divided into sub-domains and GOPAC is run for each in separate CPU threads. The algorithm returns the largest \u03bd * and the associated pose and correspondences. While not supplied, a massively parallel implementation on a GPU is very feasible. Further algorithmic details are provided in the appendix.", "publication_ref": ["b29", "b31"], "figure_ref": [], "table_ref": []}, {"heading": "Results", "text": "The GOPAC algorithm was evaluated with respect to the baseline RANSAC [13], SoftPOSIT [9] and BlindPnP [35] algorithms, denoted GP, RS, SP and BP respectively, with synthetic and real data. The RANSAC approach uses the OpenGV framework [21] and the P3P algorithm [23] with randomly-sampled correspondences. Since SoftPOSIT and BlindPnP require pose priors to function, we use a torus prior in the synthetic experiments. In general, the space of camera poses is much larger than the restrictive torus prior and a good prior can rarely be known in advance. Except where otherwise specified, the inlier threshold \u03b8 was set to 1 \u2022 , the rotation and translation bounds ( 10) and ( 13) were used, SoftPOSIT and nonlinear PnP refinement were applied and multithreading was not used. It is crucial to observe that finding the global optimum does not necessarily imply finding the ground-truth transformation. There may be multiple global optima, particularly in the case of symmetries, and noise may create false optima.", "publication_ref": ["b12", "b8", "b36", "b21", "b24"], "figure_ref": [], "table_ref": []}, {"heading": "Synthetic Data Experiments", "text": "To evaluate our algorithm in a setting where true priors can be applied, we performed 50 independent Monte Carlo simulations per parameter setting, using the framework of [35]: M random 3D points were generated from [\u22121, 1] 3 ; a fraction \u03c9 3D of the 3D points were randomly selected as outliers to model occlusion; the inliers were projected to a virtual image; normal noise was added with \u03c3 = 2 pixels; and random points were added to the image such that a fraction \u03c9 2D of the 2D points were outliers. To facilitate fair comparison with SoftPOSIT and BlindPnP, we use a pose prior for these experiments. The torus prior constrains the camera centre to a torus around the point-set with the optical axis directed towards the model, as in [35]. BlindPnP represents the poses with a 20 component Gaussian mixture model, the means of which are used to initialise SoftPOSIT, as in [35]. GOPAC is given a set of translation cubes which approximate the torus and is not given the rotation priors.\nThe results are shown in Figures 7 and 8a. We repeated the experiments for the repetitive CAD structure shown in Figure 9a, with results shown in Figure 8b. Two success rates are reported: the fraction of trials where the true maximum number of inliers was found and the fraction where the correct pose was found, where the angle between the output rotation and the ground truth rotation is less than 0.1 radians and the camera centre error t \u2212 t GT / t GT relative to the ground truth t GT is less than 0.1, as in [35]. The 2D and 3D outlier fractions were fixed to 0 when not being varied and multithreading was used in the 2D outlier experiments. GOPAC outperforms the other methods, reliably finding the global optimum while still being relatively efficient, particularly when the fraction of 2D outliers is low. For the repetitive CAD structure, while GOPAC finds the  globally optimal number of inliers in all cases, the pose is occasionally incorrect when 75% of the 3D points are occluded, due to the highly symmetric nature of the model. The evolution of the global lower and upper bounds is shown in Figure 9c: BB and PnP collaborate to increase the lower bound with BB guiding the search into better convergence basins and PnP refining the bound by jumping to the nearest local maximum (the staircase pattern). The majority of the time is spent decreasing the upper bound, indicating it will often find the global optimum when terminated early.\nTo show the improvement attributable to the tighter upper bounds derived, we measured the runtime of the algorithm with 10 random 3D points and 50% 2D outliers using different upper bounds, shown in Figure 10. The weak sphere-based bounding functions in (7) and ( 16) are denoted \u03c8 w r and \u03c8 w t respectively, the tighter cuboid-based bounding functions in (10) and ( 13) are denoted \u03c8 r and \u03c8 t respectively and the bounding function from ( 22) is denoted \u0393. Further results are provided in the appendix.  ", "publication_ref": ["b36", "b36", "b36", "b36", "b6"], "figure_ref": ["fig_9", "fig_9", "fig_10"], "table_ref": []}, {"heading": "Real Data Experiments", "text": "To evaluate the algorithm on real data, we use the DATA61/2D3D (formerly NICTA) dataset [37], a large and repetitive multi-modal outdoor dataset. Finding the pose of a camera within a large laser-scanned point-set without a good initialisation represents an unsolved problem in computer vision, which this work makes progress towards solving. For each image, we obtain the ground truth camera pose from the provided 2D-3D correspondences using EPnP [26] followed by nonlinear PnP [21]. Extracting points from a laser scan that correspond to known pixels in an image is itself a challenging unsolved problem for 2D-3D registration pipelines. Due to the robust and optimal nature of GOPAC, we can relax this problem to isolating regions of the point-set that appear in the image and vice versa, from which putative correspondences may be drawn. We used semantic segmentations of the images and pointset to select regions that were potentially observable in both modalities, in this case the 'building' class. We then used grid downsampling and k-means clustering on the class pixels and points independently to reduce them to a manageable size and converted the pixels to bearing vectors. While we do not know the correspondences in advance, each bearing vector has a good chance of having a 3D point as an inlier. In this way, we constructed a dataset consisting of a 3D point-set with 88 points, a set of 11 images containing 30 2D features and a set of ground truth camera poses. For this experiment, we used an inlier threshold of \u03b8 = 2 \u2022 , multithreading and a 2D outlier fraction guess of \u03c9 2D = 0.25.\nThe translation domain was 50\u00d75\u00d75m, covering two lanes of the road, making use of the knowledge that the camera was mounted on a survey vehicle. SoftPOSIT and BlindPnP failed to find the correct camera pose for every image in this dataset, even when supplied the ground truth pose as a prior, due to the weak ground truth correspondences and an inability to handle 3D points behind the camera. Moreover, they do not natively support panoramic imagery and required an artificially restricted field of view to function.\nQualitative results for the GOPAC and RANSAC algorithms are shown in Figure 1 and quantitative results in Table 1. GOPAC finds the optimal number of inliers for all frames and the correct camera pose for the majority of frames, despite the weakness of the 2D/3D point extraction process, surpassing the other methods. The failure modes for GOPAC were 180 \u2022 rotation flips, due to ambiguities arising from the low angular separation of points in the vertical direction. The difficulty of this ill-posed problem is illustrated by the performance of truncated GOPAC, which was not able to find all optima even after running for 30s, motivating the necessity for globally-optimal guided search.", "publication_ref": ["b38", "b27", "b21"], "figure_ref": [], "table_ref": ["tab_0"]}, {"heading": "Conclusion", "text": "In this paper, we have introduced a robust and globallyoptimal solution to the simultaneous camera pose and correspondence problem using inlier set cardinality maximisation. The method applies the branch-and-bound paradigm to guarantee optimality regardless of initialisation and uses local optimisation to accelerate convergence. The pivotal contribution is the derivation of the function bounds using the geometry of SE(3). The algorithm outperformed other local and global methods on challenging synthetic and real datasets, finding the global optimum reliably. Further investigation is warranted to develop a complete 2D-3D pipeline, from segmentation and clustering to alignment.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Optimal geometric fitting under the truncated L2-norm", "journal": "", "year": "2013", "authors": "E Ask; O Enqvist; F Kahl"}, {"ref_id": "b1", "title": "Seeing 3D chairs: exemplar part-based 2D-3D alignment using a large dataset of CAD models", "journal": "", "year": "2014", "authors": "M Aubry; D Maturana; A A Efros; B C Russell; J Sivic"}, {"ref_id": "b2", "title": "A method for registration of 3-D shapes", "journal": "IEEE Trans. Pattern Anal. Mach. Intell", "year": "1992", "authors": "P J Besl; N D Mckay"}, {"ref_id": "b3", "title": "Implementation techniques for geometric branch-and-bound matching methods. Computer Vision and Image Understanding", "journal": "", "year": "2003", "authors": "T M Breuel"}, {"ref_id": "b4", "title": "Globally optimal 2D-3D registration from points or lines without correspondences", "journal": "", "year": "2006", "authors": "M Brown; D Windridge; J.-Y Guillemaut"}, {"ref_id": "b5", "title": "GOGMA: Globally-Optimal Gaussian Mixture Alignment", "journal": "IEEE", "year": "2003", "authors": "D Campbell; L Petersson"}, {"ref_id": "b6", "title": "Guaranteed outlier removal with mixed integer linear programs", "journal": "", "year": "2016", "authors": "T.-J Chin; Y Heng Kee; A Eriksson; F Neumann"}, {"ref_id": "b7", "title": "Optimal randomized RANSAC", "journal": "IEEE Trans. Pattern Anal. Mach. Intell", "year": "2008", "authors": "O Chum; J Matas"}, {"ref_id": "b8", "title": "SoftPOSIT: simultaneous pose and correspondence determination", "journal": "Int. J. Comput. Vision", "year": "2004", "authors": "P David; D Dementhon; R Duraiswami; H Samet"}, {"ref_id": "b9", "title": "Structure from motion without correspondence", "journal": "", "year": "2000", "authors": "F Dellaert; S M Seitz; C E Thorpe; S Thrun"}, {"ref_id": "b10", "title": "Robust fitting for multiple view geometry", "journal": "Springer", "year": "2012", "authors": "O Enqvist; E Ask; F Kahl; K \u00c5str\u00f6m"}, {"ref_id": "b11", "title": "Tractable algorithms for robust model estimation", "journal": "Int. J. Comput. Vision", "year": "2015", "authors": "O Enqvist; E Ask; F Kahl; K \u00c5str\u00f6m"}, {"ref_id": "b12", "title": "Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography", "journal": "Communications of the ACM", "year": "1981", "authors": "M A Fischler; R C Bolles"}, {"ref_id": "b13", "title": "Optimal relative pose with unknown correspondences", "journal": "", "year": "2016", "authors": "J Fredriksson; V Larsson; C Olsson; F Kahl"}, {"ref_id": "b14", "title": "Vision Pattern Recognition", "journal": "IEEE", "year": "2016", "authors": " Conf;  Comput"}, {"ref_id": "b15", "title": "Object Recognition by Computer: The Role of Geometric Constraints", "journal": "MIT Press", "year": "1990", "authors": "W E L Grimson"}, {"ref_id": "b16", "title": "Review and analysis of solutions of the three point perspective pose estimation problem", "journal": "Int. J. Comput. Vision", "year": "1994", "authors": "B M Haralick; C.-N Lee; K Ottenberg; M N\u00f6lle"}, {"ref_id": "b17", "title": "Global optimization through rotation space search", "journal": "Int. J. Comput. Vision", "year": "2009", "authors": "R I Hartley; F Kahl"}, {"ref_id": "b18", "title": "A direct least-squares (DLS) method for PnP", "journal": "IEEE", "year": "2002", "authors": "J A Hesch; S I Roumeliotis"}, {"ref_id": "b19", "title": "Recognizing solid objects by alignment with an image", "journal": "Int. J. Comput. Vision", "year": "1990", "authors": "D P Huttenlocher; S Ullman"}, {"ref_id": "b20", "title": "Solution of the simultaneous pose and correspondence problem using Gaussian error model. Computer Vision and Image Understanding", "journal": "", "year": "1999", "authors": "F Jurie"}, {"ref_id": "b21", "title": "OpenGV: A unified and generalized approach to real-time calibrated geometric vision", "journal": "", "year": "", "authors": "L Kneip; P Furgale"}, {"ref_id": "b22", "title": "Robotics and Automation", "journal": "IEEE", "year": "2014", "authors": " Int;  Conf"}, {"ref_id": "b23", "title": "UPnP: An optimal O(n) solution to the absolute pose problem with universal applicability", "journal": "Springer", "year": "2014", "authors": "L Kneip; H Li; Y Seo"}, {"ref_id": "b24", "title": "A novel parametrization of the perspective-three-point problem for a direct computation of absolute camera position and orientation", "journal": "IEEE", "year": "2007", "authors": "L Kneip; D Scaramuzza; R Siegwart"}, {"ref_id": "b25", "title": "SDICP: Semi-dense tracking based on iterative closest points", "journal": "BMVA Press", "year": "2001", "authors": "L Kneip; Z Yi; H Li"}, {"ref_id": "b26", "title": "An automatic method of solving discrete programming problems", "journal": "Econometrica: Journal of the Econometric Society", "year": "1960", "authors": "A H Land; A G Doig"}, {"ref_id": "b27", "title": "EPnP: An accurate O(n) solution to the PnP problem", "journal": "Int. J. Comput. Vision", "year": "2008", "authors": "V Lepetit; F Moreno-Noguer; P Fua"}, {"ref_id": "b28", "title": "Consensus set maximization with guaranteed global optimality for robust geometry estimation", "journal": "", "year": "2009", "authors": "H Li"}, {"ref_id": "b29", "title": "The 3D-3D registration problem revisited", "journal": "", "year": "2007", "authors": "H Li; R Hartley"}, {"ref_id": "b30", "title": "Worldwide pose estimation using 3D point clouds", "journal": "Springer-Verlag", "year": "2012", "authors": "Y Li; N Snavely; D Huttenlocher; P Fua"}, {"ref_id": "b31", "title": "Location recognition using prioritized feature matching", "journal": "Springer", "year": "2010", "authors": "Y Li; N Snavely; D P Huttenlocher"}, {"ref_id": "b32", "title": "Simultaneous camera pose and correspondence estimation with motion coherence", "journal": "Int. J. Comput. Vision", "year": "2012", "authors": "W.-Y Lin; L.-F Cheong; P Tan; G Dong; S Liu"}, {"ref_id": "b33", "title": "Distinctive image features from scale-invariant keypoints", "journal": "Int. J. Comput. Vision", "year": "2004", "authors": "D G Lowe"}, {"ref_id": "b34", "title": "Correspondencefree structure from motion", "journal": "Int. J. Comput. Vision", "year": "2007", "authors": "A Makadia; C Geyer; K Daniilidis"}, {"ref_id": "b35", "title": "Pose estimation for augmented reality: a hands-on survey", "journal": "IEEE Trans. Vis. Comput. Graphics", "year": "2016", "authors": "E Marchand; H Uchiyama; F Spindler"}, {"ref_id": "b36", "title": "Pose priors for simultaneously solving alignment and correspondence", "journal": "Springer", "year": "2008", "authors": "F Moreno-Noguer; V Lepetit; P Fua"}, {"ref_id": "b37", "title": "Object recognition in the geometric era: A retrospective", "journal": "Springer", "year": "2006", "authors": "J L Mundy"}, {"ref_id": "b38", "title": "A multi-modal graphical model for scene analysis", "journal": "IEEE", "year": "2015", "authors": "S T Namin; M Najafi; M Salzmann; L Petersson"}, {"ref_id": "b39", "title": "Markerless Camera Pose Estimation -An Overview", "journal": "", "year": "2011", "authors": "T N\u00f6ll; A Pagani; D Stricker"}, {"ref_id": "b40", "title": "A general method for geometric feature matching and model extraction", "journal": "Int. J. Comput. Vision", "year": "2001", "authors": "C F Olson"}, {"ref_id": "b41", "title": "Outlier removal using duality", "journal": "", "year": "2010", "authors": "C Olsson; A Eriksson; R Hartley"}, {"ref_id": "b42", "title": "Branch-and-bound methods for euclidean registration problems", "journal": "IEEE Trans. Pattern Anal. Machine Intelligence", "year": "2009", "authors": "C Olsson; F Kahl; M Oskarsson"}, {"ref_id": "b43", "title": "LMI-based 2D-3D registration: From uncalibrated images to Euclidean scene", "journal": "", "year": "2015", "authors": "D P Paudel; A Habed; C Demonceaux; P Vasseur"}, {"ref_id": "b44", "title": "Robust and optimal sum-of-squares-based point-to-plane registration of image sets and structured scenes", "journal": "", "year": "2015", "authors": "D P Paudel; A Habed; C Demonceaux; P Vasseur"}, {"ref_id": "b45", "title": "Comput. Vision", "journal": "", "year": "2015", "authors": " Int;  Conf"}, {"ref_id": "b46", "title": "Fast image-based localization using direct 2D-to-3D matching", "journal": "", "year": "2011", "authors": "T Sattler; B Leibe; L Kobbelt"}, {"ref_id": "b47", "title": "Improving image-based localization by active correspondence search", "journal": "", "year": "", "authors": "T Sattler; B Leibe; L Kobbelt"}, {"ref_id": "b48", "title": "European Conf. Comput. Vision", "journal": "Springer-Verlag", "year": "2012", "authors": ""}, {"ref_id": "b49", "title": "Removing outliers using the L\u221e norm", "journal": "", "year": "2006", "authors": "K Sim; R Hartley"}, {"ref_id": "b50", "title": "City-scale localization for cameras with known vertical direction", "journal": "IEEE Trans. Pattern Anal. Machine Intelligence", "year": "2016", "authors": "L Svarm; O Enqvist; F Kahl; M Oskarsson"}, {"ref_id": "b51", "title": "Accurate localization and pose estimation for large 3D models", "journal": "", "year": "2014", "authors": "L Sv\u00e4rm; O Enqvist; M Oskarsson; F Kahl"}, {"ref_id": "b52", "title": "Go-ICP: A globally optimal solution to 3D ICP point-set registration", "journal": "IEEE Trans. Pattern Anal. Mach. Intell", "year": "2006", "authors": "J Yang; H Li; D Campbell; Y Jia"}, {"ref_id": "b53", "title": "An adversarial optimization approach to efficient outlier removal", "journal": "", "year": "", "authors": "J Yu; A Eriksson; T.-J Chin; D Suter"}, {"ref_id": "b54", "title": "Comput. Vision", "journal": "", "year": "2011", "authors": " Int;  Conf"}], "figures": [{"figure_label": "3", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 3 .3Figure 3. Parametrisation of SE(3). (a) The rotation space SO(3) is parametrised by angle-axis 3-vectors in a solid radius-\u03c0 ball. (b) The translation space R 3 is parametrised by 3-vectors bounded by a cuboid with half-widths [\u03c4x, \u03c4y, \u03c4z]. The domain is branched into sub-cuboids as shown using nested octree data structures.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 4 .4Figure 4. Uncertainty angles induced by rotation and translation sub-cubes. (a) Rotation uncertainty angle \u03c8r for Cr.The optimal rotation of p may be anywhere within the umbrella-shaped region, which is entirely contained by the cone defined by Rr 0 p and \u03c8r. (b) Translation uncertainty angle \u03c8t for Ct. The optimal translation of p may be anywhere within the cuboidal region, which is entirely contained by the cone defined by p \u2212 t0 and \u03c8t.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Lemma 4 .4(Translation uncertainty angle) Given a 3D point p and a translation cube C t centred at t 0 with vertices", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 5 .5Figure 5. Comparison of translation bounds when the cube centre lies along a ray from the origin towards (a) any face centre and (b) any vertex. Our bound \u03c8t is tighter across the entire domain.", "figure_data": ""}, {"figure_label": "6", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 6 .6Figure6. The triangle inequality in spherical geometry, given by \u03b2 \u03b1 + \u03b3 or \u2220(fr, pt 0 ) \u2220(fr, pt) + \u2220(pt, pt 0 ). The transformed points have been normalised to lie on the unit sphere.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "4 :4Read cube C r with greatest upper bound\u03bd r from Q r", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "\u03c9 3D = 0.75", "figure_data": ""}, {"figure_label": "7278", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "Figure 7 .M = 27 Figure 8 .7278Figure 7. Mean success rates and median runtimes with respect to the number of random 3D points and the 3D outlier fraction, for 50 Monte Carlo simulations per parameter value with the torus prior.", "figure_data": ""}, {"figure_label": "9", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "Figure 9 .9Figure 9. Sample 2D and 3D results for two trials using the random points and repetitive CAD model datasets. (a) 3D models, true and GOPAC-estimated camera fulcra (completely overlapping) and toroidal pose priors. Only non-occluded 3D points are shown. (b) True projections of non-occluded 3D points are shown as black dots, 2D outliers as red dots, GOPAC projections as black circles and GOPAC-classified 3D outliers as red crosses. (c) Evolution over time of the upper and lower bounds (black), remaining translation volume (blue) and translation queue size (green) as a fraction of their maximum values. Best viewed in colour.", "figure_data": ""}, {"figure_label": "10", "figure_type": "figure", "figure_id": "fig_10", "figure_caption": "Figure 10 .10Figure 10. Comparison of the different upper bound functions. Runtime is plotted relative to the maximum (leftmost) value. The weakest upper bound is 50% slower than the tightest upper bound.", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "Camera pose results for the DATA61/2D3D dataset. The median translation error, rotation error and runtime and the mean inlier recall and success rates are reported. GP denotes truncated GOPAC, where search is terminated after 30s, with no optimality guarantee. RSK denotes RANSAC with K million iterations.", "figure_data": "MethodGPGPRS 20 RS 280Translation Error (m)2.303.1020.328.5Rotation Error ( \u2022 )2.083.04178179Recall (Inliers)1.000.970.750.81Success Rate (Inliers) 1.000.450.000.00Success Rate (Pose)0.820.640.090.09Runtime (s)4773434471"}], "formulas": [{"formula_id": "formula_0", "formula_text": "\u03bd * = max R, t |S I |(1)", "formula_coordinates": [3.0, 138.36, 489.72, 148.01, 16.51]}, {"formula_id": "formula_1", "formula_text": "S I = {f \u2208 F | \u2203p \u2208 P : \u2220(f , R(p \u2212 t)) \u03b8} (2)", "formula_coordinates": [3.0, 75.56, 509.29, 210.81, 9.68]}, {"formula_id": "formula_2", "formula_text": "\u03bd * = max R, t f (R, t)(3)", "formula_coordinates": [3.0, 132.52, 550.03, 153.84, 16.51]}, {"formula_id": "formula_3", "formula_text": "f (R, t) = f \u2208F max p\u2208P 1 \u03b8 \u2212 \u2220(f , R(p \u2212 t))(4)", "formula_coordinates": [3.0, 83.09, 569.59, 203.27, 20.17]}, {"formula_id": "formula_4", "formula_text": "C(c, \u03b4) = {x \u2208 R 3 | e i (x\u2212c) \u2208 [\u2212\u03b4 i , \u03b4 i ], i = 1, 2, 3} (5)", "formula_coordinates": [4.0, 55.09, 321.07, 231.27, 13.01]}, {"formula_id": "formula_5", "formula_text": "\u2220(R r1 p, R r2 p) r 1 \u2212 r 2 . (6", "formula_coordinates": [4.0, 109.73, 615.47, 172.76, 9.68]}, {"formula_id": "formula_6", "formula_text": ")", "formula_coordinates": [4.0, 282.49, 615.82, 3.87, 8.64]}, {"formula_id": "formula_8", "formula_text": "\u2220(R r p, R r0 p) min( r \u2212 r 0 , \u03c0) (8) min( \u221a 3\u03b4 r , \u03c0)(9)", "formula_coordinates": [4.0, 357.46, 96.22, 187.65, 26.78]}, {"formula_id": "formula_9", "formula_text": "\u2200r \u2208 C r , \u2220(R r p, R r0 p) min(max r\u2208Sr \u2220(R r p, R r0 p), \u03c0) \u03c8 r (p, C r ).(10)", "formula_coordinates": [4.0, 308.86, 257.14, 236.25, 46.26]}, {"formula_id": "formula_10", "formula_text": "\u2220(R r p, R r0 p) min(max r\u2208Cr \u2220(R r p, R r0 p), \u03c0)(11)", "formula_coordinates": [4.0, 329.63, 334.77, 215.48, 14.61]}, {"formula_id": "formula_11", "formula_text": "r\u2208Sr \u2220(R r p, R r0 p), \u03c0)(12)", "formula_coordinates": [4.0, 418.57, 355.54, 126.55, 14.61]}, {"formula_id": "formula_12", "formula_text": "V t , then \u2200t \u2208 C t , \u2220(p \u2212 t, p \u2212 t 0 ) max t\u2208Vt \u2220(p \u2212 t, p \u2212 t 0 ) if p / \u2208 C t \u03c0 else \u03c8 t (p, C t ).(13)", "formula_coordinates": [4.0, 313.16, 539.49, 231.96, 67.12]}, {"formula_id": "formula_13", "formula_text": "\u2220(p \u2212 t, p \u2212 t 0 ) max t\u2208Ct \u2220(p \u2212 t, p \u2212 t 0 ) (14) = max t\u2208Vt \u2220(p \u2212 t, p \u2212 t 0 )(15", "formula_coordinates": [4.0, 332.11, 674.98, 213.0, 35.39]}, {"formula_id": "formula_14", "formula_text": "\u03c8 w t (p, C t ) arcsin \u03c1t p\u2212t0 if \u03c1 t p \u2212 t 0 \u03c0 else. (16", "formula_coordinates": [5.0, 55.28, 392.69, 226.93, 27.88]}, {"formula_id": "formula_15", "formula_text": ")", "formula_coordinates": [5.0, 282.21, 402.58, 4.15, 8.64]}, {"formula_id": "formula_17", "formula_text": "max r, t f (R r , t) f (R r0 , t 0 ).(18)", "formula_coordinates": [5.0, 114.72, 588.0, 171.64, 14.28]}, {"formula_id": "formula_18", "formula_text": "f (R r , t) f \u2208F max p\u2208P 1 \u03b8\u2212\u2220(f , p r0 t0 )+\u03c8 r (f , C r )+\u03c8 t (p, C t ) .(19)", "formula_coordinates": [5.0, 50.11, 680.31, 238.15, 34.24]}, {"formula_id": "formula_19", "formula_text": "\u2220(f , p r t ) \u2220(f , p r0 t0 ) \u2212 \u2220(f r , f r0 ) \u2212 \u2220(p t , p t0 ) (20) \u2220(f , p r0 t0 ) \u2212 \u03c8 r (f , C r ) \u2212 \u03c8 t (p, C t )(21)", "formula_coordinates": [5.0, 322.0, 210.85, 223.11, 28.1]}, {"formula_id": "formula_20", "formula_text": "f (R r , t) f \u2208F max p\u2208P \u0393(f , p)(22)", "formula_coordinates": [5.0, 371.02, 457.37, 174.1, 20.17]}, {"formula_id": "formula_21", "formula_text": "\u0393(f , p) = max t\u2208Ct 1 \u03b8 \u2212 \u2220(f , p r0 t ) + \u03c8 r (f , C r ) .(23)", "formula_coordinates": [5.0, 325.92, 484.1, 219.19, 16.99]}, {"formula_id": "formula_22", "formula_text": "1 \u03b8\u2212\u2220(f , p r t ) 1 \u03b8 \u2212 \u2220(f , p r0 t ) + \u2220(f r , f r0 )(24)", "formula_coordinates": [5.0, 306.22, 524.0, 238.89, 13.15]}, {"formula_id": "formula_23", "formula_text": "max t\u2208Ct 1 \u03b8 \u2212 \u2220(f , p r0 t ) + \u03c8 r (f , C r ) (25)", "formula_coordinates": [5.0, 382.72, 540.04, 162.39, 16.99]}, {"formula_id": "formula_24", "formula_text": "\u0393 = max t\u2208Skt 1 \u03b8 \u2212 \u2220(f , p r0 t ) + \u03c8 r if \u2220(f , p r0 t0 ) > \u03c8 t 1 else.(26)", "formula_coordinates": [5.0, 314.49, 682.33, 230.62, 32.21]}, {"formula_id": "formula_25", "formula_text": "\u03bd r f \u2208F max p\u2208P 1 \u03b8 \u2212 \u2220(f , p r0 t0 ) + \u03c8 t (p)(27)", "formula_coordinates": [6.0, 57.55, 210.86, 418.89, 22.55]}, {"formula_id": "formula_26", "formula_text": "\u03bd r f \u2208F max p\u2208P 1 \u03b8 \u2212 \u2220(f , p r0 t0 ) + \u03c8 t (p) + \u03c8 r (f ) . (28", "formula_coordinates": [6.0, 57.55, 238.81, 224.66, 22.55]}, {"formula_id": "formula_27", "formula_text": ")", "formula_coordinates": [6.0, 282.21, 241.54, 4.15, 8.64]}, {"formula_id": "formula_28", "formula_text": "\u03bd r f \u2208F max p\u2208P,t\u2208Ct 1 \u03b8 \u2212 \u2220(f , p r0 t )(29)", "formula_coordinates": [6.0, 67.22, 293.58, 399.55, 22.55]}, {"formula_id": "formula_29", "formula_text": "\u03bd r f \u2208F max p\u2208P,t\u2208Ct 1 \u03b8 \u2212 \u2220(f , p r0 t ) + \u03c8 r (f ) . (30", "formula_coordinates": [6.0, 67.22, 321.53, 215.0, 22.55]}, {"formula_id": "formula_30", "formula_text": ")", "formula_coordinates": [6.0, 282.21, 324.25, 4.15, 8.64]}, {"formula_id": "formula_31", "formula_text": "(\u03bd ti , r) \u2190 RBB(\u03bd * , t 0i , \u03c8 t = 0) 9: if \u03bd * < 2\u03bd ti then (\u03bd * , r * , t * ) \u2190 PnP(r, t 0i ) 10:\u03bd ti \u2190 RBB(\u03bd * , t 0i , \u03c8 t ) 11:", "formula_coordinates": [6.0, 310.63, 230.2, 223.35, 45.97]}], "doi": ""}