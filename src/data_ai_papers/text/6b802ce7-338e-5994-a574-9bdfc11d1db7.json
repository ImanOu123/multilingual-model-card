{"title": "Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations", "authors": "Francesco Locatello; Stefan Bauer; Mario Lucic; Gunnar R\u00e4tsch; Sylvain Gelly; Bernhard Sch\u00f6lkopf; Olivier Bachem", "pub_date": "", "abstract": "The key idea behind the unsupervised learning of disentangled representations is that real-world data is generated by a few explanatory factors of variation which can be recovered by unsupervised learning algorithms. In this paper, we provide a sober look at recent progress in the field and challenge some common assumptions. We first theoretically show that the unsupervised learning of disentangled representations is fundamentally impossible without inductive biases on both the models and the data. Then, we train more than 12 000 models covering most prominent methods and evaluation metrics in a reproducible large-scale experimental study on seven different data sets. We observe that while the different methods successfully enforce properties \"encouraged\" by the corresponding losses, well-disentangled models seemingly cannot be identified without supervision. Furthermore, increased disentanglement does not seem to lead to a decreased sample complexity of learning for downstream tasks. Our results suggest that future work on disentanglement learning should be explicit about the role of inductive biases and (implicit) supervision, investigate concrete benefits of enforcing disentanglement of the learned representations, and consider a reproducible experimental setup covering several data sets.", "sections": [{"heading": "Introduction", "text": "In representation learning it is often assumed that real-world observations x (e.g., images or videos) are generated by a two-step generative process. First, a multivariate latent random variable z is sampled from a distribution P (z). Intuitively, z corresponds to semantically meaningful factors of variation of the observations (e.g., content + position of objects in an image). Then, in a second step, the observation x is sampled from the conditional distribution P (x|z). The key idea behind this model is that the high-dimensional data x can be explained by the substantially lower dimensional and semantically meaningful latent variable z which is mapped to the higher-dimensional space of observations x. Informally, the goal of representation learning is to find useful transformations r(x) of x that \"make it easier to extract useful information when building classifiers or other predictors\" (Bengio et al., 2013).\nA recent line of work has argued that representations that are disentangled are an important step towards a better representation learning (Bengio et al., 2013;Peters et al., 2017;LeCun et al., 2015;Bengio et al., 2007;Schmidhuber, 1992;Lake et al., 2017;Tschannen et al., 2018). They should contain all the information present in x in a compact and interpretable structure (Bengio et al., 2013;Kulkarni et al., 2015;Chen et al., 2016) while being independent from the task at hand (Goodfellow et al., 2009;Lenc & Vedaldi, 2015). They should be useful for (semi-)supervised learning of downstream tasks, transfer and few shot learning (Bengio et al., 2013;Sch\u00f6lkopf et al., 2012;Peters et al., 2017). They should enable to integrate out nuisance factors (Kumar et al., 2017), to perform interventions, and to answer counterfactual questions (Pearl, 2009;Spirtes et al., 1993;Peters et al., 2017).\nWhile there is no single formalized notion of disentanglement (yet) which is widely accepted, the key intuition is that a disentangled representation should separate the distinct, informative factors of variations in the data (Bengio et al., 2013). A change in a single underlying factor of variation z i should lead to a change in a single factor in the learned representation r(x). This assumption can be extended to groups of factors as, for instance, in Bouchacourt et al. (2018) or Suter et al. (2018). Based on this idea, a variety of disentanglement evaluation protocols have been proposed leveraging the statistical relations between the learned arXiv:1811.12359v4 [cs.LG] 18 Jun 2019 representation and the ground-truth factor of variations. Disentanglement is then measured as a particular structural property of these relations (Higgins et al., 2017a;Kim & Mnih, 2018;Eastwood & Williams, 2018;Kumar et al., 2017;Chen et al., 2018;Ridgeway & Mozer, 2018).\nState-of-the-art approaches for unsupervised disentanglement learning are largely based on Variational Autoencoders (VAEs) (Kingma & Welling, 2014): One assumes a specific prior P (z) on the latent space and then uses a deep neural network to parameterize the conditional probability P (x|z). Similarly, the distribution P (z|x) is approximated using a variational distribution Q(z|x), again parametrized using a deep neural network. The model is then trained by minimizing a suitable approximation to the negative log-likelihood. The representation for r(x) is usually taken to be the mean of the approximate posterior distribution Q(z|x). Several variations of VAEs were proposed with the motivation that they lead to better disentanglement (Higgins et al., 2017a;Burgess et al., 2017;Kim & Mnih, 2018;Chen et al., 2018;Kumar et al., 2017;Rubenstein et al., 2018). The common theme behind all these approaches is that they try to enforce a factorized aggregated posterior x Q(z|x)P (x)dx, which should encourage disentanglement.\nOur contributions. In this paper, we challenge commonly held assumptions in this field in both theory and practice.\nOur key contributions can be summarized as follows:\n\u2022 We theoretically prove that (perhaps unsurprisingly) the unsupervised learning of disentangled representations is fundamentally impossible without inductive biases both on the considered learning approaches and the data sets.\n\u2022 We investigate current approaches and their inductive biases in a reproducible large-scale experimental study 1 with a sound experimental protocol for unsupervised disentanglement learning. We implement six recent unsupervised disentanglement learning methods as well as six disentanglement measures from scratch and train more than 12 000 models on seven data sets.\n\u2022 We release disentanglement_lib 2 , a new library to train and evaluate disentangled representations. As reproducing our results requires substantial computational effort, we also release more than 10 000 trained models which can be used as baselines for future research.\n\u2022 We analyze our experimental results and challenge common beliefs in unsupervised disentanglement learning: (i) While all considered methods prove effective at ensuring that the individual dimensions of the aggregated posterior (which is sampled) are not correlated, we observe that the 1 Reproducing these experiments requires approximately 2.52 GPU years (NVIDIA P100).\n2 https://github.com/google-research/ disentanglement_lib dimensions of the representation (which is taken to be the mean) are correlated. (ii) We do not find any evidence that the considered models can be used to reliably learn disentangled representations in an unsupervised manner as random seeds and hyperparameters seem to matter more than the model choice. Furthermore, good trained models seemingly cannot be identified without access to ground-truth labels even if we are allowed to transfer good hyperparameter values across data sets. (iii) For the considered models and data sets, we cannot validate the assumption that disentanglement is useful for downstream tasks, for example through a decreased sample complexity of learning.\n\u2022 Based on these empirical evidence, we suggest three critical areas of further research: (i) The role of inductive biases and implicit and explicit supervision should be made explicit: unsupervised model selection persists as a key question. (ii) The concrete practical benefits of enforcing a specific notion of disentanglement of the learned representations should be demonstrated. (iii) Experiments should be conducted in a reproducible experimental setup on data sets of varying degrees of difficulty.", "publication_ref": ["b2", "b2", "b1", "b2", "b2", "b2"], "figure_ref": [], "table_ref": []}, {"heading": "Other related work", "text": "In a similar spirit to disentanglement, (non-)linear independent component analysis (Comon, 1994;Bach & Jordan, 2002;Jutten & Karhunen, 2003;Hyvarinen & Morioka, 2016) studies the problem of recovering independent components of a signal. The underlying assumption is that there is a generative model for the signal composed of the combination of statistically independent non-Gaussian components. While the identifiability result for linear ICA (Comon, 1994) proved to be a milestone for the classical theory of factor analysis, similar results are in general not obtainable for the nonlinear case and the underlying sources generating the data cannot be identified (Hyvarinen & Pajunen, 1999). The lack of almost any identifiability result in nonlinear ICA has been a main bottleneck for the utility of the approach (Hyvarinen et al., 2018) and partially motivated alternative machine learning approaches (Desjardins et al., 2012;Schmidhuber, 1992;Cohen & Welling, 2015). Given that unsupervised algorithms did not initially perform well on realistic settings most of the other works have considered some more or less explicit form of supervision (Reed et al., 2014;Zhu et al., 2014;Yang et al., 2015;Kulkarni et al., 2015;Cheung et al., 2015;Mathieu et al., 2016;Narayanaswamy et al., 2017;Suter et al., 2018). (Hinton et al., 2011;Cohen & Welling, 2014) assume some knowledge of the effect of the factors of variations even though they are not observed. One can also exploit known relations between factors in different samples (Karaletsos et al., 2015;Goroshin et al., 2015;Whitney et al., 2016;Fraccaro et al., 2017;Denton & Birodkar, 2017;Hsu et al., 2017;Yingzhen & Mandt, 2018) or explicit inductive biases (Locatello et al., 2018). This is not a limiting assumption especially in sequential data, i.e., for videos. We focus our study on the setting where factors of variations are not observable at all, i.e. we only observe samples from P (x).", "publication_ref": ["b0"], "figure_ref": [], "table_ref": []}, {"heading": "Impossibility result", "text": "The first question that we investigate is whether unsupervised disentanglement learning is even possible for arbitrary generative models. Theorem 1 essentially shows that without inductive biases both on models and data sets the task is fundamentally impossible. The proof is provided in Appendix A.\nTheorem 1. For d > 1, let z \u223c P denote any distribution which admits a density p(z) = d i=1 p(z i ). Then, there exists an infinite family of bijective functions f : supp(z) \u2192 supp(z) such that \u2202fi(u) \u2202uj = 0 almost everywhere for all i and j (i.e., z and f (z) are completely entangled) and P (z \u2264 u) = P (f (z) \u2264 u) for all u \u2208 supp(z) (i.e., they have the same marginal distribution).\nConsider the commonly used \"intuitive\" notion of disentanglement which advocates that a change in a single groundtruth factor should lead to a single change in the representation. In that setting, Theorem 1 implies that unsupervised disentanglement learning is impossible for arbitrary generative models with a factorized prior 3 in the following sense: Assume we have p(z) and some P (x|z) defining a generative model. Consider any unsupervised disentanglement method and assume that it finds a representation r(x) that is perfectly disentangled with respect to z in the generative model. Then, Theorem 1 implies that there is an equivalent generative model with the latent variable\u1e91 = f (z) where\u1e91 is completely entangled with respect to z and thus also r(x): as all the entries in the Jacobian of f are non-zero, a change in a single dimension of z implies that all dimensions of\u1e91 change. Furthermore, since f is deterministic and p(z) = p(\u1e91) almost everywhere, both generative models have the same marginal distribution of the observations x by construction, i.e., P (x) = p(x|z)p(z)dz = p(x|\u1e91)p(\u1e91)d\u1e91. Since the (unsupervised) disentanglement method only has access to observations x, it hence cannot distinguish between the two equivalent generative models and thus has to be entangled to at least one of them. This may not be surprising to readers familiar with the causality and ICA literature as it is consistent with the following argument: After observing x, we can construct infinitely many generative models which have the same marginal distribution of x. Any one of these models could be the true causal generative model for the data, and the right model cannot be identified given only the distribution of x (Peters et al., 2017). Similar results have been obtained in the context of non-linear ICA (Hyvarinen & Pajunen, 1999). The main novelty of Theorem 1 is that it allows the explicit construction of latent spaces z and\u1e91 that are completely entangled with each other in the sense of (Bengio et al., 2013). We note that while this result is very intuitive for multivariate Gaussians it also holds for distributions which are not invariant to rotation, for example multivariate uniform distributions.\nWhile Theorem 1 shows that unsupervised disentanglement learning is fundamentally impossible for arbitrary generative models, this does not necessarily mean it is an impossible endeavour in practice. After all, real world generative models may have a certain structure that could be exploited through suitably chosen inductive biases. However, Theorem 1 clearly shows that inductive biases are required both for the models (so that we find a specific set of solutions) and for the data sets (such that these solutions match the true generative model). We hence argue that the role of inductive biases should be made explicit and investigated further as done in the following experimental study.", "publication_ref": ["b2"], "figure_ref": [], "table_ref": []}, {"heading": "Experimental design", "text": "Considered methods. All the considered methods augment the VAE loss with a regularizer: The \u03b2-VAE (Higgins et al., 2017a), introduces a hyperparameter in front of the KL regularizer of vanilla VAEs to constrain the capacity of the VAE bottleneck. The AnnealedVAE (Burgess et al., 2017) progressively increase the bottleneck capacity so that the encoder can focus on learning one factor of variation at the time (the one that most contribute to a small reconstruction error). The FactorVAE (Kim & Mnih, 2018) and the \u03b2-TCVAE (Chen et al., 2018) penalize the total correlation (Watanabe, 1960) with adversarial training (Nguyen et al., 2010;Sugiyama et al., 2012) or with a tractable but biased Monte-Carlo estimator respectively. The DIP-VAE-I and the DIP-VAE-II (Kumar et al., 2017) both penalize the mismatch between the aggregated posterior and a factorized prior. Implementation details and further discussion on the methods can be found in Appendix B and G.\nConsidered metrics. The BetaVAE metric (Higgins et al., 2017a) measures disentanglement as the accuracy of a linear classifier that predicts the index of a fixed factor of variation. Kim & Mnih (2018) address several issues with this metric in their FactorVAE metric by using a majority vote classifier on a different feature vector which accounts for a corner case in the BetaVAE metric. The Mutual Information Gap (MIG) (Chen et al., 2018) measures for each factor of vari-ation the normalized gap in mutual information between the highest and second highest coordinate in r(x). Instead, the Modularity (Ridgeway & Mozer, 2018) measures if each dimension of r(x) depends on at most a factor of variation using their mutual information. The Disentanglement metric of Eastwood & Williams (2018) (which we call DCI Disentanglement for clarity) computes the entropy of the distribution obtained by normalizing the importance of each dimension of the learned representation for predicting the value of a factor of variation. The SAP score (Kumar et al., 2017) is the average difference of the prediction error of the two most predictive latent dimensions for each factor. Implementation details and further descriptions can be found in Appendix C. Data sets. We consider four data sets in which x is obtained as a deterministic function of z: dSprites (Higgins et al., 2017a), Cars3D (Reed et al., 2015, SmallNORB (Le-Cun et al., 2004), Shapes3D (Kim & Mnih, 2018. We also introduce three data sets where the observations x are stochastic given the factor of variations z: Color-dSprites, Noisy-dSprites and Scream-dSprites. In Color-dSprites, the shapes are colored with a random color. In Noisy-dSprites, we consider white-colored shapes on a noisy background. Finally, in Scream-dSprites the background is replaced with a random patch in a random color shade extracted from the famous The Scream painting (Munch, 1893). The dSprites shape is embedded into the image by inverting the color of its pixels. Further details on the preprocessing of the data can be found in Appendix H.\nInductive biases. To fairly evaluate the different approaches, we separate the effect of regularization (in the form of model choice and regularization strength) from the other inductive biases (e.g., the choice of the neural architecture). Each method uses the same convolutional architecture, optimizer, hyperparameters of the optimizer and batch size. All methods use a Gaussian encoder where the mean and the log variance of each latent factor is parametrized by the deep neural network, a Bernoulli decoder and latent dimension fixed to 10. We note that these are all standard choices in prior work (Higgins et al., 2017a;Kim & Mnih, 2018).\nWe choose six different regularization strengths, i.e., hyperparameter values, for each of the considered methods.\nThe key idea was to take a wide enough set to ensure that there are useful hyperparameters for different settings for each method and not to focus on specific values known to work for specific data sets. However, the values are partially based on the ranges that are prescribed in the literature (including the hyperparameters suggested by the authors).\nWe fix our experimental setup in advance and we run all the considered methods on each data set for 50 different random seeds and evaluate them on the considered metrics. The full details on the experimental setup are provided in the Appendix G. Our experimental setup, the limitations of this study, and the differences with previous implementations are extensively discussed in Appendices D-F.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Key experimental results", "text": "In this section, we highlight our key findings with plots specifically picked to be representative of our main results. In Appendix I, we provide the full experimental results with a complete set of plots for different methods, data sets and disentanglement metrics.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Can current methods enforce a uncorrelated aggregated posterior and representation?", "text": "While many of the considered methods aim to enforce a factorizing and thus uncorrelated aggregated posterior (e.g., regularizing the total correlation of the sampled representation), they use the mean vector of the Gaussian encoder as the representation and not a sample from the Gaussian encoder. This may seem like a minor, irrelevant modification; however, it is not clear whether a factorizing aggregated posterior also ensures that the dimensions of the mean representation are uncorrelated. To test the impact of this, we compute the total correlation of both the mean and the sampled representation based on fitting Gaussian distributions for each data set, model and hyperparameter value (see Appendix C and I.2 for details).\nFigure 1 (left) shows the total correlation based on a fitted Gaussian of the sampled representation plotted against the regularization strength for each method except Annealed-VAE on Color-dSprites. We observe that the total correlation of the sampled representation generally decreases with the regularization strength. One the other hand, Figure 1 (right) shows the total correlation of the mean representation plotted against the regularization strength. It is evident that the total correlation of the mean representation generally increases with the regularization strength. The only exception is DIP-VAE-I for which we observe that the total correlation of the mean representation is consistently low. This is not surprising as the DIP-VAE-I objective directly optimizes the covariance matrix of the mean representation to be diagonal which implies that the corresponding total correlation (as we measure it) is low. These findings are confirmed by our detailed experimental results in Appendix I.2 (in particular Figures 8-9) which considers all different data sets. Furthermore, we observe largely the same pattern if we consider the average mutual information between different dimension of the representation instead of the total correlation (see Figures 27-28 in Appendix J).\nImplications. Overall, these results lead us to conclude with minor exceptions that the considered methods are effective at enforcing an aggregated posterior whose individual dimensions are not correlated but that this does not seem to imply that the dimensions of the mean representation (usually used for representation) are uncorrelated. \n(A) (B) (C) (D) (E) (F) BetaVAE Score (A) FactorVAE Score (B) MIG (C) DCI Disentanglement (D) Modularity (E) SAP (F)", "publication_ref": [], "figure_ref": ["fig_0", "fig_0"], "table_ref": []}, {"heading": "How much do the disentanglement metrics agree?", "text": "As there exists no single, common definition of disentanglement, an interesting question is to see how much different proposed metrics agree. Figure 2 shows the Spearman rank correlation between different disentanglement metrics on Noisy-dSprites whereas Figure 12 in Appendix I.3 shows the correlation for all the different data sets. We observe that all metrics except Modularity seem to be correlated strongly on the data sets dSprites, Color-dSprites and Scream-dSprites and mildly on the other data sets. There appear to be two pairs among these metrics that capture particularly similar notions: the BetaVAE and the FactorVAE score as well as the MIG and DCI Disentanglement.\nImplication. All disentanglement metrics except Modularity appear to be correlated. However, the level of correlation changes between different data sets.", "publication_ref": [], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "How important are different models and hyperparameters for disentanglement?", "text": "The primary motivation behind the considered methods is that they should lead to improved disentanglement. This In this case, the variance is only due to the different random seeds. We observe that randomness (in the form of different random seeds) has a substantial impact on the attained result and that a good run with a bad hyperparameter can beat a bad run with a good hyperparameter.\nraises the question how disentanglement is affected by the model choice, the hyperparameter selection and randomness (in the form of different random seeds). To investigate this, we compute all the considered disentanglement metrics for each of our trained models.\nIn Figure 3 (left), we show the range of attainable Factor-VAE scores for each method on Cars3D. We observe that these ranges are heavily overlapping for different models leading us to (qualitatively) conclude that the choice of hyperparameters and the random seed seems to be substantially more important than the choice of objective function. These results are confirmed by the full experimental results on all the data sets presented in Figure 13 of Appendix I.4: While certain models seem to attain better maximum scores on specific data sets and disentanglement metrics, we do not observe any consistent pattern that one model is consistently better than the other. At this point, we note that in our study we have fixed the range of hyperparameters a priori to six different values for each model and did not explore additional hyperparameters based on the results (as that would bias our study). However, this also means that specific models may have performed better than in Figure 13 (left) if we had chosen a different set of hyperparameters.\nIn Figure 3 (right), we further show the impact of randomness in the form of random seeds on the disentanglement scores. Each violin plot shows the distribution of the Fac-torVAE metric across all 50 trained FactorVAE models for each hyperparameter setting on Cars3D. We clearly see that randomness (in the form of different random seeds) has a substantial impact on the attained result and that a good run with a bad hyperparameter can beat a bad run with a good hyperparameter in many cases. Again, these findings   (left) FactorVAE score vs hyperparameters for each score on Cars3d. There seems to be no model dominating all the others and for each model there does not seem to be a consistent strategy in choosing the regularization strength. (center) Unsupervised scores vs disentanglement metrics on Shapes3D. Metrics are abbreviated ((A)=BetaVAE Score, (B)=FactorVAE Score, (C)=MIG , (D)=DCI Disentanglement, (E)=Modularity, (F)=SAP). The unsupervised scores we consider do not seem to be useful for model selection. (right) Rank-correlation of DCI disentanglement metric across different data sets. Good hyperparameters only seem to transfer between dSprites and Color-dSprites but not in between the other data sets.\nare consistent with the complete set of plots provided in Figure 14 of Appendix I.4.\nFinally, we perform a variance analysis by trying to predict the different disentanglement scores using ordinary least squares for each data set: If we allow the score to depend only on the objective function (treated as a categorical variable), we are only able to explain 37% of the variance of the scores on average (see Table 5 in Appendix I.4 for further details). Similarly, if the score depends on the Cartesian product of objective function and regularization strength (again categorical), we are able to explain 59% of the variance while the rest is due to the random seed.\nImplication. The disentanglement scores of unsupervised models are heavily influenced by randomness (in the form of the random seed) and the choice of the hyperparameter (in the form of the regularization strength). The objective function appears to have less impact.", "publication_ref": [], "figure_ref": ["fig_1", "fig_0", "fig_0", "fig_1", "fig_0"], "table_ref": []}, {"heading": "Are there reliable recipes for model selection?", "text": "In this section, we investigate how good hyperparameters can be chosen and how we can distinguish between good and bad training runs. In this paper, we advocate that that model selection should not depend on the considered disentanglement score for the following reasons: The point of unsupervised learning of disentangled representation is that there is no access to the labels as otherwise we could incorporate them and would have to compare to semi-supervised and fully supervised methods. All the disentanglement metrics considered in this paper require a substantial amount of ground-truth labels or the full generative model (for example for the BetaVAE and the FactorVAE metric). Hence, one may substantially bias the results of a study by tuning hyperparameters based on (supervised) disentanglement metrics. Furthermore, we argue that it is not sufficient to fix a set of hyperparameters a priori and then show that one of those hyperparameters and a specific random seed achieves a good disentanglement score as it amounts to showing the existence of a good model, but does not guide the practitioner in finding it. Finally, in many practical settings, we might not even have access to adequate labels as it may be hard to identify the true underlying factor of variations, in particular, if we consider data modalities that are less suitable to human interpretation than images.\nIn the remainder of this section, we hence investigate and assess different ways how hyperparameters and good model runs could be chosen. In this study, we focus on choosing the learning model and the regularization strength corresponding to that loss function. However, we note that in practice this problem is likely even harder as a practitioner might also want to tune other modeling choices such architecture or optimizer.\nGeneral recipes for hyperparameter selection. We first investigate whether we may find generally applicable \"rules of thumb\" for choosing the hyperparameters. For this, we plot in Figure 4 (left) the FactorVAE score against different regularization strengths for each model on the Cars3D data set whereas Figure 16 in Appendix I.5 shows the same plot for all data sets and disentanglement metrics. The values correspond to the median obtained values across 50 random seeds for each model, hyperparameter and data set. Overall, there seems to be no model consistently dominating all the others and for each model there does not seem to be a consistent strategy in choosing the regularization strength to maximize disentanglement scores. Furthermore, even if we could identify a good objective function and corresponding hyperparameter value, we still could not distinguish between a good and a bad training run.\nModel selection based on unsupervised scores. Another approach could be to select hyperparameters based on unsupervised scores such as the reconstruction error, the KL divergence between the prior and the approximate posterior, the Evidence Lower BOund or the estimated total correlation of the sampled representation (mean representation gives similar results). This would have the advantage that Table 1. Probability of outperforming random model selection on a different random seed. A random disentanglement metric and data set is sampled and used for model selection. That model is then compared to a randomly selected model: (i) on the same metric and data set, (ii) on the same metric and a random different data set, (iii) on a random different metric and the same data set, and (iv) on a random different metric and a random different data set. The results are averaged across 10 000 random draws.\nRandom data set Same data set Random metric 54.9% 62.6% Same metric 59.3% 80.7%\nwe could select specific trained models and not just good hyperparameter settings whose median trained model would perform well. To test whether such an approach is fruitful, we compute the rank correlation between these unsupervised metrics and the disentanglement metrics and present it in Figure 4 (center) for Shapes3D and in Figure 16 of Appendix I.5 for all the different data sets. While we do observe some correlations, no clear pattern emerges which leads us to conclude that this approach is unlikely to be successful in practice.\nHyperparameter selection based on transfer. The final strategy for hyperparameter selection that we consider is based on transferring good settings across data sets. The key idea is that good hyperparameter settings may be inferred on data sets where we have labels available (such as dSprites) and then applied to novel data sets. Figure 4 (right) shows the rank correlations obtained between different data sets for the DCI disentanglement (whereas Figure 17 in Appendix I.5 shows it for all data sets). We find a strong and consistent correlation between dSprites and Color-dSprites. While these results suggest that some transfer of hyperparameters is possible, it does not allow us to distinguish between good and bad random seeds on the target data set.\nTo illustrate this, we compare such a transfer based approach to hyperparameter selection to random model selection as follows: First, we sample one of our 50 random seeds, a random disentanglement metric and a data set and use them to select the hyperparameter setting with the highest attained score. Then, we compare that selected hyperparameter setting to a randomly selected model on either the same or a random different data set, based on either the same or a random different metric and for a randomly sampled seed. Finally, we report the percentage of trials in which this transfer strategy outperforms or performs equally well as random model selection across 10 000 trials in Table 1. If we choose the same metric and the same data set (but a different random seed), we obtain a score of 80.7%. If we aim to transfer for the same metric across data sets, we achieve around 59.3%. Finally, if we transfer both across metrics and data sets, our performance drops to 54.9%.  Implications. Unsupervised model selection remains an unsolved problem. Transfer of good hyperparameters between metrics and data sets does not seem to work as there appears to be no unsupervised way to distinguish between good and bad random seeds on the target task.\n5.5. Are these disentangled representations useful for downstream tasks in terms of the sample complexity of learning?\nOne of the key motivations behind disentangled representations is that they are assumed to be useful for later downstream tasks. In particular, it is argued that disentanglement should lead to a better sample complexity of learning (Bengio et al., 2013;Sch\u00f6lkopf et al., 2012;Peters et al., 2017). In this section, we consider the simplest downstream classification task where the goal is to recover the true factors of variations from the learned representation using either multi-class logistic regression (LR) or gradient boosted trees (GBT).\nFigure 5 shows the rank correlations between the disentanglement metrics and the downstream performance on dSprites. We observe that all metrics except Modularity seem to be correlated with increased downstream performance on the different variations of dSprites and to some degree on Shapes3D but not on the other data sets. However, it is not clear whether this is due to the fact that disentangled representations perform better or whether some of these scores actually also (partially) capture the informativeness of the evaluated representation. Furthermore, the full results in Figure 19 of Appendix I.6 indicate that the correlation is weaker or inexistent on other data sets (e.g. Cars3D).\nTo assess the sample complexity argument we compute for each trained model a statistical efficiency score which we define as the average accuracy based on 100 samples divided by the average accuracy based on 10 000 samples. Figure 6 show the sample efficiency of learning (based on GBT) versus the FactorVAE Score on dSprites. We do not observe that higher disentanglement scores reliably lead to a higher sample efficiency. This finding which appears to be consistent with the results in Figures 20-23 of Appendix I.6. Implications. While the empirical results in this section are negative, they should also be interpreted with care. After all, we have seen in previous sections that the models considered in this study fail to reliably produce disentangled representations. Hence, the results in this section might change if one were to consider a different set of models, for example semi-supervised or fully supervised one. Furthermore, there are many more potential notions of usefulness such as interpretability and fairness that we have not considered in our experimental evaluation. Nevertheless, we argue that the lack of concrete examples of useful disentangled representations necessitates that future work on disentanglement methods should make this point more explicit. While prior work (Steenbrugge et al., 2018;Laversanne-Finot et al., 2018;Nair et al., 2018;Higgins et al., 2017b;2018) successfully applied disentanglement methods such as \u03b2-VAE on a variety of downstream tasks, it is not clear to us that these approaches and trained models performed well because of disentanglement.", "publication_ref": ["b2"], "figure_ref": ["fig_3", "fig_0", "fig_3", "fig_0", "fig_3", "fig_0", "fig_4", "fig_0", "fig_5"], "table_ref": []}, {"heading": "Conclusions", "text": "In this work we first theoretically show that the unsupervised learning of disentangled representations is fundamentally impossible without inductive biases. We then performed a large-scale empirical study with six state-of-the-art disentanglement methods, six disentanglement metrics on seven data sets and conclude the following: (i) A factorizing aggregated posterior (which is sampled) does not seem to necessarily imply that the dimensions in the representation (which is taken to be the mean) are uncorrelated. (ii) Random seeds and hyperparameters seem to matter more than the model but tuning seem to require supervision. (iii)\nWe did not observe that increased disentanglement implies a decreased sample complexity of learning downstream tasks. Based on these findings, we suggest three main directions for future research:\nInductive biases and implicit and explicit supervision.\nOur theoretical impossibility result in Section 3 highlights the need of inductive biases while our experimental results indicate that the role of supervision is crucial. As currently there does not seem to exist a reliable strategy to choose hyperparameters in the unsupervised learning of disentangled representations, we argue that future work should make the role of inductive biases and implicit and explicit supervision more explicit. We would encourage and motivate future work on disentangled representation learning that deviates from the static, purely unsupervised setting considered in this work. Promising settings (that have been explored to some degree) seem to be for example (i) disentanglement learning with interactions (Thomas et al., 2017), (ii) when weak forms of supervision e.g.\nthrough grouping information are available (Bouchacourt et al., 2018), or (iii) when temporal structure is available for the learning problem. The last setting seems to be particularly interesting given recent identifiability results in non-linear ICA (Hyvarinen & Morioka, 2016).\nConcrete practical benefits of disentangled representations. In our experiments we investigated whether higher disentanglement scores lead to increased sample efficiency for downstream tasks and did not find evidence that this is the case. While these results only apply to the setting and downstream task used in our study, we are also not aware of other prior work that compellingly shows the usefulness of disentangled representations. Hence, we argue that future work should aim to show concrete benefits of disentangled representations. Interpretability and fairness as well as interactive settings seem to be particularly promising candidates to evaluate usefulness. One potential approach to include inductive biases, offer interpretability, and generalization is the concept of independent causal mechanisms and the framework of causal inference (Pearl, 2009;Peters et al., 2017).\nExperimental setup and diversity of data sets. Our study also highlights the need for a sound, robust, and reproducible experimental setup on a diverse set of data sets in order to draw valid conclusions. We have observed that it is easy to draw spurious conclusions from experimental results if one only considers a subset of methods, metrics and data sets. Hence, we argue that it is crucial for future work to perform experiments on a wide variety of data sets to see whether conclusions and insights are generally applicable. This is particularly important in the setting of disentanglement learning as experiments are largely performed on toy-like data sets. For this reason, we released disentanglement_lib, the library we created to train and evaluate the different disentanglement methods on multiple data sets. We also released more than 10 000 trained models to provide a solid baseline for future methods and metrics.    ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A. Proof of Theorem 1", "text": "Proof. To show the claim, we explicitly construct a family of functions f using a sequence of bijective functions. Let d > 1 be the dimensionality of the latent variable z and consider the function g : supp(z) \u2192 [0, 1] d defined by\ng i (v) = P (z i \u2264 v i ) \u2200i = 1, 2, . . . , d.\nSince P admits a density p(z) = i p(z i ), the function g is bijective and, for almost every v \u2208 supp(z), it holds that \u2202gi(v) \u2202vi = 0 for all i and \u2202gi(v) \u2202vj = 0 for all i = j. Furthermore, it is easy to see that, by construction, g(z) is a independent d-dimensional uniform distribution. Similarly, consider the function h :\n(0, 1] d \u2192 R d defined by h i (v) = \u03c8 \u22121 (v i ) \u2200i = 1, 2, . . . , d,\nwhere \u03c8(\u2022) denotes the cumulative density function of a standard normal distribution. Again, by definition, h is bijective with \u2202hi(v) \u2202vi = 0 for all i and \u2202hi(v) \u2202vj = 0 for all i = j. Furthermore, the random variable h(g(z)) is a d-dimensional standard normal distribution.\nLet A \u2208 R d\u00d7d be an arbitrary orthogonal matrix with A ij = 0 for all i = 1, 2, . . . , d and j = 1, 2, . . . , d. An infinite family of such matrices can be constructed using a Householder transformation: Choose an arbitrary \u03b1 \u2208 (0, 0.5) and consider the vector v with v 1 = \u221a \u03b1 and v i = 1\u2212\u03b1 d\u22121 for i = 2, 3, . . . , d. By construction, we have v T v = 1 and both v i = 0 and v i = 1 2 for all i = 1, 2, . . . , d. Define the matrix A = I d \u2212 2vv T and note that A ii = 1 \u2212 2v 2 i = 0 for all 1, 2, . . . , d as well as A ij = \u2212v i v j = 0 for all i = j. Furthermore, A is orthogonal since\nA T A = I d \u2212 2vv T T I d \u2212 2vv T = I d \u2212 4vv T + 4v(v T v)v T = I d .\nSince A is orthogonal, it is invertible and thus defines a bijective linear operator. The random variable Ah(g(z)) \u2208 R d is hence an independent, multivariate standard normal distribution since the covariance matrix A T A is equal to I d .\nSince h is bijective, it follows that h \u22121 (Ah(g(z))) is an independent d-dimensional uniform distribution. Define the function f : supp(z) \u2192 supp(z)\nf (u) = g \u22121 (h \u22121 (Ah(g(u))))\nand note that by definition f (z) has the same marginal distribution as z under P , i.e., P (z \u2264 u) = P (f (z) \u2264 u) for all u. Finally, for almost every u \u2208 supp(z), it holds that\n\u2202f i (u) \u2202u j = A ij \u2022 \u2202hj (g(u)) \u2202vj \u2022 \u2202gj (u) \u2202uj \u2202hi(h \u22121 i (Ah(g(u))) \u2202vi \u2022 \u2202gi(g \u22121 (h \u22121 (Ah(g(u))))) \u2202vi = 0,\nas claimed. Since the choice of A was arbitrary, there exists an infinite family of such functions f .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B. Unsupervised learning of disentangled representations with VAEs", "text": "Variants of variational autoencoders (Kingma & Welling, 2014) are considered the state-of-the-art for unsupervised disentanglement learning. One assumes a specific prior P (z) on the latent space and then parameterizes the conditional probability P (x|z) with a deep neural network. Similarly, the distribution P (z|x) is approximated using a variational distribution Q(z|x), again parametrized using a deep neural network. One can then derive the following approximation to the maximum likelihood objective,\nmax \u03c6,\u03b8 E p(x) [E q \u03c6 (z|x) [log p \u03b8 (x|z)] \u2212 D KL (q \u03c6 (z|x) p(z))](1)\nwhich is also know as the evidence lower bound (ELBO). By carefully considering the KL term, one can encourage various properties of the resulting presentation. We will briefly review the main approaches.\nBottleneck capacity. Higgins et al. (2017a) propose the \u03b2-VAE, introducing a hyperparameter in front of the KL regularizer of vanilla VAEs. They maximize the following expression:\nE p(x) [E q \u03c6 (z|x) [log p \u03b8 (x|z)] \u2212 \u03b2D KL (q \u03c6 (z|x) p(z))]\nBy setting \u03b2 > 1, the encoder distribution will be forced to better match the factorized unit Gaussian prior. This procedure introduces additional constraints on the capacity of the latent bottleneck, encouraging the encoder to learn a disentangled representation for the data. Burgess et al. ( 2017) argue that when the bottleneck has limited capacity, the network will be forced to specialize on the factor of variation that most contributes to a small reconstruction error. Therefore, they propose to progressively increase the bottleneck capacity, so that the encoder can focus on learning one factor of variation at the time:\nE p(x) [E q \u03c6 (z|x) [log p \u03b8 (x|z)] \u2212 \u03b3|D KL (q \u03c6 (z|x) p(z)) \u2212 C|]\nwhere C is annealed from zero to some value which is large enough to produce good reconstruction. In the following, we refer to this model as AnnealedVAE.\nPenalizing the total correlation. Let I(x; z) denote the mutual information between x and z and note that the second term in equation 1 can be rewritten as\nE p(x) [D KL (q \u03c6 (z|x) p(z))] = I(x; z) + D KL (q(z) p(z)).\nTherefore, when \u03b2 > 1, \u03b2-VAE penalizes the mutual information between the latent representation and the data, thus constraining the capacity of the latent space. Furthermore, it pushes q(z), the so called aggregated posterior, to match the prior and therefore to factorize, given a factorized prior. Kim & Mnih (2018) argues that penalizing I(x; z) is neither necessary nor desirable for disentanglement. The FactorVAE (Kim & Mnih, 2018) and the \u03b2-TCVAE (Chen et al., 2018) augment the VAE objective with an additional regularizer that specifically penalizes dependencies between the dimensions of the representation:\nE p(x) [E q \u03c6 (z|x) [log p \u03b8 (x|z)] \u2212 D KL (q \u03c6 (z|x) p(z))] \u2212 \u03b3D KL (q(z) d j=1 q(z j )).\nThis last term is also known as total correlation (Watanabe, 1960). The total correlation is intractable and vanilla Monte Carlo approximations require marginalization over the training set. (Kim & Mnih, 2018) propose an estimate using the density ratio trick (Nguyen et al., 2010;Sugiyama et al., 2012) (FactorVAE). Samples from d j=1 q(z j ) can be obtained shuffling samples from q(z) (Arcones & Gine, 1992). Concurrently, Chen et al. (2018) propose a tractable biased Monte-Carlo estimate for the total correlation (\u03b2-TCVAE).\nDisentangled priors. Kumar et al. (2017) argue that a disentangled generative model requires a disentangled prior. This approach is related to the total correlation penalty, but now the aggregated posterior is pushed to match a factorized prior. Therefore\nE p(x) [E q \u03c6 (z|x) [log p \u03b8 (x|z)] \u2212 D KL (q \u03c6 (z|x) p(z))] \u2212 \u03bbD(q(z) p(z)),\nwhere D is some (arbitrary) divergence. Since this term is intractable when D is the KL divergence, they propose to match the moments of these distribution. In particular, they regularize the deviation of either Cov p(x) [\u00b5 \u03c6 (x)] or Cov q \u03c6 [z] from the identity matrix in the two variants of the DIP-VAE. This results in maximizing either the DIP-VAE-I objective\nE p(x) [E q \u03c6 (z|x) [log p \u03b8 (x|z)] \u2212 D KL (q \u03c6 (z|x) p(z))] \u2212 \u03bb od i =j Cov p(x) [\u00b5 \u03c6 (x)] 2 ij \u2212 \u03bb d i Cov p(x) [\u00b5 \u03c6 (x)] ii \u2212 1 2 or the DIP-VAE-II objective E p(x) [E q \u03c6 (z|x) [log p \u03b8 (x|z)] \u2212 D KL (q \u03c6 (z|x) p(z))] \u2212 \u03bb od i =j Cov q \u03c6 [z] 2 ij \u2212 \u03bb d i Cov q \u03c6 [z] ii \u2212 1 2 .", "publication_ref": ["b0"], "figure_ref": [], "table_ref": []}, {"heading": "C. Implementation of metrics", "text": "All our metrics consider the expected representation of training samples (except total correlation for which we also consider the sampled representation as described in Section 5).\nBetaVAE metric. Higgins et al. (2017a) suggest to fix a random factor of variation in the underlying generative model and to sample two mini batches of observations x. Disentanglement is then measured as the accuracy of a linear classifier that predicts the index of the fixed factor based on the coordinate-wise sum of absolute differences between the representation vectors in the two mini batches. We sample two batches of 64 points with a random factor fixed to a randomly sampled value across the two batches and the others varying randomly. We compute the mean representations for these points and take the absolute difference between pairs from the two batches. We then average these 64 values to form the features of a training (or testing) point. We train a Scikit-learn logistic regression with default parameters on 10 000 points. We test on 5000 points.\nFactorVAE metric Kim & Mnih (2018) address several issues with this metric by using a majority vote classifier that predicts the index of the fixed ground-truth factor based on the index of the representation vector with the least variance. First, we estimate the variance of each latent dimension by embedding 10 000 random samples from the data set and we exclude collapsed dimensions with variance smaller than 0.05. Second, we generate the votes for the majority vote classifier by sampling a batch of 64 points, all with a factor fixed to the same random value. Third, we compute the variance of each dimension of their latent representation and divide by the variance of that dimension we computed on the data without interventions. The training point for the majority vote classifier consists of the index of the dimension with the smallest normalized variance. We train on 10 000 points and evaluate on 5000 points.\nMutual Information Gap. Chen et al. ( 2018) argue that the BetaVAE metric and the FactorVAE metric are neither general nor unbiased as they depend on some hyperparameters. They compute the mutual information between each ground truth factor and each dimension in the computed representation r(x). For each ground-truth factor z k , they then consider the two dimensions in r(x) that have the highest and second highest mutual information with z k . The Mutual Information Gap (MIG) is then defined as the average, normalized difference between the highest and second highest mutual information of each factor with the dimensions of the representation. The original metric was proposed evaluating the sampled representation. Instead, we consider the mean representation, in order to be consistent with the other metrics. We estimate the discrete mutual information by binning each dimension of the representations obtained from 10 000 points into 20 bins. Then, the score is computed as follows:\n1 K K k=1 1 H z k I(v j k , z k ) \u2212 max j =j k I(v j , z k )\nWhere z k is a factor of variation, v j is a dimension of the latent representation and j k = arg max j I(v j , z k ).\nModularity. Ridgeway & Mozer (2018) argue that two different properties of representations should be considered, i.e., Modularity and Explicitness. In a modular representation each dimension of r(x) depends on at most a single factor of variation. In an explicit representation, the value of a factor of variation is easily predictable (i.e. with a linear model) from r(x). They propose to measure the Modularity as the average normalized squared difference of the mutual information of the factor of variations with the highest and second-highest mutual information with a dimension of r(x). They measure Explicitness as the ROC-AUC of a one-versus-rest logistic regression classifier trained to predict the factors of variation. In this study, we focus on Modularity as it is the property that corresponds to disentanglement. For the modularity score, we sample 10 000 points for which we obtain the latent representations. We discretize these points into 20 bins and compute the mutual information between representations and the values of the factors of variation. These values are stored in a matrix m.\nFor each dimension of the representation i, we compute a vector t i as:\nt i,f = \u03b8 i if f = arg max g m i,g0\notherwise\nwhere \u03b8 i = max g m ig .\nThe modularity score is the average over the dimensions of the representation of 1 \u2212 \u03b4 i where:\n\u03b4 i = f (m if \u2212 t if ) 2 \u03b8 2 i (N \u2212 1)\nand N is the number of factors. DCI Disentanglement. Eastwood & Williams (2018) consider three properties of representations, i.e., Disentanglement, Completeness and Informativeness. First, Eastwood & Williams (2018) compute the importance of each dimension of the learned representation for predicting a factor of variation. The predictive importance of the dimensions of r(x) can be computed with a Lasso or a Random Forest classifier. Disentanglement is the average of the difference from one of the entropy of the probability that a dimension of the learned representation is useful for predicting a factor weighted by the relative importance of each dimension. Completeness, is the average of the difference from one of the entropy of the probability that a factor of variation is captured by a dimension of the learned representation. Finally, the Informativeness can be computed as the prediction error of predicting the factors of variations. We sample 10 000 and 5000 training and test points respectively. For each factor, we fit gradient boosted trees from Scikit-learn with the default setting. From this model, we extract the importance weights for the feature dimensions. We take the absolute value of these weights and use them to form the importance matrix R, whose rows correspond to factors and columns to the representation. To compute the disentanglement score, we first subtract from 1 the entropy of each column of this matrix (we treat the columns as a distribution by normalizing them). This gives a vector of length equal to the dimensionality of the latent space. Then, we compute the relative importance of each dimension by \u03c1 i = j R ij / ij R ij and the disentanglement score as\ni \u03c1 i (1 \u2212 H(R i )).\nSAP score. Kumar et al. (2017) propose to compute the R 2 score of the linear regression predicting the factor values from each dimension of the learned representation. For discrete factors, they propose to train a classifier. The Separated Attribute Predictability (SAP) score is the average difference of the prediction error of the two most predictive latent dimensions for each factor. We sample 10 000 points for training and 5000 for testing. We then compute a score matrix containing the prediction error on the test set for a linear SVM with C = 0.01 predicting the value of a factor from a single latent dimension. The SAP score is computed as the average across factors of the difference between the top two most predictive latent dimensions.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Downstream task.", "text": "We sample training sets of different sizes: 10, 100, 1000 and 10 000 points. We always evaluate on 5000 samples. We consider as a downstream task the prediction of the values of each factor from r(x). For each factor we fit a different model and report then report the average test accuracy across factors. We consider two different models. First, we train a cross validated logistic regression from Scikit-learn with 10 different values for the regularization strength (Cs = 10) and 5 folds. Finally, we train a gradient boosting classifier from Scikit-learn with default parameters.\nTotal correlation based on fitted Gaussian. We sample 10 000 points and obtain their latent representation r(x) by either sampling from the encoder distribution of by taking its mean. We then compute the mean \u00b5 r(x) and covariance matrix \u03a3 r(x) of these points and compute the total correlation of a Gaussian with mean \u00b5 r(x) and covariance matrix \u03a3 r(x) , i.e.,\nD KL \uf8eb \uf8ed N (\u00b5 r(x) , \u03a3 r(x) ) j N (\u00b5 r(x)j , \u03a3 r(x)jj ) \uf8f6 \uf8f8\nwhere j indexes the dimensions in the latent space. We choose this approach for the following reasons: In this study, we compute statistics of r(x) which can be either sampled from the probabilistic encoder or taken to be its mean. We argue that estimating the total correlation as in (Kim & Mnih, 2018) is not suitable for this comparison as it consistently underestimate the true value (see Figure 7 in (Kim & Mnih, 2018)) and depends on a non-convex optimization procedure (for fitting the discriminator). The estimate of (Chen et al., 2018) is also not suitable as the mean representation is a deterministic function for the data, therefore we cannot use the encoder distribution for the estimate. Furthermore, we argue that the total correlation based on the fitted Gaussian provides a simple and robust way to detect if a representation is not factorizing based on the first two moments. In particular, if it is high, it is a strong signal that the representation is not factorizing (while a low score may not imply the opposite). We note that this procedure is similar to the penalty of DIP-VAE-I. Therefore, it is not surprising that DIP-VAE-I achieves a low score for the mean representation.", "publication_ref": [], "figure_ref": ["fig_8"], "table_ref": []}, {"heading": "D. Experimental conditions and guiding principles.", "text": "In our study, we seek controlled, fair and reproducible experimental conditions. We consider the case in which we can sample from a well defined and known ground-truth generative model by first sampling the factors of variations from a distribution P (z) and then sampling an observation from P (x|z). Our experimental protocol works as follows: During training, we only observe the samples of x obtained by marginalizing P (x|z) over P (z). After training, we obtain a representation r(x) by either taking a sample from the probabilistic encoder Q(z|x) or by taking its mean. Typically, disentanglement metrics consider the latter as the representation r(x). During the evaluation, we assume to have access to the whole generative model, i.e. we can draw samples from both P (z) and P (x|z). In this way, we can perform interventions on the latent factors as required by certain evaluation metrics. We explicitly note that we effectively consider the statistical learning problem where we optimize the loss and the metrics on the known data generating distribution. As a result, we do not use separate train and test sets but always take i.i.d. samples from the known ground-truth distribution. This is justified as the statistical problem is well defined and it allows us to remove the additional complexity of dealing with overfitting and empirical risk minimization.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "E. Limitations of our study.", "text": "While we aim to provide a useful and fair experimental study, there are clear limitations to the conclusions that can be drawn from it due to design choices that we have taken. In all these choices, we have aimed to capture what is considered the state-of-the-art inductive bias in the community.\nOn the data set side, we only consider images with a heavy focus on synthetic images. We do not explore other modalities and we only consider the toy scenario in which we have access to a data generative process with uniformly distributed factors of variations. Furthermore, all our data sets have a small number of independent discrete factors of variations without any confounding variables.\nFor the methods, we only consider the inductive bias of convolutional architectures. We do not test fully connected architectures or additional techniques such as skip connections. Furthermore, we do not explore different activation functions, reconstruction losses or different number of layers. We also do not vary any other hyperparameters other than the regularization weight. In particular, we do not evaluate the role of different latent space sizes, optimizers and batch sizes. We do not test the sample efficiency of the metrics but simply set the size of the train and test set to large values.\nImplementing the different disentanglement methods and metrics has proven to be a difficult endeavour. Few \"official\" open source implementations are available and there are many small details to consider. We take a best-effort approach to these implementations and implemented all the methods and metrics from scratch as any sound machine learning practitioner might do based on the original papers. When taking different implementation choices than the original papers, we explicitly state and motivate them.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "F. Differences with previous implementations.", "text": "As described above, we use a single choice of architecture, batch size and optimizer for all the methods which might deviate from the settings considered in the original papers. However, we argue that unification of these choices is the only way to guarantee a fair comparison among the different methods such that valid conclusions may be drawn in between methods. The largest change is that for DIP-VAE and for \u03b2-TCVAE we used a batch size of 64 instead of 400 and 2048 respectively. However, Chen et al. (2018) shows in Section H.2 of the Appendix that the bias in the mini-batch estimation of the total correlation does not significantly affect the performances of their model even with small batch sizes. For DIP-VAE-II, we did not implement the additional regularizer on the third order central moments since no implementation details are provided and since this regularizer is only used on specific data sets.\nOur implementations of the disentanglement metrics deviate from the implementations in the original papers as follows: First, we strictly enforce that all factors of variations are treated as discrete variables as this corresponds to the assumed ground-truth model in all our data sets. Hence, we used classification instead of regression for the SAP score and the disentanglement score of (Eastwood & Williams, 2018). This is important as it does not make sense to use regression on true factors of variations that are discrete (e.g., shape on dSprites). Second, wherever possible, we resorted to using the default, well-tested Scikit-learn (Pedregosa et al., 2011) implementations instead of using custom implementations with potentially hard to set hyperparameters. Third, for the Mutual Information Gap (Chen et al., 2018), we estimate the discrete mutual information (as opposed to continuous) on the mean representation (as opposed to sampled) on a subset of the samples (as opposed to the whole data set). We argue that this is the correct choice as the mean is usually taken to be the representation. Hence, it would be wrong to consider the full Gaussian encoder or samples thereof as that would correspond to a different representation. Finally, we fix the number of sampled train and test points across all metrics to a large value to ensure robustness.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "G. Main experiment hyperparameters", "text": "In our study, we fix all hyperparameters except one per each model. Model specific hyperparameters can be found in Table 3. The common architecture is depicted in Table 2 along with the other fixed hyperparameters in Table 4a. For the discriminator in FactorVAE we use the architecture in Table 4b with hyperparameters in Table 4c. All the hyperparameters for which we report single values were not varied and are selected based on the literature.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_6", "tab_6", "tab_6"]}, {"heading": "H. Data sets and preprocessing", "text": "All the data sets contains images with pixels between 0 and 1. Color-dSprites: Every time we sample a point, we also sample a random scaling for each channel uniformly between 0.5 and 1. Noisy-dSprites: Every time we sample a point, we fill the background with uniform noise. Scream-dSprites: Every time we sample a point, we sample a random 64 \u00d7 64 patch of The Scream painting. We then change the color distribution by adding a random uniform number to each channel and divide the result by two. Then, we embed the dSprites shape by inverting the colors of each of its pixels. ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "I. Detailed experimental results", "text": "Given the breadth of the experimental study, we summarized our key findings in Section 5 and presented figures that we picked to be representative of our results. This section contains a self-contained presentation of all our experimental results. In particular, we present a complete set of plots for the different methods, data sets and disentanglement metrics.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "I.1. Can one achieve a good reconstruction error across data sets and models?", "text": "First, we check for each data set that we manage to train models that achieve reasonable reconstructions. Therefore, for each data set we sample a random model and show real samples next to their reconstructions. The results are depicted in Figure 7. As expected, the additional variants of dSprites with continuous noise variables are harder than the original data set. On Noisy-dSprites and Color-dSprites the models produce reasonable reconstructions with the noise on Noisy-dSprites being ignored. Scream-dSprites is even harder and we observe that the shape information is lost. On the other data sets, we observe that reconstructions are blurry but objects are distinguishable. SmallNORB seems to be the most challenging data set.", "publication_ref": [], "figure_ref": ["fig_8"], "table_ref": []}, {"heading": "I.2. Can current methods enforce a uncorrelated aggregated posterior and representation?", "text": "We investigate whether the considered unsupervised disentanglement approaches are effective at enforcing a factorizing and thus uncorrelated aggregated posterior. For each trained model, we sample 10 000 images and compute a sample from the corresponding approximate posterior. We then fit a multivariate Gaussian distribution over these 10 000 samples by computing the empirical mean and covariance matrix. Finally, we compute the total correlation of the fitted Gaussian and report the median value for each data set, method and hyperparameter value.\nFigure 8 shows the total correlation of the sampled representation plotted against the regularization strength for each data set and method except AnnealedVAE. On all data sets except SmallNORB, we observe that plain vanilla variational autoencoders (i.e. the \u03b2-VAE model with \u03b2 = 1) exhibit the highest total correlation. For \u03b2-VAE and \u03b2-TCVAE, it can be clearly seen that the total correlation of the sampled representation decreases on all data sets as the regularization strength (in the form of \u03b2) is increased. The two variants of DIP-VAE exhibit low total correlation across the data sets except DIP-VAE-I which incurs a slightly higher total correlation on SmallNORB compared to a vanilla VAE. Increased regularization in the DIP-VAE objective also seems to lead a reduced total correlation, even if the effect is not as pronounced as for \u03b2-VAE and \u03b2-TCVAE. While FactorVAE achieves a low total correlation on all data sets except on SmallNORB, we observe that the total correlation does not seem to decrease with increasing regularization strength. We further observe that AnnealedVAE (shown in Figure 25) is much more sensitive to the regularization strength. However, on all data sets except Scream-dSprites (on which AnnealedVAE performs poorly), the total correlation seems to decrease with increased regularization strength.\nWhile many of the considered methods aim to enforce a factorizing aggregated posterior, they use the mean vector of the Gaussian encoder as the representation and not a sample from the Gaussian encoder. This may seem like a minor, irrelevant modification; however, it is not clear whether a factorizing aggregated posterior also ensures that the dimensions of the mean representation are uncorrelated. To test whether this is true, we compute the mean of the Gaussian encoder for the same 10 000 samples, fit a multivariate Gaussian and compute the total correlation of that fitted Gaussian. Figure 9 shows . Reconstructions for different data sets and methods. Odd columns show real samples and even columns their reconstruction. As expected, the additional variants of dSprites with continuous noise variables are harder than the original data set. On Noisy-dSprites and Color-dSprites the models produce reasonable reconstructions with the noise on Noisy-dSprites being ignored. Scream-dSprites is even harder and we observe that the shape information is lost. On the other data sets, we observe that reconstructions are blurry but objects are distinguishable.  Figure 10. Log total correlation of mean vs sampled representations. For a large number of models, the total correlation of the mean representation is higher than that of the sampled representation.\nthe total correlation of the mean representation plotted against the regularization strength for each data set and method except AnnealedVAE. We observe that, for \u03b2-VAE and \u03b2-TCVAE, increased regularization leads to a substantially increased total correlation of the mean representations. This effect can also be observed for for FactorVAE, albeit in a less extreme fashion. For DIP-VAE-I, we observe that the total correlation of the mean representation is consistently low. This is not surprising as the DIP-VAE-I objective directly optimizes the covariance matrix of the mean representation to be diagonal which implies that the corresponding total correlation (as we compute it) is low. The DIP-VAE-II objective which enforces the covariance matrix of the sampled representation to be diagonal seems to lead to a factorized mean representation on some data sets (for example Shapes3D and Cars3d), but also seems to fail on others (dSprites). For AnnealedVAE (shown in Figure 26), we overall observe mean representations with a very high total correlation. In Figure 10, we further plot the log total correlations of the sampled representations versus the mean representations for each of the trained models.\nIt can be clearly seen that for a large number of models, the total correlation of the mean representations is much higher than that of the sampled representations. The same trend can be seen computing the average discrete mutual information of the representation. In this case, the DIP-VAE-I exhibit increasing mutual information in both the mean and sampled representation. This is to be expected as DIP-VAE-I enforces a variance of one for the mean representation. We remark that as the regularization terms and hyperparameter values are different for different losses, one should not draw conclusions from comparing different models at nominally the same regularization strength. From these plots one can only compare the effect of increasing the regularization in the different models.\nImplications. Overall, these results lead us to conclude with minor exceptions that the considered methods are effective at enforcing an aggregated posterior whose individual dimensions are not correlated but that this does not seem to imply that the dimensions of the mean representation (usually used for representation) are uncorrelated.", "publication_ref": [], "figure_ref": ["fig_4", "fig_0", "fig_5", "fig_0"], "table_ref": []}, {"heading": "I.3. How much do existing disentanglement metrics agree?", "text": "As there exists no single, common definition of disentanglement, an interesting question is to see how much different proposed metrics agree. Figure 11 shows pairwise scatter plots of the different considered metrics on dSprites where each point corresponds to a trained model, while Figure 12 shows the Spearman rank correlation between different disentanglement metrics on different data sets. Overall, we observe that all metrics except Modularity seem to be correlated strongly on the data sets dSprites, Color-dSprites and Scream-dSprites and mildly on the other data sets. There appear to be two pairs among these metrics that capture particularly similar notions: the BetaVAE and the FactorVAE score as well as the  Mutual Information Gap and DCI Disentanglement.\nImplication. All disentanglement metrics except Modularity appear to be correlated. However, the level of correlation changes between different data sets.", "publication_ref": [], "figure_ref": ["fig_0", "fig_0"], "table_ref": []}, {"heading": "I.4. How important are different models and hyperparameters for disentanglement?", "text": "The primary motivation behind the considered methods is that they should lead to improved disentanglement scores. This raises the question how disentanglement is affected by the model choice, the hyperparameter selection and randomness (in the form of different random seeds). To investigate this, we compute all the considered disentanglement metrics for each of our trained models. In Figure 13, we show the range of attainable disentanglement scores for each method on each data set. We observe that these ranges are heavily overlapping for different models leading us to (qualitatively) conclude that the choice of hyperparameters and the random seed seems to be substantially more important than the choice of objective function. While certain models seem to attain better maximum scores on specific data sets and disentanglement metrics, we do not observe any consistent pattern that one model is consistently better than the other. Furthermore, we note that in our study we have fixed the range of hyperparameters a priori to six different values for each model and did not explore additional hyperparameters based on the results (as that would bias our study). However, this also means that specific models may have performed better than in Figure 13 if we had chosen a different set of hyperparameters. In Figure 14, we further show the impact of randomness in the form of random seeds on the disentanglement scores. Each violin plot shows the distribution of the disentanglement metric across all 50 trained models for each model and hyperparameter setting on Cars3D. We clearly see that randomness (in the form of different random seeds) has a substantial impact on the attained result and that a good run with a bad hyperparameter can beat a bad run with a good hyperparameter in many cases.\nFinally, we perform a variance analysis by trying to predict the different disentanglement scores using ordinary least squares for each data set: If we allow the score to depend only on the objective function (categorical variable), we are only able to explain 37% of the variance of the scores on average. Similarly, if the score depends on the Cartesian product of objective function and regularization strength (again categorical), we are able to explain 59% of the variance while the rest is due to the random seed. In Table 5, we report the percentage of variance explained for the different metrics in each data set ). The scores are heavily overlapping and we do not observe a consistent pattern. We conclude that hyperparameters matter more than the model choice. We clearly see that randomness (in the form of different random seeds) has a substantial impact on the attained result and that a good run with a bad hyperparameter can beat a bad run with a good hyperparameter in many cases.\nTable 5. Variance of the disentanglement scores explained by the objective function or its cartesian product with the hyperparameters. The variance explained is computed regressing using ordinary least squares.\n(a) Percentage of variance explained regressing the disentanglement scores on the different data sets from the objective function only. considering the regularization strength or not.\nImplication. The disentanglement scores of unsupervised models are heavily influenced by randomness (in the form of the random seed) and the choice of the hyperparameter (in the form of the regularization strength). The objective function appears to have less impact.\nI.5. Are there reliable recipes for model selection?\nIn this section, we investigate how good hyperparameters can be chosen and how we can distinguish between good and bad training runs. In this paper, we advocate that model selection should not depend on the considered disentanglement score for the following reasons: The point of unsupervised learning of disentangled representation is that there is no access to the labels as otherwise we could incorporate them and would have to compare to semi-supervised and fully supervised methods. All the disentanglement metrics considered in this paper require a substantial amount of ground-truth labels or the full generative model (for example for the BetaVAE and the FactorVAE metric). Hence, one may substantially bias the results of a study by tuning hyperparameters based on (supervised) disentanglement metrics. Furthermore, we argue that it is not sufficient to fix a set of hyperparameters a priori and then show that one of those hyperparameters and a specific random seed achieves a good disentanglement score as it amounts to showing the existence of a good model, but does not guide the practitioner in finding it. Finally, in many practical settings, we might not even have access to adequate labels as it may be hard to identify the true underlying factor of variations, in particular, if we consider data modalities that are less suitable to human interpretation than images.\nIn the remainder of this section, we hence investigate and assess different ways how hyperparameters and good model runs could be chosen. In this study, we focus on choosing the learning model and the regularization strength corresponding to that loss function. However, we note that in practice this problem is likely even harder as a practitioner might also want to tune other modeling choices such architecture or optimizer.\nGeneral recipes for hyperparameter selection. We first investigate whether we may find generally applicable \"rules of thumb\" for choosing the hyperparameters. For this, we plot in Figure 15 different disentanglement metrics against different regularization strengths for each model and each data set. The values correspond to the median obtained values across Table 6. Probability of outperforming random model selection on a different random seed. A random disentanglement metric and data set is sampled and used for model selection. That model is then compared to a randomly selected model: (i) on the same metric and data set, (ii) on the same metric and a random different data set, (iii) on a random different metric and the same data set, and (iv) on a random different metric and a random different data set. The results are averaged across 10 000 random draws. 50 random seeds for each model, hyperparameter and data set. There seems to be no model dominating all the others and for each model there does not seem to be a consistent strategy in choosing the regularization strength to maximize disentanglement scores. Furthermore, even if we could identify a good objective function and corresponding hyperparameter value, we still could not distinguish between a good and a bad training run.\nModel selection based on unsupervised scores. Another approach could be to select hyperparameters based on unsupervised scores such as the reconstruction error, the KL divergence between the prior and the approximate posterior, the Evidence Lower Bound or the estimated total correlation of the sampled representation. This would have the advantage that we could select specific trained models and not just good hyperparameter settings whose median trained model would perform well. To test whether such an approach is fruitful, we compute the rank correlation between these unsupervised metrics and the disentanglement metrics and present it in Figure 16. While we do observe some correlations, no clear pattern emerges which leads us to conclude that this approach is unlikely to be successful in practice.\nHyperparameter selection based on transfer. The final strategy for hyperparameter selection that we consider is based on transferring good settings across data sets. The key idea is that good hyperparameter settings may be inferred on data sets where we have labels available (such as dSprites) and then applied to novel data sets. To test this idea, we plot in Figure 18 the different disentanglement scores obtained on dSprites against the scores obtained on other data sets. To ensure robustness of the results, we again consider the median across all 50 runs for each model, regularization strength, and data set. We observe that the scores on Color-dSprites seem to be strongly correlated with the scores obtained on the regular version of dSprites. Figure 17 further shows the rank correlations obtained between different data sets for each disentanglement scores. This confirms the strong and consistent correlation between dSprites and Color-dSprites. While these result suggest that some transfer of hyperparameters is possible, it does not allow us to distinguish between good and bad random seeds on the target data set.\nTo illustrate this, we compare such a transfer based approach to hyperparameter selection to random model selection as follows: We first randomly sample one of our 50 random seeds and consider the set of trained models with that random seed. First, we sample one of our 50 random seeds, a random disentanglement metric and a data set and use them to select the hyperparameter setting with the highest attained score. Then, we compare that selected hyperparameter setting to a randomly selected model on either the same or a random different data set, based on either the same or a random different metric and for a randomly sampled seed. Finally, we report the percentage of trials in which this transfer strategy outperforms or performs equally well as random model selection across 10 000 trials in Table 6. If we choose the same metric and the same data set (but a different random seed), we obtain a score of 80.7%. If we aim to transfer for the same metric across data sets, we achieve around 59.3%. Finally, if we transfer both across metrics and data sets, our performance drops to 54.9%.\nImplications. Unsupervised model selection remains an unsolved problem. Transfer of good hyperparameters between metrics and data sets does not seem to work as there appears to be no unsupervised way to distinguish between good and bad random seeds on the target task.\nI.6. Are these disentangled representations useful for downstream tasks in terms of the sample complexity of learning?\nOne of the key motivations behind disentangled representations is that they are assumed to be useful for later downstream tasks. In particular, it is argued that disentanglement should lead to a better sample complexity of learning (Bengio et al., 2013;Sch\u00f6lkopf et al., 2012;Peters et al., 2017). In this section, we consider the simplest downstream classification task Figure 15. Score vs hyperparameters for each score (column) and data set (row). There seems to be no model dominating all the others and for each model there does not seem to be a consistent strategy in choosing the regularization strength.  -9 -18 -15 -10 -35 -7 -21 -25 -25 -25 -17 -20 -53 -46 -47 -48 -9 -55 -14 -24 -20 -14 -34 -13 Dataset = Scream-dSprites   Figure 19. Rank-correlation between the metrics and the performance on downstream task on different data sets. We observe some correlation between most disentanglement metrics and downstream performance. However, the correlation varies across data sets.\nwhere the goal is to recover the true factors of variations from the learned representation using either multi-class logistic regression (LR) or gradient boosted trees (GBT). Our goal is to investigate the relationship between disentanglement and the average classification accuracy on these downstream tasks as well as whether better disentanglement leads to a decreased sample complexity of learning.\nTo compute the classification accuracy for each trained model, we sample true factors of variations and observations from our ground truth generative models. We then feed the observations into our trained model and take the mean of the Gaussian encoder as the representations. Finally, we predict each of the ground-truth factors based on the representations with a separate learning algorithm. We consider both a 5-fold cross-validated multi-class logistic regression as well as gradient boosted trees of the Scikit-learn package. For each of these methods, we train on 10, 100, 1000 and 10 000 samples. We compute the average accuracy across all factors of variation using an additional set 10 000 randomly drawn samples.\nFigure 19 shows the rank correlations between the disentanglement metrics and the downstream performance for all considered data sets. We observe that all metrics except Modularity seem to be correlated with increased downstream performance on the different variations of dSprites and to some degree on Shapes3D. However, it is not clear whether this is due to the fact that disentangled representations perform better or whether some of these scores actually also (partially) capture the informativeness of the evaluated representation. Furthermore, the correlation is weaker or inexistent on other data sets (e.g., Cars3D). Finally, we report in Figure 24 the rank correlation between unsupervised scores computed after training on the mean and sampled representation and downstream performance. Depending on the data set, the rank correlation ranges from from mildly negative, to mildly positive. In particular, we do not observe enough evidence supporting the claim that decreased total correlation of the aggregate posterior proves beneficial for downstream task performance.\nTo assess the sample complexity argument we compute for each trained model a statistical efficiency score which we define as the average accuracy based on 100 samples divided by the average accuracy based on 10 000 samples for either the logistic regression or the gradient boosted trees. The key idea is that if disentangled representations lead to sample efficiency, then they should also exhibit a higher statistical efficiency score. We remark that this score differs from the definition of sample complexity commonly used in statistical learning theory. The corresponding results are shown in Figures 20 and 21 where we plot the statistical efficiency versus different disentanglement metrics for different data sets and models and in Figure 19 where we show rank correlations. Overall, we do not observe conclusive evidence that models with higher disentanglement scores also lead to higher statistical efficiency. We note that some AnnealedVAE models seem to exhibit a high statistical efficiency on Scream-dSprites and to some degree on Noisy-dSprites. This can be explained by the fact that these models Figure 20. Statistical efficiency (accuracy with 100 samples \u00f7 accuracy with 10 000 samples) based on a logistic regression versus disentanglement metrics for different models and data sets. We do not observe that higher disentanglement scores lead to higher statistical efficiency. Figure 21. Statistical efficiency (accuracy with 100 samples \u00f7 accuracy with 10 000 samples) based on gradient boosted trees versus disentanglement metrics for different models and data sets. We do not observe that higher disentanglement scores lead to higher statistical efficiency (except for DCI Disentanglement and Mutual Information Gap on Shapes3D and to some extend in Cars3D).\nChallenging Common Assumptions in the Unsupervised Learning of Disentangled Representations have low downstream performance and that hence the accuracy with 100 samples is similar to the accuracy with 10 000 samples. We further observe that DCI Disentanglement and MIG seem to be lead to a better statistical efficiency on the the data set Shapes3D for gradient boosted trees. Figures 22 and 23 show the downstream performance for three groups with increasing levels of disentanglement (measured in DCI Disentanglement and MIG respectively). We observe that indeed models with higher disentanglement scores seem to exhibit better performance for gradient boosted trees with 100 samples. However, considering all data sets, it appears that overall increased disentanglement is rather correlated with better downstream performance (on some data sets) and not statistical efficiency. We do not observe that higher disentanglement scores reliably lead to a higher sample efficiency.\nImplications. While the empirical results in this section are negative, they should also be interpreted with care. After all, we have seen in previous sections that the models considered in this study fail to reliably produce disentangled representations. Hence, the results in this section might change if one were to consider a different set of models, for example semi-supervised or fully supervised one. Furthermore, there are many more potential notions of usefulness such as interpretability and fairness that we have not considered in our experimental evaluation. Nevertheless, we argue that the lack of concrete examples of useful disentangled representations necessitates that future work on disentanglement methods should make this point more explicit. While prior work (Steenbrugge et al., 2018;Laversanne-Finot et al., 2018;Nair et al., 2018;Higgins et al., 2017b;2018) successfully applied disentanglement methods such as \u03b2-VAE on a variety of downstream tasks, it is not clear to us that these approaches and trained models performed well because of disentanglement. ", "publication_ref": ["b2"], "figure_ref": ["fig_0", "fig_0", "fig_0", "fig_0", "fig_0", "fig_0", "fig_0", "fig_0", "fig_0", "fig_3", "fig_0", "fig_0", "fig_1"], "table_ref": []}, {"heading": "Acknowledgements", "text": "The authors thank Ilya Tolstikhin, Paul Rubenstein and Josip Djolonga for helpful discussions and comments. This research was partially supported by the Max Planck ETH Center for Learning Systems and by an ETH core grant (to Gunnar R\u00e4tsch). This work was partially done while Francesco Locatello was at Google Research Zurich.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "", "text": "- 22 -36 27 -30 -38 -23 -19 -26 2 -33 -18 -42 -16 -29 -8 -44 -16 -43 -11 -28 -9 -43 -15 -45 -18 -36 20 -31 -30 -27 -22 -40 4 -27 -14 -41 -26 -43 9 -24 -15 -40 -26 -45 ", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "On the bootstrap of u and v statistics. The Annals of Statistics", "journal": "Journal of machine learning research", "year": "1992-07", "authors": "M A Arcones; E Gine; F R Bach; M I Jordan"}, {"ref_id": "b1", "title": "Scaling learning algorithms towards ai. Large-scale kernel machines", "journal": "", "year": "2007", "authors": "Y Bengio; Y Lecun"}, {"ref_id": "b2", "title": "Representation learning: A review and new perspectives. IEEE transactions on pattern analysis and machine intelligence", "journal": "", "year": "2013", "authors": "Y Bengio; A Courville; P Vincent"}, {"ref_id": "b3", "title": "Multi-level variational autoencoder: Learning disentangled representations from grouped observations", "journal": "", "year": "", "authors": "D Bouchacourt; R Tomioka; S Nowozin"}, {"ref_id": "b4", "title": "FactorVAE trained on Color-dSprites. (d) FactorVAE trained on Scream-dSprites", "journal": "", "year": "", "authors": ""}, {"ref_id": "b5", "title": "AnneaeledVAE trained on Shapes3D. (f) \u03b2-TCVAE trained on SmallNORB", "journal": "", "year": "", "authors": ""}, {"ref_id": "b6", "title": "Reconstructions for a DIP-VAE-II trained on Cars3D", "journal": "", "year": "", "authors": ""}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 .1Figure1. Total correlation based on a fitted Gaussian of the sampled (left) and the mean representation (right) plotted against regularization strength for Color-dSprites and approaches (except AnnealedVAE). The total correlation of the sampled representation decreases while the total correlation of the mean representation increases as the regularization strength is increased.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 3 .3Figure 3. (left) FactorVAE score for each method on Cars3D. Models are abbreviated (0=\u03b2-VAE, 1=FactorVAE, 2=\u03b2-TCVAE, 3=DIP-VAE-I, 4=DIP-VAE-II, 5=AnnealedVAE). The variance is due to different hyperparameters and random seeds. The scores are heavily overlapping. (right) Distribution of FactorVAE scores for FactorVAE model for different regularization strengths on Cars3D.In this case, the variance is only due to the different random seeds. We observe that randomness (in the form of different random seeds) has a substantial impact on the attained result and that a good run with a bad hyperparameter can beat a bad run with a good hyperparameter.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 4 .4Figure4. (left) FactorVAE score vs hyperparameters for each score on Cars3d. There seems to be no model dominating all the others and for each model there does not seem to be a consistent strategy in choosing the regularization strength. (center) Unsupervised scores vs disentanglement metrics on Shapes3D. Metrics are abbreviated ((A)=BetaVAE Score, (B)=FactorVAE Score, (C)=MIG , (D)=DCI Disentanglement, (E)=Modularity, (F)=SAP). The unsupervised scores we consider do not seem to be useful for model selection. (right) Rank-correlation of DCI disentanglement metric across different data sets. Good hyperparameters only seem to transfer between dSprites and Color-dSprites but not in between the other data sets.", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 5 .5Figure 5. Rank correlations between disentanglement metrics and downstream performance (accuracy and efficiency) on dSprites.", "figure_data": ""}, {"figure_label": "6", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Figure 6 .6Figure 6. Statistical efficiency of the FactorVAE Score for learning a GBT downstream task on dSprites.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Burgess, C. P., Higgins, I., Pal, A., Matthey, L., Watters, N., Desjardins, G., and Lerchner, A. Understanding disentangling in beta-vae. In Workshop on Learning Disentangled Representations at the 31st Conference on Neural Information Processing Systems, 2017.Chen, T. Q., Li, X., Grosse, R. B., and Duvenaud, D. K.Isolating sources of disentanglement in variational autoencoders. In Advances in Neural Information Processing Systems, pp. 2615-2625, 2018. Chen, X., Duan, Y., Houthooft, R., Schulman, J., Sutskever, I., and Abbeel, P. Infogan: Interpretable representation learning by information maximizing generative adversarial nets. In Advances in Neural Information Processing Systems, pp. 2172-2180, 2016. Cheung, B., Livezey, J. A., Bansal, A. K., and Olshausen, B. A. Discovering hidden factors of variation in deep networks. In Workshop at International Conference on Learning Representations, 2015. Cohen, T. and Welling, M. Learning the irreducible representations of commutative lie groups. In International Conference on Machine Learning, pp. 1755-1763, 2014. Cohen, T. S. and Welling, M. Transformation properties of learned visual representations. In International Conference on Learning Representations, 2015. Comon, P. Independent component analysis, a new concept? Signal processing, 36(3):287-314, 1994. Denton, E. L. and Birodkar, v. Unsupervised learning of disentangled representations from video. In Advances in Neural Information Processing Systems, pp. 4414-4423, 2017. Desjardins, G., Courville, A., and Bengio, Y. Disentangling factors of variation via generative entangling. arXiv preprint arXiv:1210.5474, 2012. Eastwood, C. and Williams, C. K. I. A framework for the quantitative evaluation of disentangled representations. In International Conference on Learning Representations, 2018. Fraccaro, M., Kamronn, S., Paquet, U., and Winther, O. A disentangled recognition and nonlinear dynamics model for unsupervised learning. In Advances in Neural Information Processing Systems, pp. 3601-3610, 2017.Goodfellow, I., Lee, H., Le, Q. V., Saxe, A., and Ng, A. Y. Measuring invariances in deep networks. In Advances in neural information processing systems, pp. 646-654, 2009. Goroshin, R., Mathieu, M. F., and LeCun, Y. Learning to linearize under uncertainty. In Advances in Neural Information Processing Systems, pp. 1234-1242, 2015. Higgins, I., Matthey, L., Pal, A., Burgess, C., Glorot, X., Botvinick, M., Mohamed, S., and Lerchner, A. betavae: Learning basic visual concepts with a constrained variational framework. In International Conference on Learning Representations, 2017a. Higgins, I., Pal, A., Rusu, A., Matthey, L., Burgess, C., Pritzel, A., Botvinick, M., Blundell, C., and Lerchner, A. Darla: Improving zero-shot transfer in reinforcement learning. In International Conference on Machine Learning, pp. 1480-1490, 2017b. Higgins, I., Sonnerat, N., Matthey, L., Pal, A., Burgess, C. P., Bo\u0161njak, M., Shanahan, M., Botvinick, M., Hassabis, D., and Lerchner, A. Scan: Learning hierarchical compositional visual concepts. In International Conference on Learning Representations, 2018. Hinton, G. E., Krizhevsky, A., and Wang, S. D.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "Narayanaswamy, S., Paige, T. B., Van de Meent, J.-W., Desmaison, A., Goodman, N., Kohli, P., Wood, F., and Torr, P. Learning disentangled representations with semisupervised deep generative models. In Advances in Neural Information Processing Systems, pp. 5925-5935, 2017. Nguyen, X., Wainwright, M. J., and Jordan, M. I. Estimating divergence functionals and the likelihood ratio by convex risk minimization. IEEE Transactions on Information Theory, 56(11):5847-5861, 2010. Pearl, J. Causality. Cambridge university press, 2009. Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., and Duchesnay, E. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12:2825-2830, 2011. Peters, J., Janzing, D., and Sch\u00f6lkopf, B.", "figure_data": ""}, {"figure_label": "7", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "Figure 77Figure7. Reconstructions for different data sets and methods. Odd columns show real samples and even columns their reconstruction. As expected, the additional variants of dSprites with continuous noise variables are harder than the original data set. On Noisy-dSprites and Color-dSprites the models produce reasonable reconstructions with the noise on Noisy-dSprites being ignored. Scream-dSprites is even harder and we observe that the shape information is lost. On the other data sets, we observe that reconstructions are blurry but objects are distinguishable.", "figure_data": ""}, {"figure_label": "89", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "Figure 8 .Figure 9 .89Figure8. Total correlation of sampled representation plotted against regularization strength for different data sets and approaches (except AnnealedVAE). The total correlation of the sampled representation decreases as the regularization strength is increased.", "figure_data": ""}, {"figure_label": "11", "figure_type": "figure", "figure_id": "fig_11", "figure_caption": "Figure 11 .11Figure 11. Pairwise scatter plots of different disentanglement metrics on dSprites. All the metrics except Modularity appear to be correlated. The strongest correlation seems to be between MIG and DCI Disentanglement.", "figure_data": ""}, {"figure_label": "13", "figure_type": "figure", "figure_id": "fig_12", "figure_caption": "Figure 13 .13Figure13. Score for each method for each score (column) and data set (row). Models are abbreviated (0=\u03b2-VAE, 1=FactorVAE, 2=\u03b2-TCVAE, 3=DIP-VAE-I, 4=DIP-VAE-II, 5=AnnealedVAE). The scores are heavily overlapping and we do not observe a consistent pattern. We conclude that hyperparameters matter more than the model choice.", "figure_data": ""}, {"figure_label": "14", "figure_type": "figure", "figure_id": "fig_13", "figure_caption": "Figure 14 .14Figure14. Distribution of scores for different models, hyperparameters and regularization strengths on Cars3D. We clearly see that randomness (in the form of different random seeds) has a substantial impact on the attained result and that a good run with a bad hyperparameter can beat a bad run with a good hyperparameter in many cases.", "figure_data": ""}, {"figure_label": "22", "figure_type": "figure", "figure_id": "fig_18", "figure_caption": "Figure 22 .22Figure 22. Downstream performance for three groups with increasing DCI Disentanglement scores.", "figure_data": ""}, {"figure_label": "2325262728", "figure_type": "figure", "figure_id": "fig_19", "figure_caption": "Figure 23 .Figure 25 .Figure 26 .Figure 27 .Figure 28 .2325262728Figure 23. Downstream performance for three groups with increasing MIG scores.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "Hsu, W.-N., Zhang, Y., and Glass, J.Unsupervised learning of disentangled and interpretable representations from sequential data. In Advances in Neural Information Processing Systems, pp. 1878-1889, 2017. Hyvarinen, A. and Morioka, H. Unsupervised feature extraction by time-contrastive learning and nonlinear ica. In Advances in Neural Information Processing Systems, pp. 3765-3773, 2016. Variational inference of disentangled latent concepts from unlabeled observations. In International Conference on Learning Representations, 2017. Lake, B. M., Ullman, T. D., Tenenbaum, J. B., and Gershman, S. J. Building machines that learn and think like people. Behavioral and Brain Sciences, 40, 2017. Laversanne-Finot, A., Pere, A., and Oudeyer, P.-Y. Curiosity driven exploration of learned disentangled goal spaces. In Conference on Robot Learning, pp. 487-504, 2018. LeCun, Y., Huang, F. J., and Bottou, L. Learning methods for generic object recognition with invariance to pose and lighting. In Computer Vision and Pattern Recognition, 2004. CVPR 2004. Proceedings of the 2004 IEEE Computer Society Conference on, volume 2, pp. II-104. IEEE, 2004. LeCun, Y., Bengio, Y., and Hinton, G. Deep learning. nature, 521(7553):436, 2015. Lenc, K. and Vedaldi, A. Understanding image representations by measuring their equivariance and equivalence. In IEEE conference on computer vision and pattern recognition, pp. 991-999, 2015.", "figure_data": "Locatello, F., Vincent, D., Tolstikhin, I., R\u00e4tsch, G., Gelly,S., and Sch\u00f6lkopf, B. Competitive training of mixturesHyvarinen, A. and Pajunen, P. Nonlinear independent com-of independent deep generative models. arXiv preprintponent analysis: Existence and uniqueness results. NeuralarXiv:1804.11130, 2018.Networks, 12(3):429-439, 1999.Mathieu, M. F., Zhao, J. J., Zhao, J., Ramesh, A., Sprech-Hyvarinen, A., Sasaki, H., and Turner, R. E. Nonlinearmann, P., and LeCun, Y. Disentangling factors of varia-ica using auxiliary variables and generalized contrastivetion in deep representation using adversarial training. Inlearning. arXiv preprint arXiv:1805.08651, 2018.Advances in Neural Information Processing Systems, pp.5040-5048, 2016.Munch, E. The scream, 1893.Nair, A. V., Pong, V., Dalal, M., Bahl, S., Lin, S., andLevine, S. Visual reinforcement learning with imaginedgoals. In Advances in Neural Information ProcessingSystems, pp. 9209-9220, 2018."}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "Elements of causal inference: foundations and learning algorithms. MIT press, 2017. Reed, S., Sohn, K., Zhang, Y., and Lee, H. Learning to disentangle factors of variation with manifold interaction. In International Conference on Machine Learning, pp. 1431-1439, 2014. Ridgeway, K. and Mozer, M. C. Learning deep disentangled embeddings with the f-statistic loss. In Advances in Neural Information Processing Systems, pp. 185-194, 2018. Rubenstein, P. K., Schoelkopf, B., and Tolstikhin, I. Learning disentangled representations with wasserstein autoencoders. In Workshop at International Conference on Learning Representations, 2018. Yang, J., Reed, S. E., Yang, M.-H., and Lee, H. Weaklysupervised disentangling with recurrent transformations for 3d view synthesis. In Advances in Neural Information Processing Systems, pp. 1099-1107, 2015. Yingzhen, L. and Mandt, S. Disentangled sequential autoencoder. In International Conference on Machine Learning, pp. 5656-5665, 2018. Zhu, Z., Luo, P., Wang, X., and Tang, X. Multi-view perceptron: a deep model for learning face identity and view representations. In Advances in Neural Information Processing Systems, pp. 217-225, 2014.", "figure_data": "Schmidhuber, J. Learning factorial codes by predictabilityminimization. Neural Computation, 4(6):863-879, 1992.Sch\u00f6lkopf, B., Janzing, D., Peters, J., Sgouritsa, E., Zhang,K., and Mooij, J. On causal and anticausal learning.In International Conference on Machine Learning, pp.1255-1262, 2012.Spirtes, P., Glymour, C., and Scheines, R. Causation, pre-diction, and search. Springer-Verlag. (2nd edition MITPress 2000), 1993.Steenbrugge, X., Leroux, S., Verbelen, T., and Dhoedt, B.Improving generalization for abstract reasoning tasks us-ing disentangled feature representations. In Workshopon Relational Representation Learning at Conference onNeural Information Processing Systems, 2018.Sugiyama, M., Suzuki, T., and Kanamori, T. Density-ratiomatching under the bregman divergence: a unified frame-work of density-ratio estimation. Annals of the Instituteof Statistical Mathematics, 64(5):1009-1044, 2012.Suter, R., Miladinovi\u0107, \u00d0., Bauer, S., and Sch\u00f6lkopf, B.Interventional robustness of deep latent variable models.arXiv preprint arXiv:1811.00007, 2018.Thomas, V., Bengio, E., Fedus, W., Pondard, J., Beaudoin,P., Larochelle, H., Pineau, J., Precup, D., and Bengio,Y. Disentangling the independently controllable factorsof variation by interacting with the world. In Workshopon Learning Disentangled Representations at the 31stConference on Neural Information Processing Systems,2017.Tschannen, M., Bachem, O., and Lucic, M. Recent advancesin autoencoder-based representation learning. arXivpreprint arXiv:1812.05069, 2018.Watanabe, S. Information theoretical analysis of multivari-ate correlation. IBM Journal of research and development,4(1):66-82, 1960."}, {"figure_label": "23", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "Encoder and Decoder architecture for the main experiment. Model's hyperparameters. We allow a sweep over a single hyperparameter for each model.", "figure_data": "EncoderDecoderInput: 64 \u00d7 64\u00d7 number of channels Input: R 104 \u00d7 4 conv, 32 ReLU, stride 2FC, 256 ReLU4 \u00d7 4 conv, 32 ReLU, stride 2FC, 4 \u00d7 4 \u00d7 64 ReLU4 \u00d7 4 conv, 64 ReLU, stride 24 \u00d7 4 upconv, 64 ReLU, stride 24 \u00d7 4 conv, 64 ReLU, stride 24 \u00d7 4 upconv, 32 ReLU, stride 2FC 256, F2 2 \u00d7 104 \u00d7 4 upconv, 32 ReLU, stride 24 \u00d7 4 upconv, number of channels, stride 2ModelParameterValues\u03b2-VAE\u03b2[1, 2, 4, 6, 8, 16]AnnealedVAE c max[5, 10, 25, 50, 75, 100]iteration threshold 100000\u03b31000FactorVAE\u03b3[10, 20, 30, 40, 50, 100]DIP-VAE-I\u03bb od[1, 2, 5, 10, 20, 50]\u03bb d10\u03bb odDIP-VAE-II\u03bb od[1, 2, 5, 10, 20, 50]\u03bb d\u03bb od\u03b2-TCVAE\u03b2[1, 2, 4, 6, 8, 10]"}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "Other fixed hyperparameters. (a) Hyperparameters common to each of the considered methods.", "figure_data": "(b) Architecture for the discriminator in(c) Parameters for the discriminator inFactorVAE.FactorVAE.ParameterValuesDiscriminatorParameterValuesBatch size Latent space dimension 10 64 Optimizer Adam Adam: beta1 0.9FC, 1000 leaky ReLU FC, 1000 leaky ReLU FC, 1000 leaky ReLUBatch size Optimizer Adam: beta164 Adam 0.5Adam: beta20.999FC, 1000 leaky ReLUAdam: beta20.9Adam: epsilon1e-8FC, 1000 leaky ReLUAdam: epsilon1e-8Adam: learning rate Decoder type Training steps0.0001 300000 BernoulliFC, 2 FC, 1000 leaky ReLUAdam: learning rate 0.0001"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_7", "figure_caption": "Rank correlation of different metrics on different data sets. Overall, we observe that all metrics except Modularity seem to be strongly correlated on the data sets dSprites, Color-dSprites and Scream-dSprites and mildly on the other data sets. There appear to be two pairs among these metrics that capture particularly similar notions: the BetaVAE and the FactorVAE score as well as the Mutual Information Gap and DCI Disentanglement.", "figure_data": "Dataset = dSpritesDataset = Color-dSpritesDataset = Noisy-dSpritesDataset = Scream-dSpritesBetaVAE Score100 82 81 84181BetaVAE Score100 76 80 87979BetaVAE Score100 80 44 41 46 37BetaVAE Score100 95 94 92 47 95FactorVAE Score82 100 72 77 -5 67FactorVAE Score76 100 68 76262FactorVAE Score80 100 49 52 25 38FactorVAE Score95 100 95 89 49 90MIG81 72 100 93 -5 83MIG80 68 100 91182MIG44 49 100 76642MIG94 95 100 95 50 87DCI Disentanglement84 77 93 100 -14 84DCI Disentanglement87 76 91 100 -7 82DCI Disentanglement41 52 76 100 -8 38DCI Disentanglement92 89 95 100 44 87Modularity1-5 -5 -14 100 -10Modularity921-7 100 -7Modularity46 256-8 100 13Modularity47 49 50 44 100 41SAP81 67 83 84 -10 100SAP79 62 82 82 -7 100SAP37 38 42 38 13 100SAP95 90 87 87 41 100BetaVAE ScoreFactorVAE ScoreMIGDCI DisentanglementModularitySAPBetaVAE ScoreFactorVAE ScoreMIGDCI DisentanglementModularitySAPBetaVAE ScoreFactorVAE ScoreMIGDCI DisentanglementModularitySAPBetaVAE ScoreFactorVAE ScoreMIGDCI DisentanglementModularitySAPDataset = SmallNORBDataset = Cars3DDataset = Shapes3DBetaVAE Score100 63 56 45 -60 39BetaVAE Score100 37 22 38 29 13BetaVAE Score100 76 24 54 46 57FactorVAE Score63 100 34 39 -69 2FactorVAE Score37 100 66 60 39 40FactorVAE Score76 100 44 49 23 66MIG56 34 100 79 -50 76MIG22 66 100 67 52 43MIG24 44 100 67970DCI Disentanglement45 39 79 100 -42 58DCI Disentanglement38 60 67 100 57 27DCI Disentanglement54 49 67 100 52 58Modularity-60 -69 -50 -42 100 -28Modularity29 39 52 57 100 18Modularity46 23952 100 17SAP39276 58 -28 100SAP13 40 43 27 18 100SAP57 66 70 58 17 100BetaVAE ScoreFactorVAE ScoreMIGDCI DisentanglementModularitySAPBetaVAE ScoreFactorVAE ScoreMIGDCI DisentanglementModularitySAPBetaVAE ScoreFactorVAE ScoreMIGDCI DisentanglementModularitySAPFigure 12."}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_11", "figure_caption": "Rank correlation between unsupervised scores and supervised disentanglement metrics. The unsupervised scores we consider do not seem to be useful for model selection.", "figure_data": "Dataset = SmallNORBDataset = Cars3DDataset = Shapes3DReconstruction-83 -73 -59 -54 69 -38Reconstruction-19 9 42 20 38 12Reconstruction-30 -4 59 22 -21 27TC (sampled)-12 41 -21 -2 -12 -46TC (sampled)-18 -6 -3 -14 20TC (sampled)15 -11 -8 -11 -2KL20 49 -19 -18 -22 -39KL-14 -10 -46 -45 -40 -5KL-14 -1 -38 -31 -11 -29ELBO-79 -57 -72 -65 61 -55ELBO-24 5 35 12 29 11ELBO-38 -9 48 9 -25 15BetaVAE ScoreFactorVAE ScoreMIGDCI DisentanglementModularitySAPBetaVAE ScoreFactorVAE ScoreMIGDCI DisentanglementModularitySAPBetaVAE ScoreFactorVAE ScoreMIGDCI DisentanglementModularitySAPColor-dSprites 100 83 -22 54 -11 34 21 Noisy-dSprites Scream-dSprites SmallNORB Cars3D Shapes3D 83 100 -24 69 -28 39 38 -22 -24 100 -24 -14 16 -16 54 69 -24 100 -6 63 72 -11 -28 -14 -6 100 -3 13 34 39 16 63 -3 100 65 21 38 -16 72 13 65 100 Figure 16. dSprites dSprites Color-dSprites Noisy-dSprites Scream-dSprites SmallNORB Cars3D Shapes3D Metric = BetaVAE ScoredSprites Color-dSprites Noisy-dSprites Scream-dSprites SmallNORB Cars3D Shapes3DdSprites 100 91 4 61 4 61 13 Color-dSprites Noisy-dSprites Scream-dSprites SmallNORB Cars3D Shapes3D 91 100 13 61 3 68 12 4 13 100 -20 62 34 -22 61 61 -20 100 -16 51 50 4 3 62 -16 100 30 -38 61 68 34 51 30 100 34 13 12 -22 50 -38 34 100 Metric = FactorVAE ScoredSprites Color-dSprites Noisy-dSprites Scream-dSprites SmallNORB Cars3D Shapes3DdSprites 100 94 75 59 3 80 58 Color-dSprites Noisy-dSprites Scream-dSprites SmallNORB Cars3D Shapes3D 94 100 75 54 -10 85 65 75 75 100 55 -23 74 68 59 54 55 100 28 64 18 3 -10 -23 28 100 -23 -48 80 85 74 64 -23 100 68 58 65 68 18 -48 68 100 Metric = MIGMetric = DCI DisentanglementMetric = ModularityMetric = SAPdSprites100 95 65 65 34 64 46dSprites100 86 78 -17 -6 -55 2dSprites100 86 27 63 17 51 35Color-dSprites95 100 61 60 21 63 47Color-dSprites86 100 71 -11 -4 -32 30Color-dSprites86 100 39 65 10 43 43Noisy-dSprites65 61 100 68 17 64 59Noisy-dSprites78 71 100 3 5 -57 10Noisy-dSprites27 39 100 -3 -34 21 2Scream-dSprites65 60 68 100 36 93 69Scream-dSprites-17 -11 3 100 -45 -6 25Scream-dSprites63 65 -3 100 38 24 68SmallNORB34 21 17 36 100 21 -9SmallNORB-6 -4 5 -45 100 21 -25SmallNORB17 10 -34 38 100 -16 -2Cars3D64 63 64 93 21 100 85Cars3D-55 -32 -57 -6 21 100 31Cars3D51 43 21 24 -16 100 -4Shapes3D46 47 59 69 -9 85 100Shapes3D2 30 10 25 -25 31 100Shapes3D35 43 2 68 -2 -4 100dSpritesColor-dSpritesNoisy-dSpritesScream-dSpritesSmallNORBCars3DShapes3DdSpritesColor-dSpritesNoisy-dSpritesScream-dSpritesSmallNORBCars3DShapes3DdSpritesColor-dSpritesNoisy-dSpritesScream-dSpritesSmallNORBCars3DShapes3D"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_12", "figure_caption": "Disentanglement scores on dSprites vs other data sets. Good hyperparameters only seem to transfer consistently from dSprites to Color-dSprites.", "figure_data": "LR10181318 Dataset = dSprites 19-312LR101-11 Dataset = Color-dSprites -1 -5 15-7LR102819 Dataset = Noisy-dSprites 18 12 279LR106165 Dataset = Scream-dSprites 60 55 4860LR10065496365-964LR10063436365255LR1005333-0-11 5515LR100837977754681LR1000281320181520LR1000321215181916LR100060402-55818LR1000867980804184LR100002812-141812LR10000241-15238LR100005740-8-16 5817LR10000898382824387GBT1067587175-671GBT1068577175-471GBT10191426251914GBT10676868654164GBT10078738694 -17 77GBT10081688793-577GBT10026376485 -19 28GBT100857885933780GBT1000 GBT10000 Efficiency (LR)75 76 5071 71 4386 87 6294 -19 74 94 -13 75 62 -19 56GBT1000 GBT10000 Efficiency (LR)76 72 3866 61 3684 82 59Metric = MIG 89 -5 84 5 54 -15 43 69 66Metric = DCI Disentanglement GBT1000 -1 20 52 GBT10000 -6 15 43 0.45 Efficiency (LR) -14 -12 130.92 75 -36 15 Metric = Modularity GBT1000 65 -35 8 GBT10000 16 -18 -4 Efficiency (LR)83 81 -69 -63 -65 -67 -39 -67 78 85 94 35 79 Metric = SAP 75 82 92 33 78 0.075Efficiency (GBT) 0.6 0.6 0.7 0.8 0.9 Metric value 0.6 0.56 0.64 0.72 0.80 Metric value 0.6 0.25 0.50 0.75 Metric value 0.6 0.60 0.75 Metric value 0.6 0.002 0.004 0.006 Metric value +9.96e 1 0.7 50 0.7 0.7 0.7 0.7 0.6 0.7 dSprites 46 0.8 0.8 0.8 0.8 0.8 0.8 0.75 0.90 Metric value FactorVAE Score BetaVAE Score FactorVAE Score LR100 LR1000 LR10000 GBT10 GBT100 GBT1000 GBT10000 Efficiency (LR) Efficiency (GBT) 1 -2 24 23 -18 -29 47 54 -14 49 0.9 0.45 0.45 0.60 0.75 0.9 0.45 0.40 0.48 0.56 0.9 0.45 0.2 0.4 0.6 0.8 0.9 0.45 0.30 0.45 0.60 0.9 0.45 0.72 0.80 0.88 0.9 0.45 0.4 0.6 0.8 1.0 MIG DCI Disentanglement Modularity SAP MIG DCI Disentanglement Modularity SAP -41 -53 22 -45 0 -30 60 53 14 3 -33 -9 -46 -46 -26 -26 53 -21 63 39 83 86 -43 62 69 56 80 87 -56 53 74 63 77 82 -61 49 -49 -58 -59 -64 58 -38 -55 -77 -29 -34 64 0 Figure 18. BetaVAE Score LR10 -19 -21 -12 -4 29 -12 Dataset = SmallNORBEfficiency (GBT) 0.60 0.75 0.60 0.75 0.60 0.75 0.60 0.75 0.60 0.75 0.60 0.75 dSprites LR100 LR1000 LR10000 GBT10 GBT100 GBT1000 GBT10000 Efficiency (LR) Efficiency (GBT) LR1036 BetaVAE Score BetaVAE Score 4 12 19 15 13 37 0 -17 8 2734 0.0 0.00 0.15 0.30 0.0 0.000 0.025 0.050 0.075 0.0 0.0 0.1 0.2 0.0 0.0 0.1 0.2 0.3 0.0 0.04 0.08 0.12 0.16 0.0 0.0 0.2 0.4 0.6 FactorVAE Score FactorVAE Score -10 -39 -25 -44 -12 32 41 -21 41 0.1 0.2 0.3 0.4 0.1 0.2 0.3 0.4 0.1 0.2 0.3 0.4 0.1 0.2 0.3 0.4 0.1 0.2 0.3 0.4 0.1 0.2 0.3 0.4 dSprites MIG DCI Disentanglement Modularity SAP MIG DCI Disentanglement Modularity SAP -9 -44 -20 -49 -15 -3 -40 -12 -43 -13 10 -6 4 -8 -8 27 44 52 17 8 57 64 80 45 21 -13 -23 -32 -22 -1 -7 -2 -18 -2 4 26 40 53 23 6 7 -27 -3 -23 -3 Dataset = Cars3D0.00 0.00 0.15 0.30 Efficiency (GBT) 0.00 0.00 0.15 0.30 0.45 0.00 0.04 0.08 0.12 0.16 0.00 0.0 0.1 0.2 0.3 0.00 0.1 0.2 0.3 0.4 0.00 0.1 0.2 0.3 0.4 0.5 0.00 0.25 0.50 0.75 LR100 LR1000 LR10000 GBT10 GBT100 GBT1000 GBT10000 Efficiency (LR) Efficiency (GBT) LR100.15 33 0.15 0.15 0.15 0.15 0.15 0.15 dSprites 0.30 26 0.30 0.30 0.30 0.30 0.30 0.30 BetaVAE Score FactorVAE Score BetaVAE Score FactorVAE Score 73 56 44 11 -47 0.45 32 0.45 0.45 0.45 0.45 0.45 0.45 MIG MIG -1 42 7 -52 60 56 51 43 36 71 53 42 56 59 46 48 14 40 66 23 21 77 55 38 -14 11 36 DCI Disentanglement DCI Disentanglement 30 -1 -6 71 96 97 94 35 -11 49 0.80 0.80 0.84 0.88 6 25 0.80 0.80 0.84 0.88 0.92 0.80 0.72 0.80 0.88 0.80 0.60 0.65 0.70 0.75 0.80 0.80 0.80 0.88 0.96 0.80 0.84 0.88 0.92 0.96 0.80 0.80 0.85 0.90 0.95 1.00 Modularity SAP Modularity SAP 30 32 38 -14 33 -16 42 55 50 50 55 49 55 49 80 38 45 19 14 Dataset = Shapes3D0.84 Efficiency (GBT) 0.88 0.84 0.88 0.84 0.88 0.84 0.88 0.84 0.88 0.84 0.88 0.84 0.88 dSprites0.92 -71 -65 -72 -82 -28 -69 0.000 0.025 0.050 0.075 0.000 0.025 0.050 0.92 0.000 0.025 0.050 0.075 0.000 0.025 0.050 0.075 0.92 0.000 0.025 0.050 0.075 0.000 0.008 0.016 0.024 0.92 0.000 0.025 0.050 0.075 0.000 0.025 0.050 0.92 0.000 0.025 0.050 0.075 0.00 0.04 0.08 0.12 0.16 0.92 0.000 0.025 0.050 0.075 0.000 0.008 0.016 0.024 0.92 0.000 0.025 0.050 0.075 dSprites 0.04 0.08 0.12 BetaVAE Score FactorVAE Score MIG DCI Disentanglement Modularity SAPDataset = dSprites Dataset = Color-dSprites Dataset = Noisy-dSprites Dataset = Scream-dSprites Dataset = SmallNORB Dataset = Cars3D Dataset = Shapes3D"}], "formulas": [{"formula_id": "formula_0", "formula_text": "(A) (B) (C) (D) (E) (F) BetaVAE Score (A) FactorVAE Score (B) MIG (C) DCI Disentanglement (D) Modularity (E) SAP (F)", "formula_coordinates": [5.0, 81.26, 286.99, 175.73, 79.03]}, {"formula_id": "formula_1", "formula_text": "g i (v) = P (z i \u2264 v i ) \u2200i = 1, 2, . . . , d.", "formula_coordinates": [12.0, 220.19, 125.35, 156.51, 9.65]}, {"formula_id": "formula_2", "formula_text": "(0, 1] d \u2192 R d defined by h i (v) = \u03c8 \u22121 (v i ) \u2200i = 1, 2, . . . , d,", "formula_coordinates": [12.0, 225.32, 176.48, 215.09, 35.03]}, {"formula_id": "formula_3", "formula_text": "A T A = I d \u2212 2vv T T I d \u2212 2vv T = I d \u2212 4vv T + 4v(v T v)v T = I d .", "formula_coordinates": [12.0, 148.8, 353.8, 299.27, 14.03]}, {"formula_id": "formula_4", "formula_text": "f (u) = g \u22121 (h \u22121 (Ah(g(u))))", "formula_coordinates": [12.0, 236.79, 443.59, 123.3, 10.81]}, {"formula_id": "formula_5", "formula_text": "\u2202f i (u) \u2202u j = A ij \u2022 \u2202hj (g(u)) \u2202vj \u2022 \u2202gj (u) \u2202uj \u2202hi(h \u22121 i (Ah(g(u))) \u2202vi \u2022 \u2202gi(g \u22121 (h \u22121 (Ah(g(u))))) \u2202vi = 0,", "formula_coordinates": [12.0, 179.48, 500.98, 239.12, 34.71]}, {"formula_id": "formula_6", "formula_text": "max \u03c6,\u03b8 E p(x) [E q \u03c6 (z|x) [log p \u03b8 (x|z)] \u2212 D KL (q \u03c6 (z|x) p(z))](1)", "formula_coordinates": [12.0, 180.47, 667.85, 360.97, 14.66]}, {"formula_id": "formula_7", "formula_text": "E p(x) [E q \u03c6 (z|x) [log p \u03b8 (x|z)] \u2212 \u03b2D KL (q \u03c6 (z|x) p(z))]", "formula_coordinates": [13.0, 192.47, 104.09, 211.94, 10.63]}, {"formula_id": "formula_8", "formula_text": "E p(x) [E q \u03c6 (z|x) [log p \u03b8 (x|z)] \u2212 \u03b3|D KL (q \u03c6 (z|x) p(z)) \u2212 C|]", "formula_coordinates": [13.0, 179.92, 195.75, 237.04, 10.63]}, {"formula_id": "formula_9", "formula_text": "E p(x) [D KL (q \u03c6 (z|x) p(z))] = I(x; z) + D KL (q(z) p(z)).", "formula_coordinates": [13.0, 181.34, 288.12, 234.21, 9.99]}, {"formula_id": "formula_10", "formula_text": "E p(x) [E q \u03c6 (z|x) [log p \u03b8 (x|z)] \u2212 D KL (q \u03c6 (z|x) p(z))] \u2212 \u03b3D KL (q(z) d j=1 q(z j )).", "formula_coordinates": [13.0, 141.01, 390.84, 314.86, 30.32]}, {"formula_id": "formula_11", "formula_text": "E p(x) [E q \u03c6 (z|x) [log p \u03b8 (x|z)] \u2212 D KL (q \u03c6 (z|x) p(z))] \u2212 \u03bbD(q(z) p(z)),", "formula_coordinates": [13.0, 156.8, 552.43, 283.29, 10.63]}, {"formula_id": "formula_12", "formula_text": "E p(x) [E q \u03c6 (z|x) [log p \u03b8 (x|z)] \u2212 D KL (q \u03c6 (z|x) p(z))] \u2212 \u03bb od i =j Cov p(x) [\u00b5 \u03c6 (x)] 2 ij \u2212 \u03bb d i Cov p(x) [\u00b5 \u03c6 (x)] ii \u2212 1 2 or the DIP-VAE-II objective E p(x) [E q \u03c6 (z|x) [log p \u03b8 (x|z)] \u2212 D KL (q \u03c6 (z|x) p(z))] \u2212 \u03bb od i =j Cov q \u03c6 [z] 2 ij \u2212 \u03bb d i Cov q \u03c6 [z] ii \u2212 1 2 .", "formula_coordinates": [13.0, 55.44, 617.91, 481.47, 79.77]}, {"formula_id": "formula_13", "formula_text": "1 K K k=1 1 H z k I(v j k , z k ) \u2212 max j =j k I(v j , z k )", "formula_coordinates": [14.0, 213.47, 440.24, 163.81, 30.55]}, {"formula_id": "formula_14", "formula_text": "t i,f = \u03b8 i if f = arg max g m i,g0", "formula_coordinates": [14.0, 227.8, 627.8, 139.34, 23.08]}, {"formula_id": "formula_15", "formula_text": "otherwise", "formula_coordinates": [14.0, 281.01, 642.46, 38.73, 8.64]}, {"formula_id": "formula_16", "formula_text": "where \u03b8 i = max g m ig .", "formula_coordinates": [14.0, 55.08, 660.21, 91.63, 9.65]}, {"formula_id": "formula_17", "formula_text": "\u03b4 i = f (m if \u2212 t if ) 2 \u03b8 2 i (N \u2212 1)", "formula_coordinates": [14.0, 252.54, 675.84, 90.11, 27.57]}, {"formula_id": "formula_18", "formula_text": "i \u03c1 i (1 \u2212 H(R i )).", "formula_coordinates": [15.0, 65.96, 237.59, 68.56, 11.15]}, {"formula_id": "formula_19", "formula_text": "D KL \uf8eb \uf8ed N (\u00b5 r(x) , \u03a3 r(x) ) j N (\u00b5 r(x)j , \u03a3 r(x)jj ) \uf8f6 \uf8f8", "formula_coordinates": [15.0, 197.07, 476.33, 202.75, 33.53]}], "doi": ""}