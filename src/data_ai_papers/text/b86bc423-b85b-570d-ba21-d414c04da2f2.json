{"title": "Rewiring What-to-Watch-Next Recommendations to Reduce Radicalization Pathways", "authors": "Francesco Fabbri; Yanhao Wang; Carlos Castillo; Francesco Bonchi; Michael 2022 Mathioudakis;  Rewiring", "pub_date": "2022-02-01", "abstract": "Recommender systems typically suggest to users content similar to what they consumed in the past. If a user happens to be exposed to strongly polarized content, she might subsequently receive recommendations which may steer her towards more and more radicalized content, eventually being trapped in what we call a \"radicalization pathway\". In this paper, we study the problem of mitigating radicalization pathways using a graph-based approach. Specifically, we model the set of recommendations of a \"what-to-watch-next\" recommender as a -regular directed graph where nodes correspond to content items, links to recommendations, and paths to possible user sessions. We measure the \"segregation\" score of a node representing radicalized content as the expected length of a random walk from that node to any node representing non-radicalized content. High segregation scores are associated to larger chances to get users trapped in radicalization pathways. Hence, we define the problem of reducing the prevalence of radicalization pathways by selecting a small number of edges to \"rewire\", so to minimize the maximum of segregation scores among all radicalized nodes, while maintaining the relevance of the recommendations. We prove that the problem of finding the optimal set of recommendations to rewire is NP-hard and NP-hard to approximate within any factor. Therefore, we turn our attention to heuristics, and propose an efficient yet effective greedy algorithm based on the absorbing random walk theory. Our experiments on real-world datasets in the context of video and news recommendations confirm the effectiveness of our proposal.\u2022 Information systems \u2192 Web applications; \u2022 Theory of computation \u2192 Random walks and Markov chains.", "sections": [{"heading": "INTRODUCTION", "text": "\"What-to-watch-next\" (W2W) recommenders are key features of video sharing platforms [55], as they sustain user engagement, thus increasing content views and driving advertisement and monetization. However, recent studies have raised serious concerns about the potential role played by W2W recommenders, specifically in driving users towards undesired or polarizing content [29]. Specifically, radicalized communities 1 on social networks and content sharing platforms have been recognized as keys in the consumption of news and in building opinions around politics and related subjects [30,48,53]. Recent work highlights the role of recommender systems, which may steer users towards radicalized content, eventually building \"radicalization pathways\" [30,47] (i.e., a user might be further driven towards radicalized content even when this was not her initial intent). In this paper, we study the problem of reducing the prevalence of radicalization pathways in W2W recommenders while maintaining the relevance of recommendations.\nFormally, we model a W2W recommender system as a directed labeled graph where nodes correspond to videos (or other types of content) and directed edges represent recommendation links from one node to another 2 . In this scenario, each video is accompanied by the same number of recommendation links, and thus every node in the graph has the same out-degree . Moreover, each node has a binary label such as \"harmful\" (e.g., radicalized) or \"neutral\" (e.g., non-radicalized). The browsing activity of a user through the W2W recommendations is modeled as a random walk on the graph: after visiting a node (e.g., watching a video), the user moves to one of the recommended videos with a probability that depends on its visibility or ranking in the recommendation list. In this setting, for each harmful node , we measure the expected number of consecutive harmful nodes visited in a random walk before reaching any neutral node. We call this measure the \"segregation\" score of node : intuitively, it quantifies how easy it is to get \"stuck\" in radicalization pathways starting from a given node. Our goal is to reduce the segregation of the graph while guaranteeing that the quality of recommendations is maintained, where the quality is measured by the normalized discount cumulative gain [4,24] (nDCG) of each node. An important challenge is that the underlying recommendation graph has intrinsically some level of homophily because, given that the W2W seeks to recommend relevant videos, it is likely to link harmful nodes to other harmful nodes.\nWe formulate the problem of reducing the segregation of the graph as selecting rewiring operations on edges (corresponding to modifications in the lists of recommended videos for some nodes) so as to minimize the maximum of segregation scores among all harmful nodes, while maintaining recommendation quality measured by nDCG above a given threshold for all nodes. We prove that our -Rewiring problem is NP-hard and NP-hard to approximate within any factor. We therefore turn our attention to design efficient and effective heuristics. Our proposed algorithm is based on the absorbing random walk theory [34], thanks to which we can efficiently compute the segregation score of each node and update it after every rewiring operation. Specifically, our method finds a set of rewiring operations by greedily choosing the optimal rewiring for the special case of = 1 -i.e., the 1-Rewiring problem, then updates the segregation score of each node. We further design a sorting and pruning strategy to avoid unnecessary attempts and thus improve the efficiency for searching the optimal rewiring. Though the worst-case time complexity of our algorithm is quadratic with respect to the number of nodes , it exhibits much better performance (nearly linear w.r.t. ) in practice.\nFinally, we present experiments on two real-world datasets: one in the context of video sharing and the other in the context of news feeds. We compare our proposed algorithm against several baselines, including an algorithm for suggesting new edges to reduce radicalization in Web graphs. The results show that our algorithm outperforms existing solutions in mitigating radicalization pathways in recommendation graphs.\nIn the rest of this paper, we first review the literature relevant to our work in Section 2. Then, we introduce the background and formally define our problem in Section 3. Our proposed algorithms are presented in Section 4. The experimental setup and results are shown in Section 5. Finally, we conclude this paper and discuss possible future directions in Section 6.", "publication_ref": ["b54", "b28", "b0", "b29", "b47", "b52", "b29", "b46", "b1", "b3", "b23", "b33"], "figure_ref": [], "table_ref": []}, {"heading": "RELATED WORK", "text": "A great deal of research has been recently published about the potential created by unprecedented opportunities to access information on the Web and social media. These risks include the spread of misinformation [1,50], the presence of bots [16], the abundance of offensive hate speech [33,37], the availability of inappropriate videos targeting children [40], the increase in controversy [18] and polarization [20], and the creation of radicalization pathways [47]. Consequently, a substantial research effort has been devoted to model, detect, quantify, reduce, and/or block such negative phenomena. Due to space limitations, we only discuss the existing studies that are the most relevant to our work here -in particular, algorithmic approaches to optimizing graph structures for achieving the aforementioned goals [7, 8, 19, 21, 23, 25-28, 38, 49, 51, 54].\nA line of research deals with limiting the spread of undesirable content in a social network via edge manipulation [25-28, 49, 51, 54]. In these studies, the graph being manipulated is a network of users where the edges represent connections such as friendship or interactions among users. In contrast, we consider a graph of content items (e.g., videos or news), where the edges represent recommendation links. Moreover, these algorithmic methods are primarily based on information propagation models, while our work is based on random walks.\nAnother line of work aims at reducing controversy, disagreement, and polarization by edge manipulation in a social network, exposing users to others with different views [7,8,19,21,23,38]. Garimella et al. [19] introduce the controversy score of a graph based on random walks and propose an efficient algorithm to minimize it by edge addition. Musco et al. [38] introduce the Polarization-Disagreement index of a graph based on Friedkin-Johnsen dynamics and propose a network-design approach to find a set of \"best\" edges that minimize this index. Chen et al. [7] define the worst-case conflict risk and average-case conflict risk of a graph, also based on Friedkin-Johnsen dynamics, and propose algorithms to locally edit the graphs for reducing both measures. Chitra and Musco [8] analyze the impact of \"filter bubbles\" in social network polarization and how to mitigate them by graph modification. Interian et al. [23] define a polarization reduction problem by adding edges between users from different groups and propose integer programming-based methods to solve it. Another related line of work proposes to model and mitigate the disparate exposure generated by people recommenders (e.g. whoto-follow link predictions) in presence of effects like homophily and polarization [9,14,15,45]. These studies also deal with networks of users, while in our case we consider a network of items.\nThe work probably most related to ours is the one by Haddadan et al. [21], which considers a graph of items (e.g., Web pages with hyperlinks) and defines the structural bias of a node as the difficulty/effort needed to reach nodes of a different opinion. They, then propose an efficient approximation algorithm to reduce the structural bias by edge insertions. There are three main differences between this and our work. First, two-directional edge manipulations (from class A to B and also from B to A) are considered by Haddadan et al. [21], but one-directional edge manipulations (from harmful to neutral nodes only) are considered in our work. Second, they consider inserting new links on a node, which better fits the case of Web pages, but we consider rewiring existing edges, which better fits the case of W2W recommenders. Third, they define the structural bias of the graph as the sum of the bubble radii of all nodes, while we define the segregation of the graph as the worstcase segregation score among all harmful nodes. We compare our proposed algorithm with theirs in our experiments.\nA recent line of work introduces the notion of reachability in recommender systems [11,13]. Instead of rewiring the links, they focus on making allowable modifications in the user's rating history to avoid unintended consequences such as filter bubbles and radicalization. However, as the problem formulation is different from ours, their proposed methods are not applicable to our problem.\nFinally, there are many studies on modifying various graph characteristics, such as shortest paths [42,43], centrality [3,10,12,36,44,52], opinion dynamics [2,5], and so on [6,31,41,56], by edge manipulation. We can draw insights from these methods but cannot directly apply them to our problem.", "publication_ref": ["b0", "b49", "b15", "b32", "b36", "b39", "b17", "b19", "b46", "b6", "b7", "b18", "b20", "b22", "b37", "b18", "b37", "b6", "b7", "b22", "b8", "b13", "b14", "b44", "b20", "b20", "b10", "b12", "b41", "b42", "b2", "b9", "b11", "b35", "b43", "b51", "b1", "b4", "b5", "b30", "b40", "b55"], "figure_ref": [], "table_ref": []}, {"heading": "PRELIMINARIES", "text": "Let us consider a set of items and a matrix S \u2208 R \u00d7 , where each entry \u2208 [0, 1] at position ( , ) denotes the relevance score of an item given that a user has browsed an item . This expresses the likelihood that a user who has just watched would be interested in watching . Typically, a recommender system selects the most relevant items to compose the recommendation list \u0393 + ( ) of , where the number of recommendations is a design constraint (e.g., given by the size of the app window). We assume that the system selects the top-items w.r.t. and that their relevance score uniquely determines the ranking of the items in \u0393 + ( ). For each \u2208 \u0393 + ( ), we use ( ) to denote its ranking in \u0393 + ( ). After a user has seen , she/he will find the next item to see from \u0393 + ( ), and the probability of selecting \u2208 \u0393 + ( ) depends on the ranking ( ) of in \u0393 + ( ). More formally, = ( ( )), where is a non-increasing function that maps from ( ) to with\n\u2208\u0393 + ( ) =\n1. This setting can be modeled as a directed probabilistic -regular graph = ( , , M), where the node set corresponds to the set of all items, the edge set comprises \u2022 edges where each node \u2208 has out-edges connected to the nodes in \u0393 + ( ), and M is an \u00d7 transition matrix with a value of for each ( , ) \u2208 and 0 otherwise. A user's browsing session is thus modeled as a random walk on starting from an arbitrary node in with transition probability for each ( , ) \u2208 . We further consider that the items in are divided into two disjoint subsets and \u210e (i.e., \u2229 \u210e = \u2205 and \u222a \u210e = ) corresponding to \"neutral\" (e.g., not-radicalized) and \"harmful\" (e.g., radicalized) nodes, respectively.\nThe risk we want to mitigate is having users stuck in a long sequence of harmful nodes while performing a random walk. In order to quantify this phenomenon we define the measure of segregation. Given a set \u2282 of nodes and a node \u2208 \\ , we use a random variable ( ) to indicate the first instant when a random walk starting from reaches (or \"hits\") any node in . We define E [ ( )] as the hitting length of w.r.t. , where the expectation is over the space of all possible random walks on starting from . In our case, we define the segregation score of node \u2208 \u210e by its expected hitting length E [ ( )] w.r.t. . The segregation ( ) of graph is defined by the maximum of segregation scores among all nodes in \u210e -i.e., ( ) = max \u2208 \u210e . In the following, we omit the argument from ( ) when it is clear from the context.\nOur main problem in this paper is to mitigate the effect of segregation by modifying the structure of . Specifically, we aim to find a set of rewiring operations on , each of which removes an existing edge ( , ) \u2208 and inserts a new one ( , ) \u2209 instead, such that ( ) is minimized, where is the new graph after performing on . For simplicity, we require that , \u2208 \u210e , \u2208 , and = . In other words, each rewiring operation changes the recommendation list \u0393 + ( ) of by replacing one (harmful) item \u2208 \u0393 + ( ) with another (neutral) item \u2209 \u0393 + ( ) and keeping the ranking ( ) of the same as the ranking ( ) of in \u0393 + ( ).\nAnother goal, which is often conflicting, is to preserve the relevance of recommendations after performing the rewiring operations. Besides requiring only a predefined number of rewirings, we also consider an additional constraint on the loss in the quality of the recommendations. For this purpose we adopt the well-known normalized discounted cumulative gain (nDCG) [4,24] to evaluate the loss in the quality. Formally, the discounted cumulative gain (DCG) of a recommendation list \u0393 + ( ) is defined as:\nDCG(\u0393 + ( )) = \u2211\ufe01 \u2208\u0393 + ( ) 1 + log 2 (1 + ( ))\nThen, we define the quality loss of \u0393 + ( ) after rewiring operations by nDCG as follows:\n(\u0393 + ( )) = nDCG(\u0393 + ( )) = DCG(\u0393 + ( )) DCG(\u0393 + 0 ( ))(1)\nwhere \u0393 + 0 ( ) is the original (ideal) recommendation list where all the top-items that are the most relevant to are included.\nLet = ( , , ) be a rewiring operation that deletes ( , ) while adding ( , ) and be a set of rewiring operations. For ease of presentation, we define a function \u0394( ) \u225c ( ) \u2212 ( ) to denote the decrease in the segregation after performing the rewiring operations in and updating to . We are now ready to formally define the main problem studied in this paper. Problem 1 ( -Rewiring). Given a directed probabilistic graph = ( , , M), a positive integer \u2208 Z + , and a threshold \u2208 (0, 1), find a set of rewiring operations that maximizes \u0394( ), under the constraint that (\u0393 + ( )) \u2265 for each node \u2208 .\nThe hardness of the -Rewiring problem is analyzed in the following theorem. Theorem 3.1. The -Rewiring problem is NP-hard and NP-hard to approximate within any factor.\nWe show the NP-hardness of the -Rewiring problem by reducing from the VertexCover problem. Furthermore, we show that finding an -approximate solution of the -Rewiring problem for any factor > 0 is at least as hard as finding the minimum vertex cover of a graph. Therefore, the -Rewiring problem is NP-hard to approximate within any factor. The proof of Theorem 3.1 can be found in Appendix A.", "publication_ref": ["b3", "b23"], "figure_ref": [], "table_ref": []}, {"heading": "Absorbing Random Walk", "text": "We now provide notions from the absorbing random walk theory [34] on which our algorithms are built.\nThe -Rewiring problem asks to minimize segregation, which is defined as the maximum hitting length from any harmful node to neutral nodes. Specifically, in the context of -Rewiring for the given probabilistic directed graph = ( , , M), we equivalently consider a modified transition matrix M as follows:\nM = M \u210e\u210e M \u210e 0 I\nIn the matrix M above, each neutral node has been set to be absorbing, i.e., its transition probability to itself is set to = 1 and 0 to other nodes (see the bottom row of M). Intuitively, no random walk passing through an absorbing node can move away from it [34]. For each harmful node, its transition probabilities remain unmodified (see the top row of M) and thus the node remains transient (i.e., non-absorbing).\nThe fundamental matrix F can be computed from the sub-matrix M \u210e\u210e as follows [34]:\nF = (I \u2212 M \u210e\u210e ) \u22121\nwhere the entry represents the expected total number of times that the random walk visits node having started from node . Then, the expected length of a random walk that starts from any node and stops when it gets absorbed is given by vector z:\nz = (I \u2212 M \u210e\u210e ) \u22121 0 1 (2)\nwhere 1 is an -dimensional vector of all 1's. Here, the -th entry of vector z represents the expected number of random walk steps before being absorbed by any absorbing node, assuming that the random walk starts from the -th node.\nGiven that the absorbing and transient nodes are set to correspond exactly to the neutral and harmful nodes, respectively, the values of z correspond exactly to the expected hitting length as used to define segregation. Hence, the -Rewiring problem asks to choose a set of rewiring operations to minimize the maximum entry = max 1\u2264 \u2264 of vector z.", "publication_ref": ["b33", "b33", "b33"], "figure_ref": [], "table_ref": []}, {"heading": "ALGORITHMS", "text": "Since -Rewiring is NP-hard to approximate within any factor, we propose an efficient heuristic. The heuristic is motivated by the following observation: despite the NP-hardness of -Rewiring, its special case when = 1, which we call 1-Rewiring, is solvable in polynomial time. Given an optimal 1-Rewiring algorithm, -Rewiring can be addressed by running it times. We begin our presentation of algorithms by showing a bruteforce algorithm for finding the optimal solution of 1-Rewiring (Section 4.1), as well as a way to speed it up via incremental updates (Section 4.2). Subsequently, we propose our optimal 1-Rewiring algorithm that improves the efficiency of the brute-force algorithm by faster rewiring search (Section 4.3). Finally, we present how our 1-Rewiring algorithm is used for -Rewiring (Section 4.4).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Brute-Force Algorithm for 1-Rewiring", "text": "Given a graph and a rewiring operation , we use \u0394( ) to denote the decrease in after performing on . We present a bruteforce algorithm to find the rewiring operation * that maximizes \u0394( ). The algorithm has three steps: (1) enumerate the set \u03a9 of all feasible rewiring operations for and a given threshold ; (2) get \u0394( ) for each \u2208 \u03a9 by computing using Eq. 2 on before/after performing ; (3) find the operation that has the largest \u0394( ) as the optimal solution * . In the brute-force algorithm, since the number of existing edges is ( ) and the number of possible new edges to rewire is ( ) for each existing edge, the size of \u03a9 is ( 2 ). In addition, the old and new values of can be computed by matrix inversion using Eq. 2 in ( 3 ) time. Therefore, the bruteforce algorithm runs in ( 5 ) time. As all feasible operations are examined, this solution is guaranteed to be optimal. The brute-force algorithm is impractical if the graph is large, due to the huge number of feasible operations and the high cost of computing . We introduce two strategies to improve its efficiency. First, we update the vector z incrementally for a rewiring operation. Second, we devise efficient strategies to avoid unnecessary computation when searching for the optimal rewiring operation, leading to our optimal 1-Rewiring algorithm.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Incremental Update of Vector z", "text": "We analyze how the fundamental matrix F and vector z change after performing a rewiring operation = ( , , ). Two edits will be performed on for : (1) the removal of an existing edge ( , ) \u2208 and (2) the insertion of a new edge ( , ) \u2209 to .\nThe two operations update the transition matrix M to M \u2032 as follows:\nM\n\u2032 = M + eg \u22a4\nwhere e is an -dimensional column vector that indicates the position of the source node :\n= 1 if = 0 otherwise\nand g \u22a4 is an -dimensional row vector that denotes the changes in the transition probabilities. Specifically, for the removal of ( , ) and insertion of ( , ), the probability of ( , ) is reassigned to ( , ). We denote the probability as = . Formally,\n= \uf8f1 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f3 \u2212 if = + if = 0 otherwise\nThus, operation = ( , , ) on the fundamental matrix F yields an updated fundamental matrix F \u2032 :\nF \u2032 = ((I \u2212 M \u210e\u210e ) \u2212 eg \u22a4 ) \u22121 = (F \u22121 + (\u22121)eg \u22a4 ) \u22121\nBy applying the Sherman-Morrison formula [46], we can avoid the computation of the new inverse and express F \u2032 as:\nF \u2032 = F \u2212 Feg \u22a4 F 1 + g \u22a4 Fe (3)\nAccordingly, the new vector z \u2032 is expressed as:\nz \u2032 = z \u2212 Feg \u22a4 F 1 + g \u22a4 Fe 1 (4)\nThe denominator of the second term in Eq. 4 can be written as:\n1 + g \u22a4 Fe = 1 \u2212 ( \u2022 1 \u2208 \u210e \u2212 )\nwhere 1 \u2208 \u210e is an indicator that is equal to 1 if \u2208 \u210e and 0 otherwise. Because, as mentioned in Section 3, we restrict ourselves to rewiring with \u2209 \u210e , the above expression is simplified as:\n1 + g \u22a4 Fe = 1 + .\nMeanwhile, the numerator of the second term in Eq. 4 is written as: Compute \u0394(\u210e 1 , ) using Eq. 5;\nFeg \u22a4 F1 = \u2212f ( \u2022 1 \u2208 \u210e \u2212 )\n9 if \u2032 \u210e 1 > \u210e 2 then 10 \u0394( ) \u2190 \u0394(\u210e 1 , ); 11 else 12 Find the largest > 1 such that \u2032 \u210e 1 < \u210e ; 13 Compute \u0394(\u210e , ) for each = 2, . . . , ; 14 \u0394( ) \u2190 \u210e 1 \u2212 max \u2208 [1, ] \u2032 \u210e ; 15 if \u0394( ) > \u0394 * then 16 * \u2190 and \u0394 * \u2190 \u0394( ); 17 return * ;\nwhere f is the column vector corresponding to in F, and are the entries of z for and , respectively. As previously, because \u2209 \u210e , we have that Eq. 4 is simplified as:\nz \u2032 = z \u2212 f 1/ + .\nFor any harmful node \u210e, we calculate its decrease \u0394(\u210e, ) in segregation score after performing = ( , , ) as:\n\u0394(\u210e, ) = \u210e \u2212 \u2032 \u210e = \u210e 1/ + (5)\nThe optimal 1-Rewiring we present next is based on Eq. 5.", "publication_ref": ["b45"], "figure_ref": [], "table_ref": []}, {"heading": "Optimal 1-Rewiring Algorithm", "text": "We now introduce our method to find the optimal solution * of 1-Rewiring, i.e., the rewiring operation that maximizes \u0394( ) among all \u2208 \u03a9. The detailed procedure is presented in Algorithm 1, to which the fundamental matrix F and segregation vector z are given as input. The algorithm proceeds in two steps: (1) candidate generation, as described in Lines 2-5, which returns a set \u03a9 of possible rewiring operations that definitely include the optimal 1-Rewiring, and (2) optimal rewiring search, as described in Lines 6-16, which computes the objective value for each candidate rewiring to identify the optimal one. Compared with the brute-force algorithm, this method reduces the cost of computing \u0394( ) since it only probes a few nodes with the largest segregation scores. In addition, it can still be guaranteed to find the optimal solution, as all rewiring operations that might be the optimal one have been considered.\nCandidate generation. The purpose of this step is to exclude from enumeration all rewiring operations that violate the quality constraint. Towards this end, we do not consider any rewiring operation that for any node will lead to the discount cumulative gain (DCG) of below the threshold . According to Eq. 5, we find that \u0394(\u210e, ) of node \u210e w.r.t. = ( , , ) is independent of ( , ). Therefore, for a specific node , we can fix to the neutral (absorbing) node with the highest relevance score and ( , ) \u2209 so that as many rewiring operations as possible are feasible. Then, we should select the node where ( , ) \u2208 will be replaced. We need to guarantee that (\u0393 + ( )) \u2265 after ( , ) is replaced by ( , ). For each node \u2208 \u0393 + ( ), we can take and into Eq. 1. If (\u0393 + ( )) \u2265 , we will list = ( , , ) as a candidate. After considering each node \u2208 \u210e , we generate the set \u03a9 of all candidate rewiring operations.\nOptimal rewiring search. The second step is to search for the optimal rewiring operation * from \u03a9. We first sort all harmful nodes in descending order of their segregation scores as \u27e8\u210e 1 , \u210e 2 , . . . , \u210e \u210e \u27e9, where \u210e is the node with the -th largest segregation score. Since we are interested in minimizing the maximum segregation, we can focus on the first few nodes with the largest segregation scores and ignore the remaining ones. We need to compute \u0394( ) for each \u2208 \u03a9 and always keep the maximum of \u0394( ). After evaluating every \u2208 \u03a9, it is obvious that the one maximizing \u0394( ) is * . Furthermore, to compute \u0394( ) for some operation , we perform the following steps: (1) compute \u0394(\u210e 1 , ) using Eq. 5;\n(2) if \u2032 \u210e 1 > \u210e 2 , then \u0394( ) = \u0394(\u210e 1 , ); (3) otherwise, find the largest such that \u2032 \u210e 1 < \u210e , compute \u0394(\u210e , ) for each = 2, . . . , ; in this case, we have \u0394( ) = \u210e 1 \u2212 max \u2208 [1, ] \u2032 \u210e .\nTime complexity. Compared with the brute-force algorithm, the size of \u03a9 is reduced from ( 2 ) to ( ). Then, sorting the nodes in \u210e takes ( log ) time. Moreover, it takes (1) time to compute \u0394(\u210e, ) for each \u210e and . For each \u2208 \u03a9, \u0394(\u210e, ) is computed ( ) times in the worst case. Therefore, the time complexity is ( 2 ) in the worst case. However, in our experimental evaluation, we find that \u0394(\u210e, ) is computed only a small number of times. Therefore, if computing \u0394( ) takes (1) time in practice, then the anticipated running time is ( + log ) , as confirmed empirically.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Heuristic -Rewiring Algorithm", "text": "Our -Rewiring algorithm based on the 1-Rewiring algorithm is presented in Algorithm 2. Its basic idea is to find the rewiring operations by running the 1-Rewiring algorithm times. The first step is to initialize the fundamental matrix F and segregation vector z. In our implementation, instead of performing the expensive matrix inversion (in Eq. 2), F and z are approximated through the power iteration method in [34]. Then, the procedure of candidate generation is the same as that in Algorithm 1. Next, it runs iterations for getting rewiring operations. At each iteration, it also searches for the the optimal rewiring operation * = ( * , * , * ) among \u03a9 as Algorithm 1. After that, , M, F, and z are updated according to * (see Eq. 3 and 4 for the update of F and z). Since the existing rewiring operations of * are not feasible anymore, it will regenerate new possible operations of * based on the updated \u0393 + ( * ) and the threshold to replace the old ones. Finally, the algorithm terminates when rewiring operations have been found or there is no feasible operation anymore.\nTime complexity. The time complexity of computing F and z is (iter \u2022 ) where iter is the number of iterations in the power method. The time to update F and z for each rewiring operation is ( ). Overall, its time complexity is (\n2 ) since it is safe to consider that iter \u226a . In practice, it takes (1) time to compute \u0394( ) and iter = ( ), and thus the running time of the -Rewiring algorithm can be regarded as ( ( + log )).", "publication_ref": ["b33"], "figure_ref": [], "table_ref": []}, {"heading": "EXPERIMENTS", "text": "Our experiments aim to: (1) show the effectiveness of our algorithm on mitigating radicalization pathways compared to existing algorithms; (2) test the robustness of our algorithm with respect to different thresholds ; and (3) illustrate how much our algorithm can reduce the total exposure to harmful content.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Experimental Setup", "text": "Datasets. We perform experiments within two application domains: video sharing and news feeding.\nFor the first application, we use the YouTube dataset [47], which contains 330,925 videos and 2,474,044 recommendations. The dataset includes node labels such as \"alt-right\", \"alt-lite\", \"intellectual dark web\" and \"neutral\". We categorize the first three classes as \"radicalized\" or harmful and the last class as \"neutral, \" following the analysis done by this dataset's curators [47], in which these three classes are shown to be overlapping in terms of audience and content. When generating the recommendation graphs, we consider only videos having a minimum of 10k views. In this way, we filter out all the ones with too few interactions. We consider the video-to-video recommendations collected via simulations as implicit feedback interactions, where the video-to-video interactions can be formatted as a square matrix, with position ( , ) containing the number of times the user jumped from video to video . Using alternating least squares (ALS) [22], we can first derive the latent dimensions of the matrix, generate the scores (normalized to [0, 1]) and then build the recommendation lists for each video. We eventually create different -regular graphs with \u2208 {5, 10, 20}. To evaluate the effect of graph size on performance, we also use a smaller subset of videos with only 100k or more views for graph construction. Finally, we have 3 smaller (YT-D5-S, YT-D10-S, and YT-D20-S) and 3 larger (YT-D5-B, YT-D10-B, and YT-D20-B) recommendation graphs. For the second application, we use the NELA-GT dataset [39], which is a collection of 713k news in English. Each news article includes title, text, and timestamp, as well as credibility labels (reliable or unreliable). Our task is to reduce the risk of users getting stuck in unreliable content via \"what-to-read-next\" recommendations. To build the recommendation graphs, we compute the pairwise semantic similarities between news through the pre-generated weights with RoBERTa [32]. After normalizing the scores in the range [0, 1], in order to reproduce different instances of news feeding websites, we generate different subsets of news by month. We perform our experiments on the 4 months with the largest number of news: August (NEWS-1), September (NEWS-2), October (NEWS-3) and November (NEWS-4).\nThe characteristics of the ten recommendation graphs used in our experiments are reported in Table 1.\nAlgorithms. We compare our proposed heuristic (HEU) algorithm for -Rewiring with three baselines and one existing algorithm. The first baseline (BSL-1) selects the set of rewiring operations by running Algorithm 1. Instead of picking only one rewiring operation, it picks the operations with the largest values of \u0394 all at once. The second baseline (BSL-2) considers the best possible rewiring operations by looking at the initial values of the vector z. It firsts select the nodes with the largest values, then among the possible rewiring operations from those nodes, it returns the operations with the largest values of \u0394. The third baseline (RND) just picks random rewiring operations from all the candidates. Finally, the existing method we compare with is the RePBubLik algorithm [21] (RBL). It reduces the structural bias of the graph by looking at the bubble radius of the two partitions of nodes, returning a list of new edges to add. The original algorithm is designed for the insertion of new links, and not for the rewiring (deletion + insertion). Consequently, we adapt the RePBubLik algorithm to our objective as follows: (1) we run it to return a list of potential edges to be added for reducing the structural bias of the harmful nodes;\n(2) for each potential insertion, in order to generate a rewiring operation, we check among the existing edges to find the one edge that meets the quality constraint after being replaced by the new edge; (3) we finally select a set of rewiring operations from the previous step.\nThe experiments were conducted on a server running Ubuntu 16.04 with an Intel Broadwell 2.40GHz CPU and 29GB of memory. Our algorithm and baselines were implemented in Python 3. Our code and datasets are publicly available at https://github.com/ FraFabbri/rewiring-what-to-watch. The implementation of ReP-BubLik is available at https://github.com/CriMenghini/RePBubLik.", "publication_ref": ["b46", "b46", "b21", "b38", "b31", "b20"], "figure_ref": [], "table_ref": ["tab_0"]}, {"heading": "Experimental Results", "text": "Effectiveness of our method. In Figure 1, we present the results on the YouTube recommendation graphs. On each graph, we evaluate the performance of each algorithm along 50 rewiring operations with the threshold of quality constraint is fixed to = 0.9. We keep track of the relative decrease in the segregation / 0 after each rewiring operation, where 0 is the initial segregation and is the segregation after rewiring operations. On all the graphs, it is clear that our heuristic algorithm (HEU) outperforms all the competitors. On the graphs with the smallest out-degree ( = 5), it decreases by over 40% within only 10 rewiring operations (i.e., 10 / 0 \u2264 0.6). In this case, it stops decreasing after 30 rewiring operations, which implies that only after a few rewiring operations our heuristic algorithm has found the best possible operations constrained by the threshold . On the graphs with = 10, our heuristic algorithm is able to decrease by nearly 80%, which is even larger than the case of = 5. This result is consistent in both smaller (YT-D10-S) and bigger (YT-D10-B) graphs. On the graphs with the largest out-degree ( = 20), the algorithm is still effective but, as expected, achieves a comparable reduction in after 50 operations.\nThe first baseline (BSL-1) shows almost the same solution quality as HEU, since most of the operations found by both algorithms are the same. Although the rewiring operations provided by ReP-BubLik (RBL) also decrease the original 0 significantly, they are less effective than the ones given by our algorithm. Also, with a smaller size of recommendation list ( = 5), it reaches some steady states along the iterations, where the new rewiring operations do not decrease the value at all. For the YouTube dataset, we present only the results of RBL on the smaller graphs (the second column of Figure 1), since it cannot finish in reasonable time (24 hours) on larger graphs. The other baseline (BSL-2) and the random solution (RND) do not produce substantial decreases over the initial 0 .\nIn Figure 2, we present the results on the NELA-GT recommendation graphs. We also fix = 0.9 in these experiments. Given that the values of 0 are smaller in the news recommendation graph, we evaluate the performance of different algorithms with smaller (i.e., = 20). As for the previous case, our heuristic algorithm is the one achieving the best performance on every graph, which reduces by at least 60% after 20 rewiring operations. Furthermore, on the graph with the biggest value (NEWS-3), it decreases the initial segregation by more than 80% only after 4 rewiring operations. The two baselines (BSL-1 and BSL-2) show comparable performance, but only on NEWS-3 they obtain close drops in 0 to HEU after 20 iterations. In the other cases, they are stuck in steady states far from HEU. The rewiring provided by RePBubLik (RBL) shows no significant decrease over the initial 0 , which is comparable only to RND. The difference in performance between YouTube and NELA-GT can be to some extent attributed to differences in their degree distributions. We compute the Gini coefficient of the in-degree distribution of the graphs: for the YouTube graphs the Gini coefficient of in-degree for the harmful nodes is never below 90%; while for the NELA-GT graphs this index is never above 50%. These differences imply that RePBubLik might not perform well when the in-degree distribution of the graph is not highly skewed.\nRobustness w.r.t. threshold of recommendation quality. To investigate the role of the threshold of recommendation quality on the output of our algorithm, we test on the YouTube recommendation graphs with the same number of rewiring operations ( = 50) but different values of in {0.5, 0.8, 0.9, 0.99}. We present the results in Figure 3. As expected, under a more lenient quality constraint ( = 0.5), the algorithm achieves a larger decease in the value of . It is also clear that the differences are less evident on graphs with a larger out-degree ( = 20). Specifically, for a smaller out-degree ( = 5) all the configurations except = 0.5 tend to stabilize after = 20 rewiring operations. This is because the number of possible rewiring operations constrained by is small. It is also evident that the graph size, given different values of , does not impact the overall performance of our algorithm.\nTotal exposure to harmful content. Having tested the effectiveness of our algorithm in reducing the maximum segregation score, we study its effect on the distribution of the segregation scores over all harmful nodes. Figure 4 depicts the distribution of the values before and after the rewiring operations (with = 50 and = 0.9) provided by HEU and RBL on the YouTube recommendation graphs. For each graph, the violin plot in blue (left) denotes the distribution of segregation scores before the rewiring operations and the one in red (right) the distribution after the rewiring operations. The range of segregation scores is normalized to [0, 1], where the maximum corresponds to the initial segregation. We observe that reducing the maximum segregation also helps reduce the segregation scores of other harmful nodes. Compared to RBL, HEU generates a distribution more highly concentrated around smaller values; this discrepancy between the distributions is most significant when = 20.", "publication_ref": [], "figure_ref": ["fig_0", "fig_0"], "table_ref": []}, {"heading": "CONCLUSIONS AND FUTURE WORK", "text": "In this paper we studied the problem of reducing the risk of radicalization pathways in what-to-watch-next recommenders via edge rewiring on the recommendation graph. We formally defined the segregation score of a radicalized node to measure its potential to trap users into radicalization pathways, and formulated the -Rewiring problem to minimize the maximum segregation score among all radicalized nodes, while maintaining the quality of the recommendations. We proposed an efficient yet effective greedy algorithm based on the absorbing random walk theory. Our experiments, in the context of video and news recommendations, confirmed the effectiveness of our proposed algorithm.\nThis work is just a first step and it has several limitations that we plan to tackle in future work. One main limitation is assuming a binary labelling of nodes, which limits each content to one of the two groups (harmful or neutral), which is not always realistic. A natural extension is to assume numerical labels in [0, 1]. This would require to re-define segregation accordingly.\nAnother limitation is that we are given the recommendation graph as input. This implies that the recommendations are precomputed and static. We plan to extend our setting to a scenario where recommendations are generated dynamically in an online fashion.\nFinally, we showed through empirical evidence how our method, designed to reduce maximum segregation, may actually reduce the total segregation generated by all harmful nodes in the graph. We plan to design different algorithms which are able to directly tackle this objective.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "ACKNOWLEDGMENTS", "text": "Francesco Fabbri is a fellow of Eurecat's Vicente L\u00f3pez PhD grant program; his work was partially financially supported by the Catalan Government through the funding grant ACCI\u00d3-Eurecat (Project PRIVany-nom). Francesco Bonchi acknowledges support from Intesa Sanpaolo Innovation Center. Carlos Castillo has been partially supported by the HUMAINT programme (Human Behaviour and Machine Intelligence), European Commission, and by \"la Caixa\" Foundation (ID 100010434), under agreement LCF/PR/PR16/51110009. Michael Mathioudakis has been supported by the MLDB project of the Academy of Finland (decision number: 322046).\nThe funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.  A PROOF OF THEOREM 3.1\nv 1 v 2 v n \u2026 \u2026 \u2026 h 1 n 1 e 3 v 3 v 4 n 2 h 2 (a) Construct * from e 1 e 2 e m \u2026 \u2026 \u2026 v 1 v 2 v n \u2026 \u2026 \u2026 h 1 n 1 e 3 v 3 v 4 n 2 h 2 (b) -Rewiring on *\nProof. We prove the NP-hardness of the -Rewiring problem by a reduction from the VertexCover problem [17].\nA VertexCover instance is specified by an undirected graph = ( , ), where | | = and | | = , and an integer . It asks whether has a vertex cover of size at most , i.e., whether there exists a subset \u2286 with | | \u2264 such that { , } \u2229 \u2260 \u2205 for every edge = ( , ) \u2208 . We construct an instance of the -Rewiring problem on * from a VertexCover instance on as illustrated in Figure 5a. Given a graph = ( , ), the graph * = ( * , * ) is constructed as follows: One vertex in * is created for each \u2208 and \u2208 . Furthermore, four vertices \u210e 1 , \u210e 2 , 1 , 2 are added to * . Let * \u210e = \u222a \u222a {\u210e 1 , \u210e 2 } be the set of ( + + 2) \"harmful\" vertices (in red) and * = { 1 , 2 } be the set of two \"neutral\" vertices (in blue). Then, for each = ( , ) \u2208 , two directed edges ( , ) and ( , ) are added to * . For each \u2208 , two directed edges ( , \u210e 1 ) and ( , \u210e 2 ) are added to * . Finally, four directed edges (\u210e 1 , 1 ), (\u210e 1 , 2 ), (\u210e 2 , 1 ), and (\u210e 2 , 2 ) are added to * . The out-degree of each red node in * is 2. Accordingly, the transition probability of every edge in * is set to 0.5. We first show that there will be a set of at most rewiring operations such that \u0394( ) > 0 after the rewiring operations in are performed on * if has a vertex cover of size at most . For the original * , we have (\u210e 1 ) = (\u210e 2 ) = 1, ( ) = 2 for each vertex \u2208 , and ( ) = 3 for each edge \u2208 . Thus, we have = ( ) = 3. So, we will have \u0394( ) > 0 as long as \u2032 ( ) < 3 for each edge \u2208 . Let = { 1 , . . . , } be a size-vertex cover of . We construct a set = { 1 , . . . , } of rewiring operations on * , where = ( , \u210e 1 , 1 ), corresponding to , as illustrated in Figure 5b. After performing the set of rewiring operations on * , we have two cases for \u2032 ( ) of each = ( , ):\n\u2032 ( ) = 0.5 \u00d7 3 + 0.5 \u00d7 2 = 2.5, if |{ , } \u2229 | = 2 0.5 \u00d7 3 + 0.5 \u00d7 2.5 = 2.75, if |{ , } \u2229 | = 1\nSince is a vertex cover, there is no edge = ( , ) such that { , } \u2229 = \u2205. Therefore, after performing the set of rewiring operations on * , it must hold that \u2032 ( ) < 3 for every \u2208 and thus \u0394( ) > 0. We then show that there will be a set of at most rewiring operations such that \u0394( ) > 0 after the rewiring operations in are performed on * only if has a vertex cover of size at most . Or equivalently, if does not have a vertex cover of size , then any set of rewiring operations performed on * cannot make \u0394( ) > 0. Since does not have a vertex cover of size , there must exist some edge = ( , ) with { , } \u2229 = \u2205 for any sizevertex set \u2286 . Therefore, after performing the set of rewiring operations corresponding to , we have \u2032 ( ) = 3 for an uncovered edge . So, we can say that any set of rewiring operations from cannot make \u0394( ) > 0. Furthermore, we consider the case of rewiring operations from , i.e., to find a set of edges { 1 , . . . , } and rewire one out-edge from each of them to 1 or 2 . In this case, we can always find some unselected edge with \u2032 ( ) = 3 as long as > , which obviously holds as does not have a vertex cover of size . Finally, we consider the case of a \"hybrid\" set of rewiring operations from both and . W.l.o.g., we assume that there are ( \u2212 \u2032 ) operations from and \u2032 operations from for some 0 < \u2032 < . Since does not have a vertex cover of size , we can say that any vertex set of size ( \u2212 \u2032 ) can cover at most ( \u2212 \u2032 \u2212 1) edges. Otherwise, we would find a vertex cover of size by adding \u2032 vertices to cover the remaining \u2032 edges and thus lead to contradiction. Therefore, after performing only \u2032 rewiring operations from , there always exists at least one edge that are covered by neither the vertex set nor the edge set, and thus \u2032 ( ) = 3 and \u0394( ) = 0. Considering all the three cases, we prove that any set of rewiring operations performed on * cannot make \u0394( ) > 0 if does not have a vertex cover of size .\nGiven that both the \"if \" and \"only-if \" directions are proven and * can be constructed from in ( + ) time, we reduce from the VertexCover problem to the -Rewiring problem in polynomial time and thus prove that the -Rewiring problem is NP-hard.\nTo show the hardness of approximation, we suppose that there is a polynomial-time algorithm A that approximates the -Rewiring problem within a factor of > 0. Or equivalently, for any -Rewiring instance, if * is the set of optimal rewiring operations, then the set \u2032 of rewiring operations returned by A will always satisfy that \u0394( \u2032 ) \u2265 \u2022 \u0394( * ). Let us consider a -Rewiring instance on the above graph * constructed from and be the size of the minimum vertex cover of . For this instance, the optimal solution * of the -Rewiring problem exactly corresponds to the minimum vertex cover * of with \u0394( * ) > 0; any other solution \u2032 will lead to \u0394( \u2032 ) = 0, as we have shown in this proof. If A could find a solution for the -Rewiring problem with any approximation factor > 0 in polynomial time, then A would have solved the VertexCover problem in polynomial time, which has been known to be impossible unless P=NP. Therefore, the -Rewiring problem is NP-hard to approximate with any factor. \u25a1", "publication_ref": ["b16"], "figure_ref": ["fig_5", "fig_5"], "table_ref": []}, {"heading": "B ETHICS STATEMENT", "text": "In this work, we aim at reducing the exposure to radicalized content generated by W2W recommender systems. Our approach does not include any form of censorship, and instead limits algorithmicinduced over-exposure, which is stimulated by biased organic interactions (e.g., the spread of radicalized content through user-user interactions). Our work contributes to raise awareness on the importance of devising policies aimed at reducing harmful algorithmic side-effects. Generally, we do not foresee any immediate and direct harmful impacts from this work.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Social Media and Fake News in the 2016 Election", "journal": "J. Econ. Perspect", "year": "2017", "authors": "Hunt Allcott; Matthew Gentzkow"}, {"ref_id": "b1", "title": "Fighting Opinion Control in Social Networks via Link Recommendation", "journal": "", "year": "2019", "authors": "Victor Amelkin; Ambuj K Singh"}, {"ref_id": "b2", "title": "Improving the Betweenness Centrality of a Node by Adding Links", "journal": "ACM J. Exp. Algorithmics", "year": "2018", "authors": "Elisabetta Bergamini; Pierluigi Crescenzi; D' Gianlorenzo; Henning Angelo; Lorenzo Meyerhenke; Yllka Severini;  Velaj"}, {"ref_id": "b3", "title": "Equity of Attention: Amortizing Individual Fairness in Rankings", "journal": "", "year": "2018", "authors": "Asia J Biega; Krishna P Gummadi; Gerhard Weikum"}, {"ref_id": "b4", "title": "Election Control in Social Networks via Edge Addition or Removal", "journal": "", "year": "2020", "authors": "Matteo Castiglioni; Diodato Ferraioli; Nicola Gatti"}, {"ref_id": "b5", "title": "Make It or Break It: Manipulating Robustness in Large Networks", "journal": "", "year": "2014", "authors": "Leman Hau Chan; Hanghang Akoglu;  Tong"}, {"ref_id": "b6", "title": "Quantifying and Minimizing Risk of Conflict in Social Networks", "journal": "", "year": "2018", "authors": "Xi Chen; Jefrey Lijffijt; Tijl De Bie"}, {"ref_id": "b7", "title": "Analyzing the Impact of Filter Bubbles on Social Network Polarization", "journal": "", "year": "2020", "authors": "Uthsav Chitra; Christopher Musco"}, {"ref_id": "b8", "title": "The Effect of People Recommenders on Echo Chambers and Polarization", "journal": "", "year": "2021", "authors": "Federico Cinus; Marco Minici; Corrado Monti; Francesco Bonchi"}, {"ref_id": "b9", "title": "Greedily Improving Our Own Closeness Centrality in a Network", "journal": "ACM Trans. Knowl. Discov. Data", "year": "2016", "authors": "Pierluigi Crescenzi; D' Gianlorenzo; Lorenzo Angelo; Yllka Severini;  Velaj"}, {"ref_id": "b10", "title": "Quantifying Availability and Discovery in Recommender Systems via Stochastic Reachability", "journal": "", "year": "2021", "authors": "Mihaela Curmei; Sarah Dean; Benjamin Recht"}, {"ref_id": "b11", "title": "Coverage Centrality Maximization in Undirected Networks", "journal": "", "year": "2019", "authors": "D' Gianlorenzo; Martin Angelo; Lorenzo Olsen;  Severini"}, {"ref_id": "b12", "title": "Recommendations and user agency: the reachability of collaboratively-filtered information", "journal": "", "year": "2020", "authors": "Sarah Dean; Sarah Rich; Benjamin Recht"}, {"ref_id": "b13", "title": "The Effect of Homophily on Disparate Visibility of Minorities in People Recommender Systems", "journal": "", "year": "2020", "authors": "Francesco Fabbri; Francesco Bonchi; Ludovico Boratto; Carlos Castillo"}, {"ref_id": "b14", "title": "Exposure Inequality in People Recommender Systems: The Long-Term Effects", "journal": "", "year": "2021", "authors": "Francesco Fabbri; Maria Luisa Croci; Francesco Bonchi; Carlos Castillo"}, {"ref_id": "b15", "title": "The rise of social bots", "journal": "Commun. ACM", "year": "2016", "authors": "Emilio Ferrara; Onur Varol; Clayton A Davis; Filippo Menczer; Alessandro Flammini"}, {"ref_id": "b16", "title": "Computers and Intractability: A Guide to the Theory of NP-Completeness", "journal": "W. H. Freeman", "year": "1979", "authors": "M R Garey; David S Johnson"}, {"ref_id": "b17", "title": "Quantifying Controversy in Social Media", "journal": "", "year": "2016", "authors": "Kiran Garimella; Gianmarco De Francisci;  Morales"}, {"ref_id": "b18", "title": "Reducing Controversy by Connecting Opposing Views", "journal": "", "year": "2017", "authors": "Kiran Garimella; Gianmarco De Francisci; Aristides Morales; Michael Gionis;  Mathioudakis"}, {"ref_id": "b19", "title": "A Measure of Polarization on Social Media Networks Based on Community Boundaries", "journal": "", "year": "2013", "authors": "Pedro Henrique Calais Guerra; Wagner Meira; Claire Cardie; Robert Kleinberg"}, {"ref_id": "b20", "title": "RePBubLik: Reducing Polarized Bubble Radius with Link Insertions", "journal": "", "year": "2021", "authors": "Shahrzad Haddadan; Cristina Menghini; Matteo Riondato; Eli Upfal"}, {"ref_id": "b21", "title": "Collaborative filtering for implicit feedback datasets", "journal": "", "year": "2008", "authors": "Yifan Hu; Yehuda Koren; Chris Volinsky"}, {"ref_id": "b22", "title": "Polarization reduction by minimum-cardinality edge additions: Complexity and integer programming approaches", "journal": "Int. Trans. Oper. Res", "year": "2021", "authors": "Ruben Interian; Jorge R Moreno; Celso C Ribeiro"}, {"ref_id": "b23", "title": "Cumulated gain-based evaluation of IR techniques", "journal": "ACM Trans. Inf. Syst", "year": "2002", "authors": "Kalervo J\u00e4rvelin; Jaana Kek\u00e4l\u00e4inen"}, {"ref_id": "b24", "title": "Scalable diffusion-aware optimization of network topology", "journal": "", "year": "2014", "authors": "Bistra Elias Boutros Khalil; Le Dilkina;  Song"}, {"ref_id": "b25", "title": "Minimizing the Spread of Contamination by Blocking Links in a Network", "journal": "", "year": "2008", "authors": "Masahiro Kimura; Kazumi Saito; Hiroshi Motoda"}, {"ref_id": "b26", "title": "Blocking Simple and Complex Contagion by Edge Removal", "journal": "", "year": "2013", "authors": "Chris J Kuhlman; Gaurav Tuli; Samarth Swarup; V Madhav; S S Marathe;  Ravi"}, {"ref_id": "b27", "title": "MET: A Fast Algorithm for Minimizing Propagation in Large Graphs with Small Eigen-Gaps", "journal": "", "year": "2015", "authors": "Long T Le; Tina Eliassi-Rad; Hanghang Tong"}, {"ref_id": "b28", "title": "Algorithmic extremism: Examining YouTube's rabbit hole of radicalization", "journal": "First Monday", "year": "2020", "authors": "Mark Ledwich; Anna Zaitsev"}, {"ref_id": "b29", "title": "Alternative Influence: Broadcasting the Reactionary Right on YouTube", "journal": "Data & Society Research Institute", "year": "2018", "authors": "Rebecca Lewis"}, {"ref_id": "b30", "title": "Triangle minimization in large networks", "journal": "Knowl. Inf. Syst", "year": "2015", "authors": "Rong-Hua Li; Jeffrey Xu; Yu "}, {"ref_id": "b31", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach", "journal": "", "year": "2019", "authors": "Yinhan Liu; Myle Ott; Naman Goyal; Jingfei Du; Mandar Joshi; Danqi Chen; Omer Levy; Mike Lewis; Luke Zettlemoyer; Veselin Stoyanov"}, {"ref_id": "b32", "title": "Detecting Hate Speech in Social Media", "journal": "", "year": "2017", "authors": "Shervin Malmasi; Marcos Zampieri"}, {"ref_id": "b33", "title": "Absorbing Random-Walk Centrality: Theory and Algorithms", "journal": "", "year": "2015", "authors": "Charalampos Mavroforakis; Michael Mathioudakis; Aristides Gionis"}, {"ref_id": "b34", "title": "Mechanisms of Political Radicalization", "journal": "Pathways Toward Terrorism. Terror. Political Violence", "year": "2008", "authors": "Clark Mccauley; Sophia Moskalenko"}, {"ref_id": "b35", "title": "Group Centrality Maximization via Network Design", "journal": "", "year": "2018", "authors": "Sourav Medya; Arlei Silva; Ambuj K Singh; Prithwish Basu; Ananthram Swami"}, {"ref_id": "b36", "title": "A Measurement Study of Hate Speech in Social Media", "journal": "", "year": "2017", "authors": "Mainack Mondal; Leandro Ara\u00fajo Silva; Fabr\u00edcio Benevenuto"}, {"ref_id": "b37", "title": "Minimizing Polarization and Disagreement in Social Networks", "journal": "", "year": "2018", "authors": "Cameron Musco; Christopher Musco; Charalampos E Tsourakakis"}, {"ref_id": "b38", "title": "NELA-GT-2018: A Large Multi-Labelled News Dataset for the Study of Misinformation in News Articles", "journal": "", "year": "2019", "authors": "Jeppe N\u00f8rregaard; Benjamin D Horne; Sibel Adali"}, {"ref_id": "b39", "title": "Disturbed YouTube for Kids: Characterizing and Detecting Inappropriate Videos Targeting Young Children", "journal": "", "year": "", "authors": "Kostantinos Papadamou; Antonis Papasavva"}, {"ref_id": "b40", "title": "Refining Social Graph Connectivity via Shortcut Edge Addition", "journal": "ACM Trans. Knowl. Discov. Data", "year": "2015", "authors": "Manos Papagelis"}, {"ref_id": "b41", "title": "Suggesting ghost edges for a smaller world", "journal": "", "year": "2011", "authors": "Manos Papagelis; Francesco Bonchi; Aristides Gionis"}, {"ref_id": "b42", "title": "Selecting Shortcuts for a Smaller World", "journal": "", "year": "2015", "authors": "Nikos Parotsidis; Evaggelia Pitoura; Panayiotis Tsaparas"}, {"ref_id": "b43", "title": "Centrality-Aware Link Recommendations", "journal": "", "year": "2016", "authors": "Nikos Parotsidis; Evaggelia Pitoura; Panayiotis Tsaparas"}, {"ref_id": "b44", "title": "Fairness in Rankings and Recommenders", "journal": "", "year": "2020", "authors": "Evaggelia Pitoura; Georgia Koutrika; Kostas Stefanidis"}, {"ref_id": "b45", "title": "Numerical recipes 3rd edition: The art of scientific computing", "journal": "Cambridge University Press", "year": "2007", "authors": "H William; Saul A Press; William T Teukolsky; Brian P Vetterling;  Flannery"}, {"ref_id": "b46", "title": "Auditing radicalization pathways on YouTube", "journal": "", "year": "2020", "authors": "Raphael Manoel Horta Ribeiro; Robert Ottoni;  West; A F Virg\u00edlio; Wagner Almeida;  Meira"}, {"ref_id": "b47", "title": "The Making of a YouTube Radical", "journal": "", "year": "2019", "authors": "Kevin Roose"}, {"ref_id": "b48", "title": "Approximation Algorithms for Reducing the Spectral Radius to Control Epidemic Spread", "journal": "", "year": "2015", "authors": "Sudip Saha; Abhijin Adiga; B Aditya Prakash; Anil Kumar; S Vullikanti"}, {"ref_id": "b49", "title": "", "journal": "Fake News Detection on Social Media: A Data Mining Perspective. SIGKDD Explor", "year": "2017", "authors": "Kai Shu; Amy Sliva; Suhang Wang; Jiliang Tang; Huan Liu"}, {"ref_id": "b50", "title": "Michalis Faloutsos, and Christos Faloutsos. 2012. Gelling, and melting, large graphs by edge manipulation", "journal": "", "year": "", "authors": "Hanghang Tong; B Aditya Prakash; Tina Eliassi-Rad"}, {"ref_id": "b51", "title": "The Manipulability of Centrality Measures -An Axiomatic Approach", "journal": "", "year": "2020", "authors": "Tomasz Was; Marcin Waniek; Talal Rahwan; Tomasz P Michalak"}, {"ref_id": "b52", "title": "Meet the Renegades of the Intellectual Dark Web. The New York Times", "journal": "", "year": "2018", "authors": "Bari Weiss; Damon Winter"}, {"ref_id": "b53", "title": "Rumor Blocking through Online Link Deletion on Social Networks", "journal": "ACM Trans. Knowl. Discov. Data", "year": "2019", "authors": "Ruidong Yan; Yi Li; Weili Wu; Deying Li; Yongcai Wang"}, {"ref_id": "b54", "title": "Recommending what video to watch next: a multitask ranking system", "journal": "", "year": "", "authors": "Zhe Zhao; Lichan Hong; Li Wei; Jilin Chen; Aniruddh Nath; Shawn Andrews; Aditee Kumthekar; Maheswaran Sathiamoorthy"}, {"ref_id": "b55", "title": "K-core Minimization: An Edge Manipulation Approach", "journal": "", "year": "2018", "authors": "Weijie Zhu; Chen Chen; Xiaoyang Wang; Xuemin Lin"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Algorithm 1 :61Optimal 1-Rewiring Input : Graph = ( , , M), fundamental matrix F, segregation vector z, threshold Output : Optimal rewiring operation * 1 Initialize \u03a9 \u2190 \u2205, * \u2190 , \u0394 * \u2190 0; 2 foreach node \u2208 \u210e do 3 Find node \u2208 s.t. ( , ) \u2209 and is the maximum; 4 foreach node \u2208 \u210e with ( , ) \u2208 do 5 Add = ( , , ) to \u03a9 if (\u0393 + ( )) \u2265 after replacing ( , ) with ( , ); Sort nodes in \u210e as \u27e8\u210e 1 , . . . , \u210e \u210e \u27e9 in descending order of \u210e ; 7 foreach \u2208 \u03a9 do 8", "figure_data": ""}, {"figure_label": "2568", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Algorithm 2 : 5 Run 6 \u2190 82568Heuristic -Rewiring Input : Graph = ( , , M), threshold , size constraint Output : A set of rewiring operations 1 Compute the initial F and z based on M; 2 Acquire \u03a9 using Lines 2-5 of Algorithm 1; 3 Initialize \u2190 \u2205; 4 for \u2190 1, 2, . . . , do Lines 6-16 of Algorithm 1 to get * = ( * , * , * ); \u222a { * }; 7 Update , M, F, and z for * ; Delete the existing rewiring operations of * from \u03a9 and add new possible operations of * to \u03a9;", "figure_data": ""}, {"figure_label": "142", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 1 : 4 Figure 2 :142Figure 1: Performance comparison in the YouTube dataset. Algorithms HEU BSL-1 BSL-2 RND RBL", "figure_data": ""}, {"figure_label": "34", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 3 :Figure 4 :34Figure 3: Performance of our algorithm (HEU) with varying quality constraints .", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Figure 5 :5Figure 5: Illustration of the reduction from the VertexCover problem to the -Rewiring problem.", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "Characteristics of the recommendation graphs used in the experiments, including out-degree , number of nodes , number of edges , fraction of nodes from \u210e (i.e., \u210e / ), and initial segregation 0 of each graph.", "figure_data": "YouTubeName\u210e /0YT-D5-S YT-D5-B531524 105143 525715 1576200.48 588.86 0.43 598.32YT-D10-S 10 YT-D10-B31524 105143 1051430 0.43 718.37 315240 0.48 718.92YT-D20-S 20 YT-D20-B31524 105143 2102860 0.43 331.09 630480 0.48 328.03NELA-GTName\u210e /0NEWS-1272862728600.6188.53NEWS-2 NEWS-31022296 28861222960 2886100.62 0.61 335.23 29.90NEWS-4261142611400.6575.15"}], "formulas": [{"formula_id": "formula_0", "formula_text": "\u2208\u0393 + ( ) =", "formula_coordinates": [3.0, 65.21, 372.3, 44.86, 9.23]}, {"formula_id": "formula_1", "formula_text": "DCG(\u0393 + ( )) = \u2211\ufe01 \u2208\u0393 + ( ) 1 + log 2 (1 + ( ))", "formula_coordinates": [3.0, 363.05, 232.26, 148.42, 21.99]}, {"formula_id": "formula_2", "formula_text": "(\u0393 + ( )) = nDCG(\u0393 + ( )) = DCG(\u0393 + ( )) DCG(\u0393 + 0 ( ))(1)", "formula_coordinates": [3.0, 370.68, 283.85, 187.52, 25.71]}, {"formula_id": "formula_3", "formula_text": "M = M \u210e\u210e M \u210e 0 I", "formula_coordinates": [3.0, 403.7, 691.23, 59.69, 18.88]}, {"formula_id": "formula_4", "formula_text": "F = (I \u2212 M \u210e\u210e ) \u22121", "formula_coordinates": [4.0, 144.22, 190.26, 58.9, 10.91]}, {"formula_id": "formula_5", "formula_text": "z = (I \u2212 M \u210e\u210e ) \u22121 0 1 (2)", "formula_coordinates": [4.0, 137.49, 258.6, 156.55, 21.42]}, {"formula_id": "formula_6", "formula_text": "\u2032 = M + eg \u22a4", "formula_coordinates": [4.0, 419.97, 287.58, 43.65, 10.91]}, {"formula_id": "formula_7", "formula_text": "= 1 if = 0 otherwise", "formula_coordinates": [4.0, 406.07, 331.41, 67.82, 19.15]}, {"formula_id": "formula_8", "formula_text": "= \uf8f1 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f3 \u2212 if = + if = 0 otherwise", "formula_coordinates": [4.0, 400.58, 409.55, 79.32, 36.79]}, {"formula_id": "formula_9", "formula_text": "F \u2032 = ((I \u2212 M \u210e\u210e ) \u2212 eg \u22a4 ) \u22121 = (F \u22121 + (\u22121)eg \u22a4 ) \u22121", "formula_coordinates": [4.0, 351.38, 474.15, 172.9, 10.91]}, {"formula_id": "formula_10", "formula_text": "F \u2032 = F \u2212 Feg \u22a4 F 1 + g \u22a4 Fe (3)", "formula_coordinates": [4.0, 404.66, 519.11, 153.54, 22.81]}, {"formula_id": "formula_11", "formula_text": "z \u2032 = z \u2212 Feg \u22a4 F 1 + g \u22a4 Fe 1 (4)", "formula_coordinates": [4.0, 403.19, 563.7, 155.01, 22.81]}, {"formula_id": "formula_12", "formula_text": "1 + g \u22a4 Fe = 1 \u2212 ( \u2022 1 \u2208 \u210e \u2212 )", "formula_coordinates": [4.0, 369.49, 608.13, 136.73, 11.71]}, {"formula_id": "formula_13", "formula_text": "1 + g \u22a4 Fe = 1 + .", "formula_coordinates": [4.0, 398.89, 664.27, 78.22, 10.93]}, {"formula_id": "formula_14", "formula_text": "Feg \u22a4 F1 = \u2212f ( \u2022 1 \u2208 \u210e \u2212 )", "formula_coordinates": [4.0, 375.36, 698.5, 116.07, 11.71]}, {"formula_id": "formula_15", "formula_text": "9 if \u2032 \u210e 1 > \u210e 2 then 10 \u0394( ) \u2190 \u0394(\u210e 1 , ); 11 else 12 Find the largest > 1 such that \u2032 \u210e 1 < \u210e ; 13 Compute \u0394(\u210e , ) for each = 2, . . . , ; 14 \u0394( ) \u2190 \u210e 1 \u2212 max \u2208 [1, ] \u2032 \u210e ; 15 if \u0394( ) > \u0394 * then 16 * \u2190 and \u0394 * \u2190 \u0394( ); 17 return * ;", "formula_coordinates": [5.0, 53.59, 231.57, 177.06, 106.29]}, {"formula_id": "formula_16", "formula_text": "z \u2032 = z \u2212 f 1/ + .", "formula_coordinates": [5.0, 137.3, 400.25, 73.09, 20.17]}, {"formula_id": "formula_17", "formula_text": "\u0394(\u210e, ) = \u210e \u2212 \u2032 \u210e = \u210e 1/ + (5)", "formula_coordinates": [5.0, 117.73, 454.65, 176.31, 17.08]}, {"formula_id": "formula_18", "formula_text": "(2) if \u2032 \u210e 1 > \u210e 2 , then \u0394( ) = \u0394(\u210e 1 , ); (3) otherwise, find the largest such that \u2032 \u210e 1 < \u210e , compute \u0394(\u210e , ) for each = 2, . . . , ; in this case, we have \u0394( ) = \u210e 1 \u2212 max \u2208 [1, ] \u2032 \u210e .", "formula_coordinates": [5.0, 317.96, 513.24, 241.23, 48.56]}, {"formula_id": "formula_19", "formula_text": "v 1 v 2 v n \u2026 \u2026 \u2026 h 1 n 1 e 3 v 3 v 4 n 2 h 2 (a) Construct * from e 1 e 2 e m \u2026 \u2026 \u2026 v 1 v 2 v n \u2026 \u2026 \u2026 h 1 n 1 e 3 v 3 v 4 n 2 h 2 (b) -Rewiring on *", "formula_coordinates": [10.0, 65.73, 88.24, 215.09, 85.49]}, {"formula_id": "formula_20", "formula_text": "\u2032 ( ) = 0.5 \u00d7 3 + 0.5 \u00d7 2 = 2.5, if |{ , } \u2229 | = 2 0.5 \u00d7 3 + 0.5 \u00d7 2.5 = 2.75, if |{ , } \u2229 | = 1", "formula_coordinates": [10.0, 69.61, 576.6, 202.79, 21.59]}], "doi": "10.1145/3485447.3512143"}