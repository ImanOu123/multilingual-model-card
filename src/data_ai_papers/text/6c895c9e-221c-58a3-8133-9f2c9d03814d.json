{"title": "Elucidating the Design Space of Diffusion-Based Generative Models", "authors": "Tero Karras; Nvidia Miika; Aittala Nvidia; Timo Aila; Nvidia Samuli; Laine Nvidia", "pub_date": "", "abstract": "We argue that the theory and practice of diffusion-based generative models are currently unnecessarily convoluted and seek to remedy the situation by presenting a design space that clearly separates the concrete design choices. This lets us identify several changes to both the sampling and training processes, as well as preconditioning of the score networks. Together, our improvements yield new state-of-the-art FID of 1.79 for CIFAR-10 in a class-conditional setting and 1.97 in an unconditional setting, with much faster sampling (35 network evaluations per image) than prior designs. To further demonstrate their modular nature, we show that our design changes dramatically improve both the efficiency and quality obtainable with pre-trained score networks from previous work, including improving the FID of a previously trained ImageNet-64 model from 2.07 to near-SOTA 1.55, and after re-training with our proposed improvements to a new SOTA of 1.36.", "sections": [{"heading": "Introduction", "text": "Diffusion-based generative models [46] have emerged as a powerful new framework for neural image synthesis, in both unconditional [16,37,49] and conditional [17,36,37,39,40,42,43,49] settings, even surpassing the quality of GANs [13] in certain situations [9]. They are also rapidly finding use in other domains such as audio [28,38] and video [19] generation, image segmentation [4,57] and language translation [35]. As such, there is great interest in applying these models and improving them further in terms of image/distribution quality, training cost, and generation speed.\nThe literature on these models is dense on theory, and derivations of sampling schedule, training dynamics, noise level parameterization, etc., tend to be based as directly as possible on theoretical frameworks, which ensures that the models are on a solid theoretical footing. However, this approach has a danger of obscuring the available design space -a proposed model may appear as a tightly coupled package where no individual component can be modified without breaking the entire system.\nAs our first contribution, we take a look at the theory behind these models from a practical standpoint, focusing more on the \"tangible\" objects and algorithms that appear in the training and sampling phases, and less on the statistical processes from which they might be derived. The goal is to obtain better insights into how these components are linked together and what degrees of freedom are available in the design of the overall system. We focus on the broad class of models where a neural network is used to model the score [22] of a noise level dependent marginal distribution of the training data corrupted by Gaussian noise. Thus, our work is in the context of denoising score matching [54].\nOur second set of contributions concerns the sampling processes used to synthesize images using diffusion models. We identify the best-performing time discretization for sampling, apply a higherorder Runge-Kutta method for the sampling process, evaluate different sampler schedules, and analyze the usefulness of stochasticity in the sampling process. The result of these improvements is a significant drop in the number of sampling steps required during synthesis, and the improved sampler can be used as a drop-in replacement with several widely used diffusions models [37,49]. . With increasing noise level, the result approaches dataset mean.\nThe third set of contributions focuses on the training of the score-modeling neural network. While we continue to rely on the commonly used network architectures (DDPM [16], NCSN [48]), we provide the first principled analysis of the preconditioning of the networks' inputs, outputs, and loss functions in a diffusion model setting and derive best practices for improving the training dynamics. We also suggest an improved distribution of noise levels during training, and note that non-leaking augmentation [25] -typically used with GANs -is beneficial for diffusion models as well.\nTaken together, our contributions enable significant improvements in result quality, e.g., leading to record FIDs of 1.79 for CIFAR-10 [29] and 1.36 for ImageNet [8] in 64\u00d764 resolution. With all key ingredients of the design space explicitly tabulated, we believe that our approach will allow easier innovation on the individual components, and thus enable more extensive and targeted exploration of the design space of diffusion models. Our implementation and pre-trained models are available at https://github.com/NVlabs/edm", "publication_ref": ["b45", "b15", "b36", "b48", "b16", "b35", "b36", "b38", "b39", "b41", "b42", "b48", "b12", "b8", "b27", "b37", "b18", "b3", "b56", "b34", "b21", "b53", "b36", "b48", "b15", "b47", "b24", "b7"], "figure_ref": [], "table_ref": []}, {"heading": "Expressing diffusion models in a common framework", "text": "Let us denote the data distribution by p data (x), with standard deviation \u03c3 data , and consider the family of mollified distributions p(x; \u03c3) obtained by adding i.i.d. Gaussian noise of standard deviation \u03c3 to the data. For \u03c3 max \u03c3 data , p(x; \u03c3 max ) is practically indistinguishable from pure Gaussian noise. The idea of diffusion models is to randomly sample a noise image x 0 \u223c N (0, \u03c3 2 max I), and sequentially denoise it into images x i with noise levels \u03c3 0 = \u03c3 max > \u03c3 1 > \u2022 \u2022 \u2022 > \u03c3 N = 0 so that at each noise level x i \u223c p(x i ; \u03c3 i ). The endpoint x N of this process is thus distributed according to the data. Song et al. [49] present a stochastic differential equation (SDE) that maintains the desired distribution p as sample x evolves over time. This allows the above process to be implemented using a stochastic solver that both removes and adds noise at each iteration. They also give a corresponding \"probability flow\" ordinary differential equation (ODE) where the only source of randomness is the initial noise image x 0 . Contrary to the usual order of treatment, we begin by examining the ODE, as it offers a fruitful setting for analyzing sampling trajectories and their discretizations. The insights carry over to stochastic sampling, which we reintroduce as a generalization in Section 4. [49] continuously increases or reduces noise level of the image when moving forward or backward in time, respectively. To specify the ODE, we must first choose a schedule \u03c3(t) that defines the desired noise level at time t. For example, setting \u03c3(t) \u221d \u221a t is mathematically natural, as it corresponds to constant-speed heat diffusion [12]. However, we will show in Section 3 that the choice of schedule has major practical implications and should not be made on the basis of theoretical convenience.", "publication_ref": ["b48", "b48", "b11"], "figure_ref": [], "table_ref": []}, {"heading": "ODE formulation. A probability flow ODE", "text": "The defining characteristic of the probability flow ODE is that evolving a sample x a \u223c p x a ; \u03c3(t a ) from time t a to t b (either forward or backward in time) yields a sample x b \u223c p x b ; \u03c3(t b ) . Following previous work [49], this requirement is satisfied (see Appendix B.1 and B.2) by dx = \u2212\u03c3(t) \u03c3(t) \u2207 x log p x; \u03c3(t) dt,\nwhere the dot denotes a time derivative. \u2207 x log p(x; \u03c3) is the score function [22], a vector field that points towards higher density of data at a given noise level. Intuitively, an infinitesimal forward step of this ODE nudges the sample away from the data, at a rate that depends on the change in noise level. Equivalently, a backward step nudges the sample towards the data distribution.\nDenoising score matching. The score function has the remarkable property that it does not depend on the generally intractable normalization constant of the underlying density function p(x; \u03c3) [22], Table 1: Specific design choices employed by different model families. N is the number of ODE solver iterations that we wish to execute during sampling. The corresponding sequence of time steps is {t 0 , t 1 , . . . , t N }, where t N = 0. If the model was originally trained for specific choices of N and {t i }, the originals are denoted by M and {u j }, respectively. The denoiser is defined as D \u03b8 (x; \u03c3) = c skip (\u03c3)x + c out (\u03c3)F \u03b8 c in (\u03c3)x; c noise (\u03c3) ; F \u03b8 represents the raw neural network layers.\nVP [49] VE [49] iDDPM [37] + DDIM [47] Ours (\"EDM\") Sampling (Section 3) ODE solver Euler Euler Euler 2 nd order Heun Time steps 2 * iDDPM also employs a second loss term L vlb \u2020 In our tests, j 0 = 8 yielded better FID than j 0 = 0 used by iDDPM and thus can be much easier to evaluate. Specifically, if D(x; \u03c3) is a denoiser function that minimizes the expected L 2 denoising error for samples drawn from p data separately for every \u03c3, i.e., E y\u223cpdata E n\u223cN (0,\u03c3 2 I) D(y + n; \u03c3) \u2212 y 2 2 , then \u2207 x log p(x; \u03c3) = D(x; \u03c3) \u2212 x /\u03c3 2 , (2, 3) where y is a training image and n is noise. In this light, the score function isolates the noise component from the signal in x, and Eq. 1 amplifies (or diminishes) it over time. Figure 1 illustrates the behavior of ideal D in practice. The key observation in diffusion models is that D(x; \u03c3) can be implemented as a neural network D \u03b8 (x; \u03c3) trained according to Eq. 2. Note that D \u03b8 may include additional pre-and post-processing steps, such as scaling x to an appropriate dynamic range; we will return to such preconditioning in Section 5. Time-dependent signal scaling. Some methods (see Appendix C.1) introduce an additional scale schedule s(t) and consider x = s(t)x to be a scaled version of the original, non-scaled variablex. This changes the time-dependent probability density, and consequently also the ODE solution trajectories. The resulting ODE is a generalization of Eq. 1:\nt i<N 1 + i N \u22121 ( s \u2212 1) \u03c3 2 max \u03c3 2 min /\u03c3 2 max i N \u22121 u j0+ M \u22121\u2212j 0 N \u22121\ndx = \u1e61(t) s(t) x \u2212 s(t) 2\u03c3 (t) \u03c3(t) \u2207 x log p x s(t) ; \u03c3(t) dt.(4)\nNote that we explicitly undo the scaling of x when evaluating the score function to keep the definition of p(x; \u03c3) independent of s(t).\nSolution by discretization. The ODE to be solved is obtained by substituting Eq. 3 into Eq. 4 to define the point-wise gradient, and the solution can be found by numerical integration, i.e., taking finite steps over discrete time intervals. This requires choosing both the integration scheme (e.g., Euler or a variant of Runge-Kutta), as well as the discrete sampling times {t 0 , t 1 , . . . , t N }. Many prior works rely on Euler's method, but we show in Section 3 that a 2 nd order solver offers a better computational tradeoff. For brevity, we do not provide a separate pseudocode for Euler's method applied to our ODE here, but it can be extracted from Algorithm 1 by omitting lines 6-8.\nPutting it together. Table 1 presents formulas for reproducing deterministic variants of three earlier methods in our framework. These methods were chosen because they are widely used and Comparison of deterministic sampling methods using three pre-trained models. For each curve, the dot indicates the lowest NFE whose FID is within 3% of the lowest observed FID.\nachieve state-of-the-art performance, but also because they were derived from different theoretical foundations. Some of our formulas appear quite different from the original papers as indirection and recursion have been removed; see Appendix C for details. The main purpose of this reframing is to bring into light all the independent components that often appear tangled together in previous work. In our framework, there are no implicit dependencies between the components -any choices (within reason) for the individual formulas will, in principle, lead to a functioning model. In other words, changing one component does not necessitate changes elsewhere in order to, e.g., maintain the property that the model converges to the data in the limit. In practice, some choices and combinations will of course work better than others.", "publication_ref": ["b48", "b21", "b21", "b48", "b48", "b36", "b46", "b1"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Improvements to deterministic sampling", "text": "Improving the output quality and/or decreasing the computational cost of sampling are common topics in diffusion model research (e.g., [10,24,31,32,33,37,44,53,55,56,59]). Our hypothesis is that the choices related to the sampling process are largely independent of the other components, such as network architecture and training details. In other words, the training procedure of D \u03b8 should not dictate \u03c3(t), s(t), and {t i }, nor vice versa; from the viewpoint of the sampler, D \u03b8 is simply a black box [55,56]. We test this by evaluating different samplers on three pre-trained models, each representing a different theoretical framework and model family. We first measure baseline results for these models using their original sampler implementations, and then bring these samplers into our unified framework using the formulas in Table 1, followed by our improvements. This allows us to evaluate different practical choices and propose general improvements to the sampling process that are applicable to all models.\nWe evaluate the \"DDPM++ cont. (VP)\" and \"NCSN++ cont. (VE)\" models by Song et al. [49] trained on unconditional CIFAR-10 [29] at 32\u00d732, corresponding to the variance preserving (VP) and variance exploding (VE) formulations [49], originally inspired by DDPM [16] and SMLD [48]. We also evaluate the \"ADM (dropout)\" model by Dhariwal and Nichol [9] trained on class-conditional Im-ageNet [8] at 64\u00d764, corresponding to the improved DDPM (iDDPM) formulation [37]. This model was trained using a discrete set of M = 1000 noise levels. Further details are given in Appendix C.\nWe evaluate the result quality in terms of Fr\u00e9chet inception distance (FID) [15] computed between 50,000 generated images and all available real images. Figure 2 shows FID as a function of neural function evaluations (NFE), i.e., how many times D \u03b8 is evaluated to produce a single image. Given that the sampling process is dominated entirely by the cost of D \u03b8 , improvements in NFE translate directly to sampling speed. The original deterministic samplers are shown in blue, and the reimplementations of these methods in our unified framework (orange) yield similar but consistently better results. The differences are explained by certain oversights in the original implementations as well as our more careful treatment of discrete noise levels in the case of DDIM; see Appendix C. Note that our reimplementations are fully specified by Algorithm 1 and Table 1, even though the original codebases are structured very differently from each other.\nDiscretization and higher-order integrators. Solving an ODE numerically is necessarily an approximation of following the true solution trajectory. At each step, the solver introduces truncation error that accumulates over the course of N steps. The local error generally scales superlinearly with respect to step size, and thus increasing N improves the accuracy of the solution.\nThe commonly used Euler's method is a first order ODE solver with O(h 2 ) local error with respect to step size h. Higher-order Runge-Kutta methods [50] scale more favorably but require multiple Algorithm 1 Deterministic sampling using Heun's 2 nd order method with arbitrary \u03c3(t) and s(t).\n1: procedure HEUNSAMPLER(D \u03b8 (x; \u03c3), \u03c3(t), s(t), t i\u2208{0,...,N } ) 2: sample x0 \u223c N 0, \u03c3 2 (t0) s 2 (t0) I Generate initial sample at t0 3:\nfor i \u2208 {0, . . . , N \u2212 1} do Solve Eq. 4 over N time steps\n4: di \u2190 \u03c3(ti) \u03c3(ti) +\u1e61 (ti) s(ti) xi \u2212\u03c3 (ti)s(ti) \u03c3(ti) D \u03b8 xi s(ti)\n; \u03c3(ti) Evaluate dx/dt at ti\n5: xi+1 \u2190 xi + (ti+1 \u2212 ti)di\nTake Euler step from ti to ti+1 6: if \u03c3(ti+1) = 0 then Apply 2 nd order correction unless \u03c3 goes to zero 7:\nd i \u2190 \u03c3(ti+1) \u03c3(ti+1) +\u1e61 (ti+1) s(ti+1) xi+1 \u2212\u03c3 (ti+1)s(ti+1) \u03c3(ti+1) D\u03b8 xi+1 s(ti+1)\n; \u03c3(ti+1)\nEval. dx/dt at ti+1\n8: xi+1 \u2190 xi + (ti+1 \u2212 ti) 1 2 di + 1 2 d i\nExplicit trapezoidal rule at ti+1 9:\nreturn xN Return noise-free sample at tN evaluations of D \u03b8 per step. Linear multistep methods have also been recently proposed for sampling diffusion models [31,59]. Through extensive tests, we have found Heun's 2 nd order method [2] (a.k.a. improved Euler, trapezoidal rule) -previously explored in the context of diffusion models by Jolicoeur-Martineau et al. [24] -to provide an excellent tradeoff between truncation error and NFE.\nAs illustrated in Algorithm 1, it introduces an additional correction step for x i+1 to account for change in dx/dt between t i and t i+1 . This correction leads to O(h 3 ) local error at the cost of one additional evaluation of D \u03b8 per step. Note that stepping to \u03c3 = 0 would result in a division by zero, so we revert to Euler's method in this case. We discuss the general family of 2 nd order solvers in Appendix D.2.\nThe time steps {t i } determine how the step sizes and thus truncation errors are distributed between different noise levels. We provide a detailed analysis in Appendix D.1, concluding that the step size should decrease monotonically with decreasing \u03c3 and it does not need to vary on a per-sample basis. We adopt a parameterized scheme where the time steps are defined according to a sequence of noise levels {\u03c3 i }, i.e., t i = \u03c3 \u22121 (\u03c3 i ). We set \u03c3 i<N = (Ai + B) \u03c1 and select the constants A and B so that \u03c3 0 = \u03c3 max and \u03c3 N \u22121 = \u03c3 min , which gives\n\u03c3 i<N = \u03c3 max 1 \u03c1 + i N \u22121 (\u03c3 min 1 \u03c1 \u2212 \u03c3 max 1 \u03c1 ) \u03c1 and \u03c3 N = 0. (5\n)\nHere \u03c1 controls how much the steps near \u03c3 min are shortened at the expense of longer steps near \u03c3 max . Our analysis in Appendix D.1 shows that setting \u03c1 = 3 nearly equalizes the truncation error at each step, but that \u03c1 in range of 5 to 10 performs much better for sampling images. This suggests that errors near \u03c3 min have a large impact. We set \u03c1 = 7 for the remainder of this paper.\nResults for Heun's method and Eq. 5 are shown as the green curves in Figure 2. We observe consistent improvement in all cases: Heun's method reaches the same FID as Euler's method with considerably lower NFE.\nTrajectory curvature and noise schedule. The shape of the ODE solution trajectories is defined by functions \u03c3(t) and s(t). The choice of these functions offers a way to reduce the truncation errors discussed above, as their magnitude can be expected to scale proportional to the curvature of dx/dt. We argue that the best choice for these functions is \u03c3(t) = t and s(t) = 1, which is also the choice made in DDIM [47]. With this choice, the ODE of Eq. 4 simplifies to dx/dt = x \u2212 D(x; t) /t and \u03c3 and t become interchangeable.\nAn immediate consequence is that at any x and t, a single Euler step to t = 0 yields the denoised image D \u03b8 (x; t). The tangent of the solution trajectory therefore always points towards the denoiser output. This can be expected to change only slowly with the noise level, which corresponds to largely linear solution trajectories. The 1D ODE sketch of Figure 3c supports this intuition; the solution trajectories approach linear at both large and small noise levels, and have substantial curvature in only a small region in between. The same effect can be seen with real data in Figure 1b, where the change between different denoiser targets occurs in a relatively narrow \u03c3 range. With the advocated schedule, this corresponds to high ODE curvature being limited to this same range.\nThe effect of setting \u03c3(t) = t and s(t) = 1 is shown as the red curves in Figure 2. As DDIM already employs these same choices, the red curve is identical to the green one for ImageNet-64. However, VP and VE benefit considerably from switching away from their original schedules.  [47] and us, as \u03c3 increases the solution trajectories approach straight lines that point towards the mean of data. As \u03c3 \u2192 0, the trajectories become linear and point towards the data manifold.\nDiscussion. The choices that we made in this section to improve deterministic sampling are summarized in the Sampling part of Table 1. Together, they reduce the NFE needed to reach highquality results by a large factor: 7.3\u00d7 for VP, 300\u00d7 for VE, and 3.2\u00d7 for DDIM, corresponding to the highlighted NFE values in Figure 2. In practice, we can generate 26.3 high-quality CIFAR-10 images per second on a single NVIDIA V100. The consistency of improvements corroborates our hypothesis that the sampling process is orthogonal to how each model was originally trained. As further validation, we show results for the adaptive RK45 method [11] using our schedule as the dashed black curves in Figure 2; the cost of this sophisticated ODE solver outweighs its benefits.", "publication_ref": ["b9", "b23", "b30", "b31", "b32", "b36", "b43", "b52", "b54", "b55", "b58", "b54", "b55", "b48", "b48", "b15", "b47", "b8", "b7", "b36", "b14", "b49", "b30", "b58", "b1", "b23", "b46", "b46", "b10"], "figure_ref": ["fig_2", "fig_2", "fig_3", "fig_0", "fig_2", "fig_2", "fig_2"], "table_ref": []}, {"heading": "Stochastic sampling", "text": "Deterministic sampling offers many benefits, e.g., the ability to turn real images into their corresponding latent representations by inverting the ODE. However, it tends to lead to worse output quality [47,49] than stochastic sampling that injects fresh noise into the image in each step. Given that ODEs and SDEs recover the same distributions in theory, what exactly is the role of stochasticity?\nBackground. The SDEs of Song et al. [49] can be generalized [20,58] as a sum of the probability flow ODE of Eq. 1 and a time-varying Langevin diffusion SDE [14] (see Appendix B.5):\ndx \u00b1 = \u2212\u03c3(t)\u03c3(t)\u2207 x log p x; \u03c3(t) dt probability flow ODE (Eq. 1) \u00b1 \u03b2(t)\u03c3(t) 2 \u2207 x log p x; \u03c3(t) dt deterministic noise decay + 2\u03b2(t)\u03c3(t) d\u03c9 t noise injection Langevin diffusion SDE ,(6)\nwhere \u03c9 t is the standard Wiener process. dx + and dx \u2212 are now separate SDEs for moving forward and backward in time, related by the time reversal formula of Anderson [1]. The Langevin term can further be seen as a combination of a deterministic score-based denoising term and a stochastic noise injection term, whose net noise level contributions cancel out. As such, \u03b2(t) effectively expresses the relative rate at which existing noise is replaced with new noise. The SDEs of Song et al. [49] are recovered with the choice \u03b2(t) =\u03c3(t)/\u03c3(t), whereby the score vanishes from the forward SDE.\nThis perspective reveals why stochasticity is helpful in practice: The implicit Langevin diffusion drives the sample towards the desired marginal distribution at a given time, actively correcting for any errors made in earlier sampling steps. On the other hand, approximating the Langevin term with discrete SDE solver steps introduces error in itself. Previous results [3,24,47,49] suggest that non-zero \u03b2(t) is helpful, but as far as we can tell, the implicit choice for \u03b2(t) in Song et al. [49] enjoys no special properties. Hence, the optimal amount of stochasticity should be determined empirically.\nOur stochastic sampler. We propose a stochastic sampler that combines our 2 nd order deterministic ODE integrator with explicit Langevin-like \"churn\" of adding and removing noise. A pseudocode is given in Algorithm 2. At each step i, given the sample x i at noise level t i (= \u03c3(t i )), we perform two Algorithm 2 Our stochastic sampler with \u03c3(t) = t and s(t) = 1.\n1: procedure STOCHASTICSAMPLER(D \u03b8 (x; \u03c3), t i\u2208{0,...,N } , \u03b3 i\u2208{0,...,N \u22121} , Snoise)\n2: sample x0 \u223c N 0, t 2 0 I 3: for i \u2208 {0, . . . , N \u2212 1} do \u03b3i = min S churn N , \u221a 2\u22121 if ti\u2208[Stmin,Stmax] 0 otherwise 4: sample i \u223c N 0, S 2 noise I 5:ti \u2190 ti + \u03b3iti Select temporarily increased noise levelti 6:xi \u2190 xi + t 2 i \u2212 t 2 i i\nAdd new noise to move from ti toti 7:\ndi \u2190 xi \u2212 D \u03b8 (xi;ti) /ti\nEvaluate dx/dt atti 8:\nxi+1 \u2190xi + (ti+1 \u2212ti)di Take Euler step fromti to ti+1 9:\nif ti+1 = 0 then 10:\nd i \u2190 xi+1 \u2212 D \u03b8 (xi+1; ti+1) /ti+1\nApply 2 nd order correction 11:\nxi+1 \u2190xi + (ti+1 \u2212ti)\n1 2 di + 1 2 d i 12:\nreturn xN sub-steps. First, we add noise to the sample according to a factor \u03b3 i \u2265 0 to reach a higher noise level t i = t i + \u03b3 i t i . Second, from the increased-noise samplex i , we solve the ODE backward fromt i to t i+1 with a single step. This yields a sample x i+1 with noise level t i+1 , and the iteration continues. We stress that this is not a general-purpose SDE solver, but a sampling procedure tailored for the specific problem. Its correctness stems from the alternation of two sub-steps that each maintain the correct distribution (up to truncation error in the ODE step). The predictor-corrector sampler of Song et al. [49] has a conceptually similar structure to ours.\nTo analyze the main difference between our method and Euler-Maruyama, we first note a subtle discrepancy in the latter when discretizing Eq. 6. One can interpret Euler-Maruyama as first adding noise and then performing an ODE step, not from the intermediate state after noise injection, but assuming that x and \u03c3 remained at the initial state at the beginning of the iteration step. In our method, the parameters used to evaluate D \u03b8 on line 7 of Algorithm 2 correspond to the state after noise injection, whereas an Euler-Maruyama -like method would use x i ; t i instead ofx i ;t i . In the limit of \u2206 t approaching zero there may be no difference between these choices, but the distinction appears to become significant when pursuing low NFE with large steps.\nPractical considerations. Increasing the amount of stochasticity is effective in correcting errors made by earlier sampling steps, but it has its own drawbacks. We have observed (see Appendix E.1) that excessive Langevin-like addition and removal of noise results in gradual loss of detail in the generated images with all datasets and denoiser networks. There is also a drift toward oversaturated colors at very low and high noise levels. We suspect that practical denoisers induce a slightly nonconservative vector field in Eq. 3, violating the premises of Langevin diffusion and causing these detrimental effects. Notably, our experiments with analytical denoisers (such as the one in Figure 1b) have not shown such degradation.\nIf the degradation is caused by flaws in D \u03b8 (x; \u03c3), they can only be remedied using heuristic means during sampling. We address the drift toward oversaturated colors by only enabling stochasticity within a specific range of noise levels t i \u2208 [S tmin , S tmax ]. For these noise levels, we define \u03b3 i = S churn /N , where S churn controls the overall amount of stochasticity. We further clamp \u03b3 i to never introduce more new noise than what is already present in the image. Finally, we have found that the loss of detail can be partially counteracted by setting S noise slightly above 1 to inflate the standard deviation for the newly added noise. This suggests that a major component of the hypothesized non-conservativity of D \u03b8 (x; \u03c3) is a tendency to remove slightly too much noise -most likely due to regression toward the mean that can be expected to happen with any L 2 -trained denoiser [30].\nEvaluation. Figure 4 shows that our stochastic sampler outperforms previous samplers [24,37,49] by a significant margin, especially at low step counts. Jolicoeur-Martineau et al. [24] use a standard higher-order adaptive SDE solver [41] and its performance is a good baseline for such solvers in general. Our sampler has been tailored to the use case by, e.g., performing noise injection and ODE step sequentially, and it is not adaptive. It is an open question if adaptive solvers can be a net win over a well-tuned fixed schedule in sampling diffusion models.\nThrough sampler improvements alone, we are able to bring the ImageNet-64 model that originally achieved FID 2.07 [9] [45]. While our results showcase the potential gains achievable through sampler improvements, they also highlight the main shortcoming of stochasticity: For best results, one must make several heuristic choices -either implicit or explicit -that depend on the specific model. Indeed, we had to find the optimal values of {S churn , S tmin , S tmax , S noise } on a case-by-case basis using grid search (Appendix E.2). This raises a general concern that using stochastic sampling as the primary means of evaluating model improvements may inadvertently end up influencing the design choices related to model architecture and training.", "publication_ref": ["b46", "b48", "b48", "b19", "b57", "b13", "b0", "b48", "b2", "b23", "b46", "b48", "b48", "b48", "b29", "b23", "b36", "b48", "b23", "b40", "b8", "b44"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Preconditioning and training", "text": "There are various known good practices for training neural networks in a supervised fashion. For example, it is advisable to keep input and output signal magnitudes fixed to, e.g., unit variance, and to avoid large variation in gradient magnitudes on a per-sample basis [5,21]. Training a neural network to model D directly would be far from ideal -for example, as the input x = y + n is a combination of clean signal y and noise n \u223c N (0, \u03c3 2 I), its magnitude varies immensely depending on noise level \u03c3. For this reason, the common practice is to not represent D \u03b8 as a neural network directly, but instead train a different network F \u03b8 from which D \u03b8 is derived.\nPrevious methods [37,47,49] address the input scaling via a \u03c3-dependent normalization factor and attempt to precondition the output by training F \u03b8 to predict n scaled to unit variance, from which the signal is then reconstructed via D \u03b8 (x; \u03c3) = x \u2212 \u03c3F \u03b8 (\u2022). This has the drawback that at large \u03c3, the network needs to fine-tune its output carefully to cancel out the existing noise n exactly and give the output at the correct scale; note that any errors made by the network are amplified by a factor of \u03c3.\nIn this situation, it would seem much easier to predict the expected output D(x; \u03c3) directly. In the same spirit as previous parameterizations that adaptively mix signal and noise (e.g., [10,44,53]), we propose to precondition the neural network with a \u03c3-dependent skip connection that allows it to estimate either y or n, or something in between. We thus write D \u03b8 in the following form:\nD \u03b8 (x; \u03c3) = c skip (\u03c3) x + c out (\u03c3) F \u03b8 c in (\u03c3) x; c noise (\u03c3) ,(7)\nwhere F \u03b8 is the neural network to be trained, c skip (\u03c3) modulates the skip connection, c in (\u03c3) and c out (\u03c3) scale the input and output magnitudes, and c noise (\u03c3) maps noise level \u03c3 into a conditioning input for F \u03b8 . Taking a weighted expectation of Eq. 2 over the noise levels gives the overall training loss E \u03c3,y,n \u03bb(\u03c3) D(y + n; \u03c3) \u2212 y 2 2 , where \u03c3 \u223c p train , y \u223c p data , and n \u223c N (0, \u03c3 2 I). The probability of sampling a given noise level \u03c3 is given by p train (\u03c3) and the corresponding weight is given by \u03bb(\u03c3). We can equivalently express this loss with respect to the raw network output F \u03b8 in Eq. 7:\nE \u03c3,y,n \u03bb(\u03c3) c out (\u03c3) 2 effective weight F \u03b8 c in (\u03c3) \u2022 (y + n); c noise (\u03c3) network output \u2212 1 cout(\u03c3) y \u2212 c skip (\u03c3) \u2022 (y + n) effective training target 2 2 . (8\n)\nThis form reveals the effective training target of F \u03b8 , allowing us to determine suitable choices for the preconditioning functions from first principles. As detailed in Appendix B.6, we derive our choices shown in Table 1 by requiring network inputs and training targets to have unit variance (c in , c out ), and amplifying errors in F \u03b8 as little as possible (c skip ). The formula for c noise is chosen empirically.\nTable 2 shows FID for a series of training setups, evaluated using our deterministic sampler from Section 3. We start with the baseline training setup of Song et al. [49], which differs considerably between the VP and VE cases; we provide separate results for each (config A). To obtain a more meaningful point of comparison, we re-adjust the basic hyperparameters (config B) and improve the expressive power of the model (config C) by removing the lowest-resolution layers and doubling the capacity of the highest-resolution layers instead; see Appendix F.3 for further details. We then replace the original choices of {c in , c out , c noise , c skip } with our preconditioning (config D), which keeps the results largely unchanged -except for VE that improves considerably at 64\u00d764 resolution. Instead of improving FID per se, the main benefit of our preconditioning is that it makes the training more robust, enabling us to turn our focus on redesigning the loss function without adverse effects.\nLoss weighting and sampling. Eq. 8 shows that training F \u03b8 as preconditioned in Eq. 7 incurs an effective per-sample loss weight of \u03bb(\u03c3)c out (\u03c3) 2 . To balance the effective loss weights, we set \u03bb(\u03c3) = 1/c out (\u03c3) 2 , which also equalizes the initial training loss over the entire \u03c3 range as shown in Figure 5a (green curve). Finally, we need to select p train (\u03c3), i.e., how to choose noise levels during training. Inspecting the per-\u03c3 loss after training (blue and orange curves) reveals that a significant reduction is possible only at intermediate noise levels; at very low levels, it is both difficult and irrelevant to discern the vanishingly small noise component, whereas at high levels the training targets are always dissimilar from the correct answer that approaches dataset average. Therefore, we target the training efforts to the relevant range using a simple log-normal distribution for p train (\u03c3) as detailed in Table 1 and illustrated in Figure 5a (red curve).\nTable 2 shows that our proposed p train and \u03bb (config E) lead to a dramatic improvement in FID in all cases when used in conjunction with our preconditioning (config D). In concurrent work, Choi et al. [6] propose a similar scheme to prioritize noise levels that are most relevant w.r.t. forming the perceptually recognizable content of the image. However, they only consider the choice of \u03bb in isolation, which results in a smaller overall improvement.\nAugmentation regularization. To prevent potential overfitting that often plagues diffusion models with smaller datasets, we borrow an augmentation pipeline from the GAN literature [25]. The pipeline consists of various geometric transformations (see Appendix F.2) that we apply to a training image prior to adding noise. To prevent the augmentations from leaking to the generated images, we provide the augmentation parameters as a conditioning input to F \u03b8 ; during inference we set the them to zero to guarantee that only non-augmented images are generated. Table 2 shows that data augmentation provides a consistent improvement (config F) that yields new state-of-the-art FIDs of 1.79 and 1.97 for conditional and unconditional CIFAR-10, beating the previous records of 1.85 [45] and 2.10 [53].\nStochastic sampling revisited. Interestingly, the relevance of stochastic sampling appears to diminish as the model itself improves, as shown in Figure 5b,c. When using our training setup in CIFAR-10 (Figure 5b), the best results were obtained with deterministic sampling, and any amount of stochastic sampling was detrimental. 1.36 compared to the previous record of 1.48 [17]. We used the ADM architecture [9] with no changes, and trained it using our config E with minimal tuning; see Appendix F.3 for details. We did not find overfitting to be a concern, and thus chose to not employ augmentation regularization. As shown in Figure 5c, the optimal amount of stochastic sampling was much lower than with the pre-trained model, but unlike with CIFAR-10, stochastic sampling was clearly better than deterministic sampling. This suggests that more diverse datasets continue to benefit from stochastic sampling.", "publication_ref": ["b4", "b20", "b36", "b46", "b48", "b9", "b43", "b52", "b48", "b5", "b24", "b44", "b52", "b16", "b8"], "figure_ref": [], "table_ref": ["tab_1", "tab_1", "tab_1"]}, {"heading": "Conclusions", "text": "Our approach of putting diffusion models to a common framework exposes a modular design. This allows a targeted investigation of individual components, potentially helping to better cover the viable design space. In our tests this let us simply replace the samplers in various earlier models, drastically improving the results.  [17,36,40], subspace projection [23], very large networks [9,49], or hybrid approaches [39,42,53] -we believe that our contributions are orthogonal to these extensions. That said, many of our parameter values may need to be re-adjusted for higher resolution datasets. Furthermore, we feel that the precise interaction between stochastic sampling and the training objective remains an interesting question for future work.\nSocietal impact. Our advances in sample quality can potentially amplify negative societal effects when used in a large-scale system like DALL\u2022E 2, including types of disinformation or emphasizing sterotypes and harmful biases [34]. The training and sampling of diffusion models needs a lot of electricity; our project consumed \u223c250MWh on an in-house cluster of NVIDIA V100s.", "publication_ref": ["b16", "b35", "b39", "b22", "b8", "b48", "b38", "b41", "b52", "b33"], "figure_ref": [], "table_ref": []}, {"heading": "Appendices A Additional results", "text": "Figure 6 presents generated images for class-conditional ImageNet-64 [8] using the pre-trained ADM model by Dhariwal and Nichol [9]. The original DDIM [47] and iDDPM [37] samplers are compared to ours in both deterministic and stochastic settings (Sections 3 and 4). Figure 7 shows the corresponding results that we obtain by training the model from scratch using our improved training configuration (Section 5).\nThe original samplers and training configurations by Song et al. [49] are compared to ours in Figures 8 and 9 (unconditional CIFAR-10 [29]), Figure 10 (class-conditional CIFAR-10), and Figure 11 (FFHQ [27] and AFHQv2 [7]). For ease of comparison, the same latent codes x 0 are used for each dataset/scenario across different training configurations and ODE choices. Figure 12 shows generated image quality with various NFE when using deterministic sampling.\nTables 3 and 4 summarize the numerical results on deterministic and stochastic sampling methods in various datasets, previously shown as functions of NFE in Figures 2 and 4.", "publication_ref": ["b7", "b8", "b46", "b36", "b48", "b26", "b6"], "figure_ref": ["fig_0", "fig_0", "fig_0", "fig_2"], "table_ref": ["tab_4"]}, {"heading": "B Derivation of formulas B.1 Original ODE / SDE formulation from previous work", "text": "Song et al. [49] define their forward SDE (Eq. 5 in [49]) as\ndx = f (x, t) dt + g(t) d\u03c9 t ,(9)\nwhere \u03c9 t is the standard Wiener process and f (\u2022, t) : R d \u2192 R d and g(\u2022) : R \u2192 R are the drift and diffusion coefficients, respectively, where d is the dimensionality of the dataset. These coefficients are selected differently for the variance preserving (VP) and variance exploding (VE) formulations, and f (\u2022) is always of the form f (x, t) = f (t) x, where f (\u2022) : R \u2192 R. Thus, the SDE can be equivalently written as\ndx = f (t) x dt + g(t) d\u03c9 t . (10\n)\nThe perturbation kernels of this SDE (Eq. 29 in [49]) have the general form\np 0t x(t) | x(0) = N x(t); s(t) x(0), s(t) 2 \u03c3(t) 2 I ,(11)\nwhere N (x; \u00b5, \u03a3) denotes the probability density function of N (\u00b5, \u03a3) evaluated at x,\ns(t) = exp t 0 f (\u03be) d\u03be , and \u03c3(t) = t 0 g(\u03be) 2 s(\u03be) 2 d\u03be.(12)\nThe marginal distribution p t (x) is obtained by integrating the perturbation kernels over x(0):\np t (x) = R d p 0t (x | x 0 ) p data (x 0 ) dx 0 . (13\n)\nSong et al. [49] define the probability flow ODE (Eq. 13 in [49]) so that it obeys this same p t (x):\ndx = f (t) x \u2212 1 2 g(t) 2 \u2207 x log p t (x) dt.(14)\nB.2 Our ODE formulation (Eq. 1 and Eq. 4)\nThe original ODE formulation (Eq. 14) is built around the functions f and g that correspond directly to specific terms that appear in the formula; the properties of the marginal distribution (Eq. 12) can only be derived indirectly based on these functions. However, f and g are of little practical interest in themselves, whereas the marginal distributions are of utmost importance in terms of training the model in the first place, bootstrapping the sampling process, and understanding how the ODE behaves in practice. Given that the idea of the probability flow ODE is to match a particular set of marginal   2. We summarize each curve with two key values: the lowest observed FID for any NFE (\"FID\"), and the lowest NFE whose FID is within 3% of the lowest FID (\"NFE\"). The values marked with \"-\" are identical to the ones above them, because our sampler uses the same \u03c3(t) and s(t) as DDIM.  distributions, it makes sense to treat the marginal distributions as first-class citizens and define the ODE directly based on \u03c3(t) and s(t), eliminating the need for f (t) and g(t).\nLet us start by expressing the marginal distribution of Eq. 13 in closed form:\np t (x) = R d p 0t (x | x 0 ) p data (x 0 ) dx 0 (15) = R d p data (x 0 ) N x; s(t) x 0 , s(t) 2 \u03c3(t) 2 I dx 0 (16) = R d p data (x 0 ) s(t) \u2212d N x/s(t); x 0 , \u03c3(t) 2 I dx 0 (17) = s(t) \u2212d R d p data (x 0 ) N x/s(t); x 0 , \u03c3(t) 2 I dx 0 (18) = s(t) \u2212d p data * N 0, \u03c3(t) 2 I x/s(t) ,(19)\nwhere p a * p b denotes the convolution of probability density functions p a and p b . The expression inside the brackets corresponds to a mollified version of p data obtained by adding i.i.d. Gaussian noise to the samples. Let us denote this distribution by p(x; \u03c3):\np(x; \u03c3) = p data * N 0, \u03c3(t) 2 I and p t (x) = s(t) \u2212d p x/s(t); \u03c3(t) . (20\n)\nWe can now express the probability flow ODE (Eq. 14) using p(x; \u03c3) instead of p t (x):\ndx = f (t)x \u2212 1 2 g(t) 2 \u2207 x log p t (x) dt (21) = f (t)x \u2212 1 2 g(t) 2 \u2207 x log s(t) \u2212d p x/s(t); \u03c3(t) dt (22) = f (t)x \u2212 1 2 g(t) 2 \u2207 x log s(t) \u2212d + \u2207 x log p x/s(t); \u03c3(t) dt (23) = f (t)x \u2212 1 2 g(t) 2 \u2207 x log p x/s(t); \u03c3(t) dt.(24)\nNext, let us rewrite f (t) in terms of s(t) based on Eq. 12:\nexp t 0 f (\u03be) d\u03be = s(t)(25)\nt 0 f (\u03be) d\u03be = log s(t)(26)\nd t 0 f (\u03be) d\u03be dt = d log s(t) /dt (27) f (t) =\u1e61(t)/s(t).(28)\nSimilarly, we can also rewrite g(t) in terms of \u03c3(t):\nt 0 g(\u03be) 2 s(\u03be) 2 d\u03be = \u03c3(t)(29)\nt 0 g(\u03be) 2 s(\u03be) 2 d\u03be = \u03c3(t) 2 (30\n)\nd t 0 g(\u03be) 2 s(\u03be) 2 d\u03be dt = d \u03c3(t) 2 /dt (31\n)\ng(t) 2 /s(t) 2 = 2\u03c3(t) \u03c3(t)(32)\ng(t)/s(t) = 2\u03c3(t) \u03c3(t)(33)\ng(t) = s(t) 2\u03c3(t) \u03c3(t).(34)\nFinally, substitute f (Eq. 28) and g (Eq. 34) into the ODE of Eq. 24:\ndx = [f (t)] x \u2212 1 2 [g(t)] 2 \u2207 x log p x/s(t); \u03c3(t) dt (35\n)\n= \u1e61(t)/s(t) x \u2212 1 2 s(t) 2\u03c3(t) \u03c3(t) 2 \u2207 x log p x/s(t); \u03c3(t) dt (36\n)\n= \u1e61(t)/s(t) x \u2212 1 2 2 s(t) 2\u03c3 (t) \u03c3(t) \u2207 x log p x/s(t); \u03c3(t) dt (37) = \u1e61(t) s(t) x \u2212 s(t) 2\u03c3 (t) \u03c3(t) \u2207 x log p x s(t)\n; \u03c3(t) dt.\nThus we have obtained Eq. 4 in the main paper, and Eq. 1 is recovered by setting s(t) = 1:\ndx = \u2212\u03c3(t) \u03c3(t) \u2207 x log p x; \u03c3(t) dt. (39\n)\nOur formulation (Eq. 4) highlights the fact that every realization of the probability flow ODE is simply a reparameterization of the same canonical ODE; changing \u03c3(t) corresponds to reparameterizing t, whereas changing s(t) corresponds to reparameterizing x.\nB.3 Denoising score matching (Eq. 2 and Eq. 3)\nFor the sake of completeness, we derive the connection between score matching and denoising for a finite dataset. For a more general treatment and further background on the topic, see Hyv\u00e4rinen [22] and Vincent [54].\nLet us assume that our training set consists of a finite number of samples {y 1 , . . . , y Y }. This implies p data (x) is represented by a mixture of Dirac delta distributions:\np data (x) = 1 Y Y i=1 \u03b4 x \u2212 y i ,(40)\nwhich allows us to also express p(x; \u03c3) in closed form based on Eq. 20:\np(x; \u03c3) = p data * N 0, \u03c3(t) 2 I (41) = R d p data (x 0 ) N x; x 0 , \u03c3 2 I dx 0 (42) = R d 1 Y Y i=1 \u03b4 x 0 \u2212 y i N x; x 0 , \u03c3 2 I dx 0 (43) = 1 Y Y i=1 R d N x; x 0 , \u03c3 2 I \u03b4 x 0 \u2212 y i dx 0 (44) = 1 Y Y i=1 N x; y i , \u03c3 2 I . (45\n)\nLet us now consider the denoising score matching loss of Eq. 2. By expanding the expectations, we can rewrite the formula as an integral over the noisy samples x:\nL(D; \u03c3) = E y\u223cpdata E n\u223cN (0,\u03c3 2 I) D(y + n; \u03c3) \u2212 y 2 2 (46) = E y\u223cpdata E x\u223cN (y,\u03c3 2 I) D(x; \u03c3) \u2212 y 2 2 (47) = E y\u223cpdata R d N (x; y, \u03c3 2 I) D(x; \u03c3) \u2212 y 2 2 dx (48) = 1 Y Y i=1 R d N (x; y i , \u03c3 2 I) D(x; \u03c3) \u2212 y i 2 2 dx (49) = R d 1 Y Y i=1 N (x; y i , \u03c3 2 I) D(x; \u03c3) \u2212 y i 2 2 =: L(D;x,\u03c3) dx.(50)\nEq. 50 means that we can minimize L(D; \u03c3) by minimizing L(D; x, \u03c3) independently for each x:\nD(x; \u03c3) = arg min D(x;\u03c3) L(D; x, \u03c3). (51\n)\nThis is a convex optimization problem; its solution is uniquely identified by setting the gradient w.r.t. D(x; \u03c3) to zero:\n0 = \u2207 D(x;\u03c3) L(D; x, \u03c3)(52)\n0 = \u2207 D(x;\u03c3) 1 Y Y i=1 N (x; y i , \u03c3 2 I) D(x; \u03c3) \u2212 y i 2 2 (53) 0 = Y i=1 N (x; y i , \u03c3 2 I) \u2207 D(x;\u03c3) D(x; \u03c3) \u2212 y i 2 2 (54) 0 = Y i=1 N (x; y i , \u03c3 2 I) 2 D(x; \u03c3) \u2212 2 y i (55) 0 = Y i=1 N (x; y i , \u03c3 2 I) D(x; \u03c3) \u2212 Y i=1 N (x; y i , \u03c3 2 I) y i(56)\nD(x; \u03c3) = i N (x; y i , \u03c3 2 I) y i i N (x; y i , \u03c3 2 I) ,(57)\nwhich gives a closed-form solution for the ideal denoiser D(x; \u03c3). Note that Eq. 57 is feasible to compute in practice for small datasets -we show the results for CIFAR-10 in Figure 1b.\nNext, let us consider the score of the distribution p(x; \u03c3) defined in Eq. 45:\n\u2207 x log p(x; \u03c3) = \u2207 x p(x; \u03c3) p(x; \u03c3) (58) = \u2207 x 1 Y i N x; y i , \u03c3 2 I 1 Y i N x; y i , \u03c3 2 I (59\n) = i \u2207 x N x; y i , \u03c3 2 I i N x; y i , \u03c3 2 I . (60\n)\nWe can simplify the numerator of Eq. 60 further:\n\u2207 x N x; y i , \u03c3 2 I = \u2207 x 2\u03c0\u03c3 2 \u2212 d 2 exp x \u2212 y i 2 2 \u22122 \u03c3 2 (61) = 2\u03c0\u03c3 2 \u2212 d 2 \u2207 x exp x \u2212 y i 2 2 \u22122 \u03c3 2 (62) = 2\u03c0\u03c3 2 \u2212 d 2 exp x \u2212 y i 2 2 \u22122 \u03c3 2 \u2207 x x \u2212 y i 2 2 \u22122 \u03c3 2 (63) = N x; y i , \u03c3 2 I \u2207 x x \u2212 y i 2 2 \u22122 \u03c3 2 (64) = N x; y i , \u03c3 2 I y i \u2212 x \u03c3 2 . (65\n)\nLet us substitute the result back to Eq. 60:\n\u2207 x log p(x; \u03c3) = i \u2207 x N x; y i , \u03c3 2 I i N x; y i , \u03c3 2 I (66\n) = i N x; y i , \u03c3 2 I y i \u2212x \u03c3 2 i N x; y i , \u03c3 2 I (67\n) = i N x; y i , \u03c3 2 I y i i N x; y i , \u03c3 2 I \u2212 x \u03c3 2 . (68\n)\nNotice that the fraction in Eq. 68 is identical to Eq. 57. We can thus equivalently write Eq. 68 as\n\u2207 x log p(x; \u03c3) = D(x; \u03c3) \u2212 x /\u03c3 2 ,(69)\nwhich matches Eq. 3 in the main paper.", "publication_ref": ["b48", "b48", "b48", "b48", "b48", "b21", "b53"], "figure_ref": ["fig_2", "fig_0"], "table_ref": []}, {"heading": "B.4 Evaluating our ODE in practice (Algorithm 1)", "text": "Let us consider x to be a scaled version of an original, non-scaled variablex and substitute x = s(t)x into the score term that appears in our scaled ODE (Eq. 4):\n\u2207 x log p x/s(t); \u03c3(t) (70) = \u2207 [s(t)x] log p [s(t)x]/s(t); \u03c3(t) (71) = \u2207 s(t)x log p x; \u03c3(t)(72)\n= 1 s(t) \u2207x log p x; \u03c3(t) . (73\n)\nWe can further rewrite this with respect to D(\u2022) using Eq. 3:\n\u2207 x log p x/s(t); \u03c3(t) = 1 s(t)\u03c3(t) 2 D x; \u03c3(t) \u2212x . (74\n)\nLet us now substitute Eq. 74 into Eq. 4, approximating the ideal denoiser D(\u2022) with our trained model D \u03b8 (\u2022):\ndx = \u1e61(t) x/s(t) \u2212 s(t) 2\u03c3 (t) \u03c3(t) 1 s(t)\u03c3(t) 2 D \u03b8 x; \u03c3(t) \u2212x dt (75) = \u1e61(t) s(t) x \u2212\u03c3 (t)s(t) \u03c3(t) D \u03b8 x; \u03c3(t) \u2212x dt.(76)\nFinally, backsubstitutex = x/s(t):\ndx = \u1e61(t) s(t) x \u2212\u03c3 (t)s(t) \u03c3(t) D \u03b8 [x]; \u03c3(t) \u2212 [x] dt (77) = \u1e61(t) s(t) x \u2212\u03c3 (t)s(t) \u03c3(t) D \u03b8 [x/s(t)]; \u03c3(t) \u2212 [x/s(t)] dt (78) = \u1e61(t) s(t) x \u2212\u03c3 (t)s(t) \u03c3(t) D \u03b8 x/s(t); \u03c3(t) +\u03c3 (t) \u03c3(t) x dt (79) = \u03c3(t) \u03c3(t) +\u1e61 (t) s(t) x \u2212\u03c3 (t)s(t) \u03c3(t) D \u03b8 x/s(t); \u03c3(t) dt.(80)\nWe can equivalenty write Eq. 80 as\ndx/dt = \u03c3(t) \u03c3(t) +\u1e61 (t) s(t) x \u2212\u03c3 (t)s(t) \u03c3(t) D \u03b8 x s(t) ; \u03c3(t) ,(81)\nmatching lines 4 and 7 of Algorithm 1.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B.5 Our SDE formulation (Eq. 6)", "text": "We derive the SDE of Eq. 6 by the following strategy:\n\u2022 The desired marginal densities p x; \u03c3(t) are convolutions of the data density p data and an isotropic Gaussian density with standard deviation \u03c3(t) (see Eq. 20). Hence, considered as a function of the time t, the density evolves according to a heat diffusion PDE with time-varying diffusivity. As a first step, we find this PDE. \u2022 We then use the Fokker-Planck equation to recover a family of SDEs for which the density evolves according to this PDE. Eq. 6 is obtained from a suitable parametrization of this family.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B.5.1 Generating the marginals by heat diffusion", "text": "We consider the time evolution of a probability density q(x, t). Our goal is to find a PDE whose solution with the initial value q(x, 0) := p data (x) is q(x, t) = p x, \u03c3(t) . That is, the PDE should reproduce the marginals we postulate in Eq. 20.\nThe desired marginals are convolutions of p data with isotropic normal distributions of time-varying standard deviation \u03c3(t), and as such, can be generated by the heat equation with time-varying diffusivity \u03ba(t). The situation is most conveniently analyzed in the Fourier domain, where the marginal densities are simply pointwise products of a Gaussian function and the transformed data density. To find the diffusivity that induces the correct standard deviations, we first write down the heat equation PDE:\n\u2202q(x, t) \u2202t = \u03ba(t)\u2206 x q(x, t). (82\n)\nThe Fourier transformed counterpart of Eq. 82, where the transform is taken along the x-dimension, is given by \u2202q(\u03bd, t) \u2202t = \u2212\u03ba(t)|\u03bd| 2q (\u03bd, t).\nThe target solution q(x, t) and its Fourier transformq(\u03bd, t) are given by Eq. 20:\nq(x, t) = p x; \u03c3(t) = p data (x) * N 0, \u03c3(t) 2 I (84) q(\u03bd, t) =p data (\u03bd) exp \u2212 1 2 |\u03bd| 2 \u03c3(t) 2 . (85\n)\nDifferentiating the target solution along the time axis, we have\n\u2202q(\u03bd, t) \u2202t = \u2212\u03c3(t)\u03c3(t) |\u03bd| 2p data (\u03bd) exp \u2212 1 2 |\u03bd| 2 \u03c3(t) 2 (86) = \u2212\u03c3(t)\u03c3(t) |\u03bd| 2q (\u03bd, t).(87)\nEqs. 83 and 87 share the same left hand side. Equating them allows us to solve for \u03ba(t) that generates the desired evolution:\n\u2212\u03ba(t)|\u03bd| 2q (\u03bd, t) = \u2212\u03c3(t)\u03c3(t) |\u03bd| 2q (\u03bd, t) (88) \u03ba(t) =\u03c3(t)\u03c3(t). (89\n)\nTo summarize, the desired marginal densities corresponding to noise levels \u03c3(t) are generated by the PDE \u2202q(x, t) \u2202t =\u03c3(t)\u03c3(t)\u2206 x q(x, t)\nfrom the initial density q(x, 0) = p data (x).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B.5.2 Derivation of our SDE", "text": "Given an SDE dx = f (x, t) dt + g(x, t) d\u03c9 t ,(91)\nthe Fokker-Planck PDE describes the time evolution of its solution probability density r(x, t) as\n\u2202r(x, t) \u2202t = \u2212\u2207 x \u2022 f (x, t) r(x, t) + 1 2 \u2207 x \u2207 x : D(x, t) r(x, t) ,(92)\nwhere D ij = k g ik g jk is the diffusion tensor. We consider the special case g(x, t) = g(t) I of x-independent white noise addition, whereby the equation simplifies to\n\u2202r(x, t) \u2202t = \u2212\u2207 x \u2022 f (x, t) r(x, t) + 1 2 g(t) 2 \u2206 x r(x, t). (93\n)\nWe are seeking an SDE whose solution density is described by the PDE in Eq. 90. Setting r(x, t) = q(x, t) and equating Eqs. 93 and 90, we find the sufficient condition that the SDE must satisfy\n\u2212\u2207 x \u2022 f (x, t) q(x, t) + 1 2 g(t) 2 \u2206 x q(x, t) =\u03c3(t) \u03c3(t) \u2206 x q(x, t)(94)\n\u2207 x \u2022 f (x, t) q(x, t) = 1 2 g(t) 2 \u2212\u03c3(t) \u03c3(t) \u2206 x q(x, t). (95\n)\nAny choice of functions f (x, t) and g(t) satisfying this equation constitute a sought after SDE. Let us now find a specific family of such solutions. The key idea is given by the identity\n\u2207 x \u2022 \u2207 x = \u2206 x .\nIndeed, if we set f (x, t) q(x, t) = \u03c5(t) \u2207 x q(x, t) for any choice of \u03c5(t), the term \u2206 x q(x, t) appears on both sides and cancels out:\n\u2207 x \u2022 \u03c5(t) \u2207 x q(x, t) = 1 2 g(t) 2 \u2212\u03c3(t) \u03c3(t) \u2206 x q(x, t)(96)\n\u03c5(t) \u2206 x q(x, t) = 1 2 g(t) 2 \u2212\u03c3(t) \u03c3(t) \u2206 x q(x, t)(97)\n\u03c5(t) = 1 2 g(t) 2 \u2212\u03c3(t) \u03c3(t). (98\n)\nThe stated f (x, t) is in fact proportional to the score function, as the formula matches the gradient of the logarithm of the density:\nf (x, t) = \u03c5(t) \u2207 x q(x, t) q(x, t)(99)\n= \u03c5(t) \u2207 x log q(x, t)\n= 1 2 g(t) 2 \u2212\u03c3(t) \u03c3(t) \u2207 x log q(x, t). ((100)\n)101\nSubstituting this back into Eq. 91 and writing p(x; \u03c3(t)) in place of q(x, t), we recover a family of SDEs whose solution densities have the desired marginals with noise levels \u03c3(t) for any choice of g(t):\ndx = 1 2 g(t) 2 \u2212\u03c3(t) \u03c3(t) \u2207 x log p x; \u03c3(t) dt + g(t) d\u03c9 t .(102)\nThe free parameter g(t) effectively specifies the rate of noise replacement at any given time instance.\nThe special case choice of g(t) = 0 corresponds to the probability flow ODE. The parametrization by g(t) is not particularly intuitive, however. To obtain a more interpretable parametrization, we set g(t) = 2 \u03b2(t) \u03c3(t), which yields the (forward) SDE of Eq. 6 in the main paper:\ndx + = \u2212\u03c3(t)\u03c3(t)\u2207 x log p x; \u03c3(t) dt + \u03b2(t)\u03c3(t) 2 \u2207 x log p x; \u03c3(t) dt + 2\u03b2(t)\u03c3(t) d\u03c9 t . (103\n)\nThe noise replacement is now proportional to the standard deviation \u03c3(t) of the noise, with the proportionality factor \u03b2(t). Indeed, expanding the score function in the middle term according to Eq. 3 yields \u03b2(t) D x; \u03c3(t) \u2212 x dt, which changes x proportionally to the negative noise component; the stochastic term injects new noise at the same rate. Intuitively, scaling the magnitude of Langevin exploration according to the current noise standard deviation is a reasonable baseline, as the data manifold is effectively \"spread out\" by this amount due to the blurring of the density.\nThe reverse SDE used in denoising diffusion is simply obtained by applying the time reversal formula of Anderson [1] (as stated in Eq. 6 of Song et al. [49]) on Eq. 103; the entire effect of the reversal is a change of sign in the middle term.\nThe scaled generalization of the SDE can be derived using a similar approach as with the ODE previously. As such, the derivation is omitted here.", "publication_ref": ["b0", "b48"], "figure_ref": [], "table_ref": []}, {"heading": "B.6 Our preconditioning and training (Eq. 8)", "text": "Following Eq. 2, the denoising score matching loss for a given denoiser D \u03b8 on a given noise level \u03c3 is given by\nL(D \u03b8 ; \u03c3) = E y\u223cpdata E n\u223cN (0,\u03c3 2 I) D \u03b8 (y + n; \u03c3) \u2212 y 2 2 . (104\n)\nWe obtain overall training loss by taking a weighted expectation of L(D \u03b8 ; \u03c3) over the noise levels:\nL(D \u03b8 ) = E \u03c3\u223cptrain \u03bb(\u03c3) L(D \u03b8 ; \u03c3) (105) = E \u03c3\u223cptrain \u03bb(\u03c3) E y\u223cpdata E n\u223cN (0,\u03c3 2 I) D \u03b8 (y + n; \u03c3) \u2212 y 2 2 (106) = E \u03c3\u223cptrain E y\u223cpdata E n\u223cN (0,\u03c3 2 I) \u03bb(\u03c3) D \u03b8 (y + n; \u03c3) \u2212 y 2 2 (107) = E \u03c3,y,n \u03bb(\u03c3) D \u03b8 (y + n; \u03c3) \u2212 y 2 2 ,(108)\nwhere the noise levels are distributed according to \u03c3 \u223c p train and weighted by \u03bb(\u03c3).\nUsing our definition of D \u03b8 (\u2022) from Eq. 7, we can further rewrite L(D \u03b8 ) as\nE \u03c3,y,n \u03bb(\u03c3) c skip (\u03c3)(y+n) + c out (\u03c3)F \u03b8 c in (\u03c3)(y+n); c noise (\u03c3) \u2212 y 2 2 (109) = E \u03c3,y,n \u03bb(\u03c3) c out (\u03c3)F \u03b8 c in (\u03c3)(y+n); c noise (\u03c3) \u2212 y \u2212 c skip (\u03c3)(y + n) 2 2 (110) = E \u03c3,y,n \u03bb(\u03c3)c out (\u03c3) 2 F \u03b8 c in (\u03c3)(y+n); c noise (\u03c3) \u2212 1 cout(\u03c3) y \u2212 c skip (\u03c3)(y+n) 2 2 (111) = E \u03c3,y,n w(\u03c3) F \u03b8 c in (\u03c3)(y+n); c noise (\u03c3) \u2212 F target (y, n; \u03c3) 2 2 ,(112)\nwhich matches Eq. 8 and corresponds to traditional supervised training of F \u03b8 using standard L 2 loss with effective weight w(\u2022) and target F target (\u2022) given by w(\u03c3) = \u03bb(\u03c3) c out (\u03c3) 2 and F target (y, n; \u03c3)\n= 1 cout(\u03c3) y \u2212 c skip (\u03c3)(y + n) ,(113)\nWe can now derive formulas for c in (\u03c3), c out (\u03c3), c skip (\u03c3), and \u03bb(\u03c3) from first principles, shown in the \"Ours\" column of Table 1.\nFirst, we require the training inputs of F \u03b8 (\u2022) to have unit variance:\nVar y,n c in (\u03c3)(y + n) = 1 (114) c in (\u03c3) 2 Var y,n y + n = 1 (115) c in (\u03c3) 2 \u03c3 2 data + \u03c3 2 = 1 (116) c in (\u03c3) = 1 \u03c3 2 + \u03c3 2 data . (117\n)\nSecond, we require the effective training target F target to have unit variance:\nVar y,n F target (y, n; \u03c3) = 1 (118)\nVar y,n 1 cout(\u03c3) y \u2212 c skip (\u03c3)(y + n) = 1 (119) 1 cout(\u03c3) 2 Var y,n y \u2212 c skip (\u03c3)(y + n) = 1 (120) c out (\u03c3) 2 = Var y,n y \u2212 c skip (\u03c3)(y + n) (121) c out (\u03c3) 2 = Var y,n 1 \u2212 c skip (\u03c3) y + c skip (\u03c3) n (122) c out (\u03c3) 2 = 1 \u2212 c skip (\u03c3) 2 \u03c3 2 data + c skip (\u03c3) 2 \u03c3 2 . (123\n)\nThird, we select c skip (\u03c3) to minimize c out (\u03c3), so that the errors of F \u03b8 are amplified as little as possible:\nc skip (\u03c3) = arg min cskip(\u03c3) c out (\u03c3). (124\n)\nSince c out (\u03c3) \u2265 0, we can equivalently write\nc skip (\u03c3) = arg min cskip(\u03c3) c out (\u03c3) 2 . (125\n)\nThis is a convex optimization problem; its solution is uniquely identified by setting the derivative w.r.t. c skip (\u03c3) to zero:\n0 = d c out (\u03c3) 2 /dc skip (\u03c3) (126) 0 = d 1 \u2212 c skip (\u03c3) 2 \u03c3 2 data + c skip (\u03c3) 2 \u03c3 2 /dc skip (\u03c3)(127)\n0 = \u03c3 2 data d 1 \u2212 c skip (\u03c3) 2 /dc skip (\u03c3) + \u03c3 2 d c skip (\u03c3) 2 /dc skip (\u03c3)(128)\n0 = \u03c3 2 data 2 c skip (\u03c3) \u2212 2 + \u03c3 2 2 c skip (\u03c3)(129)\n0 = \u03c3 2 + \u03c3 2 data c skip (\u03c3) \u2212 \u03c3 2 data (130\n)\nc skip (\u03c3) = \u03c3 2 data / \u03c3 2 + \u03c3 2 data . (131\n)\nWe can now substitute Eq. 131 into Eq. 123 to complete the formula for c out (\u03c3):\nc out (\u03c3) 2 = 1 \u2212 c skip (\u03c3) 2 \u03c3 2 data + c skip (\u03c3) 2 \u03c3 2 (132) c out (\u03c3) 2 = 1 \u2212 \u03c3 2 data \u03c3 2 + \u03c3 2 data 2 \u03c3 2 data + \u03c3 2 data \u03c3 2 + \u03c3 2 data 2 \u03c3 2 (133) c out (\u03c3) 2 = \u03c3 2 \u03c3 data \u03c3 2 + \u03c3 2 data 2 + \u03c3 2 data \u03c3 \u03c3 2 + \u03c3 2 data 2 (134) c out (\u03c3) 2 = \u03c3 2 \u03c3 data 2 + \u03c3 2 data \u03c3 2 \u03c3 2 + \u03c3 2 data 2 (135) c out (\u03c3) 2 = (\u03c3 \u2022 \u03c3 data ) 2 \u03c3 2 + \u03c3 2 data \u03c3 2 + \u03c3 2 data 2 (136) c out (\u03c3) 2 = (\u03c3 \u2022 \u03c3 data ) 2 \u03c3 2 + \u03c3 2 data (137\n)\nc out (\u03c3) = \u03c3 \u2022 \u03c3 data \u03c3 2 + \u03c3 2 data . (138\n)\nFourth, we require the effective weight w(\u03c3) to be uniform across noise levels:\nw(\u03c3) = 1 (139) \u03bb(\u03c3) c out (\u03c3) 2 = 1 (140) \u03bb(\u03c3) = 1/c out (\u03c3) 2\n(141)\n\u03bb(\u03c3) = 1 \u03c3 \u2022 \u03c3 data \u03c3 2 + \u03c3 2 data 2 (142) \u03bb(\u03c3) = 1 (\u03c3 \u2022 \u03c3 data ) 2 \u03c3 2 + \u03c3 2 data (143\n)\n\u03bb(\u03c3) = \u03c3 2 + \u03c3 2 data /(\u03c3 \u2022 \u03c3 data ) 2 . (144\n)\nWe follow previous work and initialize the output layer weights to zero. Consequently, upon initialization F \u03b8 (\u2022) = 0 and the expected value of the loss at each noise level is 1. This can be seen by substituting the choices of \u03bb(\u03c3) and c skip (\u03c3) into Eq. 109, considered at a fixed \u03c3:\nE y,n \u03bb(\u03c3) c skip (\u03c3)(y+n) + c out (\u03c3)F \u03b8 c in (\u03c3)(y+n); c noise (\u03c3) \u2212 y 2 2 (145) = E y,n \u03c3 2 + \u03c3 2 data (\u03c3 \u2022 \u03c3 data ) 2 \u03c3 2 data \u03c3 2 + \u03c3 2 data (y+n) \u2212 y 2 2 (146) = E y,n \u03c3 2 + \u03c3 2 data (\u03c3 \u2022 \u03c3 data ) 2 \u03c3 2 data n \u2212 \u03c3 2 y \u03c3 2 + \u03c3 2 data 2 2 (147) = E y,n 1 \u03c3 2 + \u03c3 2 data \u03c3 data \u03c3 n \u2212 \u03c3 \u03c3 data y 2 2 (148) = 1 \u03c3 2 + \u03c3 2 data E y,n \u03c3 2 data \u03c3 2 n, n + \u03c3 2 \u03c3 2 data y, y \u2212 2 y, n(149)\n= 1 \u03c3 2 + \u03c3 2 data \u03c3 2 data \u03c3 2 Var(n) =\u03c3 2 + \u03c3 2 \u03c3 2 data Var(y) =\u03c3 2 data \u22122 Cov(y, n) =0 (150) = 1 (151)", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C Reframing previous methods in our framework", "text": "In this section, we derive the formulas shown in Table 1 for previous methods, discuss the corresponding original samplers and pre-trained models, and detail the practical considerations associated with using them in our framework.\nIn practice, the original implementations of these methods differ considerably in terms of the definitions of model inputs and outputs, dynamic range of image data, scaling of x, and interpretation of \u03c3. We eliminate this variation by standardizing on a unified setup where the model always matches our definition of F \u03b8 , image data is always represented in the continuous range [\u22121, 1], and the details of x and \u03c3 are always in agreement with Eq. 4.\nWe minimize the accumulation of floating point round-off errors by always executing Algorithms 1 and 2 at double precision (float64). However, we still execute the network F \u03b8 (\u2022) at single precision (float32) to minimize runtime and remain faithful to previous work in terms of network architecture.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C.1 Variance preserving formulation C.1.1 VP sampling", "text": "Song et al. [49] define the VP SDE (Eq. 32 in [49]) as\ndx = \u2212 1 2 \u03b2 min + t \u03b2 max \u2212 \u03b2 min x dt + \u03b2 min + t \u03b2 max \u2212 \u03b2 min d\u03c9 t ,(152)\nwhich matches Eq. 10 with the following choices for f and g:\nf (t) = \u2212 1 2 \u03b2(t), g(t) = \u03b2(t), and \u03b2(t) = \u03b2 max \u2212 \u03b2 min t + \u03b2 min . (153\n)\nLet \u03b1(t) denote the integral of \u03b2(t):\n\u03b1(t) = t 0 \u03b2(\u03be) d\u03be (154\n) = t 0 \u03b2 max \u2212 \u03b2 min \u03be + \u03b2 min d\u03be (155) = 1 2 \u03b2 max \u2212 \u03b2 min t 2 + \u03b2 min t (156) = 1 2 \u03b2 d t 2 + \u03b2 min t,(157)\nwhere \u03b2 d = \u03b2 max \u2212 \u03b2 min . We can now obtain the formula for \u03c3(t) by substituting Eq. 153 into Eq. 12:\n\u03c3(t) = t 0 g(\u03be) 2 s(\u03be) 2 d\u03be (158\n)\n= t 0 \u03b2(\u03be) 2 1/ \u221a e \u03b1(\u03be) 2 d\u03be (159\n)\n= t 0 \u03b2(\u03be) 1/e \u03b1(\u03be) d\u03be (160\n)\n= t 0\u03b1 (\u03be) e \u03b1(\u03be) d\u03be (161) = e \u03b1(t) \u2212 e \u03b1(0) (162) = e 1 2 \u03b2dt 2 +\u03b2mint \u2212 1,(163)\nwhich matches the \"Schedule\" row of Table 1. Similarly for s(t):\ns(t) = exp t 0 f (\u03be) d\u03be (164) = exp t 0 \u2212 1 2 \u03b2(\u03be) d\u03be (165) = exp \u2212 1 2 t 0 \u03b2(\u03be) d\u03be (166) = exp \u2212 1 2 \u03b1(t) (167) = 1/ e \u03b1(t) (168) = 1/ e 1 2 \u03b2dt 2 +\u03b2mint ,(169)\nwhich matches the \"Scaling\" row of Table 1. We can equivalently write Eq. 169 in a slightly simpler form by utilizing Eq. 163:\ns(t) = 1/ \u03c3(t) 2 + 1.(170)\nSong et al. [49] choose to distribute the sampling time steps {t 0 , . . . , t N \u22121 } at uniform intervals within [ s , 1]. This corresponds to setting\nt i<N = 1 + i N \u22121 ( s \u2212 1),(171)\nwhich matches the \"Time steps\" row of Table 1.\nFinally, Song et al. [49] set \u03b2 min = 0.1, \u03b2 max = 20, and s = 10 \u22123 (Appendix C in [49]), and choose to represent images in the range [\u22121, 1]. These choices are readily compatible with our formulation and are reflected by the \"Parameters\" section of Table 1.", "publication_ref": ["b48", "b48", "b48", "b48", "b48"], "figure_ref": [], "table_ref": []}, {"heading": "C.1.2 VP preconditioning", "text": "In the VP case, Song et al. [49] approximate the score of p t (x) of Eq. 13 as 1\n\u2207 x log p t (x) \u2248 \u2212 1 \u03c3(t) F \u03b8 x; (M \u22121)t score(x;F \u03b8 ,t) ,(172)\nwhere M = 1000, F \u03b8 denotes the network, and\u03c3(t) corresponds to the standard deviation of the perturbation kernel of Eq. 11.\nLet us expand the definitions of p t (x) and\u03c3(t) from Eqs. 20 and 11, respectively, and substitute x = s(t)x to obtain the corresponding formula with respect to the non-scaled variablex:\n\u2207 x log p x/s(t); \u03c3(t) \u2248 \u2212 1 [s(t)\u03c3(t)] F \u03b8 x; (M \u22121)t (173\n)\n\u2207 [s(t)x] log p [s(t)x]/s(t); \u03c3(t) \u2248 \u2212 1 s(t)\u03c3(t) F \u03b8 [s(t)x]; (M \u22121)t (174\n) 1 s(t) \u2207x log p x; \u03c3(t) \u2248 \u2212 1 s(t)\u03c3(t) F \u03b8 s(t)x; (M \u22121)t (175\n)\n\u2207x log p x; \u03c3(t) \u2248 \u2212 1 \u03c3(t) F \u03b8 s(t)x; (M \u22121)t . (176\n)\nWe can now replace the left-hand side with Eq. 3 and expand the definition of s(t) from Eq. 170:\nD x; \u03c3(t) \u2212x /\u03c3(t) 2 \u2248 \u2212 1 \u03c3(t) F \u03b8 s(t)x; (M \u22121)t (177) D x; \u03c3(t) \u2248x \u2212 \u03c3(t) F \u03b8 s(t)x; (M \u22121)t (178) D x; \u03c3(t) \u2248x \u2212 \u03c3(t) F \u03b8 1 \u221a \u03c3(t) 2 +1 x; (M \u22121)t ,(179)\nwhich can be further expressed in terms of \u03c3 by replacing \u03c3(t) \u2192 \u03c3 and t \u2192 \u03c3 \u22121 (\u03c3):\nD(x; \u03c3) \u2248x \u2212 \u03c3 F \u03b8 1 \u221a \u03c3 2 +1x ; (M \u22121) \u03c3 \u22121 (\u03c3) . (180\n)\nWe adopt the right-hand side of Eq. 180 as the definition of D \u03b8 , obtaining\nD \u03b8 (x; \u03c3) = 1 \u2022 cskipx \u2212 \u03c3 cout \u2022 F \u03b8 1 \u221a \u03c3 2 +1 cin \u2022x; (M \u22121) \u03c3 \u22121 (\u03c3) cnoise , (181\n)\nwhere c skip , c out , c in , and c noise match the \"Network and preconditioning\" section of Table 1.", "publication_ref": ["b48"], "figure_ref": [], "table_ref": []}, {"heading": "C.1.3 VP training", "text": "Song et al. [49] define their training loss as 2\nE t\u223cU ( t ,1),y\u223cpdata,n\u223cN (0,I) \u03c3(t) score s(t) y +\u03c3(t)n; F \u03b8 , t +n 2 2 , (182\n)\nwhere the definition of score(\u2022) is the same as in Eq. 172. Let us simplify the formula by substitutin\u1e21 \u03c3(t) = s(t)\u03c3(t) andn = n/\u03c3(t), where n \u223c N (0, \u03c3(t) 2 I):\nE t,y,n s(t)\u03c3(t) score s(t) y + [s(t)\u03c3(t)]n; F \u03b8 , t +n 2 2 (183) = E t,y,n s(t)\u03c3(t) score s(t) y + s(t)\u03c3(t) [n/\u03c3(t)]; F \u03b8 , t + [n/\u03c3(t)] 2 2 (184) = E t,y,n s(t)\u03c3(t) score s(t) (y + n); F \u03b8 , t + n/\u03c3(t) 2 2 . (185\n)\nWe can express score(\u2022) in terms of D \u03b8 (\u2022) by combining Eqs. 172, 170, and 74: Substituting this back into Eq. 185 gives\nscore s(t) x; F \u03b8 , t = 1 s(t)\u03c3(t) 2 D \u03b8 x; \u03c3(t) \u2212 x . (186\n)\nE t,y,n s(t)\u03c3(t) 1 s(t)\u03c3(t) 2 D \u03b8 y + n; \u03c3(t) \u2212 (y + n) + 1 \u03c3(t) n 2 2 (187) = E t,y,n 1 \u03c3(t) D \u03b8 y + n; \u03c3(t) \u2212 (y + n) + 1 \u03c3(t) n 2 2 (188) = E t,y,n 1 \u03c3(t) 2 D \u03b8 y + n; \u03c3(t) \u2212 y 2 2 . (189\n)\nWe can further express this in terms of \u03c3 by replacing \u03c3(t) \u2192 \u03c3 and t \u2192 \u03c3 \u22121 (\u03c3):\nE \u03c3 \u22121 (\u03c3)\u223cU ( t ,1) ptrain E y,n 1 \u03c3 2 \u03bb D \u03b8 y + n; \u03c3 \u2212 y 2 2 , (190\n)\nwhich matches Eq. 108 with the choices for p train and \u03bb shown in the \"Training\" section of Table 1.", "publication_ref": ["b48"], "figure_ref": [], "table_ref": []}, {"heading": "C.1.4 VP practical considerations", "text": "The pre-trained VP model that we use on CIFAR-10 corresponds to the \"DDPM++ cont. (VP)\" checkpoint 3 provided by Song et al. [49]. It contains a total of 62 million trainable parameters and supports a continuous range of noise levels \u03c3 \u2208 \u03c3( t ), \u03c3(1) \u2248 [0.001, 152], i.e., wider than our preferred sampling range [0.002, 80]. We import the model directly as F \u03b8 (\u2022) and run Algorithms 1 and 2 using the definitions in Table 1.\nIn Figure 2a, the differences between the original sampler (blue) and our reimplementation (orange) are explained by oversights in the implementation of Song et al. [49], also noted by Jolicoeur-Martineau et al. [24] (Appendix D in [24]). First, the original sampler employs an incorrect multiplier 4 in the Euler step: it multiplies dx/dt by \u22121/N instead of ( s \u2212 1)/(N \u2212 1). Second, it either overshoots or undershoots on the last step by going from t N \u22121 = s to t N = s \u2212 1/N , where t N < 0 when N < 1000. In practice, this means that the generated images contain noticeable noise that becomes quite severe with, e.g., N = 128. Our formulation avoids these issues, because the step sizes in Algorithm 1 are computed consistently from {t i } and t N = 0.", "publication_ref": ["b2", "b48", "b48", "b23", "b23", "b3"], "figure_ref": ["fig_2"], "table_ref": []}, {"heading": "C.2 Variance exploding formulation C.2.1 VE sampling in theory", "text": "Song et al. [49] define the VE SDE (Eq. 30 in [49]) as\ndx = \u03c3 min \u03c3 max \u03c3 min t 2 log \u03c3 max \u03c3 min d\u03c9 t ,(191)\nwhich matches Eq. 10 with\nf (t) = 0, g(t) = \u03c3 min 2 log \u03c3 d \u03c3 t d , and \u03c3 d = \u03c3 max /\u03c3 min . (192\n)\nThe VE formulation does not employ scaling, which can be easily seen from Eq. 12:\ns(t) = exp t 0 f (\u03be) d\u03be = exp t 0 0 d\u03be = exp(0) = 1.(193)\nSubstituting Eq. 192 into Eq. 12 suggests the following form for \u03c3(t):\n\u03c3(t) = t 0 g(\u03be) 2 s(\u03be) 2 d\u03be (194) = t 0 \u03c3 min \u221a 2 log \u03c3 d \u03c3 \u03be d 2 1 2 d\u03be (195\n)\n= t 0 \u03c3 2 min 2 log \u03c3 d \u03c3 2\u03be d d\u03be (196) = \u03c3 min t 0 log \u03c3 2 d \u03c3 2 d \u03be d\u03be (197) = \u03c3 min \u03c3 2 d t \u2212 \u03c3 2 d 0 (198) = \u03c3 min \u03c3 2t d \u2212 1.(199)\nEq. 199 is consistent with the perturbation kernel reported by Song et al. (Eq. 29 in [49]). However, we note that this does not fulfill their intended definition of \u03c3(t) = \u03c3 min \u03c3max \u03c3min t (Appendix C in [49]).", "publication_ref": ["b48", "b48", "b48", "b48"], "figure_ref": [], "table_ref": []}, {"heading": "C.2.2 VE sampling in practice", "text": "The original implementation 5 of Song et al. [49] uses reverse diffusion predictor 6 to integrate discretized reverse probability flow 7 of discretized VE SDE 8 . Put together, these yield the following update rule for x i+1 :\nx i+1 = x i + 1 2 \u03c3 2 i \u2212\u03c3 2 i+1 \u2207 x logp i (x),(200)\nwhere\u03c3 i<N = \u03c3 min \u03c3 max \u03c3 min 1\u2212i/(N \u22121)\nand\u03c3 N = 0.\n(201) Interestingly, Eq. 200 is identical to the Euler iteration of our ODE with the following choices:\ns(t) = 1, \u03c3(t) = \u221a t, and t i =\u03c3 2 i . (202\n)\nThese formulas match the \"Sampling\" section of Table 1, and their correctness can be verified by substituting them into line 5 of Algorithm 1:\nx i+1 = x i + (t i+1 \u2212 t i ) d i(203)\n= x i + (t i+1 \u2212 t i ) \u03c3(t) \u03c3(t) +\u1e61 (t) s(t) x \u2212\u03c3 (t)s(t) \u03c3(t) D x s(t) ; \u03c3(t)(204)\n= x i + (t i+1 \u2212 t i ) \u03c3(t) \u03c3(t) x \u2212\u03c3 (t) \u03c3(t) D x; \u03c3(t)(205)\n= x i \u2212 (t i+1 \u2212 t i )\u03c3(t) \u03c3(t) D x; \u03c3(t) \u2212 x \u03c3(t) 2 (206) = x i \u2212 (t i+1 \u2212 t i )\u03c3(t) \u03c3(t) \u2207 x log p x; \u03c3(t)(207)\n= x i \u2212 (t i+1 \u2212 t i ) 1 2 \u221a t \u221a t \u2207 x log p x; \u03c3(t)(208)\n= x i + 1 2 (t i \u2212 t i+1 ) \u2207 x log p x; \u03c3(t)(209)\n= x i + 1 2 \u03c3 2 i \u2212\u03c3 2 i+1 \u2207 x log p x; \u03c3(t) ,(210)\nwhich is made identical to Eq. 200 by the choicep i (x) = p x; \u03c3(t i ) .\nFinally, Song et al. [49] set \u03c3 min = 0.01 and \u03c3 max = 50 for CIFAR-10 (Appendix C in [49]), and choose to represent their images in the range [0, 1] to match previous SMLD models. Since our standardized range [\u22121, 1] is twice as large, we must multiply \u03c3 min and \u03c3 max by 2\u00d7 to compensate. The \"Parameters\" section of Table 1 reflects these adjusted values.", "publication_ref": ["b48", "b5", "b6", "b7", "b48", "b48"], "figure_ref": [], "table_ref": []}, {"heading": "C.2.3 VE preconditioning", "text": "In the VE case, Song et al. [49] approximate the score of p t (x) of Eq. 13 directly as 9 \u2207 x log p t (x) \u2248F \u03b8 x; \u03c3(t) ,\nwhere the networkF \u03b8 is designed to include additional pre-10 and 11 postprocessing 12 steps:\nF \u03b8 x; \u03c3 = 1 \u03c3 F \u03b8 2x\u22121; log(\u03c3) . (212\n)\nFor consistency, we handle the pre-and postprocessing using {c skip , c out , c in , c noise } as opposed to baking them into the network itself.\nWe cannot use Eqs. 211 and 212 directly in our framework, however, because they assume that the images are represented in range\n[0, 1]. In order to use [\u22121, 1] instead, we replace p t (x) \u2192 p t (2x\u22121), x \u2192 1 2 x + 1 2 and \u03c3 \u2192 1 2 \u03c3: \u2207 [ 1 C.2.", "publication_ref": ["b48"], "figure_ref": [], "table_ref": []}, {"heading": "VE practical considerations", "text": "The pre-trained VE model that we use on CIFAR-10 corresponds to the \"NCSN++ cont. (VE)\" checkpoint 14 provided by Song et al. [49]. It contains a total of 63 million trainable parameters and supports a continuous range of noise levels \u03c3 \u2208 \u03c3( t ), \u03c3(1) \u2248 [0.02, 100]. This is narrower than our preferred sampling range [0.002, 80], so we set \u03c3 min = 0.02 in all related experiments. Note that this limitation is lifted by our training improvements in config E, so we revert back to using \u03c3 min = 0.002 with configs E and F in Table 2. When importing the model, we remove the pre-and postprocessing steps shown in Eq. 212 to stay consistent with the definition of F \u03b8 (\u2022) in Eq. 217. With these changes, we can run Algorithms 1 and 2 using the definitions in Table 1.\nIn Figure 2b, the differences between the original sampler (blue) and our reimplementation (orange) are explained by floating point round-off errors that the original implementation suffers from at high step counts. Our results are more accurate in these cases because we represent x i at double precision in Algorithm 1.", "publication_ref": ["b13", "b48"], "figure_ref": ["fig_2"], "table_ref": ["tab_1"]}, {"heading": "C.3 Improved DDPM and DDIM C.3.1 DDIM ODE formulation", "text": "Song et al. [47] make the observation that their deterministic DDIM sampler can be expressed as Euler integration of the following ODE (Eq. 14 in [47]):\ndx(t) = (t) \u03b8 x(t) \u03c3(t) 2 + 1 d\u03c3(t),(223)\nwhere x(t) is a scaled version of the iterate that appears in their discrete update formula (Eq. 10 in [47]) and \u03b8 is a model trained to predict the normalized noise vector, i.e.,\n\u03b8 x(t)/ \u03c3(t) 2 + 1 \u2248 n(t)/\u03c3(t) for x(t) = y(t) + n(t).(t)\nIn our formulation, D \u03b8 is trained to approximate the clean signal, i.e., D \u03b8 x(t); \u03c3(t) \u2248 y, so we can reinterpret \u03b8 in terms of D \u03b8 as follows:\nn(t) = x(t) \u2212 y(t) (224) n(t)/\u03c3(t) = x(t) \u2212 y(t) /\u03c3(t)(225)\n(t) \u03b8 x(t)/ \u03c3(t) 2 + 1 = x(t) \u2212 D \u03b8 x(t); \u03c3(t) /\u03c3(t).(226)\nAssuming ideal (\u2022) and D(\u2022) in L 2 sense, we can further simplify the above formula using Eq. 3:\n(t) x(t)/ \u03c3(t) 2 + 1 = x(t) \u2212 D x(t); \u03c3(t) /\u03c3(t)(227)\n= \u2212\u03c3(t) D x(t); \u03c3(t) \u2212 x(t) /\u03c3(t) 2 (228) = \u2212\u03c3(t) \u2207 x(t) log p x(t); \u03c3(t) .(229)\nSubstituting Eq. 229 back into Eq. 223 gives\ndx(t) = \u2212\u03c3(t) \u2207 x(t) log p x(t); \u03c3(t) d\u03c3(t),(230)\nwhich we can further simplify by setting \u03c3(t) = t:\ndx = \u2212t \u2207 x log p x; \u03c3(t) dt.(231)\nThis matches our Eq. 4 with s(t) = 1 and \u03c3(t) = t, reflected by the \"Sampling\" section of Table 1.", "publication_ref": ["b46", "b46", "b46"], "figure_ref": [], "table_ref": []}, {"heading": "C.3.2 iDDPM time step discretization", "text": "The original DDPM formulation of Ho et al. [16] defines the forward process (Eq. 2 in [16]) as a Markov chain that gradually adds Gaussian noise tox 0 \u223c p data according to a discrete variance schedule {\u03b2 1 , . . . , \u03b2 T }:\nq(x t |x t\u22121 ) = N x t ; 1 \u2212 \u03b2 txt\u22121 , \u03b2 t I . (232\n)\nThe corresponding transition probability fromx 0 tox t (Eq. 4 in [16]) is given by\nq(x t |x 0 ) = N x t ; \u221a\u1fb1 tx0 , (1 \u2212\u1fb1 t ) I , where\u1fb1 t = t s=1 (1 \u2212 \u03b2 s ).(233)\nHo et al. [16] define {\u03b2 t } based on a linear schedule and then calculate the corresponding {\u1fb1 t } from Eq. 233. Alternatively, one can also define {\u1fb1 t } first and then solve for {\u03b2 t }:\n\u03b1 t = t s=1 (1 \u2212 \u03b2 s )(234)\n\u03b1 t =\u1fb1 t\u22121 (1 \u2212 \u03b2 t )(235)\n\u03b2 t = 1 \u2212\u1fb1 t \u03b1 t\u22121 . (236\n)\nThe improved DDPM formulation of Nichol and Dhariwal [37] employs a cosine schedule for\u1fb1 t (Eq. 17 in [37]), defined as\n\u03b1 t = f (t) f (0) , where f (t) = cos 2 t/T + s 1 + s \u2022 \u03c0 2 ,(237)\nwhere s = 0.008. In their implementation 15 , however, Nichol et al. leave out the division by f (0) and simply define 16\u1fb1\nt = cos 2 t/T + s 1 + s \u2022 \u03c0 2 . (238\n)\nTo prevent singularities near t = T , they also clamp \u03b2 t to 0.999. We can express the clamping in terms of\u1fb1 t by utilizing Eq. 233 and Eq. 234:\n\u03b1 t = t s=1 1 \u2212 [\u03b2 s ](239)\n= t s=1 1 \u2212 min [\u03b2 s ], 0.999) (240) = t s=1 1 \u2212 min 1 \u2212\u1fb1 s \u03b1 s\u22121 , 0.999 (241) = t s=1 max \u1fb1 s \u03b1 s\u22121 , 0.001 .(242)\nLet us now reinterpret the above formulas in our unified framework. Recall from Table 1 that we denote the original iDDPM sampling steps by {u j } in the order of descending noise level \u03c3(u j ), where j \u2208 {0, . . . , M }. To harmonize the notation of Eq. 233, Eq. 238, and Eq. 239, we thus have to replace T \u2212\u2192 M and t \u2212\u2192 M \u2212 j:\nq(x j |x M ) = N x j ; \u1fb1 jx M , (1 \u2212\u1fb1 j ) I ,(243)\n\u03b1 j = cos 2 (M \u2212 j)/M + C 2 1 + C 2 \u2022 \u03c0 2 , and(244)\n\u03b1 j = j s=M \u22121 max \u1fb1 j \u03b1 j+1 , C 1 =\u1fb1 j+1 max \u1fb1 j \u03b1 j+1 , C 1 ,(245)\nwhere the constants are C 1 = 0.001 and C 2 = 0.008.\n15 https://github.com/openai/improved-diffusion\nWe can further simplify Eq. 244:\n\u03b1 j = cos 2 (M \u2212 j)/M + C 2 1 + C 2 \u2022 \u03c0 2 (246) = cos 2 \u03c0 2 (1 + C 2 ) \u2212 j/M 1 + C 2 (247) = cos 2 \u03c0 2 \u2212 \u03c0 2 j M (1 + C 2 ) (248) = sin 2 \u03c0 2 j M (1 + C 2 ) ,(249)\ngiving the formula shown in the \"Parameters\" section of Table 1.\nTo harmonize the definitions of x andx, we must match the perturbation kernel of Eq. 11 with the transition probability of Eq. 243 for each time step t = u j :\np 0t x(u j ) | x(0) = q(x j |x M )(250)\nN x(u j ); s(t) x(0), s(u j ) 2 \u03c3(u j ) 2 I = N x j ; \u1fb1 jx M , 1 \u2212\u1fb1 j I . (251\n)\nSubstituting s(t) = 1 and \u03c3(t) = t from Appendix C.3.1, as well asx M = x(0):\nN x(u j ); x(0), u 2 j I = N x j ; \u1fb1 j x(0), 1 \u2212\u1fb1 j I . (252\n)\nWe can match the means of these two distributions by definingx j = \u1fb1 j x(u j ):\nN x(u j ); x(0), u 2 j I = N \u1fb1 j x(u j ); \u1fb1 j x(0), 1 \u2212\u1fb1 j I (253) = N x(u j ); x(0), 1 \u2212\u1fb1 j \u03b1 j I . (254\n)\nMatching the variances and solving for\u1fb1 j gives\nu 2 j = (1 \u2212\u1fb1 j ) /\u1fb1 j(255)\nu 2 j\u1fb1 j = 1 \u2212\u1fb1 j (256) u 2 j\u1fb1 j +\u1fb1 j = 1 (257) (u 2 j + 1)\u1fb1 j = 1 (258\n) \u03b1 j = 1 / (u 2 j + 1).(259)\nFinally, we can expand the left-hand side using Eq. 245 and solve for u j\u22121 :\n\u03b1 j+1 max(\u1fb1 j /\u1fb1 j+1 , C 1 ) = 1 / (u 2 j + 1) (260) \u03b1 j max(\u1fb1 j\u22121 /\u1fb1 j , C 1 ) = 1 / (u 2 j\u22121 + 1) (261) 1 / (u 2 j + 1) max(\u1fb1 j\u22121 /\u1fb1 j , C 1 ) = 1 / (u 2 j\u22121 + 1) (262) max(\u1fb1 j\u22121 /\u1fb1 j , C 1 ) (u 2 j\u22121 + 1) = u 2 j + 1 (263) u 2 j\u22121 + 1 = (u 2 j + 1) / max(\u1fb1 j\u22121 /\u1fb1 j , C 1 )(264)\nu j\u22121 = u 2 j + 1 max(\u1fb1 j\u22121 /\u1fb1 j , C 1 ) \u2212 1,(265)\ngiving a recurrence formula for {u j }, bootstrapped by u M = 0, that matches the \"Time steps\" row of Table 1.", "publication_ref": ["b15", "b15", "b15", "b15", "b36", "b36", "b14"], "figure_ref": [], "table_ref": []}, {"heading": "C.3.3 iDDPM preconditioning and training", "text": "We can solve D \u03b8 (\u2022) from Eq. 227 by substituting \u03c3(t) = t from Appendix C.3.1:\n(j) \u03b8 x/ \u03c3 2 + 1 = x \u2212 D \u03b8 (x; \u03c3) /\u03c3 (266) D \u03b8 (x; \u03c3) = x \u2212 \u03c3 (j) \u03b8 x/ \u03c3 2 + 1 . (267\n)\nWe choose to define F \u03b8 (\u2022; j) = (j) \u03b8 (\u2022) and solve j from \u03c3 by finding the nearest u j :\nD \u03b8 (x; \u03c3) = 1 \u2022 cskip x \u2212 \u03c3 cout \u2022 F \u03b8 1 \u221a \u03c3 2 +1 cin \u2022 x; arg min j |u j \u2212 \u03c3| cnoise , (268\n)\nwhere c skip , c out , c in , and c noise match the \"Network and preconditioning\" section of Table 1.\nNote that Eq. 268 is identical to the VP preconditioning formula in Eq. 181. Furthermore, Nichol and Dhariwal [37] define their main training loss L simple (Eq. 14 in [37]) the same way as Song et al. [49], with \u03c3 drawn uniformly from {u j }. Thus, we can reuse Eq. 190 with \u03c3 = u j , j \u223c U(0, M \u2212 1), and \u03bb(\u03c3) = 1/\u03c3 2 , matching the \"Training\" section of Table 1. In addition to L simple , Nichol and Dhariwal [37] also employ a secondary loss term L vlb ; we refer the reader to Section 3.1 in [37] for details.", "publication_ref": ["b36", "b36", "b48", "b36", "b36"], "figure_ref": [], "table_ref": []}, {"heading": "C.3.4 iDDPM practical considerations", "text": "The pre-trained iDDPM model that we use on ImageNet-64 corresponds to the \"ADM (dropout)\" checkpoint 17 provided by Dhariwal and Nichol [9]. It contains 296 million trainable parameters and supports a discrete set of M = 1000 noise levels \u03c3 \u2208 {u j } \u2248 {20291, 642, 321, 214, 160, 128, 106, 92, 80, 71, . . . , 0.0064}. The fact that we can only evaluate F \u03b8 these specific choices of \u03c3 presents three practical challenges:\n1. In the context of DDIM, we must choose how to resample {u j } to yield {t i } for N = M . Song et al. [47] employ a simple resampling scheme where t i = u k\u2022i for resampling factor k \u2208 Z + . This scheme, however, requires that 1000 \u2261 0 (mod N ), which limits the possible choices for N considerably. Nichol and Dhariwal [37], on the other hand, employ a more flexible scheme where t i = u j with j = (M \u2212 1)/(N \u2212 1) \u2022 i . We note, however, that in practice the values of u j<8 are considerably larger than our preferred \u03c3 max = 80. We choose to skip these values by defining j = j 0 + (M \u2212 1 \u2212 j 0 )/(N \u2212 1) \u2022 i with j 0 = 8, matching the \"Time steps\" row in Table 1. In Figure 2c, the differences between the original sampler (blue) and our reimplementation (orange) are explained by this choice. 2. In the context of our time step discretization (Eq. 5), we must ensure that \u03c3 i \u2208 {u j }.\nWe accomplish this by rounding each \u03c3 i to its nearest supported counterpart, i.e., \u03c3 i \u2190 u arg min j |uj \u2212\u03c3i| , and setting \u03c3 min = 0.0064 \u2248 u N \u22121 . This is sufficient, because Algorithm 1 only evaluates D \u03b8 (\u2022; \u03c3) with \u03c3 \u2208 {\u03c3 i<N }.\n3. In the context of our stochastic sampler, we must ensure thatt i \u2208 {u j }. We accomplish this by replacing line 5 of Algorithm 2 witht i \u2190 u arg min j |uj \u2212(ti+\u03b3iti)| .\nWith these changes, we are able to import the pre-trained model directly as F \u03b8 (\u2022) and run Algorithms 1 and 2 using the definitions in Table 1. Note that the model outputs both \u03b8 (\u2022) and \u03a3 \u03b8 (\u2022), as described in Section 3.1 of [37]; we use only the former and ignore the latter.", "publication_ref": ["b16", "b8", "b46", "b36", "b36"], "figure_ref": ["fig_2"], "table_ref": []}, {"heading": "D Further analysis of deterministic sampling D.1 Truncation error analysis and choice of discretization parameters", "text": "As discussed in Section 3, the fundamental reason why diffusion models tend to require a large number of sampling steps is that any numerical ODE solver is necessarily an approximation; the larger the steps, the farther away we drift from the true solution at each step. Specifically, given the value of x i\u22121 at time step i \u2212 1, the solver approximates the true x * i as x i , resulting in local truncation error \u03c4 i = x * i \u2212 x i . The local errors get accumulated over the N steps, ultimately leading to global truncation error e N .\nEuler's method is a first order ODE solver, meaning that \u03c4 i = O h 2 i for any sufficiently smooth x(t), where h i = |t i \u2212 t i\u22121 | is the local step size [50]. In other words, there exist some C and H such that ||\u03c4 i || < Ch 2 i for every h i < H, i.e., halving h i reduces \u03c4 i by 4\u00d7. Furthermore, if we assume that D \u03b8 is Lipschitz continuous -which is true for all network architectures considered in this paper -the global truncation error is bounded by ||e N || \u2264 E max i ||\u03c4 i ||, where the value of E depends on N , t 0 , t N , and the Lipschitz constant [50]. Thus, reducing the global error for given N , which in turn enables reducing N itself, boils down to choosing the solver and {t i } so that max i ||\u03c4 i || is minimized.\nTo gain insight on how the local truncation error behaves in practice, we measure the values of \u03c4 i over different noise levels using the VE-based CIFAR-10 model. For a given noise level, we set t i = \u03c3 \u22121 (\u03c3 i ) and choose some t i\u22121 > t i depending on the case. We then sample x i\u22121 from p(x; \u03c3 i\u22121 ) and estimate the true x * i by performing 200 Euler steps over uniformly selected subintervals between t i\u22121 and t. Finally, we plot the mean and standard deviation of the root mean square error (RMSE), i.e., ||\u03c4 i ||/ \u221a dim \u03c4 , as a function of \u03c3 i , averaged over 200 random samples of x i\u22121 . Results for Euler's method are shown in Figure 13a, where the blue curve corresponds to uniform step size h \u03c3 = 1.25 with respect to \u03c3, i.e., \u03c3 i\u22121 = \u03c3 i + h \u03c3 and t i\u22121 = \u03c3 \u22121 (\u03c3 i\u22121 ). We see that the error is very large (RMSE \u2248 0.56) for low noise levels (\u03c3 i \u2264 0.5) and considerably smaller for high noise levels. This is in line with the common intuition that, in order to reduce e N , the step size should be decreased monotonically with decreasing \u03c3. Each curve is surrounded by a shaded region that indicates standard deviation, barely visible at low values of \u03c3. This indicates that \u03c4 i is nearly constant with respect to x i\u22121 , and thus there would be no benefit in varying {t i } schedule on a per-sample basis.\nA convenient way to vary the local step size depending on the noise level is to define {\u03c3 i } as a linear resampling of some monotonically increasing, unbounded warp function w(z). In other words, \u03c3 i<N = w(Ai + B) and \u03c3 N = 0, where constants A and B are selected so that \u03c3 0 = \u03c3 max and \u03c3 N \u22121 = \u03c3 min . In practice, we set \u03c3 min = max(\u03c3 lo , 0.002) and \u03c3 max = min(\u03c3 hi , 80), where \u03c3 lo and \u03c3 hi are the lowest and highest noise levels supported by a given model, respectively; we have found these choices to perform reasonably well in practice. Now, to balance \u03c4 i between low and high noise levels, we can, for example, use a polynomial warp function w(z) = z \u03c1 parameterized by the exponent \u03c1. This choice leads to the following formula for {\u03c3 i }:\n\u03c3 i<N = \u03c3 max 1 \u03c1 + i N \u2212 1 \u03c3 min 1 \u03c1 \u2212 \u03c3 max 1 \u03c1 \u03c1 , \u03c3 N = 0,(269)\nwhich reduces to uniform discretization when \u03c1 = 1 and gives more and more emphasis to low noise levels as \u03c1 increases. 18 Based on the value of \u03c3 i , we can now compute \u03c3 i\u22121 = \u03c3 1/\u03c1 i \u2212 A \u03c1 , which enables us to visualize \u03c4 i for different choices of \u03c1 in Figure 13a. We see that increasing \u03c1 reduces the error for low noise levels (\u03c3 < 10) while increasing it for high noise levels (\u03c3 > 10). Approximate balance is achieved at \u03c1 = 2, but RMSE remains relatively high (\u223c 0.03), meaning that Euler's method drifts away from the correct result by several ULPs at each step. While the error could be reduced by increasing N , we would ideally like the RMSE to be well below 0.01 even with low step counts.\nHeun's method introduces an additional correction step for x i+1 to account for the fact that dx/dt may change between t i and t i+1 ; Euler's method assumes it to be constant. The correction leads to cubic convergence of the local truncation error, i.e., \u03c4 i = O h 3 i , at the cost of one additional evaluation of D \u03b8 per step. We discuss the general family of Heun-like schemes later in Appendix D.2. Figure 13b shows local truncation error for Heun's method using the same setup as Figure 13a. We see that the differences in ||\u03c4 i || are generally more pronounced, which is to be expected given the quadratic vs. cubic convergence of the two methods. Cases where Euler's method has low RMSE tend to have even lower RMSE with Heun's method, and vice versa for cases with high RMSE. Most remarkably, the red curve shows almost constant RMSE \u2208 [0.0030, 0.0045]. This means that the combination of Eq. 269 and Heun's method is, in fact, very close to optimal with \u03c1 = 3.\nThus far, we have only considered the raw numerical error, i.e., component-wise deviation from the true result in RGB space. The raw numerical error is relevant for certain use cases, e.g., image manipulation where the ODE is first evaluated in the direction of increasing t and then back to t = 0 again -in this case, ||e N || directly tells us how much the original image degrades in the process and we can use \u03c1 = 3 to minimize it. Considering the generation of novel images from scratch, however, it is reasonable to expect different noise levels to introduce different kinds of errors that may not necessarily be on equal footing considering their perceptual importance. We investigate this in Figure 13c, where we plot FID as a function of \u03c1 for different models and different choices of N . Note that the ImageNet-64 model was only trained for a discrete set of noise levels; in order to use it with Eq. 269, we round each t i to its nearest supported counterpart, i.e., t i = u arg min j |uj \u2212ti| .\nFrom the plot, we can see that even though \u03c1 = 3 leads to relatively good FID, it can be reduced further by choosing \u03c1 > 3. This corresponds to intentionally introducing error at high noise levels to reduce it at low noise levels, which makes intuitive sense because the value of \u03c3 max is somewhat arbitrary to begin with -increasing \u03c3 max can have a large impact on ||e N ||, but it does not affect the resulting image distribution nearly as much. In general, we have found \u03c1 = 7 to perform reasonably well in all cases, and use this value in all other experiments.", "publication_ref": ["b49", "b49", "b17"], "figure_ref": ["fig_0", "fig_0", "fig_0", "fig_0", "fig_0"], "table_ref": []}, {"heading": "D.2 General family of 2 nd order Runge-Kutta variants", "text": "Heun's method illustrated in Algorithm 1 belongs to a family of explicit two-stage 2 nd order Runge-Kutta methods, each having the same computational cost. A common parameterization [50] of this family is,\nd i = f (x i ; t i ) ; x i+1 = x i + h 1 \u2212 1 2\u03b1 d i + 1 2\u03b1 f (x i + \u03b1hd i ; t i + \u03b1h) ,(270)\nwhere h = t i+1 \u2212 t i and \u03b1 is a parameter that controls where the additional gradient is evaluated and how much it influences the step taken. Setting \u03b1 = 1 corresponds to Heun's method, and \u03b1 = 1 2 and \u03b1 = 2 3 yield so-called midpoint and Ralston methods, respectively. All these variants differ in the kind of approximation error they incur due to the geometry of the underlying function f .\nTo establish the optimal \u03b1 in our use case, we ran a separate series of experiments. According to the results, it appears that \u03b1 = 1 is very close to being optimal. Nonetheless, the experimentally Algorithm 3 Deterministic sampling using general 2 nd order Runge-Kutta, \u03c3(t) = t and s(t) = 1.\n1: procedure ALPHASAMPLER(D \u03b8 (x; \u03c3), t i\u2208{0,...,N } , \u03b1) 2:\nsample x0 \u223c N 0, t 2 0 I 3:\nfor i \u2208 {0, . . . , N \u2212 1} do 4:\nhi \u2190 ti+1 \u2212 ti\nStep length 5:\ndi \u2190 xi \u2212 D \u03b8 (xi; ti) /ti Evaluate dx/dt at (x, ti) 6:\n(x i , t i ) \u2190 (xi + \u03b1hdi, ti + \u03b1h) Additional evaluation point 7:\nif t i = 0 then 8:\nd i \u2190 x i \u2212 D \u03b8 (x i ; t i ) /t i Evaluate dx/dt at (x i , t i ) 9: xi+1 \u2190 xi + h 1 \u2212 1 2\u03b1 di + 1 2\u03b1 d i\nSecond order step from ti to ti+1 10: else 11:\nxi+1 \u2190 xi + hdi Euler step from ti to ti+1 12:\nreturn xN best choice was \u03b1 = 1.1 that performed slightly better, even though values greater than one are theoretically hard to justify as they overshoot the target t i+1 . As we have no good explanation for this observation and cannot tell if it holds in general, we chose not to make \u03b1 a new hyperparameter and instead fixed it to 1, corresponding exactly to Heun's method. Further analysis is left as future work, including the possibility of having \u03b1 vary during sampling.\nAn additional benefit of setting \u03b1 = 1 is that it makes it possible to use pre-trained neural networks D \u03b8 (x; \u03c3) that have been trained only for specific values of \u03c3. This is because a Heun step evaluates the additional gradient at exactly t i+1 unlike the other 2 nd order variants. Hence it is sufficient to ensure that each t i corresponds to a value of \u03c3 that the network was trained for.\nAlgorithm 3 shows the pseudocode for a general 2 nd order solver parameterized by \u03b1. For clarity, the pseudocode assumes the specific choices of \u03c3(t) = t and s(t) = 1 that we advocate in Section 3.\nNote that the fallback to Euler step (line 11) can occur only when \u03b1 \u2265 1.\nE Further results with stochastic sampling E.1 Image degradation due to excessive stochastic iteration Figure 14 illustrates the image degradation caused by excessive Langevin iteration (Section 4, \"Practical considerations\"). These images are generated by doing a specified number of iterations at a fixed noise level \u03c3 so that at each iteration an equal amount of noise is added and removed. In theory, Langevin dynamics should bring the distribution towards the ideal distribution p(x; \u03c3) but as noted in Section 4, this holds only if the denoiser D \u03b8 (x; \u03c3) induces a conservative vector field in Eq. 3.\nAs seen in the figure, it is clear that the image distribution suffers from repeated iteration in all cases, although the exact failure mode depends on dataset and noise level. For low noise levels (below 0.2 or so), the images tend to oversaturate starting at 2k iterations and become fully corrupted after that. Our heuristic of setting S tmin > 0 is designed to prevent stochastic sampling altogether at very low noise levels to avoid this effect.\nFor high noise levels, we can see that iterating without the standard deviation correction, i.e., when S noise = 1.000, the images tend to become more abstract and devoid of color at high iteration counts; this is especially visible in the 10k column of CIFAR-10 where the images become mostly black and white with no discernible backgrounds. Our heuristic inflation of standard deviation by setting S noise > 1 counteracts this tendency efficiently, as seen in the corresponding images on the right hand side of the figure. Notably, this still does not fix the oversaturation and corruption at low noise levels, suggesting multiple sources for the detrimental effects of excessive iteration. Further research will be required to better understand the root causes of these observed effects.\nFigure 15 presents the output quality of our stochastic sampler in terms of FID as a function of S churn at fixed NFE, using pre-trained networks of Song et al. [49] and Dhariwal and Nichol [9]. Generally, for each case and combination of our heuristic corrections, there is an optimal amount of stochasticity after which the results start to degrade. It can also be seen that regardless of the value of S churn , the Step 0 100 200 500 1,000 2,000 5,000 10,000 \u03c3 Step 0 100 200 500 1,000 2,000 5,000 10,000 Step 0 500 1,000 2,000 5,000 10,000\n\u03c3\nStep 0 500 1,000 2,000 5,000 10,000 Figure 14: Gradual image degradation with repeated addition and removal of noise. We start with a random image drawn from p(x; \u03c3) (first column) and run Algorithm 2 for a certain number of steps (remaining columns) with fixed \u03b3 i = \u221a 2 \u2212 1. Each row corresponds to a specific choice of \u03c3 (indicated in the middle) that we keep fixed throughout the entire process. We visualize the results after running them through the denoiser, i.e., D \u03b8 (x i ; \u03c3). Figure 15: Ablations of our stochastic sampler (Algorithm 2) parameters using pre-trained networks of Song et al. [49] and Dhariwal and Nichol [9]. Each curve shows FID (y-axis) as a function of S churn (x-axis) for N = 256 steps (NFE = 511). The dashed red lines correspond to our deterministic sampler (Algorithm 1), equivalent to setting S churn = 0. The purple curves correspond to optimal choices for {S tmin , S tmax , S noise }, found separately for each case using grid search. Orange, blue, and green correspond to disabling the effects of S tmin,tmax and/or S noise . The shaded regions indicate the range of variation between the lowest and highest observed FID. best results are obtained by enabling all corrections, although whether S noise or S tmin,tmax is more important depends on the case.", "publication_ref": ["b49", "b48", "b8", "b48", "b8"], "figure_ref": ["fig_0", "fig_0", "fig_0", "fig_0"], "table_ref": []}, {"heading": "E.2 Stochastic sampling parameters", "text": "Table 5 lists the values for S churn , S tmin , S tmax , and S noise that we used in our stochastic sampling experiments. These were determined with a grid search over the combinations listed in the rightmost column. It can be seen that the optimal parameters depend on the case; better understanding of the degradation phenomena will hopefully give rise to more direct ways of handling the problem in the future.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_8"]}, {"heading": "F Implementation details", "text": "We implemented our techniques in a newly written codebase, based loosely on the original implementations by Song et al. 19 [49], Dhariwal and Nichol 20 [9], and Karras et al. 21 [26]. We performed extensive testing to verify that our implementation produced exactly the same results as previous work, including samplers, pre-trained models, network architectures, training configurations, and evaluation. We ran all experiments using PyTorch 1.10.0, CUDA 11.4, and CuDNN 8.2.0 on NVIDIA DGX-1's with 8 Tesla V100 GPUs each.\nOur implementation and pre-trained models are available at https://github.com/NVlabs/edm ", "publication_ref": ["b18", "b48", "b8", "b20", "b25"], "figure_ref": [], "table_ref": []}, {"heading": "F.1 FID calculation", "text": "We calculate FID [15] between 50,000 generated images and all available real images, without any augmentation such as x-flips. We use the pre-trained Inception-v3 model provided with StyleGAN3 22 [26] that is, in turn, a direct PyTorch translation of the original TensorFlow-based model 23 . We have verified that our FID implementation produces identical results compared to Dhariwal and Nichol [9] and Karras et al. [26]. To reduce the impact of random variation, typically in the order of \u00b12%, we compute FID three times in each experiment and report the minimum. We also highlight the difference between the highest and lowest achieved FID in Figures 4, 5b, 13c, and 15.", "publication_ref": ["b14", "b25", "b22", "b8", "b25"], "figure_ref": [], "table_ref": []}, {"heading": "F.2 Augmentation regularization", "text": "In Section 5, we propose to combat overfitting of D \u03b8 using conditional augmentation. We build our augmentation pipeline around the same concepts that were originally proposed by Karras et al. [25] in the context of GANs. In practice, we employ a set of 6 geometric transformations; we have found other types of augmentations, such as color corruption and image-space filtering, to be consistently harmful for diffusion-based models.\nThe details of our augmentation pipeline are shown in Table 6. We apply the augmentations independently to each training image y \u223c p data prior to adding the noise n \u223c N (0, \u03c3 2 I). First, we determine whether to enable or disable each augmentation based on a weighted coin toss. The probability of enabling a given augmentation (\"Prob.\" column) is fixed to 12% for CIFAR-10 and 15% for FFHQ and AFHQv2, except for x-flips that are always enabled. We then draw 8 random parameters from their corresponding distributions (\"Parameters\" column); if a given augmentation is disabled, we override the associated parameters with zero. Based on these, we construct a homogeneous 2D transformation matrix based on the parameters (\"Transformation\" column). This transformation is applied to the image using the implementation of [25] that employs 2\u00d7 supersampled high-quality Wavelet filters. Finally, we construct a 9-dimensional conditioning input vector (\"Conditioning\" column) and feed it to the denoiser network, in addition to the image and noise level inputs.\nThe role of the conditioning input is to present the network with a set of auxiliary tasks; in addition to the main task of modeling p(x; \u03c3), we effectively ask the network to also model an infinite set of distributions p(x; \u03c3, a) for each possible choice of the augmentation parameters a. These auxiliary tasks provide the network with a large variety of unique training samples, preventing it from overfitting to any individual sample. Still, the auxiliary tasks appear to be beneficial for the main task; we speculate that this is because the denoising operation itself is similar for every choice of a.\nWe have designed the conditioning input so that zero corresponds to the case where no augmentations were applied. During sampling, we simply set a = 0 to obtain results consistent with the main task. We have not observed any leakage between the auxiliary tasks and the main task; the generated images exhibit no traces of out-of-domain geometric transformations even with A prob = 100%. In practice, this means that we are free to choose the constants {A prob , A scale , A aniso , A trans } any way we like as long as the results improve. Horizontal flips serve as an interesting example. Most of the prior work augments the training set with random x-flips, which is beneficial for most datasets but has the downside that any text or logos may appear mirrored in the generated images. With our non-leaky augmentations, we get the same benefits without the downsides by executing the x-flip augmentation with 100% probability. Thus, we rely exclusively on our augmentation scheme and disable dataset x-flips to ensure that the generated images stay true to the original distribution.", "publication_ref": ["b24", "b24"], "figure_ref": [], "table_ref": ["tab_9"]}, {"heading": "F.3 Training configurations", "text": "Table 7 shows the exact set of hyperparameters that we used in our training experiments reported in Section 5. We will first detail the configurations used with CIFAR-10, FFHQ, and AFHQv2, and then discuss the training of our improved ImageNet model.\nConfig A of Table 2 (\"Baseline\") corresponds to the original setup of Song et al. [49] for the two cases (VP and VE), and config F (\"Ours\") corresponds to our improved setup. We trained each model until a total of 200 million images had been drawn from the training set, abbreviated as \"200 Mimg\" in Table 7; this corresponds to a total of \u223c400,000 training iterations using a batch size of 512. We saved a snapshot of the model every 2.5 million images and reported results for the snapshot that achieved the lowest FID according to our deterministic sampler with NFE = 35 or NFE = 79, depending on the resolution.\nIn config B, we re-adjust the basic hyperparameters to enable faster training and obtain a more meaningful point of comparison. Specifically, we increase the parallelism from 4 to 8 GPUs and batch size from 128 to 512 or 256, depending on the resolution. We also disable gradient clipping, i.e., forcing dL(D \u03b8 )/d\u03b8 2 \u2264 1, that we found to provide no benefit in practice. Furthermore, we increase the learning rate from 0.0002 to 0.001 for CIFAR-10, ramping it up during the first 10 million images, and standardize the half-life of the exponential moving average of \u03b8 to 0.5 million images. Finally, we adjust the dropout probability for each dataset as shown in Table 7 via a full grid search at 1% increments. Our total training time is approximately 2 days for CIFAR-10 at 32\u00d732 resolution and 4 days for FFHQ and AFHQv2 at 64\u00d764 resolution.", "publication_ref": ["b48"], "figure_ref": [], "table_ref": ["tab_10", "tab_1", "tab_10", "tab_10"]}, {"heading": "", "text": "Acknowledgments. We thank Jaakko Lehtinen, Ming-Yu Liu, Tuomas Kynk\u00e4\u00e4nniemi, Axel Sauer, Arash Vahdat, and Janne Hellsten for discussions and comments, and Tero Kuosmanen, Samuel Klenberg, and Janne Hellsten for maintaining our compute infrastructure.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "", "text": "In config C, we improve the expressive power of the model by removing the 4\u00d74 layers and doubling the capacity of the 16\u00d716 layers instead; we found the former to mainly contribute to overfitting, whereas the latter were critical for obtaining high-quality results. The original models of Song et al. [49] employ 128 channels at 64\u00d764 (where applicable) and 32\u00d732, and 256 channels at 16\u00d716, 8\u00d78, and 4\u00d74. We change these numbers to 128 channels at 64\u00d764 (where applicable), and 256 channels at 32\u00d732, 16\u00d716, and 8\u00d78. We abbreviate these counts in Table 7 as multiples of 128, listed from the highest resolution to the lowest. In practice, this rebalancing reduces the total number of trainable parameters slightly, resulting in \u223c56 million parameters for each model at 32\u00d732 resolution and \u223c62 million parameters at 64\u00d764 resolution.\nIn config D, we replace the original preconditioning with our improved formulas (\"Network and preconditioning\" section in Table 1). In config E, we do the same for the noise distribution and loss weighting (\"Training\" section in Table 1). Finally, in config F, we enable augmentation regularization as discussed in Appendix F.2. The other hyperparameters remain the same as in config C.\nWith ImageNet-64, it is necessary to train considerably longer compared to the other datasets in order to reach state-of-the-art results. To reduce the training time, we employed 32 NVIDIA Ampere GPUs (4 nodes) with a batch size of 4096 (128 per GPU) and utilized the high-performance Tensor Cores via mixed-precision FP16/FP32 training. In practice, we store the trainable parameters as FP32 but cast them to FP16 when evaluating F \u03b8 , except for the embedding and self-attention layers, where we found the limited exponent range of FP16 to occasionally lead to stability issues. We trained the model for two weeks, corresponding to \u223c2500 million images drawn from the training set and \u223c600,000 training iterations, using learning rate 0.0001, exponential moving average of 50 million images, and the same model architecture and dropout probability as Dhariwal and Nichol [9]. We did not find overfitting to be a concern, and thus chose to not employ augmentation regularization.", "publication_ref": ["b48", "b8"], "figure_ref": [], "table_ref": []}, {"heading": "F.4 Network architectures", "text": "As a result of our training improvements, the VP and VE cases become otherwise identical in config F except for the network architecture; VP employs the DDPM++ architecture while VE employs NCSN++, both of which were originally proposed by Song et al. [49]. These architectures correspond to relatively straightforward variations of the same U-net backbone with three differences, as illustrated in Table 8. First, DDPM++ employs box filter [1,1] for the upsampling and downsampling layers whereas NCSN++ employs bilinear filter [1,3,3,1]. Second, DDPM++ inherits its positional encoding scheme for the noise level directly from DDPM [16] whereas NCSN++ replaces it with random Fourier features [52]. Third, NCSN++ incorporates additional residual skip connections from the input image to each block in the encoder, as explained in Appendix H of [49] (\"progressive growing architectures\").\nFor class conditioning and augmentation regularization, we extend the original DDPM++ and NCSN++ arhictectures by introducing two optional conditioning inputs alongside the noise level input. We represent class labels as one-hot encoded vectors that we first scale by \u221a C, where C is the total number of classes, and then feed through a fully-connected layer. For the augmentation parameters, we feed the conditioning inputs of Appendix F.2 through a fully-connected layer as-is.\nWe then combine the resulting feature vectors with the original noise level conditioning vector through elementwise addition.\nFor class-conditional ImageNet-64, we use the ADM architecture of Dhariwal and Nichol [9] with no changes. The model has a total of \u223c296 million trainable parameters. As detailed in Tables 7  and 8, the most notable differences to DDPM++ include the use of a slightly shallower model (3 residual blocks per resolution instead of 4) with considerably more channels (e.g., 768 in the lowest resolution instead of 256), more self-attention layers interspersed throughout the network (22 instead of 6), and the use of multi-head attention (e.g., 12 heads in the lowest resolution). We feel that the precise impact of architectural choices remains an interesting question for future work.", "publication_ref": ["b48", "b0", "b0", "b0", "b2", "b2", "b0", "b15", "b51", "b48", "b8"], "figure_ref": [], "table_ref": []}, {"heading": "F.5 Licenses", "text": "Datasets:\n\u2022 CIFAR-10 [29]: MIT license \u2022 FFHQ [27]:\nCreative Commons BY-NC-SA 4.0 license \u2022 AFHQv2 [7]:\nCreative Commons BY-NC 4.0 license \u2022 ImageNet [8]: The license status is unclear Pre-trained models:\n\u2022 CIFAR-10 models by Song et al. [49]:\nApache V2.0 license \u2022 ImageNet-64 model by Dhariwal and Nichol [9]: MIT license \u2022 Inception-v3 model by Szegedy et al. [51]:\nApache V2.0 license", "publication_ref": ["b26", "b6", "b7", "b48", "b8", "b50"], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Reverse-time diffusion equation models", "journal": "", "year": "1982", "authors": "B D Anderson"}, {"ref_id": "b1", "title": "Computer Methods for Ordinary Differential Equations and Differential-Algebraic Equations", "journal": "Society for Industrial and Applied Mathematics", "year": "1998", "authors": "U M Ascher; L R Petzold"}, {"ref_id": "b2", "title": "Analytic-DPM: an analytic estimate of the optimal reverse variance in diffusion probabilistic models", "journal": "", "year": "2022", "authors": "F Bao; C Li; J Zhu; B Zhang"}, {"ref_id": "b3", "title": "Label-efficient semantic segmentation with diffusion models", "journal": "", "year": "2022", "authors": "D Baranchuk; A Voynov; I Rubachev; V Khrulkov; A Babenko"}, {"ref_id": "b4", "title": "Neural networks for pattern recognition", "journal": "Oxford University Press", "year": "1995", "authors": "C M Bishop"}, {"ref_id": "b5", "title": "Perception prioritized training of diffusion models", "journal": "", "year": "2022", "authors": "J Choi; J Lee; C Shin; S Kim; H Kim; S Yoon"}, {"ref_id": "b6", "title": "StarGAN v2: Diverse image synthesis for multiple domains", "journal": "", "year": "2020", "authors": "Y Choi; Y Uh; J Yoo; J.-W Ha"}, {"ref_id": "b7", "title": "ImageNet: A large-scale hierarchical image database", "journal": "", "year": "2009", "authors": "J Deng; W Dong; R Socher; L.-J Li; K Li; L Fei-Fei"}, {"ref_id": "b8", "title": "Diffusion models beat GANs on image synthesis", "journal": "", "year": "2021", "authors": "P Dhariwal; A Q Nichol"}, {"ref_id": "b9", "title": "Score-based generative modeling with critically-damped Langevin diffusion", "journal": "", "year": "2022", "authors": "T Dockhorn; A Vahdat; K Kreis"}, {"ref_id": "b10", "title": "A family of embedded Runge-Kutta formulae", "journal": "Journal of computational and applied mathematics", "year": "1980", "authors": "J R Dormand; P J Prince"}, {"ref_id": "b11", "title": "Th\u00e9orie analytique de la chaleur", "journal": "Didot Paris", "year": "", "authors": "J B J Fourier; G Darboux"}, {"ref_id": "b12", "title": "Generative adversarial networks", "journal": "", "year": "2014", "authors": "I Goodfellow; J Pouget-Abadie; M Mirza; B Xu; D Warde-Farley; S Ozair; A Courville; Y Bengio"}, {"ref_id": "b13", "title": "Representations of knowledge in complex systems", "journal": "Journal of the Royal Statistical Society: Series B (Methodological)", "year": "1994", "authors": "U Grenander; M I Miller"}, {"ref_id": "b14", "title": "GANs trained by a two time-scale update rule converge to a local Nash equilibrium", "journal": "", "year": "2017", "authors": "M Heusel; H Ramsauer; T Unterthiner; B Nessler; S Hochreiter"}, {"ref_id": "b15", "title": "Denoising diffusion probabilistic models", "journal": "", "year": "2020", "authors": "J Ho; A Jain; P Abbeel"}, {"ref_id": "b16", "title": "Cascaded diffusion models for high fidelity image generation", "journal": "Journal of Machine Learning Research", "year": "", "authors": "J Ho; C Saharia; W Chan; D J Fleet; M Norouzi; T Salimans"}, {"ref_id": "b17", "title": "Classifier-free diffusion guidance", "journal": "", "year": "2021", "authors": "J Ho; T Salimans"}, {"ref_id": "b18", "title": "Video diffusion models", "journal": "", "year": "2022", "authors": "J Ho; T Salimans; A A Gritsenko; W Chan; M Norouzi; D J Fleet"}, {"ref_id": "b19", "title": "A variational perspective on diffusion-based generative models and score matching", "journal": "", "year": "2021", "authors": "C.-W Huang; J H Lim; A C Courville"}, {"ref_id": "b20", "title": "Normalization techniques in training DNNs: Methodology, analysis and application", "journal": "", "year": "2009", "authors": "L Huang; J Qin; Y Zhou; F Zhu; L Liu; L Shao"}, {"ref_id": "b21", "title": "Estimation of non-normalized statistical models by score matching", "journal": "Journal of Machine Learning Research", "year": "2005", "authors": "A Hyv\u00e4rinen"}, {"ref_id": "b22", "title": "Subspace diffusion generative models", "journal": "", "year": "2022", "authors": "B Jing; G Corso; R Berlinghieri; T Jaakkola"}, {"ref_id": "b23", "title": "Gotta go fast when generating data with score-based models", "journal": "", "year": "2021", "authors": "A Jolicoeur-Martineau; K Li; R Pich\u00e9-Taillefer; T Kachman; I Mitliagkas"}, {"ref_id": "b24", "title": "Training generative adversarial networks with limited data", "journal": "", "year": "2020", "authors": "T Karras; M Aittala; J Hellsten; S Laine; J Lehtinen; T Aila"}, {"ref_id": "b25", "title": "Alias-free generative adversarial networks", "journal": "", "year": "2021", "authors": "T Karras; M Aittala; S Laine; E H\u00e4rk\u00f6nen; J Hellsten; J Lehtinen; T Aila"}, {"ref_id": "b26", "title": "A style-based generator architecture for generative adversarial networks", "journal": "", "year": "2018", "authors": "T Karras; S Laine; T Aila"}, {"ref_id": "b27", "title": "DiffWave: A versatile diffusion model for audio synthesis", "journal": "", "year": "2021", "authors": "Z Kong; W Ping; J Huang; K Zhao; B Catanzaro"}, {"ref_id": "b28", "title": "Learning multiple layers of features from tiny images", "journal": "", "year": "2009", "authors": "A Krizhevsky"}, {"ref_id": "b29", "title": "Noise2Noise: Learning image restoration without clean data", "journal": "", "year": "2018", "authors": "J Lehtinen; J Munkberg; J Hasselgren; S Laine; T Karras; M Aittala; T Aila"}, {"ref_id": "b30", "title": "Pseudo numerical methods for diffusion models on manifolds", "journal": "", "year": "2022", "authors": "L Liu; Y Ren; Z Lin; Z Zhao"}, {"ref_id": "b31", "title": "DPM-Solver: A fast ODE solver for diffusion probabilistic model sampling in around 10 steps", "journal": "", "year": "2022", "authors": "C Lu; Y Zhou; F Bao; J Chen; C Li; J Zhu"}, {"ref_id": "b32", "title": "Knowledge distillation in iterative generative models for improved sampling speed", "journal": "", "year": "2021", "authors": "E Luhman; T Luhman"}, {"ref_id": "b33", "title": "DALL\u2022E 2 preview -risks and limitations", "journal": "OpenAI", "year": "2022", "authors": "P Mishkin; L Ahmad; M Brundage; G Krueger; G Sastry"}, {"ref_id": "b34", "title": "Zero-shot translation using diffusion models. CoRR, abs", "journal": "", "year": "1471", "authors": "E Nachmani; S Dovrat"}, {"ref_id": "b35", "title": "GLIDE: Towards photorealistic image generation and editing with text-guided diffusion models", "journal": "", "year": "2022", "authors": "A Nichol; P Dhariwal; A Ramesh; P Shyam; P Mishkin; B Mcgrew; I Sutskever; M Chen"}, {"ref_id": "b36", "title": "Improved denoising diffusion probabilistic models", "journal": "", "year": "2021", "authors": "A Q Nichol; P "}, {"ref_id": "b37", "title": "Grad-TTS: A diffusion probabilistic model for text-to-speech", "journal": "", "year": "2021", "authors": "V Popov; I Vovk; V Gogoryan; T Sadekova; M Kudinov"}, {"ref_id": "b38", "title": "Diffusion autoencoders: Toward a meaningful and decodable representation", "journal": "", "year": "2022", "authors": "K Preechakul; N Chatthee; S Wizadwongsa; S Suwajanakorn"}, {"ref_id": "b39", "title": "Hierarchical text-conditional image generation with CLIP latents", "journal": "", "year": "", "authors": "A Ramesh; P Dhariwal; A Nichol; C Chu; M Chen"}, {"ref_id": "b40", "title": "Modify the improved Euler scheme to integrate stochastic differential equations", "journal": "CoRR", "year": "2012", "authors": "A J Roberts"}, {"ref_id": "b41", "title": "High-resolution image synthesis with latent diffusion models", "journal": "", "year": "2022", "authors": "R Rombach; A Blattmann; D Lorenz; P Esser; B Ommer"}, {"ref_id": "b42", "title": "Palette: Image-to-image diffusion models", "journal": "", "year": "2022", "authors": "C Saharia; W Chan; H Chang; C A Lee; J Ho; T Salimans; D J Fleet; M Norouzi"}, {"ref_id": "b43", "title": "Progressive distillation for fast sampling of diffusion models", "journal": "", "year": "2022", "authors": "T Salimans; J Ho"}, {"ref_id": "b44", "title": "StyleGAN-XL: Scaling StyleGAN to large diverse datasets", "journal": "", "year": "2022", "authors": "A Sauer; K Schwarz; A Geiger"}, {"ref_id": "b45", "title": "Deep unsupervised learning using nonequilibrium thermodynamics", "journal": "", "year": "2015", "authors": "J Sohl-Dickstein; E Weiss; N Maheswaranathan; S Ganguli"}, {"ref_id": "b46", "title": "Denoising diffusion implicit models", "journal": "", "year": "2021", "authors": "J Song; C Meng; S Ermon"}, {"ref_id": "b47", "title": "Generative modeling by estimating gradients of the data distribution", "journal": "", "year": "2019", "authors": "Y Song; S Ermon"}, {"ref_id": "b48", "title": "Score-based generative modeling through stochastic differential equations", "journal": "", "year": "2021", "authors": "Y Song; J Sohl-Dickstein; D P Kingma; A Kumar; S Ermon; B Poole"}, {"ref_id": "b49", "title": "An Introduction to Numerical Analysis", "journal": "Cambridge University Press", "year": "2003", "authors": "E S\u00fcli; D F Mayers"}, {"ref_id": "b50", "title": "Rethinking the Inception architecture for computer vision", "journal": "", "year": "2016", "authors": "C Szegedy; V Vanhoucke; S Ioffe; J Shlens; Z Wojna"}, {"ref_id": "b51", "title": "Fourier features let networks learn high frequency functions in low dimensional domains", "journal": "", "year": "2020", "authors": "M Tancik; P P Srinivasan; B Mildenhall; S Fridovich-Keil; N Raghavan; U Singhal; R Ramamoorthi; J T Barron; R Ng"}, {"ref_id": "b52", "title": "Score-based generative modeling in latent space", "journal": "", "year": "2021", "authors": "A Vahdat; K Kreis; J Kautz"}, {"ref_id": "b53", "title": "A connection between score matching and denoising autoencoders", "journal": "Neural Computation", "year": "2011", "authors": "P Vincent"}, {"ref_id": "b54", "title": "Learning fast samplers for diffusion models by differentiating through sample quality", "journal": "", "year": "2022", "authors": "D Watson; W Chan; J Ho; M Norouzi"}, {"ref_id": "b55", "title": "Learning to efficiently sample from diffusion probabilistic models", "journal": "", "year": "2021", "authors": "D Watson; J Ho; M Norouzi; W Chan"}, {"ref_id": "b56", "title": "Diffusion models for implicit image segmentation ensembles", "journal": "", "year": "2022", "authors": "J Wolleb; R Sandk\u00fchler; F Bieder; P Valmaggia; P C Cattin"}, {"ref_id": "b57", "title": "Diffusion normalizing flow", "journal": "", "year": "2021", "authors": "Q Zhang; Y Chen"}, {"ref_id": "b58", "title": "Fast sampling of diffusion models with exponential integrator. CoRR, abs", "journal": "", "year": "2022", "authors": "Q Zhang; Y Chen"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "36thFigure 1 :1Figure 1: Denoising score matching on CIFAR-10. (a) Images from the training set corrupted with varying levels of additive Gaussian noise. High levels of noise lead to oversaturated colors; we normalize the images for cleaner visualization. (b) Optimal denoising result from minimizing Eq. 2 analytically (see Appendix B.3). With increasing noise level, the result approaches dataset mean.", "figure_data": ""}, {"figure_label": "22212", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "/ \u03c3 2 + \u03c3 2 data 2 \u03c3 2 + \u03c3 2 data 1 4 2 jM22212Output scaling c out (\u03c3) \u2212\u03c3 \u03c3 \u2212\u03c3 \u03c3 \u2022 \u03c3 data / \u03c3 2 data + \u03c3 2 Input scaling c in (\u03c3) 1/ \u221a \u03c3 Noise cond. c noise (\u03c3) (M \u2212 1) \u03c3 \u22121 (\u03c3) ln( 1 2 \u03c3) M \u22121\u2212arg min j |u j \u2212 \u03c3| ln(\u03c3) Training (Section 5) Noise distribution \u03c3 \u22121 (\u03c3) \u223c U( t , 1) ln(\u03c3) \u223c U(ln(\u03c3 min ), \u03c3 = u j , j \u223c U{0, M \u22121} ln(\u03c3) \u223c N (P mean , P 2 std ) ln(\u03c3 max )) Loss weighting \u03bb(\u03c3) 1/\u03c3 2 1/\u03c3 2 1/\u03c3 2 (note: * ) \u03c3 2 +\u03c3 2 data /(\u03c3 \u2022 \u03c3 data ) 2 Parameters \u03b2d = 19.9, \u03b2min = 0.1 \u03c3min = 0.02\u1fb1j = sin 2 ( \u03c0 (C2+1) ) \u03c3min =0.002, \u03c3max = 80 s = 10 \u22123 , t = 10 \u22125 \u03c3max = 100 C1 = 0.001, C2 = 0.008 \u03c3data = 0.5, \u03c1 = 7 M = 1000 M = 1000, j0 = 8 \u2020 Pmean = \u22121.2, Pstd = 1.", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 2 :2Figure2: Comparison of deterministic sampling methods using three pre-trained models. For each curve, the dot indicates the lowest NFE whose FID is within 3% of the lowest observed FID.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 3 :3Figure 3: A sketch of ODE curvature in 1D where p data is two Dirac peaks at x = \u00b11. Horizontal t axis is chosen to show \u03c3 \u2208 [0, 25] in each plot, with insets showing \u03c3 \u2208 [0, 1] near the data. Example local gradients are shown with black arrows. (a) Variance preserving ODE of Song et al. [49] has solution trajectories that flatten out to horizontal lines at large \u03c3. Local gradients start pointing towards data only at small \u03c3. (b) Variance exploding variant has extreme curvature near data and the solution trajectories are curved everywhere. (c) With the schedule used by DDIM[47] and us, as \u03c3 increases the solution trajectories approach straight lines that point towards the mean of data. As \u03c3 \u2192 0, the trajectories become linear and point towards the data manifold.", "figure_data": ""}, {"figure_label": "6415", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "ImageNet- 64 . 1 0Figure 5 :6415Figure 5: (a) Observed initial (green) and final loss per noise level, representative of the the 32\u00d732 (blue) and 64\u00d764 (orange) models considered in this paper. The shaded regions represent the standard deviation over 10k random samples. Our proposed training sample density is shown by the dashed red curve. (b) Effect of S churn on unconditional CIFAR-10 with 256 steps (NFE = 511). For the original training setup of Song et al.[49], stochastic sampling is highly beneficial (blue, green), while deterministic sampling (S churn = 0) leads to relatively poor FID. For our training setup, the situation is reversed (orange, red); stochastic sampling is not only unnecessary but harmful. (c) Effect of S churn on class-conditional ImageNet-64 with 256 steps (NFE = 511). In this more challenging scenario, stochastic sampling turns out to be useful again. Our training setup improves the results for both deterministic and stochastic sampling.", "figure_data": ""}, {"figure_label": "13", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Figure 13 :13Figure 13: (a) Local truncation error (y-axis) at different noise levels (x-axis) using Euler's method with the VE-based CIFAR-10 model. Each curve corresponds to a different time step discretization, defined for N = 64 and a specific choice for the polynomial exponent \u03c1. The values represent the root mean square error (RMSE) between one Euler iteration and a sequence of multiple smaller Euler iterations, representing the ground truth. The shaded regions, barely visible at low \u03c3, represent standard deviation over different latents x 0 . (b) Corresponding error curves for Heun's 2 nd order method (Algorithm 1). (c) FID (y-axis) as a function of the polynomial exponent (x-axis) for different models, measured using Heun's 2 nd order method. The shaded regions indicate the range of variation between the lowest and highest observed FID, and the dots indicate the value of \u03c1 that we use in all other experiments.", "figure_data": ""}, {"figure_label": "10", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Uncond. CIFAR- 10 ,10Pre-trained, VP, Snoise = 1.000 Uncond. CIFAR-10, Pre-trained, VP, Snoise = 1.007", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "Cond. ImageNet-64, Pre-trained, Snoise = 1.000Cond. ImageNet-64, Pre-trained, Snoise = 1.003", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "Uncond. CIFAR-10, VP (b) Uncond. CIFAR-10, VE (c) Class-cond. ImageNet-64", "figure_data": ""}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "Evaluation of our training improvements. The starting point (config A) is VP & VE using our deterministic sampler. At the end (configs E,F), VP & VE only differ in the architecture of F \u03b8 .", "figure_data": "CIFAR-10 [29] at 32\u00d732FFHQ [27] 64\u00d764AFHQv2 [7] 64\u00d764ConditionalUnconditionalUnconditionalUnconditionalTraining configurationVPVEVPVEVPVEVPVEA Baseline [49] (  *  pre-trained)2.48 3.113.01  *  3.77  *3.3925.952.5818.52B + Adjust hyperparameters2.18 2.482.51 2.943.1322.532.4323.12C + Redistribute capacity2.08 2.522.31 2.832.7841.622.5415.04D + Our preconditioning2.09 2.642.29 3.102.943.392.793.81E + Our loss function1.88 1.862.05 1.992.602.812.292.28F + Non-leaky augmentation1.79 1.791.97 1.982.392.531.962.16NFE3535353579797979"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "For example, in ImageNet-64 our sampler turned an average model (FID 2.07) to a challenger(1.55)  for the previous SOTA model (1.48)[17], and with training improvements achieved SOTA FID of 1.36. We also obtained new state-of-the-art results on CIFAR-10 while using only 35 model evaluations, deterministic sampling, and a small network. The current high-resolution diffusion models rely either on separate super-resolution steps", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "Image quality and FID as a function of NFE using our deterministic sampler. At 32\u00d732 resolution, reasonable image quality is reached around NFE = 13, but FID keeps improving until NFE = 35. At 64\u00d764 resolution, reasonable image quality is reached around NFE = 19, but FID keeps improving until NFE = 79.", "figure_data": "Deterministic, Original sampler (DDIM) Deterministic, Original sampler (p.flow), VP Deterministic, Our sampler & training configuration Deterministic, Our sampler (Alg. 1) Deterministic, Original sampler (p.flow), VE FFHQ, Original training (config A), VP FFHQ, Original training (config A), VEOstrich OstrichOriginal training (config A), VP Original training (config A), VPOstrichOriginal training (config A), VE Original training (config A), VEBeagle Car Beagle Plane Class-conditional ImageNet-64, Pre-trainedBeagle Car PlaneClass-conditional CIFAR-10, Our training, VPBalloon Balloon BirdBalloon BirdCatCatPizza Pizza DeerFID 2.94 NFE 256 Deterministic, Our sampler (Alg. 1), VP FID 3.39 NFE 79 FFHQ, Our training (config F), VPPizza DeerFID 5.45 NFE 8192 FID 25.95 NFE 79 Deterministic, Our sampler (Alg. 1), VE FFHQ, Our training (config F), VEAgaric Daisy Valley Agaric Daisy Dog Valley Truck Ship Horse Frog FID 87.16 NFE 712.39 113.56 192.66 79Agaric Daisy Valley Dog Truck Ship Horse Frog85.46 35.47 14.32 6.72 7 9 11 134.22 152.48 191.86 271.79 35FID 2.91 NFE 250 FID 3.01 NFE 35 FID 3.01 NFE 35 FID 2.48 NFE 35 FID 2.39 NFE 79FID 2.23 NFE 79FID 2.66 NFE 79 FID 3.82 NFE 27 FID 3.77 NFE 35 FID 3.11 NFE 35 FID 2.53 NFE 79Unconditional FFHQ, Our training, VPUnconditional AFHQv2, Our Training, VPStochastic, Original sampler (iDDPM) Stochastic, Our sampler & training configuration Stochastic, Our sampler (Alg. 2) Stochastic, Original sampler (E-M), VP Stochastic, Original sampler (P-C), VE Our training (config F), VP Our training (config F), VE Our training (config F), VP Our training (config F), VE AFHQv2, Original training (config A), VP AFHQv2, Original training (config A), VEOstrich Ostrich PlaneOstrich PlaneCarCarBeagle Beagle BirdBeagle BirdBalloon Deer Balloon CatBalloon Deer CatDaisy Valley Pizza Daisy Valley Pizza Dog Truck Ship Horse Frog FID 142.34 Stochastic, Our sampler (Alg. 2), VP FID 2.55 NFE 1024 FID 2.58 NFE 79 AFHQv2, Our training (config F), VP 29.22 5.13 2.39 NFE 7 11 19 79 Figure 12:Daisy Valley Pizza Dog Truck Ship Horse FrogFID 18.52 NFE 79 FID 2.46 NFE 2048 AFHQv2, Our training (config F), VE Stochastic, Our sampler (Alg. 2), VE 61.57 13.68 3.00 1.96 7 11 19 79Agaric AgaricFID 1.97 NFE 35 FID 1.79 NFE 35AgaricFID 1.98 NFE 35 FID 1.79 NFE 35FID 2.01 NFE 512 FID 2.27 NFE 511 FID 1.96 NFE 79FID 1.36 NFE 511FID 1.55 NFE 1023 FID 2.23 NFE 2047 FID 2.16 NFE 79Figure 7: Results for our training configuration on class-conditional ImageNet [8] at 64\u00d764 resolution,using our deterministic and stochastic samplers."}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "Evaluation of our improvements to deterministic sampling. The values correspond to the curves shown in Figure", "figure_data": ""}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "Evaluation and ablations of our improvements to stochastic sampling. The values correspond to the curves shown in Figure4.", "figure_data": "Unconditional CIFAR-10 at 32\u00d732Class-conditionalVPVEImageNet-64Sampling methodFID \u2193 NFE \u2193FID \u2193 NFE \u2193FID \u2193 NFE \u2193Deterministic baseline (Alg. 1)2.93353.73272.6479Alg. 2, Stmin,tmax = [0, \u221e], Snoise = 12.69952.973831.86383Alg. 2, Stmin,tmax = [0, \u221e]2.541272.515111.63767Alg. 2, Snoise = 12.52952.841911.84255Alg. 2, Optimal settings2.273832.237671.55511Previous work [49, 9]2.557682.4610242.01384"}, {"figure_label": "5", "figure_type": "table", "figure_id": "tab_8", "figure_caption": "Parameters used for the stochastic sampling experiments in Section 4. .001, . . . , 1.009, 1.010", "figure_data": "ParameterCIFAR-10 VP VEImageNet Pre-trained Our modelGrid searchSchurn308080400, 10, 20, 30, . . . , 70, 80, 90, 100Stmin0.010.050.050.050, 0.005, 0.01, 0.02, . . . , 1, 2, 5, 10Stmax1150500.2, 0.5, 1, 2, . . . , 10, 20, 50, 80Snoise1.0071.0071.0031.0031.000, 1"}, {"figure_label": "6", "figure_type": "table", "figure_id": "tab_9", "figure_caption": "Our augmentation pipeline. Each training image undergoes a combined geometric transformation based on 8 random parameters that receive non-zero values with a certain probability. The model is conditioned with an additional 9-dimensional input vector derived from these parameters.", "figure_data": "Augmentation TransformationParametersProb.Conditioning Constantsx-flipSCALE2D 1 \u2212 2a0, 1a0 \u223c U{0, 1}100% a0Aprob = 12%y-flipSCALE2D 1, 1 \u2212 2a1a1 \u223c U{0, 1}Aproba1or 15%ScalingSCALE2D (Ascale) a 2 ,a2 \u223c N (0, 1)Aproba2Ascale = 2 0.2(Ascale) a 2RotationROTATE2D \u2212a3a3 \u223c U (\u2212\u03c0, \u03c0)Aprobcos a3 \u2212 1sin a3AnisotropyROTATE2D a4a4 \u223c U (\u2212\u03c0, \u03c0)Aproba5 cos a4Aaniso = 2 0.2SCALE2D (Aaniso) a 5 ,a5 \u223c N (0, 1)a5 sin a41/(Aaniso) a 5ROTATE2D \u2212a4TranslationTRANSLATE2D (Atrans)a6,a6 \u223c N (0, 1)Aproba6Atrans = 1/8(Atrans)a7a7 \u223c N (0, 1)a7"}, {"figure_label": "7", "figure_type": "table", "figure_id": "tab_10", "figure_caption": "Hyperparameters used for the training runs in Section 5.", "figure_data": "HyperparameterCIFAR-10 BaselineOursFFHQ & AFHQv2 Baseline OursImagetNet OursNumber of GPUs484832Duration (Mimg)2002002002002500Minibatch size1285121282564096Gradient clipping---Mixed-precision (FP16)----Learning rate \u00d710 4210221LR ramp-up (Mimg)0.64100.641010EMA half-life (Mimg)0.89 / 0.90.50.89 / 0.90.550(VP / VE)(VP / VE)Dropout probability10%13%10%5% / 25%10%(FFHQ / AFHQ)Channel multiplier128128128128192Channels per resolution1-2-2-22-2-21-1-2-2-21-2-2-21-2-3-4Dataset x-flips---Augment probability-12%-15%-"}], "formulas": [{"formula_id": "formula_1", "formula_text": "t i<N 1 + i N \u22121 ( s \u2212 1) \u03c3 2 max \u03c3 2 min /\u03c3 2 max i N \u22121 u j0+ M \u22121\u2212j 0 N \u22121", "formula_coordinates": [3.0, 160.68, 166.28, 213.45, 14.81]}, {"formula_id": "formula_2", "formula_text": "dx = \u1e61(t) s(t) x \u2212 s(t) 2\u03c3 (t) \u03c3(t) \u2207 x log p x s(t) ; \u03c3(t) dt.(4)", "formula_coordinates": [3.0, 183.82, 557.83, 320.18, 22.34]}, {"formula_id": "formula_3", "formula_text": "4: di \u2190 \u03c3(ti) \u03c3(ti) +\u1e61 (ti) s(ti) xi \u2212\u03c3 (ti)s(ti) \u03c3(ti) D \u03b8 xi s(ti)", "formula_coordinates": [5.0, 111.78, 124.74, 226.1, 19.77]}, {"formula_id": "formula_4", "formula_text": "5: xi+1 \u2190 xi + (ti+1 \u2212 ti)di", "formula_coordinates": [5.0, 111.78, 148.82, 140.6, 8.09]}, {"formula_id": "formula_5", "formula_text": "d i \u2190 \u03c3(ti+1) \u03c3(ti+1) +\u1e61 (ti+1) s(ti+1) xi+1 \u2212\u03c3 (ti+1)s(ti+1) \u03c3(ti+1) D\u03b8 xi+1 s(ti+1)", "formula_coordinates": [5.0, 163.59, 174.81, 220.87, 17.79]}, {"formula_id": "formula_6", "formula_text": "8: xi+1 \u2190 xi + (ti+1 \u2212 ti) 1 2 di + 1 2 d i", "formula_coordinates": [5.0, 111.78, 196.09, 190.37, 11.96]}, {"formula_id": "formula_7", "formula_text": "\u03c3 i<N = \u03c3 max 1 \u03c1 + i N \u22121 (\u03c3 min 1 \u03c1 \u2212 \u03c3 max 1 \u03c1 ) \u03c1 and \u03c3 N = 0. (5", "formula_coordinates": [5.0, 186.28, 410.15, 313.85, 15.56]}, {"formula_id": "formula_8", "formula_text": ")", "formula_coordinates": [5.0, 500.13, 414.43, 3.87, 8.64]}, {"formula_id": "formula_9", "formula_text": "dx \u00b1 = \u2212\u03c3(t)\u03c3(t)\u2207 x log p x; \u03c3(t) dt probability flow ODE (Eq. 1) \u00b1 \u03b2(t)\u03c3(t) 2 \u2207 x log p x; \u03c3(t) dt deterministic noise decay + 2\u03b2(t)\u03c3(t) d\u03c9 t noise injection Langevin diffusion SDE ,(6)", "formula_coordinates": [6.0, 113.65, 496.01, 390.35, 41.84]}, {"formula_id": "formula_10", "formula_text": "2: sample x0 \u223c N 0, t 2 0 I 3: for i \u2208 {0, . . . , N \u2212 1} do \u03b3i = min S churn N , \u221a 2\u22121 if ti\u2208[Stmin,Stmax] 0 otherwise 4: sample i \u223c N 0, S 2 noise I 5:ti \u2190 ti + \u03b3iti Select temporarily increased noise levelti 6:xi \u2190 xi + t 2 i \u2212 t 2 i i", "formula_coordinates": [7.0, 111.78, 100.81, 391.72, 54.55]}, {"formula_id": "formula_11", "formula_text": "di \u2190 xi \u2212 D \u03b8 (xi;ti) /ti", "formula_coordinates": [7.0, 150.14, 157.35, 101.46, 8.37]}, {"formula_id": "formula_12", "formula_text": "d i \u2190 xi+1 \u2212 D \u03b8 (xi+1; ti+1) /ti+1", "formula_coordinates": [7.0, 164.29, 190.22, 138.43, 8.37]}, {"formula_id": "formula_13", "formula_text": "1 2 di + 1 2 d i 12:", "formula_coordinates": [7.0, 108.0, 199.58, 194.86, 20.74]}, {"formula_id": "formula_14", "formula_text": "D \u03b8 (x; \u03c3) = c skip (\u03c3) x + c out (\u03c3) F \u03b8 c in (\u03c3) x; c noise (\u03c3) ,(7)", "formula_coordinates": [8.0, 191.91, 579.03, 312.09, 9.84]}, {"formula_id": "formula_15", "formula_text": "E \u03c3,y,n \u03bb(\u03c3) c out (\u03c3) 2 effective weight F \u03b8 c in (\u03c3) \u2022 (y + n); c noise (\u03c3) network output \u2212 1 cout(\u03c3) y \u2212 c skip (\u03c3) \u2022 (y + n) effective training target 2 2 . (8", "formula_coordinates": [8.0, 114.81, 665.58, 385.31, 30.19]}, {"formula_id": "formula_16", "formula_text": ")", "formula_coordinates": [8.0, 500.13, 669.86, 3.87, 8.64]}, {"formula_id": "formula_17", "formula_text": "dx = f (x, t) dt + g(t) d\u03c9 t ,(9)", "formula_coordinates": [13.0, 248.52, 348.84, 255.49, 9.68]}, {"formula_id": "formula_18", "formula_text": "dx = f (t) x dt + g(t) d\u03c9 t . (10", "formula_coordinates": [13.0, 249.89, 422.3, 249.95, 9.68]}, {"formula_id": "formula_19", "formula_text": ")", "formula_coordinates": [13.0, 499.85, 422.65, 4.15, 8.64]}, {"formula_id": "formula_20", "formula_text": "p 0t x(t) | x(0) = N x(t); s(t) x(0), s(t) 2 \u03c3(t) 2 I ,(11)", "formula_coordinates": [13.0, 194.82, 458.5, 309.18, 11.72]}, {"formula_id": "formula_21", "formula_text": "s(t) = exp t 0 f (\u03be) d\u03be , and \u03c3(t) = t 0 g(\u03be) 2 s(\u03be) 2 d\u03be.(12)", "formula_coordinates": [13.0, 183.9, 500.2, 320.1, 26.29]}, {"formula_id": "formula_22", "formula_text": "p t (x) = R d p 0t (x | x 0 ) p data (x 0 ) dx 0 . (13", "formula_coordinates": [13.0, 226.71, 565.14, 273.14, 17.65]}, {"formula_id": "formula_23", "formula_text": ")", "formula_coordinates": [13.0, 499.85, 565.48, 4.15, 8.64]}, {"formula_id": "formula_24", "formula_text": "dx = f (t) x \u2212 1 2 g(t) 2 \u2207 x log p t (x) dt.(14)", "formula_coordinates": [13.0, 220.1, 612.15, 283.91, 13.66]}, {"formula_id": "formula_25", "formula_text": "p t (x) = R d p 0t (x | x 0 ) p data (x 0 ) dx 0 (15) = R d p data (x 0 ) N x; s(t) x 0 , s(t) 2 \u03c3(t) 2 I dx 0 (16) = R d p data (x 0 ) s(t) \u2212d N x/s(t); x 0 , \u03c3(t) 2 I dx 0 (17) = s(t) \u2212d R d p data (x 0 ) N x/s(t); x 0 , \u03c3(t) 2 I dx 0 (18) = s(t) \u2212d p data * N 0, \u03c3(t) 2 I x/s(t) ,(19)", "formula_coordinates": [21.0, 174.21, 457.16, 329.79, 114.22]}, {"formula_id": "formula_26", "formula_text": "p(x; \u03c3) = p data * N 0, \u03c3(t) 2 I and p t (x) = s(t) \u2212d p x/s(t); \u03c3(t) . (20", "formula_coordinates": [21.0, 154.0, 624.64, 345.85, 11.88]}, {"formula_id": "formula_27", "formula_text": ")", "formula_coordinates": [21.0, 499.85, 627.03, 4.15, 8.64]}, {"formula_id": "formula_28", "formula_text": "dx = f (t)x \u2212 1 2 g(t) 2 \u2207 x log p t (x) dt (21) = f (t)x \u2212 1 2 g(t) 2 \u2207 x log s(t) \u2212d p x/s(t); \u03c3(t) dt (22) = f (t)x \u2212 1 2 g(t) 2 \u2207 x log s(t) \u2212d + \u2207 x log p x/s(t); \u03c3(t) dt (23) = f (t)x \u2212 1 2 g(t) 2 \u2207 x log p x/s(t); \u03c3(t) dt.(24)", "formula_coordinates": [21.0, 157.0, 662.19, 347.0, 62.6]}, {"formula_id": "formula_29", "formula_text": "exp t 0 f (\u03be) d\u03be = s(t)(25)", "formula_coordinates": [22.0, 223.59, 94.19, 280.41, 26.29]}, {"formula_id": "formula_30", "formula_text": "t 0 f (\u03be) d\u03be = log s(t)(26)", "formula_coordinates": [22.0, 260.68, 123.03, 243.32, 26.29]}, {"formula_id": "formula_31", "formula_text": "d t 0 f (\u03be) d\u03be dt = d log s(t) /dt (27) f (t) =\u1e61(t)/s(t).(28)", "formula_coordinates": [22.0, 222.54, 151.47, 281.46, 38.93]}, {"formula_id": "formula_32", "formula_text": "t 0 g(\u03be) 2 s(\u03be) 2 d\u03be = \u03c3(t)(29)", "formula_coordinates": [22.0, 249.89, 230.01, 254.11, 26.29]}, {"formula_id": "formula_33", "formula_text": "t 0 g(\u03be) 2 s(\u03be) 2 d\u03be = \u03c3(t) 2 (30", "formula_coordinates": [22.0, 249.89, 260.36, 249.97, 26.29]}, {"formula_id": "formula_34", "formula_text": ")", "formula_coordinates": [22.0, 499.85, 269.73, 4.15, 8.64]}, {"formula_id": "formula_35", "formula_text": "d t 0 g(\u03be) 2 s(\u03be) 2 d\u03be dt = d \u03c3(t) 2 /dt (31", "formula_coordinates": [22.0, 211.75, 289.05, 288.1, 26.29]}, {"formula_id": "formula_36", "formula_text": ")", "formula_coordinates": [22.0, 499.85, 298.43, 4.15, 8.64]}, {"formula_id": "formula_37", "formula_text": "g(t) 2 /s(t) 2 = 2\u03c3(t) \u03c3(t)(32)", "formula_coordinates": [22.0, 250.47, 318.1, 253.53, 11.03]}, {"formula_id": "formula_38", "formula_text": "g(t)/s(t) = 2\u03c3(t) \u03c3(t)(33)", "formula_coordinates": [22.0, 259.41, 336.45, 244.59, 8.96]}, {"formula_id": "formula_39", "formula_text": "g(t) = s(t) 2\u03c3(t) \u03c3(t).(34)", "formula_coordinates": [22.0, 280.4, 352.78, 223.6, 8.96]}, {"formula_id": "formula_40", "formula_text": "dx = [f (t)] x \u2212 1 2 [g(t)] 2 \u2207 x log p x/s(t); \u03c3(t) dt (35", "formula_coordinates": [22.0, 147.67, 396.44, 352.18, 13.67]}, {"formula_id": "formula_41", "formula_text": ")", "formula_coordinates": [22.0, 499.85, 398.83, 4.15, 8.64]}, {"formula_id": "formula_42", "formula_text": "= \u1e61(t)/s(t) x \u2212 1 2 s(t) 2\u03c3(t) \u03c3(t) 2 \u2207 x log p x/s(t); \u03c3(t) dt (36", "formula_coordinates": [22.0, 169.73, 413.47, 330.12, 18.55]}, {"formula_id": "formula_43", "formula_text": ")", "formula_coordinates": [22.0, 499.85, 420.75, 4.15, 8.64]}, {"formula_id": "formula_44", "formula_text": "= \u1e61(t)/s(t) x \u2212 1 2 2 s(t) 2\u03c3 (t) \u03c3(t) \u2207 x log p x/s(t); \u03c3(t) dt (37) = \u1e61(t) s(t) x \u2212 s(t) 2\u03c3 (t) \u03c3(t) \u2207 x log p x s(t)", "formula_coordinates": [22.0, 169.73, 446.25, 334.27, 45.54]}, {"formula_id": "formula_46", "formula_text": "dx = \u2212\u03c3(t) \u03c3(t) \u2207 x log p x; \u03c3(t) dt. (39", "formula_coordinates": [22.0, 226.87, 529.98, 272.98, 9.68]}, {"formula_id": "formula_47", "formula_text": ")", "formula_coordinates": [22.0, 499.85, 530.33, 4.15, 8.64]}, {"formula_id": "formula_48", "formula_text": "p data (x) = 1 Y Y i=1 \u03b4 x \u2212 y i ,(40)", "formula_coordinates": [22.0, 247.22, 695.01, 256.78, 30.32]}, {"formula_id": "formula_49", "formula_text": "p(x; \u03c3) = p data * N 0, \u03c3(t) 2 I (41) = R d p data (x 0 ) N x; x 0 , \u03c3 2 I dx 0 (42) = R d 1 Y Y i=1 \u03b4 x 0 \u2212 y i N x; x 0 , \u03c3 2 I dx 0 (43) = 1 Y Y i=1 R d N x; x 0 , \u03c3 2 I \u03b4 x 0 \u2212 y i dx 0 (44) = 1 Y Y i=1 N x; y i , \u03c3 2 I . (45", "formula_coordinates": [23.0, 182.27, 92.82, 321.73, 144.2]}, {"formula_id": "formula_50", "formula_text": ")", "formula_coordinates": [23.0, 499.85, 217.43, 4.15, 8.64]}, {"formula_id": "formula_51", "formula_text": "L(D; \u03c3) = E y\u223cpdata E n\u223cN (0,\u03c3 2 I) D(y + n; \u03c3) \u2212 y 2 2 (46) = E y\u223cpdata E x\u223cN (y,\u03c3 2 I) D(x; \u03c3) \u2212 y 2 2 (47) = E y\u223cpdata R d N (x; y, \u03c3 2 I) D(x; \u03c3) \u2212 y 2 2 dx (48) = 1 Y Y i=1 R d N (x; y i , \u03c3 2 I) D(x; \u03c3) \u2212 y i 2 2 dx (49) = R d 1 Y Y i=1 N (x; y i , \u03c3 2 I) D(x; \u03c3) \u2212 y i 2 2 =: L(D;x,\u03c3) dx.(50)", "formula_coordinates": [23.0, 174.57, 278.97, 329.43, 144.33]}, {"formula_id": "formula_52", "formula_text": "D(x; \u03c3) = arg min D(x;\u03c3) L(D; x, \u03c3). (51", "formula_coordinates": [23.0, 229.32, 458.0, 270.53, 10.62]}, {"formula_id": "formula_53", "formula_text": ")", "formula_coordinates": [23.0, 499.85, 458.35, 4.15, 8.64]}, {"formula_id": "formula_54", "formula_text": "0 = \u2207 D(x;\u03c3) L(D; x, \u03c3)(52)", "formula_coordinates": [23.0, 186.91, 511.07, 317.09, 9.99]}, {"formula_id": "formula_55", "formula_text": "0 = \u2207 D(x;\u03c3) 1 Y Y i=1 N (x; y i , \u03c3 2 I) D(x; \u03c3) \u2212 y i 2 2 (53) 0 = Y i=1 N (x; y i , \u03c3 2 I) \u2207 D(x;\u03c3) D(x; \u03c3) \u2212 y i 2 2 (54) 0 = Y i=1 N (x; y i , \u03c3 2 I) 2 D(x; \u03c3) \u2212 2 y i (55) 0 = Y i=1 N (x; y i , \u03c3 2 I) D(x; \u03c3) \u2212 Y i=1 N (x; y i , \u03c3 2 I) y i(56)", "formula_coordinates": [23.0, 186.91, 529.37, 317.09, 135.18]}, {"formula_id": "formula_56", "formula_text": "D(x; \u03c3) = i N (x; y i , \u03c3 2 I) y i i N (x; y i , \u03c3 2 I) ,(57)", "formula_coordinates": [23.0, 159.32, 667.9, 344.68, 26.43]}, {"formula_id": "formula_57", "formula_text": "\u2207 x log p(x; \u03c3) = \u2207 x p(x; \u03c3) p(x; \u03c3) (58) = \u2207 x 1 Y i N x; y i , \u03c3 2 I 1 Y i N x; y i , \u03c3 2 I (59", "formula_coordinates": [24.0, 204.72, 91.91, 299.28, 63.82]}, {"formula_id": "formula_58", "formula_text": ") = i \u2207 x N x; y i , \u03c3 2 I i N x; y i , \u03c3 2 I . (60", "formula_coordinates": [24.0, 273.2, 134.09, 230.8, 54.86]}, {"formula_id": "formula_59", "formula_text": ")", "formula_coordinates": [24.0, 499.85, 170.76, 4.15, 8.64]}, {"formula_id": "formula_60", "formula_text": "\u2207 x N x; y i , \u03c3 2 I = \u2207 x 2\u03c0\u03c3 2 \u2212 d 2 exp x \u2212 y i 2 2 \u22122 \u03c3 2 (61) = 2\u03c0\u03c3 2 \u2212 d 2 \u2207 x exp x \u2212 y i 2 2 \u22122 \u03c3 2 (62) = 2\u03c0\u03c3 2 \u2212 d 2 exp x \u2212 y i 2 2 \u22122 \u03c3 2 \u2207 x x \u2212 y i 2 2 \u22122 \u03c3 2 (63) = N x; y i , \u03c3 2 I \u2207 x x \u2212 y i 2 2 \u22122 \u03c3 2 (64) = N x; y i , \u03c3 2 I y i \u2212 x \u03c3 2 . (65", "formula_coordinates": [24.0, 157.58, 218.38, 346.42, 156.39]}, {"formula_id": "formula_61", "formula_text": ")", "formula_coordinates": [24.0, 499.85, 359.52, 4.15, 8.64]}, {"formula_id": "formula_62", "formula_text": "\u2207 x log p(x; \u03c3) = i \u2207 x N x; y i , \u03c3 2 I i N x; y i , \u03c3 2 I (66", "formula_coordinates": [24.0, 189.49, 403.53, 310.36, 27.46]}, {"formula_id": "formula_63", "formula_text": ") = i N x; y i , \u03c3 2 I y i \u2212x \u03c3 2 i N x; y i , \u03c3 2 I (67", "formula_coordinates": [24.0, 257.97, 412.79, 246.03, 54.86]}, {"formula_id": "formula_64", "formula_text": ") = i N x; y i , \u03c3 2 I y i i N x; y i , \u03c3 2 I \u2212 x \u03c3 2 . (68", "formula_coordinates": [24.0, 257.97, 449.45, 246.03, 50.48]}, {"formula_id": "formula_65", "formula_text": ")", "formula_coordinates": [24.0, 499.85, 481.73, 4.15, 8.64]}, {"formula_id": "formula_66", "formula_text": "\u2207 x log p(x; \u03c3) = D(x; \u03c3) \u2212 x /\u03c3 2 ,(69)", "formula_coordinates": [24.0, 229.26, 527.52, 274.74, 11.72]}, {"formula_id": "formula_67", "formula_text": "\u2207 x log p x/s(t); \u03c3(t) (70) = \u2207 [s(t)x] log p [s(t)x]/s(t); \u03c3(t) (71) = \u2207 s(t)x log p x; \u03c3(t)(72)", "formula_coordinates": [24.0, 234.52, 618.09, 269.48, 41.92]}, {"formula_id": "formula_68", "formula_text": "= 1 s(t) \u2207x log p x; \u03c3(t) . (73", "formula_coordinates": [24.0, 234.52, 664.17, 265.33, 13.47]}, {"formula_id": "formula_69", "formula_text": ")", "formula_coordinates": [24.0, 499.85, 666.37, 4.15, 8.64]}, {"formula_id": "formula_70", "formula_text": "\u2207 x log p x/s(t); \u03c3(t) = 1 s(t)\u03c3(t) 2 D x; \u03c3(t) \u2212x . (74", "formula_coordinates": [24.0, 194.46, 709.82, 305.39, 13.47]}, {"formula_id": "formula_71", "formula_text": ")", "formula_coordinates": [24.0, 499.85, 712.02, 4.15, 8.64]}, {"formula_id": "formula_72", "formula_text": "dx = \u1e61(t) x/s(t) \u2212 s(t) 2\u03c3 (t) \u03c3(t) 1 s(t)\u03c3(t) 2 D \u03b8 x; \u03c3(t) \u2212x dt (75) = \u1e61(t) s(t) x \u2212\u03c3 (t)s(t) \u03c3(t) D \u03b8 x; \u03c3(t) \u2212x dt.(76)", "formula_coordinates": [25.0, 152.41, 104.6, 351.59, 35.58]}, {"formula_id": "formula_73", "formula_text": "dx = \u1e61(t) s(t) x \u2212\u03c3 (t)s(t) \u03c3(t) D \u03b8 [x]; \u03c3(t) \u2212 [x] dt (77) = \u1e61(t) s(t) x \u2212\u03c3 (t)s(t) \u03c3(t) D \u03b8 [x/s(t)]; \u03c3(t) \u2212 [x/s(t)] dt (78) = \u1e61(t) s(t) x \u2212\u03c3 (t)s(t) \u03c3(t) D \u03b8 x/s(t); \u03c3(t) +\u03c3 (t) \u03c3(t) x dt (79) = \u03c3(t) \u03c3(t) +\u1e61 (t) s(t) x \u2212\u03c3 (t)s(t) \u03c3(t) D \u03b8 x/s(t); \u03c3(t) dt.(80)", "formula_coordinates": [25.0, 174.72, 172.5, 329.28, 80.14]}, {"formula_id": "formula_74", "formula_text": "dx/dt = \u03c3(t) \u03c3(t) +\u1e61 (t) s(t) x \u2212\u03c3 (t)s(t) \u03c3(t) D \u03b8 x s(t) ; \u03c3(t) ,(81)", "formula_coordinates": [25.0, 191.39, 282.9, 312.61, 22.34]}, {"formula_id": "formula_75", "formula_text": "\u2202q(x, t) \u2202t = \u03ba(t)\u2206 x q(x, t). (82", "formula_coordinates": [25.0, 252.53, 592.76, 247.31, 22.31]}, {"formula_id": "formula_76", "formula_text": ")", "formula_coordinates": [25.0, 499.85, 599.81, 4.15, 8.64]}, {"formula_id": "formula_78", "formula_text": "q(x, t) = p x; \u03c3(t) = p data (x) * N 0, \u03c3(t) 2 I (84) q(\u03bd, t) =p data (\u03bd) exp \u2212 1 2 |\u03bd| 2 \u03c3(t) 2 . (85", "formula_coordinates": [25.0, 200.19, 690.7, 568.56, 32.59]}, {"formula_id": "formula_79", "formula_text": ")", "formula_coordinates": [25.0, 499.85, 712.02, 4.15, 8.64]}, {"formula_id": "formula_80", "formula_text": "\u2202q(\u03bd, t) \u2202t = \u2212\u03c3(t)\u03c3(t) |\u03bd| 2p data (\u03bd) exp \u2212 1 2 |\u03bd| 2 \u03c3(t) 2 (86) = \u2212\u03c3(t)\u03c3(t) |\u03bd| 2q (\u03bd, t).(87)", "formula_coordinates": [26.0, 182.93, 93.42, 321.07, 35.12]}, {"formula_id": "formula_81", "formula_text": "\u2212\u03ba(t)|\u03bd| 2q (\u03bd, t) = \u2212\u03c3(t)\u03c3(t) |\u03bd| 2q (\u03bd, t) (88) \u03ba(t) =\u03c3(t)\u03c3(t). (89", "formula_coordinates": [26.0, 212.53, 170.99, 291.47, 24.93]}, {"formula_id": "formula_82", "formula_text": ")", "formula_coordinates": [26.0, 499.85, 187.28, 4.15, 8.64]}, {"formula_id": "formula_84", "formula_text": "Given an SDE dx = f (x, t) dt + g(x, t) d\u03c9 t ,(91)", "formula_coordinates": [26.0, 108.0, 301.47, 396.0, 21.23]}, {"formula_id": "formula_85", "formula_text": "\u2202r(x, t) \u2202t = \u2212\u2207 x \u2022 f (x, t) r(x, t) + 1 2 \u2207 x \u2207 x : D(x, t) r(x, t) ,(92)", "formula_coordinates": [26.0, 173.11, 347.53, 330.89, 22.31]}, {"formula_id": "formula_86", "formula_text": "\u2202r(x, t) \u2202t = \u2212\u2207 x \u2022 f (x, t) r(x, t) + 1 2 g(t) 2 \u2206 x r(x, t). (93", "formula_coordinates": [26.0, 191.24, 406.37, 308.62, 22.31]}, {"formula_id": "formula_87", "formula_text": ")", "formula_coordinates": [26.0, 499.85, 413.43, 4.15, 8.64]}, {"formula_id": "formula_88", "formula_text": "\u2212\u2207 x \u2022 f (x, t) q(x, t) + 1 2 g(t) 2 \u2206 x q(x, t) =\u03c3(t) \u03c3(t) \u2206 x q(x, t)(94)", "formula_coordinates": [26.0, 133.13, 470.09, 370.87, 13.66]}, {"formula_id": "formula_89", "formula_text": "\u2207 x \u2022 f (x, t) q(x, t) = 1 2 g(t) 2 \u2212\u03c3(t) \u03c3(t) \u2206 x q(x, t). (95", "formula_coordinates": [26.0, 226.41, 489.02, 273.45, 13.66]}, {"formula_id": "formula_90", "formula_text": ")", "formula_coordinates": [26.0, 499.85, 491.42, 4.15, 8.64]}, {"formula_id": "formula_91", "formula_text": "\u2207 x \u2022 \u2207 x = \u2206 x .", "formula_coordinates": [26.0, 443.78, 530.06, 61.97, 9.65]}, {"formula_id": "formula_92", "formula_text": "\u2207 x \u2022 \u03c5(t) \u2207 x q(x, t) = 1 2 g(t) 2 \u2212\u03c3(t) \u03c3(t) \u2206 x q(x, t)(96)", "formula_coordinates": [26.0, 180.76, 570.0, 323.24, 13.66]}, {"formula_id": "formula_93", "formula_text": "\u03c5(t) \u2206 x q(x, t) = 1 2 g(t) 2 \u2212\u03c3(t) \u03c3(t) \u2206 x q(x, t)(97)", "formula_coordinates": [26.0, 208.19, 591.91, 295.81, 13.66]}, {"formula_id": "formula_94", "formula_text": "\u03c5(t) = 1 2 g(t) 2 \u2212\u03c3(t) \u03c3(t). (98", "formula_coordinates": [26.0, 251.77, 610.98, 248.08, 13.66]}, {"formula_id": "formula_95", "formula_text": ")", "formula_coordinates": [26.0, 499.85, 613.37, 4.15, 8.64]}, {"formula_id": "formula_96", "formula_text": "f (x, t) = \u03c5(t) \u2207 x q(x, t) q(x, t)(99)", "formula_coordinates": [26.0, 201.62, 666.25, 302.38, 22.31]}, {"formula_id": "formula_97", "formula_text": "= 1 2 g(t) 2 \u2212\u03c3(t) \u03c3(t) \u2207 x log q(x, t). ((100)", "formula_coordinates": [26.0, 240.69, 694.09, 263.31, 29.21]}, {"formula_id": "formula_98", "formula_text": ")101", "formula_coordinates": [26.0, 486.74, 712.02, 17.26, 8.64]}, {"formula_id": "formula_99", "formula_text": "dx = 1 2 g(t) 2 \u2212\u03c3(t) \u03c3(t) \u2207 x log p x; \u03c3(t) dt + g(t) d\u03c9 t .(102)", "formula_coordinates": [27.0, 178.14, 109.85, 325.86, 13.67]}, {"formula_id": "formula_100", "formula_text": "dx + = \u2212\u03c3(t)\u03c3(t)\u2207 x log p x; \u03c3(t) dt + \u03b2(t)\u03c3(t) 2 \u2207 x log p x; \u03c3(t) dt + 2\u03b2(t)\u03c3(t) d\u03c9 t . (103", "formula_coordinates": [27.0, 118.54, 186.96, 381.14, 21.94]}, {"formula_id": "formula_101", "formula_text": ")", "formula_coordinates": [27.0, 499.68, 200.26, 4.32, 8.64]}, {"formula_id": "formula_102", "formula_text": "L(D \u03b8 ; \u03c3) = E y\u223cpdata E n\u223cN (0,\u03c3 2 I) D \u03b8 (y + n; \u03c3) \u2212 y 2 2 . (104", "formula_coordinates": [27.0, 189.89, 402.15, 309.8, 16.11]}, {"formula_id": "formula_103", "formula_text": ")", "formula_coordinates": [27.0, 499.69, 406.43, 4.32, 8.64]}, {"formula_id": "formula_104", "formula_text": "L(D \u03b8 ) = E \u03c3\u223cptrain \u03bb(\u03c3) L(D \u03b8 ; \u03c3) (105) = E \u03c3\u223cptrain \u03bb(\u03c3) E y\u223cpdata E n\u223cN (0,\u03c3 2 I) D \u03b8 (y + n; \u03c3) \u2212 y 2 2 (106) = E \u03c3\u223cptrain E y\u223cpdata E n\u223cN (0,\u03c3 2 I) \u03bb(\u03c3) D \u03b8 (y + n; \u03c3) \u2212 y 2 2 (107) = E \u03c3,y,n \u03bb(\u03c3) D \u03b8 (y + n; \u03c3) \u2212 y 2 2 ,(108)", "formula_coordinates": [27.0, 156.2, 444.23, 347.81, 74.91]}, {"formula_id": "formula_105", "formula_text": "E \u03c3,y,n \u03bb(\u03c3) c skip (\u03c3)(y+n) + c out (\u03c3)F \u03b8 c in (\u03c3)(y+n); c noise (\u03c3) \u2212 y 2 2 (109) = E \u03c3,y,n \u03bb(\u03c3) c out (\u03c3)F \u03b8 c in (\u03c3)(y+n); c noise (\u03c3) \u2212 y \u2212 c skip (\u03c3)(y + n) 2 2 (110) = E \u03c3,y,n \u03bb(\u03c3)c out (\u03c3) 2 F \u03b8 c in (\u03c3)(y+n); c noise (\u03c3) \u2212 1 cout(\u03c3) y \u2212 c skip (\u03c3)(y+n) 2 2 (111) = E \u03c3,y,n w(\u03c3) F \u03b8 c in (\u03c3)(y+n); c noise (\u03c3) \u2212 F target (y, n; \u03c3) 2 2 ,(112)", "formula_coordinates": [27.0, 140.43, 559.84, 363.57, 81.86]}, {"formula_id": "formula_106", "formula_text": "= 1 cout(\u03c3) y \u2212 c skip (\u03c3)(y + n) ,(113)", "formula_coordinates": [27.0, 324.76, 676.01, 179.24, 13.47]}, {"formula_id": "formula_107", "formula_text": "Var y,n c in (\u03c3)(y + n) = 1 (114) c in (\u03c3) 2 Var y,n y + n = 1 (115) c in (\u03c3) 2 \u03c3 2 data + \u03c3 2 = 1 (116) c in (\u03c3) = 1 \u03c3 2 + \u03c3 2 data . (117", "formula_coordinates": [28.0, 211.69, 91.88, 292.31, 63.65]}, {"formula_id": "formula_108", "formula_text": ")", "formula_coordinates": [28.0, 499.69, 144.64, 4.32, 8.64]}, {"formula_id": "formula_109", "formula_text": "Var y,n 1 cout(\u03c3) y \u2212 c skip (\u03c3)(y + n) = 1 (119) 1 cout(\u03c3) 2 Var y,n y \u2212 c skip (\u03c3)(y + n) = 1 (120) c out (\u03c3) 2 = Var y,n y \u2212 c skip (\u03c3)(y + n) (121) c out (\u03c3) 2 = Var y,n 1 \u2212 c skip (\u03c3) y + c skip (\u03c3) n (122) c out (\u03c3) 2 = 1 \u2212 c skip (\u03c3) 2 \u03c3 2 data + c skip (\u03c3) 2 \u03c3 2 . (123", "formula_coordinates": [28.0, 135.86, 202.26, 368.14, 89.25]}, {"formula_id": "formula_110", "formula_text": ")", "formula_coordinates": [28.0, 499.68, 281.05, 4.32, 8.64]}, {"formula_id": "formula_111", "formula_text": "c skip (\u03c3) = arg min cskip(\u03c3) c out (\u03c3). (124", "formula_coordinates": [28.0, 240.29, 324.78, 259.39, 10.59]}, {"formula_id": "formula_112", "formula_text": ")", "formula_coordinates": [28.0, 499.68, 325.09, 4.32, 8.64]}, {"formula_id": "formula_113", "formula_text": "c skip (\u03c3) = arg min cskip(\u03c3) c out (\u03c3) 2 . (125", "formula_coordinates": [28.0, 238.06, 355.25, 261.63, 12.67]}, {"formula_id": "formula_114", "formula_text": ")", "formula_coordinates": [28.0, 499.69, 357.64, 4.32, 8.64]}, {"formula_id": "formula_115", "formula_text": "0 = d c out (\u03c3) 2 /dc skip (\u03c3) (126) 0 = d 1 \u2212 c skip (\u03c3) 2 \u03c3 2 data + c skip (\u03c3) 2 \u03c3 2 /dc skip (\u03c3)(127)", "formula_coordinates": [28.0, 176.57, 400.61, 327.43, 31.78]}, {"formula_id": "formula_116", "formula_text": "0 = \u03c3 2 data d 1 \u2212 c skip (\u03c3) 2 /dc skip (\u03c3) + \u03c3 2 d c skip (\u03c3) 2 /dc skip (\u03c3)(128)", "formula_coordinates": [28.0, 176.57, 439.57, 327.43, 14.74]}, {"formula_id": "formula_117", "formula_text": "0 = \u03c3 2 data 2 c skip (\u03c3) \u2212 2 + \u03c3 2 2 c skip (\u03c3)(129)", "formula_coordinates": [28.0, 176.57, 460.53, 327.43, 12.85]}, {"formula_id": "formula_118", "formula_text": "0 = \u03c3 2 + \u03c3 2 data c skip (\u03c3) \u2212 \u03c3 2 data (130", "formula_coordinates": [28.0, 176.57, 476.61, 323.12, 12.85]}, {"formula_id": "formula_119", "formula_text": ")", "formula_coordinates": [28.0, 499.68, 479.0, 4.32, 8.64]}, {"formula_id": "formula_120", "formula_text": "c skip (\u03c3) = \u03c3 2 data / \u03c3 2 + \u03c3 2 data . (131", "formula_coordinates": [28.0, 151.31, 492.69, 348.37, 12.85]}, {"formula_id": "formula_121", "formula_text": ")", "formula_coordinates": [28.0, 499.68, 495.08, 4.32, 8.64]}, {"formula_id": "formula_122", "formula_text": "c out (\u03c3) 2 = 1 \u2212 c skip (\u03c3) 2 \u03c3 2 data + c skip (\u03c3) 2 \u03c3 2 (132) c out (\u03c3) 2 = 1 \u2212 \u03c3 2 data \u03c3 2 + \u03c3 2 data 2 \u03c3 2 data + \u03c3 2 data \u03c3 2 + \u03c3 2 data 2 \u03c3 2 (133) c out (\u03c3) 2 = \u03c3 2 \u03c3 data \u03c3 2 + \u03c3 2 data 2 + \u03c3 2 data \u03c3 \u03c3 2 + \u03c3 2 data 2 (134) c out (\u03c3) 2 = \u03c3 2 \u03c3 data 2 + \u03c3 2 data \u03c3 2 \u03c3 2 + \u03c3 2 data 2 (135) c out (\u03c3) 2 = (\u03c3 \u2022 \u03c3 data ) 2 \u03c3 2 + \u03c3 2 data \u03c3 2 + \u03c3 2 data 2 (136) c out (\u03c3) 2 = (\u03c3 \u2022 \u03c3 data ) 2 \u03c3 2 + \u03c3 2 data (137", "formula_coordinates": [28.0, 179.63, 531.8, 324.37, 172.3]}, {"formula_id": "formula_123", "formula_text": ")", "formula_coordinates": [28.0, 499.68, 686.39, 4.32, 8.64]}, {"formula_id": "formula_124", "formula_text": "c out (\u03c3) = \u03c3 \u2022 \u03c3 data \u03c3 2 + \u03c3 2 data . (138", "formula_coordinates": [28.0, 184.1, 711.24, 315.58, 12.59]}, {"formula_id": "formula_125", "formula_text": ")", "formula_coordinates": [28.0, 499.68, 712.95, 4.32, 8.64]}, {"formula_id": "formula_126", "formula_text": "w(\u03c3) = 1 (139) \u03bb(\u03c3) c out (\u03c3) 2 = 1 (140) \u03bb(\u03c3) = 1/c out (\u03c3) 2", "formula_coordinates": [29.0, 214.93, 94.64, 289.07, 39.97]}, {"formula_id": "formula_127", "formula_text": "\u03bb(\u03c3) = 1 \u03c3 \u2022 \u03c3 data \u03c3 2 + \u03c3 2 data 2 (142) \u03bb(\u03c3) = 1 (\u03c3 \u2022 \u03c3 data ) 2 \u03c3 2 + \u03c3 2 data (143", "formula_coordinates": [29.0, 249.41, 137.81, 254.59, 58.07]}, {"formula_id": "formula_128", "formula_text": ")", "formula_coordinates": [29.0, 499.68, 178.17, 4.32, 8.64]}, {"formula_id": "formula_129", "formula_text": "\u03bb(\u03c3) = \u03c3 2 + \u03c3 2 data /(\u03c3 \u2022 \u03c3 data ) 2 . (144", "formula_coordinates": [29.0, 249.41, 198.16, 250.28, 12.85]}, {"formula_id": "formula_130", "formula_text": ")", "formula_coordinates": [29.0, 499.69, 200.55, 4.32, 8.64]}, {"formula_id": "formula_131", "formula_text": "E y,n \u03bb(\u03c3) c skip (\u03c3)(y+n) + c out (\u03c3)F \u03b8 c in (\u03c3)(y+n); c noise (\u03c3) \u2212 y 2 2 (145) = E y,n \u03c3 2 + \u03c3 2 data (\u03c3 \u2022 \u03c3 data ) 2 \u03c3 2 data \u03c3 2 + \u03c3 2 data (y+n) \u2212 y 2 2 (146) = E y,n \u03c3 2 + \u03c3 2 data (\u03c3 \u2022 \u03c3 data ) 2 \u03c3 2 data n \u2212 \u03c3 2 y \u03c3 2 + \u03c3 2 data 2 2 (147) = E y,n 1 \u03c3 2 + \u03c3 2 data \u03c3 data \u03c3 n \u2212 \u03c3 \u03c3 data y 2 2 (148) = 1 \u03c3 2 + \u03c3 2 data E y,n \u03c3 2 data \u03c3 2 n, n + \u03c3 2 \u03c3 2 data y, y \u2212 2 y, n(149)", "formula_coordinates": [29.0, 162.58, 267.07, 341.42, 138.59]}, {"formula_id": "formula_132", "formula_text": "= 1 \u03c3 2 + \u03c3 2 data \u03c3 2 data \u03c3 2 Var(n) =\u03c3 2 + \u03c3 2 \u03c3 2 data Var(y) =\u03c3 2 data \u22122 Cov(y, n) =0 (150) = 1 (151)", "formula_coordinates": [29.0, 162.58, 407.94, 341.42, 47.49]}, {"formula_id": "formula_133", "formula_text": "dx = \u2212 1 2 \u03b2 min + t \u03b2 max \u2212 \u03b2 min x dt + \u03b2 min + t \u03b2 max \u2212 \u03b2 min d\u03c9 t ,(152)", "formula_coordinates": [29.0, 155.85, 709.82, 348.15, 13.47]}, {"formula_id": "formula_134", "formula_text": "f (t) = \u2212 1 2 \u03b2(t), g(t) = \u03b2(t), and \u03b2(t) = \u03b2 max \u2212 \u03b2 min t + \u03b2 min . (153", "formula_coordinates": [30.0, 155.88, 91.49, 343.81, 13.47]}, {"formula_id": "formula_135", "formula_text": ")", "formula_coordinates": [30.0, 499.69, 93.69, 4.32, 8.64]}, {"formula_id": "formula_136", "formula_text": "\u03b1(t) = t 0 \u03b2(\u03be) d\u03be (154", "formula_coordinates": [30.0, 218.14, 131.14, 281.54, 26.29]}, {"formula_id": "formula_137", "formula_text": ") = t 0 \u03b2 max \u2212 \u03b2 min \u03be + \u03b2 min d\u03be (155) = 1 2 \u03b2 max \u2212 \u03b2 min t 2 + \u03b2 min t (156) = 1 2 \u03b2 d t 2 + \u03b2 min t,(157)", "formula_coordinates": [30.0, 245.86, 140.51, 258.14, 77.47]}, {"formula_id": "formula_138", "formula_text": "\u03c3(t) = t 0 g(\u03be) 2 s(\u03be) 2 d\u03be (158", "formula_coordinates": [30.0, 237.3, 241.72, 262.38, 29.48]}, {"formula_id": "formula_139", "formula_text": ")", "formula_coordinates": [30.0, 499.68, 253.38, 4.32, 8.64]}, {"formula_id": "formula_140", "formula_text": "= t 0 \u03b2(\u03be) 2 1/ \u221a e \u03b1(\u03be) 2 d\u03be (159", "formula_coordinates": [30.0, 264.66, 281.97, 235.02, 29.48]}, {"formula_id": "formula_141", "formula_text": ")", "formula_coordinates": [30.0, 499.68, 293.63, 4.32, 8.64]}, {"formula_id": "formula_142", "formula_text": "= t 0 \u03b2(\u03be) 1/e \u03b1(\u03be) d\u03be (160", "formula_coordinates": [30.0, 264.66, 321.97, 235.02, 26.29]}, {"formula_id": "formula_143", "formula_text": ")", "formula_coordinates": [30.0, 499.68, 331.34, 4.32, 8.64]}, {"formula_id": "formula_144", "formula_text": "= t 0\u03b1 (\u03be) e \u03b1(\u03be) d\u03be (161) = e \u03b1(t) \u2212 e \u03b1(0) (162) = e 1 2 \u03b2dt 2 +\u03b2mint \u2212 1,(163)", "formula_coordinates": [30.0, 264.66, 356.45, 239.34, 64.13]}, {"formula_id": "formula_145", "formula_text": "s(t) = exp t 0 f (\u03be) d\u03be (164) = exp t 0 \u2212 1 2 \u03b2(\u03be) d\u03be (165) = exp \u2212 1 2 t 0 \u03b2(\u03be) d\u03be (166) = exp \u2212 1 2 \u03b1(t) (167) = 1/ e \u03b1(t) (168) = 1/ e 1 2 \u03b2dt 2 +\u03b2mint ,(169)", "formula_coordinates": [30.0, 229.54, 444.2, 274.47, 134.91]}, {"formula_id": "formula_146", "formula_text": "s(t) = 1/ \u03c3(t) 2 + 1.(170)", "formula_coordinates": [30.0, 260.63, 609.34, 243.37, 9.79]}, {"formula_id": "formula_147", "formula_text": "t i<N = 1 + i N \u22121 ( s \u2212 1),(171)", "formula_coordinates": [30.0, 253.53, 655.83, 250.47, 13.47]}, {"formula_id": "formula_148", "formula_text": "\u2207 x log p t (x) \u2248 \u2212 1 \u03c3(t) F \u03b8 x; (M \u22121)t score(x;F \u03b8 ,t) ,(172)", "formula_coordinates": [31.0, 220.64, 110.21, 283.35, 29.12]}, {"formula_id": "formula_149", "formula_text": "\u2207 x log p x/s(t); \u03c3(t) \u2248 \u2212 1 [s(t)\u03c3(t)] F \u03b8 x; (M \u22121)t (173", "formula_coordinates": [31.0, 191.74, 202.69, 307.95, 13.47]}, {"formula_id": "formula_150", "formula_text": ")", "formula_coordinates": [31.0, 499.68, 204.89, 4.32, 8.64]}, {"formula_id": "formula_151", "formula_text": "\u2207 [s(t)x] log p [s(t)x]/s(t); \u03c3(t) \u2248 \u2212 1 s(t)\u03c3(t) F \u03b8 [s(t)x]; (M \u22121)t (174", "formula_coordinates": [31.0, 158.49, 220.32, 341.19, 13.47]}, {"formula_id": "formula_152", "formula_text": ") 1 s(t) \u2207x log p x; \u03c3(t) \u2248 \u2212 1 s(t)\u03c3(t) F \u03b8 s(t)x; (M \u22121)t (175", "formula_coordinates": [31.0, 206.85, 222.52, 297.15, 28.91]}, {"formula_id": "formula_153", "formula_text": ")", "formula_coordinates": [31.0, 499.68, 240.16, 4.32, 8.64]}, {"formula_id": "formula_154", "formula_text": "\u2207x log p x; \u03c3(t) \u2248 \u2212 1 \u03c3(t) F \u03b8 s(t)x; (M \u22121)t . (176", "formula_coordinates": [31.0, 221.04, 255.59, 278.64, 13.47]}, {"formula_id": "formula_155", "formula_text": ")", "formula_coordinates": [31.0, 499.68, 257.79, 4.32, 8.64]}, {"formula_id": "formula_156", "formula_text": "D x; \u03c3(t) \u2212x /\u03c3(t) 2 \u2248 \u2212 1 \u03c3(t) F \u03b8 s(t)x; (M \u22121)t (177) D x; \u03c3(t) \u2248x \u2212 \u03c3(t) F \u03b8 s(t)x; (M \u22121)t (178) D x; \u03c3(t) \u2248x \u2212 \u03c3(t) F \u03b8 1 \u221a \u03c3(t) 2 +1 x; (M \u22121)t ,(179)", "formula_coordinates": [31.0, 162.95, 302.17, 341.05, 56.72]}, {"formula_id": "formula_157", "formula_text": "D(x; \u03c3) \u2248x \u2212 \u03c3 F \u03b8 1 \u221a \u03c3 2 +1x ; (M \u22121) \u03c3 \u22121 (\u03c3) . (180", "formula_coordinates": [31.0, 199.91, 389.23, 299.78, 14.73]}, {"formula_id": "formula_158", "formula_text": ")", "formula_coordinates": [31.0, 499.68, 391.62, 4.32, 8.64]}, {"formula_id": "formula_159", "formula_text": "D \u03b8 (x; \u03c3) = 1 \u2022 cskipx \u2212 \u03c3 cout \u2022 F \u03b8 1 \u221a \u03c3 2 +1 cin \u2022x; (M \u22121) \u03c3 \u22121 (\u03c3) cnoise , (181", "formula_coordinates": [31.0, 179.98, 436.29, 319.71, 27.97]}, {"formula_id": "formula_160", "formula_text": ")", "formula_coordinates": [31.0, 499.69, 438.69, 4.32, 8.64]}, {"formula_id": "formula_161", "formula_text": "E t\u223cU ( t ,1),y\u223cpdata,n\u223cN (0,I) \u03c3(t) score s(t) y +\u03c3(t)n; F \u03b8 , t +n 2 2 , (182", "formula_coordinates": [31.0, 158.4, 530.83, 341.28, 16.11]}, {"formula_id": "formula_162", "formula_text": ")", "formula_coordinates": [31.0, 499.68, 535.11, 4.32, 8.64]}, {"formula_id": "formula_163", "formula_text": "E t,y,n s(t)\u03c3(t) score s(t) y + [s(t)\u03c3(t)]n; F \u03b8 , t +n 2 2 (183) = E t,y,n s(t)\u03c3(t) score s(t) y + s(t)\u03c3(t) [n/\u03c3(t)]; F \u03b8 , t + [n/\u03c3(t)] 2 2 (184) = E t,y,n s(t)\u03c3(t) score s(t) (y + n); F \u03b8 , t + n/\u03c3(t) 2 2 . (185", "formula_coordinates": [31.0, 151.39, 584.32, 352.61, 59.94]}, {"formula_id": "formula_164", "formula_text": ")", "formula_coordinates": [31.0, 499.68, 632.44, 4.32, 8.64]}, {"formula_id": "formula_165", "formula_text": "score s(t) x; F \u03b8 , t = 1 s(t)\u03c3(t) 2 D \u03b8 x; \u03c3(t) \u2212 x . (186", "formula_coordinates": [31.0, 198.02, 678.31, 301.66, 13.48]}, {"formula_id": "formula_166", "formula_text": ")", "formula_coordinates": [31.0, 499.68, 680.51, 4.32, 8.64]}, {"formula_id": "formula_167", "formula_text": "E t,y,n s(t)\u03c3(t) 1 s(t)\u03c3(t) 2 D \u03b8 y + n; \u03c3(t) \u2212 (y + n) + 1 \u03c3(t) n 2 2 (187) = E t,y,n 1 \u03c3(t) D \u03b8 y + n; \u03c3(t) \u2212 (y + n) + 1 \u03c3(t) n 2 2 (188) = E t,y,n 1 \u03c3(t) 2 D \u03b8 y + n; \u03c3(t) \u2212 y 2 2 . (189", "formula_coordinates": [32.0, 155.08, 99.04, 348.92, 59.94]}, {"formula_id": "formula_168", "formula_text": ")", "formula_coordinates": [32.0, 499.68, 147.16, 4.32, 8.64]}, {"formula_id": "formula_169", "formula_text": "E \u03c3 \u22121 (\u03c3)\u223cU ( t ,1) ptrain E y,n 1 \u03c3 2 \u03bb D \u03b8 y + n; \u03c3 \u2212 y 2 2 , (190", "formula_coordinates": [32.0, 201.51, 205.35, 298.18, 28.4]}, {"formula_id": "formula_170", "formula_text": ")", "formula_coordinates": [32.0, 499.69, 209.63, 4.32, 8.64]}, {"formula_id": "formula_171", "formula_text": "dx = \u03c3 min \u03c3 max \u03c3 min t 2 log \u03c3 max \u03c3 min d\u03c9 t ,(191)", "formula_coordinates": [32.0, 229.43, 536.25, 274.57, 26.58]}, {"formula_id": "formula_172", "formula_text": "f (t) = 0, g(t) = \u03c3 min 2 log \u03c3 d \u03c3 t d , and \u03c3 d = \u03c3 max /\u03c3 min . (192", "formula_coordinates": [32.0, 178.81, 600.96, 320.88, 12.85]}, {"formula_id": "formula_173", "formula_text": ")", "formula_coordinates": [32.0, 499.69, 603.35, 4.32, 8.64]}, {"formula_id": "formula_174", "formula_text": "s(t) = exp t 0 f (\u03be) d\u03be = exp t 0 0 d\u03be = exp(0) = 1.(193)", "formula_coordinates": [32.0, 174.14, 655.37, 329.86, 26.29]}, {"formula_id": "formula_175", "formula_text": "\u03c3(t) = t 0 g(\u03be) 2 s(\u03be) 2 d\u03be (194) = t 0 \u03c3 min \u221a 2 log \u03c3 d \u03c3 \u03be d 2 1 2 d\u03be (195", "formula_coordinates": [33.0, 215.39, 95.71, 288.61, 69.73]}, {"formula_id": "formula_176", "formula_text": ")", "formula_coordinates": [33.0, 499.68, 147.61, 4.32, 8.64]}, {"formula_id": "formula_177", "formula_text": "= t 0 \u03c3 2 min 2 log \u03c3 d \u03c3 2\u03be d d\u03be (196) = \u03c3 min t 0 log \u03c3 2 d \u03c3 2 d \u03be d\u03be (197) = \u03c3 min \u03c3 2 d t \u2212 \u03c3 2 d 0 (198) = \u03c3 min \u03c3 2t d \u2212 1.(199)", "formula_coordinates": [33.0, 242.75, 176.16, 261.25, 101.02]}, {"formula_id": "formula_178", "formula_text": "x i+1 = x i + 1 2 \u03c3 2 i \u2212\u03c3 2 i+1 \u2207 x logp i (x),(200)", "formula_coordinates": [33.0, 220.29, 377.63, 283.72, 13.66]}, {"formula_id": "formula_179", "formula_text": "where\u03c3 i<N = \u03c3 min \u03c3 max \u03c3 min 1\u2212i/(N \u22121)", "formula_coordinates": [33.0, 107.64, 394.72, 228.05, 34.63]}, {"formula_id": "formula_180", "formula_text": "s(t) = 1, \u03c3(t) = \u221a t, and t i =\u03c3 2 i . (202", "formula_coordinates": [33.0, 224.27, 449.78, 275.41, 19.2]}, {"formula_id": "formula_181", "formula_text": ")", "formula_coordinates": [33.0, 499.68, 458.68, 4.32, 8.64]}, {"formula_id": "formula_182", "formula_text": "x i+1 = x i + (t i+1 \u2212 t i ) d i(203)", "formula_coordinates": [33.0, 152.47, 509.82, 351.53, 9.68]}, {"formula_id": "formula_183", "formula_text": "= x i + (t i+1 \u2212 t i ) \u03c3(t) \u03c3(t) +\u1e61 (t) s(t) x \u2212\u03c3 (t)s(t) \u03c3(t) D x s(t) ; \u03c3(t)(204)", "formula_coordinates": [33.0, 182.4, 524.0, 321.6, 22.34]}, {"formula_id": "formula_184", "formula_text": "= x i + (t i+1 \u2212 t i ) \u03c3(t) \u03c3(t) x \u2212\u03c3 (t) \u03c3(t) D x; \u03c3(t)(205)", "formula_coordinates": [33.0, 182.4, 551.92, 321.6, 22.31]}, {"formula_id": "formula_185", "formula_text": "= x i \u2212 (t i+1 \u2212 t i )\u03c3(t) \u03c3(t) D x; \u03c3(t) \u2212 x \u03c3(t) 2 (206) = x i \u2212 (t i+1 \u2212 t i )\u03c3(t) \u03c3(t) \u2207 x log p x; \u03c3(t)(207)", "formula_coordinates": [33.0, 182.4, 584.49, 321.6, 33.64]}, {"formula_id": "formula_186", "formula_text": "= x i \u2212 (t i+1 \u2212 t i ) 1 2 \u221a t \u221a t \u2207 x log p x; \u03c3(t)(208)", "formula_coordinates": [33.0, 182.4, 618.83, 321.6, 21.2]}, {"formula_id": "formula_187", "formula_text": "= x i + 1 2 (t i \u2212 t i+1 ) \u2207 x log p x; \u03c3(t)(209)", "formula_coordinates": [33.0, 182.4, 644.46, 321.6, 13.47]}, {"formula_id": "formula_188", "formula_text": "= x i + 1 2 \u03c3 2 i \u2212\u03c3 2 i+1 \u2207 x log p x; \u03c3(t) ,(210)", "formula_coordinates": [33.0, 182.4, 660.34, 321.6, 13.67]}, {"formula_id": "formula_190", "formula_text": "F \u03b8 x; \u03c3 = 1 \u03c3 F \u03b8 2x\u22121; log(\u03c3) . (212", "formula_coordinates": [34.0, 234.49, 209.06, 265.19, 13.47]}, {"formula_id": "formula_191", "formula_text": ")", "formula_coordinates": [34.0, 499.69, 211.26, 4.32, 8.64]}, {"formula_id": "formula_192", "formula_text": "[0, 1]. In order to use [\u22121, 1] instead, we replace p t (x) \u2192 p t (2x\u22121), x \u2192 1 2 x + 1 2 and \u03c3 \u2192 1 2 \u03c3: \u2207 [ 1 C.2.", "formula_coordinates": [34.0, 108.0, 264.41, 397.24, 37.72]}, {"formula_id": "formula_193", "formula_text": "dx(t) = (t) \u03b8 x(t) \u03c3(t) 2 + 1 d\u03c3(t),(223)", "formula_coordinates": [35.0, 231.55, 313.99, 272.45, 23.73]}, {"formula_id": "formula_194", "formula_text": "\u03b8 x(t)/ \u03c3(t) 2 + 1 \u2248 n(t)/\u03c3(t) for x(t) = y(t) + n(t).(t)", "formula_coordinates": [35.0, 108.0, 358.49, 396.0, 24.05]}, {"formula_id": "formula_195", "formula_text": "n(t) = x(t) \u2212 y(t) (224) n(t)/\u03c3(t) = x(t) \u2212 y(t) /\u03c3(t)(225)", "formula_coordinates": [35.0, 231.72, 403.51, 272.28, 23.93]}, {"formula_id": "formula_196", "formula_text": "(t) \u03b8 x(t)/ \u03c3(t) 2 + 1 = x(t) \u2212 D \u03b8 x(t); \u03c3(t) /\u03c3(t).(226)", "formula_coordinates": [35.0, 185.96, 433.23, 318.05, 14.3]}, {"formula_id": "formula_197", "formula_text": "(t) x(t)/ \u03c3(t) 2 + 1 = x(t) \u2212 D x(t); \u03c3(t) /\u03c3(t)(227)", "formula_coordinates": [35.0, 167.17, 477.11, 336.83, 11.03]}, {"formula_id": "formula_198", "formula_text": "= \u2212\u03c3(t) D x(t); \u03c3(t) \u2212 x(t) /\u03c3(t) 2 (228) = \u2212\u03c3(t) \u2207 x(t) log p x(t); \u03c3(t) .(229)", "formula_coordinates": [35.0, 267.88, 496.04, 236.12, 30.96]}, {"formula_id": "formula_199", "formula_text": "dx(t) = \u2212\u03c3(t) \u2207 x(t) log p x(t); \u03c3(t) d\u03c3(t),(230)", "formula_coordinates": [35.0, 213.24, 556.41, 290.76, 9.99]}, {"formula_id": "formula_200", "formula_text": "dx = \u2212t \u2207 x log p x; \u03c3(t) dt.(231)", "formula_coordinates": [35.0, 243.71, 592.48, 260.29, 9.68]}, {"formula_id": "formula_201", "formula_text": "q(x t |x t\u22121 ) = N x t ; 1 \u2212 \u03b2 txt\u22121 , \u03b2 t I . (232", "formula_coordinates": [35.0, 213.95, 693.11, 285.74, 9.79]}, {"formula_id": "formula_202", "formula_text": ")", "formula_coordinates": [35.0, 499.68, 693.57, 4.32, 8.64]}, {"formula_id": "formula_203", "formula_text": "q(x t |x 0 ) = N x t ; \u221a\u1fb1 tx0 , (1 \u2212\u1fb1 t ) I , where\u1fb1 t = t s=1 (1 \u2212 \u03b2 s ).(233)", "formula_coordinates": [36.0, 156.67, 91.88, 347.34, 30.2]}, {"formula_id": "formula_204", "formula_text": "\u03b1 t = t s=1 (1 \u2212 \u03b2 s )(234)", "formula_coordinates": [36.0, 258.91, 163.08, 441.04, 30.2]}, {"formula_id": "formula_205", "formula_text": "\u03b1 t =\u1fb1 t\u22121 (1 \u2212 \u03b2 t )(235)", "formula_coordinates": [36.0, 258.91, 197.58, 245.09, 9.65]}, {"formula_id": "formula_206", "formula_text": "\u03b2 t = 1 \u2212\u1fb1 t \u03b1 t\u22121 . (236", "formula_coordinates": [36.0, 259.65, 213.25, 240.03, 19.69]}, {"formula_id": "formula_207", "formula_text": ")", "formula_coordinates": [36.0, 499.68, 216.78, 4.32, 8.64]}, {"formula_id": "formula_208", "formula_text": "\u03b1 t = f (t) f (0) , where f (t) = cos 2 t/T + s 1 + s \u2022 \u03c0 2 ,(237)", "formula_coordinates": [36.0, 200.2, 273.1, 303.8, 22.31]}, {"formula_id": "formula_209", "formula_text": "t = cos 2 t/T + s 1 + s \u2022 \u03c0 2 . (238", "formula_coordinates": [36.0, 257.16, 326.66, 242.53, 22.31]}, {"formula_id": "formula_210", "formula_text": ")", "formula_coordinates": [36.0, 499.69, 333.72, 4.32, 8.64]}, {"formula_id": "formula_211", "formula_text": "\u03b1 t = t s=1 1 \u2212 [\u03b2 s ](239)", "formula_coordinates": [36.0, 210.85, 387.44, 293.15, 30.2]}, {"formula_id": "formula_212", "formula_text": "= t s=1 1 \u2212 min [\u03b2 s ], 0.999) (240) = t s=1 1 \u2212 min 1 \u2212\u1fb1 s \u03b1 s\u22121 , 0.999 (241) = t s=1 max \u1fb1 s \u03b1 s\u22121 , 0.001 .(242)", "formula_coordinates": [36.0, 230.69, 421.79, 273.31, 98.91]}, {"formula_id": "formula_213", "formula_text": "q(x j |x M ) = N x j ; \u1fb1 jx M , (1 \u2212\u1fb1 j ) I ,(243)", "formula_coordinates": [36.0, 152.6, 586.89, 617.75, 11.07]}, {"formula_id": "formula_214", "formula_text": "\u03b1 j = cos 2 (M \u2212 j)/M + C 2 1 + C 2 \u2022 \u03c0 2 , and(244)", "formula_coordinates": [36.0, 188.51, 610.84, 581.85, 23.22]}, {"formula_id": "formula_215", "formula_text": "\u03b1 j = j s=M \u22121 max \u1fb1 j \u03b1 j+1 , C 1 =\u1fb1 j+1 max \u1fb1 j \u03b1 j+1 , C 1 ,(245)", "formula_coordinates": [36.0, 188.51, 638.68, 315.5, 30.94]}, {"formula_id": "formula_216", "formula_text": "\u03b1 j = cos 2 (M \u2212 j)/M + C 2 1 + C 2 \u2022 \u03c0 2 (246) = cos 2 \u03c0 2 (1 + C 2 ) \u2212 j/M 1 + C 2 (247) = cos 2 \u03c0 2 \u2212 \u03c0 2 j M (1 + C 2 ) (248) = sin 2 \u03c0 2 j M (1 + C 2 ) ,(249)", "formula_coordinates": [37.0, 223.66, 94.24, 280.35, 106.91]}, {"formula_id": "formula_217", "formula_text": "p 0t x(u j ) | x(0) = q(x j |x M )(250)", "formula_coordinates": [37.0, 231.7, 257.92, 272.31, 9.68]}, {"formula_id": "formula_218", "formula_text": "N x(u j ); s(t) x(0), s(u j ) 2 \u03c3(u j ) 2 I = N x j ; \u1fb1 jx M , 1 \u2212\u1fb1 j I . (251", "formula_coordinates": [37.0, 145.66, 275.24, 354.02, 13.01]}, {"formula_id": "formula_219", "formula_text": ")", "formula_coordinates": [37.0, 499.69, 277.63, 4.32, 8.64]}, {"formula_id": "formula_220", "formula_text": "N x(u j ); x(0), u 2 j I = N x j ; \u1fb1 j x(0), 1 \u2212\u1fb1 j I . (252", "formula_coordinates": [37.0, 183.81, 327.49, 315.87, 13.01]}, {"formula_id": "formula_221", "formula_text": ")", "formula_coordinates": [37.0, 499.68, 329.88, 4.32, 8.64]}, {"formula_id": "formula_222", "formula_text": "N x(u j ); x(0), u 2 j I = N \u1fb1 j x(u j ); \u1fb1 j x(0), 1 \u2212\u1fb1 j I (253) = N x(u j ); x(0), 1 \u2212\u1fb1 j \u03b1 j I . (254", "formula_coordinates": [37.0, 159.62, 388.11, 344.38, 45.63]}, {"formula_id": "formula_223", "formula_text": ")", "formula_coordinates": [37.0, 499.69, 416.29, 4.32, 8.64]}, {"formula_id": "formula_224", "formula_text": "u 2 j = (1 \u2212\u1fb1 j ) /\u1fb1 j(255)", "formula_coordinates": [37.0, 278.06, 468.84, 225.95, 12.69]}, {"formula_id": "formula_225", "formula_text": "u 2 j\u1fb1 j = 1 \u2212\u1fb1 j (256) u 2 j\u1fb1 j +\u1fb1 j = 1 (257) (u 2 j + 1)\u1fb1 j = 1 (258", "formula_coordinates": [37.0, 240.09, 485.25, 401.37, 45.52]}, {"formula_id": "formula_226", "formula_text": ") \u03b1 j = 1 / (u 2 j + 1).(259)", "formula_coordinates": [37.0, 277.66, 520.46, 403.55, 26.71]}, {"formula_id": "formula_227", "formula_text": "\u03b1 j+1 max(\u1fb1 j /\u1fb1 j+1 , C 1 ) = 1 / (u 2 j + 1) (260) \u03b1 j max(\u1fb1 j\u22121 /\u1fb1 j , C 1 ) = 1 / (u 2 j\u22121 + 1) (261) 1 / (u 2 j + 1) max(\u1fb1 j\u22121 /\u1fb1 j , C 1 ) = 1 / (u 2 j\u22121 + 1) (262) max(\u1fb1 j\u22121 /\u1fb1 j , C 1 ) (u 2 j\u22121 + 1) = u 2 j + 1 (263) u 2 j\u22121 + 1 = (u 2 j + 1) / max(\u1fb1 j\u22121 /\u1fb1 j , C 1 )(264)", "formula_coordinates": [37.0, 160.61, 579.78, 594.06, 78.34]}, {"formula_id": "formula_228", "formula_text": "u j\u22121 = u 2 j + 1 max(\u1fb1 j\u22121 /\u1fb1 j , C 1 ) \u2212 1,(265)", "formula_coordinates": [37.0, 279.95, 665.3, 224.05, 25.89]}, {"formula_id": "formula_229", "formula_text": "(j) \u03b8 x/ \u03c3 2 + 1 = x \u2212 D \u03b8 (x; \u03c3) /\u03c3 (266) D \u03b8 (x; \u03c3) = x \u2212 \u03c3 (j) \u03b8 x/ \u03c3 2 + 1 . (267", "formula_coordinates": [38.0, 203.27, 112.4, 300.73, 36.22]}, {"formula_id": "formula_230", "formula_text": ")", "formula_coordinates": [38.0, 499.68, 137.77, 4.32, 8.64]}, {"formula_id": "formula_231", "formula_text": "D \u03b8 (x; \u03c3) = 1 \u2022 cskip x \u2212 \u03c3 cout \u2022 F \u03b8 1 \u221a \u03c3 2 +1 cin \u2022 x; arg min j |u j \u2212 \u03c3| cnoise , (268", "formula_coordinates": [38.0, 176.22, 188.0, 323.47, 27.78]}, {"formula_id": "formula_232", "formula_text": ")", "formula_coordinates": [38.0, 499.68, 190.2, 4.32, 8.64]}, {"formula_id": "formula_233", "formula_text": "\u03c3 i<N = \u03c3 max 1 \u03c1 + i N \u2212 1 \u03c3 min 1 \u03c1 \u2212 \u03c3 max 1 \u03c1 \u03c1 , \u03c3 N = 0,(269)", "formula_coordinates": [40.0, 188.62, 90.99, 315.38, 25.51]}, {"formula_id": "formula_234", "formula_text": "d i = f (x i ; t i ) ; x i+1 = x i + h 1 \u2212 1 2\u03b1 d i + 1 2\u03b1 f (x i + \u03b1hd i ; t i + \u03b1h) ,(270)", "formula_coordinates": [40.0, 137.74, 598.06, 366.26, 13.47]}, {"formula_id": "formula_235", "formula_text": "d i \u2190 x i \u2212 D \u03b8 (x i ; t i ) /t i Evaluate dx/dt at (x i , t i ) 9: xi+1 \u2190 xi + h 1 \u2212 1 2\u03b1 di + 1 2\u03b1 d i", "formula_coordinates": [41.0, 111.78, 168.54, 393.29, 27.13]}, {"formula_id": "formula_236", "formula_text": "\u03c3", "formula_coordinates": [42.0, 303.2, 619.12, 5.27, 7.86]}], "doi": ""}