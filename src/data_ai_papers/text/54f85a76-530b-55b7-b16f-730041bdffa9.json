{"title": "LoRaLay: A Multilingual and Multimodal Dataset for Long Range and Layout-Aware Summarization", "authors": "Laura Nguyen; Thomas Scialom; Benjamin Piwowarski; Jacopo Staiano; Mary Ann Lila", "pub_date": "", "abstract": "Text Summarization is a popular task and an active area of research for the Natural Language Processing community. It requires accounting for long input texts, a characteristic which poses computational challenges for neural models. Moreover, real-world documents come in a variety of complex, visually-rich, layouts. This information is of great relevance, whether to highlight salient content or to encode long-range interactions between textual passages. Yet, all publicly available summarization datasets only provide plain text content. To facilitate research on how to exploit visual/layout information to better capture longrange dependencies in summarization models, we present LoRaLay, a collection of datasets for long-range summarization with accompanying visual/layout information. We extend existing and popular English datasets (arXiv and PubMed) with visual/layout information and propose four novel datasets -consistently built from scholar resources -covering French, Spanish, Portuguese, and Korean languages. Further, we propose new baselines merging layout-aware and long-range models -two orthogonal approaches -and obtain state-of-theart results, showing the importance of combining both lines of research.", "sections": [{"heading": "Introduction", "text": "Deep learning techniques have enabled remarkable progress in Natural Language Processing (NLP) in recent years (Devlin et al., 2018;Brown et al., 2020). However, the majority of models, benchmarks, and tasks have been designed for unimodal approaches, i.e. focusing exclusively on a single source of information, namely plain text. While it can be argued that for specific NLP tasks, such as textual entailment or machine translation, plain text is all that is needed, there exist several tasks for which disregarding the visual appearance of text is clearly sub-optimal: in * Work partially done while at reciTAL. a real-world context (business documentation, scientific articles, etc.), text does not naturally come as a sequence of characters, but is rather displayed in a bi-dimensional space containing rich visual information. The layout of e.g. this very paper provides valuable semantics to the reader: in which section are we right now? At the blink of an eye, this information is readily accessible via the salient section title (formatted differently and placed to highlight its role) preceding these words. Just to emphasize this point, imagine having to scroll this content in plain text to access such information.\nIn the last couple of years, the research community has shown a growing interest in addressing these limitations. Several approaches have been proposed to deal with visually-rich documents and integrate layout information into language models, with direct applications to Document Understanding tasks. Joint multi-modal pretraining (Xu et al., 2021;Powalski et al., 2021;Appalaraju et al., 2021) has been key to reach state-of-the-art performance on several benchmarks (Jaume et al., 2019;Grali\u0144ski et al., 2020;Mathew et al., 2021). Nonetheless, a remaining limitation is that these (transformer-based) approaches are not suitable for processing long documents, the quadratic complexity of self-attention constraining their use to short sequences. Such models are hence unable to encode global context (e.g. long-range dependencies among text blocks).\nFocusing on compressing the most relevant information from long texts to short summaries, the Text Summarization task naturally lends itself to benefit from such global context. Notice that, in practice, the limitations linked to sequence length are also amplified by the lack of visual/layout information in the existing datasets. Therefore, in this work, we aim at spurring further research on how to incorporate multimodal information to better capture long-range dependencies.\nOur contributions can be summarized as follows:\n\u2022 We extend two popular datasets for long-range summarization, arXiv and PubMed (Cohan et al., 2018), by including visual and layout information -thus allowing direct comparison with previous works;\n\u2022 We release 4 additional layout-aware summarization datasets (128K documents), covering French, Spanish, Portuguese, and Korean languages;\n\u2022 We provide baselines including adapted architectures for multi-modal long-range summarization, and report results showing that (1) performance is far from being optimal; and\n(2) layout provides valuable information.\nAll the datasets are available on HuggingFace. 1\n2 Related Work", "publication_ref": ["b8", "b3", "b31", "b0", "b13", "b19", "b6"], "figure_ref": [], "table_ref": []}, {"heading": "Layout/Visually-rich Datasets", "text": "Document Understanding covers problems that involve reading and interpreting visually-rich documents (in contrast to plain texts), requiring comprehending the conveyed multimodal information. Hence, several tasks with a central layout aspect have been proposed by the document understanding community. Key Information Extraction tasks consist in extracting the values of a given set of keys, e.g., the total amount in a receipt or the date in a form. In such tasks, documents have a layout structure that is crucial for their interpretation. Notable datasets include FUNSD (Jaume et al., 2019) for form understanding in scanned documents, and SROIE (Huang et al., 2019), as well as CORD (Park et al., 2019), for information extraction from receipts. Grali\u0144ski et al. (2020) elicit progress on deeper and more complex Key Information Extraction by introducing the Kleister datasets, a collection of business documents with varying lengths, released as PDF files. However, the documents in Kleister often contain single-column layouts, which are simpler than the various multi-column layouts considered in LoRaLay. Document VQA is another popular document understanding task that requires processing multimodal information (e.g., text, layout, font style, images) conveyed by a document to be able to answer questions about a visually rich document (e.g., What is the date given at the top left of the form?, Whose picture is given in this figure ?). The DocVQA dataset (Mathew et al., 2021) and InfographicsVQA (Mathew et al., 2022) ", "publication_ref": ["b13", "b12", "b21", "b19", "b18"], "figure_ref": [], "table_ref": []}, {"heading": "Existing Summarization Datasets", "text": "Several large-scale summarization datasets have been proposed to boost research on text summarization systems. Hermann et al. (2015) proposed the CNN/DailyMail dataset, a collection of English articles extracted from the CNN and The Daily Mail portals. Each news article is associated with multi-sentence highlights which serve as reference summaries. Scialom et al. (2020) bridge the gap between English and non-English resources for text summarization by introducing MLSum, a largescale multilingual summarization corpus providing news articles written in French, German, Spanish, Turkish and Russian. Going toward more challenging scenarios involving significantly longer documents, the arXiv and PubMed datasets (Cohan et al., 2018) consist of scientific articles collected from academic repositories, wherein the paper abstracts are used as summaries. To encourage a shift towards building more abstractive summarization models with global content understanding, Sharma et al. (2019) introduce BIGPATENT, a large-scale dataset made of U.S. patent filings. Here, invention descriptions serve as reference summaries.\nThe vast majority of summarization datasets only deal with plain text documents. As opposed to other Document Understanding tasks (e.g., form understanding, visual QA) in which the placement of text on the page and/or visual components are the main source of information needed to find the desired data (Borchmann et al., 2021), text plays a predominant role in document summarization. However, guidelines for summarizing texts -espe-cially long ones -often recommend roughly previewing them to break them down into their major sections (Toprak and Almacioglu, 2009;Luo et al., 2019). This suggests that NLP systems might leverage multimodal information in documents. Miculicich and Han (2022) propose a two-stage method which detects text segments and incorporates this information in an extractive summarization model. Cao and Wang (2022) collect a new dataset for long and structure-aware document summarization, consisting of 21k documents written in English and extracted from WikiProject Biography.\nAlthough not all documents are explicitly organized into clearly defined sections, the great majority contains layout and visual clues (e.g., a physical organization into paragraphs, bigger headings/subheadings) which help structure their textual contents and facilitate reading. Thus, we argue that layout is crucial to summarize long documents. We propose a corpus of more than 345K long documents with layout information. Furthermore, to address the need for multilingual training data (Chi et al., 2020), we include not only English documents, but also French, Spanish, Portuguese and Korean ones.", "publication_ref": ["b11", "b25", "b6", "b26", "b2", "b29", "b17", "b20", "b4", "b5"], "figure_ref": [], "table_ref": []}, {"heading": "Datasets Construction", "text": "Inspired by the way the arXiv and PubMed datasets were built (Cohan et al., 2018), we construct our corpus from research papers, with abstracts as ground-truth summaries. As the PDF format allows simultaneous access to textual, visual and layout information, we collect PDF files to construct our datasets, and provide their URLs. 2 For each language, we select a repository that contains a high number of academic articles (in the order of hundreds of thousands) and provides easy access to abstracts. More precisely, we chose the following repositories:\n\u2022 Archives Ouverte HAL (French), 3 an open archive of scholarly documents from all academic fields. As HAL is primarily directed towards French academics, a great proportion of articles are written in French;\n\u2022 SciELO (Spanish and Portuguese), 4 an open access database of academic articles published in journal collections from Latin America, Iberian Peninsula and South Africa, and covering a broad range of topics (e.g. agricultural sciences, engineering, health sciences, letters and arts). Languages include English, Spanish, and Portuguese.\n\u2022 KoreaScience (Korean), 5 an open archive of Korean scholarly publications in the fields of natural sciences, life sciences, engineering, and humanities and social sciences. Articles are written in English or Korean.\nFurther, we provide enhanced versions of the arXiv and PubMed datasets, respectively denoted as arXiv-Lay and PubMed-Lay, for which layout information is provided.", "publication_ref": ["b6"], "figure_ref": [], "table_ref": []}, {"heading": "Collecting the Data", "text": "Extended Datasets The arXiv and PubMed datasets (Cohan et al., 2018) contain long scientific research papers extracted from the arXiv and PubMed repositories. We augment them by providing their PDFs, allowing access to layout and visual information. As the abstracts contained in the original datasets are all lowercased, we do not reuse them, but rather extract the raw abstracts using the corresponding APIs.\nNote that we were unable to retrieve all the original documents. For the most part, we failed to retrieve the corresponding abstracts, as they did not necessarily match the ones contained in the PDF files (due to e.g. PDF-parsing errors). We also found that some PDF files were unavailable, while others were corrupted or scanned documents. 6 In total, about 39% (35%) of the original documents in arXiv (PubMed) were lost.\narXiv-Lay The original arXiv dataset (Cohan et al., 2018) was constructed by converting the L A T E X files to plain text. To be consistent with the other datasets -for which L A T E X files are not available -we instead use the PDF files to extract both text and layout elements. For each document contained in the original dataset, we fetch (when possible) the corresponding PDF file using Google Cloud Storage buckets. As opposed to the original procedure, we do not remove tables nor discard sections that follow the conclusion. We retrieve the corresponding abstracts from a metadata file provided by Kaggle. 7 PubMed-Lay For PubMed, we use the PMC OAI Service 8 to retrieve abstracts and PDF files.\nHAL We use the HAL API 9 to download research papers written in French. To avoid excessively long (e.g. theses) or short (e.g. posters) documents, extraction is restricted to journal and conference papers.\nSciELO Using Scrapy, 10 we crawl the following SciELO collections: Ecuador, Colombia, Paraguay, Uruguay, Bolivia, Peru, Portugal, Spain and Brazil. We download documents written either in Spanish or Portuguese, according to the metadata, obtaining two distinct datasets: SciELO-ES (Spanish) and SciELO-PT (Portuguese).\nKoreaScience Similarly, we scrape the Korea-Science website to extract research papers. We limit search results to documents whose publishers' names contain the word Korean. This rule was designed after sampling documents in the repository, and is the simplest way to get a good proportion of papers written in Korean. 11 Further, search is restricted to papers published between 2012 and 2021, as recent publications are more likely to have digital-born, searchable PDFs. Finally, we download the PDF files of documents that contain an abstract written in Korean.", "publication_ref": ["b6", "b6"], "figure_ref": [], "table_ref": []}, {"heading": "Data Pre-processing", "text": "For each corpus, we use the 95th percentile of the page distribution as an upper bound to filter out documents with too many pages, while the 5th (1st for HAL and SciELO) percentile of the summary length distribution is used as a minimum threshold to remove documents whose abstracts are too short. As our baselines do not consider visual information, we only extract text and layout from the PDF files. Layout is incorporated by providing the spatial position of each word in a document page image, represented by its bounding box (x 0 , y 0 , x 1 , y 1 ), where (x 0 , y 0 ) and (x 1 , y 1 ) respectively denote the coordinates of the top-left and bottom-right corners. Using the PDF rendering library Poppler 12 , text and word bounding boxes are extracted from each PDF, and the sequence order is recovered based on heuristics around the document layout (e.g., tables, columns). Abstracts are then removed by searching for exact matches; when no exact match is found, we use fuzzysearch 13 and regex 14 to find near matches. 15 For the non-English datasets, documents might contain several abstracts, written in different languages. To avoid information leakage, we retrieve the abstract of each document in every language available -according to the API for HAL or the websites for SciELO and KoreaScience -and remove them using the same strategy as for the main language. In the case an abstract cannot be found, we discard the document to prevent any unforeseen leakage. The dataset construction process is illustrated in Section A in the Appendix.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Datasets Statistics", "text": "The statistics of our proposed datasets, along with those computed on existing summarization datasets of long documents (Cohan et al., 2018;Sharma et al., 2019) are reported in Table 1. We see that document lengths are comparable or greater than for the arXiv, PubMed and BigPatent datasets.\nFor arXiv-Lay and PubMed-Lay, we retain the original train/validation/splits and try to reconstruct them as faithfully to the originals as possible. For the new datasets, we order documents based on their publication dates and provide splits following a chronological ordering. For HAL and Korea-Science, we retain 3% of the articles as validation data, 3% as test, and the remaining as training data.\nTo match the number of validation/test documents in HAL and KoreaScience, we split the data into 90% for training, 5% for validation and 5% for test, for both SciELO datasets.", "publication_ref": ["b6", "b26"], "figure_ref": [], "table_ref": ["tab_2"]}, {"heading": "Experiments", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Models", "text": "For reproducibility purposes, we make the models' implementation, along with the fine-tuning and evaluation scripts, publicly available. 16 We do not explore the use of visual information in long document summarization, as the focus is on evaluating baseline performance using state-of-theart summarization models augmented with layout information. While visual features might provide a better understanding of structures such as tables and figures, we do not expect substantial gains with  respect to layout-aware models. Indeed, the information provided in figures (i.e., information that cannot be captured by layout or text) are commonly described in the caption or related paragraphs.\nText-only models with standard input size We use Pegasus  as a text-only baseline for arXiv-Lay and PubMed-Lay. Pegasus is an encoder-decoder model pre-trained using gapsentences generation, making it a state-of-the-art model for abstractive summarization. For the non-English datasets, we rely on a finetuned MBART as our baseline. MBART ) is a multilingual sequence-to-sequence model pretrained on large-scale monolingual corpora in many languages using the BART objective (Lewis et al., 2019). We use its extension, MBART-50 (Tang et al., 2020), 17 which is created from the original MBART by extending its embeddings layers and pre-training it on a total of 50 languages. Both Pegasus and MBART are limited to a maximum sequence length of 1,024 tokens, which is well below the median length of each dataset.\nLayout-aware models with standard input size We introduce layout-aware extensions of Pegasus and MBART, respectively denoted as Pe-gasus+Layout and MBART+Layout. Following LayoutLM (Xu et al., 2020), which is state-ofthe-art on several document understanding tasks (Jaume et al., 2019;Huang et al., 2019;Harley et al., 2015), each token bounding box coordinates (x 0 , y 0 , x 1 , y 1 ) is normalized into an integer in the range [0,1000]. Spatial positions are encoded using four embedding tables, namely two for the coordinate axes (x and y), and the other two for the bounding box size (width and height). The layout representation of a token is formed by summing the resulting embedding representations The final representation of a token is then obtained through point-wise summation of its textual, 1D-positional and layout embeddings.\nLong-range, text-only models To process longer sequences, we leverage BigBird , a sparse-attention based Transformer which reduces the quadratic dependency to a linear one.\nFor arXiv-Lay and PubMed-Lay, we initialize Big-Bird from Pegasus  and for the non-English datasets, we use the weights of MBART. The resulting models are referred to as BigBird-Pegasus and BigBird-MBART. For both models, BigBird sparse attention is used only in the encoder. Both models can handle up to 4,096 inputs tokens, which is greater than the median length in PubMed-Lay, HAL and KoreaScience.\nLong-range, layout-aware models We also include layout information in long-range text-only models. Similarly to layout-aware models with standard input size, we integrate layout information into our long-range models by encoding each token's spatial position in the page. The resulting models are denoted as BigBird-Pegasus+Layout and BigBird-MBART+Layout.\nAdditional State-of-the-Art Baselines We further consider additional state-of-the-art baselines for summarization: i) the text-only T5  with standard input size, ii) the long-range Longformer-Encoder-Decoder (LED) , and iii) the layout-aware, long-range LED+Layout, which we implement similarly to the previous layout-aware models.", "publication_ref": ["b15", "b28", "b32", "b13", "b12", "b10"], "figure_ref": [], "table_ref": []}, {"heading": "Implementation Details", "text": "We initialize our Pegasus-based and MBART-based models with, respectively, the google/pegasus-large and facebook/mbart-large-50 checkpoints shared through the Hugging Face Model Hub. As for T5 and LED, we use the weights from t5-base and allenai/led-base-16384, respectively. 18 Following  and , we fine-tune our models up to 74k (100k) steps on arXiv-Lay (PubMed-Lay). On HAL, the total number of steps is set to 100k, while it is de-  creased to 50k for the other non-English datasets. 19 For each model, we select the checkpoint with the best validation loss. For Pegasus and MBART models, inputs are truncated at 1,024 tokens. For BigBird-Pegasus models, we follow  and set the maximum input length at 3,072 tokens. As the median input length is much greater in almost every non-English dataset, we increase the maximum input length to 4,096 tokens for BigBird-MBART models. Output length is restricted to 256 tokens for all models, which is enough to fully capture at least 50% of the summaries in each dataset.\nFor evaluation, we use beam search and report a single run for each model and dataset. Following ; , we set the number of beams to 8 for Pegasus-based models, and 5 for BigBird-Pegasus-based models. For the non-English datasets, we set it to 5 for all models, for fair comparison. For all experiments, we use a length penalty of 0.8. For more implementation details, see Section B.1 in the Appendix.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Results and Discussion", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "General Results", "text": "In Table 3, we report the ROUGE-L scores obtained on arXiv and PubMed datasets (reported by ), as well as on the corresponding layout-augmented counterparts we release. 20 On arXiv-Lay and PubMed-Lay, we observe that, while the addition of layout to Pegasus does not improve the ROUGE-L scores, there are gains in integrating layout information into BigBird-Pegasus. To assess whether these gains are significant, we perform significance analysis at the 0.05 level using bootstrap, and estimate a ROUGE-L thresh- 19 We tested different values for the number of steps (10k, 25k, 50k, 100k) and chose the one that gave the best validation scores for MBART. 20 For detailed results, please refer to Section C.1 in the Appendix.\nold that predicts when improvements are significant. ROUGE-L improvements between each pair of models are reported in Table 11 in the appendix.\nOn arXiv-Lay, we compute a threshold of 1.48 ROUGE-L, showing that BigBird-Pegasus+Layout significantly outperforms all Pegasus-based models. In particular, we find a 1.56 ROUGE-L improvement between BigBird-Pegasus and its layoutaugmented counterpart, demonstrating that the addition of layout to long-range modeling significantly improves summarization. On PubMed-Lay, we compute a threshold of 1.77. Hence, the 0.96 ROUGE-L improvement from BigBird-Pegasus to its layout-augmented counterpart is not significant. However, the variance in font sizes in PubMed-Lay is much smaller compared to arXiv-Lay (see Table 12 in the appendix), reflecting an overall more simplistic layout. Therefore, we argue that layout integration has a lesser impact in PubMed-Lay, which can explain the non-significance of results.\nIn addition, we find that BigBird-Pegasus significantly outperforms Pegasus and Pegasus+Layout only when augmented with layout, with an improvement of, respectively, 2.3 and 2.2 points. This demonstrates the importance of combining layout and long-range modeling. While T5 and LED obtain competitive results, we find that the gain in adding layout to LED is minor. However, the models we consider have all been pre-trained only on plain text. As a result, the layout representations are learnt from scratch during fine-tuning. Similarly to us, Borchmann et al. (2021) show that their layout-augmented T5 does not necessarily improve the scores, and that performance is significantly enhanced only when the model has been pre-trained on layout-rich data.\nFurther, we observe, for both Pegasus and BigBird-Pegasus, a drop in performance w.r.    datasets contain less training data due to the inability to process all original documents. Secondly, the settings are different: while the original arXiv and PubMed datasets contain clear discourse information (e.g., each section is delimited by markers) obtained from L A T E X files, documents in our extended versions are built by parsing raw PDF files. Therefore, the task is more challenging for text-only baselines, as they have no access to the discourse structure of documents, which further underlines the importance of taking the structural information, brought by visual cues, into account.\nTable 4 presents the ROUGE-L scores reported on the non-English datasets. On HAL, we note that BigBird-MBART does not benefit from layout. After investigation, we hypothesize that this is due to the larger presence of single-column and simple layouts, which makes layout integration less needed. On both SciELO datasets, we notice that combining layout with long-range modeling brings substantial improvements over MBART. Fur-ther, we find that the plain-text BigBird models do not improve over the layout-aware Pegasus and MBART on arXiv-Lay and SciELO-ES, demonstrating that simply capturing more context does not always suffice. Regarding performance on Ko-reaScience, we can see a significant drop in performance for every model w.r.t the other non-English datasets. At first glance, we notice a high amount of English segments (e.g., tables, figure captions, scientific concepts) in documents in KoreaScience. To investigate this, we use the cld2 library 21 to detect the language in each non-English document. We consider the percent confidence of the top-1 matching language as an indicator of the presence of the main language (i.e., French, Spanish, Portuguese or Korean) in a document, and average the results to obtain a score for the whole dataset. Table 5 reports the average percent confidence obtained on each split, for each dataset. We find that the percentage of text written in the main language in KoreaScience (i.e., Korean) is smaller than in other datasets. As the MBART-based models expect only one language in a document (the information is encoded using a special token), we claim the strong presence of non-Korean segments in KoreaScience causes them to suffer from interference problems. Therefore, we highlight that KoreaScience is a more challenging dataset, and we hope our work will boost research on better long-range, multimodal and multilingual models.\nn < Q 1 Q 1 \u2264 n < Q 2 Q 2 \u2264 n < Q 3 Q 3 \u2264 n 0 0.5 1 1.5 2 2.5 Difference in ROUGE-L (a) Article length m < Q 1 Q 1 \u2264 m < Q 2 Q 2 \u2264 m < Q 3 Q 3 \u2264 m 0 0.5 1 1.5 2 Difference in ROUGE-L (b) Summary length \u03c3 < Q 1 Q 1 \u2264 \u03c3 < Q 2 Q 2 \u2264 \u03c3 < Q 3 Q 3 \u2264\nOverall, results show a clear benefit of integrating layout information for long document summarization.  To gain more insight into the effect of document layout for summarizing long textual content, we conduct a human evaluation of summaries generated by BigBird-Pegasus/BigBird-MBART and their layout-aware counterparts. We choose the BigBird-based models over the LED ones, as the gain in augmenting BigBird with layout is much more apparent. We evenly sample 50 documents from arXiv-Lay and HAL test sets, filtering documents by their topics (computer science) to match the judgment capabilities of the three human annotators. We design an evaluation interface (see Section C.2 in the appendix). For each sentence s i in the generated summary, we ask the annotators to highlight the relevant tokens in s i , along with the equivalent parts in the ground-truth abstract (de-noted h i ). Further, we ask them to rate the summary in terms of coherence and fluency, on a scale of 0 to 5, following the DUC quality guidelines (Dang, 2005). Finally, annotators are asked to penalize summaries with hallucinated facts. The highlighting process allows us to compute precision and recall as the percentage of highlighted information in the generated summary and the ground-truth abstract, respectively. Moreover, we can compute an overlap ratio as the percentage of highlighted information that appears several times in the generated summary. Lastly, we calculate a flow percentage that evaluates how well the order of the groundtruth information is preserved by computing the percentage of times where the highlighted text h i in the gold summary for one generated sentence s i follows the highlighted text h i\u22121 for the previous sentence s i\u22121 (i.e. where any token from h i occurs after a token in h i\u22121 ). Table 6 reports the scores for each metric and model, averaged over all 50 documents, along with inter-rater agreements, computed using Krippendorff's alpha coefficient. We find that adding layout to the models significantly improves precision and recall, results in less overlap (repetition), and is more in line with the ground truth order. Further, annotators did not encounter any hallucinated fact in the 50 generated summaries. To conclude, reported results show that human annotators strongly agree that adding layout generates better summaries, further validating our claim that layout provides vital information for summarization tasks.", "publication_ref": ["b2", "b7"], "figure_ref": [], "table_ref": ["tab_6", "tab_2", "tab_7", "tab_8", "tab_10"]}, {"heading": "Human Evaluation", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Case Studies", "text": "To have a better understanding of the previous results, we focus on uncovering the cases in which layout is most helpful. To this end, we identify fea-tures that relate to the necessity of having layout: 1) article length, as longer texts are intuitively easier to understand with layout, 2) summary length, as longer summaries are likely to cover more salient information, and 3) variance in font sizes (using the height of the bounding boxes), and, as such, the complexity of the layout. The benefit of using layout is measured as the difference in ROUGE-L scores between BigBird-Pegasus+Layout and its purely textual counterpart, on arXiv-Lay and PubMed-Lay. We compute quartiles from the distributions of article lengths, ground-truth summary lengths, and variance in the height of bounding boxes. 22 Based on the aforementioned factors, the scores obtained by each model are then grouped by quartile range, and averaged over each range, see Figure 1. On arXiv-Lay, we find that layout brings most improvement when dealing with the 25% longest documents and summaries, while, for both datasets, layout is least beneficial for the shortest documents and summaries. These results corroborate our claim that layout can bring important information about long-range context. Concerning the third factor, we see, on PubMed-Lay, that layout is most helpful for documents that have the widest ranges of font sizes, showcasing the advantage of using layout to capture salient information.", "publication_ref": [], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Conclusion", "text": "We have presented LoRaLay, a set of large-scale datasets for long-range and layout-aware text summarization. LoRaLay provides the research community with 4 novel multimodal corpora covering French, Spanish, Portuguese, and Korean languages, built from scientific articles. Furthermore, it includes additional layout and visual information for existing long-range summarization datasets (arXiv and PubMed). We provide adapted architectures merging layout-aware and long-range models, and show the importance of layout information in capturing long-range dependencies.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Limitations", "text": "The proposed corpus is limited to a single domain, that of scientific literature. Such limitation arguably extends to the layout diversity of documents. In terms of risks, we acknowledge the presence of Personally Identifiable Information such as author names and affiliations; nonetheless, such informa- (1) PDF Extraction\n(2) Filtering  ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A.1 Extended Datasets -Lost Documents", "text": "Figure 3 provides details on the amount of original documents lost in the process of augmenting arXiv and PubMed with layout/visual information. We observe four types of failures, and provide numbers for each type:\n\u2022 The link to the document's PDF file is not provided (Unavailable PDF);\n\u2022 The PDF file is corrupted (i.e., cannot be opened) (Corrupted PDF);\n\u2022 The document is not digital-born, making it impossible to parse it with PDF parsing tools ( Scanned PDF);\n\u2022 The document's abstract cannot be found in the PDF (Irretrievable Abstract). ", "publication_ref": [], "figure_ref": ["fig_4"], "table_ref": []}, {"heading": "A.2 KoreaScience -Extraction Rule", "text": "Korean documents in KoreaScience are extracted by restricting search results to documents containing the word \"Korean\" in the publisher's name. We show that this rule does not bias the sample towards a specific research area. We compute the distribution of topics covered by all publishers, and compare it to the distribution of topics covered by publishers whose name contains the word Korean.\nFigure 4 shows that the distribution obtained using our rule remains roughly the same as the original.  ", "publication_ref": [], "figure_ref": ["fig_6"], "table_ref": []}, {"heading": "A.3 Samples", "text": "We provide samples of documents from each dataset in Figure 5.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A.4 Datasets Statistics", "text": "The distribution of research areas in arXiv-Lay and HAL are provided in Figures 6 and 7, respectively. Such distributions are not available for the other datasets, as we did not have access to topic information during extraction.  ", "publication_ref": [], "figure_ref": ["fig_7"], "table_ref": []}, {"heading": "B Experiments", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B.1 Implementation Details", "text": "Models were implemented in Python using Py-Torch (Paszke et al., 2017) and Hugging Face (Wolf et al., 2019) librairies. In all experiments, we use Adafactor (Shazeer and Stern, 2018), a stochastic optimization method based on Adam (Kingma and Ba, 2014) that reduces memory usage while retaining the empirical benefits of adaptivity. We set a learning rate warmup over the first 10% stepsexcept on arXiv-Lay where it is set to 10k consistently with , and use a square root decay of the learning rate. All our experiments have been run on four Nvidia V100 with 32GB each.   ", "publication_ref": ["b22", "b30", "b27"], "figure_ref": [], "table_ref": []}, {"heading": "C Results", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C.1 Detailed Results", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Model", "text": "R-1 R-2 R-LMBART", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C.2 Human Evaluation", "text": "Using the Streamlit 23 framework, we design and develop an interface to aid human evaluation of summarization models. 24     The present knowledge of the structure of the photon is presented based on results obtained by measurements of photon structure functions at e+e\u2212 collider. Results are presented both for the QED structure of the photon as well as for the hadronic structure, where the data are also compared to recent parametrisations of the hadronic structure function F \u03b3 2 (x, Q2). Prospects of future photon structure function measurements, especially at an International Linear Collider are outlined.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C.3 Analysis of the Impact of Layout", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Introduction", "text": "The measurements of photon structure functions have a long tradition since the first of such measurements was performed by the PLUTO Collaboration in 1981. The investigations concern the QED structure of the photon as well as the hadronic structure. For the hadronic structure function F \u03b3 2 (x, Q2) the main areas of interest are the behavior at low values of x and the evolution with the momentum scale Q2, which is predicted by QCD to be logarithmic. The experimental information is dominated by the results from the four LEP experiments.\nThis review is based on earlier work [1,2] and as an extension provides a number of updated figures, together with a comparison of the experimental data with new parametrisations of F \u03b3 2 (x, Q2) that became available since then. Only results on the structure of quasi-real photons are discussed here. The structure of virtual photons and the corresponding measurements of effective structure functions are detailed in [3].", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Structure function measurements", "text": "The photon can fluctuate into a fermion-anti-fermion state consistent with the quantum numbers of the photon and within the limitations set by the Heisenberg uncertainty principle. These fluctuations are favored, i.e. have the longest lifetimes, for high energetic photons of low virtuality. If such a fluctuation of the photon is probed, the photon reveals its structure. Using this feature, measurements of photon structure functions are obtained from the differential crosssection of the deep-inelastic electron-photon scattering1 process sketched in Figure 1. In this", "publication_ref": [], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "ANTHOCYANINS AND BIOMEDICINAL PROPERTIES", "text": "Anthocyanins are members of the flavonoid group of phytochemicals, a group predominant in teas, honey, wines, fruits, vegetables, nuts, olive oil, cocoa, and cereals. The flavonoids, perhaps the most important single group of phenolics in foods, comprise a group of over 4000 C15 aromatic plant compounds with multiple substitution patterns (www.nal.usda.gov/fnic/foodcomp/index.html). The primary players in this group include the anthocyanins (eg, cyanidin, pelargonidin, petunidin), the flavonols (quercetin, kaempferol), flavones (luteolin, apigenin), flavanones (myricetin, naringin, hesperetin, naringenin), flavan-3-ols (catechin, epicatechin, gallocatechin), and, although sometimes classified separately, the isoflavones (genistein, daidzein). Phytochemicals in this class are frequently referred to as bioflavonoids due to their multifaceted roles in human health maintenance, and anthocyanins in food are typically ingested as components of complex mixtures of flavonoid components. Daily intake is estimated from 500 mg to 1 g, but can be several g/d if an individual is consuming flavonoid supplements (grape seed extract, ginkgo biloba, or pycnogenol; see, eg, [1]).\nThe colorful anthocyanins are the most recognized, visible members of the bioflavonoid phytochemicals. The free-radical scavenging and antioxidant capacities of anthocyanin pigments are the most highly publicized of the modus operandi used by these pigments to intervene with human therapeutic targets, but, in fact, research clearly suggests that other mechanisms of action are also responsible for observed health benefits [2,3,4,5]. Anthocyanin isolates and anthocyanin-rich mixtures of bioflavonoids may provide protection from DNA cleavage, estrogenic activity (altering development of hormone-dependent disease symptoms), enzyme inhibition, boosting production of cytokines (thus regulating immune responses), anti-inflammatory activity, lipid peroxidation, decreasing capillary permeability and fragility, and membrane strengthening [6,7,8,9,10]. The chemical structure (position, number, and types of substitutions) of the individual anthocyanin molecule also has a bearing on the degree to which anthocyanins exert their bioactive properties [11,12] and the structure/function relationships also influence the intracellular localization of the pigments [7]. The anthocyanin literature includes some controversy over the relative contributions of glycosylated anthocyanins versus aglycones in terms of bioavailability and bioactive potential [7,13,14,15,16]. Originally, it was assumed that only aglycones could enter the circulation circuit, however, absorption and metabolism of anthocyanin glycosides has now been demonstrated. The nature of the sugar conjugate and the aglycone are important determinants of anthocyanin absorption and excretion in both humans and rats [15].\nThe roles of anthocyanin pigments as medicinal agents have been well-accepted dogma in folk medicine throughout the world, and, in fact, these pigments are linked to an amazingly broad-based range of health benefits. For example, anthocyanins from Hibiscus sp have Le choix du prisme des \u00e9l\u00e8ves en grande r\u00e9ussite scolaire (EGRS) et donc ici, des parents de ceux-ci, a \u00e9t\u00e9 pris pour \u00e9tudier l'avis des enseignants sur un profil particulier, celui des familles dont les \u00e9l\u00e8ves r\u00e9ussissent (Hache, 2016) alors que l'on s'attendrait \u00e0 ce qu'ils soient en difficult\u00e9 scolaire. En effet, Charlot (2001, p. 7) les appelle les \u00ab r\u00e9ussites paradoxales \u00bb car ils r\u00e9ussissent dans un milieu qualifi\u00e9 de d\u00e9favorable pour la r\u00e9ussite scolaire. Cela a permis aux enseignants de s'exprimer sur la diff\u00e9rence ou l'absence de diff\u00e9rence entre les parents des EGRS et les autres. ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Con icto de Intereses/Competing interest", "text": "Los autores no presentan con icto de intereses.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Financiaci\u00f3n/Funding", "text": "Este trabajo no ha recibido ninguna nanciaci\u00f3n.  ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Contribuciones de autor\u00eda/Author contributions", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Resumo", "text": "Ap\u00f3s a assinatura da Conven\u00e7\u00e3o de 1826 com a Gr\u00e3-Bretanha, pela qual o governo de D. Pedro I concordou, em troca do reconhecimento brit\u00e2nico, coibir o tr\u00e1fico transatl\u00e2ntico de africanos para o Imp\u00e9rio a partir de 1830, foram criadas representa\u00e7\u00f5es consulares brasileiras na \u00c1frica Portuguesa com a expl\u00edcita finalidade de proteger a atua\u00e7\u00e3o de negreiros brasileiros nos \u00faltimos anos de legalidade do com\u00e9rcio de escravos sob a bandeira imperial. Neste sentido, o presente artigo investiga a atua\u00e7\u00e3o de Jo\u00e3o Luiz Airoza, c\u00f4nsul do Brasil em Mo\u00e7ambique, entre 1827 e 1828, na defesa do circuito negro entre o Brasil e a \u00c1frica Oriental. Para tanto, o texto aqui apresentado priorizou como fonte de estudo a documenta\u00e7\u00e3o consular produzida por Airoza e dirigida \u00e0 antiga Secretaria de Estado dos Neg\u00f3cios Estrangeiros.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Palavras-chave", "text": "Rela\u00e7\u00f5es internacionais -Rela\u00e7\u00f5es Brasil-Mo\u00e7ambique -Miss\u00e3o consular -Tr\u00e1fico de escravos -\u00c1frica Oriental. ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgements", "text": "We thank the reviewers for their insightful comments. This work is supported by the Association Nationale de la Recherche et de la Technologie (ANRT) under CIFRE grant N2020/0916. It was partially performed using HPC resources from GENCI-IDRIS (Grant 2021-AD011011841).", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Docformer: End-to-end transformer for document understanding", "journal": "", "year": "2021", "authors": "Srikar Appalaraju; Bhavan Jasani; Yusheng Bhargava Urala Kota; R Xie;  Manmatha"}, {"ref_id": "b1", "title": "Longformer: The long-document transformer", "journal": "", "year": "2020", "authors": "Iz Beltagy; E Matthew; Arman Peters;  Cohan"}, {"ref_id": "b2", "title": "Due: End-to-end document understanding benchmark", "journal": "", "year": "2021", "authors": "\u0141ukasz Borchmann; Micha\u0142 Pietruszka; Tomasz Stanislawek; Dawid Jurkiewicz; Micha\u0142 Turski; Karolina Szyndler; Filip Grali\u0144ski"}, {"ref_id": "b3", "title": "Language models are few-shot learners", "journal": "", "year": "2020", "authors": "Tom Brown; Benjamin Mann; Nick Ryder; Melanie Subbiah; Jared D Kaplan; Prafulla Dhariwal; Arvind Neelakantan; Pranav Shyam; Girish Sastry; Amanda Askell"}, {"ref_id": "b4", "title": "Hibrids: Attention with hierarchical biases for structure-aware long document summarization", "journal": "", "year": "2022", "authors": "Shuyang Cao; Lu Wang"}, {"ref_id": "b5", "title": "Cross-lingual natural language generation via pre-training", "journal": "", "year": "2020", "authors": "Zewen Chi; Li Dong; Furu Wei; Wenhui Wang; Xian-Ling Mao; Heyan Huang"}, {"ref_id": "b6", "title": "A discourse-aware attention model for abstractive summarization of long documents", "journal": "", "year": "2018", "authors": "Arman Cohan; Franck Dernoncourt; Soon Doo; Trung Kim; Seokhwan Bui; Walter Kim; Nazli Chang;  Goharian"}, {"ref_id": "b7", "title": "Overview of duc", "journal": "", "year": "2005", "authors": "Hoa Trang Dang"}, {"ref_id": "b8", "title": "Bert: Pre-training of deep bidirectional transformers for language understanding", "journal": "", "year": "2018", "authors": "Jacob Devlin; Ming-Wei Chang; Kenton Lee; Kristina Toutanova"}, {"ref_id": "b9", "title": "Agnieszka Kaliska, Paulina Rosalska", "journal": "", "year": "", "authors": "Filip Grali\u0144ski; Tomasz Stanis\u0142awek; Anna Wr\u00f3blewska; Dawid Lipi\u0144ski"}, {"ref_id": "b10", "title": "Evaluation of deep convolutional nets for document image classification and retrieval", "journal": "IEEE", "year": "2015", "authors": "W Adam; Alex Harley; Konstantinos G Ufkes;  Derpanis"}, {"ref_id": "b11", "title": "Teaching machines to read and comprehend", "journal": "", "year": "2015", "authors": "Karl Moritz Hermann; Tomas Kocisky; Edward Grefenstette; Lasse Espeholt; Will Kay; Mustafa Suleyman; Phil Blunsom"}, {"ref_id": "b12", "title": "Icdar2019 competition on scanned receipt ocr and information extraction", "journal": "IEEE", "year": "2019", "authors": "Zheng Huang; Kai Chen; Jianhua He; Xiang Bai; Dimosthenis Karatzas; Shijian Lu; C V Jawahar"}, {"ref_id": "b13", "title": "Funsd: A dataset for form understanding in noisy scanned documents", "journal": "IEEE", "year": "2019", "authors": "Guillaume Jaume; Jean-Philippe Hazim Kemal Ekenel;  Thiran"}, {"ref_id": "b14", "title": "Adam: A method for stochastic optimization", "journal": "", "year": "2014", "authors": "P Diederik; Jimmy Kingma;  Ba"}, {"ref_id": "b15", "title": "Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension", "journal": "", "year": "2019", "authors": "Mike Lewis; Yinhan Liu; Naman Goyal; Marjan Ghazvininejad; Abdelrahman Mohamed; Omer Levy; Ves Stoyanov; Luke Zettlemoyer"}, {"ref_id": "b16", "title": "Multilingual denoising pretraining for neural machine translation", "journal": "", "year": "2020", "authors": "Yinhan Liu; Jiatao Gu; Naman Goyal; Xian Li; Sergey Edunov; Marjan Ghazvininejad; Mike Lewis; Luke Zettlemoyer"}, {"ref_id": "b17", "title": "Reading like her: Human reading inspired extractive summarization", "journal": "", "year": "2019", "authors": "Ling Luo; Xiang Ao; Yan Song; Feiyang Pan; Min Yang; Qing He"}, {"ref_id": "b18", "title": "Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision", "journal": "", "year": "2022", "authors": "Minesh Mathew; Viraj Bagal; Rub\u00e8n Tito; Dimosthenis Karatzas; Ernest Valveny; C V Jawahar"}, {"ref_id": "b19", "title": "Docvqa: A dataset for vqa on document images", "journal": "", "year": "2021", "authors": "Minesh Mathew; Dimosthenis Karatzas; C V Jawahar"}, {"ref_id": "b20", "title": "Document summarization with text segmentation", "journal": "", "year": "2022", "authors": "Lesly Miculicich; Benjamin Han"}, {"ref_id": "b21", "title": "Cord: a consolidated receipt dataset for post-ocr parsing", "journal": "", "year": "2019", "authors": "Seunghyun Park; Seung Shin; Bado Lee; Junyeop Lee; Jaeheung Surh; Minjoon Seo; Hwalsuk Lee"}, {"ref_id": "b22", "title": "Automatic differentiation in pytorch", "journal": "", "year": "2017", "authors": "Adam Paszke; Sam Gross; Soumith Chintala; Gregory Chanan; Edward Yang; Zachary Devito; Zeming Lin; Alban Desmaison; Luca Antiga; Adam Lerer"}, {"ref_id": "b23", "title": "Micha\u0142 Pietruszka, and Gabriela Pa\u0142ka. 2021. Going full-tilt boogie on document understanding with text-image-layout transformer", "journal": "", "year": "", "authors": "Rafa\u0142 Powalski; \u0141ukasz Borchmann; Dawid Jurkiewicz; Tomasz Dwojak"}, {"ref_id": "b24", "title": "Exploring the limits of transfer learning with a unified text-to-text transformer", "journal": "", "year": "2019", "authors": "Colin Raffel; Noam Shazeer; Adam Roberts; Katherine Lee; Sharan Narang; Michael Matena; Yanqi Zhou; Wei Li; Peter J Liu"}, {"ref_id": "b25", "title": "Mlsum: The multilingual summarization corpus", "journal": "", "year": "2020", "authors": "Thomas Scialom; Paul-Alexis Dray; Sylvain Lamprier; Benjamin Piwowarski; Jacopo Staiano"}, {"ref_id": "b26", "title": "Bigpatent: A large-scale dataset for abstractive and coherent summarization", "journal": "", "year": "2019", "authors": "Eva Sharma; Chen Li; Lu Wang"}, {"ref_id": "b27", "title": "Adafactor: Adaptive learning rates with sublinear memory cost", "journal": "PMLR", "year": "2018", "authors": "Noam Shazeer; Mitchell Stern"}, {"ref_id": "b28", "title": "Multilingual translation with extensible multilingual pretraining and finetuning", "journal": "", "year": "2020", "authors": "Yuqing Tang; Chau Tran; Xian Li; Peng-Jen Chen; Naman Goyal; Vishrav Chaudhary; Jiatao Gu; Angela Fan"}, {"ref_id": "b29", "title": "Three reading phases and their applications in the teaching of english as a foreign language in reading classes with young learners", "journal": "Journal of language and Linguistic Studies", "year": "2009", "authors": "Elif Toprak; Gamze Almacioglu"}, {"ref_id": "b30", "title": "Huggingface's transformers: State-ofthe-art natural language processing", "journal": "", "year": "2019", "authors": "Thomas Wolf; Lysandre Debut; Victor Sanh; Julien Chaumond; Clement Delangue; Anthony Moi; Pierric Cistac; Tim Rault; R\u00e9mi Louf; Morgan Funtowicz"}, {"ref_id": "b31", "title": "LayoutLMv2: Multi-modal pre-training for visually-rich document understanding", "journal": "Association for Computational Linguistics", "year": "2021", "authors": "Yang Xu; Yiheng Xu; Tengchao Lv; Lei Cui; Furu Wei; Guoxin Wang; Yijuan Lu; Dinei Florencio; Cha Zhang; Wanxiang Che; Min Zhang; Lidong Zhou"}, {"ref_id": "b32", "title": "Layoutlm: Pre-training of text and layout for document image understanding", "journal": "", "year": "2020", "authors": "Yiheng Xu; Minghao Li; Lei Cui; Shaohan Huang; Furu Wei; Ming Zhou"}, {"ref_id": "b33", "title": "Big bird: Transformers for longer sequences", "journal": "Advances in Neural Information Processing Systems", "year": "2020", "authors": "Manzil Zaheer; Guru Guruganesh; Joshua Kumar Avinava Dubey; Chris Ainslie; Santiago Alberti; Philip Ontanon; Anirudh Pham; Qifan Ravula; Li Wang;  Yang"}, {"ref_id": "b34", "title": "Pegasus: Pre-training with extracted gap-sentences for abstractive summarization", "journal": "", "year": "2020", "authors": "Jingqing Zhang; Yao Zhao; Mohammad Saleh; Peter Liu"}, {"ref_id": "b35", "title": "", "journal": "", "year": "2020", "authors": "( Pegasus;  Zhang"}, {"ref_id": "b36", "title": "", "journal": "", "year": "2020", "authors": "( Bigbird-Pegasus;  Zaheer"}, {"ref_id": "b37", "title": "", "journal": "", "year": "2019", "authors": " T5 (raffel"}, {"ref_id": "b38", "title": "", "journal": "", "year": "2020", "authors": " Led (beltagy"}, {"ref_id": "b39", "title": "Publi\u00e9 dans la revue Cahier E&D 2017 Cahier N\u00b0 28 Familles", "journal": "", "year": "", "authors": ""}, {"ref_id": "b40", "title": "Quelles repr\u00e9sentations les enseignants ont de cette relation et de l'influence du milieu familial sur la r\u00e9ussite de leurs \u00e9l\u00e8ves ? Nous avons r\u00e9alis\u00e9 une enqu\u00eate nationale aupr\u00e8s de 1790 professeurs des \u00e9coles (PE) en zone d'\u00e9ducation prioritaire (ZEP) puis des entretiens avec dix d'entre eux. Le prisme des \u00e9l\u00e8ves en grande r\u00e9ussite scolaire (EGRS) dans les ZEP a \u00e9t\u00e9 choisi pour \u00e9tudier la diff\u00e9rence de perceptions des enseignants en fonction de la r\u00e9ussite de l'\u00e9l\u00e8ve. Les PE d\u00e9crivent le profil id\u00e9al des parents d'\u00e9l\u00e8ves. Ils souhaitent davantage d", "journal": "", "year": "", "authors": ""}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 :1Figure 1: Benefit of using layout on arXiv-Lay (blue) and PubMed-Lay (red), defined as the difference in ROUGE-L scores between BigBird-Pegasus+Layout and BigBird-Pegasus. For each dataset, quartiles are calculated from the distributions of article lengths (a), summary lengths (b) and variance in the height of the bounding boxes (c). ROUGE-L scores are then computed per quartile range, and averaged over each range.", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 2 :2Figure 2: Dataset Construction Process.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 3 :3Figure 3: Distribution of failure types in arXiv-Lay (top) and PubMed-Lay (bottom).", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Figure 4 :4Figure 4: Distribution of topics covered by all publishers (red) vs distribution of topics covered by publishers whose name contains the word Korean (blue).", "figure_data": ""}, {"figure_label": "6", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "Figure 6 :6Figure 6: Distribution of research areas in arXiv-Lay.", "figure_data": ""}, {"figure_label": "7", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "Figure 7 :7Figure 7: Distribution of research areas in HAL.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "\u00e9tudient la proportion d'\u00e9l\u00e8ves de milieu populaire ayant obtenu le baccalaur\u00e9at g\u00e9n\u00e9ral sans redoubler, Ould Ferhat et Terrail (2005) indique qu'un d\u00e9sir fort de la part des parents peut faire la diff\u00e9rence entre les \u00e9l\u00e8ves qui r\u00e9ussissent et ceux qui \u00e9chouent. On retrouve dans la litt\u00e9rature (Lorcerie, 2015) une cat\u00e9gorisation des conduites des \u00e9l\u00e8ves lorsqu'ils font face aux apprentissages en fonction de l'attitude de leurs parents. Les textes officielsi encouragent une relation positive \u00e9cole/famille, car la famille est consid\u00e9r\u00e9e comme un partenaire de l'\u00e9cole avec une place importante dans la scolarit\u00e9 de l'\u00e9l\u00e8ve (Houssaye, 2001). Que pensent les enseignants de ces d\u00e9clarations ? Quelles sont les repr\u00e9sentations des enseignants concernant l'influence des familles populaires sur la r\u00e9ussite scolaire de leur enfant ? Notre \u00e9tude se propose, dans une premi\u00e8re enqu\u00eate, d'interroger par questionnaire 1790 enseignants d'\u00e9cole \u00e9l\u00e9mentaire, toutes en ZEPii, autour de leur quotidien dans les classes et, dans une deuxi\u00e8me enqu\u00eate, de r\u00e9aliser des entretiens avec dix d'entre eux. Le sujet des parents d'\u00e9l\u00e8ves a pris une place importante dans les entretiens de tous les enseignants, comme ceux interrog\u00e9s par Moisan et Simon (1997, p. 68) qui ont plus parl\u00e9 \u00ab des parents que des \u00e9l\u00e8ves \u00bb.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_10", "figure_caption": ": 2530-5115 DOI: http://doi.org/10.22585/hospdomic.v5i4.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_11", "figure_caption": "Todos los autores han contribuido por igual en la realiczaci\u00f3n de este trabajo. C\u00d3MO CITAR ESTE TRABAJO | HOW TO CITE THIS PAPER Palomo-Llinares R, Sanchez-Tormo J, Palomo-Llinares B. Tendencias temporales de los patrones de b\u00fasqueda sobre Servicios de Atenci\u00f3n de Salud a Domicilio antes y despu\u00e9s del COVID-19. Hosp Domic. 2021;5(4):187-95.Tendencias temporales de los patrones de b\u00fasqueda sobre Servicios de Atenci\u00f3n de Salud a Domicilio antes y despu\u00e9s del COVID-19Temporal trends in Home Care Services search patterns before and after COVID-", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Datasets statistics. Article and summary lengths are computed in words. For KoreaScience, words are obtained via white-space tokenization. Difference between arXiv and arXiv-Lay is due to the fact that we retain the whole document, whileCohan et al.   ", "figure_data": ""}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "Datasets splits and statistics. Input and output lengths are computed in tokens, obtained using Pegasus and MBART-50's tokenizers for the English and non-English datasets, respectively.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "t. the scores obtained on the original datasets. This can be explained by two factors. First, our extended", "figure_data": "Model# ParamsarXiv/ arXiv-LayPubMed/ PubMed-LayPegasus (Zhang et al., 2020) BigBird-Pegasus (Zaheer et al., 2020) T5 (Raffel et al., 2019) LED (Beltagy et al., 2020) LED+Layout568M 576M 223M 161M 165M38.83 41.77 37.90 40.74 40.9641.34 42.33 39.23 41.54 41.83Pegasus Pegasus+Layout BigBird-Pegasus BigBird-Pegasus+Layout568M 572M 576M 581M39.07 39.25 39.59 41.1539.75 39.85 41.09 42.05"}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "ROUGE-L scores on arXiv-Lay and PubMed-Lay. Reported results obtained by Pegasus and BigBird-Pegasus on the original arXiv and PubMed are reported with a gray background. The best results obtained on arXiv-Lay and PubMed-Lay are denoted in bold.", "figure_data": "Model# ParamsHAL (fr)SciELO-ES (es)SciELO-PT (pt)KoreaScience (ko)MBART MBART+Layout BigBird-MBART BigBird-MBART+Layout610M 615M 617M 621M42.00 41.67 45.04 45.2036.55 37.47 37.76 40.7136.42 34.37 39.63 40.5116.94 14.98 18.55 19.95"}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_7", "figure_caption": "", "figure_data": "DatasetTrain ValidationTestHAL (fr) SciELO-ES (es) SciELO-PT (pt) KoreaScience (ko) 73.53 90.72 84.86 90.9590.54 85.84 84.28 84.90 90.58 91.96 70.26 68.78"}, {"figure_label": "5", "figure_type": "table", "figure_id": "tab_8", "figure_caption": "Percent confidence obtained for the main language, for each dataset split.", "figure_data": ""}, {"figure_label": "6", "figure_type": "table", "figure_id": "tab_10", "figure_caption": "", "figure_data": ": Average human judgement scores obtained by comparing gold-truth abstracts and summaries gener-ated by BigBird and BigBird+Layout from 50 docu-ments sampled from arXiv-Lay and HAL. Inter-rater agreement is computed using Krippendorff's alpha co-efficient, and enclosed between parentheses."}, {"figure_label": "8", "figure_type": "table", "figure_id": "tab_12", "figure_caption": "ROUGE scores on HAL. Best results are reported in bold.", "figure_data": "ModelR-1R-2R-LMBART MBART+Layout BigBird-MBART BigBird-MBART+Layout 20.36 9.49 19.95 17.33 7.70 16.94 15.43 6.69 14.98 18.96 8.01 18.55"}, {"figure_label": "10", "figure_type": "table", "figure_id": "tab_13", "figure_caption": "ROUGE scores on KoreaScience. The best results are reported in bold.", "figure_data": ""}, {"figure_label": "7", "figure_type": "table", "figure_id": "tab_14", "figure_caption": "ROUGE scores on arXiv-Lay and PubMed-Lay. Reported results obtained by Pegasus and BigBird-Pegasus on the original arXiv and PubMed are reported with a gray background. The best results obtained on arXiv-Lay and PubMed-Lay are denoted in bold.", "figure_data": "ModelR-1SciELO-ES R-2 R-LR-1SciELO-PT R-2 R-LMBART MBART+Layout BigBird-MBART BigBird-MBART+Layout 45.64 19.33 40.71 41.04 15.65 36.55 42.27 15.73 37.47 42.64 16.60 37.7641.18 15.53 36.42 39.45 14.17 34.37 44.85 18.70 39.63 45.47 20.40 40.51"}, {"figure_label": "9", "figure_type": "table", "figure_id": "tab_15", "figure_caption": "ROUGE scores on the SciELO datasets. The best results are reported in bold.", "figure_data": ""}, {"figure_label": "12", "figure_type": "table", "figure_id": "tab_16", "figure_caption": "lists the quartiles computed from the distributions of article lengths, summary lengths, and variation in the height of bounding boxes, for arXiv-Lay and PubMed-Lay.", "figure_data": "LEDLED+LayoutPegasusPegasus+Layout BigBird-Pegasus BigBird-Pegasus+LayoutT5 LED LED+Layout Pegasus Pegasus+Layout BigBird-Pegasus2.84 / 2.31 -----3.06 / 2.60 0.22 / 0.29 ----1.17 / 0.52 1.67 / 1.79 1.89 / 2.08 ---1.35 / 0.62 1.49 / 1.69 1.71 / 1.98 0.34 / 0.10 --1.69 / 1.86 1.15 / 0.45 1.38 / 0.74 0.52 / 1.34 0.34 / 1.24 -3.25 / 2.82 0.41 / 0.51 0.19 / 0.22 2.08 / 2.30 1.90 / 2.20 1.56 / 0.96"}, {"figure_label": "11", "figure_type": "table", "figure_id": "tab_17", "figure_caption": "Absolute ROUGE-L score differences between each pair of models, on arXiv-Lay/PubMed-Lay.", "figure_data": "DistributionQ1 arXiv-Lay PubMed-LayQ2 arXiv-Lay PubMed-LayQ3 arXiv-Lay PubMed-LayArticle Length Summary Length \u03c3 of bounding box height6,226 119 3.373,513 130 1.349,142 159 3.985,557 182 1.7313,190 202 4.708,036 247 2.28"}, {"figure_label": "12", "figure_type": "table", "figure_id": "tab_18", "figure_caption": "Quartiles calculated from the distributions of article lengths, summary lengths, and variation in the height of bounding boxes, for arXiv-Lay and PubMed-Lay.", "figure_data": "MPP-2009-131Experimental Review of Photon Structure Func-tion DataarXiv:0907.2782v1 [hep-ex] 16 Jul 2009Richard Nisius Max-Planck-Institut f\u00fcr Physik (Werner-Heisenberg-Institut), F\u00f6hringer Ring 6, D-80805 M\u00fcn-chen, Germany, E-mail: Richard.Nisius@mpp.mpg.de *  DOI: will be assigned"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_19", "figure_caption": "0000-0002-3892-3551 1. Universidad Miguel Hern\u00e1ndez, Departamento de Salud P\u00fablica e Historia de la Ciencia, Sant Joan d\u00b4Alacant, Alicante, Espa\u00f1a. 2. Centro Internacional Virtual de Investigaci\u00f3n en Nutrici\u00f3n (CIVIN), Alicante, Espa\u00f1a. 3. Universitat Miguel Hern\u00e1ndez d'Elx, Elche, Espa\u00f1a. Gilberto da Silva Guizelin Uma luz sobre as rela\u00e7\u00f5es Brasil-Mo\u00e7ambique no oitocentos: a Miss\u00e3o Consular de Jo\u00e3o Luiz Airoza (1827-1828) rev. hist. (S\u00e3o Paulo), n.178, a03318, 2019 http://dx.doi.org/10.11606/issn.2316-9141.rh.2019.144021", "figure_data": "(d) SciELO-ESARTIGOUMA LUZ SOBRE ASREL A\u00c7\u00d5ES BR ASIL-MO\u00c7AMBIQUE NOOITOCENTOS: AMISS\u00c3O CONSULARDE JO\u00c3O LUIZ AIROZA(1827-1828 ) *Gilberto da Silva Guizelin **Universidade de S\u00e3o PauloS\u00e3o Paulo -S\u00e3o Paulo -Brasil1"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_20", "figure_caption": "Contato Rua Belo Horizonte, 433, apto. 603 86020-060 -Londrina -Paran\u00e1 -Brasil guizelin.gs@gmail.com * Todas as obras e todos os documentos utilizados na pesquisa e na elabora\u00e7\u00e3o do artigo s\u00e3o citados nas notas e na bibliografia. ** Doutor em Hist\u00f3ria pela Faculdade de Ci\u00eancias Humanas e Sociais de Franca, da Universidade Estadual Paulista J\u00falio de Mesquita Filho (Unesp). P\u00f3s-doutorando em Hist\u00f3ria pela Faculdade de Filosofia, Letras e Ci\u00eancias Humanas, da Universidade de S\u00e3o Paulo (FFLCH/USP). Bolsista p\u00f3sdoc processo n\u00ba 2018/07798-1, Funda\u00e7\u00e3o de Amparo \u00e0 Pesquisa do Estado de S\u00e3o Paulo (FAPESP). \uad6d\ubb38\uc694\uc57d \ubcf8 \uc5f0\uad6c\ub294 2000\ub144\ubd80\ud130 2018\ub144\uae4c\uc9c0\ub97c \ubd84\uc11d\uc758 \uc2dc\uac04\uc801 \ubc94\uc704\ub85c \uc124\uc815\ud558\uc5ec \uc81c\uc870\uc5c5 \ucc3d\uc5c5 \ud65c\ub3d9\uc774 \uacf5\uac04\uc801\uc73c\ub85c \uc5b4\ub5a0\ud55c \ubcc0\ud654\ub97c \ubcf4\uc5ec\uc654\ub294\uc9c0\ub97c \ud0d0\uc0c9\uc801\uc73c\ub85c \ubd84\uc11d\ud558\uace0, \ud5a5\ud6c4 \ucc3d\uc5c5 \ud65c\ub3d9\uc758 \ubd84\ud3ec \ud328\ud134 \ubcc0\ud654\ub97c \uc608\uce21\ud558\ub294 \uac83\uc744 \ubaa9\uc801\uc73c\ub85c \ud55c \ub2e4. \ubd84\uc11d\uc744 \uc704\ud574 2000\ub144\ubd80\ud130 2018\ub144\uae4c\uc9c0\uc758 \u300c\uc804\uad6d\uc0ac\uc5c5\uccb4\uc870\uc0ac\u300d \ub9c8\uc774\ud06c\ub85c\ub370\uc774\ud130 \uc81c\uc870\uc5c5 \uc0ac\uc5c5\uccb4 \uc790\ub8cc\ub97c \ud65c\uc6a9\ud558\uc600\ub2e4. \ud55c\uad6d\uc0b0\uc5c5\uc5f0\uad6c\uc6d0\uc758 ISTANS \ubd84\ub958\uccb4\uacc4\uc5d0\uc11c \uc81c\uc2dc\ud558\ub294 40\ub300 \uc81c\uc870\uc5c5 \uae30\uc900\uc5d0 \ub530\ub77c \uc81c\uc870\uc5c5\uc744 4\uac1c\uc758 \uc138\ubd80 \uc0b0\uc5c5\uad70\uc73c\ub85c \uad6c \ubd84\ud55c \ud6c4, \uc218\ub3c4\uad8c \ud589\uc815\uad6c\uc5ed \uc74d\uba74\ub3d9 \uc218\uc900\uc5d0\uc11c \uacf5\uac04\uc790\uae30\uc0c1\uad00 \ubd84\uc11d \ubc0f \uacf5\uac04 \ub9c8\ub974\ucf54\ud504 \uccb4\uc778 \ubd84\uc11d\uc744 \uc218\ud589\ud558\uc600\ub2e4. \ubd84\uc11d \uacb0 \uacfc\uc5d0 \ub530\ub974\uba74, \uace0\uc704\uae30\uc220\uc0b0\uc5c5\uad70 \ubc0f \uc911\uace0\uc704\uae30\uc220\uc0b0\uc5c5\uad70\uc758 \ucc3d\uc5c5 \ud65c\ub3d9\uc740 \uc2dc\uac04\uc774 \ud750\ub984\uc5d0 \ub530\ub77c \uacbd\uae30\ub3c4 \ub0a8\ubd80\ub97c \uc911\uc2ec\uc73c\ub85c \uc9d1 \uc911\ub418\uace0 \uc788\ub294 \uac83\uc73c\ub85c \ub098\ud0c0\ub0ac\uc73c\uba70, \uc911\uc800\uc704\uae30\uc220\uc0b0\uc5c5\uad70 \ubc0f \uc800\uc704\uae30\uc220\uc0b0\uc5c5\uad70 \ucc3d\uc5c5 \ud65c\ub3d9\uc758 \uc9d1\uc911\uc740 \uc218\ub3c4\uad8c \uc678\uacfd\uc73c\ub85c \ubd84\uc0b0 \ub418\uace0 \uc788\ub294 \uac83\uc73c\ub85c \ub098\ud0c0\ub0ac\ub2e4. 2000\ub144\ubd80\ud130 2018\ub144\uae4c\uc9c0\uc758 \ucd94\uc138\ub97c \uc5f0\uc7a5\ud558\uc5ec 2036\ub144\uae4c\uc9c0\uc758 \ubd84\ud3ec \ubcc0\ud654\ub97c \uc608\uce21\ud558\uc600\uc744 \ub54c, \ucc3d\uc5c5 \ud65c\ub3d9\uc774 \ud65c\ubc1c\ud788 \ubc1c\uc0dd\ud558\ub294 \uc9c0\uc5ed \ubc0f \uadf8\uc640 \uc778\uc811\ud558\uace0 \uc788\ub294 \uc9c0\uc5ed\uc758 \uacbd\uc6b0 \ud5a5\ud6c4 \ubd84\uc704 \uc0c1\uc2b9\uc758 \uac00\ub2a5\uc131\uc774 \ub192\uc740 \uac83\uc73c\ub85c \ub098\ud0c0\ub098 \uae0d\uc815\uc801\uc778 \uacf5\uac04 \ud6a8\uacfc\uac00 \uc874\uc7ac\ud558\ub294 \uac83\uc73c\ub85c \ud655\uc778\ub418\uc5c8\ub2e4. \ubcf8 \uc5f0\uad6c\ub294 \uc77c\uc790\ub9ac \ucc3d\ucd9c\uc758 \uc8fc\uc694 \uc6d0\ucc9c\uc774 \ub418\ub294 \uc81c\uc870\uc5c5 \ucc3d \uc5c5 \ud65c\ub3d9\uc758 \ubd84\ud3ec \ud328\ud134 \ubcc0\ud654\ub97c \ub3d9\ud0dc\uc801\uc73c\ub85c \ubd84\uc11d\ud568\uc73c\ub85c\uc368 \ucc3d\uc5c5 \uc721\uc131 \ubc0f \uc77c\uc790\ub9ac \ucc3d\ucd9c\uacfc \uad00\ub828\ud55c \uc9c0\uc5ed \uc815\ucc45\uc5d0\uc758 \uc2dc\uc0ac\uc810\uc744 \uc81c\uacf5\ud558\uace0\uc790 \ud558\uc600\ub2e4. \uc8fc\uc81c\uc5b4 \uc81c\uc870\uc5c5, \ucc3d\uc5c5, \ud0d0\uc0c9\uc801\uacf5\uac04\uc790\ub8cc \ubd84\uc11d, \uacf5\uac04\ub9c8\ub974\ucf54\ud504 \uccb4\uc778 Abstract: is study aims to explore how manufacturing start-up activities from 2000 to 2018 have changed spatially and to predict changes in distribution patterns of future start-up activities. For the analysis, the Census on Establishments microdata from 2000 to 2018 were used, and the manufacturing industry was classi ed into four detailed industrial", "figure_data": "63\uc218\ub3c4\uad8c \uc81c\uc870\uc5c5 \ucc3d\uc5c5 \ud65c\ub3d9\uc758 \uacf5\uac04\uc801 \ubd84\ud3ec \ubcc0\ud654-\uacf5\uac04 \ub9c8\ub974\ucf54\ud504 \uccb4\uc778\uc758 \uc751\uc6a9 -*\uc1a1\ucc3d\ud604**\u2022\uc548\uc21c\ubc94***\u2022\uc784\uc5c5****Changes in Spatial Distribution of Manufacturing Startup Activities in the Capital Region, Korea: A Spatial Markov Chain Approach*Changhyun Song* \u2022 Soonbeom Ahn** \u2022 Up Lim***(e) SciELO-PT"}], "formulas": [{"formula_id": "formula_0", "formula_text": "n < Q 1 Q 1 \u2264 n < Q 2 Q 2 \u2264 n < Q 3 Q 3 \u2264 n 0 0.5 1 1.5 2 2.5 Difference in ROUGE-L (a) Article length m < Q 1 Q 1 \u2264 m < Q 2 Q 2 \u2264 m < Q 3 Q 3 \u2264 m 0 0.5 1 1.5 2 Difference in ROUGE-L (b) Summary length \u03c3 < Q 1 Q 1 \u2264 \u03c3 < Q 2 Q 2 \u2264 \u03c3 < Q 3 Q 3 \u2264", "formula_coordinates": [8.0, 76.71, 87.71, 419.66, 102.29]}, {"formula_id": "formula_1", "formula_text": "R-1 R-2 R-LMBART", "formula_coordinates": [13.0, 351.57, 215.75, 153.87, 26.79]}], "doi": "10.22669/krsa.2021.37.2.063"}