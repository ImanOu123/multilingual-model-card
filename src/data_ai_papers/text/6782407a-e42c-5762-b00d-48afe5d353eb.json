{"title": "A non-local algorithm for image denoising", "authors": "Antoni Buades; Bartomeu Coll; Jean-Michel Morel", "pub_date": "", "abstract": "We propose a new measure, the method noise, to evaluate and compare the performance of digital image denoising methods. We first compute and analyze this method noise for a wide class of denoising algorithms, namely the local smoothing filters. Second, we propose a new algorithm, the non local means (NL-means), based on a non local averaging of all pixels in the image. Finally, we present some experiments comparing the NL-means algorithm and the local smoothing filters.", "sections": [{"heading": "Introduction", "text": "The goal of image denoising methods is to recover the original image from a noisy measurement,\nv(i) = u(i) + n(i),(1)\nwhere v(i) is the observed value, u(i) is the \"true\" value and n(i) is the noise perturbation at a pixel i. The best simple way to model the effect of noise on a digital image is to add a gaussian white noise. In that case, n(i) are i.i.d. gaussian values with zero mean and variance \u03c3 2 . Several methods have been proposed to remove the noise and recover the true image u. Even though they may be very different in tools it must be emphasized that a wide class share the same basic remark : denoising is achieved by averaging. This averaging may be performed locally: the Gaussian smoothing model (Gabor [7]), the anisotropic filtering , Alvarez et al. [1]) and the neighborhood filtering (Yaroslavsky [16], Smith et al. [14], Tomasi et al. [15]), by the calculus of variations: the Total Variation minimization (Rudin-Osher-Fatemi [13]), or in the frequency domain: the empirical Wiener filters (Yaroslavsky [16]) and wavelet thresholding methods (Coiffman-Donoho [5,4]).\nFormally we define a denoising method D h as a decomposition\nv = D h v + n(D h , v),\nwhere v is the noisy image and h is a filtering parameter which usually depends on the standard deviation of the noise. Ideally, D h v is smoother than v and n(D h , v) looks like the realization of a white noise. The decomposition of an image between a smooth part and a non smooth or oscillatory part is a current subject of research (for example Osher et al. [10]). In [8], Y. Meyer studied the suitable functional spaces for this decomposition. The primary scope of this latter study is not denoising since the oscillatory part contains both noise and texture. The denoising methods should not alter the original image u. Now, most denoising methods degrade or remove the fine details and texture of u. In order to better understand this removal, we shall introduce and analyze the method noise. The method noise is defined as the difference between the original (always slightly noisy) image u and its denoised version.\nWe also propose and analyze the NL-means algorithm, which is defined by the simple formula\nNL[u](x) = 1 C(x) \u2126 e \u2212 (Ga * |u(x+.)\u2212u(y+.)| 2 )(0) h 2 u(y) dy, where x \u2208 \u2126, C(x) = \u2126 e \u2212 (G a * |u(x+.)\u2212u(z+.)| 2 )(0) h 2\ndz is a normalizing constant, G a is a Gaussian kernel and h acts as a filtering parameter. This formula amounts to say that the denoised value at x is a mean of the values of all points whose gaussian neighborhood looks like the neighborhood of x. The main difference of the NL-means algorithm with respect to local filters or frequency domain filters is the systematic use of all possible self-predictions the image can provide, in the spirit of [6]. For a more detailed analysis on the NL-means algorithm and a more complete comparison, see [2].\nSection 2 introduces the method noise and computes its mathematical formulation for the mentioned local smooth-ing filters. Section 3 gives a discrete definition of the NLmeans algorithm. In section 4 we give a theoretical result on the consistency of the method. Finally, in section 5 we compare the performance of the NL-means algorithm and the local smoothing filters.", "publication_ref": ["b6", "b0", "b15", "b13", "b14", "b12", "b15", "b4", "b3", "b9", "b7", "b5", "b1"], "figure_ref": [], "table_ref": []}, {"heading": "Method noise", "text": "Definition 1 (Method noise) Let u be an image and D h a denoising operator depending on a filtering parameter h. Then, we define the method noise as the image difference\nu \u2212 D h u.\nThe application of a denoising algorithm should not alter the non noisy images. So the method noise should be very small when some kind of regularity for the image is assumed. If a denoising method performs well, the method noise must look like a noise even with non noisy images and should contain as little structure as possible. Since even good quality images have some noise, it makes sense to evaluate any denoising method in that way, without the traditional \"add noise and then remove it\" trick. We shall list formulas permitting to compute and analyze the method noise for several classical local smoothing filters: the Gaussian filtering [7], the anisotropic filtering [1,11], the Total Variation minimization [13] and the neighborhood filtering [16]. The formal analysis of the method noise for the frequency domain filters fall out of the scope of this paper. These method noises can also be computed but their interpretation depends on the particular choice of the wavelet basis.", "publication_ref": ["b6", "b0", "b10", "b12", "b15"], "figure_ref": [], "table_ref": []}, {"heading": "The Gaussian filtering", "text": "The image isotropic linear filtering boils down to the convolution of the image by a linear symmetric kernel. The paradigm of such kernels is of course the gaussian kernel\nx \u2192 G h (x) = 1 (4\u03c0h 2 ) e \u2212 |x| 2 4h 2 .\nIn that case, G h has standard deviation h and it is easily seen that", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Theorem 1 (Gabor 1960) The image method noise of the convolution with a gaussian kernel", "text": "G h is u \u2212 G h * u = \u2212h 2 \u2206u + o(h 2 ), for h small enough.\nThe gaussian method noise is zero in harmonic parts of the image and very large near edges or texture, where the Laplacian cannot be small. As a consequence, the Gaussian convolution is optimal in flat parts of the image but edges and texture are blurred.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "The anisotropic filtering", "text": "The anisotropic filter (AF ) attempts to avoid the blurring effect of the Gaussian by convolving the image u at x only in the direction orthogonal to Du(x). The idea of such filter goes back to Perona and Malik [11]. It is defined by\nAF h u(x) = G h (t)u(x + t Du(x) \u22a5 |Du(x)| )dt,\nfor x such that Du(x) = 0 and where (x, y) \u22a5 = (\u2212y, x) and G h is the one-dimensional Gauss function with variance h 2 . If one assumes that the original image u is twice continuously differentiable (C 2 ) at x, it is easily shown by a second order Taylor expansion that", "publication_ref": ["b10"], "figure_ref": [], "table_ref": []}, {"heading": "Theorem 2", "text": "The image method noise of an anisotropic filter\nAF h is u(x) \u2212 AF h u(x) = \u2212 1 2 h 2 |Du|curv(u)(x) + o(h 2 ),\nwhere the relation holds when Du(x) = 0.\nBy curv(u)(x), we denote the curvature, i.e. the signed inverse of the radius of curvature of the level line passing by x. This method noise is zero wherever u behaves locally like a straight line and large in curved edges or texture (where the curvature and gradient operators take high values). As a consequence, the straight edges are well restored while flat and textured regions are degraded.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "The Total Variation minimization", "text": "The Total Variation minimization was introduced by Rudin, Osher and Fatemi [13]. Given a noisy image v(x), these authors proposed to recover the original image u(x) as the solution of the minimization problem\nTVF \u03bb (v) = arg min u T V (u) + \u03bb |v(x) \u2212 u(x)| 2 dx\nwhere T V (u) denotes the total variation of u and \u03bb is a given Lagrange multiplier. The minimum of the above minimization problem exists and is unique. The parameter \u03bb is related to the noise statistics and controls the degree of filtering of the obtained solution.", "publication_ref": ["b12"], "figure_ref": [], "table_ref": []}, {"heading": "Theorem 3 The method noise of the Total Variation minimization is", "text": "u(x) \u2212 TVF \u03bb (u)(x) = \u2212 1 2\u03bb curv(TVF \u03bb (u))(x).\nAs in the anisotropic case, straight edges are maintained because of their small curvature. However, details and texture can be over smoothed if \u03bb is too small.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "The neighborhood filtering", "text": "We call neighborhood filter any filter which restores a pixel by taking an average of the values of neighboring pixels with a similar grey level value. Yaroslavsky (1985) [16] averages pixels with a similar grey level value and belonging to the spatial neighborhood B \u03c1 (x),\nYNF h,\u03c1 u(x) = 1 C(x) B\u03c1(x) u(y)e \u2212 |u(y)\u2212u(x)| 2 h 2 dy, (2)\nwhere\nx \u2208 \u2126, C(x) = B\u03c1(x) e \u2212 |u(y)\u2212u(x)| 2 h 2\ndy is the normalization factor and h is a filtering parameter.\nThe Yaroslavsky filter is less known than more recent versions, namely the SUSAN filter (1995) [14] and the Bilateral filter (1998) [15]. Both algorithms, instead of considering a fixed spatial neighborhood B \u03c1 (x), weigh the distance to the reference pixel x,\nSNF h,\u03c1 u(x) = 1 C(x) \u2126 u(y)e \u2212 |y\u2212x| 2 \u03c1 2 e \u2212 |u(y)\u2212u(x)| 2 h 2 dy,(3)\nwhere\nC(x) = \u2126 e \u2212 |y\u2212x| 2 \u03c1 2 e \u2212 |u(y)\u2212u(x)| 2 h 2\ndy is the normalization factor and \u03c1 is now a spatial filtering parameter. In practice, there is no difference between YNF h,\u03c1 and SNF h,\u03c1 . If the grey level difference between two regions is larger than h, both algorithms compute averages of pixels belonging to the same region as the reference pixel. Thus, the algorithm does not blur the edges, which is its main scope. In the experimentation section we only compare the Yaroslavsky neighborhood filter.\nThe problem with these filters is that comparing only grey level values in a single pixel is not so robust when these values are noisy. Neighborhood filters also create artificial shocks which can be justified by the computation of its method noise, see [3].", "publication_ref": ["b15", "b15", "b13", "b14", "b2"], "figure_ref": [], "table_ref": []}, {"heading": "NL-means algorithm", "text": "Given a discrete noisy image v = {v(i) | i \u2208 I}, the estimated value NL[v](i), for a pixel i, is computed as a weighted average of all the pixels in the image,\nNL[v](i) = j\u2208I w(i, j)v(j),\nwhere the family of weights {w(i, j)} j depend on the similarity between the pixels i and j, and satisfy the usual conditions 0 \u2264 w(i, j) \u2264 1 and j w(i, j) = 1.\nThe similarity between two pixels i and j depends on the similarity of the intensity gray level vectors v(N i ) and v(N j ), where N k denotes a square neighborhood of fixed size and centered at a pixel k. This similarity is measured as a decreasing function of the weighted Euclidean distance, v(N i ) \u2212 v(N j ) 2 2,a , where a > 0 is the standard deviation of the Gaussian kernel. The application of the Euclidean distance to the noisy neighborhoods raises the following equality\nE||v(N i ) \u2212 v(N j )|| 2 2,a = ||u(N i ) \u2212 u(N j )|| 2 2,a + 2\u03c3 2 .\nThis equality shows the robustness of the algorithm since in expectation the Euclidean distance conserves the order of similarity between pixels.\nThe pixels with a similar grey level neighborhood to v(N i ) have larger weights in the average, see Figure 1. These weights are defined as,\nw(i, j) = 1 Z(i) e \u2212 ||v(N i )\u2212v(N j )|| 2 2,a h 2 ,\nwhere Z(i) is the normalizing constant\nZ(i) = j e \u2212 ||v(N i )\u2212v(N i )|| 2 2,a h 2\nand the parameter h acts as a degree of filtering. It controls the decay of the exponential function and therefore the decay of the weights as a function of the Euclidean distances.\nThe NL-means not only compares the grey level in a single point but the the geometrical configuration in a whole neighborhood. This fact allows a more robust comparison than neighborhood filters. Figure 1 illustrates this fact, the pixel q3 has the same grey level value of pixel p, but the neighborhoods are much different and therefore the weight w(p, q3) is nearly zero. ", "publication_ref": ["b1"], "figure_ref": ["fig_0", "fig_0"], "table_ref": []}, {"heading": "NL-means consistency", "text": "Under stationarity assumptions, for a pixel i, the NLmeans algorithm converges to the conditional expectation of i once observed a neighborhood of it. In this case, the stationarity conditions amount to say that as the size of the image grows we can find many similar patches for all the details of the image.\nLet V be a random field and suppose that the noisy image v is a realization of V . Let Z denote the sequence of random variables Z i = {Y i , X i } where Y i = V (i) is real valued and X i = V (N i \\{i}) is R p valued. The NL-means is an estimator of the conditional expectation r\n(i) = E[Y i | X i = v(N i \\{i})].", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Theorem 4 (Conditional expectation theorem", "text": ") Let Z = {V (i), V (N i \\{i})} for i = 1, 2, . . .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "be a strictly stationary and mixing process.", "text": "Let NL n denote the NL-means algorithm applied to the sequence\nZ n = {V (i), V (N i \\{i})} n i=1 . Then, |NL n (j) \u2212 r(j)| \u2192 0 a.s for j \u2208 {1, . . . , n}.\nThe full statement of the hypothesis of the theorem and its proof can be found in a more general framework in [12]. This theorem tells us that the NL-means algorithm corrects the noisy image rather than trying to separate the noise (oscillatory) from the true image (smooth).\nIn the case that an additive white noise model is assumed, the next result shows that the conditional expectation is the function of V (N i \\{i}) that minimizes the mean square error with the true image u.\nTheorem 5 Let V, U, N be random fields on I such that V = U + N , where N is a signal independent white noise. Then, the following statements are hold.\n(i) E[V (i) | X i = x] = E[U (i) | X i = x] for all i \u2208 I and x \u2208 R p . (ii) The expected random variable E[U (i) | V (N i \\{i})]\nis the function of V (N i \\{i}) that minimizes the mean square error\nmin g E[U (i) \u2212 g(V (N i \\{i}))] 2\nSimilar optimality theoretical results have been obtained in [9] and presented for the denoising of binary images. Theoretical links between the two algorithms will be explored in a future work.", "publication_ref": ["b11", "b8"], "figure_ref": [], "table_ref": []}, {"heading": "Discussion and experimentation", "text": "In this section we compare the local smoothing filters and the NL-means algorithm under three well defined criteria: the method noise, the visual quality of the restored image and the mean square error, that is, the Euclidean difference between the restored and true images.\nFor computational purposes of the NL-means algorithm, we can restrict the search of similar windows in a larger \"search window\" of size S \u00d7 S pixels. In all the experimentation we have fixed a search window of 21\u00d721 pixels and a similarity square neighborhood N i of 7 \u00d7 7 pixels. If N 2 is the number of pixels of the image, then the final complexity of the algorithm is about 49 \u00d7 441 \u00d7 N 2 .\nThe 7 \u00d7 7 similarity window has shown to be large enough to be robust to noise and small enough to take care of details and fine structure. The filtering parameter h has been fixed to 10 * \u03c3 when a noise of standard deviation \u03c3 is added. Due to the fast decay of the exponential kernel, large Euclidean distances lead to nearly zero weights acting as an automatic threshold, see Fig. 2.  In section 2 we have computed explicitly the method noise of the local smoothing filters. These formulas are corroborated by the visual experiments of Figure 4. This figure displays the method noise for the standard image Lena, that is, the difference u \u2212 D h (u), where the parameter h is been fixed in order to remove a noise of standard deviation 2.5. The method noise helps us to understand the performance and limitations of the denoising algorithms, since removed details or texture have a large method noise. We see in Figure 4 that the NL-means method noise does not present any noticeable geometrical structures. Figure 2 explains this property since it shows how the NL-means algorithm chooses a weighting configuration adapted to the local and non local geometry of the image.\nThe human eye is the only one able to decide if the quality of the image has been improved by the denoising method. We display some denoising experiences comparing the NL-means algorithm with local smoothing filters. All experiments have been simulated by adding a gaussian white noise of standard deviation \u03c3 to the true image. The objective is to compare the visual quality of the restored images, the non presence of artifacts and the correct recon-struction of edges, texture and details.\nDue to the nature of the algorithm, the most favorable case for the NL-means is the textured or periodic case. In this situation, for every pixel i, we can find a large set of samples with a very similar configuration. See Figure 2 e) for an example of the weight distribution of the NL-means algorithm for a periodic image. Figure 3 (c). In addition, natural images allow us to find many similar configurations in far away pixels, as Figure 2 (f) shows. Figure 5 shows an experiment on a natural image. This experience must be compared with Figure 4, where we display the method noise of the original image. The blurred or degraded structures of the restored images coincide with the noticeable structures of its method noise.\nFinally Table 1 displays the mean square error for the  denoising experiments given in the paper. This numerical measurement is the most objective one, since it does not rely on any visual interpretation. However, this error is not computable in a real problem and a small mean square error does not assure a high visual quality. So all above discussed criteria seem necessary to compare the performance of algorithms.", "publication_ref": [], "figure_ref": ["fig_1", "fig_3", "fig_3", "fig_1", "fig_1", "fig_2", "fig_1", "fig_5", "fig_3"], "table_ref": ["tab_0"]}], "references": [{"ref_id": "b0", "title": "Image selective smoothing and edge detection by nonlinear diffusion (ii)", "journal": "Journal of numerical analysis", "year": "1992", "authors": "L Alvarez; P.-L Lions; J.-M Morel"}, {"ref_id": "b1", "title": "On image denoising methods", "journal": "", "year": "2004", "authors": "A Buades; B Coll; J Morel"}, {"ref_id": "b2", "title": "Neighborhood filters and pde's", "journal": "", "year": "2005", "authors": "A Buades; B Coll; J Morel"}, {"ref_id": "b3", "title": "Wavelets and Statistics, chapter Translation-invariant de-noising", "journal": "Springer Verlag", "year": "1995", "authors": "R Coifman; D Donoho"}, {"ref_id": "b4", "title": "De-noising by soft-thresholding", "journal": "IEEE Transactions on Information Theory", "year": "1995", "authors": "D Donoho"}, {"ref_id": "b5", "title": "Texture synthesis by non parametric sampling", "journal": "", "year": "1999", "authors": "A Efros; T Leung"}, {"ref_id": "b6", "title": "On gabor contribution to image enhancement", "journal": "Pattern Recognition", "year": "1994", "authors": "M Lindenbaum; M Fischer; A Bruckstein"}, {"ref_id": "b7", "title": "Oscillating Patterns in Image Processing and Nonlinear Evolution Equations", "journal": "AMS University", "year": "2002", "authors": "Y Meyer"}, {"ref_id": "b8", "title": "A discrete universal denoiser and its application to binary images", "journal": "", "year": "2003", "authors": "E Ordentlich; G Seroussi; M W S Verd\u00fa; T Weissman"}, {"ref_id": "b9", "title": "Image decomposition and restoration using total variation minimization and the h \u22121 norm", "journal": "Multiscale Modeling and Simulation", "year": "2003", "authors": "S Osher; A Sole; L Vese"}, {"ref_id": "b10", "title": "Scale space and edge detection using anisotropic diffusion", "journal": "IEEE Trans. Patt. Anal. Mach. Intell", "year": "1990", "authors": "P Perona; J Malik"}, {"ref_id": "b11", "title": "Nonparametric regression estimation under mixing conditions. Stochastic processes and their applications", "journal": "", "year": "1990", "authors": "G Roussas"}, {"ref_id": "b12", "title": "Nonlinear total variation based noise removal algorithms", "journal": "Physica D", "year": "1992", "authors": "L Rudin; S Osher; E Fatemi"}, {"ref_id": "b13", "title": "Susan -a new approach to low level image processing", "journal": "International Journal of Computer Vision", "year": "1997", "authors": "S Smith; J Brady"}, {"ref_id": "b14", "title": "Bilateral filtering for gray and color images", "journal": "", "year": "1998", "authors": "C Tomasi; R Manduchi"}, {"ref_id": "b15", "title": "Digital Picture Processing -An Introduction", "journal": "Springer Verlag", "year": "1985", "authors": "L Yaroslavsky"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 .1Figure 1. Scheme of NL-means strategy. Similar pixel neighborhoods give a large weight, w(p,q1) and w(p,q2), while much different neighborhoods give a small weight w(p,q3).", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 2 .2Figure 2. Display of the NL-means weight distribution used to estimate the central pixel of every image. The weights go from 1(white) to zero(black).", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 3 .3Figure 3. Denoising experience on a natural texture. From left to right: noisy image (standard deviation 35), Gauss filtering, anisotropic filtering, Total variation, Neighborhood filtering and NL-means algorithm.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 4 .4Figure 4. Method noise experience on a natural image. Displaying of the image difference u\u2212D h (u). From left to right and from top to bottom: original image, Gauss filtering, anisotropic filtering, Total variation minimization, Neighborhood filtering and NL-means algorithm. The visual experiments corroborate the formulas of section 2.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "compares the performance of the NL-means and local smoothing filters for a natural texture. Natural images also have enough redundancy to be restored by NL-means. Flat zones present a huge number of similar configurations lying inside the same object, see Figure 2 (a). Straight or curved edges have a complete line of pixels with similar configurations, see Figure 2 (b) and", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Figure 5 .5Figure 5. Denoising experience on a natural image. From left to right and from top to bottom: noisy image (standard deviation 20), Gauss filtering, anisotropic filtering, Total variation, Neighborhood filtering and NLmeans algorithm. The removed details must be compared with the method noise experience, Figure 4.", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "", "figure_data": "ImageGF AF TVF YNF NLLena120 114 11012968Baboon 507 418 365381 292"}], "formulas": [{"formula_id": "formula_0", "formula_text": "v(i) = u(i) + n(i),(1)", "formula_coordinates": [1.0, 137.56, 464.45, 157.44, 9.96]}, {"formula_id": "formula_1", "formula_text": "v = D h v + n(D h , v),", "formula_coordinates": [1.0, 391.25, 258.65, 88.75, 10.19]}, {"formula_id": "formula_2", "formula_text": "NL[u](x) = 1 C(x) \u2126 e \u2212 (Ga * |u(x+.)\u2212u(y+.)| 2 )(0) h 2 u(y) dy, where x \u2208 \u2126, C(x) = \u2126 e \u2212 (G a * |u(x+.)\u2212u(z+.)| 2 )(0) h 2", "formula_coordinates": [1.0, 317.51, 510.3, 231.26, 52.11]}, {"formula_id": "formula_3", "formula_text": "u \u2212 D h u.", "formula_coordinates": [2.0, 157.0, 225.41, 39.75, 10.19]}, {"formula_id": "formula_4", "formula_text": "x \u2192 G h (x) = 1 (4\u03c0h 2 ) e \u2212 |x| 2 4h 2 .", "formula_coordinates": [2.0, 58.75, 536.13, 115.37, 18.93]}, {"formula_id": "formula_5", "formula_text": "G h is u \u2212 G h * u = \u2212h 2 \u2206u + o(h 2 ), for h small enough.", "formula_coordinates": [2.0, 58.76, 590.77, 182.61, 53.7]}, {"formula_id": "formula_6", "formula_text": "AF h u(x) = G h (t)u(x + t Du(x) \u22a5 |Du(x)| )dt,", "formula_coordinates": [2.0, 352.18, 156.31, 166.88, 24.91]}, {"formula_id": "formula_7", "formula_text": "AF h is u(x) \u2212 AF h u(x) = \u2212 1 2 h 2 |Du|curv(u)(x) + o(h 2 ),", "formula_coordinates": [2.0, 317.51, 273.73, 222.47, 41.21]}, {"formula_id": "formula_8", "formula_text": "TVF \u03bb (v) = arg min u T V (u) + \u03bb |v(x) \u2212 u(x)| 2 dx", "formula_coordinates": [2.0, 330.19, 524.57, 210.88, 16.56]}, {"formula_id": "formula_9", "formula_text": "u(x) \u2212 TVF \u03bb (u)(x) = \u2212 1 2\u03bb curv(TVF \u03bb (u))(x).", "formula_coordinates": [2.0, 338.25, 651.0, 194.76, 23.53]}, {"formula_id": "formula_10", "formula_text": "YNF h,\u03c1 u(x) = 1 C(x) B\u03c1(x) u(y)e \u2212 |u(y)\u2212u(x)| 2 h 2 dy, (2)", "formula_coordinates": [3.0, 67.92, 171.8, 223.37, 24.51]}, {"formula_id": "formula_11", "formula_text": "x \u2208 \u2126, C(x) = B\u03c1(x) e \u2212 |u(y)\u2212u(x)| 2 h 2", "formula_coordinates": [3.0, 81.83, 207.16, 139.46, 18.53]}, {"formula_id": "formula_12", "formula_text": "SNF h,\u03c1 u(x) = 1 C(x) \u2126 u(y)e \u2212 |y\u2212x| 2 \u03c1 2 e \u2212 |u(y)\u2212u(x)| 2 h 2 dy,(3)", "formula_coordinates": [3.0, 65.18, 306.38, 226.12, 34.0]}, {"formula_id": "formula_13", "formula_text": "C(x) = \u2126 e \u2212 |y\u2212x| 2 \u03c1 2 e \u2212 |u(y)\u2212u(x)| 2 h 2", "formula_coordinates": [3.0, 81.64, 340.46, 128.6, 20.01]}, {"formula_id": "formula_14", "formula_text": "NL[v](i) = j\u2208I w(i, j)v(j),", "formula_coordinates": [3.0, 115.6, 603.84, 115.14, 20.61]}, {"formula_id": "formula_15", "formula_text": "E||v(N i ) \u2212 v(N j )|| 2 2,a = ||u(N i ) \u2212 u(N j )|| 2 2,a + 2\u03c3 2 .", "formula_coordinates": [3.0, 321.44, 397.25, 220.96, 13.54]}, {"formula_id": "formula_16", "formula_text": "w(i, j) = 1 Z(i) e \u2212 ||v(N i )\u2212v(N j )|| 2 2,a h 2 ,", "formula_coordinates": [3.0, 362.14, 502.11, 139.58, 24.24]}, {"formula_id": "formula_17", "formula_text": "Z(i) = j e \u2212 ||v(N i )\u2212v(N i )|| 2 2,a h 2", "formula_coordinates": [3.0, 370.82, 559.43, 120.03, 28.63]}, {"formula_id": "formula_18", "formula_text": "(i) = E[Y i | X i = v(N i \\{i})].", "formula_coordinates": [4.0, 57.52, 437.77, 236.26, 22.15]}, {"formula_id": "formula_19", "formula_text": ") Let Z = {V (i), V (N i \\{i})} for i = 1, 2, . . .", "formula_coordinates": [4.0, 57.52, 467.45, 236.25, 22.15]}, {"formula_id": "formula_20", "formula_text": "Z n = {V (i), V (N i \\{i})} n i=1 . Then, |NL n (j) \u2212 r(j)| \u2192 0 a.s for j \u2208 {1, . . . , n}.", "formula_coordinates": [4.0, 57.52, 503.31, 236.25, 57.36]}, {"formula_id": "formula_21", "formula_text": "(i) E[V (i) | X i = x] = E[U (i) | X i = x] for all i \u2208 I and x \u2208 R p . (ii) The expected random variable E[U (i) | V (N i \\{i})]", "formula_coordinates": [4.0, 319.04, 294.0, 233.46, 41.96]}, {"formula_id": "formula_22", "formula_text": "min g E[U (i) \u2212 g(V (N i \\{i}))] 2", "formula_coordinates": [4.0, 381.38, 369.45, 125.41, 16.56]}], "doi": ""}