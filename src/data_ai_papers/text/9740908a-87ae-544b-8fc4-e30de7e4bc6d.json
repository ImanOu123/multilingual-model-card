{"title": "Thin Junction Tree Filters for Simultaneous Localization and Mapping (Revised May 14, 2003) *", "authors": "Mark A Paskin", "pub_date": "2002-09", "abstract": "Simultaneous Localization and Mapping (SLAM) is a fundamental problem in mobile robotics: while a robot navigates in an unknown environment, it must incrementally build a map of its surroundings and localize itself within that map. Traditional approaches to the problem are based upon Kalman filters, but suffer from complexity issues: the size of the belief state and the time complexity of the filtering operation grow quadratically in the size of the map. This paper presents a filtering technique that maintains a tractable approximation of the filtered belief state as a thin junction tree. The junction tree grows under measurement and motion updates and is periodically \"thinned\" to remain tractable via efficient maximum likelihood projections. When applied to the SLAM problem, these thin junction tree filters have a linear-space belief state representation, and use a linear-time filtering operation. Further approximation can yield a constant-time filtering operation, at the expense of delaying the incorporation of observations into the majority of the map. Experiments on a suite of SLAM problems validate the approach. * This is a reorganized and expanded version of the original report that includes some experimental results. Shortly it will be revised again to include the results of more experiments.", "sections": [{"heading": "Introduction", "text": "Simultaneous Localization and Mapping (SLAM) is a fundamental problem in mobile robotics: while a robot navigates in an unknown environment, it must incrementally build a map of its surroundings and localize itself within that map . The traditional approach treats SLAM as a Kalman filtering problem [Smith and Cheeseman, 1986;Smith et al., 1990;Leonard et al., 1992]. The system state at time t is\nm t = \uf8ee \uf8ef \uf8ef \uf8ef \uf8f0 x t l 1 . . . l nt \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fb (1)\nwhere x t is the pose of the robot at time t, l i is the state of landmark i (landmarks are assumed stationary) and n t is the number of landmarks observed up to time t. 1 (Thus, the length of the state vector will increase over time, as more landmarks are observed.) The filtered belief state at time t, p(m t | observations to time t), is a multivariate Gaussian distribution N (\u00b5 t , \u03a3 t ); we can view its mean \u00b5 t as an estimate of the map m t and its covariance matrix \u03a3 t as a measure of its estimation confidence.\nThe Kalman filter solution is elegant, but it does not scale to large SLAM problems. Because it explicitly represents correlations between all pairs of landmark estimates (in \u03a3 t ), the size of its belief state grows as O(n 2 t ); and because each of these correlations must be updated whenever a landmark is reobserved, the time complexity of its filter operation is also O(n 2 t ). This quadratic complexity renders the Kalman filter inapplicable to large SLAM problems and gives rise to the need for principled, efficient approximations.\nThe simplest approach to this problem is to discard correlations so each variable is estimated independently; however, this presents two problems. First, ignoring robot-landmark correlations leads to overconfidence and divergence; this happens because the filter fails to account for the fact that multiple observations of the same landmark may give the same or similar information about its location [H\u00e9bert et al., 1996]. Second, maintaining inter-landmark correlations is required for quick convergence when the robot closes a loop, i.e., it reobserves known landmarks after an extended period of mapping unknown territory. Thus, the challenge of scalable SLAM filtering is to estimate and reason with quadratically many correlations without quadratic time or space complexity.\nIn this report we present a novel and general approximate filtering method satisfying this criterion. Our point of departure (in Section 2) is to view the belief state of the Kalman filter as a Gaussian graphical model that evolves over time; this allows us to express correlations-which the Kalman filter represents explicitly-in terms of direct and indirect dependencies. Analyzing the evolution of this graphical model motivates an approximation scheme in which weak or redundant dependencies are removed to improve the complexity of inference. Because some direct dependencies remain, indirect dependencies-and thus correlations-persist between each pair of variables.\nTo implement such a scheme, we represent the filter belief state using a junction tree. In Section 3 we present methods for updating this representation to reflect measurements of the system and its evolution. These updates can cause the width of the junction tree to grow, which makes inference more expensive; in Section 4 we present a novel \"thinning\" operation over junction trees called variable contraction. 2 We prove that each variable contraction is a maximum likelihood approximation that removes a set of edges from the corresponding graphical model. The approximation error introduced by a variable contraction can be computed efficiently; this allows us to choose which edges to remove at each time step so as to minimize the error.\nIn Section 5 we apply these techniques to the SLAM problem and obtain a Thin Junction Tree Filter (TJTF) with a O(n t ) space belief state representation and a O(n t ) time filter operation. By delaying the incorporation of recent evidence into the majority of the map, we improve the filter's time complexity to O(1). We also present a method of evaluating the significance evidence has on different portions of the map, which can be used to adaptively interpolate between constant and linear-time filter operations. Empirically, we find that these adaptive filters choose constant-time updates when mapping new territory, and when closing a loop, they use time linear in the length of the loop. This is perhaps the best time complexity one would hope for in the SLAM problem, since linearly-many estimates cannot be improved in constant time. Section 6 presents the results of simulation experiments that compare TJTF to other SLAM filters and Section 7 concludes by drawing connections between the present proposal and other approaches.", "publication_ref": ["b19", "b19", "b13", "b10"], "figure_ref": [], "table_ref": []}, {"heading": "The Kalman filter approach to SLAM", "text": "The traditional approach to SLAM endows m with a multivariate Gaussian distribution N (\u00b5, \u03a3), and assumes known affine measurement and motion models so that the Kalman filter can be used to estimate the map given the robot's actions and observations. (See Appendix A for background on the multivariate Gaussian distribution, the Kalman filter, and its traditional application to SLAM.) The two operations the filter must support are measurement updates (in which the robot observes a landmark or receives an odometry measurement), and motion updates (in which the robot moves).\nAt time step t, the robot makes k t landmark measurements, which we will denote z 1 t , z 2 t , . . . , z kt t . The correspondence between the measurements and the landmarks from which they originated is represented by a data association variable \u03b4 t : landmark measurement z i t originates from landmark \u03b4 i t . Given \u03b4 t , each landmark measurement is modeled as a noisy affine function of the state:\nz i t = Ex t + F l \u03b4 i t + g + u (2)\nwhere u \u223c N (0, S) is an independent white noise variable. (Of course, the parameters E, F , g and S may differ for different measurements.) Thus, all measurements are conditionally independent given m t and \u03b4 t . When the data association \u03b4 t is unknown, it is popular to assume it is distributed uniformly and approximate it with its a posteriori maximum likelihood value under p(\u03b4 t | m t , z t ); i.e., we choose \u03b4 t to be that value that associates each measurement with the landmark that was most likely to generate it. In some domains, data associations are constrained such that two measurements cannot be associated with the same landmark; in this case, we can evaluate the likelihoods p(z i t | x t , l j , \u03b4 i t = j) for all measurements i and landmarks j, and performing a global matching (using, say, the Hungarian algorithm). Using this technique in very noisy environments can lead to incorrect associations, which are usually followed by catastrophic divergence of the filter; more sophisticated techniques maintain a set of hypothetical associations. In this work, we will assume that the data association is known.\nNew landmarks can be added to the map by a technique called gating, wherein measurements whose likelihoods under all data associations are below some threshold cause new landmarks to be added to the map (see Appendix B.3). In this case, the landmark state is added to the map with an uninformative (infinite variance, zero covariance) prior, and the measurement update yields an informed posterior estimate of its state (see Appendix B.2). In order to avoid incorrectly adding landmarks due to extremely noisy measurements, practical implementations usually require a hypothesis landmark to have absorbed a certain number of measurements before it is permanently added to the map.\nAfter observing the landmarks, the robot moves based upon a noisy affine model:\nx t+1 = Ax t + b + v (3) x 1 z 1 1 z 2 1 z 3 1 x y 2 z 1 2 z 2 2 x 3 y 3 z 1 3 z 2 3 z 3 3 l 1 l 2 l 3 l 4 l 5\nFigure 1: A DBN representing three time steps of an example SLAM problem. The edges from landmarks to measurements are determined by data association; e.g., \u03b4 1 2 = 2 in this example, and so there is an edge from l 2 to z 1 2 .\nwhere v \u223c N (0, Q) is an independent white noise variable. (The parameters of this model, A, b, and Q, may depend implicitly upon a control u t applied at time t.) Then it obtains an odometry measurement y t+1 , which is a noisy affine function of its new state:\ny t+1 = Cx t+1 + d + w (4)\nwhere w \u223c N (0, R) is an independent white noise variable.\nIn the common case where the measurement and motion functions are not affine with independent Gaussian noise, it is standard to approximate them as such using either the Extended Kalman Filter (EKF) or the Unscented Kalman Filter (UKF) [Wan and van der Merwe, 2000]. The UKF generally gives more accurate results because it uses second-order terms from the function's Taylor expansion, whereas the EKF is a firstorder method. However, the UKF requires knowledge of both the mean and covariance of the function inputs, whereas the EKF requires only the mean. Because this linearization requires inference to determine around what input the nonlinear function should be approximated, fast inference is essential to SLAM filtering. (See Appendix B.4 for details on the EKF and UKF.)\nPerhaps the best way to visualize the dependencies between the variables of a SLAM problem is with a dynamic Bayesian network (DBN). 3 Figure 1 depicts the DBN for three time steps of an example SLAM inference problem. For example, each measurement z i t depends only upon the state of the robot x t and the state of the landmark that was observed l \u03b4 i t (assuming a known data association \u03b4 t ). Hence, in Figure 1, each observed measurement node takes only these nodes as parents. Also, the state of the robot at time t + 1 depends only upon its previous state x t . Finally, the odometry measurement y t at time t depends only upon the current state of the robot x t .", "publication_ref": ["b25"], "figure_ref": [], "table_ref": []}, {"heading": "The complexity problem and previous approaches", "text": "Using the Kalman filter for SLAM quickly runs into problems. First, its representation of the belief state (or more specifically, the covariance matrix \u03a3) grows quadratically with the number of landmarks. Second, the time complexity of incorporating measurements via equation ( 71) also grows quadratically in the number of landmarks, regardless of how few variables are being measured. 4 The computational complexity of the Kalman filter make it inapplicable to large scale mapping problems, and give rise to the need for principled, efficient approximations. Significant interest in this problem has led to a number of approaches. We will examine three: Rao-Blackwellised particle-filters, sub-map approaches, and Sparse Extended Information Filters.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Rao-Blackwellised particle filters", "text": "One family of techniques involves using approximate inference. From the model description above, it can be shown that conditioned on the path of the robot, the states of all the landmarks are independent of each other. (For example, in Figure 1 x 1 , x 2 , and x 3 d-separate all the l i from each other.) This motivates a Rao-Blackwellized particle filtering scheme: the estimate of the robot's path is represented by a set of particles (or samples); within each particle is a bank of tiny Kalman filters, one to represent the state estimate of each landmark, conditioned on the robot's path [Doucet et al., 2000]. This representation, combined with a clever particle representation that avoids unnecessary copying of the landmark estimates during resampling, comprises the FastSLAM algorithm, which has an impressively fast O(k log n) time filter operation (where k is the number of particles) [Montemerlo et al., 2002].\nThe primary advantages of the FastSLAM approach are threefold: it has excellent time complexity; it does not need to linearize the robot's motion or odometry models 5 ; and, most importantly, it can represent multimodal distributions over the robot's state, which makes it particularly useful in tasks where global localization is also important [Thrun et al., 2001].\nHowever, there are also drawbacks. The first is that each particle has a different view of the map, including the estimates and even the number of landmarks; integrating these views to obtain a single map is nontrivial, and more importantly, data association must be performed for each particle independently. While this gives the representation a great deal of flexibility (in that the model need not commit to a particular maximum likelihood data association), it also introduces a significant computational burden (because data association can be expensive). Methods of integrating data association into FastSLAM are presented in [Montemerlo and Thrun, 2002].\nThe second problem is that FastSLAM is prone to diverge in regions where its measurements are not very informative, either due to high noise or a sparseness of landmarks. In particle filters like FastSLAM, good performance hinges on having a particle population that is large enough to \"fill\" the high-probability portion of the state space; for if there are too few particles, the filter is essentially ignoring likely hypotheses of the hidden state. In FastSLAM, the problem is aggravated by the curse of dimensionality: the state space of the particles is the set of all possible paths of the robot-not states-and so its dimension increases linearly with time. Thus, we have a situation where a constant number of particles is used to fill the high probability region of a state space whose volume is growing exponentially over time. The only regime in which we can hope to avoid the curse of dimensionality is when the volume of the high-probability region remains small, in spite of the increasing dimension of its embedding space. This volume increases when the robot moves due to motion noise, but it decreases when informative landmark and odometry measurements are made; thus, FastSLAM requires frequent, informative measurements to avoid divergence. 6 The successful application of FastSLAM to real-world SLAM problems indicates that this is possible [Montemerlo and Thrun, 2002].", "publication_ref": ["b6", "b17", "b22", "b17", "b17"], "figure_ref": [], "table_ref": []}, {"heading": "Submap approaches", "text": "Rather than using approximate inference on the exact model, we can also use exact inference on tractable approximations of the true model. Another family of techniques involves a decomposition of the map into a set of submaps, one or more of which maintain (independent) estimates of the robot's state. When the submaps are small enough, mapping each independently is tractable; the difficulty is \"stitching\" the submaps together.\nThere are now numerous approaches based upon this idea. The Decoupled Stochastic Mapping technique of [Leonard and Feder, 2000] uses a global coordinate system and splits the world into overlapping submaps. The Atlas framework of [Bosse et al., 2002] uses submaps that have independent local coordinate systems and are related by a graph of coordinate transformations. The Suboptimal SLAM filter of [Guivant and Nebot, 2000] does not have an explicit notion of submap, but updates a small number of local landmarks at each time step. Each of these techniques obtains a constant-time update (because the size of the mapping problem addressed at each time step is independent of the total number of landmarks). However, techniques for passing information between the maps are limited, and thus these methods can converge very slowly.\nThe Compressed Filter [Guivant and Nebot, 2000] and Linear Sequence Mapping [Tard\u00f3s et al., 2001] use the submap approach in a somewhat different way: the robot maps a local region until its map reaches a predefined size, and then the map is incorporated into a (large) global map in a single Kalman update. This does not avoid the quadratic complexity of the Kalman filter, but it can significantly reduce the constant factor. The map update is correct so long as the global and local maps are conditionally independent given the current state of the robot, which happens whenever they do not represent a landmark in common.", "publication_ref": ["b12", "b1", "b9", "b9", "b21"], "figure_ref": [], "table_ref": []}, {"heading": "Sparse extended information filters", "text": "Sparse Extended Information Filters (SEIF) [Thrun et al., 2002] go one step further, and employ approximate inference over an approximate model. As its name suggests, SEIF is based upon the information filter and uses the EKF to linearize nonlinear motion and measurement models. The fundamental observation of SEIF is that even if the covariance matrix \u03a3 is dense, the precision matrix \u039b may be sparse or many of its entries may be small; moreover, when \u039b is sparse, measurement and motion updates can be made to happen in constant time. Thus, at each time step SEIF selectively zeros-out small entries of \u039b, and thereby obtains a constant-time approximate filter update. (In Section 2.4 we develop a similar filter that takes makes no sparseness assumptions and thereby obtains a quadratic-time update.)\nIt is worth noting that it is nontrivial to zero-out arbitrary entries of a precision matrix, because the resulting matrix must still be positive semidefinite. The maximum likelihood approximation to \u039b with an arbitrary sparsity pattern can be computed by the Iterative Proportional Fitting algorithm [Speed and Kiiveri, 1986]; however, as this algorithm is iterative (and slow), it is unsuitable for a projection operation that must be applied at every time step. SEIF avoids this cost by allowing new nonzero entries (which do not significantly affect the time complexity) to be introduced when others are removed.\nIn spite of its unbeatable time complexity, SEIF has a significant representational problem. Recovering the map \u00b5 or the covariance matrix \u03a3 from the canonical parameterization used by SEIF requires inverting \u039b, which takes time cubic in the number of landmarks. This is troublesome not only because the map is inaccessible; subvectors of \u00b5 are required to use the EKF to linearize nonlinear measurement and motion models, and subblocks of \u03a3 are required for the UKF or for data association. The solution adopted by SEIF is to efficiently approximate the map \u00b5 by taking a constant number of hill-climbing steps in the probability density, and to approximate the marginal landmark covariances needed for data association using conditional covariances that can be computed in constant time. There is empirical evidence that these approximations can perform well; simulation studies have shown that the approximate map recovery is not a large source of error [Thrun et al., 2002], and data association using conditional covariances seems to work well, in spite of the fact that it should be overconfident [Liu and Thrun, 2002].  ", "publication_ref": ["b23", "b20", "b23", "b15"], "figure_ref": [], "table_ref": []}, {"heading": "On constant-time algorithms and \"closing the loop\"", "text": "Some of the approximations described above achieve a constant-time filter update, which seems desirable. However, there are situations in SLAM problems where it seems that some measurements should cause a linear-time update.\nConsider the case where the robot closes the loop, i.e., it reobserves a landmark after a long period of mapping unknown territory. In this scenario, reobserving landmarks whose positions are known with relative certainty helps the robot localize; its improved position estimate improves the estimates of recently observed landmarks via the robot-landmark correlations; finally, inter-landmark correlations improve the estimates of the other landmarks on the tour. (Robot-landmark correlations decay over time due to motion noise, so they are too weak to improve estimates of landmarks observed in the distant past.) Figure 2 demonstrates this phenomenon.\nThus, if the robot's path consists of one long loop, the robot's reobservation of its starting location can potentially improve all of its landmark position estimates. To do this, however, the measurement update would require time linear in the number of landmarks. 7 At best, a constant-time measurement update could improve the location estimates of constantly many landmarks, and achieve convergence by repeatedly retracing its steps; but this seems wasteful. Perhaps the best complexity one would want in a SLAM filter is one that can choose to perform constant time updates when mapping new territory (and the majority of the map remains unchanged), and then switch to a linear-time update when the robot closes the loop.", "publication_ref": [], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "A graphical model perspective", "text": "The approach presented here employs exact inference over an approximate model, and can be viewed as a generalization of both the submap approach and SEIF (as we discuss in Section 7). Importantly, it improves significantly over both techniques, culminating in an efficient, flexible, and principled approximation algorithm. The easiest way to motivate the present approach is in the graphical model framework. We begin by presenting our notation and vocabulary for graphical models.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Gaussian graphical models", "text": "A potential function is any function whose range is R + , the nonnegative real numbers. A graphical model G = (V, \u03a8) consists of a set of random variables V and a set of potential functions \u03a8 over subsets of V . The probability density represented by G is\np G (V ) = 1 Z \u03c8\u2208\u03a8 \u03c8(V \u03c8 )(5)\nwhere V \u03c8 \u2286 V is the domain of \u03c8 and\nZ = V \u03c8\u2208\u03a8 \u03c8(V \u03c8 )(6)\nis a normalization constant to ensure p G integrates to unity over V . The (Markov) graph associated with G has vertex set V and an edge between two variables u and v iff u, v \u2208 V \u03c8 for some potential \u03c8 \u2208 \u03a8. Given p G > 0, the Hammersley-Clifford Theorem says (roughly) that the graph separation relation in the Markov graph of G is exactly the conditional independence relation over V , i.e., if A, B, and S are subsets of V such that S separates A and B in the Markov graph of G, then A\u22a5 \u22a5B | S, i.e, A is conditionally independent of B given S.\nGraphical models are useful to identify conditional independence structure in a multivariate Gaussian distribution. In this case, we typically use the canonical parameterization of the Gaussian (see Appendix A.1). The Gaussian (43) can be represented by a graphical model, since if we partition x = {x 1 , . . . ,\nx n } p(x) = 1 Z n i=1 \u03c8 i (x i ) n j=i+1 \u03c8 ij (x i , x j )(7)\nwhere\n\u03c8 i (x i ) = exp \u03b7 i x T i \u2212 1 2 x T i \u039b ii x i (8) \u03c8 ij (x i , x j ) = exp \u2212x T i \u039b ij x j(9)\nand Z = e \u2212a is the normalization constant. Thus, all the potential functions in a Gaussian graphical model are either unary (node potentials) or binary (edge potentials). We also have the important interpretation that if \u039b ij = 0, then \u03c8 ij (x i , x j ) is unity (and therefore superfluous), meaning there is no edge between x i and x j . Thus, \u039b can be viewed as an adjacency matrix for the graphical model. When the belief state is represented as a graphical model, filtering can be viewed as a three-step procedure [Russell and Norvig, 2002]: 1. prediction, in which we augment the model with the state variables of the next time step; 2. roll-up, in which we marginalize out the state variables from the past time step; and 3. estimation, in which we incorporate the current time step's measurements.\nIn the next two sections, we examine the structural and parametric changes caused by these updates.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Structural updates during filtering", "text": "Representing the belief state using graphical models has some advantages over the traditional multivariate Gaussian representation. The first advantage is that the quadratic growth of the size of the belief state is easily understood by viewing filtering (which is nothing more than marginalizing out variables from past time steps) as an instance of the variable elimination algorithm [Russell and Norvig, 2002].\nLet us begin with the first time slice of the example SLAM DBN in Figure 1. Figure 3 depicts the landmark measurement portion of the first time step. Eliminating each measurement node adds an elimination edge between the robot's state and those of the observed landmarks. (Intuitively, each measurement imposes an uncertain constraint between the state of the robot and the observed landmark, which is reflected by the undirected edge. We can imagine the robot thinking, \"I'm not sure where I am or where that landmark is, but I'm pretty certain it is five meters in front of me; so if I learn where I am, I'll have a good idea of where it is, and vice-versa.\") Using the terminology of [Thrun et al., 2002], we will call the set of landmarks that are directly dependent upon x t (i.e., no other set of variables can render them conditionally independent of x t ) the active landmarks; thus, a landmark becomes active as soon as it is measured.\nThus far, our model is still tractable, since the graph is in the form of a tree. However, when we perform roll-up (depicted in Figure 4), the situation changes. Eliminating the robot's previous state variable creates an elimination clique over the robot's new state variable and all of the active landmarks. The intuition here is more subtle, but worth understanding: in the previous model, weak constraints existed between all pairs of active landmarks via their individual couplings to the previous state of the robot; when the robot's previous state variable is eliminated from the model, these indirect couplings must be represented by explicit edges. However, as Figure 5 demonstrates, these indirect couplings are weaker than the direct ones and can include a good deal of redundancy. These two facts suggest that eliminating some of these dependencies may not significantly affect the quality of the map estimate, an intuition that motivates both SEIF and the current proposal.\nOnce a landmark becomes active (by observation), it will never again become inactive. Thus, if k landmarks have been observed up to time t, then the filtered distribution after the time-t roll-up will have a cluster containing k + 1 variables and it will take O(k 2 ) space to represent the parameters of this cluster.", "publication_ref": ["b17", "b23"], "figure_ref": ["fig_2", "fig_4", "fig_6"], "table_ref": []}, {"heading": "Parameter updates during filtering", "text": "While the graphical model we have given in Figure 1 is directed, we will focus more on undirected graphical models: they are the natural method of representing conditional independence statements about multivariate Gaussian distributions, and, the graphical models we are left with after estimation updates and roll-up are undirected (see Figures 3(c) and 4(d)).\nFor conceptual clarity, we partition the map variable as follows. Let m (0) = x and m (i) = l i , let \u03b7 (i) be the subvector of \u03b7 corresponding to m (i) , and let \u039b (ij) be the submatrix of \u039b corresponding to m (i) and m (j) . Then we can write    When represented conditional on the state of l1, the confidence regions of l2 and l3 shrink by 80% and 75% (respectively) from their counterparts in (a): knowing l1 helps us localize l2 and l3. However, these reductions are not as significant as the reduction obtained by conditioning on x, as in (b). Thus, the indirect landmarklandmark dependencies are weaker than the direct robotlandmark dependencies.\np(m) = 1 Z n i=0 \u03c8 i (m (i) ) n j=i+1 \u03c8 ij (m (i) , m (j) )(10)\nx 1 z 1 1 z 2 1 z 3 1 l 1 l 2 l 3 (a) x 1 z 1 1 z 2 1 z 3 1 l 1 l 2 l 3 (b) x 1 l 1 l 2 l 3 (c)\n1 l 1 l 2 l 3 x 2 y 2 (a) x 1 l 1 l 2 l 3 x 2 y 2 (b) x 1 l 1 l 2 l 3 x 2 (c) x 2 l 1 l 2 l 3 (d)\nl 1 (2.1) l 2 (2.3) l 3 (0.36) (d) p(l1, l2)p(l3 | l1, l2):\nWhen represented conditional on the states of l1 and l2, the confidence region of l3 shrinks by 85% (or only an additional 10% over the reduction obtained by conditioning on l1 alone), demonstrating redundancy in the indirect dependencies: the information l1 and l2 jointly give about l3 is not twice as much as the information given by l1 alone. where\n\u03c8 i (m (i) ) = exp \u03b7 T (i) m (i) \u2212 1 2 m T (i) \u039b (ii) m (i)(11)\nand\n\u03c8 ij (m (i) , m (j) ) = exp \u2212m T (i) \u039b (ij) m (j)(12)\nand Z = e \u2212a is the normalization constant. We will alternatingly view the parameters of a Gaussian graphical model as a set of node and edge potentials (with functional forms ( 11) and ( 12)) or as the vector \u03b7 and matrix \u039b that underlie them. Thus, when we speak of \"multiplying in\" new unary and binary potentials, this corresponds to straightforward additive updates to \u03b7 and \u039b.\nThere are three types of changes made to the graphical model during filtering: estimation, prediction, and roll-up. Each of these updates can be implemented by multiplying small, simple potentials into the current graphical model. We begin with the following proposition, which summarizes some algebra: Proposition 1. Let q be a random n-vector distributed according to p(q, r) (for any arbitrary random variable r) and let the random variable s be defined via the affine-Gaussian equation\ns = s 0 + Lq + t (13\n)\nwhere s 0 and L are constants and t \u223c N (0, U ). Then\np(q, r, s) \u221d p(q, r) \u2022 \u03c6 q (q) \u2022 \u03c6 s (s) \u2022 \u03c6 qs (q, s)(14)\nwhere\n\u03c6 q (q) = exp \u2212s T 0 U \u22121 Lq \u2212 1 2 q T L T U \u22121 Lq (15) \u03c6 s (s) = exp s T 0 U \u22121 s \u2212 1 2 s T U \u22121 s (16) \u03c6 qs (q, s) = exp s T U \u22121 Lq (17) Furthermore, p(q, r | s) \u221d p(q, r) \u2022 \u03c6 q (q)(18)\nwhere\n\u03c6 q (q) = exp (s \u2212 s 0 ) T U \u22121 Lq \u2212 1 2 q T L T U \u22121 Lq(19)\n(The proof of this and all other propositions is given in Appendix C.) The import of this proposition is that we can update the graphical model to reflect landmark measurements, odometry measurements, and robot motion by multiplying in small, simple potentials. Equivalently, since these potentials are all of the forms ( 11) or ( 12), these updates can be accomplished by additive updates to small portions of \u03b7 and \u039b. We describe this process in more detail below.", "publication_ref": [], "figure_ref": ["fig_2"], "table_ref": []}, {"heading": "Estimation updates", "text": "Since all landmark measurements are assumed independent, we will deal with the case of a single measurement z originating from the landmark l. By applying Proposition 1 (with s = z, q = (x, l), s 0 = g, and L = [ E F ]), we find that we can condition on z by multiplying the binary potential\n\u03c6 (x, l) = exp (z \u2212 g) T S \u22121 (Ex + F l) \u2212 1 2 (Ex + F l) T S \u22121 (Ex + F l)\ninto the graphical model. Equivalently, we can update the parameters \u03b7 and \u039b as follows:\n\u03b7 x + \u2190 E T S \u22121 (z \u2212 g) \u03b7 l + \u2190 F T S \u22121 (z \u2212 g) \u039b xx + \u2190 E T S \u22121 E \u039b ll + \u2190 F T S \u22121 F \u039b xl + \u2190 E T S \u22121 F (20)\nwhere a + \u2190 b means \"increment a by the value b.\" We can now see algebraically how the new edges in Figure 3(c) arise, since \u039b xl becomes non-zero after this update.\nA second application of the proposition gives that the odometry model p(y t+1 | x t+1 ) can be multiplied in via the following updates:\n\u03b7 x t+1 + \u2190 C T R \u22121 (y \u2212 d) \u039b x t+1 x t+1 + \u2190 C T R \u22121 C (21)", "publication_ref": [], "figure_ref": ["fig_2"], "table_ref": []}, {"heading": "Prediction update", "text": "The prediction update consists of adding a new node x t+1 and connecting it to x t via the potential function p(x t+1 | x t ). Using Proposition 1, we find that the motion model p(x t+1 | x t ) can be multiplied into the graphical model via the following updates:\n\u03b7 xt + \u2190 \u2212b T Q \u22121 A \u03b7 x t+1 \u2190 bQ \u22121 \u039b xtxt + \u2190 A T Q \u22121 A \u039b x t+1 x t+1 \u2190 Q \u22121 \u039b xtx t+1 \u2190 A T Q \u22121 (22)\nwhere a \u2190 b means \"assign a the value b.\"", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Roll-up", "text": "To \"roll up\" the DBN, we must marginalize out the previous state variable x t . This too can be implemented by multiplying potentials onto the graphical model. The rule for marginalizing out a variable x from a multivariate Gaussian distribution is given in Appendix A.2. However, by leveraging the structure of the graphical model, we can speed up the computation. Because zero entries of \u039b correspond to missing edges in the graphical model, we can see that the only entries of \u03b7 and \u039b that change in (50) are those that correspond to variables in the Markov blanket of x t , i.e., the set of neighbors of x t . If we denote the Markov blanket of x byx, then the update is as follows:\n\u03b7x + \u2190 \u2212\u039bx x \u039b \u22121 xx \u03b7 x \u039bxx + \u2190 \u2212\u039bx x \u039b \u22121 xx \u039b xx (23)\nAfter this update is completed, we can discard all potentials involving x and eliminate the node from our graphical model. Note that although we have written this update in terms of the parameters \u03b7 and \u039b, we could equally well express it in terms of multiplying in node and edge potentials over the Markov blanket of x t .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "An information filter for SLAM", "text": "Our results thus far define a filter whose belief state is a graphical model. However, as we noted in Section 2.2, the graphical model is degenerate; it is complete after every roll-up step, which means that it is characterized by a single potential function. Because that potential function is in the canonical parameterization, we have effectively defined an information filter for the SLAM problem.\nThe belief state of the filter will be a single Gaussian N \u22121 (\u03b7, \u039b). Our filter steps are:\n1. prediction, where we add the state variables from the next time step. This can be accomplished in constant time using the update ( 22).\n2. estimation, where we condition on the current time-slice's observations. Assuming constantly many landmarks are observed, this too can be accomplished in constant time. We apply (20) for each landmark measurement and ( 21) for the odometry update.\n3. roll-up, where we marginalize out the state variables of the previous time slice. This can be accomplished using ( 23), which takes time quadratic in the number of landmarks.\nThe space complexity of this filter operation is linear in the length of the filtering problem (assuming a constant number of landmarks are observed per time step), because each observation can create one nonzero entry in \u039b.\nIf the motion and measurement models are known in advance, then this completes the description of the algorithm. However, when we must linearize our motion and measurement models, we require subvectors of \u00b5 (for the EKF) and possibly subblocks of \u03a3 (for the UKF) at each time step. We can compute these quantities exactly in cubic time by inverting \u039b, or can approximate them in constant time using SEIF's techniques of approximate map recovery and using conditional landmark covariances rather than marginal ones .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Junction tree filtering", "text": "Exact inference in graphical models is frequently based upon message passing in a junction tree, which is a special data structure based upon the graphical model [Cowell et al., 1999]. We adopt consistent junction trees as our representation of the belief state. This gives us efficient access the filtered marginals of any sets of variables contained in the same cluster; we just marginalize out the unwanted variables from the (consistent) cluster potential. 8 In our context, the graphical model changes over time, and so we must consider methods of maintaining the junction tree incrementally over time. From the discussion above, we see that we require a junction tree representation that allows us to (1) add new node and edge potentials (for observations and motion) and to (2) marginalize out nodes (specifically, the robot state at the previous time step). In this section, we describe how all of these updates can be applied to the junction tree incrementally. We begin with a brief review of junction trees to introduce notation.", "publication_ref": ["b5"], "figure_ref": [], "table_ref": []}, {"heading": "Junction trees", "text": "A junction tree T for a graphical model G = (V, \u03a8) is an undirected graph such that each vertex (or cluster) C is a subset of the variables V and the following three properties hold:\n1. Singly connected property: T is a tree.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Potential property:", "text": "For every potential \u03c8 \u2208 \u03a8 there is some cluster C such that C \u2287 V \u03c8 .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Running intersection property:", "text": "If a variable is present in two clusters C i and C j of T , it is also present in all clusters on the (unique) path between C i and C j in T .\nThe set of T 's clusters is denoted C. A cluster C i is nonmaximal if there is another cluster C j such that C i \u2286 C j ; typically we require T has no nonmaximal clusters. T also has a set of separators S, one per edge\n{C i , C j } such that S ij = C i \u2229 C j .\nThe parameterization of T is a set of potential functions \u03a6 = {\u03c6 C : C \u2208 C} \u222a {\u03c6 S : S \u2208 S}, one for each cluster and separator. The charge on T is defined to be\n\u03c6 T (V ) = C\u2208C \u03c6 C (C) S\u2208S \u03c6 S (S)(24)\n\u03a6 is initialized by setting all cluster and separator potentials to unity, multiplying each potential \u03c8 \u2208 \u03a8 into \u03c6 C for some C \u2287 V \u03c8 (which is possible by the potential property), and multiplying Z \u22121 into an arbitrary \u03c6 C ; then \u03c6 T = p G . Inference in the graphical model G can be carried out by a message passing algorithm over T . Passing a message from C i to C j consists of the following updates:\n\u03c6 * S ij = C i \u2212S ij \u03c6 C i (25) \u03c6 * C j = \u03c6 C j \u03c6 * S ij \u03c6 S ij (26)\nEven though passing a message C i \u2192 C j changes the parameterization \u03a6, the charge \u03c6 T remains invariant.\nWe distribute evidence from a cluster C by passing messages along edges in any preorder traversal from C. When messages are passed along every edge in both directions (in an appropriate schedule), the cluster and separator potentials are updated so that they are marginals of p G over their respective variables. A junction tree in this state is called consistent and it can be used to obtain marginals over any set of variables that cohabit, i.e., that reside together in some cluster. When T has no nonmaximal clusters, |C| \u2264 |V | so the number of messages required for inference is bounded by 2 \u2022 |V |. In the case of a Gaussian graphical model, the cluster and separator potentials are Gaussians. If they are represented in the canonical parameterization, the time complexity of passing a message is dominated by the cost of the marginalization in (25) which is implemented via (50); thus, it is at worst cubic in the size of the cluster. In sum, inference is linear in |V | and cubic in the width of T , traditionally defined as the size of the largest cluster minus one.\nWe will make use of two nonstandard operations on junction trees. To clone a cluster C i , we create a copy C j , attach C j to C i , and set \u03c6 S ij and \u03c6 C j equal to \u03c6 C i . When we merge a cluster C j into one of its neighbors C i , we: update C i to C i \u222a C j , update \u03c6 C i to \u03c6 C i \u03c6 C j /\u03c6 S ij , swing all edges incident to C j over to C i , and remove C j . It is easy to check that both of these operations preserve the structural constraints as well as the charge and consistency of a junction tree.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Adding potentials", "text": "Adding a node potential to the graphical model (as in the odometry update) requires no updates to the structure of the junction tree; we need only multiply the potential into one of the clusters containing the variable in order to update the charge, and then distribute evidence from that cluster to restore consistency.\nIn contrast, it is more complicated to update the junction tree to reflect the addition of an edge potential between variables u and v in the graphical model. If u and v do not appear in the same cluster, then the potential property will be violated. In order to restore it, we can add v to any cluster C containing u. However, this update may violate the running intersection property, as C may not be a neighbor of another cluster containing v. To restore this property, we can add an edge from C to any other cluster C containing v. However, this will violate the singly connected property.\nThere are several techniques for updating the structure of a junction tree to reflect an edge addition [Draper, 1995]. Here, we adopt the following simple method: after adding v to C, we find the cluster C that contains v and is closest to C (in path length), and add v to every cluster along the path between C and C . (The cluster and separator potentials can be updated by passing messages on the path from C i to C j ; any clusters that become nonmaximal can be merged into their subsuming neighbors.) The resulting junction tree does not violate the singly connected property or the running intersection property, and therefore is correct for the graph with the new edge. (This update can be shown to be equivalent to loop-cutset conditioning on v [Shachter et al., 1994]; it is also equivalent to repeated use of Lauritzen's PUSH operator [Lauritzen and Jensen, 2001].) To update the charge on the junction tree, we simply multiply the edge potential into the potential of C; then, to restore consistency, we distribute evidence from C. This is generalized to the case of potentials over arbitrarily many variables by Algorithm 1.\nAlgorithm 1 Multiply \u03c8 into cluster C of T Require: T is valid, consistent, and has no nonmaximal clusters Ensure: T is valid, consistent, has no nonmaximal clusters, and \u03c6 T \u2190 \u03c6 T \u00d7 \u03c8 1: for all variables u bound by \u03c8 do {ensure the potential property} 2:\nif u \u2208 C then 3:\nif u \u2208 T then {must ensure the running intersection property} 4:\nC \u2190 cluster closest to C containing u 5:\n(C = C 1 , C 2 , . . . , C k\u22121 , C k = C) \u2190 path from C to C 6:\nfor i = 2 to k do {restores the running intersection property} 7:\nC i \u2190 C i \u222a {u} 8: S i,i\u22121 \u2190 S i,i\u22121 \u222a {u} 9:\nPass a message from C i\u22121 to C i . {restore consistency} 10:\nif C i subsumes one of its neighbors C k then {Ensure no non-maximal clusters} 11:\nSwing all edges incident to C k over to C i .\n12:\nRemove C k from T . ", "publication_ref": ["b7", "b18", "b11"], "figure_ref": [], "table_ref": []}, {"heading": "Avoiding message passing", "text": "In three important cases that arise in SLAM, conditional independences render the evidence distribution step of Algorithm 1 superfluous; that is, it is not necessary to pass messages in order to restore consistency. This is a significant optimization, since the message passing is by far the most expensive operation.\nFor example, when adding x t+1 to the model and multiplying on the potential p(x t+1 | x t ), we need not pass messages from the (unique) cluster containing x t+1 to any other clusters. This is because x t+1 is an unobserved (directed) leaf of the graphical model-a barren node-and therefore does not impact the marginal distributions of the other nodes [Geiger et al., 1990].\nAnother case arises in a common type of odometry model p(y | x). Often we have the following type of situation: the state of the robot x consists of pose variables p (e.g., the coordinates of the robot and its heading) and some derivatives\u1e57 (e.g., the translational and rotational velocities); the dynamics model updates p by integrating in\u1e57 and then setting\u1e57 to\u0169, the result of corrupting a control u by noise; and, the odometry y is a noisy measurement of the noisy control\u0169. (For an example of this type of odometry model, see Section 6.1.) In this case, we can again appeal to conditional independencies (see Figure 6) to see that x t and all landmark state variables are independent of y t+1 . Thus, in this setting, we can also avoid message passing in the odometry update.\nThe final case arises when observing a landmark for the first time. Intuitively, observing a landmark l whose absolute position is unknown cannot give you any information about your location. However, we cannot appeal to a graphical criterion to avoid message passing. Rather, the independence of x (and all other variables) from l is an artifact of the completely uninformative prior on l before the measurement z is made. In this case, \"explaining away\" leads to l assuming all responsibility for z, and therefore x's distribution remains unchanged. This is verified algebraically in the proof of Proposition 2. Observing a landmark for the first time does not change the map distribution.\nTherefore, to perform such an update, we simply multiply on the observation potential p(z | x, l) onto the appropriate cluster; no message passing is required.\nIn fact, the only type of update in the SLAM application that requires message passing (provided our odometry update is as described above) is when the robot reobserves a landmark. Later we will leverage this fact-by delaying our use of this additional information-to obtain a filter operation that is commonly constant time.", "publication_ref": ["b8"], "figure_ref": ["fig_7"], "table_ref": []}, {"heading": "Marginalizing out nodes", "text": "As described in Section 2.3.3, marginalizing out a variable x creates a new potential over the Markov blanket of x, MB(x). Because the update potential factors into a product of unary and binary potentials, we could add each of the edges of this cluster independently using the technique described above. However, there is a much simpler and more efficient method.\nC 1 C 2 C 4 C 3 S 12 S 23 S 34 (a) C 1 \u222a C 2 \u222a C 3 \u222a C 4 (b)\nIn order to preserve the potential property, the structure of the junction tree must be updated so that it has a cluster containing MB(x). The Markov blanket of x may not be efficiently computable from the junction tree, but we are guaranteed that it is a subset of the union of all clusters containing x (since the junction tree has the potential property). Because the junction tree also has the running intersection property, all clusters containing x must constitute a subtree of the junction tree, which we denote T x . We can therefore merge all of these clusters to obtain a new cluster that contains x and MB(x); this new cluster will inherit all of the edges incident to all of the merged clusters. It is straightforward to verify that the resulting junction tree is valid for the original graphical model. An example of this transformation is given in Figure 7.\nThe charge on the junction tree can be preserved during this cluster merging by setting the potential on the new cluster to the product of the potentials of the merged clusters divided by the product of the potentials of the eliminated separators. Then, to marginalize x out of the junction tree, we simply marginalize x out of this new cluster, which is the only cluster that contains it. It is straightforward to verify that if the junction tree was previously consistent, then this operation preserves its consistency without message passing.", "publication_ref": [], "figure_ref": ["fig_8"], "table_ref": []}, {"heading": "Thinning the junction tree", "text": "As discussed in Section 2.2, the size of the largest cluster of the junction tree will grow linearly in the number of landmarks. Thus, if we are to avoid cubic-time inference, we must resort to an approximation. In this section, we consider a method of thinning the junction tree so that the complexity of message passing remains manageable. The approach here is related to that of Kjaerulff (1993); that work describes how removing an edge from a graphical model can sometimes result in a thinner junction tree. The approach presented here is simpler and more direct, as it operates on the junction tree without making reference to the underlying graphical model.", "publication_ref": ["b11"], "figure_ref": [], "table_ref": []}, {"heading": "Variable contraction", "text": "The complexity of message passing is determined by the sizes of the clusters in the junction tree, and therefore our goal will be to define a thinning operation that reduces the size of clusters in the junction tree. We now describe such an operation, which we call variable contraction: Definition 1. Let x be a variable that appears in more than one cluster of the junction tree T , let C be a leaf of T x (the subtree of T induced by x), and let S be the separator joining C to T x . A variable contraction of x from C removes x from C and S and marginalizes x out of \u03c6 C and \u03c6 S ; if C becomes non-maximal, it is merged into its subsuming neighbor.\nAs an illustration, consider the junction tree of Figure 7(a). Notice that the set of clusters containing v constitutes a subtree (because of the running intersection property). We can contract v from C 1 (and S 12 ) or C 4 (and S 34 ), because these are the leaves of the subtree. If we wish to contract v from C 3 , an interior node, we can first contract it from C 4 (making C 3 a leaf of the subtree) and then contract it from C 3 .\nVariable contraction has some attractive properties:\nProposition 3. Variable contractions preserve the singly connectedness property, the running intersection property, and consistency.\nThus, the new junction tree is a valid junction tree for some graph, although perhaps not G: the potential property may be violated. Variable contraction is local and efficient: it requires marginalizing a variable out of one cluster potential and one separator potential, which in the Gaussian case can be accomplished in O(|C| 2 ) time using (50). Also, variable contraction is a general method of \"thinning\" a junction tree. Consider the problem of contracting an arbitrary variable v from some cluster C i . If v satisfies the preconditions of Definition 1, then we can simply contract it. If not, there are two cases to consider. The first is that v appears only in C i . In this case, we can 1. clone C i to obtain C j , 2. contract v from C i to C j , and then 3. contract some other variable u from C j to C i . This operation is illustrated in Figure 8. The second case is when v appears elsewhere but v is not a leaf of T v . In this case, we can contract v from other clusters until C i is a leaf of T v and then contract v from C i .\nFinally, variable contraction is a maximum likelihood approximation:\nProposition 4. LetT be the junction tree obtained from the variable contraction of Definition 1. Then\n\u03c6T = argmax {q : v \u22a5 \u22a5 C\u2212S | S\\v} \u03c6 T log q (27)\nIn other words, the probability distribution represented byT has maximum likelihood (under the original junction tree's distribution) over all distributions in which v is conditionally independent of C \u2212 S given S \\ v. It is as if we treated the distribution of T as a data set and then chose the maximum likelihood parameterization of a graphical model that is missing certain edges. Analyzing the conditional indepence properties of T andT reveals that it is the edges between v and each u \u2208 C \u2212S that have been removed. Thus, we can consider each variable contraction to be a maximum likelihood projection that removes the edges between v and C \u2212S. While computing the maximum likelihood projection to a graphical model with an arbitrary set of edges may be computationally intensive (requiring Iterative Proportional Fitting), deleting particular sets of edges via variable contractions is efficient. This is because projection to decomposable models is an efficient operation, and junction trees represent decomposable models [Whittaker, 1989]. Thus, in settings such as SLAM where a graphical model becomes denser over time, periodically thinning the junction tree via variable contraction is an attractive means of ensuring the model remains tractable.", "publication_ref": ["b26"], "figure_ref": ["fig_8", "fig_9"], "table_ref": []}, {"heading": "Thinning clusters with contractions", "text": "Consider the problem of reducing of a given junction tree cluster C by one. (A solution to this problem can be applied recursively to thin the junction tree by an arbitrary amount.) Let C shared be the subset of variables in C that appear elsewhere in the junction tree. The question we must now ask is: which of the variables in C shared should be contracted from C? (If we wish to contract any of the variables in C, then we can first clone C so that C shared = C.) Clearly, we would like to contract that variable that minimizes the approximation error, which we take to be D(\u03c6 T || \u03c6 T ), the (differential) relative entropy (or Kullback-Liebler divergence) from the original distribution to the approximate one.\nThe following result, similar to Theorem 11 of [Kjaerulff, 1993], proves that the error introduced by contracting x from a cluster C can be computed using only the marginal over C:", "publication_ref": ["b11"], "figure_ref": [], "table_ref": []}, {"heading": "Proposition 5. Let T be the junction tree obtained from the variable contraction of Definition 1. Then", "text": "D(\u03c6 T || \u03c6 T ) = I(x; C \u2212 S | S \\ x).\nThus, of all the variables x \u2208 C shared such that C is a leaf of T x , we should contract the one that minimizes I(x; C \u2212 S | S \\ x). While it is possible to eventually contract on all variables in C shared , those variables for which C is not a leaf of T x will first have to be contracted from other clusters. The error introduced by a sequence of contractions is additive (cf. Theorem 12 of [Kjaerulff, 1993]); thus, the error introduced by (eventually) contracting x from C can be computed by adding the errors of each of the successive contractions of x.\nThe conditional mutual information I(x; C \u2212 S | S \\ x) can be computed using p(C). In a consistent junction tree, this marginal is simply \u03c6 C , and therefore the approximation error of a variable contraction can be computed locally.\nIf these mutual information terms were expensive to compute (as they typically are), then this result would be of little value, since computing the best variable to contract would be costly. As it turns out, in the case where p(C) is a Gaussian distribution, the approximation error I(x; C \u2212 S | S \\ x) can be computed in a constant amount of time independent of the sizes of C and S. Proposition 6. Let C be a set of Gaussian random variables, let S \u2286 C, and let x \u2208 S. Then\nI(x; C \u2212 S | S \\ x) = 1 2 log det \u039b C xx \u2212 log det \u039b S xx (28\n)\nwhere\n\u039b C = Cov (C) \u22121 and \u039b S = Cov (S) \u22121 .\nWhen our junction tree is consistent, \u039b C and \u039b S are simply the parameters of \u03c6 C and \u03c6 S ; thus, we can extract the sub-blocks corresponding to x from each and compute the difference of their log determinants.", "publication_ref": ["b11"], "figure_ref": [], "table_ref": []}, {"heading": "Thin junction tree filters for SLAM", "text": "We have now assembled most of the machinery we require to design a thin junction tree filter (TJTF) for the SLAM problem. All that remains is the logic that decides which clusters new potentals are multiplied into and also how variable contractions are employed to thin the junction tree. 9 We first present a simple linear-time filter, and then describe a further approximation that results in a constant-time filtering operation.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Linear-time approximate filtering", "text": "Recall from Section 3.1 that if the width of our junction tree is k, then it will require O(|V |k 2 ) space and message passing will take O(|V |k 3 ) time. In SLAM |V | = n t + 1, so we can obtain a O(n t ) space filter with a O(n t ) time filter operation by periodically thinning the junction tree so that its width remains bounded by a constant k.\nWe initialize the filter with a junction tree that has a single cluster containing x. We begin with motion update, which consists of the predition and odometry updates and then roll-up. Recall that when x t is marginalized out in roll-up, we must merge all of the clusters in which it resides. In the worst case, x t could reside in all of the junction tree's clusters, in which case our belief state would collapse to one large cluster. To prevent this from happening, we start the motion update by first contracting x t until it resides in only one cluster; then, we perform the prediction and odometry updates and then marginalization. This update is summarized by Algorithm 2.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Algorithm 2", "text": "Prediction update and roll-up in the thin junction tree.\n1: while x t resides in more than one cluster do 2:\nContract x t from a leaf of T x so as to minimize (28) 3: C \u2190 the only cluster containing x t 4: Multiply the evolution potential \u03c8(x t , x t+1 ) into \u03c6 C . 5: Marginalize x t out of \u03c6 C . 6: Multiply the odometry potential \u03c8(x t+1 ) into \u03c6 C . 7: Distribute evidence from C. {if necessary} When updating with a measurement of landmark l, the simple case is when x and l cohabit in some cluster C. In that case, we simply multiply the observation potential \u03c8(x, l) into \u03c6 C and distribute evidence from C. There are two nontrivial cases:\n1. If l has not yet been observed, then we multiply \u03c8(x, l) into the smallest cluster C that contains x. If adding l to this cluster would cause it to violate the width limit, then we A cluster overlap parameter h governs by how much C is thinned, and therefore how many variables reside in its separator. If it is thinned a lot, then it will admit more new landmarks before another cloning is required; the trade-off is that its separator will be small, and therefore the volume of information it can transmit is reduced.\nThe motivation for contracting x to C is two-fold. First, if C is a perfect clone of C, then all contractions from C have zero error; thus, in order to choose make good decisions when thinning C , it must have more variables than C. Second, since x is contracted to a single cluster during roll-up, it might as well be contracted to the cluster containing the most recently measured landmarks.\n2. If l has been previously observed, then we multiply \u03c8(x, l) into the cluster C that contains l and is closest to another cluster containing x. This may involve adding x to C and other clusters in order to restore the running intersection property.\nThis logic is summarized by Algorithm 3. Clone C to obtain C .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "5:", "text": "Attach C to C Perform the variable contraction from C that minimizes (28). Distribute evidence from C. {restores consistency} Figures 9, 10, and 11 demonstrate the thin junction tree filter for the example of Figure 1 in which we choose k (the width limit) to be three and h (the overlap) to be two.\nNote that when reobservations are incorporated in Algorithm 3, it would also be valid to instead simply add l to the closest cluster containing x (and all clusters necessary to restore the running intersection property). However, this scheme has two disadvantages:\n{x 1 } (a) {x 1 , l 1 } \u03c8(x 1 , l 1 ) (b) {x 1 , l 1 , l 2 } \u03c8(x 1 , l 2 ) (c) {l 1 , l 2 } {x 1 , l 1 , l 2 } (d) {l 1 , l 2 } {x 1 , l 2 } (e) {l 1 , l 2 } {x 1 , l 2 , l 3 } \u03c8(x 1 , l 3 ) (f) {l 1 , l 2 } {x 1 , x 2 , l 2 , l 3 } \u03c8(x 1 , x 2 ) (g) {l 1 , l 2 } {x 2 , l 2 , l 3 } \u03c8(x 2 ) (h)\nFigure 9: The updates at time t = 1, when landmarks one, two, and three are observed. (a) The initial junction tree. (b) l 1 is observed and the measurement potential \u03c8(x 1 , l 1 ) is multiplied into the only cluster. (c) l 2 is observed and \u03c8(x 1 , l 2 ) is multiplied into the only cluster. (d) l 3 is observed, but \u03c8(x 1 , l 3 ) cannot be multiplied into the only cluster because its size is k = 3; the cluster is cloned and x 1 is contracted to the clone. (e) The clone is thinned so that it contains h = 2 variables. Assume I(l 1 ; x 1 | l 2 ) < I(l 2 ; x 1 | l 1 ), so contracting l 1 yields the smallest approximation error. (f) \u03c8(x 1 , l 3 ) is multiplied into the top cluster's potential. (g) For the motion update, \u03c8(x 1 , x 2 ) is multiplied into the top cluster's potential. (h) x 1 is marginalized out of the top cluster and the odometry potential \u03c8(x 2 ) is multiplied in.\n{l 1 , l 2 } {x 2 , l 2 , l 3 } \u03c8(x 2 , l 2 ) (a) {l 1 , l 2 } {l 2 , l 3 } {x 2 , l 2 , l 3 } (b) {l 1 , l 2 } {l 2 , l 3 } {x 2 , l 2 } (c) {l 1 , l 2 } {l 2 , l 3 } {x 2 , l 2 , l 4 } \u03c8(x 2 , l 4 ) (d) {l 1 , l 2 } {l 2 , l 3 } {x 2 , x 3 , l 2 , l 4 } \u03c8(x 2 , x 3 ) (e) {l 1 , l 2 } {l 2 , l 3 } {x 3 , l 2 , l 4 } \u03c8(x 3 ) (f)\nFigure 10: The updates at time t = 2, when landmarks two and four are observed. (a) The measurement potential \u03c8(x 2 , l 2 ) is multiplied into the top cluster. (b) l 4 is observed, but \u03c8(x 2 , l 4 ) cannot be multiplied into the top cluster because its size is k = 3; the top cluster is cloned, and x 2 is contracted to the clone. (c) The clone is thinned so that it contains h = 2 variables. Assume I(l 3 ; x 2 | l 2 ) < I(l 2 ; x 2 | l 3 ), so contracting l 3 yields the smallest approximation error. (d) \u03c8(x 2 , l 4 ) is multiplied into the top cluster's potential. (e) \u03c8(x 2 , x 3 ) is multiplied into the top cluster's potential. (f) x 2 is marginalized out, and \u03c8(x 3 ) is multiplied in.\n{l 1 , l 2 } {x 3 , l 2 , l 3 } {x 3 , l 2 , l 4 } \u03c8(x 3 , l 3 ) (a) {l 1 , l 2 } {x 3 , l 2 , l 3 } {x 3 , l 2 , l 4 } \u03c8(x 3 , l 4 ) (b) {l 1 , l 2 } {l 2 , l 3 } {l 2 , l 4 } {x 3 , l 3 } (c) {l 1 , l 2 } {l 2 , l 3 } {l 2 , l 4 } {x 3 , l 3 , l 5 } \u03c8(x 3 , l 5 ) (d)\nFigure 11: The updates at time t = 3, when landmarks three, four, and five are observed. (a) \u03c8(x 3 , l 3 ) is multiplied into the middle cluster. (b) \u03c8(x 3 , l 4 ) is multiplied into the top cluster. (c) l 5 is observed, but the smallest cluster containing x has reached the size limit k; the middle cluster is cloned, x is contracted to the clone, and then the clone is thinned so that it contains h = 2 variables. Assume I(l 2 ; x 3 | l 3 ) < I(l 3 ; x 3 | l 2 ), so contracting l 2 yields the smallest approximation error. (d) \u03c8(x 3 , l 5 ) is multiplied into the clone.\n1. In Algorithm 3, restoring the running intersection property can add x to many clusters of the junction tree, but the subsequent execution of Algorithm 2 contracts it back to the active cluster; thus, the net change in the sizes of these clusters is zero. If during the measurement update we instead were to add l to the active cluster (and intermediate clusters), additional thinning operations would be required to ensure the intervening clusters satisfy the width limit.\n2. Empirically, we find that variables that have not been observed for some time typically reside in clusters that are far from the active cluster. (This is intuitive, since the mutual information between x and a landmark variable decreases over time if the landmark is not reobserved.) Thus, closing the loop in the variant scheme would cause a mass migration of variables through the junction tree, requiring expensive thinning operations.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Constant-time approximate filtering", "text": "Because landmark observations cause the robot's state variable to move to clusters containing recentlyobserved landmarks, we expect that landmarks whose state variables are far from the robot's state variable (in the junction tree) are those that were last observed in the distant past. Thus, in the common case where the robot observes new landmarks and reobserves some recently-viewed landmarks, only a small portion of the junction tree's structure changes. Moreover, the linear-time filter presented above would take constant time, were it not for the fact that reobserving landmarks necessitates a round of message passing. We can get a constant-time filter operation by employing a lazy message passing scheme, where we distribute evidence only to constantly many nearby clusters; the approximation is that the marginals of the remaining clusters will not be conditioned on the observation. This technique can be useful in domains where the robot has a limited number of floating-point operations it can perform in each time step.\nThis additional approximation has the disirable property that it is temporary: because we are still updating the charge correctly, at any later time we can use a complete round of message passing (taking linear Figure 12: Four examples of differential relative entropy for two-dimensional Gaussians (such as planar location estimates). p is represented by the blue (solid) 95% confidence region, and q is represented by the red (dashed) 95% confidence region. As q becomes a poorer model for p, the relative entropy increases.\ntime) to update our map entirely; the filtered estimate becomes the same estimate that would have obtained from passing all messages at every time step. Our sacrifice has simply been a period during which the majority of the map was slightly out of date. Alternatively, we can smoothly interpolate between the original linear-time filter and this constant-time filter by employing an adaptive message passing scheme, in which messages are propagated only as long as they induce significant changes in the belief state. If we define \"significant\" sensibly, this scheme will take constant time when mapping new territory and when closing loops, it will take time linear in the length of the loop.\nTo determine if a message C i \u2192 C j has induced a significant change, we compute the (differential) relative entropy (or Kullback-Liebler divergence) from the separator marginal before the message is passed to the separator marginal after the message is passed:\nD(\u03c6 * S i,j || \u03c6 S i,j ) = \u03c6 * S i,j log \u03c6 * S i,j \u03c6 S i,j (29) = 1 2 log det \u03a3 det \u03a3 * \u2212 n + trace(\u03a3 \u22121 (\u03a3 * + (\u00b5 * \u2212 \u00b5)(\u00b5 * \u2212 \u00b5) T )(30)\nwhere \u03c6 S i,j = N (\u00b5, \u03a3), \u03c6 * S i,j = N (\u00b5 * , \u03a3 * ), and n is the sum dimension of the variables in S i,j . Our choice of the relative entropy can be justified in several ways. First, it is a well-known \"dissimilarity\" measure for probability distributions (i.e., it is non-negative and zero iff the two distributions are equal), and is able to quantify both changes in value and certainty; see Figure 12 for some examples.\nSecond, we can draw a valuable analogy between using relative entropy to determine when to pass messages in a junction tree and its use in Information Theory [Cover and Thomas, 1991]. In a communication context, the relative entropy from a distribution p to another distribution q can be thought of as the expected extra number of bits (actually, nats-natural logarithmic units-in the Gaussian case) necessary to communicate the value of a sample from the true distribution p given we have an optimal coding scheme based upon our approximation q. In our context, D(\u03c6 * S i,j || \u03c6 S i,j ) represents a measure of the overhead involved in communicating our updated knowledge \u03c6 * S i,j using our outdated representation \u03c6 S i,j ; if the overhead is not too great, we will not bother to revise our beliefs.\nFinally, it can be easily shown that the \"significance\" of evidence propagated from some cluster C to some other cluster C (measured using relative entropy) decreases with the distance between C and C in the junction tree [Kjaerulff, 1993, Theorem 13]. Thus, we can be certain that if a message was not significant for a particular cluster, then that cluster need not continue the evidence propagation.", "publication_ref": ["b4"], "figure_ref": ["fig_1", "fig_1"], "table_ref": []}, {"heading": "Experiments", "text": "We now present the results of experiments using simulated SLAM problems. In particular, we compare the computational cost and estimation accuracy of the Kalman filter, TJTF, and FastSLAM. It is appropriate to preface these results with a brief discussion of what conclusions one could reasonably draw from them.\nIn any realistic SLAM problem, all three of these algorithms are approximations (since the Kalman filter incurs linearization error). When one compares a set of approximation algorithms on particular applications, there is a danger that the particular problems considered may favor one approximation algorithm over another. This problem is especially troublesome when the problem class is diverse, as in SLAM: different state spaces, motion and sensor models, and control policies can dramatically affect how well a particular approximate algorithm will perform. For example:\n1. If the motion or observation models are highly nonlinear, then techniques that must linearize them (the Kalman filter and TJTF must linearize both, and FastSLAM must linearize the measurement model) will perform poorly.\n2. If the controller generates large loops, the world contains regions without enough landmarks, or there is a large amount of noise, FastSLAM will be more susceptible to divergence, for the reasons described in Section 1.2.1.\nThus, the strength of the conclusions that the reader can draw from the experiments presented below will depend greatly on the similarity of their application to the ones used below.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "The SLAM simulations", "text": "We have chosen to use simulated SLAM problems rather than real ones in our experiments for two reasons: first, it is very time consuming to obtain ground-truth in real SLAM problems; and second, using simulations allows us to examine how these algorithms perform under varying conditions. The SLAM simulations we use are inspired by the familiar task of a mobile robot mapping a planar environment with feature-type landmarks.\nIn the family of SLAM problems we consider, the robot operates in a planar world of stationary point landmarks. The robot's state is described by a vector\nx = \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 x x x y x h x t x r \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb (31)\ncontaining the (x, y) coordinates of the robot, its heading h (relative to the positive x-axis), its translational velocity t along that heading, and its rotational velocity r about the z-axis. The state of each landmark is represented by a vector\nl = l x l y (32\n)\ngiving the (x, y) coordinates of the landmark's position.\nWe use a landmark observation model in which the robot makes noisy range and bearing measurements of every landmark that lies within a forward-looking \"visual cone\" of a prescribed angular width c w and length c l . Assume a landmark l falls within the visual cone and define\n\u03b4 = x x x y \u2212 l x l y (33)\nto be the vector from the position of the robot to that of the landmark. Then the robot receives a rangebearing measurement\nz = z r z b = ||\u03b4|| 2 (1 + u r ) + u a arctan(\u03b4) \u2212 x h + u b (34)\nwhere u a , u r and u b are independent zero-mean Gaussian noise variables; thus, there is additive (or absolute) and multiplicative (or relative) Gaussian noise in the range measurements and absolute Gaussian noise in the bearing measurements. This has the effect of making the location of far-off landmarks harder to estimate than those close to the robot, while retaining some noise in observations of close landmarks. To avoid problems associated with linearizing functions with periodic outputs, the landmark measurement z is represented in Cartesian coordinates rather than the polar coordinates of (34).\nAt each time step the robot exerts a control\nu = u t u r(35)\nconsisting of a desired translational and rotational velocity. The robot translates along its current heading at its current translational velocity, rotates at its current rotational velocity, and then updates its velocities according to the control signal. The dynamics model is\nx t+1 = \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 x x t+1 x y t+1 x h t+1 x t t+1 x r t+1 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb = \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 x x t + x t t cos x h t x y t + x t t sin x h t x h t + x r t u t (1 + v t ) + v a u r (1 + v r ) + v b \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb(36)\nwhere v t , v a , v r and v b are independent zero-mean Gaussian noise variables; thus, there is both absolute and relative noise in the controls. After moving, the robot receives an odometry measurement of its translational and rotational velocity\ny = y t y r = x t + w t x r + w r (37\n)\nwhere w r and w t are independent zero-mean Gaussian noise variables representing absolute noise in the differential odometry. (Note that this odometry model is of the type described in Section 3.3, and so odometry updates in TJTF will not require message passing.)\nThe motion and landmark observation models are nonlinear; we use the UKF for linearization in all cases. In the case of FastSLAM, this linearization was performed on a per-particle basis as required by the algorithm.\nWe use two types of SLAM problems (see Figure 13): a square loop (such as a robot would encounter when mapping the interior of a building) and a switchback pattern (which could be used to map an open area). In both cases, the robot maps a square region whose side length is L. In the case of switchbacks, the distance between the \"passes\" is fixed at half of the width of the visual cone; this ensures that in each pass the robot will reobserve approximately half of the landmarks it observed on the previous pass.  Choosing the controls to obtain these paths presents an interesting dilemma. We would like to fix the simulation in advance-which requires fixing the controls in advance-so that all algorithms receive the same input and our comparisons are fair. However, if we fix the control signal without taking motion noise into account, the actual robot path will differ markedly from the desired (square or switchbacks) trajectory (resulting, for example, in the robot not physically closing the loop of a square trajectory). Our solution is to fix the path of the robot and the motion noise in advance, and then invert the motion model to obtain an omniscient controller-i.e., one that chooses control sequence knowing the (in reality, unobservable) noise pattern in advance. (This explains the erratic path of the integrated control signal in Figure 13-to counteract the motion noise, the control signal must be noisy.) Using this technique, we compute the control law by having the robot follow the desired trajectory as quickly as possible, subject to the constraint that its translational and rotational velocity controls do not exceed t max and r max , respectively.\nFinally, in each simulation the environment was populated with landmarks by sampling N landmark locations uniformly from the smallest rectangular region that could possible be observed by the robot, given its path and its visual field. Table 1 contains a summary of the parameters necessary to define a simulation and their default values. Figure 13 contains an example of each type of trajectory.", "publication_ref": [], "figure_ref": ["fig_2", "fig_2", "fig_2"], "table_ref": ["tab_0"]}, {"heading": "Metrics", "text": "In order to quantify the computational cost of each filter operation, we compute the number of floatingpoint operations used by each filter operation. The dominant cost in all three of these algorithms is floating point operations, and so this is a very accurate (and portable) method of quantifying not only the computational complexity of the algorithms (which we have already analyzed theoretically), but also their respective \"constant factors\".\nWe divide the estimation error into localization error and mapping error. We could measure these errors using Euclidean distances between ground truth and the algorithm's mean estimate, but this would exhibit a bias towards the coordinate system used in the problem description. Even though we initialize every filter with the correct initial state of the robot, it is possible for the filter to settle into a coordinate system different  than that used by the problem description. This can happen, for example, when the filter makes an early mistake about the true heading or position of the robot and obtains a rotated or translated map; it can also occur when closing the loop causes all landmarks to shift. See Figure 14 for an example.\nBecause the value of a map is independent of its coordinate system, we calculate the localization and mapping errors as follows. We first compute the (unscaled) rigid transformation that minimizes the sum of squared Euclidean distances between landmark positions and their filter estimates (as described in [Umeyama, 1991]). Then, the localization error is computed as the Euclidean distance between robot's position and the transformed filter's estimate; the mapping error is computed as the average Euclidean distance between the landmarks' true positions and the transformed filter's estimates.", "publication_ref": ["b24"], "figure_ref": ["fig_4"], "table_ref": []}, {"heading": "Comparisons to the Kalman filter and FastSLAM", "text": "Figure 15 shows how TJTF, the Kalman filter, and FastSLAM behave when run on the simulations shown in Figure 13. TJTF was run with k = 16, h = 4, and adaptive message passing with the significance threshold set at 0.1 natural logarithmic units; FastSLAM was run with 100 particles, as recommended in [Montemerlo et al., 2002]. In these plots, the floating point counts are time-averaged for clarity.\nWe found that the estimation error of TJTF with maximum cluster sizes as small as 16 can be comparable with the Kalman filter, and that it gets smaller as k increases. This indicates that the edges removed by TJTF indeed carry little information; it also suggests that the estimation error of TJTF will be at least competitive with that of SEIF (an approximate form of the Kalman filter) and less than that of the submap approaches (which neglect long-distance correlations).\nWe also found that TJTF is good at closing loops; in Figure 15(a) we can see the localization and mapping error of TJTF suddenly drop at t = 780, when the robot first reobserves its starting point; also evident is a sudden increase in the computational cost: the filter is choosing to update the entire map in linear time rather than using cheaper constant-time updates. We found that FastSLAM had difficulty closing large loops (notice its divergence in Figure 15(a)) and that its estimation error in general was larger than that of TJTF. Using accurate counts of floating point operations, we found that TJTF can be as fast as FastSLAM, and that it becomes more efficient than the Kalman filter when the map contains a few hundred or more landmarks. Of course, the constant factor associated with TJTF varies significantly with the width limit k, the overlap h, and the significance s used in adaptive message passing, allowing the practitioner to trade-off computational cost for estimation accuracy.", "publication_ref": ["b17"], "figure_ref": ["fig_6", "fig_2", "fig_6", "fig_6"], "table_ref": []}, {"heading": "Discussion", "text": "TJTF is a novel approach to maintaining tractable approximations to a belief state that can be represented by graphical models with changing dependencies. As such, it represents a principled, flexible, and efficient solution to the SLAM complexity problem. Having now worked through the details of the filter, we can now offer a detailed comparison of it with the other methods described in Section 1.2.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Comparison to previous approaches", "text": "In the SLAM domain, TJTF can be made to (frequently) operate in constant-time, making its time complexity competitive with that of the FastSLAM algorithm. TJTF also represent a single estimate of the map, in contrast to FastSLAM; while this improves the complexity of data association and extracting map marginals, it significantly curbs the representation's expressiveness. Finally, while FastSLAM relies on the diversity of the particle population to represent correlations between landmark estimates (and is therefore sensitive to noise, due to the curse of dimensionality), TJTF chooses the optimal correlations to represent directly, subject to a computational complexity constraint; thus, we expect it to be less susceptible to divergence. Interestingly, the approach presented here has significant connections to both the submap approach and SEIF. First, the belief state of a TJTF has a natural interpretation as a coupled set of local maps, just as in the submap approaches. In particular, each cluster of the junction tree can be viewed as a submap, and the consistency of the junction tree can be viewed as a constraint that overlapping submaps must agree on their shared content. The TJTF formulation gives concrete semantics to the relationships between the maps, including how they must be updated, how consistency is maintained, and how the set of local maps can be determined online to minimize the approximation error subject to a complexity constraint.\nSecond, since thinning the junction tree is equivalent to removing sets of edges from the graphical model, which in turn is equivalent to zeroing out entries of \u039b, TJTF can be viewed as a technique for making \u039b sparse; thus, its goal is identical to that of SEIF. As stated above, the maximum likelihood approach to deleting single edges requires Iterative Proportional Fitting, and is computationally complex; SEIF employs an approximation that is constant time, but leads to representational problems. In contrast, the approach presented here is a maximum likelihood sparse approximation to \u039b that can be computed analytically and efficiently; it permits constant-time access to marginal distributions, and it allows both constant-time and linear-time updates. As we have seen, these improvements arise because we restrict ourselves to a distinguished set of sparsity patterns-those that correspond to the set of decomposable models.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A more general understanding", "text": "TJTF falls into a broad class of approximate inference techniques for dynamic probabilistic inference called Assumed Density Filtering (ADF). An ADF algorithm performs standard filtering operations until the complexity of the belief state starts to become unmanageable; then it is projected to a more tractable family of distributions. (The standard application of ADF is to Switching Kalman Filters, where the belief state consists of a mixture of n Gaussians where n grows exponentially over time; ADF is used to periodically project the mixture to one with a constant number of mixing components.) TJTF follows the ADF model where the tractable family of distributions is the family of decomposable models characterized by thin junction trees; there is one caviat, however: the independence structure of the TJTF projection is not determined in advance, as in ADF; rather, the projection is determined online in order to minimize the approximation error. Thus, we can view TJTF as a type of adaptive ADF.\nOne of the more exciting developments in dynamic probabilistic inference is the analysis of ADF-type algorithms given in [Boyen and Koller, 1998], which proves that when the independence structure of the projection remains a fixed product of independent terms, the approximation error cannot increase without bound. This analysis was extended in [Boyen and Koller, 1999] to the case where the belief state is represented by an adaptively chosen junction tree, just as in TJTF. (In fact, TJTF can be viewed as perhaps the simplest method of implementing the architecture they describe.) They give theoretical results that bound the influence different clusters in the junction tree can have on one another (similar in flavor to the results in [Kjaerulff, 1993]). These theoretical results give powerful intuitions into the design of good approximate filters.", "publication_ref": ["b2", "b3", "b11"], "figure_ref": [], "table_ref": []}, {"heading": "A The multivariate gaussian", "text": "This section presents the basic facts about Gaussian random variables that are used in this technical report.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A.1 Parameterizations", "text": "The multivariate Gaussian probability density function can be expressed in two forms. The first is called the moment parameterization:\np(x) = 1 (2\u03c0) n det \u03a3 exp \u2212 1 2 (x \u2212 \u00b5) T \u03a3 \u22121 (x \u2212 \u00b5) (38\n)\nwhere \u00b5 (a vector) and \u03a3 (a positive semidefinite matrix 10 ) are the parameters (and n is the dimension of the vector-valued random variable x). It is called the moment parameterization because E (x) = \u00b5 and Cov (x) = \u03a3. The quadratic form in the exponent, (x \u2212 \u00b5) T \u03a3 \u22121 (x \u2212 \u00b5), is called the Mahalanobis distance between x and \u00b5 under \u03a3. It is a generalization of Euclidean distance that allows the coordinate system to be scaled and sheared; the squared Euclidean distance is obtained by taking \u03a3 = I. If x is a random variable distributed according to a multivariate Gaussian distribution with moment parameters \u00b5 and \u03a3, then we write x \u223c N (\u00b5, \u03a3).\nThe second form is called the canonical parameterization, and is obtained from the moment parameterization by rearranging terms:\np(x) = exp \u2212 1 2 log((2\u03c0) n det \u03a3) \u2212 1 2 (x \u2212 \u00b5) T \u03a3 \u22121 (x \u2212 \u00b5) (39) = exp \u2212 n 2 log(2\u03c0) + 1 2 log det \u03a3 \u22121 \u2212 1 2 (x T \u03a3 \u22121 x + \u00b5 T \u03a3 \u22121 \u00b5 \u2212 2x T \u03a3 \u22121 \u00b5) (40) = exp \u2212 1 2 (n log(2\u03c0) \u2212 log det \u03a3 \u22121 + \u00b5 T \u03a3 \u22121 \u00b5) + x T \u03a3 \u22121 \u00b5 \u2212 1 2 x T \u03a3 \u22121 x (41)(42)\nDefining \u039b = \u03a3 \u22121 and \u03b7 = \u03a3 \u22121 \u00b5, we can write this as\np(x) = exp a + \u03b7 T x \u2212 1 2 x T \u039bx(43)\nwhere\na = \u2212 1 2 (n log(2\u03c0) \u2212 log det \u039b + \u03b7 T \u039b \u22121 \u03b7)(44)\nis the (log) normalization constant. The parameters \u03b7 and \u039b are called the information vector and the information (or precision) matrix, respectively. If x is a random variable distributed according to a multivariate Gaussian distribution with canonical parameters \u03b7 and \u039b, then we write x \u223c N \u22121 (\u03b7, \u039b).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A.2 Marginalization and conditioning", "text": "In this section, we present the formulae for marginal and conditional Gaussian distributions for both the moment and canonical parameterizations; proofs of these formulae can be found in [Jordan, 2003]. Let x be a multivariate Gaussian random variable. Partition x as follows:\nx = x 1 x 2 (45)\nThen x 1 and x 2 are also multivariate Gaussian random variables. If x \u223c N (\u00b5, \u03a3) where\n\u00b5 = \u00b5 1 \u00b5 2 \u03a3 = \u03a3 11 \u03a3 12 \u03a3 21 \u03a3 22 (46) then x 1 \u223c N (\u00b5 m 1 , \u03a3 m 1 )\nwhere\n\u00b5 m 1 = \u00b5 1 (47) \u03a3 m 1 = \u03a3 11 (48)\nThus, marginalization in the moment parameterization is performed by simply selecting the relevant blocks of the parameters. If instead x \u223c N \u22121 (\u03b7, \u039b) where\n\u03b7 = \u03b7 1 \u03b7 2 \u039b = \u039b 11 \u039b 12 \u039b 21 \u039b 22 (49) then x 1 \u223c N \u22121 (\u03b7 m 1 , \u039b m 1 )\nwhere\n\u03b7 m 1 = \u03b7 1 \u2212 \u039b 12 \u039b \u22121 22 \u03b7 1 \u039b m 1 = \u039b 11 \u2212 \u039b 12 \u039b \u22121 22 \u039b 21 (50)\nThus, when the dimension of x 2 is O(n), computing the marginal of x 1 using this technique can require O(n 3 ) time.\nThe situation is reversed when we condition on x 2 rather than marginalize it out: the computation is trivial in the canonical parameterization, and expensive in the moment parameterization.\nIf x \u223c N \u22121 (\u03b7, \u039b) then p(x 1 | x 2 ) = N \u22121 (\u03b7 c 1|2 , \u039b c 1|2 )\nwhere\n\u03b7 c 1|2 = \u03b7 1 \u2212 \u039b 12 x 2 \u039b c 1|2 = \u039b 11 (51) If instead x \u223c N (\u00b5, \u03a3) then p(x 1 | x 2 ) = N (\u00b5 c 1|2 , \u03a3 c 1|2 )\nwhere\n\u00b5 c 1|2 = \u00b5 1 + \u03a3 12 \u03a3 \u22121 22 (x 2 \u2212 \u00b5 2 ) \u03a3 c 1|2 = \u03a3 11 \u2212 \u03a3 12 \u03a3 \u22121 22 \u03a3 21(52)", "publication_ref": ["b10"], "figure_ref": [], "table_ref": []}, {"heading": "A.3 Affine Gaussian functions", "text": "If x \u223c N (\u00b5 x , \u03a3 x ) and w \u223c N (0, R) are independent and we define\ny = Ax + b + w (53)\nthen y \u223c N (\u00b5 y , \u03a3 y,y ) where\n\u00b5 y = E (b + Ax + w) = b + AE (x) + E (w) = b + A\u00b5 x (54) \u03a3 y,y = E (y \u2212 E (y))(y \u2212 E (y)) T = E (A(x \u2212 \u00b5 x ) + w)(A(x \u2212 \u00b5 x ) + w) T = E A(x \u2212 \u00b5 x )(x \u2212 \u00b5 x ) T A T + A(x \u2212 \u00b5 x )w T + w(x \u2212 \u00b5 x ) T A T + ww T = AE (x \u2212 \u00b5 x )(x \u2212 \u00b5 x ) T A T + AE (x \u2212 \u00b5 x )w T + E w(x \u2212 \u00b5 x ) T A T + E ww T = A\u03a3 x A T + R (55)\nThen we apply (52) to get p(s t | z t ) = N (\u00b5 t , \u03a3 t ) where\n\u00b5 t =\u03bc t +\u03a3 t C T (C\u03a3 t C T + Q) \u22121 (z t \u2212 d \u2212 C\u03bc t ) (67) \u03a3 t =\u03a3 t \u2212\u03a3 t C T (C\u03a3 t C T + Q) \u22121 C\u03a3 t (68)\nIf we define\nK t =\u03a3 t C T (C\u03a3 t C T + Q) \u22121 (69)\nto be the Kalman gain matrix, then the measurement update can be rewritten\n\u00b5 t =\u03bc t + K t (z t \u2212 d \u2212 C\u03bc t ) (70) \u03a3 t = (I \u2212 K t C)\u03a3 t (71)\nCollectively, equations ( 64), ( 65), ( 69), ( 70), and (71) constitute the Kalman filter. If the dimension of the observations is small, then the time and space complexity of the measurement update is quadratic in the dimension of the state space because of the additive covariance update in (71).\nAs it became popular in control applications, practitioners discovered the Kalman filter suffered from numerical stability problems [Maybeck, 1979]. The preferred solution to these numerical issues is to use one of a family of square-root filters, which represent the belief state's covariance using the Cholesky decomposition of \u03a3 t (or its inverse). Motion and measurement updates can operate directly on these representations, reducing the susceptibility of the filter to round-off error. However, the measurement update of these filters requires time cubic in the dimension of the state variable. (Some special cases, like when R or Q is diagonal, this complexity can be reduced to quadratic.)", "publication_ref": ["b16"], "figure_ref": [], "table_ref": []}, {"heading": "B.2 Application to SLAM", "text": "Two useful optimizations are possible when applying the Kalman filter to a SLAM problem. The first reduces the complexity of the time update from cubic to linear in the dimension of the state space, and the second reduces the complexity of the measurement update from quadratic to linear when a landmark is observed for the first time.\nBecause none of the landmark states change over time, the matrix A in (62) has the form of the identity matrix, except for the block corresponding to the robot state x t . This structure can be leveraged to yield a linear-time update: Proposition 7. Let p(m t ) = N (\u00b5 t , \u03a3 t ) where = {l 1 , . . . , l n } is the set of all landmarks and\n\u00b5 t = \u00b5 xt \u00b5 and \u03a3 t = \u03a3 xtxt \u03a3 xt \u03a3 T xt \u03a3 (72)\nLet the robot's dynamics be governed by\nx t+1 = Ax t + b + v (73)\nwhere v \u223c N (0, Q) is an independent white noise variable. Then p(m t+1 ) = N (\u00b5 t+1 , \u03a3 t+1 ) where\n\u00b5 t+1 = A\u00b5 xt + b \u00b5 and \u03a3 t+1 = A\u03a3 xtxt A T + Q A\u03a3 xt \u03a3 T xt A T \u03a3 (74)\nThis update requires time linear in the number of landmarks, because only the elements of the covariance matrix that correspond to x t+1 must be computed.\nwhere the zero precision of l reflects our uninformative prior. Using (20), we know that incorporating the first measurement z of l results in the following distribution:\nx l \u223c N \u22121 \uf8eb \uf8ec \uf8ec \uf8ec \uf8ed \u03a3 \u22121 xx \u00b5 x + E T S \u22121 (z \u2212 g) F T S \u22121 (z \u2212 g) \u03b7 , \u03a3 \u22121 xx + E T S \u22121 E E T S \u22121 F F T S \u22121 E F T S \u22121 F \u039b \uf8f6 \uf8f7 \uf8f7 \uf8f7 \uf8f8 (86)\nWe now must perform the tedious conversion from the canonical parameterization back to the moment parameterization. Our first step is to invert \u039b to obtain \u03a3:\n\u03a3 = \u039b \u22121 = \u03a3 \u22121 xx + E T S \u22121 E E T S \u22121 F F T S \u22121 E F T S \u22121 F \u22121 = \u03a3 xx \u2212\u03a3 xx E T F \u2212T \u2212F \u22121 E\u03a3 xx F \u22121 (E\u03a3 xx E T + S)F \u2212T (87)\nThis follows from the partitioned inverse formula; if\nM = E F G H (88) then M \u22121 = (M/H) \u22121 \u2212(M/H) \u22121 F H \u22121 \u2212H \u22121 G(M/H) \u22121 H \u22121 + H \u22121 G(M/H) \u22121 F H \u22121 (89)\nwhere M/H = E \u2212 F H \u22121 G is the Schur complement of M with respect to H. We now have proved the correctness of (82), and (83). We compute \u00b5 as\n\u00b5 = \u039b \u22121 \u03b7 = \u03a3\u03b7 = \u03a3 xx \u2212\u03a3 xx E T F \u2212T \u2212F \u22121 E\u03a3 xx F \u22121 (E\u03a3 xx E T + S)F \u2212T \u03a3 \u22121 xx \u00b5 x + E T S \u22121 (z \u2212 g) F T S \u22121 (z \u2212 g) = \u03a3 xx \u03a3 \u22121 xx \u00b5 x + \u03a3 xx E T S \u22121 (z \u2212 g) \u2212 \u03a3 xx E T F \u2212T F T S \u22121 (z \u2212 g) \u2212F \u22121 E\u03a3 xx \u03a3 \u22121 xx \u00b5 x \u2212 F \u22121 E\u03a3 xx E T S \u22121 (z \u2212 g) + F \u22121 (E\u03a3 xx E T + S)F \u2212T F T S \u22121 (z \u2212 g) = \u00b5 x \u2212F \u22121 E\u00b5 x \u2212 F \u22121 E\u03a3 xx E T S \u22121 (z \u2212 g) + F \u22121 (E\u03a3 xx E T + S)S \u22121 (z \u2212 g) = \u00b5 x F \u22121 (z \u2212 g \u2212 E\u00b5 x )\nThus, we now have proved the correctness of (81).\nTo prove (84), we make use of the iterated expectation theorem and the iterated covariance theorem:\nE (x) = E (E (x | y)) (90) Cov (x, y) = Cov (E (x | y) , y)(91)\nUsing these facts, we get\n\u03a3 l = Cov ( , l) = Cov (E ( | l) , l) (92) = Cov (E (E ( | x) | l) , l) (93) = Cov E \u00b5 + \u03a3 x \u03a3 \u22121 xx (x \u2212 \u00b5 x ) | l , l (94) = Cov \u00b5 + \u03a3 x \u03a3 \u22121 xx (\u00b5 x + \u03a3 xl \u03a3 \u22121 ll (l \u2212 \u00b5 l ) \u2212 \u00b5 x ), l(95)\n= Cov \u00b5 + \u03a3 x \u03a3 \u22121 xx \u03a3 xl \u03a3 \u22121 ll (l \u2212 \u00b5 l ), l (96) = \u03a3 x \u03a3 \u22121 xx \u03a3 xl \u03a3 \u22121 ll \u03a3 ll (97) = \u2212\u03a3 x (F \u22121 E) T (98\n)\nNote that we can only get away with this \"trick\"-starting with an uninformative prior over the landmark state and then using the measurement to yield an informed posterior-when the measurements are informative enough. When the observation model is not invertible, then the problem is ill-posed; for example, a robot which receives only bearing (and not range) information cannot use this technique. In such cases, the robot must start with an informed prior distribution of the landmark state; however, a similar effect is obtained by choosing this prior to be very weak, e.g., choosing a prior centered at the origin with very large variance.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B.3 Gating", "text": "Gating is a statistical test to determine whether a measurement z issued from some landmark l. One simple method of doing this is to use confidence regions. Let l \u223c N (\u00b5, \u03a3). If we choose some Mahalanobis threshold k > 0, this defines an ellipsoid\nE = {x : (x \u2212 \u00b5) T \u03a3 \u22121 (x \u2212 \u00b5) \u2264 k} (99)\nThe points on the boundary of E all have equal likelihood, because they all have equal Mahalanobis distance.\nBecause l is distributed according to a multivariate Gaussian (say, of dimension d), the Mahalanobis distance is distributed according to a \u03c7 2 distribution with d degrees of freedom. Thus, we can compute the probability mass of E by evaluating the cumulative distribution function of the \u03c7 2 distribution (with d degrees of freedom) at our threshold k.\nBy inverting this computation, we can take a desired confidence value p and compute the Mahalanobis distance k defining the smallest ellipsoid containing p probability. 11 Therefore, for a fixed confidence p and a given measurement z, we can determine if the Mahalanobis distance of z is less than the threshold defined by p; if it is, we assume z originated from l; otherwise, we assume it did not. Given our assumptions, this statistical test will fail with probability 1 \u2212 p. For example, if we choose p = 95%, then 5% of the time we will incorrectly assume z did not originate from l when it actually did. It is difficult to quantify how often the complementary sort of error will occur, i.e., how often we will assign z to l when it did not originate from l; that would require a detailed model of noise, outliers, and the other landmarks in the region.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B.4 Dealing with nonlinear models", "text": "When the dynamic and measurement models are not affine with additive Gaussian noise, there are two standard techniques for approximating them with such functions (see Figure 16). The most commonly used is the Extended Kalman Filter (EKF), in which a nonlinear function is approximated by its first-order Taylor expansion about the expectation its input variables. This technique requires only the mean of the input distribution and a method for evaluating the Jacobian of the function at the mean. Unfortunately, the EKF can perform very poorly in cases where the function is not approximately linear in the likely region of its inputs.\nThe second technique, the Unscented Kalman Filter (UKF), trades the difficult problem of approximating a nonlinear function with the simpler problem of approximating the output distribution as a conditional Gaussian [Wan and van der Merwe, 2000]. Once this is accomplished, the conditional Gaussian distribution can be easily translated into a corresponding affine approximation of the nonlinear function. To approximate the output distribution, a small set of weighted points in the input space (called sigma points) are strategically selected to characterize the Gaussian input distribution (typically the mean and the endpoints of the axes of the one standard deviation covariance ellipse); then the output distribution is approximated by computing the weighted mean and covariance of the images of the sigma points under the nonlinear function. The UKF is generally more precise than the EKF and has comparable computational complexity, but it requires knowledge of both the mean and covariance of the function input, whereas the EKF requires only the mean. Lerner has shown that the UKF is merely one choice from a family of numerical integration techniques that can smoothly trade computational effort for approximation accuracy [Lerner, 2002]. Linearization is more complicated in the case of observing a landmark for the first time. In this case, we have an observation z, a distribution over the robot state p(x), a white noise distribution p(u), and a nonlinear landmark observation function z = f (x, l, u) that takes as input the robot state x, the landmark state l, and a white noise value u. However, because we do not have an informative prior over l, the state of the landmark, we cannot apply the linearization techniques above.\nWe can solve this problem if the landmark measurement model is invertible. Assume that in addition to f , we also have its inverse with respect to l; i.e., we have the function l = f \u22121 (x, z, u) which computes the state of the landmark given the robot state, the measurement, and the noise value. Because z is known, we can linearize f \u22121 using the techniques above to obtain an estimate of p(l | z). We can then use this estimate as our prior belief in l to linearize f (x, l, u).", "publication_ref": ["b25", "b14"], "figure_ref": ["fig_7"], "table_ref": []}, {"heading": "C Proofs", "text": "Proof of Proposition 1. (Sketch) p(s | q) is a conditional Gaussian distribution with mean s 0 + Lq and covariance U . Thus, the canonical parameters of its conditional Gaussian distribution are U \u22121 (s 0 + Lq) and U \u22121 . Writing out the distribution using these canonical parameters and collecting terms reveals that p(s | q) is proportional to the product \u03c6 q (q) \u2022 \u03c6 s (s) \u2022 \u03c6 qs (q, s), which in combination with the chain rule yields ( 14). ( 18) is obtained by substituting s = s and eliminating constant terms.\nProof of Proposition 2. Let = (l 1 , . . . , l n ) be the currently known landmarks; when the new landmark l is first added to the map, the state variable and the parameters are augmented to\nm = \uf8ee \uf8f0 x l \uf8f9 \uf8fb , \u03b7 = \uf8ee \uf8f0 \u03b7 x \u03b7 0 \uf8f9 \uf8fb , and \u039b = \uf8ee \uf8f0 \u039b xx \u039b x 0 \u039b x \u039b 0 0 0 0 \uf8f9 \uf8fb\nwhere the zero precision of l reflects our uninformative prior. Using (20), we know that incorporating the first measurement z of l results in the following updates:\n\u03b7 z = \uf8ee \uf8f0 \u03b7 x + E T S \u22121 (z \u2212 g) \u03b7 F T S \u22121 (z \u2212 g) \uf8f9 \uf8fb\n(100)\n\u039b z = \uf8ee \uf8f0 \u039b xx + E T S \u22121 E \u039b x E T S \u22121 F \u039b x \u039b 0 F T S \u22121 E 0 F T S \u22121 F \uf8f9 \uf8fb (101)\nApplying ( 50) to marginalize out the new landmark l, we find\n\u03b7 m z = \u03b7 x + E T S \u22121 (z \u2212 g) \u2212 E T S \u22121 F (F T S \u22121 F ) \u22121 F T S \u22121 (z \u2212 g) \u03b7 (102) = \u03b7 x + E T S \u22121 (z \u2212 g) \u2212 E T S \u22121 F (F \u22121 RF \u2212T )F T S \u22121 (z \u2212 g) \u03b7 (103) = \u03b7 x + E T S \u22121 (z \u2212 g) \u2212 E T S \u22121 (z \u2212 g) \u03b7 = \u03b7 x \u03b7 l(104)\nand\n\u039b m z = \u039b xx + E T S \u22121 E \u2212 E T S \u22121 F (F T S \u22121 F ) \u22121 F T S \u22121 E \u039b x \u039b x \u039b (105) = \u039b xx + E T S \u22121 E \u2212 E T S \u22121 F (F \u22121 RF \u2212T )F T S \u22121 E \u039b x \u039b x \u039b (106) = \u039b xx + E T S \u22121 E \u2212 E T S \u22121 E \u039b x \u039b x \u039b = \u039b xx \u039b x \u039b x \u039b (107\n)\nwhich parameterized the distribution before the new measurement was incorporated; thus, the measurement update for the new landmark does not affect their marginal distribution.\nProof of Proposition 3. (Sketch.) Variable contraction preserves the singly connected property, because it introduces no new edges into the graph. (While it may empty a separator, this does not remove the corresponding edge. Merging a nonmaximal cluster into its subsuming neighbor also does not change violate the singly connected property because they must be neighbors in the junction tree.) Variable contraction preserves the running intersection property by construction, since it contracts a variable x only from a leaf of its induced subtree; more concretely, any path between two clusters containing x (except C, of course) is preserved. Finally, marginalizing x out of \u03c6 C and \u03c6 S does not change the marginals of the other variables under \u03c6 C and \u03c6 S , and so consistency is preserved. We now prove that of all distributions with the same conditional independence structure, the distribution \u03c6 T has maximum likelihood (under \u03c6 T ). Because the probability model of T is decomposable, we know it is parameterized in terms of the marginals of its clusters and separators [Whittaker, 1989]. It immediately follows that choosing \u03c6\u0108 to be \u03c6 C dx and \u03c6\u015c to be \u03c6 S dx (and leaving the other cluster potentials alone) is a maximum likelihood projection, since those are the maximum-likelihood marginals as obtained from \u03c6 T . Now, for a k-dimensional Gaussian random variable u, the differential entropy is (see [Cover and Thomas, 1991, Theorem 9.4.1])", "publication_ref": ["b26"], "figure_ref": [], "table_ref": []}, {"heading": "Proof of", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Proof of", "text": "H(u) = 1 2 log((2\u03c0e) k det Cov (u)) = k 2 log(2\u03c0e) \u2212 1 2 log det Cov (u) \u22121\nThus, we need only the precision matrices of the conditional distributions p(x | S \\ x) and p(x | C \\ x). Using ( 110) and ( 51 ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgments", "text": "I gratefully acknowledge Intel Corporation for supporting this research via an Intel Research Internship, as well as Sekhar Tatikonda, Francis Bach, and Andrew Ng for valuable discussions.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "", "text": "Therefore,", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B The traditional approach to SLAM", "text": "In this section, we describe the traditional approach to SLAM as exemplified by [Smith and Cheeseman, 1986;Smith et al., 1990;Leonard et al., 1992]. We begin by deriving the Kalman filter and describing two important optimizations in its application to the SLAM problem. Then we describe gating, a technique used in maximum likelihood data association. Finally, we address the issue of dealing with non-linear models.", "publication_ref": ["b19", "b19", "b13"], "figure_ref": [], "table_ref": []}, {"heading": "B.1 The Kalman filter", "text": "The Kalman Filter is an iterative algorithm for estimating the state of an unobserved system whose dynamics and observations are affine with Gaussian noise. The state variable evolves according to the affine-Gaussian relationship\nwhere w \u223c N (0, R) is an independent white noise variable. At each time step, we receive an observation governed by another affine-Gaussian relationship\nwhere u \u223c N (0, Q) is another independent white noise variable. This model is called the state space model. If the model parameters b, A, R, d, C and Q do not vary over time, the model is called time invariant.\nAssume that s t\u22121 \u223c N (\u00b5 t\u22121 , \u03a3 t\u22121 ). Then time update consists of computing the distribution of s t , which by ( 54) and ( 55), is N (\u03bc t ,\u03a3 t ) wher\u00ea\nIn general, the time update takes time cubic in the dimension of the state space because of the matrix multiplications in (65).\nThe measurement update consists of computing the distribution p(s t | z t ). To do this, we can form the joint distribution p(s t , z t ) using ( 61):\nwhere\u0100 = [ A 0 ] so that x t+1 is an affine Gaussian function of m t . By ( 61), the joint distribution of m t and x t+1 is given by\nExpanding m t , \u00b5 and \u03a3 we get\nMarginalizing x t out of this distribution via ( 47) and ( 48) and reordering and x t+1 gives the result.\nThe second optimization is that when a landmark is observed for the first time, we can avoid the quadratic time complexity of the measurement update. Proposition 8. Let p(m) = N (\u00b5, \u03a3) where = {l 1 , . . . , l n } is the set of all landmarks and\nLet l be a landmark with a uniform prior (i.e., p(l) = 1) which is observed for the first time via the measurement equation (2):\nwhere u \u223c N (0, S) and F is invertible. Then\nwhere\nThis update requires time linear in the number of landmarks, because only the elements of the covariance matrix that correspond to the new landmark change.\nProof. By Proposition 2, the marginal density of m does not change, and so \u00b5 x , \u00b5 , \u03a3 xx , \u03a3 x , and \u03a3 remain the same. Thus, we must only compute \u00b5 l , \u03a3 ll , \u03a3 xl , and \u03a3 l . Let us first consider the case where = \u2205, i.e., there are no landmarks in the map. Then the initial joint distribution over x and l (before incorporating the measurement) is", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Thin junction trees", "journal": "MIT Press", "year": "2002", "authors": "Jordan ; F R Bach; M I Bach;  Jordan"}, {"ref_id": "b1", "title": "An atlas framework for scalable mapping. MIT Marine Robotics Laboratory Technical memorandum 2002-04", "journal": "", "year": "2002", "authors": "[ Bosse"}, {"ref_id": "b2", "title": "Tractable inference for complex stochastic processes", "journal": "", "year": "1998-07", "authors": "Daphne Koller ; Xavier Boyen;  Koller"}, {"ref_id": "b3", "title": "Exploiting the architecture of dynamic systems", "journal": "", "year": "1999", "authors": "Koller ; Xavier Boyen; Daphne Boyen;  Koller"}, {"ref_id": "b4", "title": "Elements of Information Theory", "journal": "John Wiley & Sons", "year": "1991", "authors": "; Thomas; M Thomas; Joy A Cover;  Thomas"}, {"ref_id": "b5", "title": "Probabilistic Networks and Expert Systems", "journal": "Springer", "year": "1999", "authors": " Cowell"}, {"ref_id": "b6", "title": "Raoblackwellised particle filtering for dynamic bayesian networks", "journal": "", "year": "2000", "authors": "[ Doucet"}, {"ref_id": "b7", "title": "Clustering without (thinking about) triangulation", "journal": "Morgan Kaufmann Publishers", "year": "1995", "authors": "Denise L Draper"}, {"ref_id": "b8", "title": "Identifying independence in bayesian networks", "journal": "Networks", "year": "1990", "authors": "[ Geiger"}, {"ref_id": "b9", "title": "Optimization of the simultaneous localization and map building algorithm for real time implementation", "journal": "IEEE Transactions on Robotic and Automation", "year": "2000", "authors": "J E Nebot; E M Guivant;  Nebot"}, {"ref_id": "b10", "title": "Probabilistic map learning: Necessity and difficulties", "journal": "Springer", "year": "1996", "authors": "[ H\u00e9bert"}, {"ref_id": "b11", "title": "Stable local computation with conditional Gaussian distributions", "journal": "", "year": "1993", "authors": "; S Kjaerulff; F Lauritzen;  Jensen"}, {"ref_id": "b12", "title": "A computationally efficient method for largescale concurrent mapping and localization", "journal": "Springer-Verlag", "year": "2000", "authors": " Leonard; J J Feder; H J S Leonard;  Feder"}, {"ref_id": "b13", "title": "Dynamic map building for an autonomous mobile robot", "journal": "International Journal of Robotics Research", "year": "1992-08", "authors": "[ Leonard"}, {"ref_id": "b14", "title": "Hybrid Bayesian Networks for Reasoning About Complex Systems", "journal": "", "year": "2002-10", "authors": "Uri Lerner;  Lerner"}, {"ref_id": "b15", "title": "Results for outdoor-SLAM using sparse extended information filters", "journal": "", "year": "2002", "authors": "Thrun ; Yufeng Liu; Sebastian Liu;  Thrun"}, {"ref_id": "b16", "title": "Stochastic Models, Estimation and Control", "journal": "Academic", "year": "1979", "authors": "; P S Maybeck;  Maybeck"}, {"ref_id": "b17", "title": "Simultaneous localization and mapping with unknown data association using FastSLAM", "journal": "Prentice Hall", "year": "2002", "authors": "Thrun ; Mike Montemerlo; Sebastian Montemerlo; ; Thrun;  Montemerlo"}, {"ref_id": "b18", "title": "Global conditioning for probabilistic inference in belief networks", "journal": "Morgan Kaufmann", "year": "1994", "authors": "[ Shachter"}, {"ref_id": "b19", "title": "On the representation and estimation of spatial uncertainty", "journal": "Springer-Verlag", "year": "1986", "authors": " Smith; C Cheeseman ; Randall; Peter Smith; ; Cheeseman; C Randall; Matthew Smith; Peter Self;  Cheeseman"}, {"ref_id": "b20", "title": "Gaussian markov distributions over finite graphs", "journal": "Annals of Statistics", "year": "1986-03", "authors": "; T P Kiiveri; H T Speed;  Kiiveri"}, {"ref_id": "b21", "title": "Robust mapping and localization in indoor environments using sonar data. MIT Marine Robotics Laboratory Technical Memorandum", "journal": "", "year": "2001-04", "authors": " Tard\u00f3s"}, {"ref_id": "b22", "title": "Hugh Durrant-Whyte, and Andrew Ng. Simultaneous localization and mapping with sparse extended information filters: Theory and initial results", "journal": "Artificial Intelligence", "year": "2001", "authors": "[ Thrun"}, {"ref_id": "b23", "title": "Robotic mapping: A survey", "journal": "", "year": "2002-02", "authors": " Thrun ; Sebastian Thrun"}, {"ref_id": "b24", "title": "Least-squares estimation of transformation parameters between two point patterns", "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": "1991-04", "authors": "Shinji Umeyama"}, {"ref_id": "b25", "title": "The unscented kalman filter for nonlinear estimation", "journal": "AS-SPCC", "year": "2000", "authors": "[ Wan; ; E Van Der Merwe; R Wan;  Van Der Merwe"}, {"ref_id": "b26", "title": "", "journal": "John Wiley & Sons", "year": "1989", "authors": "Whittaker ; Joe Whittaker"}], "figures": [{"figure_label": "", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "(a) Before closing the loop. (b) After closing the loop.", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 2 :2Figure 2: In this simulation, a full Kalman filter was used; the robot travels counter-clockwise on a noisy square path through a world randomly populated with point landmarks. The 95% confidence regions are shown (bold for the robot). The true position of the robot is shown by a square. (a) Before closing the loop, accumulated error has led to uncertain and drifted estimates for the positions of the robot and the recentlyobserved landmarks. (b) After closing the loop, the estimates are all improved and the confidence is greatly increased.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 3 :3Figure 3: Incorporating landmark measurements. (a) At time one, three landmark measurements, z 1 1 , z 1 2 , and z 1 3 , are made of landmark states l 1 , l 2 , and l 3 . (b) Moralizing the directed graph produces the undirected graphical model in which the landmarks are coupled with the robot state. (c) Eliminating the observed measurement variables leaves a graph in which the robot state is directly dependent upon the states of all the measured landmarks.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "x", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 4 :4Figure 4: Incorporating robot motion. (a) The robot's state at the next time step and its odometry measurement y 2 are added to the model. (b) Moralizing this graph adds no new edges. (c) Eliminating the odometry variables adds no new edges. (d) Eliminating the state at the previous time step adds an elimination clique that includes the current state x 2 and all the active landmarks.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "p(l1, l2, l3): Three landmarks, l1, l2, and l3, are measured from the same robot position. p(x)p(l1, l2, l3 | x): When represented conditional on the position of the observing robot, the confidence regions of l1, l2, and l3 shrink by 95%, 94%, and 93%, respectively: knowing x gives us good information about the locations of l1, l2, and l3. p(l1)p(l2, l3 | l1):", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Figure 5 :5Figure 5: Illustration of direct versus indirect dependencies and redundancy. Each image visualizes a joint distribution. Variable distributions are shown by 95% confidence regions; marginal distributions are shown in red (solid) and conditional distributions are shown in black (dashed). The area of each confidence region (a measure of uncertainty) is shown in parentheses.", "figure_data": ""}, {"figure_label": "6", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "CFigure 6 :6Figure6: The graphical model representing a common type of dynamics/odometry model; x t (and all active landmarks) are independent of y t+1 because x t+1 is unobserved.", "figure_data": ""}, {"figure_label": "7", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "Figure 7 :7Figure 7: An example of cluster merging. (a) The shaded clusters and separators are those containing the variable v. (b) In order to marginalize v out of the junction tree, we merge C 1 , C 2 , C 3 and C 4 and eliminate the separators between them.", "figure_data": ""}, {"figure_label": "8", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "Figure 8 :8Figure 8: An example of a cloning contraction. (a) Assume v appears only in C. (b) We first clone C and attach the clone to C; thus, the separator must also contain the variables of C. Now the original cluster is a leaf of T v . (c) We contract v from the original cluster to the clone. (d) We contract some other variable u \u2208 C from the clone. Now the size of both clusters is one less than before.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_10", "figure_caption": "(a) clone C to obtain C , (b) attach C to C, (c) contract x to C , and (d) thin C .", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_11", "figure_caption": "Algorithm 33Multiply a measurement potential \u03c8(x, l) into the thin junction tree. 1: if l has not yet been observed then", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_13", "figure_caption": "x, l) into \u03c6 C . {updates charge} 10: else {l has been previously observed} 11: C \u2190 the cluster closest to T x containing l 12: p \u2190 the path from T x to C 13: Add x to all clusters and separators along p. {restores running intersection property} 14: Pass messages along p. {restores consistency} 15: Multiply \u03c8(x, l) into \u03c6 C . {updates charge} 16:", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_15", "figure_caption": "30 \u2022 /s STDEV(v t ) relative noise in translational velocity control (STDEV) 0.03 STDEV(v a ) absolute noise in translational velocity control (STDEV) 0.02m/s STDEV(v r ) relative noise in rotational velocity control (STDEV) 0.05 STDEV(v b ) absolute noise in rotational velocity control (STDEV) 1 \u2022 /s STDEV(w t ) additive noise in translational velocity odometry (STDEV) 0.02m/s STDEV(w r ) additive noise in rotational velocity odometry (STDEV) 1 \u2022 /s STDEV(u b ) additive noise in bearing measurements (STDEV) 2 \u2022 STDEV(u r ) relative noise in range measurements (STDEV) 0.1 STDEV(u a ) absolute noise in range measurements (STDEV) 0.5m L the length of the side of the square region being mapped 100m N number of landmarks 1000", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_16", "figure_caption": "(a) A square trajectory. (b) A switchback trajectory.", "figure_data": ""}, {"figure_label": "13", "figure_type": "figure", "figure_id": "fig_17", "figure_caption": "Figure 13 :13Figure 13: Two example simulations. The solid line is the actual robot path; the dashed line is the integrated odometry; the dash-dotted line is the integrated control signal; circles are landmarks; and dots are landmark observations (relative to the unknown actual viewpoint). For clarity, only a fraction of the 1000 landmarks are plotted.", "figure_data": ""}, {"figure_label": "15", "figure_type": "figure", "figure_id": "fig_18", "figure_caption": "Figure 15 :15Figure 15: Performance of TJTF (k = 16, h = 4, s = 0.1), the Kalman filter, and FastSLAM (n = 100) on the simulations depicted in Figure 13.", "figure_data": ""}, {"figure_label": "16", "figure_type": "figure", "figure_id": "fig_19", "figure_caption": "Figure 16 :16Figure16: An illustration of the UKF and EKF. The bottom graph gives the density of x \u223c N (0, \u03c0 2 ) and shows the sigma points selected by the UKF; the upper left graph shows a nonlinearity f (x) = x + sin x, along with the linearization used by the EKF and the images of sigma points chosen by the UKF. On the right is a histogram of 10,000 samples of x passed through f (x) and the maximum likelihood, EKF, and UKF Gaussian approximations.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_20", "figure_caption": "Proposition 4. We must first prove that the distribution of T has the conditional independence structure of T , plus x\u22a5 \u22a5C \u2212 S | S \\ x. But this is a simple consequence of C i \u22a5 \u22a5C j | S ij , that two adjacent clusters are conditionally independent given their separator. Let C be the cluster joined to C via S, and recall x \u2208 C . In T we had C \u22a5 \u22a5C | S, or equivalently,C \u2212 C\u22a5 \u22a5C \u2212 S | S (108) because S = C \u2229 C. In T this becomes C \u2212 (C \\ x)\u22a5 \u22a5C \u2212 S | S \\ x,because x has been removed from C and S. Comparing this to (108), we see there is now one additional conditional independence: x\u22a5 \u22a5C \u2212 S | S \\ x.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_21", "figure_caption": "log C \u2208C p(C )/q(C ) S \u2208S p(S )/q(S ) \\ x | S \\ x) dC = H(C \\ x | S \\ x) \u2212 H(C | S) = H(C \u2212 S | S \\ x) \u2212 H(C \u2212 S | S) = H(C \u2212 S | S \\ x) \u2212 H(C \u2212 S | (S \\ x) \u222a {x}) = I(x; C \u2212 S | S \\ x)Proof of Proposition 6. Using the identity I(u; v) = H(u) \u2212 H(u | v), we get thatI(x; C \u2212 S | S \\ x) = H(x | S \\ x) \u2212 H(x | (C \u2212 S) \u222a (S \\ x)) (109) = H(x | S \\ x) \u2212 H(x | C \\ x) (110)", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_22", "figure_caption": ") we get I(x; C \u2212 S | S \\ x) where \u039b C = Cov (C) \u22121 and \u039b S = Cov (S) \u22121 .", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "A table of the simulation parameters and their default values.", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "m t = \uf8ee \uf8ef \uf8ef \uf8ef \uf8f0 x t l 1 . . . l nt \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fb (1)", "formula_coordinates": [5.0, 257.18, 182.66, 274.3, 61.83]}, {"formula_id": "formula_1", "formula_text": "z i t = Ex t + F l \u03b4 i t + g + u (2)", "formula_coordinates": [6.0, 231.53, 438.3, 299.92, 16.73]}, {"formula_id": "formula_2", "formula_text": "x t+1 = Ax t + b + v (3) x 1 z 1 1 z 2 1 z 3 1 x y 2 z 1 2 z 2 2 x 3 y 3 z 1 3 z 2 3 z 3 3 l 1 l 2 l 3 l 4 l 5", "formula_coordinates": [6.0, 244.08, 727.3, 287.38, 11.53]}, {"formula_id": "formula_3", "formula_text": "y t+1 = Cx t+1 + d + w (4)", "formula_coordinates": [7.0, 236.75, 358.22, 294.7, 12.51]}, {"formula_id": "formula_4", "formula_text": "p G (V ) = 1 Z \u03c8\u2208\u03a8 \u03c8(V \u03c8 )(5)", "formula_coordinates": [11.0, 234.84, 308.82, 296.64, 30.63]}, {"formula_id": "formula_5", "formula_text": "Z = V \u03c8\u2208\u03a8 \u03c8(V \u03c8 )(6)", "formula_coordinates": [11.0, 244.29, 378.76, 287.19, 23.25]}, {"formula_id": "formula_6", "formula_text": "x n } p(x) = 1 Z n i=1 \u03c8 i (x i ) n j=i+1 \u03c8 ij (x i , x j )(7)", "formula_coordinates": [11.0, 201.98, 520.75, 329.5, 54.56]}, {"formula_id": "formula_7", "formula_text": "\u03c8 i (x i ) = exp \u03b7 i x T i \u2212 1 2 x T i \u039b ii x i (8) \u03c8 ij (x i , x j ) = exp \u2212x T i \u039b ij x j(9)", "formula_coordinates": [11.0, 199.04, 604.91, 332.44, 44.27]}, {"formula_id": "formula_8", "formula_text": "p(m) = 1 Z n i=0 \u03c8 i (m (i) ) n j=i+1 \u03c8 ij (m (i) , m (j) )(10)", "formula_coordinates": [12.0, 183.96, 705.9, 347.51, 34.13]}, {"formula_id": "formula_9", "formula_text": "x 1 z 1 1 z 2 1 z 3 1 l 1 l 2 l 3 (a) x 1 z 1 1 z 2 1 z 3 1 l 1 l 2 l 3 (b) x 1 l 1 l 2 l 3 (c)", "formula_coordinates": [13.0, 115.64, 158.93, 342.66, 130.9]}, {"formula_id": "formula_10", "formula_text": "1 l 1 l 2 l 3 x 2 y 2 (a) x 1 l 1 l 2 l 3 x 2 y 2 (b) x 1 l 1 l 2 l 3 x 2 (c) x 2 l 1 l 2 l 3 (d)", "formula_coordinates": [13.0, 113.44, 489.67, 356.03, 117.22]}, {"formula_id": "formula_11", "formula_text": "l 1 (2.1) l 2 (2.3) l 3 (0.36) (d) p(l1, l2)p(l3 | l1, l2):", "formula_coordinates": [14.0, 308.83, 442.02, 161.21, 124.29]}, {"formula_id": "formula_12", "formula_text": "\u03c8 i (m (i) ) = exp \u03b7 T (i) m (i) \u2212 1 2 m T (i) \u039b (ii) m (i)(11)", "formula_coordinates": [15.0, 182.39, 118.0, 349.08, 25.78]}, {"formula_id": "formula_13", "formula_text": "\u03c8 ij (m (i) , m (j) ) = exp \u2212m T (i) \u039b (ij) m (j)(12)", "formula_coordinates": [15.0, 191.48, 177.63, 340.0, 15.41]}, {"formula_id": "formula_14", "formula_text": "s = s 0 + Lq + t (13", "formula_coordinates": [15.0, 249.97, 349.33, 276.93, 11.81]}, {"formula_id": "formula_15", "formula_text": ")", "formula_coordinates": [15.0, 526.9, 350.07, 4.54, 9.82]}, {"formula_id": "formula_16", "formula_text": "p(q, r, s) \u221d p(q, r) \u2022 \u03c6 q (q) \u2022 \u03c6 s (s) \u2022 \u03c6 qs (q, s)(14)", "formula_coordinates": [15.0, 186.12, 398.08, 345.34, 11.81]}, {"formula_id": "formula_17", "formula_text": "\u03c6 q (q) = exp \u2212s T 0 U \u22121 Lq \u2212 1 2 q T L T U \u22121 Lq (15) \u03c6 s (s) = exp s T 0 U \u22121 s \u2212 1 2 s T U \u22121 s (16) \u03c6 qs (q, s) = exp s T U \u22121 Lq (17) Furthermore, p(q, r | s) \u221d p(q, r) \u2022 \u03c6 q (q)(18)", "formula_coordinates": [15.0, 63.49, 443.45, 467.98, 123.46]}, {"formula_id": "formula_18", "formula_text": "\u03c6 q (q) = exp (s \u2212 s 0 ) T U \u22121 Lq \u2212 1 2 q T L T U \u22121 Lq(19)", "formula_coordinates": [15.0, 170.45, 599.41, 361.03, 25.78]}, {"formula_id": "formula_19", "formula_text": "\u03c6 (x, l) = exp (z \u2212 g) T S \u22121 (Ex + F l) \u2212 1 2 (Ex + F l) T S \u22121 (Ex + F l)", "formula_coordinates": [16.0, 118.49, 166.74, 329.86, 25.77]}, {"formula_id": "formula_20", "formula_text": "\u03b7 x + \u2190 E T S \u22121 (z \u2212 g) \u03b7 l + \u2190 F T S \u22121 (z \u2212 g) \u039b xx + \u2190 E T S \u22121 E \u039b ll + \u2190 F T S \u22121 F \u039b xl + \u2190 E T S \u22121 F (20)", "formula_coordinates": [16.0, 229.87, 221.0, 301.61, 74.28]}, {"formula_id": "formula_21", "formula_text": "\u03b7 x t+1 + \u2190 C T R \u22121 (y \u2212 d) \u039b x t+1 x t+1 + \u2190 C T R \u22121 C (21)", "formula_coordinates": [16.0, 216.67, 368.47, 314.81, 29.29]}, {"formula_id": "formula_22", "formula_text": "\u03b7 xt + \u2190 \u2212b T Q \u22121 A \u03b7 x t+1 \u2190 bQ \u22121 \u039b xtxt + \u2190 A T Q \u22121 A \u039b x t+1 x t+1 \u2190 Q \u22121 \u039b xtx t+1 \u2190 A T Q \u22121 (22)", "formula_coordinates": [16.0, 226.78, 481.9, 304.7, 69.93]}, {"formula_id": "formula_23", "formula_text": "\u03b7x + \u2190 \u2212\u039bx x \u039b \u22121 xx \u03b7 x \u039bxx + \u2190 \u2212\u039bx x \u039b \u22121 xx \u039b xx (23)", "formula_coordinates": [16.0, 232.01, 711.57, 299.47, 29.73]}, {"formula_id": "formula_24", "formula_text": "{C i , C j } such that S ij = C i \u2229 C j .", "formula_coordinates": [18.0, 86.78, 320.27, 150.38, 11.81]}, {"formula_id": "formula_25", "formula_text": "\u03c6 T (V ) = C\u2208C \u03c6 C (C) S\u2208S \u03c6 S (S)(24)", "formula_coordinates": [18.0, 233.34, 368.45, 298.14, 28.59]}, {"formula_id": "formula_26", "formula_text": "\u03c6 * S ij = C i \u2212S ij \u03c6 C i (25) \u03c6 * C j = \u03c6 C j \u03c6 * S ij \u03c6 S ij (26)", "formula_coordinates": [18.0, 249.31, 485.68, 282.17, 55.88]}, {"formula_id": "formula_27", "formula_text": "(C = C 1 , C 2 , . . . , C k\u22121 , C k = C) \u2190 path from C to C 6:", "formula_coordinates": [19.0, 69.61, 552.77, 293.84, 23.95]}, {"formula_id": "formula_28", "formula_text": "C i \u2190 C i \u222a {u} 8: S i,i\u22121 \u2190 S i,i\u22121 \u222a {u} 9:", "formula_coordinates": [19.0, 69.61, 579.87, 155.71, 37.5]}, {"formula_id": "formula_29", "formula_text": "C 1 C 2 C 4 C 3 S 12 S 23 S 34 (a) C 1 \u222a C 2 \u222a C 3 \u222a C 4 (b)", "formula_coordinates": [21.0, 136.59, 113.54, 268.31, 200.82]}, {"formula_id": "formula_30", "formula_text": "\u03c6T = argmax {q : v \u22a5 \u22a5 C\u2212S | S\\v} \u03c6 T log q (27)", "formula_coordinates": [22.0, 211.23, 607.5, 320.22, 20.09]}, {"formula_id": "formula_31", "formula_text": "D(\u03c6 T || \u03c6 T ) = I(x; C \u2212 S | S \\ x).", "formula_coordinates": [23.0, 63.49, 553.3, 161.73, 12.28]}, {"formula_id": "formula_32", "formula_text": "I(x; C \u2212 S | S \\ x) = 1 2 log det \u039b C xx \u2212 log det \u039b S xx (28", "formula_coordinates": [24.0, 172.86, 154.75, 354.08, 25.78]}, {"formula_id": "formula_33", "formula_text": ")", "formula_coordinates": [24.0, 526.94, 162.87, 4.54, 9.82]}, {"formula_id": "formula_34", "formula_text": "\u039b C = Cov (C) \u22121 and \u039b S = Cov (S) \u22121 .", "formula_coordinates": [24.0, 92.44, 188.92, 176.08, 13.73]}, {"formula_id": "formula_35", "formula_text": "{x 1 } (a) {x 1 , l 1 } \u03c8(x 1 , l 1 ) (b) {x 1 , l 1 , l 2 } \u03c8(x 1 , l 2 ) (c) {l 1 , l 2 } {x 1 , l 1 , l 2 } (d) {l 1 , l 2 } {x 1 , l 2 } (e) {l 1 , l 2 } {x 1 , l 2 , l 3 } \u03c8(x 1 , l 3 ) (f) {l 1 , l 2 } {x 1 , x 2 , l 2 , l 3 } \u03c8(x 1 , x 2 ) (g) {l 1 , l 2 } {x 2 , l 2 , l 3 } \u03c8(x 2 ) (h)", "formula_coordinates": [26.0, 83.82, 120.1, 436.96, 135.29]}, {"formula_id": "formula_36", "formula_text": "{l 1 , l 2 } {x 2 , l 2 , l 3 } \u03c8(x 2 , l 2 ) (a) {l 1 , l 2 } {l 2 , l 3 } {x 2 , l 2 , l 3 } (b) {l 1 , l 2 } {l 2 , l 3 } {x 2 , l 2 } (c) {l 1 , l 2 } {l 2 , l 3 } {x 2 , l 2 , l 4 } \u03c8(x 2 , l 4 ) (d) {l 1 , l 2 } {l 2 , l 3 } {x 2 , x 3 , l 2 , l 4 } \u03c8(x 2 , x 3 ) (e) {l 1 , l 2 } {l 2 , l 3 } {x 3 , l 2 , l 4 } \u03c8(x 3 ) (f)", "formula_coordinates": [26.0, 103.33, 438.57, 394.05, 163.63]}, {"formula_id": "formula_37", "formula_text": "{l 1 , l 2 } {x 3 , l 2 , l 3 } {x 3 , l 2 , l 4 } \u03c8(x 3 , l 3 ) (a) {l 1 , l 2 } {x 3 , l 2 , l 3 } {x 3 , l 2 , l 4 } \u03c8(x 3 , l 4 ) (b) {l 1 , l 2 } {l 2 , l 3 } {l 2 , l 4 } {x 3 , l 3 } (c) {l 1 , l 2 } {l 2 , l 3 } {l 2 , l 4 } {x 3 , l 3 , l 5 } \u03c8(x 3 , l 5 ) (d)", "formula_coordinates": [27.0, 125.69, 108.2, 350.69, 163.63]}, {"formula_id": "formula_38", "formula_text": "D(\u03c6 * S i,j || \u03c6 S i,j ) = \u03c6 * S i,j log \u03c6 * S i,j \u03c6 S i,j (29) = 1 2 log det \u03a3 det \u03a3 * \u2212 n + trace(\u03a3 \u22121 (\u03a3 * + (\u00b5 * \u2212 \u00b5)(\u00b5 * \u2212 \u00b5) T )(30)", "formula_coordinates": [28.0, 114.88, 446.41, 416.6, 61.36]}, {"formula_id": "formula_39", "formula_text": "x = \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 x x x y x h x t x r \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb (31)", "formula_coordinates": [29.0, 261.16, 518.54, 270.31, 67.95]}, {"formula_id": "formula_40", "formula_text": "l = l x l y (32", "formula_coordinates": [29.0, 266.02, 649.27, 260.92, 25.87]}, {"formula_id": "formula_41", "formula_text": ")", "formula_coordinates": [29.0, 526.94, 658.72, 4.54, 9.82]}, {"formula_id": "formula_42", "formula_text": "\u03b4 = x x x y \u2212 l x l y (33)", "formula_coordinates": [30.0, 238.68, 118.83, 292.8, 25.86]}, {"formula_id": "formula_43", "formula_text": "z = z r z b = ||\u03b4|| 2 (1 + u r ) + u a arctan(\u03b4) \u2212 x h + u b (34)", "formula_coordinates": [30.0, 195.28, 192.66, 336.19, 25.93]}, {"formula_id": "formula_44", "formula_text": "u = u t u r(35)", "formula_coordinates": [30.0, 264.03, 335.83, 267.44, 25.92]}, {"formula_id": "formula_45", "formula_text": "x t+1 = \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 x x t+1 x y t+1 x h t+1 x t t+1 x r t+1 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb = \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 x x t + x t t cos x h t x y t + x t t sin x h t x h t + x r t u t (1 + v t ) + v a u r (1 + v r ) + v b \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb(36)", "formula_coordinates": [30.0, 190.29, 420.87, 341.19, 70.38]}, {"formula_id": "formula_46", "formula_text": "y = y t y r = x t + w t x r + w r (37", "formula_coordinates": [30.0, 222.88, 552.4, 304.05, 25.93]}, {"formula_id": "formula_47", "formula_text": ")", "formula_coordinates": [30.0, 526.94, 561.39, 4.54, 9.82]}, {"formula_id": "formula_48", "formula_text": "p(x) = 1 (2\u03c0) n det \u03a3 exp \u2212 1 2 (x \u2212 \u00b5) T \u03a3 \u22121 (x \u2212 \u00b5) (38", "formula_coordinates": [36.0, 166.09, 204.05, 360.85, 27.29]}, {"formula_id": "formula_49", "formula_text": ")", "formula_coordinates": [36.0, 526.94, 212.16, 4.54, 9.82]}, {"formula_id": "formula_50", "formula_text": "p(x) = exp \u2212 1 2 log((2\u03c0) n det \u03a3) \u2212 1 2 (x \u2212 \u00b5) T \u03a3 \u22121 (x \u2212 \u00b5) (39) = exp \u2212 n 2 log(2\u03c0) + 1 2 log det \u03a3 \u22121 \u2212 1 2 (x T \u03a3 \u22121 x + \u00b5 T \u03a3 \u22121 \u00b5 \u2212 2x T \u03a3 \u22121 \u00b5) (40) = exp \u2212 1 2 (n log(2\u03c0) \u2212 log det \u03a3 \u22121 + \u00b5 T \u03a3 \u22121 \u00b5) + x T \u03a3 \u22121 \u00b5 \u2212 1 2 x T \u03a3 \u22121 x (41)(42)", "formula_coordinates": [36.0, 101.56, 367.23, 429.91, 100.05]}, {"formula_id": "formula_51", "formula_text": "p(x) = exp a + \u03b7 T x \u2212 1 2 x T \u039bx(43)", "formula_coordinates": [36.0, 212.98, 494.96, 318.5, 25.77]}, {"formula_id": "formula_52", "formula_text": "a = \u2212 1 2 (n log(2\u03c0) \u2212 log det \u039b + \u03b7 T \u039b \u22121 \u03b7)(44)", "formula_coordinates": [36.0, 194.38, 542.21, 337.08, 25.77]}, {"formula_id": "formula_53", "formula_text": "x = x 1 x 2 (45)", "formula_coordinates": [36.0, 263.0, 693.68, 268.48, 25.01]}, {"formula_id": "formula_54", "formula_text": "\u00b5 = \u00b5 1 \u00b5 2 \u03a3 = \u03a3 11 \u03a3 12 \u03a3 21 \u03a3 22 (46) then x 1 \u223c N (\u00b5 m 1 , \u03a3 m 1 )", "formula_coordinates": [37.0, 63.5, 120.53, 467.98, 49.75]}, {"formula_id": "formula_55", "formula_text": "\u00b5 m 1 = \u00b5 1 (47) \u03a3 m 1 = \u03a3 11 (48)", "formula_coordinates": [37.0, 267.58, 178.82, 263.9, 31.18]}, {"formula_id": "formula_56", "formula_text": "\u03b7 = \u03b7 1 \u03b7 2 \u039b = \u039b 11 \u039b 12 \u039b 21 \u039b 22 (49) then x 1 \u223c N \u22121 (\u03b7 m 1 , \u039b m 1 )", "formula_coordinates": [37.0, 63.5, 257.16, 467.98, 50.67]}, {"formula_id": "formula_57", "formula_text": "\u03b7 m 1 = \u03b7 1 \u2212 \u039b 12 \u039b \u22121 22 \u03b7 1 \u039b m 1 = \u039b 11 \u2212 \u039b 12 \u039b \u22121 22 \u039b 21 (50)", "formula_coordinates": [37.0, 225.26, 315.84, 306.21, 29.47]}, {"formula_id": "formula_58", "formula_text": "If x \u223c N \u22121 (\u03b7, \u039b) then p(x 1 | x 2 ) = N \u22121 (\u03b7 c 1|2 , \u039b c 1|2 )", "formula_coordinates": [37.0, 63.49, 394.02, 467.97, 29.34]}, {"formula_id": "formula_59", "formula_text": "\u03b7 c 1|2 = \u03b7 1 \u2212 \u039b 12 x 2 \u039b c 1|2 = \u039b 11 (51) If instead x \u223c N (\u00b5, \u03a3) then p(x 1 | x 2 ) = N (\u00b5 c 1|2 , \u03a3 c 1|2 )", "formula_coordinates": [37.0, 63.49, 434.3, 467.98, 55.47]}, {"formula_id": "formula_60", "formula_text": "\u00b5 c 1|2 = \u00b5 1 + \u03a3 12 \u03a3 \u22121 22 (x 2 \u2212 \u00b5 2 ) \u03a3 c 1|2 = \u03a3 11 \u2212 \u03a3 12 \u03a3 \u22121 22 \u03a3 21(52)", "formula_coordinates": [37.0, 211.35, 499.79, 320.13, 31.98]}, {"formula_id": "formula_61", "formula_text": "y = Ax + b + w (53)", "formula_coordinates": [37.0, 251.82, 592.92, 279.6, 10.91]}, {"formula_id": "formula_62", "formula_text": "\u00b5 y = E (b + Ax + w) = b + AE (x) + E (w) = b + A\u00b5 x (54) \u03a3 y,y = E (y \u2212 E (y))(y \u2212 E (y)) T = E (A(x \u2212 \u00b5 x ) + w)(A(x \u2212 \u00b5 x ) + w) T = E A(x \u2212 \u00b5 x )(x \u2212 \u00b5 x ) T A T + A(x \u2212 \u00b5 x )w T + w(x \u2212 \u00b5 x ) T A T + ww T = AE (x \u2212 \u00b5 x )(x \u2212 \u00b5 x ) T A T + AE (x \u2212 \u00b5 x )w T + E w(x \u2212 \u00b5 x ) T A T + E ww T = A\u03a3 x A T + R (55)", "formula_coordinates": [37.0, 75.93, 639.74, 455.54, 99.09]}, {"formula_id": "formula_63", "formula_text": "\u00b5 t =\u03bc t +\u03a3 t C T (C\u03a3 t C T + Q) \u22121 (z t \u2212 d \u2212 C\u03bc t ) (67) \u03a3 t =\u03a3 t \u2212\u03a3 t C T (C\u03a3 t C T + Q) \u22121 C\u03a3 t (68)", "formula_coordinates": [39.0, 179.97, 118.72, 351.5, 30.37]}, {"formula_id": "formula_64", "formula_text": "K t =\u03a3 t C T (C\u03a3 t C T + Q) \u22121 (69)", "formula_coordinates": [39.0, 225.09, 182.37, 306.39, 13.84]}, {"formula_id": "formula_65", "formula_text": "\u00b5 t =\u03bc t + K t (z t \u2212 d \u2212 C\u03bc t ) (70) \u03a3 t = (I \u2212 K t C)\u03a3 t (71)", "formula_coordinates": [39.0, 225.35, 231.53, 306.13, 28.34]}, {"formula_id": "formula_66", "formula_text": "\u00b5 t = \u00b5 xt \u00b5 and \u03a3 t = \u03a3 xtxt \u03a3 xt \u03a3 T xt \u03a3 (72)", "formula_coordinates": [39.0, 194.06, 570.74, 337.42, 26.77]}, {"formula_id": "formula_67", "formula_text": "x t+1 = Ax t + b + v (73)", "formula_coordinates": [39.0, 244.08, 630.65, 287.37, 11.53]}, {"formula_id": "formula_68", "formula_text": "\u00b5 t+1 = A\u00b5 xt + b \u00b5 and \u03a3 t+1 = A\u03a3 xtxt A T + Q A\u03a3 xt \u03a3 T xt A T \u03a3 (74)", "formula_coordinates": [39.0, 143.58, 675.96, 387.89, 28.24]}, {"formula_id": "formula_69", "formula_text": "x l \u223c N \u22121 \uf8eb \uf8ec \uf8ec \uf8ec \uf8ed \u03a3 \u22121 xx \u00b5 x + E T S \u22121 (z \u2212 g) F T S \u22121 (z \u2212 g) \u03b7 , \u03a3 \u22121 xx + E T S \u22121 E E T S \u22121 F F T S \u22121 E F T S \u22121 F \u039b \uf8f6 \uf8f7 \uf8f7 \uf8f7 \uf8f8 (86)", "formula_coordinates": [41.0, 114.99, 124.56, 416.48, 62.76]}, {"formula_id": "formula_70", "formula_text": "\u03a3 = \u039b \u22121 = \u03a3 \u22121 xx + E T S \u22121 E E T S \u22121 F F T S \u22121 E F T S \u22121 F \u22121 = \u03a3 xx \u2212\u03a3 xx E T F \u2212T \u2212F \u22121 E\u03a3 xx F \u22121 (E\u03a3 xx E T + S)F \u2212T (87)", "formula_coordinates": [41.0, 72.67, 222.21, 458.8, 29.21]}, {"formula_id": "formula_71", "formula_text": "M = E F G H (88) then M \u22121 = (M/H) \u22121 \u2212(M/H) \u22121 F H \u22121 \u2212H \u22121 G(M/H) \u22121 H \u22121 + H \u22121 G(M/H) \u22121 F H \u22121 (89)", "formula_coordinates": [41.0, 63.49, 275.61, 467.98, 71.57]}, {"formula_id": "formula_72", "formula_text": "\u00b5 = \u039b \u22121 \u03b7 = \u03a3\u03b7 = \u03a3 xx \u2212\u03a3 xx E T F \u2212T \u2212F \u22121 E\u03a3 xx F \u22121 (E\u03a3 xx E T + S)F \u2212T \u03a3 \u22121 xx \u00b5 x + E T S \u22121 (z \u2212 g) F T S \u22121 (z \u2212 g) = \u03a3 xx \u03a3 \u22121 xx \u00b5 x + \u03a3 xx E T S \u22121 (z \u2212 g) \u2212 \u03a3 xx E T F \u2212T F T S \u22121 (z \u2212 g) \u2212F \u22121 E\u03a3 xx \u03a3 \u22121 xx \u00b5 x \u2212 F \u22121 E\u03a3 xx E T S \u22121 (z \u2212 g) + F \u22121 (E\u03a3 xx E T + S)F \u2212T F T S \u22121 (z \u2212 g) = \u00b5 x \u2212F \u22121 E\u00b5 x \u2212 F \u22121 E\u03a3 xx E T S \u22121 (z \u2212 g) + F \u22121 (E\u03a3 xx E T + S)S \u22121 (z \u2212 g) = \u00b5 x F \u22121 (z \u2212 g \u2212 E\u00b5 x )", "formula_coordinates": [41.0, 65.72, 399.23, 450.95, 136.22]}, {"formula_id": "formula_73", "formula_text": "E (x) = E (E (x | y)) (90) Cov (x, y) = Cov (E (x | y) , y)(91)", "formula_coordinates": [41.0, 219.64, 573.7, 311.76, 27.72]}, {"formula_id": "formula_74", "formula_text": "\u03a3 l = Cov ( , l) = Cov (E ( | l) , l) (92) = Cov (E (E ( | x) | l) , l) (93) = Cov E \u00b5 + \u03a3 x \u03a3 \u22121 xx (x \u2212 \u00b5 x ) | l , l (94) = Cov \u00b5 + \u03a3 x \u03a3 \u22121 xx (\u00b5 x + \u03a3 xl \u03a3 \u22121 ll (l \u2212 \u00b5 l ) \u2212 \u00b5 x ), l(95)", "formula_coordinates": [41.0, 133.04, 627.79, 398.44, 63.3]}, {"formula_id": "formula_75", "formula_text": "= Cov \u00b5 + \u03a3 x \u03a3 \u22121 xx \u03a3 xl \u03a3 \u22121 ll (l \u2212 \u00b5 l ), l (96) = \u03a3 x \u03a3 \u22121 xx \u03a3 xl \u03a3 \u22121 ll \u03a3 ll (97) = \u2212\u03a3 x (F \u22121 E) T (98", "formula_coordinates": [41.0, 214.24, 691.84, 317.23, 47.13]}, {"formula_id": "formula_76", "formula_text": ")", "formula_coordinates": [41.0, 526.94, 728.03, 4.54, 9.82]}, {"formula_id": "formula_77", "formula_text": "E = {x : (x \u2212 \u00b5) T \u03a3 \u22121 (x \u2212 \u00b5) \u2264 k} (99)", "formula_coordinates": [42.0, 205.97, 301.39, 325.45, 13.21]}, {"formula_id": "formula_78", "formula_text": "m = \uf8ee \uf8f0 x l \uf8f9 \uf8fb , \u03b7 = \uf8ee \uf8f0 \u03b7 x \u03b7 0 \uf8f9 \uf8fb , and \u039b = \uf8ee \uf8f0 \u039b xx \u039b x 0 \u039b x \u039b 0 0 0 0 \uf8f9 \uf8fb", "formula_coordinates": [44.0, 161.13, 281.08, 252.8, 41.31]}, {"formula_id": "formula_79", "formula_text": "\u03b7 z = \uf8ee \uf8f0 \u03b7 x + E T S \u22121 (z \u2212 g) \u03b7 F T S \u22121 (z \u2212 g) \uf8f9 \uf8fb", "formula_coordinates": [44.0, 190.52, 368.96, 154.4, 41.82]}, {"formula_id": "formula_80", "formula_text": "\u039b z = \uf8ee \uf8f0 \u039b xx + E T S \u22121 E \u039b x E T S \u22121 F \u039b x \u039b 0 F T S \u22121 E 0 F T S \u22121 F \uf8f9 \uf8fb (101)", "formula_coordinates": [44.0, 188.75, 413.59, 342.72, 41.83]}, {"formula_id": "formula_81", "formula_text": "\u03b7 m z = \u03b7 x + E T S \u22121 (z \u2212 g) \u2212 E T S \u22121 F (F T S \u22121 F ) \u22121 F T S \u22121 (z \u2212 g) \u03b7 (102) = \u03b7 x + E T S \u22121 (z \u2212 g) \u2212 E T S \u22121 F (F \u22121 RF \u2212T )F T S \u22121 (z \u2212 g) \u03b7 (103) = \u03b7 x + E T S \u22121 (z \u2212 g) \u2212 E T S \u22121 (z \u2212 g) \u03b7 = \u03b7 x \u03b7 l(104)", "formula_coordinates": [44.0, 127.62, 489.98, 403.85, 89.14]}, {"formula_id": "formula_82", "formula_text": "\u039b m z = \u039b xx + E T S \u22121 E \u2212 E T S \u22121 F (F T S \u22121 F ) \u22121 F T S \u22121 E \u039b x \u039b x \u039b (105) = \u039b xx + E T S \u22121 E \u2212 E T S \u22121 F (F \u22121 RF \u2212T )F T S \u22121 E \u039b x \u039b x \u039b (106) = \u039b xx + E T S \u22121 E \u2212 E T S \u22121 E \u039b x \u039b x \u039b = \u039b xx \u039b x \u039b x \u039b (107", "formula_coordinates": [44.0, 134.42, 610.54, 397.04, 89.14]}, {"formula_id": "formula_83", "formula_text": ")", "formula_coordinates": [44.0, 526.75, 681.99, 4.72, 9.82]}, {"formula_id": "formula_84", "formula_text": "H(u) = 1 2 log((2\u03c0e) k det Cov (u)) = k 2 log(2\u03c0e) \u2212 1 2 log det Cov (u) \u22121", "formula_coordinates": [46.0, 193.91, 131.92, 206.67, 52.2]}], "doi": ""}