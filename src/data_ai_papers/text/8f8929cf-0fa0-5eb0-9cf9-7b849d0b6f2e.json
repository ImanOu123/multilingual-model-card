{"title": "Applying Alternating Structure Optimization to Word Sense Disambiguation", "authors": "Rie Kubota Ando", "pub_date": "", "abstract": "This paper presents a new application of the recently proposed machine learning method Alternating Structure Optimization (ASO), to word sense disambiguation (WSD). Given a set of WSD problems and their respective labeled examples, we seek to improve overall performance on that set by using all the labeled examples (irrespective of target words) for the entire set in learning a disambiguator for each individual problem. Thus, in effect, on each individual problem (e.g., disambiguation of \"art\") we benefit from training examples for other problems (e.g., disambiguation of \"bar\", \"canal\", and so forth). We empirically study the effective use of ASO for this purpose in the multitask and semi-supervised learning configurations. Our performance results rival or exceed those of the previous best systems on several Senseval lexical sample task data sets.", "sections": [{"heading": "Introduction", "text": "Word sense disambiguation (WSD) is the task of assigning pre-defined senses to words occurring in some context. An example is to disambiguate an occurrence of \"bank\" between the \"money bank\" sense and the \"river bank\" sense. Previous studies e.g., (Lee and Ng, 2002;Florian and Yarowsky, 2002), have applied supervised learning techniques to WSD with success.\nA practical issue that arises in supervised WSD is the paucity of labeled examples (sense-annotated data) available for training. For example, the training set of the Senseval-2 1 English lexical sample One problem is that there are so many words and so many senses that it is hard to make available a sufficient number of labeled training examples for each of a large number of target words.\nOn the other hand, this indicates that the total number of available labeled examples (irrespective of target words) can be relatively large. A natural question to ask is whether we can effectively use all the labeled examples (irrespective of target words) for learning on each individual WSD problem.\nBased on these observations, we study a new application of Alternating Structure Optimization (ASO) (Ando and Zhang, 2005a;Ando and Zhang, 2005b) to WSD. ASO is a recently proposed machine learning method for learning predictive structure (i.e., information useful for predictions) shared by multiple prediction problems via joint empirical risk minimization. It has been shown that on several tasks, performance can be significantly improved by a semi-supervised application of ASO, which obtains useful information from unlabeled data by learning automatically created prediction problems. In addition to such semi-supervised learning, this paper explores ASO multi-task learning, which learns a number of WSD problems simultaneously to exploit the inherent predictive structure shared by these WSD problems. Thus, in effect, each individual problem (e.g., disambiguation of \"art\") benefits from labeled training examples for other problems (e.g., disambiguation of \"bar\", disambiguation of \"canal\", and so forth).\nThe notion of benefiting from training data for other word senses is not new by itself. For instance, been evaluated in the series of Senseval workshops.\non the WSD task with respect to WordNet synsets, Kohomban and Lee (2005) trained classifiers for the top-level synsets of the WordNet semantic hierarchy, consolidating labeled examples associated with the WordNet sub-trees. To disambiguate test instances, these coarse-grained classifiers are first applied, and then fine-grained senses are determined using a heuristic mapping. By contrast, our approach does not require pre-defined relations among senses such as the WordNet hierarchy. Rather, we let the machine learning algorithm ASO automatically and implicitly find relations with respect to the disambiguation problems (i.e., finding shared predictive structure). Interestingly, in our experiments, seemingly unrelated or only loosely related wordsense pairs help to improve performance.\nThis paper makes two contributions. First, we present a new application of ASO to WSD. We empirically study the effective use of ASO and show that labeled examples of all the words can be effectively exploited in learning each individual disambiguator. Second, we report performance results that rival or exceed the state-of-the-art systems on Senseval lexical sample tasks.", "publication_ref": ["b6", "b2", "b0", "b1", "b5"], "figure_ref": [], "table_ref": []}, {"heading": "Alternating structure optimization", "text": "This section gives a brief summary of ASO. We first introduce a standard linear prediction model for a single task and then extend it to a joint linear model used by ASO.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Standard linear prediction models", "text": "In the standard formulation of supervised learning, we seek a predictor that maps an input vector (or feature vector) \u00dc \u00be to the corresponding output \u00dd \u00be . For NLP tasks, binary features are often used -for example, if the word to the left is \"money\", set the corresponding entry of \u00dc to 1; otherwise, set it to 0. A -way classification problem can be cast as binary classification problems, regarding output \u00dd (1)\nA loss function \u00c4\u00b4\u00a1\u00b5 quantifies the difference between the prediction \u00b4 \u00b5 and the true output , and \u00d6\u00b4\u00a1\u00b5 is a regularization term to control the model complexity.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Joint linear models for ASO", "text": "Consider \u00d1 prediction problems indexed by \u00be \u00bd \u00d1 , each with \u00d2 samples\u00b4 \u00b5 for \u00be \u00bd \u00d2 , and assume that there exists a lowdimensional predictive structure shared by these \u00d1 problems. Ando and Zhang (2005a) extend the above traditional linear model to a joint linear model so that a predictor for problem is in the form:\n\u00b4\u00a2 \u00dc\u00b5 \u00db \u00cc \u00dc \u2022 \u00da \u00cc \u00a2\u00dc \u00a2\u00a2 \u00cc \u00c1 (2)\nwhere \u00c1 is the identity matrix. \u00db and \u00da are weight vectors specific to each problem . Predictive structure is parameterized by the structure matrix \u00a2 shared by all the \u00d1 predictors. The goal of this model can also be regarded as learning a common good feature map \u00a2\u00dc used for all the \u00d1 problems.", "publication_ref": ["b0"], "figure_ref": [], "table_ref": []}, {"heading": "ASO algorithm", "text": "Analogous to (1), we compute \u00a2 and predictors so that they minimize the empirical risk summed over all the problems:\n\u00a2 \u2104 \u00d6 \u00d1 \u00d2 \u00a2 \u00d1 \u00bd \u00d2 \u00bd \u00c4\u00b4 \u00b4\u00a2 \u00b5 \u00b5 \u00d2 \u2022 \u00d6\u00b4 \u00b5 (3)\nIt has been shown in (Ando and Zhang, 2005a)  \u00a2\u00d9 . That is, the structure matrix \u00a2 is computed so that the projection of the predictor matrix \u00cd onto the subspace spanned by \u00a2's rows gives the best approximation (in the least squares sense) of \u00cd for the given row-dimension of \u00a2. Thus, intuitively, \u00a2 captures the commonality of the \u00d1 predictors.\nASO has been shown to be useful in its semisupervised learning configuration, where the above algorithm is applied to a number of auxiliary problems that are automatically created from the unlabeled data. By contrast, the focus of this paper is the multi-task learning configuration, where the ASO algorithm is applied to a number of real problems with the goal of improving overall performance on these problems.", "publication_ref": ["b0"], "figure_ref": [], "table_ref": []}, {"heading": "Effective use of ASO on word sense disambiguation", "text": "The essence of ASO is to learn information useful for prediction (predictive structure) shared by multiple tasks, assuming the existence of such shared structure. From this viewpoint, consider the target words of the Senseval-2 lexical sample task, shown in Figure 1. Here we have multiple disambiguation tasks; however, at a first glance, it is not entirely clear whether these tasks share predictive structure (or are related to each other). There is no direct semantic relationship (such as synonym or hyponym relations) among these words.\nword uni-grams in 5-word window, Local word bi-and tri-grams of\u00b4\u00db \u00be \u00db \u00bd\u00b5,\ncontext\u00b4\u00db\u2022\u00bd \u00db\u2022\u00be\u00b5 \u00b4\u00db \u00bd \u00db\u2022\u00bd\u00b5, \u00db \u00bf \u00db \u00be \u00db \u00bd\u00b5 \u00b4\u00db\u2022\u00bd \u00db\u2022\u00be \u00db\u2022\u00bf\u00b5, \u00db \u00be \u00db \u00bd \u00db\u2022\u00bd\u00b5 \u00b4\u00db \u00bd \u00db\u2022\u00bd \u00db\u2022\u00be\u00b5.\nSyntactic full parser output; see Section 3 for detail. Global all the words excluding stopwords. POS uni-, bi-, and tri-grams in 5-word window. The goal of this section is to empirically study the effective use of ASO for improving overall performance on these seemingly unrelated disambiguation problems. Below we first describe the task setting, features, and algorithms used in our implementation, and then experiment with the Senseval-2 English lexical sample data set (with the official training / test split) for the development of our methods. We will then evaluate the methods developed on the Senseval-2 data set by carrying out the Senseval-3 tasks, i.e., training on the Senseval-3 training data and then evaluating the results on the (unseen) Senseval-3 test sets in Section 4.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Task setting", "text": "In this work, we focus on the Senseval lexical sample task. We are given a set of target words, each of which is associated with several possible senses, and their labeled instances for training. Each instance contains an occurrence of one of the target words and its surrounding words, typically a few sentences. The task is to assign a sense to each test instance.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Features", "text": "We adopt the feature design used by Lee and Ng (2002), which consists of the following four types: (1) Local context: \u00d2-grams of nearby words (position sensitive); (2) Global context: all the words (excluding stopwords) in the given context (position-insensitive; a bag of words); (3) POS: parts-of-speech \u00d2-grams of nearby words; (4) Syn-tactic relations: syntactic information obtained from parser output. To generate syntactic relation features, we use the Slot Grammar-based full parser ESG (McCord, 1990). We use as features syntactic relation types (e.g., subject-of, object-of, and noun modifier), participants of syntactic relations, and bigrams of syntactic relations / participants. Details of the other three types are shown in Figure 2. Implementation Our implementation follows Ando and Zhang (2005a). We use a modification of the Huber's robust loss for regression:\n\u00c4\u00b4\u00d4 \u00dd\u00b5 \u00b4\u00d1 \u00dc\u00b4\u00bc \u00bd \u00d4\u00dd\u00b5\u00b5 \u00be if \u00d4\u00dd \u00bd; and \u00d4\u00dd otherwise; with square regularization ( \u00bd\u00bc ), and perform empirical risk minimization by stochastic gradient descent (SGD) (see e.g., Zhang (2004)). We perform one ASO iteration.", "publication_ref": ["b6", "b7", "b0", "b11"], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "Exploring the multi-task learning configuration", "text": "The goal is to effectively apply ASO to the set of word disambiguation problems so that overall performance is improved. We consider two factors: feature split and partitioning of prediction problems.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Feature split and problem partitioning", "text": "Our features described above inherently consist of four feature groups: local context (\u00c4 ), global context (\n), syntactic relation (\u00cb\u00ca), and POS features. To exploit such a natural feature split, we explore the following extension of the joint linear model:\n\u00b4 \u00a2 \u00dc\u00b5 \u00db \u00cc \u00dc \u2022 \u00be \u00da\u00b4 \u00b5 \u00cc \u00a2 \u00dc\u00b4 \u00b5 (5)\nwhere \u00a2 \u00a2 \u00cc \u00c1 for \u00be , is a set of disjoint feature groups, and \u00dc\u00b4 \u00b5 (or \u00da\u00b4 \u00b5 ) is a portion of the feature vector \u00dc (or the weight vector \u00da ) corresponding to the feature group , respectively. This is a slight modification of the extension presented in (Ando and Zhang, 2005a). Using this model, ASO computes the structure matrix \u00a2 for each feature group separately. That is, SVD is applied to the sub-matrix of the predictor (weight) matrix corresponding to each feature group , which results in more focused dimension reduction of the predictor matrix. For example, suppose that \u00cb\u00ca . Then, we compute the structure matrix \u00a2 \u00cb\u00ca from the corresponding sub-matrix of the predictor matrix \u00cd, which is the gray region of Figure 3 (a). The structure matrices \u00a2 for \u00be (associated with the white regions in the figure) should be regarded as being fixed to the zero matrices. Similarly, it is possible to compute a structure matrix from a subset of the predictors (such as noun disambiguators only), as in Figure 3   To see why such partitioning may be useful for our WSD problems, consider the disambiguation of \"bank\" and the disambiguation of \"save\". Since a \"bank\" as in \"money bank\" and a \"save\" as in \"saving money\" may occur in similar global contexts, certain global context features effective for recognizing the \"money bank\" sense may be also effective for disambiguating \"save\", and vice versa. However, with respect to the position-sensitive local context features, these two disambiguation problems may not have much in common since, for instance, we sometimes say \"the bank announced\", but we rarely say \"the save announced\". That is, whether problems share predictive structure may depend on feature types, and in that case, seeking predictive structure for each feature group separately may be more effective. Hence, we experiment with the configurations with and without various feature splits using the extension of ASO.\nOur target words are nouns, verbs, and adjectives. As in the above example of \"bank\" (noun) and \"save\" (verb), the predictive structure of global context features may be shared by the problems irrespective of the parts of speech of the target words. However, the other types of features may be more dependent on the target word part of speech. There-fore, we explore two types of configuration. One applies ASO to all the disambiguation problems at once. The other applies ASO separately to each of the three sets of disambiguation problems (noun disambiguation problems, verb disambiguation problems, and adjective disambiguation problems) and uses the structure matrix \u00a2 obtained from the noun disambiguation problems only for disambiguating nouns, and so forth.\nThus, we explore combinations of two parameters. One is the set of feature groups in the model ( 5). The other is the partitioning of disambiguation problems. In Figure 4, we compare performance on the Senseval-2 test set produced by training on the Senseval-2 training set using the various configurations discussed above. As the evaluation metric, we use the F-measure (micro-averaged) 3 returned by the official Senseval scorer. Our baseline is the standard single-task configuration using the same loss function (modified Huber) and the same training algorithm (SGD).", "publication_ref": ["b0"], "figure_ref": ["fig_2", "fig_2"], "table_ref": []}, {"heading": "Empirical results", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "64", "text": "The results are in line with our expectation. To learn the shared predictive structure of local context (LC) and syntactic relations (SR), it is more advantageous to apply ASO to each of the three sets of problems (disambiguation of nouns, verbs, and adjectives, respectively), separately. By contrast, global context features (GC) can be more effectively exploited when ASO is applied to all the disambigua-3 Our precision and recall are always the same since our systems assign exactly one sense to each instance. That is, our F-measure is the same as 'micro-averaged recall' or 'accuracy' used in some of previous studies we will compare with. tion problems at once. It turned out that the configuration \u00c8\u00c7\u00cb does not improve the performance over the baseline. Therefore, we exclude POS from the feature group set in the rest of our experiments. Comparison of", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "\u00c4 \u2022\u00cb\u00ca\u2022", "text": "(treating the features of these three types as one group) and \u00c4 \u00cb\u00ca indicates that use of this feature split indeed improves performance. Among the configurations shown in Figure 4, the best performance (67.8%) is obtained by applying ASO to the three sets of problems (corresponding to nouns, verbs, and adjectives) separately, with the feature split \u00c4 \u00cb\u00ca . ASO has one parameter, the dimensionality of the structure matrix \u00a2 (i.e., the number of left singular vectors to compute). The performance shown in Figure 4 is the ceiling performance obtained at the best dimensionality (in \u00bd\u00bc \u00be \u00bc \u00bd\u00bc\u00bc \u00bd \u00bc \u00a1 \u00a1 \u00a1 ). In Figure 5, we show the performance dependency on \u00a2 's dimensionality when ASO is applied to all the problems at once (Figure 5 left), and when ASO is applied to the set of the noun disambiguation problems (Figure 5 right). In the left figure, the configuration (global context) produces better performance at a relatively low dimensionality. In the other configurations shown in these two figures, performance is relatively stable as long as the dimensionality is not too low. ", "publication_ref": [], "figure_ref": ["fig_3", "fig_3", "fig_3"], "table_ref": []}, {"heading": "Multi-task learning procedure for WSD", "text": "Based on the above results on the Senseval-2 test set, we develop the following procedure using the feature split and problem partitioning shown in Figure 6. Let AE \u00ce, and be sets of disambiguation problems whose target words are nouns, verbs, and adjectives, respectively. We write \u00a2\u00b4 \u00d7\u00b5 for the struc-predictors for nouns predictors for verbs predictors for adjectives", "publication_ref": [], "figure_ref": ["fig_4"], "table_ref": []}, {"heading": "LC GC SR POS", "text": "We compute seven structure matrices \u0398 j,s each from the seven shaded regions of the predictor matrix U. ture matrix associated with the feature group and computed from a problem set \u00d7. That is, we replace \u00a2 in (5) with \u00a2\u00b4 \u00d7\u00b5 .\nApply ASO to the three sets of disambiguation problems (corresponding to nouns, verbs, and adjectives), separately, using the extended model ( 5 where \u00cc \u00b4\u00c4 \u00c8 \u00b5 \u00b4\u00cb\u00ca \u00c8 \u00b5 \u00b4 AE \u00ce \u00b5 . We obtain predictor by minimizing the regularized empirical risk with respect to \u00db and \u00da .\nWe fix the dimension of the structure matrix corresponding to global context features to 50. The dimensions of the other structure matrices are set to 0.9 times the maximum possible rank to ensure relatively high dimensionality. This procedure produces \u00bd\u00b1 on the Senseval-2 English lexical sample test set.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Previous systems on Senseval-2 data set", "text": "Figure 7 compares our performance with those of previous best systems on the Senseval-2 English lexical sample test set. Since we used this test set for the development of our method above, our performance should be understood as the potential performance. (In Section 4, we will present evaluation results on  (Wu et al., 2004), LN02 (Lee and Ng, 2002) the unseen Senseval-3 test sets.) Nevertheless, it is worth noting that our potential performance (68.1%) exceeds those of the previous best systems.\nOur single-task baseline performance is almost the same as LN02 (Lee and Ng, 2002), which uses SVM. This is consistent with the fact that we adopted LN02's feature design. FY02 (Florian and Yarowsky, 2002) combines classifiers by linear average stacking. The best system of the Senseval-2 competition was an early version of FY02. WSC04 used a polynomial kernel via the kernel Principal Component Analysis (KPCA) method (Sch\u00f6lkopf et al., 1998) with nearest neighbor classifiers.", "publication_ref": ["b10", "b6", "b6", "b2", "b8"], "figure_ref": [], "table_ref": []}, {"heading": "Evaluation on Senseval-3 tasks", "text": "In this section, we evaluate the methods developed on the Senseval-2 data set above on the standard Senseval-3 lexical sample tasks.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Our methods in multi-task and semi-supervised configurations", "text": "In addition to the multi-task configuration described in Section 3.2, we test the following semi-supervised application of ASO. We first create auxiliary problems following Ando and Zhang (2005a)'s partiallysupervised strategy (Figure 8) with distinct feature maps \u00a9 \u00bd and \u00a9 \u00be each of which uses one of \u00c4 \u00cb\u00ca . Then, we apply ASO to these auxiliary problems using the feature split and the problem partitioning described in Section 3.2. Note that the difference between the multi-task and semi-supervised configurations is the source of information. The multi-task configuration utilizes the label information of the training examples that are labeled for the rest of the multiple tasks, and the semi-supervised learning configuration exploits a large amount of unlabeled data.\n1. Train a classifier \u00bd only using feature map \u00a9\u00bd on the labeled data for the target task. 2. Auxiliary problems are to predict the labels assigned by \u00bd to the unlabeled data, using the other feature map \u00a9\u00be. 3. Apply ASO to the auxiliary problems to obtain \u00a2.  ", "publication_ref": [], "figure_ref": ["fig_6"], "table_ref": []}, {"heading": "Data and evaluation metric", "text": "We conduct evaluations on four Senseval-3 lexical sample tasks (English, Catalan, Italian, and Spanish) using the official training / test splits. Data statistics are shown in Figure 9. On the Spanish, Catalan, and Italian data sets, we use part-of-speech information (as features) and unlabeled examples (for semi-supervised learning) provided by the organizer. Since the English data set was not provided with these additional resources, we use an in-house POS tagger trained with the PennTree Bank corpus, and extract 100K unlabeled examples from the Reuters-RCV1 corpus. On each language, the number of unlabeled examples is 5-15 times larger than that of the labeled training examples. We use syntactic relation features only for English data set. As in Section 3, we report micro-averaged F measure.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Baseline methods", "text": "In addition to the standard single-task supervised configuration as in Section 3, we test the following method as an additional baseline.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Output-based method", "text": "The goal of our multi-task learning configuration is to benefit from having the labeled training examples of a number of words. An alternative to ASO for this purpose is to use directly as features the output values of classifiers trained for disambiguating the other words, which we call 'output-based method' (cf. Florian et al. (2003)). We explore several variations similarly to Section 3.1 and report the ceiling performance.", "publication_ref": ["b3"], "figure_ref": [], "table_ref": []}, {"heading": "Evaluation results", "text": "Figure 10 shows F-measure results on the four Senseval-3 data sets using the official training / test splits. Both ASO multi-task learning and semisupervised learning improve performance over the single-task baseline on all the data sets. The best performance is achieved when we combine multitask learning and semi-supervised learning by using all the corresponding structure matrices \u00a2\u00b4 \u00d7\u00b5 produced by both multi-task and semi-supervised learning, in the final predictors. This combined configuration outperforms the single-task supervised baseline by up to 5.7%. Performance improvements over the supervised baseline are relatively small on English and Spanish. We conjecture that this is because the supervised performance is already close to the highest performance that automatic methods could achieve. On these two languages, our (and previous) systems outperform inter-human agreement, which is unusual but can be regarded as an indication that these tasks are difficult.\nThe performance of the output-based method (baseline) is relatively low. This indicates that output values or proposed labels are not expressive enough to integrate information from other predictors effectively on this task. We conjecture that for this method to be effective, the problems are required to be more closely related to each other as in Florian et al. (2003)'s named entity experiments.\nA practical advantage of ASO multi-task learning over ASO semi-supervised learning is that shorter computation time is required to produce similar performance. On this English data set, training for multi-task learning and semi-supervised learning takes 15 minutes and 92 minutes, respectively, using a Pentium-4 3.20GHz computer. The computation time mostly depends on the amount of the data on which auxiliary predictors are learned. Since our experiments use unlabeled data 5-15 times larger than labeled training data, semi-supervised learning takes longer, accordingly.  GGS05 combined various kernels, which includes the LSA kernel that exploits unlabeled data with global context features. Our implementation of the LSA kernel with our classifier (and our other features) also produced performance similar to that of GGS05. While the LSA kernel is closely related to a special case of the semi-supervised application of ASO (see the discussion of PCA in Ando and Zhang (2005a)), our approach here is more general in that we exploit not only unlabeled data and global context features but also the labeled examples of other target words and other types of features. G04 achieved high performance on English using regularized least squares with compensation for skewed class distributions. SGG04 is an early version of GGS05. Our methods rival or exceed these stateof-the-art systems on all the data sets.", "publication_ref": ["b3"], "figure_ref": ["fig_7"], "table_ref": []}, {"heading": "Conclusion", "text": "With the goal of achieving higher WSD performance by exploiting all the currently available resources, our focus was the new application of the ASO algorithm in the multi-task learning configuration, which improves performance by learning a number of WSD problems simultaneously instead of training for each individual problem independently.\nA key finding is that using ASO with appropriate feature / problem partitioning, labeled examples of seemingly unrelated words can be effectively exploited. Combining ASO multi-task learning with ASO semi-supervised learning results in further improvements. The fact that performance improvements were obtained consistently across several languages / sense inventories demonstrates that our approach has broad applicability and hence practical significance.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "A framework for learning predictive structures from multiple tasks and unlabeled data", "journal": "", "year": "2004", "authors": "Rie Kubota; Ando ; Tong Zhang"}, {"ref_id": "b1", "title": "High performance semi-supervised learning for text chunking", "journal": "", "year": "2005", "authors": "Rie Kubota; Ando ; Tong Zhang"}, {"ref_id": "b2", "title": "Modeling consensus: Classifier combination for word sense disambiguation", "journal": "", "year": "2002", "authors": "Radu Florian; David Yarowsky"}, {"ref_id": "b3", "title": "Named entity recognition through classifier combination", "journal": "", "year": "2003", "authors": "Radu Florian; Abe Ittycheriah; Hongyan Jing; Tong Zhang"}, {"ref_id": "b4", "title": "Finding optimal parameter settings for high performance word sense diambiguation", "journal": "", "year": "2004", "authors": "Cristian Grozea"}, {"ref_id": "b5", "title": "Learning semantic classes for word sense disambiguation", "journal": "", "year": "2005", "authors": "S Upali; Wee Kohomban;  Sun Lee"}, {"ref_id": "b6", "title": "An empirical evaluation of knowledge sources and learning algorithms for word sense disambiguation", "journal": "", "year": "2002", "authors": "Yoong Keok Lee; Hwee Tou Ng"}, {"ref_id": "b7", "title": "Slot Grammar: A system for simpler construction of practical natural language grammars. Natural Language and Logic: International Scientific Symposium", "journal": "", "year": "1990", "authors": "C Michael;  Mccord"}, {"ref_id": "b8", "title": "Nonlinear component analysis as a kernel eigenvalue problem", "journal": "Neural Computation", "year": "1998", "authors": "Bernhard Sch\u00f6lkopf; Alexander Smola; Klaus-Rober M\u00fcller"}, {"ref_id": "b9", "title": "Pattern abstraction and term similarity for word sense disambiguation: IRST at Senseval-3", "journal": "", "year": "2004", "authors": "Carlo Strapparava; Alfio Gliozzo; Claudio Giuliano"}, {"ref_id": "b10", "title": "A kernel PCA method for superior word sense disambiguation", "journal": "", "year": "2004", "authors": "Dekai Wu; Weifeng Su; Marine Carpuat"}, {"ref_id": "b11", "title": "Solving large scale linear prediction problems using stochastic gradient descent algorithms", "journal": "", "year": "2004", "authors": "Tong Zhang"}], "figures": [{"figure_label": "", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "1 http://www.cs.unt.edu/ rada/senseval/. WSD systems have task has only 10 labeled training examples per sense on average, which is in contrast to nearly 6K training examples per name class (on average) used for the CoNLL-2003 named entity chunking shared task 2 .", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 2 :2Figure 2: Features. \u00db stands for the word at position relative to the word to be disambiguated. The 5-word window is \u00be \u2022\u00be\u2104. Local context and POS features are positionsensitive. Global context features are position insensitive (a bag of words).", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 3 :3Figure 3: Examples of feature split and problem partitioning.", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 5 :5Figure 5: Left: Applying ASO to all the WSD problems at once. Right: Applying ASO to noun disambiguation problems only and testing on the noun disambiguation problems only. \u00dcaxis: dimensionality of \u00a2 .", "figure_data": ""}, {"figure_label": "6", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 6 :6Figure 6: Effective feature split and problem partitioning.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "4.Using the joint linear model (2), train the final predictor by minimizing the empirical risk for fixed \u00a2 on the labeled data for the target task.", "figure_data": ""}, {"figure_label": "8", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Figure 8 :8Figure 8: Ando and Zhang (2005a)'s ASO semi-supervised learning method using partially-supervised procedure for creating relevant auxiliary problems.", "figure_data": ""}, {"figure_label": "10", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "Figure 10 :10Figure 10: Performance results on the Senseval-3 lexical sample test sets. Numbers in the parentheses are performance gains compared with the single-task supervised baseline (italicized). [G04] Grozea (2004); [SGG04] Strapparava et al. (2004).", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_1", "figure_caption": ", bar, bum, chair, channel, child, church, circuit, day, detention, dyke, facility, fatigue, feeling,  grip, hearth, holiday, lady, material, mouth, nation, nature, post, restraint, sense, spade, stress, yew Verbs begin, call, carry, collaborate, develop, draw, dress, drift, drive, face, ferret, find, keep, leave, live, match, play, pull, replace, see, serve strike, train, treat, turn, use, wander wash, work Adjectives blind, colourless, cool, faithful, fine, fit, free, graceful, green, local, natural, oblique, simple, solemn, vital Figure 1: Words to be disambiguated; Senseval-2 English lexical sample task. 1. Fix\u00b4\u00a2 \u00da \u00b5, and find \u00d1 predictors \u00d9 that", "figure_data": "Nouns art, authorityminimizes the joint empirical risk (4).2. Fix \u00d1 predictors \u00d9 , and find\u00b4\u00a2 \u00da \u00b5 thatminimizes the joint empirical risk (4).The first step is equivalent to training \u00d1 predictorsindependently. The second step, which couples allthe predictors, can be done by setting the rows of \u00a2 to the most significant left singular vectors of the predictor (weight) matrix \u00cd \u00d9 \u00bd \u00d9 \u00d1 \u2104, andsetting \u00dathatthe optimization problem (3) has a simple solutionusing singular value decomposition (SVD) when we choose square regularization: \u00d6\u00b4 \u00b5 \u00db \u00be \u00be where is a regularization parameter. Let \u00d9 \u00db \u2022 \u00a2 \u00cc \u00da Then (3) becomes the minimization of the joint empirical risk written as:\u00d1 \u00bd\u00d2\u00bd\u00c4\u00b4\u00d9 \u00cc\u00d2\u00b5\u2022 \u00d9 \u00a2 \u00cc \u00da \u00be \u00be(4)This minimization can be approximately solved byrepeating the following alternating optimization pro-cedure until a convergence criterion is met:"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "(b). In this example, we apply the extension of ASO with \u00cb\u00ca to three sets of problems (disambiguation of nouns, verbs, and adjectives, respectively) separately.", "figure_data": "m predictorspredictors for nounspredictors for verbspredictors for adjectivesLCGC SR\u0398 \u0398 \u0398 \u0398 SR\u0398 \u0398 \u0398 \u0398 SR,AdjPOS\u0398 \u0398 \u0398 \u0398 SR,Verb(a) Partitioned by features:\u0398 \u0398 \u0398 \u0398 SR,NounF = { SR }"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_7", "figure_caption": "+0.8) 89.5 (+1.5) 63.2 (+4.9) 89.0 (+1.0) ASO semi-supervised learning 73.5 (+0.5) 88.6 (+0.6) 62.4 (+4.1) 88.9 (+0.9) multi-task+semi-supervised", "figure_data": "methodsEnglishCatalanItalianSpanishmulti-task learning73.8 (74.1 (+1.1) 89.9 (+1.9) 64.0 (+5.7) 89.5 (+1.5)baselines output-based73.0 (0.0)88.3 (+0.3) 58.0 (-0.3)88.2 (+0.2)single-task supervised learning73.088.058.388.0previous SVM with LSA kernel [GGS05] 73.389.061.388.2systemsSenseval-3 (2004) best systems72.9 [G04]85.2 [SGG04] 53.1 [SGG04] 84.2 [SGG04]inter-annotator agreement67.393.189.085.3"}], "formulas": [{"formula_id": "formula_0", "formula_text": "\u00b4\u00a2 \u00dc\u00b5 \u00db \u00cc \u00dc \u2022 \u00da \u00cc \u00a2\u00dc \u00a2\u00a2 \u00cc \u00c1 (2)", "formula_coordinates": [2.0, 336.84, 316.49, 203.07, 17.04]}, {"formula_id": "formula_1", "formula_text": "\u00a2 \u2104 \u00d6 \u00d1 \u00d2 \u00a2 \u00d1 \u00bd \u00d2 \u00bd \u00c4\u00b4 \u00b4\u00a2 \u00b5 \u00b5 \u00d2 \u2022 \u00d6\u00b4 \u00b5 (3)", "formula_coordinates": [2.0, 315.72, 499.67, 224.27, 38.07]}, {"formula_id": "formula_2", "formula_text": "context\u00b4\u00db\u2022\u00bd \u00db\u2022\u00be\u00b5 \u00b4\u00db \u00bd \u00db\u2022\u00bd\u00b5, \u00db \u00bf \u00db \u00be \u00db \u00bd\u00b5 \u00b4\u00db\u2022\u00bd \u00db\u2022\u00be \u00db\u2022\u00bf\u00b5, \u00db \u00be \u00db \u00bd \u00db\u2022\u00bd\u00b5 \u00b4\u00db \u00bd \u00db\u2022\u00bd \u00db\u2022\u00be\u00b5.", "formula_coordinates": [3.0, 331.92, 165.95, 264.95, 34.5]}, {"formula_id": "formula_3", "formula_text": "\u00b4 \u00a2 \u00dc\u00b5 \u00db \u00cc \u00dc \u2022 \u00be \u00da\u00b4 \u00b5 \u00cc \u00a2 \u00dc\u00b4 \u00b5 (5)", "formula_coordinates": [4.0, 93.84, 488.09, 204.87, 29.28]}], "doi": ""}