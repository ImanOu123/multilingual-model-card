{"title": "Variational manifold learning from incomplete data: application to multislice dynamic MRI", "authors": "Qing Zou; Abdul Haseeb Ahmed; Sarv Nagpal; Rolf F Priya; Mathews Schulte;  Jacob; Mathews Jacob; Rolf F Schulte", "pub_date": "2021-12-10", "abstract": "Current deep learning-based manifold learning algorithms such as the variational autoencoder (VAE) require fully sampled data to learn the probability density of real-world datasets. Once learned, the density can be used for a variety of tasks, including data imputation. However, fully sampled data is often unavailable in a variety of problems, including the recovery of dynamic and high-resolution MRI data considered in this work. To overcome this problem, we introduce a novel variational approach to learn a manifold from undersampled data. The VAE uses a decoder fed by latent vectors, drawn from a conditional density estimated from the fully sampled images using an encoder. Since fully sampled images are not available in our setting, we approximate the conditional density of the latent vectors by a parametric model whose parameters are estimated from the undersampled measurements using back-propagation. We use the framework for the joint alignment and recovery of multislice free breathing and ungated cardiac MRI data from highly undersampled measurements. Most of the current self-gating and manifold cardiac MRI approaches consider the independent recovery of images from each slice; these methods are not capable of exploiting the inter-slice redundancies in the datasets and require sophisticated post-processing or manual approaches to align the images from different slices. By contrast, the proposed scheme is able to align the multislice data and exploit the redundancies. Experimental results demonstrate the utility of the proposed scheme in dynamic imaging alignment and reconstructions.", "sections": [{"heading": "I. INTRODUCTION", "text": "D EEP generative models [1] that rely on convolutional neural networks (CNNs) are now widely used to represent data living on nonlinear manifolds. For instance, the variational autoencoder (VAE) [2] represents the data points as CNN mappings of the latent vectors, whose parameters are learned using the maximum likelihood formulation. Since the exact log-likelihood of the data points is intractable, VAE relies on the maximization of a lower bound of the likelihood, involving an approximation for the conditional density of the latent variable represented by an encoder neural network. The VAE framework offers several benefits over the vanilla autoencoder [1], including improved generalization [3] and ability to disentangle the important latent factors [4], [5]. Unfortunately, most of the current generative models are learned from fully sampled datasets. Once learned, the probability density of the data can be used as a prior for various applications, including data imputation [6], [7]. Unfortunately, fully-sampled datasets are often not available in many high-resolution structural and dynamic imaging applications to train autoencoder networks.\nThe main focus of this paper is to introduce a variational framework to learn a deep generative manifold directly from undersampled/incomplete measurements. The main application motivating this work is the multislice free-breathing and ungated cardiac MRI. Breath-held CINE imaging, which provides valuable indicators of abnormal structure and function, is an integral part of cardiac MRI exams. Compressed sensing [8]- [11] and deep learning methods have emerged as powerful options to reduce the breath-hold duration, with excellent performance [12]- [16]. Despite these advances, breath-held CINE imaging is challenging for several subject groups, including pediatric and chronic obstructive pulmonary disease (COPD) subjects. Several authors have introduced self-gating [17]- [22] and manifold approaches [23]- [27] to enable freebreathing and ungated single-slice cardiac MRI. For instance, the smoothness regularization on manifolds (SToRM) approach [28]- [30] models the images as points on a lowdimensional manifold whose structure is exploited using a kernel low-rank formulation [29], [30] to recover the images from highly undersampled measurements. Recently, deep learning-based manifold models were introduced [31]- [33] to further improve the performance; these schemes learn a deep generative network and its latent variables directly from the measured k-space data using a non-probabilistic formulation.\nAll of the previously described free-breathing cardiac MRI reconstruction approaches (e.g., compressed sensing-based approaches, manifold approaches, and deep learning-based approaches) independently recover the data from each slice. Cardiac MRI often relies on slice-by-slice acquisition to preserve myocardium to blood pool contrast, resulting from the in-flow of blood from unexcited regions to the slice of interest; the improved contrast facilitates segmentation. The above-mentioned 2D self-gating and manifold methods are thus unable to exploit the extensive redundancies between adjacent slices, which could offer improved performance. Note that the respiratory and cardiac motion during the acquisition of the different slices is often very different; this makes the direct 3D extension of the 2D self-gating and manifold methods impossible. Another challenge with the approaches mentioned above is the need for post-processing methods to determine matching slices at specific cardiac/respiratory phases for estimation of cardiac parameters (e.g., ejection fraction, strain). Several post-processing methods have been introduced to align the data post reconstruction [24], [34]- [37]. Because these methods require fully sampled data, they will not facilitate the exploitation of the inter-slice redundancies during image recovery.\nWe introduce a novel variational framework for the joint recovery and alignment of multislice data from the entire heart. This approach combines the undersampled k-t space data from different slices, possibly acquired with multiple cardiac and respiratory motion patterns, to recover the 3D dynamic MRI dataset. We use a 3D CNN generative model, which takes in a latent vector and outputs a 3D image volume. The time-varying latent vectors capture the intrinsic variability in the dataset, including cardiac and respiratory motion. The latent variables and the parameters of the 3D CNN are jointly learned from the multislice k-t space data using a maximum likelihood formulation. Since the likelihood is not tractable, we maximize its variational lower bound involving a model for the conditional distribution of the latent variables, which is conceptually similar to the VAE approach [2]. The VAE scheme uses an encoder network to derive the conditional probabilities of the latent vectors from fully sampled data [2]. This approach is not directly applicable in our setting because each data sample is measured using a different measurement operator. We hence model the conditional densities as a Gaussian distribution whose parameters are learned from the undersampled data directly using back-propagation. We use a Gaussian prior on the latent variables while deriving the evidence-based lower bound (ELBO); the Gaussian prior ensures that the latent variables from different slices have similar distributions, facilitating the alignment of the slices. We note that the direct extension of our previous generative manifold model [31], [32] to the 3D setting does not have any constraint on the latent variables; this extension results in poor alignment of the slices and degradation in image quality in the 3D setting. We also use smoothness priors on the latent variables to further improve the performance. Once learned, the representation can be used to generate matching 3D volumes with any desired cardiac/respiratory phase by exciting the generator with appropriate latent vectors. This approach of learning a generative model of the entire heart may thus be viewed as a paradigm shift from conventional slice-by-slice image-recovery algorithms [17]- [30].", "publication_ref": ["b0", "b1", "b0", "b2", "b3", "b4", "b5", "b6", "b7", "b10", "b11", "b15", "b16", "b21", "b22", "b26", "b27", "b29", "b28", "b29", "b30", "b32", "b23", "b33", "b36", "b1", "b1", "b30", "b31", "b16", "b29"], "figure_ref": [], "table_ref": []}, {"heading": "II. BACKGROUND ON DYNAMIC MRI A. multislice free-breathing MRI: problem statement", "text": "The main application considered in this paper is the recovery of 3D cardiac volumes of the heart from undersampled 2D multislice k-t space data acquired in the free-breathing and ungated setting. In particular, we consider the recovery of the time series x(r, t z ), where r = (x, y, z) represents the spatial coordinates and t z denotes the time frame during the acquisition of the z th slice. We model the acquisition of the data as\nb(t z ) = A tz x(r, t z ) + n tz ,(1)\nwhere b(t z ) is the k-t space data of the z th slice at the t th time frame. Here, A tz are the time-dependent measurement operators, which evaluate the multi-channel single-slice Fourier measurements of the 3D volume x(r, t z ) on the trajectory k tz corresponding to the time point t. Specifically, A tz extracts the z th slice from the volume x(r, t z ) and evaluates its single-slice measurements. n tz represents the noise in the measurements.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B. CNN-based generative manifold models in dynamic MRI", "text": "CNN-based generative models were recently introduced for single-slice dynamic MRI [31]. This scheme models the 2-D images in the time series as the output of a CNN generator D \u03b8 :\nx\ni = D \u03b8 (c i ), i = 1, \u2022 \u2022 \u2022 , M.\nThe input c i is the latent vector, which lives in a lowdimensional subspace. The recovery of the images in the time series involves the minimization of the criterion\nC(c, \u03b8) = N i=1 A i (D \u03b8 (c i )) \u2212 b i 2 data term + \u03bb 1 J c D \u03b8 (c) 2 net reg. +\u03bb 2 \u2207 i c i 2 latent reg. .(2)\nThe first term in the cost function is a measure of data consistency, while the second term is a network regularization term that controls the smoothness of the generated manifold [31]. The last term is the temporal smoothness of the latent variables, which is used to further improve the performance.", "publication_ref": ["b30", "b30"], "figure_ref": [], "table_ref": []}, {"heading": "III. VARIATIONAL MANIFOLD LEARNING", "text": "We now introduce a novel variational formulation to learn a manifold from undersampled measurements, which is the generalization of the seminal VAE approach [2] to the undersampled setting. We will first present the proposed approach in a simple and general setting for simplicity and ease of understanding. The use of this variational manifold model for the joint alignment and recovery of 3D images from 2-D multislice MRI data will be described in Section IV.", "publication_ref": ["b1"], "figure_ref": [], "table_ref": []}, {"heading": "A. General problem statement and intuition", "text": "We assume that the images in the time series, indexed by i, live on a smooth manifold M and hence can be modeled as the output of a CNN-based generator:\nx i = D \u03b8 (c i ),(3)\nwhere c i is the low-dimensional latent variable corresponding to x i . Here, \u03b8 denotes the weights of the generator, which is shared for all the images. Most generative models consider the learning of the above model from fully sampled data. By contrast, we consider the recovery from incomplete measurements\nb i = A i (x i ) + n i .(4)\nHere, A i is an undersampled measurement operator corresponding to the i th image frame. Here, n i \u2208 N (0, \u03c3 2 I) are noise vectors. Note that the measurement operators for each x i are different. If the same sampling operators are used for all the data points, it is impossible to recover the images without additional prior information. We assume that the sampling operators satisfy the following properties: 1) We assume A i to be a rectangular sub-matrix, obtained by picking specific rows of an orthonormal measurement operator (e.g., Fourier transform). 2) We assume that the measurement operators A \u223c S are drawn from a distribution and satisfy\nE A\u223cS [A T A] = I,(5)\nwhich is the identity operator. The above condition guarantees diversity in the measurement operators. We now provide some intuition about why the learning of the model with the above settings will succeed under the restrictive assumptions on the measurement operators described above. In the noiseless setting, we consider the learning of the latent variables c i and the weights \u03b8 by minimizing the empirical error:\n{\u03b8 * , c * i } = arg min \u03b8,ci i A i (x i \u2212 D \u03b8 (c i )) 2 L .(6)\nHere, x i are the fully sampled data points. When A \u223c S, this empirical sum approximates\nL \u2248 E x\u223cM E A\u223cS A (x \u2212 D \u03b8 (c)) 2 = E x\u223cM E A\u223cS x \u2212 D \u03b8 (c), A H A (x \u2212 D \u03b8 (c)) = E x\u223cM x \u2212 D \u03b8 (c), E A\u223cS [A H A] I (x \u2212 D \u03b8 (c)) = arg min \u03b8,c E x\u223cM x \u2212 D \u03b8 (c) 2 .\nThe above result follows from ( 5) and the orthonormality of the full measurement operator. This result shows that the recovery of the true manifold is feasible from undersampled data when the sampling operators satisfy the properties listed above.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B. Proposed algorithm", "text": "We consider the recovery of the images x i from their measurements (4) by maximizing their likelihood, specified by\np(b i ) = p(b i , c i ) p(c i |b i )(7)\nWe note that the posterior p(c i |b i ) is not tractable. Following the VAE approach in [2], we use a surrogate distribution to approximate p(c i |b i ). The VAE formulation uses an encoder network to model p(c i |x i ) from the fully sampled data (b i = x i ). Unfortunately, this approach is not directly applicable in our setting since b i is the undersampled data, measured using A i that vary with i.\nWe propose to use a Gaussian model q i (c i ) \u2248 p(c i |b i ), parameterized by its mean \u00b5 i and diagonal covariance matrix \u03a3 i , and to estimate these parameters using back-propagation.\nFollowing a similar argument as in [2], we show in the Appendix that the likelihood term in ( 7) can be lower-bounded as\nlog p(b i ) \u2265 \u2212 1 2\u03c3 2 E ci\u223cqi(ci) A i D \u03b8 (c i ) \u2212 b i 2 data term \u2212 KL[q i (c i )||p(c i )] L(qi):latent regularization .(8)\nHere, p(c i ) is a prior on the latent variables. In this work, we assume p(c i ) = N (0, I), where I is the identity matrix. In this case, the KL divergence can be explicitly evaluated as\nL(c i ) = \u2212 log[det(\u03a3)] \u2212 n + trace(\u03a3) + \u00b5 T \u00b5 2 ,\nwhere we assume a latent space of dimension n.\nWe hence solve for the unknown weights of the generator \u03b8 as well as the parameters of q i denoted by \u00b5 i and \u03a3 i by minimizing the negative of the lower bound in (8).\nFollowing [2], we use a Monte-Carlo approach to approximate the expectation in the data term. In particular, at each epoch of the training loop, we derive the samples c i as\nc i = \u00b5 i + \u03a3 i ,(9)\nwhere is a zero-mean unit variance Gaussian random variable. At each iteration, the estimation process thus involves the minimization of the criterion\nC \uf8eb \uf8ed \u03b8, {\u00b5 i , \u03a3 i qi } \uf8f6 \uf8f8 = N data i=1 A i D \u03b8 (c i ) \u2212 b i 2 + \u03c3 2 L(q i ) ,(10)\nwith respect to the unknowns \u03b8, \u00b5 i and \u03a3 i .", "publication_ref": ["b1", "b1", "b7", "b1"], "figure_ref": [], "table_ref": []}, {"heading": "C. Illustration using MNIST data", "text": "We provide a simple example for the illustration of the above variational model from undersampled data of the digit 1 in the MNIST dataset [38]. The images used are scaled to the range [\u22121, 1].\nThe generator we used here is a simple CNN with three layers. ReLU activation function is used for the first two layers and tanh is used for the last layer. The dimension of the latent space is chosen as 2. In this example, all the trainable parameters are initialized as small random numbers, and the hyper-parameter for the latent regularization L(c i ) is chosen as 1. We used 1,000 epoches to train the CNN generator.\nWe first trained the model from the fully sampled data (A i = I), whose results are shown in the first row of Fig. 1. Then we trained the model from undersampled noisy data. In the example, 70% of the pixel values in each image are missing, while Gaussian white noise with standard deviation 0.05 is added to the known 30% pixel values. The recovered images are shown in the second row of Fig. 1. We report the peak signal-to-noise ratio (PSNR) and the structural similarity index measure (SSIM) for the results. ", "publication_ref": ["b37"], "figure_ref": ["fig_0", "fig_0"], "table_ref": []}, {"heading": "IV. APPLICATION TO DYNAMIC MRI", "text": "We first describe the application of the algorithm in the single-slice free-breathing and ungated data, which is the setting considered in [31]. We then generalize the approach to the novel setting of the joint alignment and recovery of 3D MRI from multislice free-breathing data in Section IV-C.", "publication_ref": ["b30"], "figure_ref": [], "table_ref": []}, {"heading": "A. Acquisition scheme and pre-processing of data", "text": "The datasets used in this work are acquired using a 2D (GRE) sequence with golden angle spiral readouts in the freebreathing and ungated setting on a MR750W scanner (GE Healthcare, Waukesha, WI, USA). The sequence parameters for the datasets are: FOV = 320 mm \u00d7 320 mm, flip angle = 18 \u2022 , slice thickness = 8 mm. The datasets were acquired using a cardiac multi-channel array with 34 channels. The Institutional Review Board at the University of Iowa approved the acquisition of the data, and written consents were obtained from the subjects. The number of slices acquired for different subjects varies.\nWe used an algorithm developed in house to pre-select the coils that provide the best signal-to-noise ratio in the region of interest. A PCA-based coil combination scheme was then used such that the approximation error was less than 5%. We then estimated the coil sensitivity maps based on these virtual channels using ESPIRiT [39] and assumed them to be constant over time.\nA total of 3,192 spirals were acquired for each slice in the subjects with TR=8.4 ms, which corresponds to an acquisition time of 27 seconds. Among the 3,192 spirals, every sixth spiral was acquired with the same angle; these spirals were used for self-navigation in the reconstruction methods that require self-navigation. We binned the data from six spiral interleaves corresponding to 50 ms temporal resolution for each frame.", "publication_ref": ["b38"], "figure_ref": [], "table_ref": []}, {"heading": "B. Single-slice Variational SToRM algorithm", "text": "Based on the analysis in the previous sections, we use the following scheme for the recovery of single-slice dynamic MRI. We use a re-parameterization layer to obtain the latent variables c(t) from the time-varying probability distributions q(c(t)) with parameters \u00b5 t and \u03a3 t . These latent variables are fed to the CNN generator D \u03b8 , which generates the reconstructed volumes x(t) = D \u03b8 (c(t)). The multi-channel, non-uniform, Fourier transform-based forward operators are applied on the reconstructed images, which are then compared to the actual noisy measurements b i . The illustration of this scheme is shown in Fig. 2 (a). The parameters in the generator and the \u00b5 i and the \u03a3 i are updated based on the loss function\nL(\u03b8, {\u00b5 t , \u03a3 t }) = C(\u03b8, {\u00b5 t , \u03a3 t }) + \u03bb 1 ||\u03b8|| 2 1 + \u03bb 2 ||\u2207\u00b5 t || 2 . (11\n)\nHere, C(\u03b8, {\u00b5 t , \u03a3 t }) is defined in (10), which is the lower bound for maximum likelihood estimation. The second term in ( 11) is a regularization penalty on the generator weights. It has been shown in [31] that adding this term makes the training of the decoder more stable. The third term involves the temporal gradients of the latent vectors, which enforces the latent vectors to capture the smooth nature of motion patterns in the dynamic images. We use the ADAM optimization to determine the optimal parameters. We also adopt The 2D network D receives the latent vectors sampled from their respective latent distributions using (9). The measurements of the 2D-generated images obtained by the respective sampling operators A i are compared to the acquired multi-channel measurements using the cost function specified by (11). (b) the multislice 3D setting: Similar to the single-slice setting, the inputs to the 3D network are samples from the respective latent distributions. The 3D volumes are sampled by the respective sampling operators Az,t, which extract the z th slice and compare it to the measured data. The optimization criterion specified by ( 12) is minimized in this case.\nthe progressive-in-time training strategy introduced in [31] to realize a computationally efficient reconstruction. We term this dynamic MRI reconstruction scheme as single-slice variational SToRM.", "publication_ref": ["b9", "b30", "b8", "b10", "b30"], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "C. Multislice Variational SToRM algorithm", "text": "We now generalize the single-slice variational SToRM scheme for the joint alignment and recovery of multislice dynamic MRI. We assume that the image volume at the time point t during the acquisition of the z th slice, denoted by x(r, t z ), as the output of the generator:\nx(r, t z ) = D \u03b8 (c(t z )) .\nHere, c(t z ) are the low-dimensional latent vectors corresponding to slice z at the time point t, which is formed by the reparameterization layer. We note that the generator D \u03b8 is shared across all slices and time points; this approach facilitates the exploitation of the spatial redundancies between the slices and time points.\nWe propose to jointly align and reconstruct the multislice MRI by jointly estimating the parameters \u03b8, \u00b5(t z ) and \u03a3(t z ) from the measured multislice data by minimizing the following cost function:\nL M S (\u03b8, \u00b5(t z ), \u03a3(t z )) =C M S (\u03b8, \u00b5(t z ), \u03a3(t z )) + \u03bb 1 ||\u03b8|| 2 1 + \u03bb 2 z ||\u2207 tz \u00b5(t z )|| 2 ,(12)\nwhere\nC M S = N slice z=1 N data t=1 A tz [D \u03b8 (c(t z ))] \u2212 b tz 2 + \u03c3 2 L(q(t z ))\nis the lower bound for maximum likelihood as the first term in (11). The illustration of this scheme is given in Fig. 2(b). The parameters of the shared 3D generator D \u03b8 are jointly learned in an unsupervised fashion from the measured k-t space data using the ADAM optimization algorithm. After the training process is complete, we will generate the image time series by feeding the generator with the latent variables of any specific slice. Following successful learning, we expect the volumes of the multislice reconstructions to have the same motion patterns characterized by the latent variables of that particular slice. We refer to this dynamic MRI reconstruction scheme as multislice variational SToRM, or V-SToRM.", "publication_ref": ["b10"], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "D. Comparison with state-of-the-art (SOTA) methods", "text": "We compare the proposed V-SToRM approach with the following existing methods.\n\u2022 Analysis SToRM [28]: The analysis SToRM model uses a kernel low-rank formulation, which involves the estimation of the manifold Laplacian matrix from the kspace navigators using kernel low-rank regularization. This Laplacian is then used to solve for the images. We note that the analysis SToRM approach has been demonstrated to yield improved performance over stateof-the-art self-gated methods, as shown in our prior work [28], [30]. We refer to this approach as A-SToRM. \u2022 Single-slice generative SToRM [31]: The single-slice generative SToRM approach uses a CNN generator to generate the single-slice image series from the highly undersampled k-t space data. This scheme does not rely on a variational formulation. It performs the independent recovery of each slice and hence fails to exploit the inter-slice redundancies. We refer to this approach as G-SToRM:SS. \u2022 Multislice generative SToRM: We extended the singleslice generative SToRM approach without the variational framework to the multislice setting. In particular, we use the CNN generator to produce the image volume; the generator parameters and the latent vectors for each slice are jointly learned. Finally, we feed the latent variables of a particular slice into the generator to obtain the aligned multislice reconstruction. We refer to this approach as G-SToRM:MS.\nFor the quantitative comparisons, in addition to the SSIM metric, we also use the signal-to-error ratio (SER) defined as\nSER = 20 \u2022 log 10 ||x ref || ||x ref \u2212 x recon || .\nHere, x ref and x recon represent the reference and the reconstructed images, respectively. The unit for SER is decibel (dB).\nIn our free-breathing and ungated cardiac MRI setting, we usually do not have access to the ground truth. Therefore, in our work, we employ the analysis SToRM method using 25 seconds of data for the reconstruction as the simulated ground truth.", "publication_ref": ["b27", "b27", "b29", "b30"], "figure_ref": [], "table_ref": []}, {"heading": "V. EXPERIMENTS AND RESULTS", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A. Implementation details", "text": "In this work, we use deep CNN to build the generator. The number of generator output channels is dependent on the specific datasets. For the experiments using the MNIST dataset, the channel is chosen as 1. By contrast, a twochannel output corresponding to the real and imaginary parts of the MR images is used for the rest of the experiments. In the MRI setting, we use a generator of 10 layers. The total number of trainable parameters is about 6 times the size of the image volume. For the convolutional layers in the generator, the activation function is chosen as leaky ReLU [40] except for the final layer, where tanh is used as the activation function. Random initialization is used to initialize the generator network.\nThe algorithm has three free parameters, \u03c3 2 , \u03bb 1 , and \u03bb 2 . For each method, we optimize these parameters as well as the architecture of the generator on a single dataset such that the reconstructions closely match the 25-second A-SToRM reconstructions. Once the optimal parameters are determined, they are kept fixed for the remaining datasets. Our experiments showed that two latent vectors were sufficient for the good recovery of the single-slice datasets, which correspond to the cardiac and respiratory phases. In the multislice case, we required three to obtain good reconstructions. In this case, two of the three latent vectors captured cardiac and respiratory motion, respectively. The third latent vector seemed to capture a harmonic of the respiratory motion.", "publication_ref": ["b39"], "figure_ref": [], "table_ref": []}, {"heading": "B. Single-slice V-SToRM and comparisons", "text": "In this section, we focus on single-slice V-SToRM; the reconstructions of a dataset and its latent vectors are shown in Fig. 3. We trained the variational model using the data of one slice. The latent vectors we obtained are shown at the bottom of Fig. 3. Four different phases in the time series are shown in the figure, and their corresponding latent vectors are indicated in the plot of the latent vectors.\nThe comparisons between the single-slice V-SToRM and the state-of-the-art methods on a different dataset are shown in Fig. 4. In these experiments, we compare the region of interest for A-SToRM, G-SToRM, and V-SToRM reconstructions using the 7.5 seconds of data. We use A-SToRM reconstructions from 25 seconds of data as the reference. From Fig. 4, we see that G-SToRM (7.5 s) and V-SToRM (7.5) are able to reduce  The figure shows the visual comparison of three phases: the diastole phase (top row), the systole phase (third row), and the phase that is in between the diastole and systole phases (second row). The first three columns correspond to the reconstructions using the A-SToRM, G-SToRM, and V-SToRM approaches based on 7.5 seconds of data. The last column shows the reconstructions from A-SToRM based on 25 seconds of data; we use these reconstructions as references for quantitative comparisons. We also report the quantitative results at the bottom of the figure.", "publication_ref": [], "figure_ref": ["fig_2", "fig_2", "fig_3", "fig_3"], "table_ref": []}, {"heading": "C. Joint alignment and recovery of multislice data", "text": "In this section, we show the results of the joint alignment and recovery of multislice data using the proposed multislice V-SToRM scheme. We also compare the alignment results obtained from the straightforward multislice extension of the G-SToRM scheme. The results are shown in Fig. 5. More results are shown in the supplementary material. , we see that all the slices have the same cardiac phase and respiratory phase, indicating that the multislice V-SToRM is able to align the slices. In (b), we show the alignment and recovery of the eight slices obtained from the generalization of single-slice G-SToRM to the multislice setting. We also use four different phases in the time series for each slice to illustrate the alignment of the multislice data. From (b), we see that some of the phases for some of the slices have poor image quality. In particular, the details in the cardiac regions are poorly captured, and in some cases the boundaries of the heart are not visible. These issues can be understood from the plot distributions of the latent vectors obtained by the multislice V-SToRM and G-SToRM:MS, shown in (c) and (d), respectively. We also plot the latent vectors for two of the slices for each method. Note that we generated the results in (a) and (b) by feeding the latent vectors corresponding to the second slice into the generators. The dataset used in Fig. 5 was acquired with eight slices that covered the whole heart. We trained the variational model based on the undersampled k-t space data and fed the latent vectors corresponding to the second slice to the generator, which produces the aligned multislice reconstructions. Shown in the figures are four time points based on the different phases identified by the latent variables. The rows in Fig. 5 (a) correspond to diastole in End-Inspiration, diastole in End-Expiration, systole in End-Inspiration, and systole in End-Expiration for each slice obtained using the proposed multislice V-SToRM scheme. From Fig. 5 (a), we see that the proposed multislice V-SToRM scheme is able to jointly reconstruct and align the multislice free-breathing and ungated cardiac MRI. We note that all the slices in each row have the same cardiac phase and respiratory phase.\nIn Fig. 5 (b), we show the corresponding results for the direct extension of the multislice G-SToRM approach. In particular, we trained the model using the undersampled k-t space data and fed the latent vectors corresponding to the second slice into the generator to produce the aligned multislice reconstructions. From Fig. 5 (b), we see that the multislice G-SToRM approach has some ability to align the multislice reconstructions. However, we find that the image quality for some of the frames (e.g., slices 5-8) is poor. For example, the diastole phases for the G-SToRM:MS reconstructions are blurred and the cardiac boundaries are missing.\nThe reason for the poor reconstructions offered by multislice G-SToRM and the improved performance of V-SToRM can be From both the visual comparisons and the quantitative results, we see that the multislice V-SToRM scheme is able to provide comparable reconstructions when compared to the competing methods. We also highlighted some of the phases in the multislice G-SToRM reconstruction, from which we see that G-SToRM:MS has some issues in generating some of the image frames.\neasily appreciated from the distribution of the latent vectors shown in Fig. 5 (c) and Fig. 5 (d), respectively. The use of the variational formulation in V-SToRM encouraged the latent variables of the slices to approximate a Gaussian distribution. We also reported the KL divergence value compared to N (0, I) for each set of the latent vector in the figure. We note that the V-SToRM scheme offers low KL divergence values, indicating that the latent distribution of all the slices are roughly similar to a unit Gaussian. By contrast, the G-SToRM scheme cannot guarantee that the latent variables follow any distribution. We note from the top rows of (d) that the distribution of the latent variables of the second slice is very different from that of the other slices. When we feed the latent vectors of the second slice into the generator, the generator is only able to generate reasonable results for the second slice.", "publication_ref": [], "figure_ref": ["fig_4", "fig_4", "fig_4", "fig_4", "fig_4", "fig_4", "fig_4", "fig_4"], "table_ref": []}, {"heading": "D. Comparison of image quality with state-of-the-art methods", "text": "We compare the image quality of the multislice V-SToRM reconstructions with the image quality of the reconstructions from the state-of-the-art methods, including single-slice methods, in Fig. 6. Note that the motion patterns of the slices recovered by the single-slice methods may be very different. For comparison, we manually matched the images of the slices of the single-slice and multislice methods by their cardiac and respiratory phases. The quantitative comparisons of the slices are shown at the bottom of each sub-figure. We also show more results using another dataset in the supplementary material.\nThe single-slice A-SToRM and G-SToRM:SS comparisons roughly match the observations in Fig. 4 and the results in [31]. The results show that the multislice V-SToRM approach is able to offer reconstructions that are less blurred and have fewer alias artifacts when compared to single-slice analysis methods (A-SToRM and G-SToRM:SS). The improved performance is also evidenced by the higher SER and SSIM values. We attribute the improved performance to the exploitation of the redundancies across slices, enabled by V-SToRM. We also note that the G-SToRM:MS method offers poor performance, evidenced by image blurring and missing details on the myocardium. The poor performance of G-SToRM:MS can be understood in terms of the differences in distribution of the latent vectors, shown in Fig. 5.", "publication_ref": ["b30"], "figure_ref": ["fig_3", "fig_4"], "table_ref": []}, {"heading": "VI. DISCUSSION AND CONCLUSION", "text": "In this work, we introduced an approach for the variational learning of a CNN manifold model from undersampled measurements. This work generalized the traditional VAE scheme to the undersampled setting. Unlike the traditional VAE scheme that uses an encoder to learn the conditional distribution from the images, we propose to learn the parameters of the distribution from the measurements using backpropagation. The application of the framework to multislice cardiac MRI data enabled the joint alignment and recovery from highly undersampled measurements. Unlike current single-slice methods that perform independent recovery of the slices, the proposed approach aligns the acquisitions and jointly recovers the images from the undersampled k-t space data. In addition to facilitating the exploitation of inter-slice redundancies, this approach also eliminates the need for postprocessing schemes to match the phases of the slices.\nOur results show that the joint alignment and recovery of the slices offer reduced blurring and reduction of artifacts compared to the direct generalization of G-SToRM to the multislice setting. In particular, the variational framework encourages the latent variables of different slices to have the same distribution. By contrast, the G-SToRM framework cannot guarantee the similarity of the probability distributions; the improper alignment translates to image blurring and other artifacts. Similarly, the use of the CNN generator offers implicit spatial regularization, resulting in improved recovery over A-SToRM.\nA benefit with the proposed scheme is that it does not require fully sampled data to train the CNN. The subject-specific CNN parameters and the latent vectors are learned directly from the undersampled data. We note that the acquisition of fully sampled data to train neural networks is not always possible, especially in the high-resolution and dynamic MRI settings considered in this work. In this context, direct learning from undersampled data is desirable. However, a challenge of the proposed scheme when compared to pretrained deep learning methods that offer super-fast inference is the higher computational complexity. We will explore training strategies, including transfer learning and meta-learning, to reduce the run time in the future.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "VII. APPENDIX", "text": "In this appendix, we show that the likelihood term in ( 7) can be lower-bounded by (8).\nAccording to (7) and using the result of joint probability, we obtain\np(b i ) = p(b i , c i ) q i (c i ) q i (c i ) p(c i |b i ) = p(b i , c i ) p(c i ) p(bi|ci) p(c i ) q i (c i ) q i (c i ) p(c i |b i ) . (13\n)\nTaking the logarithm on both sides of (13), we have\nlog p(b i ) = log p(b i |c i ) \u2212 log q i (c i ) p(c i ) + log q i (c i ) p(c i |b i ) .(14)\nNext, we take the expectation with respect to c i \u223c q i (c i ) of both sides of ( 14), and realizing that Ec i\u223cqi(ci) log p(b i ) = log p(b i ), we obtain\nlog p(b i ) = E ci\u223cqi(ci) log p(b i |c i ) data term \u2212 E ci\u223cqi(ci) log q i (c i ) p(c i ) KL[qi(ci)||p(ci)] + E ci\u223cqi(ci) log q i (c i ) p(c i |b i ) KL[qi(ci)||p(ci|bi)]>0 . (15\n)\nThe last term is always greater than zero. The first term is the conditional density of the measurements b i given the images x i = D \u03b8 (c i ). With the measurement model specified by (4), we obtain\nE ci\u223cqi(ci) log p(b i |c i ) = \u2212 1 2\u03c3 2 E ci\u223cqi(ci) A i D(c i ) \u2212 b i 2 + c,\nwhere c is a constant independent of the parameters of interest.\nIgnoring the constant c and plugging E ci\u223cqi(ci) log p(b i |c i ) back into (15), we obtain the desired lower bound (8).", "publication_ref": ["b7", "b6", "b14"], "figure_ref": [], "table_ref": []}, {"heading": "ACKNOWLEDGMENTS", "text": "The authors would like to thank Ms. Melanie Laverman from the University of Iowa for making editorial corrections to refine this paper. Financial support for this study was provided by grants NIH 1R01EB019961 and NIH R01AG067078-01A1. This work was conducted on MRI instruments funded by 1S10OD025025-01.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Reducing the dimensionality of data with neural networks", "journal": "Science", "year": "2006", "authors": "G E Hinton; R R Salakhutdinov"}, {"ref_id": "b1", "title": "Auto-encoding variational bayes", "journal": "", "year": "2013", "authors": "D P Kingma; M Welling"}, {"ref_id": "b2", "title": "Early visual concept learning with unsupervised deep learning", "journal": "", "year": "2016", "authors": "I Higgins"}, {"ref_id": "b3", "title": "beta-vae: Learning basic visual concepts with a constrained variational framework", "journal": "", "year": "2016", "authors": "I Higgins"}, {"ref_id": "b4", "title": "A recurrent latent variable model for sequential data", "journal": "", "year": "2015", "authors": "J Chung"}, {"ref_id": "b5", "title": "Separation of metabolites and macromolecules for short-te 1 h-mrsi using learned component-specific representations", "journal": "IEEE Transactions on Medical Imaging", "year": "2021", "authors": "Y Li; Z Wang; R Sun; F Lam"}, {"ref_id": "b6", "title": "qmodel: A plug-and-play model-based reconstruction for highly accelerated multi-shot diffusion mri using learned priors", "journal": "Magnetic Resonance in Medicine", "year": "2021", "authors": "M Mani; V A Magnotta; M Jacob"}, {"ref_id": "b7", "title": "Compressed sensing real-time cine cardiovascular magnetic resonance: accurate assessment of left ventricular function in a single-breath-hold", "journal": "Journal of Cardiovascular Magnetic Resonance", "year": "2016", "authors": "T Kido"}, {"ref_id": "b8", "title": "Accelerated mri for the assessment of cardiac function", "journal": "The British Journal of Radiology", "year": "2016", "authors": "L Axel; R Otazo"}, {"ref_id": "b9", "title": "Sparse mri: The application of compressed sensing for rapid mr imaging", "journal": "Magnetic Resonance in Medicine", "year": "2007", "authors": "M Lustig; D Donoho; J M Pauly"}, {"ref_id": "b10", "title": "Isotropic 3D Cartesian single breath-hold CINE MRI with multi-bin patch-based low-rank reconstruction", "journal": "Magnetic Resonance in Medicine", "year": "2020", "authors": "T K\u00fcstner"}, {"ref_id": "b11", "title": "Convolutional Recurrent Neural Networks for Dynamic MR Image Reconstruction", "journal": "IEEE Transactions on Medical Imaging", "year": "2019", "authors": "C Qin"}, {"ref_id": "b12", "title": "From compressedsensing to artificial intelligence-based cardiac mri reconstruction", "journal": "Frontiers in Cardiovascular Medicine", "year": "2020", "authors": "A Bustin; N Fuin; R M Botnar; C Prieto"}, {"ref_id": "b13", "title": "Cinenet: deep learning-based 3d cardiac cine mri reconstruction with multi-coil complex-valued 4d spatio-temporal convolutions", "journal": "Scientific Reports", "year": "2020", "authors": "T K\u00fcstner"}, {"ref_id": "b14", "title": "Accelerating cardiac cine mri using a deep learning-based espirit reconstruction", "journal": "Magnetic Resonance in Medicine", "year": "2021", "authors": "C M Sandino; P Lai; S S Vasanawala; J Y Cheng"}, {"ref_id": "b15", "title": "Ica-unet: Ica inspired statistical unet for real-time 3d cardiac cine mri segmentation", "journal": "Springer", "year": "2020", "authors": "T Wang"}, {"ref_id": "b16", "title": "Magnetic resonance multitasking for motion-resolved quantitative cardiovascular imaging", "journal": "Nature Biomedical Engineering", "year": "2018", "authors": "A G Christodoulou"}, {"ref_id": "b17", "title": "Xd-grasp: golden-angle radial mri with reconstruction of extra motion-state dimensions using compressed sensing", "journal": "Magnetic Resonance in Medicine", "year": "2016", "authors": "L Feng"}, {"ref_id": "b18", "title": "Golden-angle radial sparse parallel mri: combination of compressed sensing, parallel imaging, and golden-angle radial sampling for fast and flexible dynamic volumetric mri", "journal": "Magnetic Resonance in Medicine", "year": "2014", "authors": "L Feng"}, {"ref_id": "b19", "title": "Four-dimensional mri using three-dimensional radial sampling with respiratory self-gating to characterize temporal phaseresolved respiratory motion in the abdomen", "journal": "Magnetic Resonance in Medicine", "year": "2016", "authors": "Z Deng"}, {"ref_id": "b20", "title": "Cardiac and respiratory self-gating in radial mri using an adapted singular spectrum analysis (ssa-fary)", "journal": "IEEE Transactions on Medical Imaging", "year": "2020", "authors": "S Rosenzweig; N Scholand; H C M Holme; M Uecker"}, {"ref_id": "b21", "title": "Free-breathing cine imaging with motion-corrected reconstruction at 3T using SPiral Acquisition with Respiratory correction and Cardiac Self-gating (SPARCS)", "journal": "Magnetic Resonance in Medicine", "year": "2019", "authors": "R Zhou"}, {"ref_id": "b22", "title": "Manifold learning based ECG-free free-breathing cardiac CINE MRI", "journal": "Journal of Magnetic Resonance Imaging", "year": "2015", "authors": "M Usman; D Atkinson; C Kolbitsch; T Schaeffter; C Prieto"}, {"ref_id": "b23", "title": "High-Resolution Self-Gated Dynamic Abdominal MRI Using Manifold Alignment", "journal": "IEEE Transactions on Medical Imaging", "year": "2017", "authors": "X Chen"}, {"ref_id": "b24", "title": "Mls: Joint manifold-learning and sparsity-aware framework for highly accelerated dynamic magnetic resonance imaging", "journal": "IEEE", "year": "2018", "authors": "U Nakarmi; K Slavakis; L Ying"}, {"ref_id": "b25", "title": "Bi-linear modeling of data manifolds for dynamicmri recovery", "journal": "IEEE Transactions on Medical Imaging", "year": "2019", "authors": "G N Shetty"}, {"ref_id": "b26", "title": "A kernel-based low-rank (klr) model for low-dimensional manifold recovery in highly accelerated dynamic mri", "journal": "IEEE Transactions on Medical Imaging", "year": "2017", "authors": "U Nakarmi; Y Wang; J Lyu; D Liang; L Ying"}, {"ref_id": "b27", "title": "Free-breathing and ungated dynamic mri using navigator-less spiral storm", "journal": "IEEE Transactions on Medical Imaging", "year": "2020", "authors": "A H Ahmed"}, {"ref_id": "b28", "title": "Dynamic mri using smoothness regularization on manifolds (storm)", "journal": "IEEE Transactions on Medical Imaging", "year": "2015", "authors": "S Poddar; M Jacob"}, {"ref_id": "b29", "title": "Manifold recovery using kernel low-rank regularization: Application to dynamic imaging", "journal": "IEEE Transactions on Computational Imaging", "year": "2019", "authors": "S Poddar"}, {"ref_id": "b30", "title": "Dynamic imaging using deep generative storm (gen-storm) model", "journal": "IEEE Transactions on Medical Imaging", "year": "2021", "authors": "Q Zou; A H Ahmed; P Nagpal; S Kruger; M Jacob"}, {"ref_id": "b31", "title": "Deep generative storm model for dynamic imaging", "journal": "IEEE", "year": "2021", "authors": "Q Zou; A H Ahmed; P Nagpal; S Kruger; M Jacob"}, {"ref_id": "b32", "title": "Time-dependent deep image prior for dynamic mri", "journal": "IEEE Transactions on Medical Imaging", "year": "2021", "authors": "J Yoo"}, {"ref_id": "b33", "title": "Exact and approximate graph matching using random walks", "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": "2005", "authors": "M Gori; M Maggini; L Sarti"}, {"ref_id": "b34", "title": "High-resolution dynamic mr imaging of the thorax for respiratory motion correction of pet using groupwise manifold alignment", "journal": "Medical Image Analysis", "year": "2014", "authors": "C F Baumgartner"}, {"ref_id": "b35", "title": "Self-aligning manifolds for matching disparate medical image datasets", "journal": "Springer", "year": "2015", "authors": "C F Baumgartner"}, {"ref_id": "b36", "title": "Dynamic volume reconstruction from multi-slice abdominal mri using manifold alignment", "journal": "Springer", "year": "2016", "authors": "X Chen"}, {"ref_id": "b37", "title": "The mnist database of handwritten digits", "journal": "", "year": "1998", "authors": "Y Lecun"}, {"ref_id": "b38", "title": "Espirit-an eigenvalue approach to autocalibrating parallel mri: where sense meets grappa", "journal": "Magnetic Resonance in Medicine", "year": "2014", "authors": "M Uecker"}, {"ref_id": "b39", "title": "Empirical evaluation of rectified activations in convolutional network", "journal": "", "year": "2015", "authors": "B Xu; N Wang; T Chen; M Li"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Fig. 1 .1Fig. 1. Illustration of variational manifold learning in the context of learning the digit 1 from the MNIST dataset. We first trained the variational model from the fully sampled data. (a) shows several of the original images, and (b) shows the corresponding output of the generator (reconstructions). (c) illustrates the learned manifold; we sample the latent vectors on a uniform grid in the range [\u22123, 3] 2 and show the corresponding reconstructions. Note that the latent vectors capture the intrinsic variability in the dataset. The second row shows the results from the variational model, which are trained with undersampled noisy measurements. In this setting, 70% of the pixel values are missing, and the remaining 30% of the pixel values are corrupted with Gaussian white noise with 0 mean and 0.05 standard deviation. The zero-filled images are shown in (d). In (e), we show the reconstructions from the undersampled measurements. Note that the reconstructions closely resemble the original digits in (a). (f) is the illustration of the manifold. Note that the variability in the manifold is captured in comparison to (c).", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Fig. 2 .2Fig.2. Illustration of the proposed variational SToRM (V-SToRM) scheme. (a) single-slice setting: The 2D network D receives the latent vectors sampled from their respective latent distributions using(9). The measurements of the 2D-generated images obtained by the respective sampling operators A i are compared to the acquired multi-channel measurements using the cost function specified by(11). (b) the multislice 3D setting: Similar to the single-slice setting, the inputs to the 3D network are samples from the respective latent distributions. The 3D volumes are sampled by the respective sampling operators Az,t, which extract the z th slice and compare it to the measured data. The optimization criterion specified by (12) is minimized in this case.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Fig. 3 .3Fig. 3. Showcase of the single-slice V-SToRM. We trained the variational model using the data of one slice. We showed four different phases in the time series: diastole in End-Inspiration (E-I), diastole in End-Expiration (E-E), systole in End-Inspiration (E-I), and systole in End-Expiration (E-E), obtained from single-slice V-SToRM. The plot of the latent vectors are shown at the bottom of the figure, and the latent vectors corresponding to the four phases are indicated on the plot of the latent vectors.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Fig. 4 .4Fig. 4. Comparisons with the state-of-the-art methods for single-slice results.The figure shows the visual comparison of three phases: the diastole phase (top row), the systole phase (third row), and the phase that is in between the diastole and systole phases (second row). The first three columns correspond to the reconstructions using the A-SToRM, G-SToRM, and V-SToRM approaches based on 7.5 seconds of data. The last column shows the reconstructions from A-SToRM based on 25 seconds of data; we use these reconstructions as references for quantitative comparisons. We also report the quantitative results at the bottom of the figure.", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Fig. 5 .5Fig.5. Alignment and joint recovery of multislice data. In (a), we show the alignment and recovery of the eight slices obtained from the proposed multislice V-SToRM scheme. Four different phases in the time series for each slice are displayed. From (a), we see that all the slices have the same cardiac phase and respiratory phase, indicating that the multislice V-SToRM is able to align the slices. In (b), we show the alignment and recovery of the eight slices obtained from the generalization of single-slice G-SToRM to the multislice setting. We also use four different phases in the time series for each slice to illustrate the alignment of the multislice data. From (b), we see that some of the phases for some of the slices have poor image quality. In particular, the details in the cardiac regions are poorly captured, and in some cases the boundaries of the heart are not visible. These issues can be understood from the plot distributions of the latent vectors obtained by the multislice V-SToRM and G-SToRM:MS, shown in (c) and (d), respectively. We also plot the latent vectors for two of the slices for each method. Note that we generated the results in (a) and (b) by feeding the latent vectors corresponding to the second slice into the generators. The corresponding latent vectors used to generate the four different phases in (a) and (b) are indicated in the plot of the latent vectors in (c) and (d). From (c) and (d), we see that the latent vectors obtained from the proposed multislice V-SToRM scheme have similar distributions, whereas the distributions for the latent vectors obtained from G-SToRM:MS are very different.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Fig.5. Alignment and joint recovery of multislice data. In (a), we show the alignment and recovery of the eight slices obtained from the proposed multislice V-SToRM scheme. Four different phases in the time series for each slice are displayed. From (a), we see that all the slices have the same cardiac phase and respiratory phase, indicating that the multislice V-SToRM is able to align the slices. In (b), we show the alignment and recovery of the eight slices obtained from the generalization of single-slice G-SToRM to the multislice setting. We also use four different phases in the time series for each slice to illustrate the alignment of the multislice data. From (b), we see that some of the phases for some of the slices have poor image quality. In particular, the details in the cardiac regions are poorly captured, and in some cases the boundaries of the heart are not visible. These issues can be understood from the plot distributions of the latent vectors obtained by the multislice V-SToRM and G-SToRM:MS, shown in (c) and (d), respectively. We also plot the latent vectors for two of the slices for each method. Note that we generated the results in (a) and (b) by feeding the latent vectors corresponding to the second slice into the generators. The corresponding latent vectors used to generate the four different phases in (a) and (b) are indicated in the plot of the latent vectors in (c) and (d). From (c) and (d), we see that the latent vectors obtained from the proposed multislice V-SToRM scheme have similar distributions, whereas the distributions for the latent vectors obtained from G-SToRM:MS are very different.", "figure_data": ""}, {"figure_label": "46", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "4 Fig. 6 .46Fig. 6. Comparisons of the image quality of the reconstructions. We compare the image quality of the multislice V-SToRM reconstructions with the image quality of the reconstructions from A-SToRM, G-SToRM:SS, and G-SToRM:MS. The multislice dataset used in this example has four slices, and we show two of the slices in the figure to do the comparisons. For each slice, we show three different phases: the diastole phase, the systole phase, and the phase that is in between the diastole and systole phases. For each sub-figure, the first four columns represent the reconstruction from A-SToRM, G-SToRM:SS, G-SToRM:MS, and the proposed multislice V-SToRM based on 6 seconds of data. The last column shows the reconstructions using A-SToRM based on 25 seconds of data; they are used as simulated references for the quantitative results, which are shown at the bottom of each sub-figure.From both the visual comparisons and the quantitative results, we see that the multislice V-SToRM scheme is able to provide comparable reconstructions when compared to the competing methods. We also highlighted some of the phases in the multislice G-SToRM reconstruction, from which we see that G-SToRM:MS has some issues in generating some of the image frames.", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "b(t z ) = A tz x(r, t z ) + n tz ,(1)", "formula_coordinates": [2.0, 112.93, 738.55, 187.09, 9.68]}, {"formula_id": "formula_1", "formula_text": "i = D \u03b8 (c i ), i = 1, \u2022 \u2022 \u2022 , M.", "formula_coordinates": [2.0, 381.63, 219.3, 117.8, 9.65]}, {"formula_id": "formula_2", "formula_text": "C(c, \u03b8) = N i=1 A i (D \u03b8 (c i )) \u2212 b i 2 data term + \u03bb 1 J c D \u03b8 (c) 2 net reg. +\u03bb 2 \u2207 i c i 2 latent reg. .(2)", "formula_coordinates": [2.0, 351.29, 276.22, 211.74, 72.16]}, {"formula_id": "formula_3", "formula_text": "x i = D \u03b8 (c i ),(3)", "formula_coordinates": [2.0, 410.63, 611.81, 152.41, 9.68]}, {"formula_id": "formula_4", "formula_text": "b i = A i (x i ) + n i .(4)", "formula_coordinates": [2.0, 399.52, 708.58, 163.52, 9.68]}, {"formula_id": "formula_5", "formula_text": "E A\u223cS [A T A] = I,(5)", "formula_coordinates": [3.0, 149.13, 183.83, 150.9, 11.72]}, {"formula_id": "formula_6", "formula_text": "{\u03b8 * , c * i } = arg min \u03b8,ci i A i (x i \u2212 D \u03b8 (c i )) 2 L .(6)", "formula_coordinates": [3.0, 81.35, 312.1, 218.67, 35.75]}, {"formula_id": "formula_7", "formula_text": "L \u2248 E x\u223cM E A\u223cS A (x \u2212 D \u03b8 (c)) 2 = E x\u223cM E A\u223cS x \u2212 D \u03b8 (c), A H A (x \u2212 D \u03b8 (c)) = E x\u223cM x \u2212 D \u03b8 (c), E A\u223cS [A H A] I (x \u2212 D \u03b8 (c)) = arg min \u03b8,c E x\u223cM x \u2212 D \u03b8 (c) 2 .", "formula_coordinates": [3.0, 54.85, 382.78, 229.6, 83.44]}, {"formula_id": "formula_8", "formula_text": "p(b i ) = p(b i , c i ) p(c i |b i )(7)", "formula_coordinates": [3.0, 137.8, 598.01, 162.23, 23.25]}, {"formula_id": "formula_9", "formula_text": "log p(b i ) \u2265 \u2212 1 2\u03c3 2 E ci\u223cqi(ci) A i D \u03b8 (c i ) \u2212 b i 2 data term \u2212 KL[q i (c i )||p(c i )] L(qi):latent regularization .(8)", "formula_coordinates": [3.0, 327.39, 94.8, 235.65, 61.91]}, {"formula_id": "formula_10", "formula_text": "L(c i ) = \u2212 log[det(\u03a3)] \u2212 n + trace(\u03a3) + \u00b5 T \u00b5 2 ,", "formula_coordinates": [3.0, 337.72, 204.93, 199.58, 23.89]}, {"formula_id": "formula_11", "formula_text": "c i = \u00b5 i + \u03a3 i ,(9)", "formula_coordinates": [3.0, 404.06, 323.98, 158.98, 9.68]}, {"formula_id": "formula_12", "formula_text": "C \uf8eb \uf8ed \u03b8, {\u00b5 i , \u03a3 i qi } \uf8f6 \uf8f8 = N data i=1 A i D \u03b8 (c i ) \u2212 b i 2 + \u03c3 2 L(q i ) ,(10)", "formula_coordinates": [3.0, 314.89, 380.25, 248.14, 45.98]}, {"formula_id": "formula_13", "formula_text": "L(\u03b8, {\u00b5 t , \u03a3 t }) = C(\u03b8, {\u00b5 t , \u03a3 t }) + \u03bb 1 ||\u03b8|| 2 1 + \u03bb 2 ||\u2207\u00b5 t || 2 . (11", "formula_coordinates": [4.0, 319.37, 616.29, 239.52, 22.98]}, {"formula_id": "formula_14", "formula_text": ")", "formula_coordinates": [4.0, 558.89, 630.64, 4.15, 8.64]}, {"formula_id": "formula_15", "formula_text": "x(r, t z ) = D \u03b8 (c(t z )) .", "formula_coordinates": [5.0, 128.76, 446.14, 91.47, 9.68]}, {"formula_id": "formula_16", "formula_text": "L M S (\u03b8, \u00b5(t z ), \u03a3(t z )) =C M S (\u03b8, \u00b5(t z ), \u03a3(t z )) + \u03bb 1 ||\u03b8|| 2 1 + \u03bb 2 z ||\u2207 tz \u00b5(t z )|| 2 ,(12)", "formula_coordinates": [5.0, 58.83, 589.05, 241.2, 38.72]}, {"formula_id": "formula_17", "formula_text": "C M S = N slice z=1 N data t=1 A tz [D \u03b8 (c(t z ))] \u2212 b tz 2 + \u03c3 2 L(q(t z ))", "formula_coordinates": [5.0, 53.78, 648.8, 241.42, 30.38]}, {"formula_id": "formula_18", "formula_text": "SER = 20 \u2022 log 10 ||x ref || ||x ref \u2212 x recon || .", "formula_coordinates": [6.0, 103.09, 85.86, 142.81, 23.22]}, {"formula_id": "formula_19", "formula_text": "p(b i ) = p(b i , c i ) q i (c i ) q i (c i ) p(c i |b i ) = p(b i , c i ) p(c i ) p(bi|ci) p(c i ) q i (c i ) q i (c i ) p(c i |b i ) . (13", "formula_coordinates": [9.0, 97.22, 393.33, 198.65, 64.01]}, {"formula_id": "formula_20", "formula_text": ")", "formula_coordinates": [9.0, 295.87, 426.94, 4.15, 8.64]}, {"formula_id": "formula_21", "formula_text": "log p(b i ) = log p(b i |c i ) \u2212 log q i (c i ) p(c i ) + log q i (c i ) p(c i |b i ) .(14)", "formula_coordinates": [9.0, 58.57, 479.5, 241.45, 23.23]}, {"formula_id": "formula_22", "formula_text": "log p(b i ) = E ci\u223cqi(ci) log p(b i |c i ) data term \u2212 E ci\u223cqi(ci) log q i (c i ) p(c i ) KL[qi(ci)||p(ci)] + E ci\u223cqi(ci) log q i (c i ) p(c i |b i ) KL[qi(ci)||p(ci|bi)]>0 . (15", "formula_coordinates": [9.0, 54.66, 548.07, 241.22, 82.45]}, {"formula_id": "formula_23", "formula_text": ")", "formula_coordinates": [9.0, 295.87, 598.88, 4.15, 8.64]}, {"formula_id": "formula_24", "formula_text": "E ci\u223cqi(ci) log p(b i |c i ) = \u2212 1 2\u03c3 2 E ci\u223cqi(ci) A i D(c i ) \u2212 b i 2 + c,", "formula_coordinates": [9.0, 48.96, 685.48, 251.06, 22.73]}], "doi": ""}