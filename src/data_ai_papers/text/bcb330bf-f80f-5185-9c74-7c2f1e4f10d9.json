{"title": "Scaling in Cognitive Modelling: a Multilingual Approach to Human Reading Times", "authors": "Andrea Gregor De Varda; Marco Marelli", "pub_date": "", "abstract": "Neural language models are increasingly valued in computational psycholinguistics, due to their ability to provide conditional probability distributions over the lexicon that are predictive of human processing times. Given the vast array of available models, it is of both theoretical and methodological importance to assess what features of a model influence its psychometric quality. In this work we focus on parameter size, showing that larger Transformerbased language models generate probabilistic estimates that are less predictive of early eyetracking measurements reflecting lexical access and early semantic integration. However, relatively bigger models show an advantage in capturing late eye-tracking measurements that reflect the full semantic and syntactic integration of a word into the current language context. Our results are supported by eye movement data in ten languages and consider four models, spanning from 564M to 4.5B parameters.", "sections": [{"heading": "Introduction", "text": "The role of context-dependent statistical information in human language processing has received considerable attention in cognitive modelling. A solid empirical finding that has emerged from this research line is that speakers actively anticipate the upcoming linguistic material (Huettig, 2015;Staub, 2015). Indeed, behavioral and neural patterns that are diagnostic of reduced cognitive cost have been reported in response to predictable words; these emerged from the analysis of eye movements (Staub, 2015;Ehrlich and Rayner, 1981), changes in pupil size (Frank and Thompson, 2012), selfpaced reading times, (Frank and Hoeks, 2019;Fernandez Monsalve et al., 2012), ERP responses (De-Long et al., 2005;Van Berkum et al., 2005;Kwon et al., 2017), frontotemporal blood oxygenation levels (Baumgaertner et al., 2002;Dien et al., 2008), and MEG data (Takahashi et al., 2021).\nInferential theories of language comprehension argue that prediction must be an intrinsic feature of an incremental probabilistic cognitive processor (Levy, 2008;Shain et al., 2022). These accounts contend that the Kullback-Leibler (KL) divergence (i.e., relative entropy) between the probabilistic state of the processor before and after observing a given word is the cause of the processing difficulty associated with that word. It has been demonstrated that the KL divergence associated with this probability shift is mathematically equivalent to the surprisal of that word, i.e., the negative logarithm of its probability conditioned by the preceding sentence context (surprisal(w i ) = \u2212 log P (w i |w 1 , w 2 . . . w i\u22121 ); Levy, 2008). Inferential theories, which predict a logarithmic linking function between contextual predictability and cognitive cost, are supported by extensive experimental evidence in the computational psycholinguistics literature (Smith and Levy, 2008Levy, , 2013Wilcox et al., 2020;Shain et al., 2022, but see Hoover et al., 2022;Brothers and Kuperberg, 2020).\nStatistical language models developed in NLP research have been of paramount importance in the evolution of inferential theories of language comprehension. Indeed, language models are usually trained to predict the upcoming word in a corpus of naturalistic text, and thus define a conditional probability distribution that can be employed to compute word surprisal. Modern computationallyderived estimates of word predictability have been shown to perform on par (Shain et al., 2022) or even better (Hofmann et al., 2022;Michaelov et al., 2022) than predictability estimates obtained with expensive human annotation (although they fail to account for the processing demands of some specific linguistic patterns, see Arehalli et al., 2022;Van Schijndel and Linzen, 2021;Hahn et al., 2022). However, given that language models display a great amount of variation in their architectures and performances, various studies have investigated which models are better suited to characterize the behavioral correlates of human sentence comprehension. Seminal work has shown that the \"linguistic accuracy\" of a model (i.e., its ability to accurately predict the next word) is positively related to its \"psychological accuracy\" (namely, the capability of a surprisal estimate to explain variance in human responses, as captured by the increase in fit in a corresponding statistical model; Goodkind and Bicknell, 2018;Wilcox et al., 2020;Merkx andFrank, 2021, but see Hao et al., 2020;Kuribayashi et al., 2021).\nA recent incidental finding by Shain et al. (2022) shed doubt on such conclusion. The authors reported that the GPT-2 small model substantially outperformed GPT-3 in predicting self-paced reading times and fixation patterns while having a parameter size smaller by three degrees of magnitude and displaying higher perplexity values in next-word prediction. The result, which suggests that the correlations between the linguistic and psychological accuracy of language models might not hold for very deep transformer-based architectures, has been promptly replicated with different GPT-2 variants . This observation is at odds with the empirical scaling laws for neural language models , which show that the quality of a language model (both in terms of test loss and downstream performance, Hernandez et al., 2021) increases monotonically as the number of parameters increases (although see Lin et al., 2022).", "publication_ref": ["b19", "b40", "b40", "b14", "b42", "b24", "b2", "b13", "b41", "b25", "b36", "b25", "b25", "b39", "b44", "b36", "b18", "b5", "b36", "b17", "b30", "b0", "b43", "b44", "b28", "b23", "b36", "b16", "b26"], "figure_ref": [], "table_ref": []}, {"heading": "Related work and motivation", "text": "Research in computational psycholinguistics has largely followed the progressive switch to the Transformer architecture that has characterized the NLP literature in the last years, with Transformerbased surprisal estimates being evaluated as predictors of processing difficulty (Wilcox et al., 2020;Hao et al., 2020;Merkx and Frank, 2021). While early studies within this research line have documented a positive relationship between the linguistic and the psychological accuracy of a model (Goodkind and Bicknell, 2018;Wilcox et al., 2020;Merkx and Frank, 2021), recent findings with decoder-only large language models have documented an opposite pattern, with larger and betterperforming pre-trained Transformers providing worse psychometric estimates than their smaller counterparts .\nThe possibility that cognitive modelling might constitute an exception to scaling laws is intriguing, but further examination is needed to warrant such claims. All the evidence in support of this view has come from the English language alone (except from Kuribayashi et al., 2021), leaving an open question as to the cross-lingual generalizability of these findings. The English-centric approach to this problem is not surprising, since inferential approaches to language processing have been primarily supported by experimental evidence in English (Aurnhammer and Frank, 2019;Frank and Bod, 2011;Frank et al., 2015;Fernandez Monsalve et al., 2012;Wilcox et al., 2020;Goodkind and Bicknell, 2018;Levy, 2013), Dutch (Frank andHoeks, 2019;Brouwer et al., 2010) and German (Boston et al., 2008;Brouwer et al., 2021), while empirical support from non-Germanic languages is far more limited (although see Fan and Reilly, 2020;Kuribayashi et al., 2021). To the best of our knowledge, there is only one study that provided large-scale cross-lingual evidence in support of surprisal theory (de Varda and Marelli, 2022). Indeed, both NLP (Joshi et al., 2020) and cognitive science research (Blasi et al., 2022) have long overrelied on the English language to develop language processing systems and test theories of language and cognition. This tendency can lead to hasty claims of generality, and must be mitigated with cross-linguistic research efforts challenging the universality of English-specific findings.\nAnother potential shortcoming of the studies that reported the inverse scaling trend is that they only considered a single eye-tracking measurement as an index of processing cost . This choice reflects a common tendency within the inferential language processing framework (Aurnhammer and Frank, 2019;Goodkind and Bicknell, 2018;Smith and Levy, 2013;Wilcox et al., 2020); however, natural reading is an ability composed of multiple sub-processes characterized by different levels of complexity (see for instance Plaut et al., 1996;Coltheart et al., 2001). In principle, it is reasonable to assume that different processing stages, characterized by different degrees of complexity, might be better captured by models with varying parameter sizes, with shallow processes better modelled by (relatively) simpler networks, and complex integrative operations better characterized by more complex architectures.", "publication_ref": ["b44", "b15", "b28", "b44", "b28", "b23", "b1", "b44", "b7", "b4", "b6", "b23", "b10", "b21", "b3", "b1", "b39", "b44", "b33", "b9"], "figure_ref": [], "table_ref": []}, {"heading": "Aims", "text": "The current work aims at inspecting the relationship between the linguistic and the psychological accuracy of a neural language model across languages, testing whether previous observations on inverse scaling in cognitive modelling hold across a sample of ten languages belonging to four different families. Furthermore, our study considers different eye-tracking measures that are thought to reflect different processing stages, to examine the possibility that the relationship between the psychological and linguistic accuracy of a model might vary as a function of the computational complexity of the cognitive operations being studied.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Methods and materials 4.1 Data", "text": "In this study, we considered the eye movement data from the MECO-L1 corpus (Siegelman et al., 2022), a large-scale repository of eye-tracking records covering 13 languages. Participants engaged in a naturalistic reading task, and were presented with 12 texts consisting of encyclopedic entries on a handful of topics; five of the twelve original texts were translated from English to the target languages, while the other seven were nontranslated texts on the same topics and with the same writing styles, comparable length, and similar difficulty. Data points that showed either very short first fixation durations (< 80 ms) or very long total fixation times (top 1% of the participant-specific distribution) were discarded. We analyzed three measures of eye movement behavior for each word w i , which are thought to reflect early, intermediate, and late stages of processing:\n1. First fixation (FF): the time elapsed during the first fixation on w i . This measure is often assumed to reflect low-level oculomotor processes, early lexical access, and predictive processing (Demberg and Keller, 2008;Staub, 2015).\n2. Gaze duration (GD): the sum of the fixations landing on w i before the gaze leaves the word for the first time. This measure is thought to be indicative of lexical access, and possibly of early syntactic and semantic integration (Inhoff and Radach, 1998;Rayner, 1998).\n3. Total reading time (TT): the total amount of time spent looking at w i , including fixations returning to the word after having left it. This measure is thought to reflect full semantic integration (Radach and Kennedy, 2013) and syntactic integration and reanalysis (Meseguer et al., 2002).", "publication_ref": ["b37", "b12", "b40", "b20", "b35", "b34", "b29"], "figure_ref": [], "table_ref": []}, {"heading": "Models", "text": "In this study, we employed the XGLM family of auto-regressive language models (Lin et al., 2021). XGLMs are Transformer-based, decoder-only language models inspired by GPT-3 (Brown et al., 2020). We considered four pre-trained models, with 564M, 1.7B, 2.9B, and 4.5B parameters, and extracted word-by-word surprisal estimates from each of them. In the case of multi-token words, we summed the log probabilities assigned to the sub-word tokens, following the chain rule.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Analyses", "text": "Of the 13 languages included in the MECO dataset we had to exclude the Hebrew, Dutch, and Norwegian data, since these languages were not included in the XGLM pre-training data. Thus, our analyses were conducted in ten languages belonging to four language families (see Appendix A). On average, there were 65,450.8 available data points for each language (SD = 19,712.2). We fit 120 linear 1 mixed-effects regression models (10 languages \u00d7 4 models \u00d7 3 fixation measurements), with random intercepts for participants and items. We included as linear covariates length, log-frequency, and their interaction relative to w i , w i\u22121 , and w i\u22122 , to account for spillover effects. Our models also included a main effect of surprisal relative to w i , w i\u22121 , and w i\u22122 . All the variables were standardized before being entered into the mixed-effects regression models.\nTo evaluate the increase in the goodness of fit due to the inclusion of surprisal as a fixed effect, we compared each model with a corresponding baseline model, which was identical except for the absence of the fixed effects of surprisal. As common practice in the literature, we calculated the difference in the log likelihood between the baseline and the experimental model (\u2206LogLik; Goodkind and Bicknell, 2018;Wilcox et al., 2020;Kuribayashi et al., 2021;. In the literature we have reviewed in \u00a71, a common approach was to correlate the perplexity of a language model with the \u2206LogLik obtained by adding the surprisal terms; however, perplexity values can be properly compared only in the context of a fixed reference vocabulary (Wilcox et al., 2020). Technically, XGLM models produce a conditional probability distribution over the same whole vocabulary, regardless of the language of the specific text they are processing. However, the models have received strong evidence during pre-training that some subportions of the vocabulary (e.g. Cyrillic tokens) should be essentially ignored while processing text in some languages (e.g. English), thus reducing their actual reference vocabulary. Hence, while we report the perplexity-based results in Appendix B, we focused on the link between the linguistic and psychological accuracy of the models by observing how the \u2206LogLik was affected by the parameter size of the model. The choice of employing parameter size as a proxy of linguistic accuracy is supported by the results in the original XGLM paper, where the authors reported better results in almost all downstream tasks with the bigger versions of the XGLM model family (Lin et al., 2021).\nThe code employed in this study is publicly available 2 .", "publication_ref": ["b44", "b23", "b44"], "figure_ref": [], "table_ref": []}, {"heading": "Results", "text": "The first main finding of our study is that surprisal is a solid predictor of reading times across the languages considered, confirming the previous observation that context-dependent probabilistic processing generalizes beyond the Germanic language sample typically considered in the literature (de Varda and Marelli, 2022). The XGLM-based surprisal estimates were statistically significant in all cases when considering GD and TT, and in the vast majority of the cases when considering FF (see Appendix A).\nThe increase in goodness of fit that could be attributed to surprisal is displayed in Figure 1, grouped by model type and fixation measure. Concerning FF (1a), we reported a general decrease in \u2206LogLik when increasing the number of parameters, with the smallest XGLM 564M variant outperforming the bigger models in terms of psychological accuracy. A similar trend can be observed in GD (1b), although the difference in psychological accuracy between XGLM 564M and XGLM 1.7B appears to be rather small 3 . The results are different when considering TT as the dependent variable (1c), as in this case the model that provided the highest average increase in goodness of fit was XGLM 1.7B 4 .", "publication_ref": ["b10"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Discussion", "text": "In this experiment, we showed that large multilingual Transformer-based models were outperformed by their smaller variants in predicting early eye movement measurements of processing difficulty. These measurements are thought to reflect predictive processes, lexical access, and early semantic integration. This result corroborates the previous claims that cognitive modelling might constitute an exception to empirical scaling laws in NLP . However, predictability estimates computed by relatively larger variants of the same architecture -but not the largest -provided surprisal estimates that better captured late eye-tracking measurements, which are thought to reflect the full semantic and syntactic integration of a word into the phrasal context. This dissociation is in line with the observation that it is not appropriate to adopt a \"one-size-fits-all\" approach when studying how linguistic distributional knowledge explains different cognitive processes (Wingfield and Connell, 2022). Instead, context-dependent probabilistic information derived from different neural architectures might be more apt to model certain cognitive mechanisms, depending on the computational complexity of the processes being considered.", "publication_ref": ["b45"], "figure_ref": [], "table_ref": []}, {"heading": "Limitations", "text": "This work complemented previous analyses on the link between the linguistic and psychological accuracy of a neural language model by expanding the language sample to ten typologically distinct languages. However, our sample of neural language models was limited with respect to the literature focusing exclusively on English Shain et al., 2022). This problem cannot be overcome at the present state of affairs, since there are very few available massively multilingual auto-regressive language models, and the only one with sufficient coverage of our language sample was XGLM. This problem is an expression of a general difficulty in NLP to conduct experimental research on low-resource languages, due to the extreme skewness in the distribution of available resources (Joshi et al., 2020). However, we are confident that future developments in natural language engineering will support an additional test of our hypotheses with a more representative sample of models. ", "publication_ref": ["b36", "b21"], "figure_ref": [], "table_ref": []}, {"heading": "A Effects of surprisal by language and model type", "text": "We report in Table 1 the regression coefficients of surprisal (as computed on the target word w i ), the t statistic and the associated p-value, divided by language, number of parameters, and fixation measure considered. The surprisal estimates obtained from the four XGLM models were statistically significant predictors of processing times in all the language \u00d7 model combinations when considering GD and TT, and in the vast majority of the cases when considering FF as the dependent variable. These result are overall more solid than the ones obtained by de Varda and Marelli (2022), who did not report significant partial effects of surprisal on FF and GD in some of the languages considered. The authors derived their probabilistic estimates employing mBERT, a bidirectional encoder. This finding highlights the importance of employing standard left-to-right causal language models when studying the effects of predictability on incremental sentence processing.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B Relationship between perplexity and \u2206LogLik", "text": "The perplexity of a model (Eq. 1) is commonly considered as an intrinsic measure of a language model's linguistic accuracy. The employment of perplexity as an evaluation of a multilingual language model is not free of concerns (see \u00a74), but for completeness and consistency with the literature we also report the relationship between perplexity and \u2206LogLik.\nexp \u2212 1 N N i=1 log P (w i |w 1...i\u22121 )(1)\nWe analyzed the relationship between perplexity and \u2206LogLik by fitting three generalized additive mixed models (GAMMs; one for each eye-tracking measure considered), with random slopes and intercepts for language. Note that the presence of by-language random effects mitigates the problem of comparing perplexity values with potentially different employed vocabularies.\nThe results are graphically depicted in Figure 2. In the case of FF (2a), we found a significant relationship between perplexity and \u2206LogLik (EDF = 6.093, F = 3.623, p = 0.0095), which appears to be positive and (near)-linear from graphical inspection. In the case of GD (2b), we still found a significant partial effect of perplexity (EDF = 6.760, F = 4.466, p = 0.0019); however, the functional form of this relationship is far from linearity in this case, and is characterized by an initial growth in \u2206LogLik with increasing perplexity, a local plateau, and an inversion of the trend in the 400-550 perplexity range. There is then a second inversion of the trend in the 500-600 perplexity range, although with high partial residuals. In the case of TT (2c), the relationship is clearly quadratic from graphical inspection, although the partial effect of perplexity is not statistically significant (EDF = 2.016, F = 2.152, p = 0.123).\nTaken together, these results corroborate our observation that there is a negative relationship between the linguistic and the psychological accuracy of a model when considering the earliest fixation measurement, namely FF ( \u00a75); this relationship is less clear-cut when considering GD, and nonsignificant when considering TT. The very absence of a significant relationship between perplexity and \u2206LogLik in this latter case demonstrates that the finding that smaller models outperform their overparametrized counterparts in cognitive modelling critically depends on the computational complexity of the mental processes being analyzed.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C Cross-lingual variation in later measurements", "text": "The cross-lingual variation of our results increased with gaze duration and total reading time, in particular when considering XGLM 564M ; our tentative explanation for this pattern is motivated by the fact that late eye-tracking measures subsume the early ones (FF < GD < TT). XGLM 564M is very effective at capturing early eye movement measurements (Figure 1a); some of the later measures are de facto equivalent to the earlier ones in some cases (e.g., if a word is only fixated once, FF, GD, and TT will have the same value). XGLM 564M might be more effective in modelling late eye tracking data in languages where these cases are more common, and less effective in languages where it is more common to refixate. This hypothesis relies on the observation in the MECO paper that refixations are more common in some languages than others (e.g., Estonian, see Siegelman et al., 2022).", "publication_ref": ["b37"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "ACL 2023 Responsible NLP Checklist", "text": "A For every submission:\nA1. Did you describe the limitations of your work?\nSection \"Limitations\" (unnumbered, page 5) A2. Did you discuss any potential risks of your work?\nThere are no reasonable risks in our work. No, due to space restrictions. However, the artifacts that we employed were publicly released for research purposes.\nB3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided that it was specified? For the artifacts you create, do you specify intended use and whether that is compatible with the original access conditions (in particular, derivatives of data accessed for research purposes should not be used outside of research contexts)?\nNo; however, the artifacts were employed in accordance with their intended use.\nB4. Did you discuss the steps taken to check whether the data that was collected / used contains any information that names or uniquely identifies individual people or offensive content, and the steps taken to protect / anonymize it?\nNo, but the authors of the artifacts did, and we provided a reference to the original article. C1. Did you report the number of parameters in the models used, the total computational budget (e.g., GPU hours), and computing infrastructure used?\nWe did report the number of parameters ( \u00a74.2) but not the computational budget or the computing infrastructure as we did not train the models ourselves.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Syntactic surprisal from neural models predicts, but underestimates, human processing difficulty from syntactic ambiguities", "journal": "", "year": "2022", "authors": "Suhas Arehalli; Brian Dillon; Tal Linzen"}, {"ref_id": "b1", "title": "Comparing gated and simple recurrent neural network architectures as models of human sentence processing", "journal": "", "year": "2019", "authors": "Christoph Aurnhammer; L Stefan;  Frank"}, {"ref_id": "b2", "title": "Event-related fmri reveals cortical sites involved in contextual sentence integration", "journal": "Neuroimage", "year": "2002", "authors": "Annette Baumgaertner; Cornelius Weiller; Christian B\u00fcchel"}, {"ref_id": "b3", "title": "Overreliance on english hinders cognitive science", "journal": "Trends in cognitive sciences", "year": "2022", "authors": "E Dami\u00e1n; Joseph Blasi; Evangelia Henrich; David Adamou; Asifa Kemmerer;  Majid"}, {"ref_id": "b4", "title": "Parsing costs as predictors of reading difficulty: An evaluation using the potsdam sentence corpus", "journal": "Journal of Eye Movement Research", "year": "2008", "authors": "Marisa Ferrara Boston; John Hale; Reinhold Kliegl"}, {"ref_id": "b5", "title": "Word predictability effects are linear, not logarithmic: Implications for probabilistic models of sentence comprehension", "journal": "Journal of Memory and Language", "year": "2020", "authors": "Trevor Brothers; Gina Kuperberg"}, {"ref_id": "b6", "title": "Neurobehavioral correlates of surprisal in language comprehension: A neurocomputational model", "journal": "Frontiers in Psychology", "year": "2021", "authors": "Harm Brouwer; Francesca Delogu; J Noortje; Matthew W Venhuizen;  Crocker"}, {"ref_id": "b7", "title": "Modeling the noun phrase versus sentence coordination ambiguity in dutch: Evidence from surprisal theory", "journal": "", "year": "2010", "authors": "Harm Brouwer; Hartmut Fitz; John Hoeks"}, {"ref_id": "b8", "title": "Language models are few-shot learners", "journal": "", "year": "2020", "authors": "Tom Brown; Benjamin Mann; Nick Ryder; Melanie Subbiah; Jared D Kaplan; Prafulla Dhariwal; Arvind Neelakantan; Pranav Shyam; Girish Sastry; Amanda Askell"}, {"ref_id": "b9", "title": "Drc: a dual route cascaded model of visual word recognition and reading aloud", "journal": "Psychological review", "year": "2001", "authors": "Max Coltheart; Kathleen Rastle; Conrad Perry; Robyn Langdon; Johannes Ziegler"}, {"ref_id": "b10", "title": "The effects of surprisal across languages: Results from native and non-native reading", "journal": "", "year": "2022", "authors": "Andrea Gregor De Varda; Marco Marelli"}, {"ref_id": "b11", "title": "Probabilistic word pre-activation during language comprehension inferred from electrical brain activity", "journal": "Nature neuroscience", "year": "2005", "authors": "A Katherine;  Delong; P Thomas; Marta Urbach;  Kutas"}, {"ref_id": "b12", "title": "Data from eyetracking corpora as evidence for theories of syntactic processing complexity", "journal": "Cognition", "year": "2008", "authors": "Vera Demberg; Frank Keller"}, {"ref_id": "b13", "title": "fmri characterization of the language formulation area", "journal": "Brain Research", "year": "2008", "authors": "Joseph Dien; S Michael; Charles A Franklin; Lisa C Michelson;  Lemen; L Christy; Kent A Adams;  Kiehl"}, {"ref_id": "b14", "title": "Contextual effects on word perception and eye movements during reading", "journal": "Journal of verbal learning and verbal behavior", "year": "1981", "authors": "F Susan; Keith Ehrlich;  Rayner"}, {"ref_id": "b15", "title": "Probabilistic predictions of people perusing: Evaluating metrics of language model performance for psycholinguistic modeling", "journal": "", "year": "2020", "authors": "Yiding Hao; Simon Mendelsohn; Rachel Sterneck; Randi Martinez; Robert Frank"}, {"ref_id": "b16", "title": "", "journal": "", "year": "2021", "authors": "Danny Hernandez; Jared Kaplan; Tom Henighan; Sam Mccandlish"}, {"ref_id": "b17", "title": "Language models explain word reading times better than empirical predictability", "journal": "Frontiers in Artificial Intelligence", "year": "2022", "authors": "J Markus; Steffen Hofmann; Chris Remus; Ralph Biemann; Lars Radach;  Kuchinke"}, {"ref_id": "b18", "title": "The plausibility of sampling as an algorithmic theory of sentence processing", "journal": "", "year": "2022", "authors": "Jacob Louis Hoover; Morgan Sonderegger; T Steven; Timothy J O' Piantadosi;  Donnell"}, {"ref_id": "b19", "title": "Four central questions about prediction in language processing", "journal": "Brain research", "year": "2015", "authors": "Falk Huettig"}, {"ref_id": "b20", "title": "Definition and computation of oculomotor measures in the study of cognitive processes. Eye guidance in reading and scene perception", "journal": "", "year": "1998", "authors": "Albrecht Werner Inhoff; Ralph Radach"}, {"ref_id": "b21", "title": "The state and fate of linguistic diversity and inclusion in the NLP world", "journal": "Online. Association for Computational Linguistics", "year": "2020", "authors": "Pratik Joshi; Sebastin Santy; Amar Budhiraja; Kalika Bali; Monojit Choudhury"}, {"ref_id": "b22", "title": "", "journal": "", "year": "2020", "authors": "Jared Kaplan; Sam Mccandlish; Tom Henighan; Tom B Brown; Benjamin Chess; Rewon Child; Scott Gray; Alec Radford; Jeffrey Wu; Dario Amodei"}, {"ref_id": "b23", "title": "Lower perplexity is not always human-like", "journal": "Long Papers", "year": "2021", "authors": "Tatsuki Kuribayashi; Yohei Oseki; Takumi Ito; Ryo Yoshida; Masayuki Asahara; Kentaro Inui"}, {"ref_id": "b24", "title": "Predicting semantic features in chinese: Evidence from erps", "journal": "Cognition", "year": "2017", "authors": "Nayoung Kwon; Patrick Sturt; Pan Liu"}, {"ref_id": "b25", "title": "Expectation-based syntactic comprehension", "journal": "Cognition", "year": "2008", "authors": "Roger Levy"}, {"ref_id": "b26", "title": "Truthfulqa: Measuring how models mimic human falsehoods", "journal": "Long Papers", "year": "2022", "authors": "Stephanie Lin; Jacob Hilton; Owain Evans"}, {"ref_id": "b27", "title": "Jingfei Du, et al. 2021. Few-shot learning with multilingual language models", "journal": "", "year": "", "authors": "Todor Xi Victoria Lin; Mikel Mihaylov; Tianlu Artetxe; Shuohui Wang; Daniel Chen; Myle Simig; Naman Ott; Shruti Goyal;  Bhosale"}, {"ref_id": "b28", "title": "Human sentence processing: Recurrence or attention?", "journal": "", "year": "2021", "authors": "Danny Merkx; L Stefan;  Frank"}, {"ref_id": "b29", "title": "Overt reanalysis strategies and eye movements during the reading of mild garden path sentences", "journal": "Memory & cognition", "year": "2002", "authors": "Enrique Meseguer; Manuel Carreiras; Charles Clifton"}, {"ref_id": "b30", "title": "So cloze yet so far: N400 amplitude is better predicted by distributional information than human predictability judgements", "journal": "IEEE Transactions on Cognitive and Developmental Systems", "year": "2022", "authors": "Seana James A Michaelov; Benjamin K Coulson;  Bergen"}, {"ref_id": "b31", "title": "Comparison of structural parsers and neural language models as surprisal estimators", "journal": "Frontiers in Artificial Intelligence", "year": "2022", "authors": " Byung-Doh; Christian Oh; William Clark;  Schuler"}, {"ref_id": "b32", "title": "Why does surprisal from larger transformer-based language models provide a poorer fit to human reading times", "journal": "", "year": "2022", "authors": "Doh Byung-; William Oh;  Schuler"}, {"ref_id": "b33", "title": "Understanding normal and impaired word reading: Computational principles in quasi-regular domains", "journal": "Psychology Press", "year": "1996", "authors": "C David; James L Plaut;  Mcclelland; S Mark; Karalyn Seidenberg;  Patterson"}, {"ref_id": "b34", "title": "Eye movements in reading: Some theoretical context", "journal": "Quarterly Journal of Experimental Psychology", "year": "2013", "authors": "Ralph Radach; Alan Kennedy"}, {"ref_id": "b35", "title": "Eye movements in reading and information processing: 20 years of research", "journal": "Psychological bulletin", "year": "1998", "authors": "Keith Rayner"}, {"ref_id": "b36", "title": "Large-scale evidence for logarithmic effects of word predictability on reading time", "journal": "", "year": "2022", "authors": "Cory Shain; Clara Meister; Tiago Pimentel; Ryan Cotterell; Roger Philip Levy"}, {"ref_id": "b37", "title": "Expanding horizons of cross-linguistic research on reading: The multilingual eye-movement corpus (meco)", "journal": "", "year": "2022", "authors": "Noam Siegelman; Sascha Schroeder; Cengiz Acart\u00fcrk; Hee-Don Ahn; Svetlana Alexeeva; Simona Amenta; Raymond Bertram; Rolando Bonandrini; Marc Brysbaert; Daria Chernova"}, {"ref_id": "b38", "title": "Optimal processing times in reading: a formal model and empirical investigation", "journal": "", "year": "2008", "authors": "J Nathaniel; Roger Smith;  Levy"}, {"ref_id": "b39", "title": "The effect of word predictability on reading time is logarithmic", "journal": "Cognition", "year": "2013", "authors": "J Nathaniel; Roger Smith;  Levy"}, {"ref_id": "b40", "title": "The effect of lexical predictability on eye movements in reading: Critical review and theoretical interpretation", "journal": "Language and Linguistics Compass", "year": "2015", "authors": "Adrian Staub"}, {"ref_id": "b41", "title": "Identifying brain regions related to word prediction during listening to japanese speech by combining a lstm language model and meg", "journal": "bioRxiv", "year": "2021", "authors": "Yuta Takahashi; Yohei Oseki; Hiromu Sakai; Michiru Makuuchi; Rieko Osu"}, {"ref_id": "b42", "title": "Anticipating upcoming words in discourse: evidence from erps and reading times", "journal": "Journal of Experimental Psychology: Learning, Memory, and Cognition", "year": "2005", "authors": "J A Jos; Colin M Van Berkum; Pienie Brown; Valesca Zwitserlood; Peter Kooijman;  Hagoort"}, {"ref_id": "b43", "title": "Singlestage prediction models do not explain the magnitude of syntactic disambiguation difficulty", "journal": "Cognitive science", "year": "2021", "authors": "Marten Van Schijndel; Tal Linzen"}, {"ref_id": "b44", "title": "On the predictive power of neural language models for human real-time comprehension behavior", "journal": "", "year": "2020", "authors": "Ethan Gotlieb Wilcox; Jon Gauthier; Jennifer Hu; Peng Qian; Roger Levy"}, {"ref_id": "b45", "title": "Understanding the role of linguistic distributional knowledge in cognition. Language", "journal": "Cognition and Neuroscience", "year": "2022", "authors": "Cai Wingfield; Louise Connell"}, {"ref_id": "b46", "title": "Did you discuss the experimental setup, including hyperparameter search and best-found hyperparameter values? Not applicable", "journal": "", "year": "", "authors": ""}, {"ref_id": "b47", "title": "error bars around results, summary statistics from sets of experiments), and is it transparent whether you are reporting the max, mean, etc", "journal": "", "year": "", "authors": ""}, {"ref_id": "b48", "title": "for preprocessing, for normalization, or for evaluation", "journal": "", "year": "", "authors": ""}, {"ref_id": "b49", "title": "crowdworkers) or research with human participants? Left blank", "journal": "", "year": "", "authors": ""}, {"ref_id": "b50", "title": "Did you report the full text of instructions given to participants, including e.g., screenshots, disclaimers of any risks to participants or annotators", "journal": "", "year": "", "authors": " D1"}, {"ref_id": "b51", "title": "crowdsourcing platform, students) and paid participants, and discuss if such payment is adequate given the participants' demographic", "journal": "", "year": "", "authors": ""}, {"ref_id": "b52", "title": "Did you discuss whether and how consent was obtained from people whose data you're using/curating? For example, if you collected data via crowdsourcing, did your instructions to crowdworkers explain how the data would be used?", "journal": "", "year": "", "authors": " D3"}, {"ref_id": "b53", "title": "Was the data collection protocol approved (or determined exempt) by an ethics review board? No response", "journal": "", "year": "", "authors": " D4"}, {"ref_id": "b54", "title": "Did you report the basic demographic and geographic characteristics of the annotator population that is the source of the data? No response", "journal": "", "year": "", "authors": " D5"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 :1Figure 1: Plots of the increase in model fit (\u2206LogLik) obtained by adding the surprisal estimates from XGLM models with different parameter sizes. The horizontal lines in the box plots indicate the median value obtained across languages, while the squared marker shows the mean value. Note that the \u2206LogLik values were standardized by language.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "A3.Do the abstract and introduction summarize the paper's main claims? Abstract (unnumbered), Introduction ( \u00a71), Related work and motivation ( \u00a72), Aims ( \u00a73) A4. Have you used AI writing assistants when working on this paper? Left blank. B Did you use or create scientific artifacts? \u00a74.1, \u00a74.2 B1. Did you cite the creators of artifacts you used? \u00a74.1, \u00a74.2 B2. Did you discuss the license or terms for use and / or distribution of any artifacts?", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "Xi Fan and Ronan Reilly. 2020. Reading development at the text level: an investigation of surprisal and embeddingbased text similarity effects on eyemovements in chinese early readers. Journal of Eye Movement Research, 13(6).", "figure_data": "Irene Fernandez Monsalve, Stefan Frank, and Gabriella Vigliocco. 2012. Lexical surprisal as a general pre-dictor of reading time. In Proceedings of the 13th Conference of the European Chapter of the Associa-tion for Computational Linguistics, pages 398-408, Avignon, France. Association for Computational Lin-guistics.Stefan Frank and Rens Bod. 2011. Insensitivity of the human sentence-processing system to hierarchical structure. Psychological science, 22(6):829-834.Stefan Frank and John CJ Hoeks. 2019. The interaction between structure and meaning in sentence compre-hension. recurrent neural networks and reading times.Stefan Frank, Leun J Otten, Giulia Galli, and Gabriella Vigliocco. 2015. The erp response to the amount of information conveyed by words in sentences. Brain and language, 140:1-11.Stefan Frank and Robin Thompson. 2012. Early effects of word surprisal on pupil size during reading. In Proceedings of the annual meeting of the cognitive science society, volume 34.Adam Goodkind and Klinton Bicknell. 2018. Predic-tive power of word surprisal for reading times is a linear function of language model quality. In Pro-ceedings of the 8th workshop on cognitive modeling and computational linguistics (CMCL 2018), pages 10-18.Michael Hahn, Richard Futrell, Roger Levy, and Ed-ward Gibson. 2022. A resource-rational model of human processing of recursive linguistic structure. Proceedings of the National Academy of Sciences, 119(43):e2122602119."}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and linguistic phenomena, demographic groups represented, etc.? \u00a74.1 B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits, etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the number of examples in train / validation / test splits, as these provide necessary context for a reader to understand experimental results. For example, small differences in accuracy on large test sets may be significant, while on small test sets they may not be.", "figure_data": "\u00a74.3C Did you run computational experiments?\u00a74,  \u00a75"}], "formulas": [{"formula_id": "formula_0", "formula_text": "exp \u2212 1 N N i=1 log P (w i |w 1...i\u22121 )(1)", "formula_coordinates": [7.0, 340.51, 708.61, 184.64, 32.83]}], "doi": "10.1016/j.jml.2020.104174"}