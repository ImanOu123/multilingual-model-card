{"title": "Fairness Without Demographics in Repeated Loss Minimization", "authors": "Tatsunori B Hashimoto; Megha Srivastava; Hongseok Namkoong; Percy Liang", "pub_date": "", "abstract": "Machine learning models (e.g., speech recognizers) are usually trained to minimize average loss, which results in representation disparityminority groups (e.g., non-native speakers) contribute less to the training objective and thus tend to suffer higher loss. Worse, as model accuracy affects user retention, a minority group can shrink over time. In this paper, we first show that the status quo of empirical risk minimization (ERM) amplifies representation disparity over time, which can even make initially fair models unfair. To mitigate this, we develop an approach based on distributionally robust optimization (DRO), which minimizes the worst case risk over all distributions close to the empirical distribution. We prove that this approach controls the risk of the minority group at each time step, in the spirit of Rawlsian distributive justice, while remaining oblivious to the identity of the groups. We demonstrate that DRO prevents disparity amplification on examples where ERM fails, and show improvements in minority group user satisfaction in a real-world text autocomplete task.", "sections": [{"heading": "Introduction", "text": "Consider a speech recognizer that is deployed to millions of users. State-of-the art speech recognizers achieve high overall accuracy, yet it is well known that such systems have systematically high errors on minority accents (Amodei et al., 2016). We refer to this phenomenon of high overall accuracy but low minority accuracy as a representation disparity, which is the result of optimizing for average loss. This representation disparity forms our definition of unfairness, and has been observed in face recognition (Grother et al., 2011), language identification (Blodgett et al., 2016; Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s). Jurgens et al., 2017), dependency parsing (Blodgett et al., 2016), part-of-speech tagging (Hovy & Sgaard, 2015), academic recommender systems (Sapiezynski et al., 2017), and automatic video captioning (Tatman, 2017).\nMoreover, a minority user suffering from a higher error rate will become discouraged and more likely to stop using the system, thus no longer providing data to the system. As a result, the minority group will shrink and might suffer even higher error rates from a retrained model in a future time step. Machine learning driven feedback loops have been observed in predictive policing (Fuster et al., 2017) and credit markets (Fuster et al., 2017), and this problem of disparity amplification is a possibility in any deployed machine learning system that is retrained on user data.\nIn this paper, we aim to mitigate the representation disparity problem and its amplification through time. We focus on the following setting: at each time step, each user interacts with the current model and incurs some loss, based on which she decides to keep or quit using the service. A model is trained on the resulting user data which is used at the next time step. We assume that each user comes from one of K groups, and our goal is to minimize the worst case risk of any group across time. However, the group membership and number of groups K are both unknown, as full demographic information is likely missing in real online services.\nWe first show that empirical risk minimization (ERM) does not control the worst-case risk over the disparate K groups and show examples where ERM turns initially fair models unfair (Section 3). To remedy this issue, we propose the use of distributionally robust optimization (DRO) (Section 4). Given a lower bound on the smallest group proportion, we show that optimizing the worst-case risk over an appropriate chi-square divergence ball bounds the worst-case risk over groups. Our approach is computationally efficient, and can be applied as a small modification to a wide class machine learning models trained by stochastic gradient descent methods. We show that DRO succeeds on the examples where ERM becomes unfair, and demonstrate higher average minority user satisfaction and lower disparity amplification on a Amazon Mechanical Turk based autocomplete task. arXiv:1806.08010v2 [stat.ML] 30 Jul 2018", "publication_ref": ["b1", "b12", "b4", "b20", "b4", "b16", "b31", "b32", "b11", "b11"], "figure_ref": [], "table_ref": []}, {"heading": "Fairness in Machine Learning", "text": "Recently, there has been a surge of interest in fairness in machine learning (Barocas & Selbst, 2016). Our work can be seen as a direct instantiation of John Rawls' theory on distributive justice and stability, where we view predictive accuracy as a resource to be allocated. Rawls argues that the difference principle, defined as maximizing the welfare of the worst-off group, is fair and stable over time since it ensures that minorities consent to and attempt to maintain the status quo (Rawls, 2001, p155).\nIn this work, we assume the task is general loss minimization, and demographic data is unavailable. This differs from the substantial body of existing research into fairness for classification problems involving protected labels such as the use of race in recidivism protection (Chouldechova, 2017). There has been extensive work (Barocas & Selbst, 2016) on guaranteeing fairness for classification over a protected label through constraints such as equalized odds (Woodworth et al., 2017;Hardt et al., 2016), disparate impact (Feldman et al., 2015) and calibration (Kleinberg et al., 2017). However, these approaches require the use of demographic labels, and are designed for classification tasks. This makes it difficult to apply such approaches to mitigate representation disparity in tasks such as speech recognition or natural language generation where full demographic information is often unavailable.\nA number of authors have also studied individual notions of fairness, either through a fixed similarity function (Dwork et al., 2012) or subgroups of a set of protected labels (Kearns et al., 2018;H\u00e9bert-Johnson et al., 2017). Dwork et al. (2012) provides fairness guarantees without explicit groups, but requires a fixed distance function which is difficult to define for real-world tasks. Kearns et al. (2018); H\u00e9bert-Johnson et al. (2017) consider subgroups of a set of protected features, but defining non-trivial protected features which cover the latent demographics in our setting is difficult. Although these works generalize the demographic group structure, similarity and subgroup structure are both ill-defined for many real-world tasks.\nIn the online setting, works on fairness in bandit learning (Joseph et al., 2016;Jabbari et al., 2017) propose algorithms compatible with Rawls' principle on equality of opportunity-an action is preferred over another only if the true quality of the action is better. Our work differs in considering Rawlsian fairness for distributive justice (Rawls, 2009). Simultaneous with our work, Liu et al. (2018) analyzed fairness over time in the context of constraint based fairness criteria, and show that enforcing static fairness constraints do not ensure fairness over time. In this paper, we consider latent demographic groups and study a loss-based approach to fairness and stability.", "publication_ref": ["b2", "b5", "b2", "b33", "b13", "b10", "b22", "b9", "b21", "b15", "b9", "b21", "b15", "b19", "b18", "b30", "b24"], "figure_ref": [], "table_ref": []}, {"heading": "Problem setup", "text": "We begin by outlining the two parts of our motivation: representation disparity and disparity amplification.\nRepresentation disparity: Consider the standard lossminimization setting where a user makes a query Z \u223c P , a model \u03b8 \u2208 \u0398 makes a prediction, and the user incurs loss (\u03b8; Z). We denote the expected loss as the risk R(\u03b8) = E Z\u223cP [ (\u03b8; Z)]. The observations Z are assumed to arise from one of K latent groups such that Z \u223c P := k\u2208[K] \u03b1 k P k . We assume that neither the population proportions {\u03b1 k } nor the group distributions {P k } are known. The goal is to control the worst-case risk over all K groups:\nR max (\u03b8) = max k\u2208[K] R k (\u03b8), R k (\u03b8) := E P k [ (\u03b8; Z)]. (1)\nRepresentation disparity refers to the phenomenon of low R(\u03b8) and high R max (\u03b8) due to a group with small \u03b1 k .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Disparity amplification:", "text": "To understand the amplification of representation disparity over time, we will make several assumptions on the behavior of users in response to observed losses. These assumptions are primarily for clarity of exposition-we will indicate whenever the assumptions can be relaxed leave generalizations to the supplement. Roughly speaking, minimizing the worst-case risk R max (\u03b8) should mitigate disparity amplification as long as lower losses lead to higher user retention. We now give assumptions that make this intuition precise.\nIn the sequential setting, loss minimization proceeds over t = 1, 2, . . . T rounds, where the group proportion \u03b1 (t) k depends on t and varies according to past losses. At each round \u03bb (t+1) k is the expected number of users from group k, which is determined by \u03bd(R k (\u03b8)), the fraction of users retained, and b k , the number of new users (see Definition 1). Here, \u03bd is a differentiable, strictly decreasing retention function which maps a risk level R to the fraction of users who continue to use the system. Modeling user retention as a decreasing function of the risk implies that each user makes an independent decision of whether to interact with the system at time t + 1 based on their expected loss at time t. For example, selecting \u03bd(x) = 1 \u2212 x and R k equal to the expected zero-one loss implies that users leave proportional to the misclassification rates of their queries.\nAt each round we learn parameters \u03b8\n(t+1) based on n (t+1) \u223c Pois( k \u03bb (t+1) k\n) users (data points). While we define the sample size as a Poisson process for concreteness, our main results hold for any distribution fulfilling the strong law of large numbers, as we perform all stability analyses in the population limit.\nDefinition 1 (Dynamics). Given a sequence \u03b8 (t) , for each t = 1 . . . T , the expected number of users \u03bb and samples\nZ (t) i starting at \u03bb (0) k = b k is governed by: \u03bb (t+1) k := \u03bb (t) k \u03bd(R k (\u03b8 (t) )) + b k \u03b1 (t+1) k := \u03bb (t+1) k k \u2208[K] \u03bb (t+1) k n (t+1) := Pois( k \u03bb (t+1) k ) Z (t+1) 1 . . . Z (t+1) n (t+1) i.i.d. \u223c P (t+1) := k\u2208[K] \u03b1 (t+1) k P k .\nIf we use ERM at each time step the parameter sequence is defined as \u03b8 (t) = arg min \u03b8\u2208\u0398 i (\u03b8;\nZ (t) i\n). Our goal is to control over all groups k = 1, . . . , K and time periods t = 1, . . . , T the group-wise risk R k (\u03b8 (t) ),\nR T max (\u03b8 (0) , \u2022 \u2022 \u2022 , \u03b8 (T ) ) = max k,t R k (\u03b8 (t) ) .(2)\nWithout knowledge of group membership labels, population proportions \u03b1\n(t)\nk , new user rate b k , and retention rate \u03bd, minimizing R T max gives rise to two major challenges. First, without group membership labels there is no way to directly measure the worst-case risk R T max , let alone minimize it. Second, we must ensure that the group proportions \u03b1\n(t) k are stable, since if \u03b1 (t) k \u2192 0 as t \u2192 \u221e for some group k \u2208 [K],\nthen no algorithm can control R T max when a group has near zero probability of appearing in our samples.\nWe begin by illustrating how models that are initially fair with low representation disparity may become unfair over time if we use ERM (Section 3). We then propose a solution based on distributionally robust optimization (Section 4), and study examples where this approach mitigates representation disparity in our experimental section (Section 5).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Disparity amplification", "text": "The standard approach to fitting a sequence of models \u03b8 (t) is to minimize an empirical approximation to the population risk at each time period. In this section, we show that even minimizing the population risk fails to control minority risk over time, since expected loss (average case) leads to disparity amplification. The decrease in user retention for the minority group is exacerbated over time since once a group shrinks sufficiently, it receives higher losses relative to others, leading to even fewer samples from the group.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Motivating example", "text": "Consider the two-class classification problem in Figure 1 where the two groups are drawn from Gaussians and the optimal classification boundary is given along x 2 = 0. Assume that the sampling distribution evolves according to definition 1 with \u03bd(x) = 1.0\u2212x, equal to the zero one loss, and\nb 0 = b 1 = n (0) 0 = n (0) 1 = 1000.\nInitially, ERM has similar and high accuracy on both groups with the boundary x 2 > 0, but over time random fluctuations in accuracy result in slightly fewer samples from the cluster on the right. This leads to disparity amplification since ERM will further improve the loss on the left cluster at the expense of the right cluster. After 500 rounds, there are nearly no samples from the right cluster, and as a result, the right cluster ends up suffering high loss.", "publication_ref": [], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Conditions for disparity amplification", "text": "The example above demonstrated that disparity amplification can occur easily even in a situation where the two groups have identical population size and initial risk. In general if we view the expected user counts \u03bb (t) as a dynamical system, the long-term fairness properties for any fairness criteria are controlled by two factors -whether \u03bb has a fair fixed point (defined as a population fraction where risk minimization maintains the same population fraction over time) and whether this fixed point is stable.\nFixed points of risk minimization are determined by a combination of user retention function \u03bd and the models \u03b8 (t) , and without knowledge of \u03bd it is hard to ensure that a model has a fair fixed point. Even if a fixed point is fair, such as when the population fraction and risk received by each group is equal, and we start at this fair fixed point, minimizing the empirical loss may deviate from this fair fixed point over time due to finite sample fluctuations or noise in the model estimation procedure.\nTo show this result, we study the dynamical system \u03a6, which is defined by dynamics in Definition 1 with \u03b8 derived from minimizing the population, rather than empirical risk. Definition 2. Let \u03a6 be the update for the expected population size\n\u03bb (t+1) k := \u03a6(\u03bb (t) k ) = \u03bb (t) k \u03bd(R k (\u03b8(\u03bb (t) k ))) + b k , \u03b8(\u03bb (t) k ) = arg min \u03b8 E k \u03b1 (t) k P k [ (\u03b8; Z)].\nThe arrival intensity \u03bb * is called a fixed point if \u03bb * = \u03a6(\u03bb * ). This fixed point is stable whenever the maximum modulus of the eigenvalues of the Jacobian of \u03a6 is less than one and unstable whenever it is greater than one (Luo, 2012, Theorem 2.1).\nProposition 1 gives a precise statement of this phenomenon. We prove the result in Section A.1, and further show a generalization to general dynamics \u03a6(\u03bb k ) = h(\u03bb k , R k ) where h is differentiable and monotone in the second argument. We denote by \u03c1 max (A) the maximum modulus of the eigenvalues of A.\nProposition 1. Let \u03bb * = \u03a6(\u03bb * ) be a fixed point, and \u03b8 * = arg min \u03b8 E k \u03b1 * k P k [ (\u03b8; Z)] be the minimizer at \u03bb * . Define H R (\u03b1 * ) as the positive definite Hessian of the expected risk at \u03b8 * , \u03bb * and define \u2207L as the per-group parameter gradients at \u03b8 * ,\n\u2207L = \uf8ee \uf8ef \uf8f0 \u2207 \u03b8 E P1 [ (\u03b8 * ; Z)] . . . \u2207 \u03b8 E P k [ (\u03b8 * ; Z)] \uf8f9 \uf8fa \uf8fb .\nThe arrival intensity \u03bb * is unstable whenever\n\u03c1 max diag(\u03bd(R(\u03b8(\u03bb * )))) \u2212 diag(\u03bb * \u03bd (R(\u03b8(\u03bb * )) \u2207LH R (\u03b1 * ) \u22121 \u2207L I k \u03bb * k \u2212 1\u03bb * ( k \u03bb * k ) 2 > 1.\nWe see that the major quantities which control risk are the retention rate \u03bd and its derivative, as well as a K \u00d7 K square matrix \u2207LH R (\u03b1 * ) \u22121 \u2207L which roughly encodes the changes in one group's risk as a function of another.\nWe can specialize the stability condition to obtain an intuitive and negative result for the stability of risk minimization (average case). Even if we start at a fair fixed point with\n\u03bb * 1 = \u2022 \u2022 \u2022 = \u03bb * k and R 1 = \u2022 \u2022 \u2022 = R k , if\ndecreasing the risk for one group increases the risk for others sufficiently, the fixed point is unstable and the model will eventually converge to a different, possibly unfair, fixed point.\nCorollary 1 (Counterexample under symmetry). Let \u03bb * 1 = \u2022 \u2022 \u2022 = \u03bb * k be a fixed point with R 1 = \u2022 \u2022 \u2022 = R k ,\nthen for any strongly convex loss,\n\u03c1 max \u2207LH R (\u03b1 * ) \u22121 \u2207L > 1 \u2212 \u03bd(R 1 ) \u2212\u03bd (R 1 )/k . (3)\nis a sufficient condition for instability.\nSee Section A.2 for proof and generalizations.\nThe bound (3) has a straightforward interpretation. The left hand side is the stability of the model, where maximal eigenvalue of the matrix \u2207LH R (\u03b1 * ) \u22121 \u2207L represents the maximum excess risk that can be incurred due to a small perturbation in the mixture weights \u03b1. The right hand side represents the underlying stability of the dynamics and measures the sensitivity of \u03bb with respect to risk.\nMean and median estimation: Consider a simple mean estimation example where each user belongs to one of two groups, \u22121 or 1 and incurs loss (\u03b8 \u2212 Z) 2 . \u03b8 = 0 is clearly a fair fixed point, since it equalizes losses to both groups, with H risk (\u03b1 * ) = 1/2 and \u2207L = [2, \u22122] making \u03c1 max \u2207LH R (\u03b1 * ) \u22121 \u2207L = 4. If we select \u03bd(x) = exp(\u2212x), the right hand side becomes 2(1 \u2212 e \u22121 )e \u2248 3.4, and thus any perturbation will eventually result in \u03bb 1 = \u03bb 2 .\nIn this case the only other fixed points are the unfair solutions of returning the mean of either one of the groups.\nThe situation is even worse for models which are not strongly convex, such as median estimation. Replacing the squared loss above with the absolute value results in a loss which has a non-unique minimizer at 0 when \u03bb 1 = \u03bb 2 but immediately becomes \u22121 whenever \u03bb 1 > \u03bb 2 . In this case, no conditions on the retention function \u03bd can induce stability. This fundamental degeneracy motivates us to search for loss minimization schemes with better stability properties than ERM (average case).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Distributionally robust optimization (DRO)", "text": "Recall that our goal is to control the worst-case risk (2) over all groups and over all time steps t. We will proceed in two steps. First, we show that performing distributionally robust optimization controls the worst-case risk R max (\u03b8 (t) ) for a single time step. Then, we show that this results in a lower bound on group proportions {\u03b1 (t) k } K k=1 , and thus ensures control over the worst-case risk for all time steps. As a result of the two steps, we show in Section 4.4 that our procedure mitigates disparity amplification over all time steps. For notational clarity, we omit the superscript t in Sections 4.1-4.3.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Bounding the risk over unknown groups", "text": "The fundamental difficulty in controlling the worst-case group risk over a single time-step R max (\u03b8 (t) ) comes from not observing the group memberships from which the data was sampled. For many machine learning systems such as speech recognition or machine translation, such situations are common since we either do not ask for sensitive demographic information, or it is unclear a priori which demographics should be protected. To achieve reasonable performance across different groups, we postulate a formulation that protects against all directions around the data generating distribution. We build on the distributionally robust formulation of  which will allow us to control the worst-case group risk R max (\u03b8 (t) ).\nTo formally describe our approach, let D \u03c7 2 (P ||Q) be the \u03c7 2 -divergence between probability distributions P and Q given by D \u03c7 2 (P ||Q) := dP dQ \u2212 1 2 dQ. If P is not absolutely continuous with respect to Q, we define D \u03c7 2 (P ||Q) := \u221e.\nLet B(P, r) be the chi-squared ball around a probability distribution P of radius r so that B(P, r) := {Q P : D \u03c7 2 (Q||P ) \u2264 r}. We consider the worst-case loss over all r-perturbations around P , R dro (\u03b8; r) := sup\nQ\u2208B(P,r) E Q [ (\u03b8; Z)].(4)\nIntuitively, the distributionally robust risk R dro (\u03b8; r) upweights examples Z with high loss (\u03b8; Z). If there is a group suffering high loss, the corresponding mixture component will be over-represented (relative to the original mixture weights) in the distributionally robust risk R dro (\u03b8; r). We show in the following proposition that R dro (\u03b8; r) bounds the risk of each group R k (\u03b8), and hence the group-wise worst-case risk (1), for an appropriate choice of the robustness radius r. Proposition 2. For P :\n= k\u2208[K] \u03b1 k P k , we have R k (\u03b8) \u2264 R dro (\u03b8; r k ) for all \u03b8 \u2208 \u0398 where r k := (1/\u03b1 k \u2212 1)\n2 is the robustness radius.\nWe prove the result in Section A.4. Roughly speaking, the above bound becomes tighter if the variation in the loss (\u03b8; Z) is substantially higher between groups than within each group. In particular, this would be the case if the loss distribution for each group have distinct support with relatively well-concentrated components within each group.\nAs a consequence of Proposition 2, if we have a lower bound on the group proportions \u03b1 min \u2264 min k\u2208[K] \u03b1 k , then we can control the worst-case group risk R max (\u03b8) by minimizing the upper bound \u03b8 \u2192 R dro (\u03b8; r max ) where\nr max := (1/\u03b1 min \u2212 1) 2 .\nSimilar formulations for robustness around the empirical distribution with radius shrinking as r/n had been considered in (Ben-Tal et al., 2013;Lam & Zhou, 2015;. While there are many possible robustness balls B which could provide upper bounds on group risk, we opt to use the chi-squared ball since it is straightforward to optimize (Ben-Tal et al., 2013; and we found it empirically outperformed other f -divergence balls.", "publication_ref": ["b3", "b23", "b3"], "figure_ref": [], "table_ref": []}, {"heading": "Interpreting the dual", "text": "The dual of the maximization problem (4) provides additional intuition on the behavior of the robust risk. Proposition 3 ( (Duchi & Namkoong, 2018)). If (\u03b8; \u2022) is upper semi-continuous for any \u03b8, then for r max \u2265 0 and any \u03b8, R dro (\u03b8; r max ) is equal to the following expression\ninf \u03b7\u2208R F (\u03b8; \u03b7) := C E P [ (\u03b8, Z) \u2212 \u03b7] 2 + 1 2 + \u03b7 (5)\nwhere\nC = 2(1/\u03b1 min \u2212 1) 2 + 1 1/2 .\nDenoting by \u03b7 the optimal dual variable (5), we see from the proposition that all examples suffering less than \u03b7levels of loss are completely ignored, and large losses above \u03b7 are upweighted due to the squared term.\nHowever, unlike standard parameter regularization techniques, which encourage \u03b8 to be close to some point, our objective biases the model to have fewer high loss examples which matches our goal of mitigating representation disparity. Median Estimation: Recall the median estimation problem over two groups mentioned in Section 3.2 where the loss is (\u03b8; Z) = \u03b8 \u2212 Z 1 . Figure 2 shows the behavior of both ERM and DRO on this median estimation task with unbalanced (\u03b1 min = 0.1) groups. The parameter estimate which minimizes R max for this problem is \u03b8 fair = 0 since this is equidistant from both groups. ERM on the other hand focuses entirely on the majority and returns \u03b8 ERM \u2248 \u22121.0.", "publication_ref": ["b7"], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "Density", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "DRO returns \u03b8 *", "text": "DRO which is close to \u03b8 fair . Analyzing the risk, we find that the single-step worst-case group risk R max (\u03b8) in ( 1) is an upper bound on ERM, and DRO forms a tight upper bound this quantity (Figure 2b). We can also understand the behavior of DRO through the worst-case distribution Q in Equation 4. Figure 2a shows the worst-case distribution Q at the minimizer \u03b8 * DRO which completely removes points within distance \u03b7 * . Additionally, points far from \u03b8 * DRO are upweighted, resulting in a large contribution to the loss from the minority group.\nWe expect the bound to be tight when all individuals within a group receive the same loss. In this case, thresholding by \u03b7 * corresponds to selecting the single highest risk group which is equivalent to directly minimizing R max (\u03b8) (1).\nOn the other hand, the worst case for our approach is if \u03b1 min is small, and a group with low expected loss has a high loss tail with population size \u03b1 min . In this case DRO is a loose upper bound and optimizes the losses of the group with already low expected loss. This is closely related to recent observations that the DRO bound can be loose for classification losses such as the zeroone loss due to the worst-case distribution consisting purely of misclassified examples (Hu et al., 2018). Even in this case, the estimated loss is still a valid upper bound on the worst case group risk, and as Figure 2 shows, there are examples where the DRO estimate is nearly tight.", "publication_ref": ["b17"], "figure_ref": ["fig_1", "fig_1", "fig_1"], "table_ref": []}, {"heading": "Optimization", "text": "We now show how to minimize \u03b8 \u2192 R dro (\u03b8; r max ) efficiently for a large class of problems. For models such as deep neural networks that rely on stochastic gradient descent, the dual objective F (\u03b8; \u03b7) in ( 5) can be used directly since it only involves an expectation over the data generating distribution P .\nFormally, the following procedure optimizes (4): for a given value of \u03b7, compute the approximate minimizer \u03b8 \u03b7\nminimize \u03b8\u2208\u0398 E P [ (\u03b8; Z) \u2212 \u03b7] 2 + .(6)\nFrom Propositions 2 and 3, we have\nR max ( \u03b8 \u03b7 ) \u2264 R dro ( \u03b8 \u03b7 ; r max ) \u2264 F ( \u03b8 \u03b7 , \u03b7)\nwhich implies that we can treat \u03b7 as a hyperparameter. For convex losses \u03b8 \u2192 (\u03b8; Z), the function \u03b7 \u2192 F ( \u03b8 \u03b7 , \u03b7) is convex, and thus we can perform a binary search over \u03b7 to find the global optimum efficiently.\nAlternatively, for models where we can compute \u03b8 * (Q) \u2208 argmin \u03b8\u2208\u0398 E Q [ (\u03b8; Z)] efficiently, we can use existing primal solvers that compute the worst-case probability distribution Q * (\u03b8) \u2208 argmax Q\u2208B(P,r) E Q [ (\u03b8; Z)] for a given \u03b8 based on projected gradient ascent on Q . By alternating between optimization on \u03b8 and Q, we can efficiently find the saddle point (\u03b8 * , Q * ) that satisfies \u03b8 * = \u03b8 * (Q * ) and Q * = Q * (\u03b8 * ).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Stability of minority loss minimization", "text": "We have thus far demonstrated that for a single time step, the worst-case risk over all groups R max (\u03b8) = max k R k (\u03b8) can be controlled by the distributionally robust risk R dro (\u03b8; r max ) where r max := (1/\u03b1 min \u2212 1) 2 and \u03b1 min is the minority group proportion. Now, we study how the individual group risk R k (\u03b8) affects user retention and hence future risk. By virtue of providing an upper bound to R max (\u03b8), optimizing R dro (\u03b8; r max ) at each time step can thus control the future group risk R max (\u03b8).\nWe show that if the initial group proportions satisfy \u03b1 (0)\nk \u2265 \u03b1 min and the worst-case risk R max (\u03b8 (t) ) is sufficiently small at each time t, then we can ensure \u03b1 (t+1) k > \u03b1 min . Thus, to control R T max , the worst-case group risk over all time steps, it suffices to control R dro (\u03b8 (t) ; r max ) using the procedure in Section 4.3.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Proposition 4. Assume the retention model in", "text": "Definition 1. Let \u03b1 (t) k > \u03b1 min , b k k b k > \u03b1 min , \u03bb (t) := k \u03bb (t) k \u2264 k b k 1\u2212\u03bdmax , and \u03bd(R k (\u03b8 (t) )) < \u03bd max .\nThen, whenever we have\nR k (\u03b8 (t) ) \u2264 \u03bd \u22121 1 \u2212 (1 \u2212 \u03bd max )b k \u03b1 min k b k , \u03b1 (t+1) k = \u03bb (t) \u03b1 (t) k \u03bd(R k (\u03b8 (t) )) + b k l \u03bb (t) \u03b1 (t) l \u03bd(R l (\u03b8 (t) )) + b l > \u03b1 min .\nWe conclude that as long as we can guarantee\nR dro (\u03b8 (t) ; r max ) \u2264 \u03bd \u22121 1 \u2212 (1 \u2212 \u03bd max )b k \u03b1 min k b k ,(7)\nwe can control R T max (\u03b8 (0) , . . . , \u03b8 (T ) ), the unknown worstcase group risk over all time steps by optimizing R dro (\u03b8 (t) ; r max ) at each step t. While the condition ( 7) is hard to verify in practice, we observe empirically in Section 5 that optimizing the distributionally robust risk R dro (\u03b8 (t) ; r max ) at time step t indeed significantly reduces disparity amplification in comparison to using ERM.\nProposition 4 gives stronger fairness guarantees than the stability conditions for ERM in Proposition 1. In ERM the best one can do is to add strong convexity to the model to stabilize to a possibly unfair fixed point. In contrast, Proposition 4 gives conditions for controlling R max over time without assuming that there exists a fair fixed point.\nStability of median estimation: Returning to our running example of geometric median estimation, we can show that under the same dynamics, ERM is highly unstable while DRO is stable. Consider a three Gaussian mixture on the corners of the simplex, with L 2 loss, retention function \u03bd(r) = exp(\u2212r), and b 1 = b 2 = 50, n (t) = 1000. By construction, (1/3, 1/3, 1/3) is the fair parameter estimate.\nFigure 3 shows that ERM is highly unstable, with the only stable fixed points being the corners, where a single group dominates all others. The fair parameter estimate is an unstable fixed point for ERM, and any perturbation eventually results in a completely unfair parameter estimate. On the other hand, DRO has the reverse behavior, with the fair parameter estimate being the unique stable fixed point. ", "publication_ref": [], "figure_ref": ["fig_2"], "table_ref": []}, {"heading": "Experiments", "text": "We demonstrate the effectiveness of DRO on our motivating example (Figure 1) and human evaluation of a text autocomplete system on Amazon Mechanical Turk. In both cases, DRO controls the worst-case risk R T max over time steps and improves minority retention.", "publication_ref": [], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Simulated task", "text": "Recall the motivating example in Figure 1 which shows that logistic regression applied to a two-class classification problem is unstable and becomes pathologically unfair.\nThe data is constructed by drawing from a mixture of two Gaussians (groups) centered at (\u22121.5, 0) and (0, 1.5). The two groups are labeled according to the linear decision boundaries (\u22123/2, \u221a 3 2 \u2212 1/3) and (3/2, \u221a 3 2 \u2212 1/3) respectively such that classifying with x 2 > 0 is accurate, but the optimal linear classifier on one group achieves 50% accuracy on the other.\nAt each round we fit a logistic regression classifier using ERM or DRO and gradient descent, constraining the norm of the weight vector to 1. Our dynamics follow Definition 1 with \u03bd(x) = 1 \u2212 x, R as the zero-one loss, and b k = 1000. The DRO model is trained using the dual objective with logistic loss, and \u03b7 = 0.95, which was the optimal dual solution to \u03b1 min = 0.2. The results do not qualitatively change for choices of \u03b1 min < 0.5, and we show that we obtain control even for group sizes substantially smaller than 0.2 (Figure 6).\nFigure 5 shows that ERM is unstable and the minority group rapidly loses accuracy beyond 300 rounds on most runs. In contrast, DRO is stable, and maintains an accuracy of 0.8. This stability is due to the fact that the regularized loss for DRO prevents small losses in the minority fraction from amplifying, as we discuss in Proposition 4. Even when the minority fraction falls as low as 1%, the DRO loss ensures that the accuracy of this minority fraction remains at 75% accuracy (Figure 6).", "publication_ref": [], "figure_ref": ["fig_0", "fig_4", "fig_4"], "table_ref": []}, {"heading": "Autocomplete task", "text": "We now present a real-world, human evaluation of user retention and satisfaction on a text autocomplete task. The task consists of the prediction of next words in a corpus of tweets built from two estimated demographic groups, African Americans and White Americans (Blodgett et al., 2016). There are several distinguishing linguistic patterns between tweets from these groups, whose language dialects we henceforth refer to as African-American English (AAE) and Standard-American English (SAE), respectively, following the nomenclature in Blodgett et al. (2016). Our overall experimental design is to measure the retention rate \u03bd and risk R for various choices of demographic proportions (\u03b1 AAE , \u03b1 SAE ) and simulate the implied dynamics, since running a fully online experiment would be prohibitively expensive.\nFor both ERM and DRO, we train a set of five maximum likelihood bigram language models on a corpus with 366,361 tweets total and a f \u2208 {0.1, 0.4, 0.5, 0.6, 0.9} fraction of the tweets labeled as AAE. This results in 10 possible autocomplete systems a given Mechanical Turk user can be assigned to during a task.\nTo evaluate the retention and loss for AAE and SAE separately, a turk user is assigned 10 tweets from either the held out AAE tweets or SAE tweets, which they must replicate using a web-based keyboard augmented by the autocomplete system. This assignment of a turk user to a demographic group simulates the situation where a user from a particular demographic group attempts to use the autocomplete system to write a tweet. Details of the autocomplete task are included in the supplement.\nAfter completing the task, users were asked to fill out a survey which included a rank from 1 to 5 on their satisfaction with the task, and a yes/no question asking whether they would continue to use such a system. We assign 50 users to each of the two held out set types and each of the 10 autocomplete models, resulting in 1,000 users' feedback across autocomplete models and assigned demographics.\nThe response to whether a user would continue to use the autocomplete system provides samples \u03bd(R K (\u03b1)) with n = 366361 and each of possible demographic proportions \u03b1. The user satisfaction survey provides a surrogate for R K (\u03b1) at these same points. We interpolate \u03bd and R K to \u03b1 \u2208 [0, 1] via isotone regression which then allows us to simulate the user dynamics and satisfaction over time using Definition 1. We estimate variability in these estimates via bootstrap replicates on the survey responses.\nOur results in Figure 4 show an improvement in both minority satisfaction and retention rate due to DRO: we improve the median user satisfaction from 3.7 to 4.0 and retention from 0.7 to 0.85, while only slightly decreasing the SAE  satisfaction and retention. Implied user counts follow the same trend with larger differences between groups due to compounding.\nCounterintuitively, the minority group has higher satisfaction and retention under DRO. Analysis of long-form comments from Turkers suggest this is likely due to users valuing the model's ability to complete slang more highly than completion of common words and indicates a slight mismatch between our training loss and human satisfaction with an autocomplete system.", "publication_ref": ["b4", "b4"], "figure_ref": [], "table_ref": []}, {"heading": "Discussion", "text": "In this work we argued for a view of loss minimization as a distributive justice problem and showed that ERM often results in disparity amplification and unfairness. We demonstrate that DRO provides a upper bound on the risk incurred by minority groups and performs well in practice.\nOur proposed algorithm is straightforward to implement, and induces distributional robustness, which can be viewed as a benefit in and of itself.\nOur arguments against ERM and in favor of minority risk minimization mirror Rawls' arguments against utilitarianism, and thus inherit the critiques of Rawlsian distributive justice. Examples of such critiques are the focus on an abstract worst-off group rather than demographic groups or individuals (Altham, 1973), extreme risk-aversion (Mueller et al., 1974), and utilitarianism with diminishing returns as an alternative (Harsanyi, 1975). In this work, we do not address the debate on the correctness of Rawlsian justice (Rawls, 2001), and leave finding a suitable philosophical framework for loss minimization to future work.\nThere are two large open questions from our work. First, as fairness is fundamentally a causal question, observational approaches such as DRO can only hope to control limited aspects of fairness. The generality with which our algorithm can be applied also limits its ability to enforce fairness as a constraint, and thus our approach here is unsuitable for high-stakes fairness applications such as classifiers for loans, criminality, or admissions. In such problems the implied minorities from DRO may differ from well-specified demographic groups who are known to suffer from historical and societal biases. This gap arises due to looseness in the DRO bound (Hu et al., 2018), and could be mitigated using smoothness assumptions (Dwork et al., 2012).\nSecond, distributional robustness proposed here runs counter to classical robust estimation for rejecting outlier samples, as high loss groups created by an adversary can easily resemble a minority group. Adversarial or high-noise settings loosen the DRO upper bound substantially, and it is an open question whether it is possible to design algorithms which are both fair to unknown latent groups and robust.\nReproducibility: Code to generate results available on the CodaLab platform at https://bit.ly/2sFkDpE.", "publication_ref": ["b0", "b26", "b14", "b29", "b17", "b9"], "figure_ref": [], "table_ref": []}, {"heading": "A. Appendix", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A.1. Proof of Proposition 1", "text": "We prove the following more general result.\nProposition 5. Let \u03bb * = \u03a6(\u03bb * ) be a fixed point, and \u03b8 * = arg min \u03b8 E k \u03b1 * k P k [ (\u03b8; Z)] be the population minimizer. Define H R (\u03b1 * ) as the positive definite Hessian of the expected risk with \u03b1 * k \u221d \u03bb * k . Further, let \u2207L define the per-group parameter gradients at \u03b8 * ,\n\u2207L = \uf8ee \uf8ef \uf8f0 \u2207 \u03b8 E P1 [ (\u03b8; Z)]\n. . .\n\u2207 \u03b8 E P k [ (\u03b8; Z)] \uf8f9 \uf8fa \uf8fb .\n\u03bb * is stable whenever the absolute value of the maximum eigenvalue \u03c1 max obeys\n\u03c1 max diag(\u03bd(R(\u03b8(\u03bb * )))) \u2212 diag(\u03bb * \u03bd (R(\u03b8(\u03bb * ))\u2207LH R (\u03b1 * ) \u22121 \u2207L I k \u03bb * k \u2212 1\u03bb * ( k \u03bb * k ) 2 < 1.\nProof A necessary and sufficient condition for stability of a discrete time dynamical system is that the Jacobian of the forward map \u03a6 has eigenvalues with absolute value strictly less than 1.\nComputing the Jacobian we have:\nJ \u03a6 (\u03bb * ) = diag(\u03bd(R k (\u03bb * ))) + diag(\u03bb * \u03bd (R(\u03b8(\u03bb * ))))J R\u2022\u03b8\u2022\u03b1 * (\u03bb * ).\nNow we must compute the Jacobian of the risk with respect to the population fraction. To do this, we apply the chain rule and separately analyze three Jacobians:R with respect to \u03b8, \u03b8 with respect to \u03b1 * , and \u03b1 * with respect to \u03bb * By strong convexity of , J \u03b8 (\u03b1 * ) = \u2212H R (\u03b1 * ) \u22121 \u2207L .\nWhere H R (\u03b1 * ) \u22121 is the Hessian of the population risk and \u2207L is\n\u2207L = \uf8ee \uf8ef \uf8f0 \u2207 \u03b8 E P1 [ (\u03b8; Z)] . . . \u2207 \u03b8 E P k [ (\u03b8; Z)] \uf8f9 \uf8fa \uf8fb .\nThe Jacobian of the risks with respect to change in \u03b8 is\nJ R (\u03b8) = \u2207L.\nThe Jacobian of the population fraction with respect to n is\nJ \u03b1 * (\u03bb * ) = I k \u03bb * k \u2212 1\u03bb * ( k \u03bb * k ) 2\nBy the chain rule, we obtain the overall claim\nJ \u03a6 (\u03bb * ) = diag(\u03bd(R k (\u03bb * ))) \u2212 diag(\u03bb * \u03bd (R(\u03b8)))\u2207LH R (\u03b1 * ) \u22121 \u2207L I k \u03bb * k \u2212 1\u03bb * ( k \u03bb * k ) 2", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A.2. Proof of Corollary 2", "text": "Recall that the instability criteria is\n\u03c1 max diag(\u03bd(R(\u03b8(\u03bb * )))) \u2212 diag(\u03bb * \u03bd (R(\u03b8(\u03bb * ))\u2207LH R (\u03b1 * ) \u22121 \u2207L I k \u03bb * k \u2212 1\u03bb * ( k \u03bb * k ) 2 > 1.\nSetting \u03bd(R(\u03b8(\u03bb * ))) = \u03bd(R 1 ) and \u03bb * k = \u03bb * 1 we have,\n\u03c1 max \u2212 \u03bd (R 1 )\u2207LH R (\u03b1 * ) \u22121 \u2207L I/k \u2212 11 /k 2 > 1 \u2212 \u03bd(R 1 ).\nBy first order optimality conditions, and the fact that \u03bb * 1 . . . = \u03bb * k , \u2207L 1 = 0. Thus, collecting terms and noting \u03bd (x) < 0 by monotonicity of \u03bd, we have\n\u03c1 max \u2207LH R (\u03b1 * ) \u22121 \u2207L > 1 \u2212 \u03bd(R 1 ) \u2212\u03bd (R 1 )/k .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A.3. Generalization of Proposition 1 and Corollary 2", "text": "Consider the more general dynamics defined by h : (\u03bb, R) \u2192 R + which defines the evolution of the expected number of users.\nDefinition 3. Let \u03a6 be the update for the expected population size\n\u03bb (t+1) k := \u03a6(\u03bb (t) k ) = h(\u03bb (t) k , \u03bd(R k (\u03b8(\u03bb (t) )))), \u03b8(\u03bb (t) k ) = arg min \u03b8 E k \u03b1 (t) k P k [ (\u03b8; Z)].\nThen as long as h is differentiable in both arguments, we obtain an essentially identical result to before. . . .\n\u2207 \u03b8 E P k [ (\u03b8; Z)] \uf8f9 \uf8fa \uf8fb . \u03bb * is stable whenever \u03c1 max diag \u2202 \u2202\u03bb h(\u03bb * , R(\u03b8(\u03bb * ))) \u2212 diag \u2202 \u2202R h(\u03bb * , R(\u03b8(\u03bb * ))) \u2207LH R (\u03b1 * ) \u22121 \u2207L I k \u03bb * k \u2212 1\u03bb * ( k \u03bb * k ) 2 < 1.\nProof A necessary and sufficient condition for stability of a discrete time dynamical system is that the Jacobian of the forward map \u03a6 has eigenvalues with absolute value strictly less than 1.\nComputing the Jacobian via total derivatives we have\nJ \u03a6 (\u03bb * ) = diag \u2202 \u2202\u03bb h(\u03bb * , R(\u03b8(\u03bb * ))) + diag \u2202 \u2202R h(\u03bb * , R(\u03b8(\u03bb * ))) J R\u2022\u03b8\u2022p (\u03bb * ).\nThe Jacobian term remains identical to before, which completes the proof.\nThe Corollary follows from this derivation:\nCorollary 2 (Counterexample under symmetry). Let \u03bb * 1 = . . . \u03bb * k be a fixed point with R 1 = . . . R k , and define \u2202h \u2202\u03bb \u03bb=\u03bb * = \u2202 \u2202\u03bb h(\u03bb * 1 , R 1 ) and \u2202h \u2202R \u03bb=\u03bb * = \u2202 \u2202R h(\u03bb * 1 , R 1 ). For any strongly convex loss,\n\u03c1 max \u2207LH R (\u03b1 * ) \u22121 \u2207L > 1 \u2212 \u2202h \u2202\u03bb \u03bb=\u03bb * \u2212 \u2202h \u2202R \u03bb=\u03bb * k\u03bb * 1 .\nProof Recall that the instability criteria is\n\u03c1 max diag \u2202 \u2202\u03bb h(\u03bb * , R(\u03b8(\u03bb * ))) \u2212 diag \u2202 \u2202R h(\u03bb * , R(\u03b8(\u03bb * ))) \u2207LH R (\u03b1 * ) \u22121 \u2207L I k \u03bb * k \u2212 1\u03bb * ( k \u03bb * k ) 2 < 1. Let \u2202h \u2202\u03bb \u03bb=\u03bb * = \u2202 \u2202\u03bb h(\u03bb * 1 , R 1 (\u03b8(\u03bb * ))) and \u2202h \u2202R \u03bb=\u03bb * = \u2202 \u2202R h(\u03bb * 1 , R 1 (\u03b8(\u03bb * ))).\nThen following the same derivation as earlier and using the monotonicity of h in the second argument gives\n\u03c1 max \u2207LH R (\u03b1 * ) \u22121 \u2207L > 1 \u2212 \u2202h \u2202\u03bb \u03bb=\u03bb * \u2212 \u2202h \u2202R \u03bb=\u03bb * k\u03bb * 1 .\nThis is essentially in the same spirit as our earlier corollary, but requires further assumptions on h in order to interpret. Generally we expect \u2202h \u2202R to be on the order of \u03bb as long as risk affects users independently, and \u2202h \u2202\u03bb is upper bounded by the maximum implied retention rate.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A.4. Proof of Proposition 2", "text": "Since P k is a mixture component of P (\nP = \u03b1 k P k + \u2022 \u2022 \u2022 ), D \u03c7 2 P k ||P (t) = x P (t) k (x) P (t) (x) \u2212 1 2 P (t) (x)dx \u2264 x 1 \u03b1 (t) k \u2212 1 2 P (t) (x)dx = r k .\nWe just showed that P k \u2208 B(P, r k ). Since the sup is over all Q \u2208 B(P, r k ), the upper bound follows.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A.5. Proof of Proposition 4", "text": "By assumption,\n\u03b1 (t+1) k \u2265 \u03bb (t) \u03b1 min \u03bd(R k (\u03b8 (t) )) + b k k \u03bb (t) \u03b1 (t) k \u03bd(R k (\u03b8 (t) )) + b k .\nWe will show t) .\n\u03bb (t) \u03b1 min \u03bd(R k (\u03b8 (t) )) + b k k \u03bb (t) \u03b1 (t) k \u03bd(R k (\u03b8 (t) )) + b k > \u03b1 min , which is equivalent to \u03bd(R k (\u03b8 (t) )) \u2265 k \u03b1 (t) k \u03bd(R k (\u03b8 (t) )) + k b k \u2212 b k /\u03b1 min \u03bb(\nBy the assumption that \u03bd(R k (\u03b8 (t) )) < \u03bd max ,\nk \u03b1 (t) k \u03bd(R k (\u03b8 (t) )) + k b k \u2212 b k /\u03b1 min \u03bb (t) \u2264 \u03bd max + k b k \u03bb (t) 1 \u2212 b k \u03b1 min k b k . Using b k k b k \u2265 \u03b1 min and \u03bb (t) \u2264 b k 1\u2212\u03bdmax the above simplifies to k \u03b1 (t) k \u03bd(R k (\u03b8 (t) )) + k b k \u2212 b k /\u03b1 min \u03bb (t) \u2264 \u03bd max + (1 \u2212 \u03bd max ) 1 \u2212 b k \u03b1 min k b k .\nThus, a sufficient condition for our proposition is\nR k (\u03b8 (t) ) \u2264 \u03bd \u22121 1 \u2212 (1 \u2212 \u03bd max )b k \u03b1 min k b k .\n.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B. Amazon Mecahnical Turk task description", "text": "The Amazon Mechanical Turk experiment modeling user retention in an autocomplete system is detailed below. The experiment design consists of a total of 1000 HITs (\"Human Intelligence Tasks\" on Mechanical Turk) consisting of 2 user replicates \u00d7 5 values of \u03b1 \u00d7 2 models (DRO/ERM) \u00d7 25 sets of 10 tweets from the test set \u00d7 two test sets (AAE/SAE).\nFor each HIT the task, users are provided the description given in Figure 7 . Users are then taken to a separate autocomplete website, where they are asked to replicate 10 tweets using a software keyboard shown in Figure 8. In this interface, users must use the mouse and the software keyboard to type the target sentence, while also being given an autocomplete system for next word prediction based on the two models. The autocomplete system appears through a dropdown as users begin typing. After completion to the task, users are prompted to fill out a survey in Figures 9,10. The first four questions are quality control questions designed to identify Turkers who were low effort (empty entries in Q1/Q3) or inconsistent (Q2 inconsistent with Q4). Moreover, low-quality HITS could easily be identified due to a user's refusal to select either yes or no to Q5. We used this as our metric for filtering which users would be considered in the analysis. Q6 is our overall satisfaction metric shown in the main paper. ", "publication_ref": [], "figure_ref": ["fig_6"], "table_ref": []}, {"heading": "Fairness Without Demographics in Repeated Loss Minimization", "text": "In the following survey, please provide feedback on the suggestions and usefulness of the autocomplete system itself -NOT the interface. Any feedback regarding the interface can be states at the end.\n1. Please describe good aspects of the autocomplete word suggestions: 1. Please describe good aspects of the autocomplete word suggestions:\n2. On a scale of 1 (very unsatisfied) to 5 (extremely satisfied), how satisfied were you 2. On a scale of 1 (very unsatisfied) to 5 (extremely satisfied), how satisfied were you with the autocomplete suggestions? with the autocomplete suggestions?\n1 -very unsatisfied, did not find autocomplete system helpful 2 3 4 5 extremely satisfied, found autocomplete system helpful with task 3. What were some drawbacks you experienced with the autocomplete word 3. What were some drawbacks you experienced with the autocomplete word suggestions? suggestions?\n4. On a scale of 1 (not frustrated) to 5 (extremely frustrated), how frustrated were 4. On a scale of 1 (not frustrated) to 5 (extremely frustrated), how frustrated were you with the autocomplete suggestions? you with the autocomplete suggestions? Fairness Without Demographics in Repeated Loss Minimization 6. On a scale of 1 (very unhappy) to 5 (very happy), how happy were you with this 6. On a scale of 1 (very unhappy) to 5 (very happy), how happy were you with this hit? hit?\n1 -very unhappy 2 3 4 5 -very happy 7. Please provide feedback on the interface for this task: 7. Please provide feedback on the interface for this task:\n8. Please provide your unique code given at the end of the task: 8. Please provide your unique code given at the end of the task:\nFigure 10. Survey, page 2, Q2 measures satisfaction, Q7 is used to measure issues with the HIT, and Q8 is used to ensure users completed the autocomplete task", "publication_ref": [], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Acknowledgements: This work was funded by an Open", "text": "Fairness Without Demographics in Repeated Loss Minimization Philanthropy Project Award.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Instructions", "text": "We would like you to evaluate a text auto-completion system and your likelihood of using such a system. We will ask you to use a virtual keyboard with an auto-completion system to re-type 10 Tweets from Twitter, using the auto-complete to help you as you wish. DISCLAIMER: As we will be asking you to re-type real data from Twitter, the example texts in this system may contain offensive text and slang, despite automated filtering.\nAfter following the instructions below, please answer the questions in the survey:\n1. Click on the \"START TASK\" link after the instructions. 2. Next to the \"Please type this\" entry is the text you have to replicate using the keyboard below. Start by clicking the first letter of the text on the keyboard. 3. If there exists any auto-complete suggestions, they appear as a drop down menu. Use them in the way that is most helpful for you. 4. If you enter a wrong key, the mismatch will be displayed next to the \"Difference\" entry. Use this entry to guide you to complete replicating the text. 5. Once you have successfully replicated, the accept button will turn green. Click to receive the next tweet. 6. Repeat until you have successfully replicated 10 tweets. Then, cancel the window and fill out the survey questions below.\nWe will manually inspect every answer before accepting your work, and will be logging your entries on the web form to verify you correctly replicated 10 tweets. Incomplete survey answers will not be approved.\nIn addition, completion of the task will result in a unique code we ask you to enter at the end of this survey -no task will be approved without a correctly provided code. This task is expected to take 10 minutes to complete, but you will be allotted an hour.  ", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Rawls' difference principle", "journal": "Philosophy", "year": "1973", "authors": "J J Altham"}, {"ref_id": "b1", "title": "Deep speech 2 end to end speech recognition in English and mandarin", "journal": "", "year": "2016", "authors": "D Amodei"}, {"ref_id": "b2", "title": "Big data's disparate impact", "journal": "California Law Review", "year": "2016", "authors": "S Barocas; A D Selbst"}, {"ref_id": "b3", "title": "Robust solutions of optimization problems affected by uncertain probabilities", "journal": "Management Science", "year": "2013", "authors": "A Ben-Tal; D Den Hertog; A D Waegenaere; B Melenberg; G Rennen"}, {"ref_id": "b4", "title": "Demographic dialectal variation in social media: A case study of African-American English", "journal": "", "year": "2016", "authors": "S L Blodgett; L Green; B Connor"}, {"ref_id": "b5", "title": "A study of bias in recidivism prediciton instruments. Big Data", "journal": "", "year": "2017", "authors": "A Chouldechova"}, {"ref_id": "b6", "title": "Variance-based regularization with convex objectives", "journal": "", "year": "2016", "authors": "J C Duchi; H Namkoong"}, {"ref_id": "b7", "title": "Distributionally robust stochastic optimization: Minimax rates and asymptotics", "journal": "", "year": "2018", "authors": "J C Duchi; H Namkoong"}, {"ref_id": "b8", "title": "Statistics of robust optimization: A generalized empirical likelihood approach", "journal": "", "year": "2016", "authors": "J C Duchi; P W Glynn; H Namkoong"}, {"ref_id": "b9", "title": "Fairness through awareness", "journal": "", "year": "2012", "authors": "C Dwork; M Hardt; T Pitassi; O Reingold; R Zemel"}, {"ref_id": "b10", "title": "Certifying and removing disparate impact", "journal": "", "year": "2015", "authors": "M Feldman; S Friedler; J Moeller; C Scheidegger; S Venkatasubramanian"}, {"ref_id": "b11", "title": "Predictably unequal? the effects of machine learning on credit markets", "journal": "CEPR Discussion Papers", "year": "2017", "authors": "A Fuster; P Goldsmith-Pinkham; T Ramadorai; Walther ; A "}, {"ref_id": "b12", "title": "Report on the evaluation of 2d still-image face recognition algorithms", "journal": "", "year": "2011", "authors": "P J Grother; G W Quinn; P J Phillips"}, {"ref_id": "b13", "title": "Equality of opportunity in supervised learning", "journal": "", "year": "2016", "authors": "M Hardt; E Price; N Srebo"}, {"ref_id": "b14", "title": "Can the maximin principle serve as a basis for morality? a critique of john rawls's theory. The American Political Science Review", "journal": "", "year": "1975", "authors": "J C Harsanyi"}, {"ref_id": "b15", "title": "Calibration for the (computationallyidentifiable) masses", "journal": "", "year": "2017", "authors": "\u00da H\u00e9bert-Johnson; M P Kim; O Reingold; G N Rothblum"}, {"ref_id": "b16", "title": "Tagging performance correlates with age", "journal": "", "year": "2015", "authors": "D Hovy; A Sgaard"}, {"ref_id": "b17", "title": "Does distributionally robust supervised learning give robust classifiers", "journal": "", "year": "2018", "authors": "W Hu; G Niu; I Sato; M Sugiyama"}, {"ref_id": "b18", "title": "Fairness in reinforcement learning", "journal": "", "year": "2017", "authors": "S Jabbari; M Joseph; M Kearns; J Morgenstern; Roth ; A "}, {"ref_id": "b19", "title": "Rawlsian fairness for machine learning", "journal": "", "year": "2016", "authors": "M Joseph; M Kearns; J Morgenstern; S Neel; Roth ; A "}, {"ref_id": "b20", "title": "Incorporating dialectal variability for socially equitable language identification", "journal": "", "year": "2017", "authors": "D Jurgens; Y Tsvetkov; D Jurafsky"}, {"ref_id": "b21", "title": "Preventing fairness gerrymandering: Auditing and learning for subgroup fairness", "journal": "", "year": "2018", "authors": "M Kearns; S Neel; A Roth; Z S Wu"}, {"ref_id": "b22", "title": "Inherent trade-offs in the fair determination of risk scores", "journal": "", "year": "2017", "authors": "J Kleinberg; S Mullainathan; M Raghavan"}, {"ref_id": "b23", "title": "Quantifying input uncertainty in stochastic optimization", "journal": "IEEE", "year": "2015", "authors": "H Lam; E Zhou"}, {"ref_id": "b24", "title": "Delayed impact of fair machine learning", "journal": "", "year": "2018", "authors": "L T Liu; S Dean; E Rolf; M Simchowitz; M Hardt"}, {"ref_id": "b25", "title": "Regularity and complexity in dynamical systems", "journal": "Springer", "year": "2012", "authors": "A C Luo"}, {"ref_id": "b26", "title": "The utilitarian contract: A generalization of rawls' theory of justice", "journal": "Theory and Decision", "year": "1974", "authors": "D C Mueller; R D Tollison; T D Willet"}, {"ref_id": "b27", "title": "Stochastic gradient methods for distributionally robust optimization with fdivergences", "journal": "", "year": "2016", "authors": "H Namkoong; J C Duchi"}, {"ref_id": "b28", "title": "Variance regularization with convex objectives", "journal": "", "year": "2017", "authors": "H Namkoong; J C Duchi"}, {"ref_id": "b29", "title": "Justice as fairness: a restatement", "journal": "Harvard University Press", "year": "2001", "authors": "J Rawls"}, {"ref_id": "b30", "title": "", "journal": "Harvard University Press", "year": "2009", "authors": "J Rawls;  Theory;  Justice"}, {"ref_id": "b31", "title": "Academic performance prediction in a gender-imbalanced environment", "journal": "", "year": "2017", "authors": "P Sapiezynski; V Kassarnig; C Wilson; S Lehmann; A Mislove"}, {"ref_id": "b32", "title": "Gender and dialect bias in youtubes automatic captions", "journal": "", "year": "2017", "authors": "R Tatman"}, {"ref_id": "b33", "title": "Learning non-discriminatory predictors", "journal": "", "year": "2017", "authors": "B Woodworth; S Gunasekar; M I Ohannessian; N Srebro"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 .1Figure 1. An example online classification problem which begins fair, but becomes unfair over time.", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 2 .2Figure 2. Chi-square distributionally robust optimization (DRO) regularizes the losses (top panel) such that the minimum loss estimate is fair to both groups (bottom panel).", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 3 .3Figure3. Dynamics of repeated median estimation -shading indicates velocity at each point. ERM results in unfair parameter estimates that favor one group. DRO is strongly stable, with an equal proportion groups being the unique stable equilibrium.", "figure_data": ""}, {"figure_label": "45", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 4 .Figure 5 .45Figure 4. Inferred dynamics from a Mechanical Turk based evaluation of autocomplete systems. DRO increases minority (a) user satisfaction and (b) retention, leading to a corresponding increase in (c) user count. Error bars indicates bootstrap quartiles.", "figure_data": ""}, {"figure_label": "6", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 6 .6Figure 6. Classifier accuracy as a function of group imbalance. Dotted lines show accuracy on majority group.", "figure_data": ""}, {"figure_label": "6", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Proposition 6 .6Let \u03bb * = \u03a6(\u03bb * ) be a fixed point, and \u03b8 * = arg min \u03b8 E k \u03b1 * k P k [ (\u03b8; Z)] be the population minimizer. Define H R (\u03b1 * ) as the positive definite Hessian of the expected risk with \u03b1 * k \u221d \u03bb * k . Further, let \u2207L define the per-group parameter gradients at \u03b8 * , \u03b8 E P1 [ (\u03b8; Z)]", "figure_data": ""}, {"figure_label": "8", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Figure 8 .8Figure 8. Autocomplete task interface on Amazon mechanical turk.", "figure_data": ""}, {"figure_label": "9", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "Figure 9 .9Figure 9. Survey, page 1, Q1-Q4 are quality control verification questions. Q5 measures retention", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "R max (\u03b8) = max k\u2208[K] R k (\u03b8), R k (\u03b8) := E P k [ (\u03b8; Z)]. (1)", "formula_coordinates": [2.0, 315.5, 249.17, 225.94, 15.05]}, {"formula_id": "formula_1", "formula_text": "(t+1) based on n (t+1) \u223c Pois( k \u03bb (t+1) k", "formula_coordinates": [2.0, 307.44, 617.84, 234.0, 26.29]}, {"formula_id": "formula_2", "formula_text": "Z (t) i starting at \u03bb (0) k = b k is governed by: \u03bb (t+1) k := \u03bb (t) k \u03bd(R k (\u03b8 (t) )) + b k \u03b1 (t+1) k := \u03bb (t+1) k k \u2208[K] \u03bb (t+1) k n (t+1) := Pois( k \u03bb (t+1) k ) Z (t+1) 1 . . . Z (t+1) n (t+1) i.i.d. \u223c P (t+1) := k\u2208[K] \u03b1 (t+1) k P k .", "formula_coordinates": [3.0, 55.44, 67.53, 217.17, 144.77]}, {"formula_id": "formula_3", "formula_text": "Z (t) i", "formula_coordinates": [3.0, 208.84, 240.36, 16.75, 14.07]}, {"formula_id": "formula_4", "formula_text": "R T max (\u03b8 (0) , \u2022 \u2022 \u2022 , \u03b8 (T ) ) = max k,t R k (\u03b8 (t) ) .(2)", "formula_coordinates": [3.0, 86.15, 295.55, 203.29, 16.73]}, {"formula_id": "formula_5", "formula_text": "(t)", "formula_coordinates": [3.0, 112.52, 339.97, 9.24, 6.12]}, {"formula_id": "formula_6", "formula_text": "(t) k are stable, since if \u03b1 (t) k \u2192 0 as t \u2192 \u221e for some group k \u2208 [K],", "formula_coordinates": [3.0, 55.44, 389.78, 235.25, 28.7]}, {"formula_id": "formula_7", "formula_text": "b 0 = b 1 = n (0) 0 = n (0) 1 = 1000.", "formula_coordinates": [3.0, 325.21, 218.91, 135.36, 13.95]}, {"formula_id": "formula_8", "formula_text": "\u03bb (t+1) k := \u03a6(\u03bb (t) k ) = \u03bb (t) k \u03bd(R k (\u03b8(\u03bb (t) k ))) + b k , \u03b8(\u03bb (t) k ) = arg min \u03b8 E k \u03b1 (t) k P k [ (\u03b8; Z)].", "formula_coordinates": [3.0, 330.56, 656.23, 187.77, 40.04]}, {"formula_id": "formula_9", "formula_text": "\u2207L = \uf8ee \uf8ef \uf8f0 \u2207 \u03b8 E P1 [ (\u03b8 * ; Z)] . . . \u2207 \u03b8 E P k [ (\u03b8 * ; Z)] \uf8f9 \uf8fa \uf8fb .", "formula_coordinates": [4.0, 115.26, 271.96, 114.36, 42.39]}, {"formula_id": "formula_10", "formula_text": "\u03c1 max diag(\u03bd(R(\u03b8(\u03bb * )))) \u2212 diag(\u03bb * \u03bd (R(\u03b8(\u03bb * )) \u2207LH R (\u03b1 * ) \u22121 \u2207L I k \u03bb * k \u2212 1\u03bb * ( k \u03bb * k ) 2 > 1.", "formula_coordinates": [4.0, 65.4, 351.9, 214.07, 48.72]}, {"formula_id": "formula_11", "formula_text": "\u03bb * 1 = \u2022 \u2022 \u2022 = \u03bb * k and R 1 = \u2022 \u2022 \u2022 = R k , if", "formula_coordinates": [4.0, 55.44, 503.3, 171.31, 12.55]}, {"formula_id": "formula_12", "formula_text": "Corollary 1 (Counterexample under symmetry). Let \u03bb * 1 = \u2022 \u2022 \u2022 = \u03bb * k be a fixed point with R 1 = \u2022 \u2022 \u2022 = R k ,", "formula_coordinates": [4.0, 55.44, 554.71, 234.0, 24.51]}, {"formula_id": "formula_13", "formula_text": "\u03c1 max \u2207LH R (\u03b1 * ) \u22121 \u2207L > 1 \u2212 \u03bd(R 1 ) \u2212\u03bd (R 1 )/k . (3)", "formula_coordinates": [4.0, 81.12, 599.93, 208.32, 23.23]}, {"formula_id": "formula_14", "formula_text": "Q\u2208B(P,r) E Q [ (\u03b8; Z)].(4)", "formula_coordinates": [5.0, 158.11, 198.91, 131.33, 16.99]}, {"formula_id": "formula_15", "formula_text": "= k\u2208[K] \u03b1 k P k , we have R k (\u03b8) \u2264 R dro (\u03b8; r k ) for all \u03b8 \u2208 \u0398 where r k := (1/\u03b1 k \u2212 1)", "formula_coordinates": [5.0, 55.44, 337.9, 234.0, 24.88]}, {"formula_id": "formula_16", "formula_text": "r max := (1/\u03b1 min \u2212 1) 2 .", "formula_coordinates": [5.0, 55.44, 510.21, 95.3, 11.38]}, {"formula_id": "formula_17", "formula_text": "inf \u03b7\u2208R F (\u03b8; \u03b7) := C E P [ (\u03b8, Z) \u2212 \u03b7] 2 + 1 2 + \u03b7 (5)", "formula_coordinates": [5.0, 315.85, 90.85, 225.59, 22.88]}, {"formula_id": "formula_18", "formula_text": "C = 2(1/\u03b1 min \u2212 1) 2 + 1 1/2 .", "formula_coordinates": [5.0, 333.91, 127.36, 124.07, 13.61]}, {"formula_id": "formula_19", "formula_text": "minimize \u03b8\u2208\u0398 E P [ (\u03b8; Z) \u2212 \u03b7] 2 + .(6)", "formula_coordinates": [6.0, 113.89, 392.45, 175.55, 17.63]}, {"formula_id": "formula_20", "formula_text": "R max ( \u03b8 \u03b7 ) \u2264 R dro ( \u03b8 \u03b7 ; r max ) \u2264 F ( \u03b8 \u03b7 , \u03b7)", "formula_coordinates": [6.0, 91.73, 444.23, 161.42, 9.81]}, {"formula_id": "formula_21", "formula_text": "Definition 1. Let \u03b1 (t) k > \u03b1 min , b k k b k > \u03b1 min , \u03bb (t) := k \u03bb (t) k \u2264 k b k 1\u2212\u03bdmax , and \u03bd(R k (\u03b8 (t) )) < \u03bd max .", "formula_coordinates": [6.0, 307.16, 192.02, 236.02, 38.64]}, {"formula_id": "formula_22", "formula_text": "R k (\u03b8 (t) ) \u2264 \u03bd \u22121 1 \u2212 (1 \u2212 \u03bd max )b k \u03b1 min k b k , \u03b1 (t+1) k = \u03bb (t) \u03b1 (t) k \u03bd(R k (\u03b8 (t) )) + b k l \u03bb (t) \u03b1 (t) l \u03bd(R l (\u03b8 (t) )) + b l > \u03b1 min .", "formula_coordinates": [6.0, 329.96, 242.64, 188.97, 66.45]}, {"formula_id": "formula_23", "formula_text": "R dro (\u03b8 (t) ; r max ) \u2264 \u03bd \u22121 1 \u2212 (1 \u2212 \u03bd max )b k \u03b1 min k b k ,(7)", "formula_coordinates": [6.0, 322.51, 342.66, 218.93, 24.72]}, {"formula_id": "formula_24", "formula_text": "\u2207L = \uf8ee \uf8ef \uf8f0 \u2207 \u03b8 E P1 [ (\u03b8; Z)]", "formula_coordinates": [11.0, 243.55, 183.01, 98.48, 30.29]}, {"formula_id": "formula_25", "formula_text": "\u2207 \u03b8 E P k [ (\u03b8; Z)] \uf8f9 \uf8fa \uf8fb .", "formula_coordinates": [11.0, 278.56, 183.01, 74.78, 43.25]}, {"formula_id": "formula_26", "formula_text": "\u03c1 max diag(\u03bd(R(\u03b8(\u03bb * )))) \u2212 diag(\u03bb * \u03bd (R(\u03b8(\u03bb * ))\u2207LH R (\u03b1 * ) \u22121 \u2207L I k \u03bb * k \u2212 1\u03bb * ( k \u03bb * k ) 2 < 1.", "formula_coordinates": [11.0, 89.69, 259.51, 417.5, 26.31]}, {"formula_id": "formula_27", "formula_text": "J \u03a6 (\u03bb * ) = diag(\u03bd(R k (\u03bb * ))) + diag(\u03bb * \u03bd (R(\u03b8(\u03bb * ))))J R\u2022\u03b8\u2022\u03b1 * (\u03bb * ).", "formula_coordinates": [11.0, 161.31, 353.41, 274.27, 11.72]}, {"formula_id": "formula_28", "formula_text": "\u2207L = \uf8ee \uf8ef \uf8f0 \u2207 \u03b8 E P1 [ (\u03b8; Z)] . . . \u2207 \u03b8 E P k [ (\u03b8; Z)] \uf8f9 \uf8fa \uf8fb .", "formula_coordinates": [11.0, 243.55, 464.43, 109.78, 43.26]}, {"formula_id": "formula_29", "formula_text": "J R (\u03b8) = \u2207L.", "formula_coordinates": [11.0, 269.89, 542.93, 57.1, 9.68]}, {"formula_id": "formula_30", "formula_text": "J \u03b1 * (\u03bb * ) = I k \u03bb * k \u2212 1\u03bb * ( k \u03bb * k ) 2", "formula_coordinates": [11.0, 225.13, 587.08, 137.59, 26.31]}, {"formula_id": "formula_31", "formula_text": "J \u03a6 (\u03bb * ) = diag(\u03bd(R k (\u03bb * ))) \u2212 diag(\u03bb * \u03bd (R(\u03b8)))\u2207LH R (\u03b1 * ) \u22121 \u2207L I k \u03bb * k \u2212 1\u03bb * ( k \u03bb * k ) 2", "formula_coordinates": [11.0, 106.71, 645.2, 374.44, 26.31]}, {"formula_id": "formula_32", "formula_text": "\u03c1 max diag(\u03bd(R(\u03b8(\u03bb * )))) \u2212 diag(\u03bb * \u03bd (R(\u03b8(\u03bb * ))\u2207LH R (\u03b1 * ) \u22121 \u2207L I k \u03bb * k \u2212 1\u03bb * ( k \u03bb * k ) 2 > 1.", "formula_coordinates": [12.0, 89.69, 108.31, 417.5, 26.31]}, {"formula_id": "formula_33", "formula_text": "\u03c1 max \u2212 \u03bd (R 1 )\u2207LH R (\u03b1 * ) \u22121 \u2207L I/k \u2212 11 /k 2 > 1 \u2212 \u03bd(R 1 ).", "formula_coordinates": [12.0, 152.95, 169.92, 290.98, 11.72]}, {"formula_id": "formula_34", "formula_text": "\u03c1 max \u2207LH R (\u03b1 * ) \u22121 \u2207L > 1 \u2212 \u03bd(R 1 ) \u2212\u03bd (R 1 )/k .", "formula_coordinates": [12.0, 207.12, 238.84, 182.65, 23.22]}, {"formula_id": "formula_35", "formula_text": "\u03bb (t+1) k := \u03a6(\u03bb (t) k ) = h(\u03bb (t) k , \u03bd(R k (\u03b8(\u03bb (t) )))), \u03b8(\u03bb (t) k ) = arg min \u03b8 E k \u03b1 (t) k P k [ (\u03b8; Z)].", "formula_coordinates": [12.0, 206.27, 344.34, 184.33, 41.6]}, {"formula_id": "formula_36", "formula_text": "\u2207 \u03b8 E P k [ (\u03b8; Z)] \uf8f9 \uf8fa \uf8fb . \u03bb * is stable whenever \u03c1 max diag \u2202 \u2202\u03bb h(\u03bb * , R(\u03b8(\u03bb * ))) \u2212 diag \u2202 \u2202R h(\u03bb * , R(\u03b8(\u03bb * ))) \u2207LH R (\u03b1 * ) \u22121 \u2207L I k \u03bb * k \u2212 1\u03bb * ( k \u03bb * k ) 2 < 1.", "formula_coordinates": [12.0, 55.44, 470.63, 489.95, 97.61]}, {"formula_id": "formula_37", "formula_text": "J \u03a6 (\u03bb * ) = diag \u2202 \u2202\u03bb h(\u03bb * , R(\u03b8(\u03bb * ))) + diag \u2202 \u2202R h(\u03bb * , R(\u03b8(\u03bb * ))) J R\u2022\u03b8\u2022p (\u03bb * ).", "formula_coordinates": [12.0, 126.85, 633.47, 343.19, 22.31]}, {"formula_id": "formula_38", "formula_text": "\u03c1 max \u2207LH R (\u03b1 * ) \u22121 \u2207L > 1 \u2212 \u2202h \u2202\u03bb \u03bb=\u03bb * \u2212 \u2202h \u2202R \u03bb=\u03bb * k\u03bb * 1 .", "formula_coordinates": [13.0, 196.54, 103.49, 203.81, 29.56]}, {"formula_id": "formula_39", "formula_text": "\u03c1 max diag \u2202 \u2202\u03bb h(\u03bb * , R(\u03b8(\u03bb * ))) \u2212 diag \u2202 \u2202R h(\u03bb * , R(\u03b8(\u03bb * ))) \u2207LH R (\u03b1 * ) \u22121 \u2207L I k \u03bb * k \u2212 1\u03bb * ( k \u03bb * k ) 2 < 1. Let \u2202h \u2202\u03bb \u03bb=\u03bb * = \u2202 \u2202\u03bb h(\u03bb * 1 , R 1 (\u03b8(\u03bb * ))) and \u2202h \u2202R \u03bb=\u03bb * = \u2202 \u2202R h(\u03bb * 1 , R 1 (\u03b8(\u03bb * ))).", "formula_coordinates": [13.0, 55.44, 164.09, 489.95, 47.72]}, {"formula_id": "formula_40", "formula_text": "\u03c1 max \u2207LH R (\u03b1 * ) \u22121 \u2207L > 1 \u2212 \u2202h \u2202\u03bb \u03bb=\u03bb * \u2212 \u2202h \u2202R \u03bb=\u03bb * k\u03bb * 1 .", "formula_coordinates": [13.0, 196.54, 229.32, 203.81, 29.56]}, {"formula_id": "formula_41", "formula_text": "P = \u03b1 k P k + \u2022 \u2022 \u2022 ), D \u03c7 2 P k ||P (t) = x P (t) k (x) P (t) (x) \u2212 1 2 P (t) (x)dx \u2264 x 1 \u03b1 (t) k \u2212 1 2 P (t) (x)dx = r k .", "formula_coordinates": [13.0, 196.64, 373.8, 203.6, 100.64]}, {"formula_id": "formula_42", "formula_text": "\u03b1 (t+1) k \u2265 \u03bb (t) \u03b1 min \u03bd(R k (\u03b8 (t) )) + b k k \u03bb (t) \u03b1 (t) k \u03bd(R k (\u03b8 (t) )) + b k .", "formula_coordinates": [13.0, 216.5, 546.27, 163.88, 28.78]}, {"formula_id": "formula_43", "formula_text": "\u03bb (t) \u03b1 min \u03bd(R k (\u03b8 (t) )) + b k k \u03bb (t) \u03b1 (t) k \u03bd(R k (\u03b8 (t) )) + b k > \u03b1 min , which is equivalent to \u03bd(R k (\u03b8 (t) )) \u2265 k \u03b1 (t) k \u03bd(R k (\u03b8 (t) )) + k b k \u2212 b k /\u03b1 min \u03bb(", "formula_coordinates": [13.0, 55.08, 590.76, 354.55, 70.66]}, {"formula_id": "formula_44", "formula_text": "k \u03b1 (t) k \u03bd(R k (\u03b8 (t) )) + k b k \u2212 b k /\u03b1 min \u03bb (t) \u2264 \u03bd max + k b k \u03bb (t) 1 \u2212 b k \u03b1 min k b k . Using b k k b k \u2265 \u03b1 min and \u03bb (t) \u2264 b k 1\u2212\u03bdmax the above simplifies to k \u03b1 (t) k \u03bd(R k (\u03b8 (t) )) + k b k \u2212 b k /\u03b1 min \u03bb (t) \u2264 \u03bd max + (1 \u2212 \u03bd max ) 1 \u2212 b k \u03b1 min k b k .", "formula_coordinates": [13.0, 140.27, 693.38, 321.34, 27.01]}, {"formula_id": "formula_45", "formula_text": "R k (\u03b8 (t) ) \u2264 \u03bd \u22121 1 \u2212 (1 \u2212 \u03bd max )b k \u03b1 min k b k .", "formula_coordinates": [14.0, 217.92, 152.95, 161.03, 24.72]}], "doi": ""}