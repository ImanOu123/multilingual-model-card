{"title": "New Outer Bounds on the Marginal Polytope", "authors": "David Sontag; Tommi Jaakkola", "pub_date": "", "abstract": "We give a new class of outer bounds on the marginal polytope, and propose a cutting-plane algorithm for efficiently optimizing over these constraints. When combined with a concave upper bound on the entropy, this gives a new variational inference algorithm for probabilistic inference in discrete Markov Random Fields (MRFs). Valid constraints on the marginal polytope are derived through a series of projections onto the cut polytope. As a result, we obtain tighter upper bounds on the log-partition function. We also show empirically that the approximations of the marginals are significantly more accurate when using the tighter outer bounds. Finally, we demonstrate the advantage of the new constraints for finding the MAP assignment in protein structure prediction.", "sections": [{"heading": "Introduction", "text": "Graphical models such as Markov Random Fields (MRFs) have been successfully applied to a wide variety of fields, from computer vision to computational biology. From the point of view of inference, we are generally interested in two questions: finding the marginal probabilities of specific subsets of the variables, and finding the Maximum a Posteriori (MAP) assignment. Both of these require approximate methods.\nWe focus on a particular class of variational approximation methods that cast the inference problem as a non-linear optimization over the marginal polytope, the set of valid marginal probabilities. The selection of appropriate marginals from the marginal polytope is guided by the (non-linear) entropy function. Both the marginal polytope and the entropy are difficult to characterize in general, reflecting the hardness of exact inference calculations. Most message-passing algorithms for evaluating marginals, including belief propagation and tree-reweighted sum-product (TRW), operate instead within the local consistency polytope, characterized by pairwise consistent marginals. For general graphs, this is an outer bound of the marginal polytope. Various approximations have also been suggested for the entropy function. For example, in the TRW algorithm [10], the entropy is decomposed into a weighted combination of entropies of tree-structured distributions.\nOur goal here is to provide tighter outer bounds on the marginal polytope. We show how this can be achieved efficiently using a cutting-plane algorithm, iterating between solving a relaxed problem and adding additional constraints. Cutting-plane algorithms are a well-known technique for solving integer linear programs. The key to such approaches is to have an efficient separation algorithm which, given an infeasible solution, can quickly find a violated constraint, generally from a very large class of valid constraints on the set of integral solutions.\nThe motivation for our approach comes from the cutting-plane literature for the maximum cut problem. Barahona et al. [3] showed that the MAP problem in pairwise binary MRFs is equivalent to a linear optimization over the cut polytope, which is the convex hull of all valid graph cuts. Tighter relaxations were obtained by using a separation algorithm together with the cutting-plane methodology. We extend this work by deriving a new class of outer bounds on the marginal polytope for non-binary and non-pairwise MRFs. The key realization is that valid constraints can be constructed by a series of projections onto the cut polytope 1 . More broadly, we seek to highlight emerging connections between polyhedral combinatorics and probabilistic inference.", "publication_ref": ["b9", "b2", "b0"], "figure_ref": [], "table_ref": []}, {"heading": "Background", "text": "Markov Random Fields. Let x \u2208 \u03c7 n denote a random vector on n variables, where, for simplicity, each variable x i takes on the values in \u03c7 i = {0, 1, . . . , k \u2212 1}. The MRF is specified by a set of d real valued potentials or sufficient statistics \u03c6(x) = {\u03c6 k (x)} and a parameter vector \u03b8 \u2208 R d :\np(x; \u03b8) = exp { \u03b8, \u03c6(x) \u2212 A(\u03b8)}, A(\u03b8) = log x\u2208\u03c7 n exp { \u03b8, \u03c6(x) }\nwhere \u03b8, \u03c6(x) denotes the dot product of the parameters and the sufficient statistics. In pairwise MRFs, potentials are restricted to be at most over the edges in the graph. We assume that the potentials are indicator functions, i.e., \u03c6 i,s (x) = \u03b4(x i = s), and make use of the following notation:\n\u00b5 i;s = E \u03b8 [\u03c6 i;s (x)] = p(x i = s; \u03b8) and \u00b5 ij;st = E \u03b8 [\u03c6 ij;st (x)] = p(x i = s, x j = t; \u03b8).\nVariational inference. The inference task is to evaluate the mean vector \u00b5 = E \u03b8 [\u03c6(x)]. The log-partition function A(\u03b8), a convex function of \u03b8, plays a critical role in these calculations. In particular, we can write the log-partition function in terms of its Fenchel-Legendre conjugate [11]:\nA(\u03b8) = sup \u00b5\u2208M { \u03b8, \u00b5 \u2212 B(\u00b5)} ,(1)\nwhere B(\u00b5) = \u2212H(\u00b5) is the negative entropy of the distribution parameterized by \u00b5 and is also convex. M is the set of realizable mean vectors \u00b5 known as the marginal polytope. More precisely, 1) is precisely the desired mean vector corresponding to p(x; \u03b8).\nM := \u00b5 \u2208 R d | \u2203p(x) s.t. \u00b5 = E p [\u03c6(x)] . The value \u00b5 * \u2208 M that maximizes (\nBoth M and the entropy H(\u00b5) are difficult to characterize in general and have to be approximated. We call the resulting approximate mean vectors pseudomarginals. Mean field algorithms optimize over an inner bound on the marginal polytope (which is not convex) by restricting the marginal vectors to those coming from simpler, e.g., fully factored, distributions. The entropy can be evaluated exactly in this case (the distribution is simple). Alternatively, we can relax the optimization to be over an outer bound on the marginal polytope and also bound the entropy function.\nMost message passing algorithms for evaluating marginal probabilities obtain locally consistent beliefs so that the pseudomarginals over the edges agree with the singleton pseudomarginals at the nodes. The solution is therefore sought within the local marginal polytope\nLOCAL(G) = { \u00b5 \u2265 0 | s\u2208\u03c7i \u00b5 i;s = 1, t\u2208\u03c7j \u00b5 ij;st = \u00b5 i;s }(2)\nClearly, M \u2286 LOCAL(G) since true marginals are also locally consistent. For trees, M = LOCAL(G). Both LOCAL(G) and M have the same integral vertices for general graphs [11,6].\nBelief propagation can be seen as optimizing pseudomarginals over LOCAL(G) with a (non-convex) Bethe approximation to the entropy [15]. The tree-reweighted sum-product algorithm [10], on the other hand, uses a concave upper bound on the entropy, expressed as a convex combination of entropies corresponding to the spanning trees of the original graph. The log-determinant relaxation [12] is instead based on a semi-definite outer bound on the marginal polytope combined with a Gaussian approximation to the entropy function. Since the moment matrix M 1 (\u00b5) can be written as\nE \u03b8 [(1 x) T (1 x)]\nfor \u00b5 \u2208 M, the outer bound is obtained simply by requiring only that the pseudomarginals lie in SDEF 1\n(K n ) = {\u00b5 \u2208 R + | M 1 (\u00b5) 0}.\nMaximum a posteriori. The marginal polytope also plays a critical role in finding the MAP assignment. The problem is to find an assignment x \u2208 \u03c7 n which maximizes p(x; \u03b8), or equivalently:\nmax x\u2208\u03c7 n log p(x; \u03b8) = max x\u2208\u03c7 n \u03b8, \u03c6(x) \u2212 A(\u03b8) = sup \u00b5\u2208M \u03b8, \u00b5 \u2212 A(\u03b8)(3)\nwhere the log-partition function A(\u03b8) remains a constant and can be ignored. The last equality holds because the optimal value of the linear program is obtained at a vertex (integral solution). That is, when the MAP assignment x * is unique, the maximizing \u00b5 * is \u03c6(x * ).\nAlgorithm 1 Cutting-plane algorithm for probabilistic inference 1: OUTER \u2190 LOCAL(G) 2: repeat 3:\n\u00b5 * \u2190 argmax \u00b5\u2208OUTER { \u03b8, \u00b5 \u2212 B * (\u00b5)} 4:\nChoose projection graph G \u03c0 , e.g. single, k, or full 5:\nC \u2190 Find Violated Inequalities(G \u03c0 , \u03a8 \u03c0 (\u00b5 * ))\n6:\nOUTER \u2190 OUTER \u2229 C 7: until C = R d (did not find any violated inequalities) Cycle inequalities. The marginal polytope can be defined by the intersection of a large number of linear inequalities. We focus on inequalities beyond those specifying LOCAL(G), in particular the cycle inequalities [4,2,6]. Assume the variables are binary. Given an assignment x \u2208 {0, 1} n , (i, j) \u2208 E is cut if x i = x j . The cycle inequalities arise from the observation that a cycle must have an even (possibly zero) number of cut edges. Suppose we start at node i, where x i = 0. As we traverse the cycle, the assignment changes each time we cross a cut edge. Since we must return to x i = 0, the assignment can only change an even number of times. For a cycle C and any F \u2286 C such that |F | is odd, this constraint can be written as (i,j)\u2208C\\F \u03b4(\nx i = x j )+ (i,j)\u2208F \u03b4(x i = x j ) \u2265 1.\nSince this constraint is valid for all assignments x \u2208 {0, 1} n , it holds also in expectation. Thus\n(i,j)\u2208C\\F (\u00b5 ij;10 + \u00b5 ij;01 ) + (i,j)\u2208F (\u00b5 ij;00 + \u00b5 ij;11 ) \u2265 1 (4)\nis valid for any \u00b5 \u2208 M {0,1} , the marginal polytope of a binary pairwise MRF. For a chordless circuit C, the cycle inequalities are facets of M {0,1} [4]. They suffice to characterize M {0,1} for a graph G if and only if G has no K 4 -minor. Although there are exponentially many cycles and cycle inequalities for a graph, Barahona and Mahjoub [4,6] give a simple algorithm to separate the whole class of cycle inequalities.\nTo see whether any cycle inequality is violated, construct the undirected graph G = (V , E ) where V contains nodes i 1 and i 2 for each i \u2208 V , and for each (i, j) \u2208 E, the edges in E are: (i 1 , j 1 ) and (i 2 , j 2 ) with weight \u00b5 ij;10 + \u00b5 ij;01 , and (i 1 , j 2 ) and (i 2 , j 1 ) with weight \u00b5 ij;00 + \u00b5 ij;11 . Then, for each node i \u2208 V we find the shortest path in G from i 1 to i 2 . The shortest of all these paths will not use both copies of any node j (otherwise the path j 1 to j 2 would be shorter), and so defines a cycle in G and gives the minimum value of (i,j)\u2208C\\F (\u00b5 ij;10 + \u00b5 ij;01 )+ (i,j)\u2208F (\u00b5 ij;00 + \u00b5 ij;11 ). If this is less than 1, we have found a violated cycle inequality; otherwise, \u00b5 satisfies all cycle inequalities. Using Dijkstra's shortest paths algorithm with a Fibonacci heap [5], the separation problem can be solved in time O(n 2 log n + n|E|).", "publication_ref": ["b10", "b10", "b5", "b14", "b9", "b11", "b3", "b1", "b5", "b3", "b5", "b4"], "figure_ref": [], "table_ref": []}, {"heading": "Cutting-plane algorithm", "text": "Our main result is the proposed Algorithm 1 given above. The algorithm alternates between solving for an upper bound of the log-partition function (see Eq. 1) and tightening the outer bound on the marginal polytope by incorporating valid constraints that are violated by the current pseudomarginals. The projection graph (line 4) is not needed for binary pairwise MRFs and will be described in the next section. We start the algorithm (line 1) with the loose outer bound on the marginal polytope given by the local consistency constraints. Tighter initial constraints, e.g., M 1 (\u00b5) 0, are possible as well.\nThe separation algorithm returns a feasible set C given by the intersection of halfspaces, and we intersect this with OUTER to obtain a smaller feasible space, i.e. a tighter relaxation. The experiments in Section 5 use the separation algorithm for cycle inequalities. However, any class of valid constraints for the marginal polytope with an efficient separation algorithm may be used in line 5. Other examples besides the cycle inequalities include the odd-wheel and bicycle odd-wheel inequalities [6], and also linear inequalities that enforce positive semi-definiteness of M 1 (\u00b5). The cutting-plane algorithm is in effect optimizing the variational objective (Eq. 1) over a relaxation of the marginal polytope defined by the intersection of all inequalities that can be returned in line 5.\nAny entropy approximation B * (\u00b5) can be used so long as we can efficiently solve the optimization problem in line 3. The log-determinant and TRW entropy approximations have two appealing fea-Figure 1: Illustration of the projection \u03a8 \u03c0 for one edge (i, j) \u2208 E where \u03c7 i = {0, 1, 2} and \u03c7 j = {0, 1, 2, 3}. The projection graph G \u03c0 , shown on the right, has 3 partitions for i and 7 for j.\ntures. First, as upper bounds they permit the algorithm to be used for obtaining tighter upper bounds on the log-partition function. Second, the objective functions to be maximized are convex and can be solved efficiently using conditional gradient or other methods.\nWhen the algorithm terminates, we can use the last \u00b5 * vector as an approximation to the single node and edge marginals. The results given in Section 5 use this method. The algorithm for MAP is the same, excluding the entropy function in line 3; the optimization is simply a linear program. Since all integral vectors in the relaxation OUTER are extreme points of the marginal polytope, any integral \u00b5 * is the MAP assignment.", "publication_ref": ["b4", "b5"], "figure_ref": [], "table_ref": []}, {"heading": "Generalization to non-binary MRFs", "text": "In this section we give a new class of valid inequalities for the marginal polytope of non-binary and non-pairwise MRFs, and show how to efficiently separate this exponentially large set of inequalities.\nThe key theoretical idea is to project the marginal polytope onto different binary marginal polytopes. Aggregation and projection are well-known techniques in polyhedral combinatorics for obtaining valid inequalities [6]. Given a linear projection \u03a6(x) = Ax, any valid inequality c \u03a6(x) \u2264 b for \u03a6(x) also gives the valid inequality c Ax \u2264 b for x. We obtain new inequalities by aggregating the values of each variable.\nFor each variable i, let \u03c0 q i be a partition of its values into two non-empty sets, i.e., the map \u03c0 q i :\n\u03c7 i \u2192 {0, 1} is surjective. Let \u03c0 i = {\u03c0 1 i , \u03c0 2 i , .\n. .} be a collection of partitions of variable i. Define the projection graph G \u03c0 = (V \u03c0 , E \u03c0 ) so that there is a node for each \u03c0 q i \u2208 \u03c0 i , and nodes \u03c0 q i and \u03c0 r j are connected if (i, j) \u2208 E. We call the graph consisting of all possible variable partitions the full projection graph. In Figure 1 we show part of the full projection graph corresponding to one edge (i, j), where x i has three values and x j has four values. Intuitively, a partition for a variable splits its values into two clusters, resulting in a binary variable. For example, the (new) variable corresponding to the partition {0, 1}{2} of x i is 1 if x i = 2, and 0 otherwise. The following gives a projection of marginal vectors of non-binary MRFs onto the marginal polytope of the projection graph G \u03c0 , which has binary variables for each partition. Definition 1. The linear map \u03a8 \u03c0 takes \u00b5 \u2208 M and for each node\nv = \u03c0 q i \u2208 V \u03c0 as- signs \u00b5 v;1 = s\u2208\u03c7i s.t. \u03c0 q i (s)=1 \u00b5 i;s and for each edge e = (\u03c0 q i , \u03c0 r j ) \u2208 E \u03c0 assigns \u00b5 e;11 =\nsi\u2208\u03c7i,sj \u2208\u03c7j s.t. \u03c0 q i (si)=\u03c0 r j (sj )=1 \u00b5 ij;sisj . To construct valid inequalities for each projection we need to characterize the image space. Let M {0,1} (G \u03c0 ) denote the binary marginal polytope of the projection graph.", "publication_ref": ["b5"], "figure_ref": [], "table_ref": []}, {"heading": "Theorem 1. The image of the projection", "text": "\u03a8 \u03c0 is M {0,1} (G \u03c0 ), i.e. \u03a8 \u03c0 : M \u2192 M {0,1} (G \u03c0 ).\nProof. Since \u03a8 \u03c0 is a linear map, it suffices to show that, for every extreme point \u00b5 \u2208 M, \u03a8 \u03c0 (\u00b5) \u2208 M {0,1} (G \u03c0 ). The extreme points of M correspond one-to-one with assignments x \u2208 \u03c7 n . Given an extreme point \u00b5 \u2208 M and variable v = \u03c0 q i \u2208 V \u03c0 , define x (\u00b5) v = s\u2208\u03c7i s.t. \u03c0 q i (s)=1 \u00b5 i;s . Since \u00b5 is an extreme point, \u00b5 i;s = 1 for exactly one value s, which implies that x (\u00b5) \u2208 {0, 1} |V\u03c0| . Then,\n\u03a8 \u03c0 (\u00b5) = E[\u03c6(x (\u00b5))], showing that \u03a8 \u03c0 (\u00b5) \u2208 M {0,1} (G \u03c0 ).\nThis result allows valid inequalities for M {0,1} (G \u03c0 ) to carry over to M. In general, the projection \u03a8 \u03c0 will not be surjective. Suppose every variable has k values. The single projection graph, where |\u03c0 i | = 1 for all i, has one node per variable and is surjective. The full projection graph has O(2 k ) nodes per variable. A cutting-plane algorithm may begin by projecting onto a small graph, then expanding to larger graphs only after satisfying all inequalities given by the smaller one. The k\u2212projection graph G k = (V k , E k ) has k partitions per variable corresponding to each value versus all the other values.\nThese projections yield a new class of cycle inequalities for the marginal polytope. Consider a single projection graph G \u03c0 , a cycle C in G, and any F \u2286 C such that |F | is odd. Let \u03c0 i be the partition for node i. We obtain the following valid inequality for \u00b5 \u2208 M by applying the projection \u03a8 \u03c0 and the cycle inequality:\n(i,j)\u2208C\\F \u00b5 \u03c0 ij (x i = x j ) + (i,j)\u2208F \u00b5 \u03c0 ij (x i = x j ) \u2265 1,(5)\nwhere\n\u00b5 \u03c0 ij (x i = x j ) = si\u2208\u03c7i,sj \u2208\u03c7j s.t. \u03c0i(si) =\u03c0j (sj ) \u00b5 ij;sisj (6) \u00b5 \u03c0 ij (x i = x j ) = si\u2208\u03c7i,sj \u2208\u03c7j s.t. \u03c0i(si)=\u03c0j (sj ) \u00b5 ij;sisj .(7)\nIt is revealing to contrast ( 5) with (i,j)\u2208C\\F \u03b4(x i = x j ) + (i,j)\u2208F \u03b4(x i = x j ) \u2265 1. For x \u2208 \u03c7 n , the latter holds only for |F | = 1. We can only obtain the more general inequality by fixing a partition of each node's values. Theorem 2. For every single projection graph G \u03c0 and every cycle inequality arising from a chordless circuit C on G \u03c0 , \u2203\u00b5 \u2208 LOCAL(G)\\M such that \u00b5 violates that inequality.\nProof. For each variable i \u2208 V , choose s i , t i s.t. \u03c0 i (s i ) = 1 and \u03c0 i (t i ) = 0. Assign \u00b5 i;q = 0 for q \u2208 \u03c7 i \\{s i , t i }. Similarly, for every (i, j) \u2208 E, assign \u00b5 ij;qr = 0 for q \u2208 \u03c7 i \\{s i , t i } and r \u2208 \u03c7 j \\{s j , t j }. The polytope resulting from the projection of M onto the remaining values (e.g. \u00b5 i;si ) is isomorphic to M {0,1} for the graph G \u03c0 . Barahona and Mahjoub [4] showed that the cycle inequality on the chordless circuit C is facet-defining for M {0,1} . Since C is over \u2265 3 variables from G, this cannot be a facet of LOCAL(G). Let LOCAL {0,1} be the projection of LOCAL(G) onto the remaining values. Thus, \u2203\u00b5 \u2208 LOCAL {0,1} \\M {0,1} , and we can assign \u00b5 accordingly.\nNote that the theorem implies that the projected cycle inequalities are strictly tighter than LOCAL(G), but it does not characterize how much is gained.\nIf all n variables have k values, then there are O((2 k ) n ) different single projection graphs. However, since for every cycle inequality in the single projection graphs there is an equivalent cycle inequality in the full projection graph, it suffices to consider just the full projection graph. Thus, even though the projection is not surjective, the full projection graph, which has O(n2 k ) nodes, allows us to efficiently obtain a tighter relaxation than any combination of projection graphs would give. In particular, the separation problem for all cycle inequalities (5) for all single projection graphs, when we allow some additional valid inequalities for M (arising from the cycle using more than one partition for some variables), can now be solved in time O(poly(n, 2 k )).", "publication_ref": ["b3"], "figure_ref": [], "table_ref": []}, {"heading": "Related work.", "text": "In earlier work, Althaus et al. [1] analyze the GMEC polyhedron, which is equivalent to the marginal polytope. They use a similar value-aggregation technique to derive valid constraints from the triangle inequalities. Koster et al. [8] investigate the Partial Constraint Satisfaction Problem polytope, which is also equivalent to the marginal polytope. They used value-aggregation to show that a class of cycle inequalities (corresponding to Eq. 5 for |F | = 1) are valid for this polytope, and give an algorithm to separate the inequalities for a single cycle. Interestingly, both papers showed that these constraints are facet-defining.\nNon-pairwise Markov random fields. These results could be applied to non-pairwise MRFs by first projecting the marginal vector onto the marginal polytope of a pairwise MRF. More generally, suppose we include additional variables corresponding to the joint probability of a cluster of variables. We need to add constraints enforcing that all variables in common between two clusters have the same marginals. For pairwise clusters these are simply the usual local consistency constraints.\nWe can now apply the projections of the previous section, considering various partitions of each cluster variable, to obtain a tighter relaxation of the marginal polytope.  ", "publication_ref": ["b0", "b7"], "figure_ref": [], "table_ref": []}, {"heading": "Experiments", "text": "Computing marginals. We experimented with Algorithm 1 using both the log-determinant [12] and the TRW [10] entropy approximations. These trials are on Ising models, which are pairwise MRFs with x i \u2208 {\u22121, 1} and potentials \u03c6 i (x) = x i for i \u2208 V and \u03c6 ij (x) = x i x j for (i, j) \u2208 E. Although TRW can efficiently optimize over the spanning tree polytope, for these experiments we simply use a weighted distribution over spanning trees, where each tree's weight is the sum of the absolute value of its edge weights \u03b8 ij . The edge appearance probabilities for this distribution can be efficiently computed using the Matrix Tree Theorem [13]. We optimize the TRW objective with conditional gradient, using linear programming after each gradient step to project onto OUTER. We used the glpkmex and YALMIP optimization packages within Matlab, and wrote the separation algorithm for the cycle inequalities in Java.\nIn Figure 2 we show results for 10 node complete graphs with\n\u03b8 i \u223c U [\u22121, 1] and \u03b8 ij \u223c U [\u2212x, x],\nwhere the coupling strength is varied along the x-axis of the figure. For each data point we averaged the results over 100 trials. The y-axis shows the average 1 error of the single node marginals. These MRFs are highly coupled, and loopy belief propagation (not shown) with a .5 decay rate seldom converges. The TRW and log-determinant algorithms, optimizing over the local consistency polytope, give pseudomarginals only slightly better than loopy BP. Even adding the positive semi-definite constraint M 1 (\u00b5) 0, for which TRW must be optimized using conditional gradient and semidefinite programming for the projection step, does not improve the accuracy by much. However, both entropy approximations give significantly better pseudomarginals when used by our algorithm together with the cycle inequalities (see \"TRW + Cycle\" and \"Logdet + Cycle\" in the figures). For small MRFs, we can exactly represent the marginal polytope as the convex hull of its 2 n vertices. We found that the cycle inequalities give nearly as good accuracy as the exact marginal polytope (see \"TRW + Marg\" and \"Logdet + Marg\").\nOur work sheds some light on the relative value of the entropy approximation compared to the relaxation of the marginal polytope. When the MRF is weakly coupled, both entropy approximations do reasonably well using the local consistency polytope. This is not surprising: the limit of weak coupling is a fully disconnected graph, for which both the entropy approximation and the marginal polytope relaxation are exact. With the local consistency polytope, both entropy approximations get steadily worse as the coupling increases. In contrast, using the exact marginal polytope, we see a peak at \u03b8 = 2, then a steady improvement in accuracy as the coupling term grows. This occurs because the limit of strong coupling is the MAP problem, for which using the exact marginal polytope will give exact results. The interesting region is near the peak \u03b8 = 2, where the entropy term is neither exact nor outweighed by the coupling. Our algorithm seems to \"solve\" the part of the problem caused by the local consistency polytope relaxation: TRW's accuracy goes from .33 to .15, and log-determinant's accuracy from .17 to .076. The fact that neither entropy approximation can achieve accuracy below .07, even with the exact marginal polytope, motivates further research on improving this part of the approximation.   Next, we looked at the number of iterations (in terms of the loop in Algorithm 1) the algorithm takes before all cycle inequalities are satisfied. In each iteration we add to OUTER at most 2 n violated cycle inequalities, coming from the n shortest paths. In Figure 3 we show boxplots of the l 1 error of the single node marginals for both 10x10 grid MRFs (40 trials) and 20 node complete MRFs (10 trials). We also show whether the pseudomarginals are on the correct side of .5, which is important if we were doing prediction based on the results from approximate inference. The middle line gives the median, the boxes show the upper and lower quartiles, and the whiskers show the extent of the data. Iteration 1 corresponds to TRW with only the local consistency constraints. For the grid MRFs, all of the cycle inequalities were satisfied within 10 iterations. We observed the same convergence results on a 30x30 grid, although we could not assess the accuracy due to the difficulty of exact marginals calculation. For the complete graph MRFs, the algorithm took many more iterations before all cycle inequalities were satisfied.\nProtein side-chain prediction. We next applied our algorithm to the problem of predicting protein side-chain configurations. Given the 3-dimensional structure of a protein's backbone, the task is to predict the relative angle of each amino acid's side-chain. The angles are discretized into at most 45 values. Yanover et al. [14] showed that minimization of the Rosetta energy function corresponds to finding the MAP assignment of a non-binary pairwise MRF. They also showed that the treereweighted max-product algorithm [9] can be used to solve the LP relaxation given by LOCAL(G), and that this succeeds in finding the MAP assignment for 339 of the 369 proteins in their data set. However, the optimal solution to the LP relaxation for the remaining 30 proteins, arguably the most difficult of the proteins, is fractional.\nUsing the k-projection graph and projected cycle inequalities, we succeeded in finding the MAP assignment for all proteins except for the protein '1rl6'. We show in Figure 4 the number of cuttingplane iterations needed for each of the 30 proteins. In each iteration, we solve the LP relaxation, and, if the solution is not integral, run the separation algorithm to find violated inequalities. For the protein '1rl6', after 12 cutting-plane iterations, the solution was not integral, and we could not find any violated cycle inequalities using the k-projection graph. We then tried using the full projection graph, and found the MAP after just one (additional) iteration. Figure 4 shows one of the cycle inequalities (5) in the full projection graph that was found to be violated. The cut edges indicate the 3 edges in F . The violating \u00b5 had \u00b5 36;s = .1667 for s \u2208 {0, 1, 2, 3, 4, 5}, \u00b5 38;6 = .3333, \u00b5 38;4 = .6667, \u00b5 43;s = .1667 for s \u2208 {1, 2, 4, 5}, \u00b5 43;3 = .3333, and zero for all other values of these variables. This example shows that the relaxation given by the full projection graph is strictly tighter than that of the k-projection graph.\nThe commercial linear programming solver CPLEX 10.0 solves each LP relaxation in under 75 seconds. Using simple heuristics, the separation algorithm runs in seconds, and we find each protein's MAP assignment in under 11.3 minutes. Kingsford et al. [7] found, and we also observed, that CPLEX's branch-and-cut algorithm for solving integer linear programs also works well for these problems. One interesting future direction would be to combine the two approaches, using our new outer bounds within the branch-and-cut scheme. Our results show that the new outer bounds are powerful, allowing us to find the MAP solution for all of the MRFs, and suggesting that using them will also lead to significantly more accurate marginals for non-binary MRFs.", "publication_ref": ["b11", "b9", "b12", "b13", "b8", "b6"], "figure_ref": ["fig_1", "fig_3", "fig_4", "fig_4"], "table_ref": []}, {"heading": "Conclusion", "text": "The facial structure of the cut polytope, equivalently, the binary marginal polytope, has been wellstudied over the last twenty years. The cycle inequalities are just one of many large classes of valid inequalities for the cut polytope for which efficient separation algorithms are known. Our theoretical results can be used to derive outer bounds for the marginal polytope from any of the valid inequalities on the cut polytope. Our approach is particularly valuable because it takes advantage of the sparsity of the graph, and only uses additional constraints when they are guaranteed to affect the solution. An interesting open problem is to develop new message-passing algorithms which can incorporate cycle and other inequalities, to efficiently do the optimization within the cutting-plane algorithm.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgments", "text": "The authors thank Amir Globerson and David Karger for helpful discussions. This work was supported in part by the DARPA Transfer Learning program. D.S. was also supported by a National Science Foundation Graduate Research Fellowship.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "A combinatorial approach to protein docking with flexible side-chains", "journal": "", "year": "2000", "authors": "E Althaus; O Kohlbacher; H.-P Lenhof; P M\u00fcller"}, {"ref_id": "b1", "title": "On cuts and matchings in planar graphs", "journal": "Mathematical Programming", "year": "1993", "authors": "F Barahona"}, {"ref_id": "b2", "title": "An application of combinatorial optimization to statistical physics and circuit layout design", "journal": "Operations Research", "year": "1988", "authors": "F Barahona; M Gr\u00f6tschel; M Junger; G Reinelt"}, {"ref_id": "b3", "title": "On the cut polytope", "journal": "Mathematical Programming", "year": "1986", "authors": "F Barahona; A R Mahjoub"}, {"ref_id": "b4", "title": "Introduction to Algorithms", "journal": "MIT Press", "year": "2001", "authors": "T H Cormen; C E Leiserson; R L Rivest; C Stein"}, {"ref_id": "b5", "title": "Geometry of Cuts and Metrics", "journal": "Springer", "year": "1997", "authors": "M M Deza; M Laurent"}, {"ref_id": "b6", "title": "Solving and analyzing side-chain positioning problems using linear and integer programming", "journal": "Bioinformatics", "year": "2005", "authors": "C L Kingsford; B Chazelle; M Singh"}, {"ref_id": "b7", "title": "The partial constraint satisfaction problem: Facets and lifting theorems", "journal": "Operations Research Letters", "year": "1998", "authors": "A Koster; S Van Hoesel; A Kolen"}, {"ref_id": "b8", "title": "MAP estimation via agreement on trees: message-passing and linear programming", "journal": "IEEE Transactions on Information Theory", "year": "2005-11", "authors": "M Wainwright; T Jaakkola; A Willsky"}, {"ref_id": "b9", "title": "A new class of upper bounds on the log partition function", "journal": "IEEE Transactions on Information Theory", "year": "2005-07", "authors": "M Wainwright; T Jaakkola; A Willsky"}, {"ref_id": "b10", "title": "Graphical models, exponential families and variational inference", "journal": "", "year": "2003", "authors": "M Wainwright; M I Jordan"}, {"ref_id": "b11", "title": "Log-determinant relaxation for approximate inference in discrete Markov random fields", "journal": "IEEE Transactions on Signal Processing", "year": "2006-06", "authors": "M Wainwright; M I Jordan"}, {"ref_id": "b12", "title": "Introduction to Graph Theory", "journal": "Prentice Hall", "year": "2001", "authors": "D B West"}, {"ref_id": "b13", "title": "Linear programming relaxations and belief propagation -an empirical study", "journal": "JMLR Special Issue on Machine Learning and Large Scale Optimization", "year": "2006-09", "authors": "C Yanover; T Meltzer; Y Weiss"}, {"ref_id": "b14", "title": "Bethe free energy, Kikuchi approximations, and belief propagation algorithms", "journal": "", "year": "2001", "authors": "J Yedidia; W Freeman; Y Weiss"}], "figures": [{"figure_label": "2", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 2 :2Figure 2: Accuracy of single node marginals on 10 node complete graph (100 trials).", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 3 :3Figure 3: Accuracy of single node marginals with TRW entropy, \u03b8 i \u2208 U [\u22121, 1] and \u03b8 ij \u2208 U [\u22124, 4].", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 4 :4Figure 4: MAP for protein side-chain prediction with Rosetta energy function.", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "p(x; \u03b8) = exp { \u03b8, \u03c6(x) \u2212 A(\u03b8)}, A(\u03b8) = log x\u2208\u03c7 n exp { \u03b8, \u03c6(x) }", "formula_coordinates": [2.0, 159.52, 196.92, 292.96, 11.15]}, {"formula_id": "formula_1", "formula_text": "\u00b5 i;s = E \u03b8 [\u03c6 i;s (x)] = p(x i = s; \u03b8) and \u00b5 ij;st = E \u03b8 [\u03c6 ij;st (x)] = p(x i = s, x j = t; \u03b8).", "formula_coordinates": [2.0, 108.0, 247.81, 341.42, 9.65]}, {"formula_id": "formula_2", "formula_text": "A(\u03b8) = sup \u00b5\u2208M { \u03b8, \u00b5 \u2212 B(\u00b5)} ,(1)", "formula_coordinates": [2.0, 235.15, 302.82, 268.85, 10.59]}, {"formula_id": "formula_3", "formula_text": "M := \u00b5 \u2208 R d | \u2203p(x) s.t. \u00b5 = E p [\u03c6(x)] . The value \u00b5 * \u2208 M that maximizes (", "formula_coordinates": [2.0, 108.0, 340.62, 326.57, 11.23]}, {"formula_id": "formula_4", "formula_text": "LOCAL(G) = { \u00b5 \u2265 0 | s\u2208\u03c7i \u00b5 i;s = 1, t\u2208\u03c7j \u00b5 ij;st = \u00b5 i;s }(2)", "formula_coordinates": [2.0, 179.51, 480.89, 324.49, 11.15]}, {"formula_id": "formula_5", "formula_text": "E \u03b8 [(1 x) T (1 x)]", "formula_coordinates": [2.0, 119.78, 591.58, 73.77, 11.23]}, {"formula_id": "formula_6", "formula_text": "(K n ) = {\u00b5 \u2208 R + | M 1 (\u00b5) 0}.", "formula_coordinates": [2.0, 229.35, 602.54, 133.81, 11.23]}, {"formula_id": "formula_7", "formula_text": "max x\u2208\u03c7 n log p(x; \u03b8) = max x\u2208\u03c7 n \u03b8, \u03c6(x) \u2212 A(\u03b8) = sup \u00b5\u2208M \u03b8, \u00b5 \u2212 A(\u03b8)(3)", "formula_coordinates": [2.0, 168.43, 648.17, 335.57, 16.52]}, {"formula_id": "formula_8", "formula_text": "\u00b5 * \u2190 argmax \u00b5\u2208OUTER { \u03b8, \u00b5 \u2212 B * (\u00b5)} 4:", "formula_coordinates": [3.0, 112.98, 117.71, 199.69, 21.28]}, {"formula_id": "formula_9", "formula_text": "x i = x j )+ (i,j)\u2208F \u03b4(x i = x j ) \u2265 1.", "formula_coordinates": [3.0, 354.46, 274.47, 149.54, 11.15]}, {"formula_id": "formula_10", "formula_text": "(i,j)\u2208C\\F (\u00b5 ij;10 + \u00b5 ij;01 ) + (i,j)\u2208F (\u00b5 ij;00 + \u00b5 ij;11 ) \u2265 1 (4)", "formula_coordinates": [3.0, 191.01, 306.35, 312.99, 20.53]}, {"formula_id": "formula_11", "formula_text": "\u03c7 i \u2192 {0, 1} is surjective. Let \u03c0 i = {\u03c0 1 i , \u03c0 2 i , .", "formula_coordinates": [4.0, 108.0, 435.26, 183.93, 12.32]}, {"formula_id": "formula_12", "formula_text": "v = \u03c0 q i \u2208 V \u03c0 as- signs \u00b5 v;1 = s\u2208\u03c7i s.t. \u03c0 q i (s)=1 \u00b5 i;s and for each edge e = (\u03c0 q i , \u03c0 r j ) \u2208 E \u03c0 assigns \u00b5 e;11 =", "formula_coordinates": [4.0, 108.0, 536.06, 396.0, 26.74]}, {"formula_id": "formula_13", "formula_text": "\u03a8 \u03c0 is M {0,1} (G \u03c0 ), i.e. \u03a8 \u03c0 : M \u2192 M {0,1} (G \u03c0 ).", "formula_coordinates": [4.0, 273.48, 613.15, 200.13, 9.96]}, {"formula_id": "formula_14", "formula_text": "\u03a8 \u03c0 (\u00b5) = E[\u03c6(x (\u00b5))], showing that \u03a8 \u03c0 (\u00b5) \u2208 M {0,1} (G \u03c0 ).", "formula_coordinates": [4.0, 108.0, 687.3, 241.85, 9.96]}, {"formula_id": "formula_15", "formula_text": "(i,j)\u2208C\\F \u00b5 \u03c0 ij (x i = x j ) + (i,j)\u2208F \u00b5 \u03c0 ij (x i = x j ) \u2265 1,(5)", "formula_coordinates": [5.0, 203.03, 192.77, 300.97, 22.6]}, {"formula_id": "formula_16", "formula_text": "\u00b5 \u03c0 ij (x i = x j ) = si\u2208\u03c7i,sj \u2208\u03c7j s.t. \u03c0i(si) =\u03c0j (sj ) \u00b5 ij;sisj (6) \u00b5 \u03c0 ij (x i = x j ) = si\u2208\u03c7i,sj \u2208\u03c7j s.t. \u03c0i(si)=\u03c0j (sj ) \u00b5 ij;sisj .(7)", "formula_coordinates": [5.0, 195.86, 231.75, 308.14, 52.54]}, {"formula_id": "formula_17", "formula_text": "\u03b8 i \u223c U [\u22121, 1] and \u03b8 ij \u223c U [\u2212x, x],", "formula_coordinates": [6.0, 360.7, 432.15, 143.3, 9.65]}], "doi": ""}