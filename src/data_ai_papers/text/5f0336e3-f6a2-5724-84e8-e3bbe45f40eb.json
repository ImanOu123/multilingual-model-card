{"title": "Real-Time Tracking of Non-Rigid Objects using Mean Shift", "authors": "Dorin Comaniciu; Visvanathan Ramesh; Peter Meer", "pub_date": "", "abstract": "A new method for real-time tracking of non-rigid objects seen from a moving camera i s p r oposed. The central computational module is based on the mean shift iterations and nds the most probable target position in the current frame. The dissimilarity between the target model (its color distribution) and the target candidates is expressed by a metric derived f r om the Bhattacharyya coe cient. The theoretical analysis of the approach shows that it relates to the Bayesian framework while providing a practical, fast and e cient solution. The capability of the tracker to handle in real-time partial occlusions, signi cant clutter, and target scale variations, is demonstrated for several image sequences.", "sections": [{"heading": "Introduction", "text": "The e cient tracking of visual features in complex environments is a challenging task for the vision community. Real-time applications such as surveillance and monitoring 10], perceptual user interfaces 4], smart rooms 16,28], and video compression 12] all require the ability t o t r a c k m o ving objects. The computational complexity of the tracker is critical for most applications, only a small percentage of a system resources being allocated for tracking, while the rest is assigned to preprocessing stages or to high-level tasks such as recognition, trajectory interpretation, and reasoning 24].\nThis paper presents a new approach to the real-time tracking of non-rigid objects based on visual features such as color and/or texture, whose statistical distributions characterize the object of interest. The proposed tracking is appropriate for a large variety of objects with di erent color/texture patterns, being robust to partial occlusions, clutter, rotation in depth, and changes in camera position. It is a natural application to motion analysis of the mean shift procedure introduced earlier 6, 7]. The mean shift iterations are employed to nd the target candidate that is the most similar to a given target model, with the similarity being expressed by a metric based on the Bhattacharyya coe cient. Various test sequences showed the superior tracking performance, obtained with low computational complexity.\nThe paper is organized as follows. Section 2 presents and extends the mean shift property. Section 3 introduces the metric derived from the Bhattacharyya coefcient. The tracking algorithm is developed and analyzed in Section 4. Experiments and comparisons are given in Section 5, and the discussions are in Section 6.", "publication_ref": ["b15", "b27"], "figure_ref": [], "table_ref": []}, {"heading": "Mean Shift Analysis", "text": "We de ne next the sample mean shift, introduce the iterative mean shift procedure, and present a new theorem showing the convergence for kernels with convex and monotonic pro les. For applications of the mean shift property in low level vision ( ltering, segmentation) see 6].", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Sample Mean Shift", "text": "Given a set fx i g i=1:::n of n points in the ddimensional space R d , the multivariate kernel density estimate with kernel K(x) and window radius (bandwidth) h, computed in the point x is given b\u0177\nf(x) = 1 nh d n X i=1 K x ; x i h : (1)\nThe minimization of the average global error between the estimate and the true density yields the multivariate Epanechnikov k ernel 25, p.139]\nK E (x) = 1 2 c ;1 d (d + 2)(1 ; k xk 2 ) if kxk < 1 0 otherwise (2)\nwhere c d is the volume of the unit d-dimensional sphere.\nAnother commonly used kernel is the multivariate normal K N (x) = ( 2 ) ;d=2 exp ; 1 2 kxk 2 :\n(3)\nLet us introduce the pro le of a kernel K as a function k : 0 1) ! R such that K(x) = k(kxk 2 ). For example, according to (2) the Epanechnikov pro le is\nk E (x) = 1 2 c ;1 d (d + 2)(1 ; x) if x < 1 0\notherwise (4) and from (3) the normal pro le is given by k N (x) = ( 2 ) ;d=2 exp ; 1 2 x :\n(5) Employing the pro le notation we can write the density estimate (1) a\u015d\nf K (x) = 1 nh d n X i=1 k x ; x i h 2 ! : (6)\nWe denote g(x) = ;k 0 (x) (7) assuming that the derivative of k exists for all x 2 0 1), except for a nite set of points. A kernel G can be de ned as\nG(x) = C g (kxk 2 ) (8\n)\nwhere C is a normalization constant. Then, by taking the estimate of the density gradient as the gradient o f the density estimate we h a v\u00ea\nrf K (x) r f K (x) = 2 nh d+2 n X i=1 (x ; x i ) k 0 x ; x i h 2 ! = 2 nh d+2 n X i=1 (x i ; x) g x ; x i h 2 ! = 2 nh d+2 \" n X i=1 g x ; x i h 2 ! # 2 4 P n i=1 x i g x;xi h 2 P n i=1 g x;xi h 2 ;x 3 5 (9)\nwhere P n i=1 g x;xi h 2 can be assumed to be nonzero. Note that the derivative of the Epanechnikov pro le is the uniform pro le, while the derivative o f t h e normal pro le remains a normal.\nThe last bracket in ( 9) contains the sample mean shift vector M h G (x) \nExpression (13) shows that the sample mean shift vector obtained with kernel G is an estimate of the normalized density gradient obtained with kernel K. This is a more general formulation of the property rst remarked by F ukunaga 15, p . 535].", "publication_ref": ["b6", "b12"], "figure_ref": [], "table_ref": []}, {"heading": "A Su cient Convergence Condition", "text": "The mean shift procedure is de ned recursively by Theorem 1 If the kernel K has a convex and monotonic decreasing pro le and the kernel G is de ned according to (7) and (8), the sequences ( 14) and (15) are convergent.\nThe Theorem 1 generalizes the convergence shown in 6], where K was the Epanechnikov kernel, and G the uniform kernel. Its proof is given in the Appendix.\nNote that Theorem 1 is also valid when we associate to each d a t a p o i n t x i a positive w eight w i .", "publication_ref": ["b6", "b7"], "figure_ref": [], "table_ref": []}, {"heading": "Bhattacharyya Coe cient Based Metric for Target Localization", "text": "The task of nding the target location in the current frame is formulated as follows. The feature z representing the color and/or texture of the target model is assumed to have a density function q z , while the target candidate centered at location y has the feature distributed according to p z (y). The problem is then to nd the discrete location y whose associated density p z (y) is the most similar to the target density q z .\nTo de ne the similarity measure we t a k e i n to account that the probability of classi cation error in statistical hypothesis testing is directly related to the similarity of the two distributions. The larger the probability o f error, the more similar the distributions. Therefore, (contrary to the hypothesis testing), we formulate the target location estimation problem as the derivation of the estimate that maximizes the Bayes error associated with the model and candidate distributions. For the moment, we assume that the target has equal prior probability to be present a t a n y location y in the neighborhood of the previously estimated location.\nAn entity closely related to the Bayes error is the Bhattacharyya coe cient, whose general form is dened by 1 9 ] (y) p(y) q ] = Z p p z (y)q z dz : (16) Properties of the Bhattacharyya coe cient such a s i t s relation to the Fisher measure of information, quality of the sample estimate, and explicit forms for various distributions are given in 11, 1 9 ]. Our interest in expression ( 16) is, however, motivated by its near optimality given by the relationship to the Bayes error. Indeed, let us denote by and two sets of parameters for the distributions p and q and by = ( p q ) a set of prior probabilities. If the value of ( 16) is smaller for the set than for the set , it can be proved 19] that, there exists a set of priors for which the error probability for the set is less than the error probability for the set . In addition, starting from (16) upper and lower error bounds can be derived for the probability of error.\nThe derivation of the Bhattacharyya coe cient from sample data involves the estimation of the densities p and q, for which w e employ the histogram formulation.\nAlthough not the best nonparametric density estimate 25], the histogram satis es the low computational cost imposed by real-time processing. We estimate the dis- \nThe geometric interpretation of ( 17) is the cosine of the angle between the m-dimensional, unit vectors  Target Candidates Let fx i g i=1:::n h be the pixel locations of the target candidate, centered at y in the current frame. Using the same kernel pro le k, but with radius h, the probability of the color u in the target candidate is given b\u0177\np u (y) = C h n h X i=1 k y ; x i h 2 ! b(x i ) ; u] (21)\nwhere C h is the normalization constant. The radius of the kernel pro le determines the number of pixels (i.e., the scale) of the target candidate. By imposing the condition that\nP m u=1p u = 1 w e obtain C h = 1 P n h i=1 k(k y;xi h k 2 ) : (22)\nNote that C h does not depend on y, since the pixel locations x i are organized in a regular lattice, y being one of the lattice nodes. Therefore, C h can be precalculated for a given kernel and di erent v alues of h.", "publication_ref": ["b15", "b15"], "figure_ref": [], "table_ref": []}, {"heading": "Distance Minimization", "text": "According to Section 3, the most probable location y of the target in the current frame is obtained by minimizing the distance (18), which is equivalent t o m a x imizing the Bhattacharyya coe cient^ (y). The search for the new target location in the current frame starts at the estimated location\u0177 0 of the target in the previous frame. Thus, the color probabilities fp u (\u0177 0 )g u=1:::m of the target candidate at location\u0177 0 in the current frame have to be computed rst. Using Taylor expansion around the valuesp u (\u0177 0 ), the Bhattacharyya c oe cient ( 1  The tracking consists in running for each frame the optimization algorithm described above. Thus, given the target model, the new location of the target in the current frame minimizes the distance (18) in the neighborhood of the previous location estimate. 4", "publication_ref": ["b17", "b17", "b3"], "figure_ref": [], "table_ref": []}, {"heading": ".3 Scale Adaptation", "text": "The scale adaptation scheme exploits the property of the distance (18) to be invariant to changes in the object scale. We simply modify the radius h of the kernel pro le with a certain fraction (we used 10%), let the tracking algorithm to converge again, and choose the radius yielding the largest decrease in the distance (18). An IIR lter is used to derive the new radius based on the current measurements and old radius.", "publication_ref": ["b17", "b17"], "figure_ref": [], "table_ref": []}, {"heading": "Experiments", "text": "The proposed method has been applied to the task of tracking a football player marked by a hand-drawn ellipsoidal region ( rst image of Figure 1). The sequence has 154 frames of 352 240 pixels each and the initial normalization constants (determined from the size of the target model) were (h x h y ) = (71 53).\nThe Epanechnikov pro le (4) has been used for histogram computation, therefore, the mean shift iterations were computed with the uniform pro le. The target histogram has been derived in the RGB space with 32 32 32 bins. The algorithm runs comfortably at 30 fps on a 600 MHz PC, Java implementation.\nThe tracking results are presented in Figure 1. The mean shift based tracker proved to be robust to partial occlusion, clutter, distractors (frame 140 in Figure 1), and camera motion. Since no motion model has been assumed, the tracker adapted well to the nonstationary character of the player's movements, which alternates abruptly between slow and fast action. In addition, the intense blurring present in some frames and due to the camera motion, did not in uence the tracker performance (frame 150 in Figure 1). The same e ect, however, can largely perturb contour based trackers.    1. The surface is asymmetric, due to the player colors that are similar to the target. Four mean shift iterations were necessary for the algorithm to converge from the initial location (circle).\nTo demonstrate the e ciency of our approach, Figure 3 presents the surface obtained by computing the Bhattacharyya coe cient for the rectangle marked in Figure 1, frame 105. The target model (the selected elliptical region in frame 30) has been compared with the target candidates obtained by s w eeping the elliptical region in frame 105 inside the rectangle. While most of the tracking approaches based on regions 3, 1 4 , 2 1 ] must perform an exhaustive search in the rectangle to nd the maximum, our algorithm converged in four iterations as shown in Figure 3. Note that since the basin of attraction of the mode covers the entire window, the correct location of the target would have been reached also from farther initial points. An optimized computation of the exhaustive s e a r c h of the mode 13] has a much larger arithmetic complexity, depending on the chosen search area.\nThe new method has been applied to track people on subway platforms. The camera being xed, additional geometric constraints and also background subtraction can be exploited to improve the tracking process. The following sequences, however, have been processed with the algorithm unchanged.\nA rst example is shown in Figure 4, demonstrating the capability of the tracker to adapt to scale changes. The sequence has 187 frames of 320 240 pixels each and the initial normalization constants were (h x h y ) = (23 37).\nFigure 5 presents six frames from a 2 minute sequence showing the tracking of a person from the moment she enters the subway platform till she gets on the train ( 3600 frames). The tracking performance is remarkable, taking into account t h e l o w quality o f t h e processed sequence, due to the compression artifacts. A thorough evaluation of the tracker, however, is subject to our current w ork.\nThe minimum value of the distance (18) for each frame is shown in Figure 6. The compression noise determined the distance to increase from 0 (perfect match) to a stationary value of about 0:3. Signi cant deviations from this value correspond to occlusions generated by other persons or rotations in depth of the target. The large distance increase at the end signals the complete occlusion of the target.", "publication_ref": ["b17"], "figure_ref": ["fig_6", "fig_6", "fig_6", "fig_6", "fig_6", "fig_5", "fig_6", "fig_5", "fig_3", "fig_12", "fig_13"], "table_ref": []}, {"heading": "Discussion", "text": "By exploiting the spatial gradient of the statistical measure (18) the new method achieves real-time tracking performance, while e ectively rejecting background clutter and partial occlusions.\nNote that the same technique can be employed to derive the measurement vector for optimal prediction schemes such as the (Extended) Kalman lter 1, p.56, 106], or multiple hypothesis tracking approaches 5, 9, 1 7 , 18]. In return, the prediction can determine the priors (de ning the presence of the target in a given neighborhood) assumed equal in this paper. This connection is however beyond the scope of this paper. A patent application has been led covering the tracking algorithm together with the Kalman extension and various applications 29].\nWe nally observe that the idea of centroid computation is also employed in 22]. The mean shift was used for tracking human faces 4], by projecting the histogram of a face model onto the incoming frame. However, the direct projection of the model histogram onto the new frame can introduce a large bias in the estimated location of the target, and the resulting measure is scale variant. Gradient based region tracking has been formulated in 2] b y minimizing the energy of the deformable region, but no real-time claims were made.", "publication_ref": ["b17"], "figure_ref": [], "table_ref": []}, {"heading": "APPENDIX P r o o f o f T h e o r e m 1", "text": "Since n is nite the sequencef K is bounded, therefore, it is su cient t o s h o w thatf K is strictly monotonic increasing, i.e., if y j 6 = y j+1 thenf K (j) <f K (j + 1 ) , for all j = 1 2 : : : . By assuming without loss of generality that y j = 0 we can writ\u00ea f K (j + 1 ) ;f K (j) =  The convexity of the pro le k implies that k(x 2 ) k(x 1 ) + k 0 (x 1 )(x 2 ; x 1 ) (A.2) for all x 1 x 2 2 0 1), x 1 6 = x 2 , and since k 0 = ;g, t h e inequality (A. Since k is monotonic decreasing we have ;k 0 (x) g(x) 0 for all x 2 0 1). The sum P n i=1 g xi h 2 is strictly positive, since it was assumed to be nonzero in the de nition of the mean shift vector (10). Thus, as long as y j+1 6 = y j = 0, the right term of (A.5) is strictly positive, i.e.,f K (j + 1 ) ;f K (j) > 0. Consequently, t h e sequencef K is convergent.\nTo p r o ve the convergence of the sequence y j j=1 2::: we rewrite (A.5) but without assuming that y j = 0.\nAfter some algebra we h a v\u00ea f K (j+1);f K (j) 1 nh d+2 ky j+1 ;y j k 2 n X i=1 g y j ;x i h 2 ! (A.6) Sincef K (j + 1) ;f K (j) converges to zero, (A.6) implies that ky j+1 ; y j k also converges to zero, i.e., y j j=1 2::: is a Cauchy sequence. This completes the proof, since any C a u c hy sequence is convergent i n t h e Euclidean space.\nProof that the distance d(p q) = p 1 ; (p q) is a metric\nThe proof is based on the properties of the Bhattacharyya coe cient (17) If we x the points p and q , and the angle between p and r , the left side of inequality (A.9) is minimized when the vectors p , q , and r lie in the same plane. Thus, the inequality (A.9) can be reduced to a 2dimensional problem that can be easily demonstrated by employing the half-angle sinus formula and a few trigonometric manipulations.\n.", "publication_ref": ["b16"], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgment", "text": "Peter Meer was supported by the NSF under the grant IRI 99-87695.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Tracking and Data Association", "journal": "Academic Press", "year": "1988", "authors": "Y Bar-Shalom; T Fortmann"}, {"ref_id": "b1", "title": "\\Region Tracking through Image Sequences", "journal": "", "year": "1995", "authors": "B Bascle; R Deriche"}, {"ref_id": "b2", "title": "\\Elliptical Head Tracking using intensity Gradients and Color Histograms", "journal": "", "year": "1998", "authors": "S Birch"}, {"ref_id": "b3", "title": "\\Computer Vision Face Tracking as a Component of a Perceptual User Interface", "journal": "IEEE Work. on Applic. Comp. Vis", "year": "1998", "authors": "G R Bradski"}, {"ref_id": "b4", "title": "\\A multiple Hypothesis Approach to Figure Tracking", "journal": "", "year": "1999", "authors": "T J Cham; J M Rehg"}, {"ref_id": "b5", "title": "\\Mean Shift Analysis and Applications", "journal": "", "year": "1999", "authors": "D Comaniciu; P Meer"}, {"ref_id": "b6", "title": "\\Distribution Free Decomposition of Multivariate Data", "journal": "Pattern Anal. and Applic", "year": "1999", "authors": "D Comaniciu; P Meer"}, {"ref_id": "b7", "title": "Elements of Information Theory", "journal": "John Wiley & Sons", "year": "1991", "authors": "T M Cover; J A Thomas"}, {"ref_id": "b8", "title": "\\An E cient Implementation of Reid's Multiple Hypothesis Tracking Algorithm and Its Evaluation for the Purpose of Visual Tracking", "journal": "IEEE Trans. Pattern Analysis Machine Intell", "year": "1996", "authors": "I J Cox; S L Hingorani"}, {"ref_id": "b9", "title": "\\Indoor Monitoring Via the Collaboration Between a Peripheral Senson and a Foveal Sensor", "journal": "", "year": "1998", "authors": "Y Cui; S Samarasekera; Q Huang;  Grei Enhagen"}, {"ref_id": "b10", "title": "\\The Quality o f T raining-Sample Estimates of the Bhattacharyya Coe cient", "journal": "IEEE Trans. Pattern Analysis Machine Intell", "year": "1990", "authors": "A Djouadi; O Snorrason; F D Garber"}, {"ref_id": "b11", "title": "\\Automatic Face Location Detection and Tracking for Model-Assisted Coding of Video Teleconference Sequences at Low Bit Rates", "journal": "Signal Processing -Image Communication", "year": "1995", "authors": "A Eleftheriadis; A Jacquin"}, {"ref_id": "b12", "title": "or Focus of Attention Using Local Color Information", "journal": "IEEE Trans. Pattern Anal. Machine Intell", "year": "1995", "authors": "F Ennesser; G Medioni; Waldo "}, {"ref_id": "b13", "title": "Terzopoulos, \\Color-Based Tracking of Heads and Other Mobile Objects at Video Frame Rates", "journal": "", "year": "1997", "authors": "P Fieguth; D "}, {"ref_id": "b14", "title": "Introduction to Statistical Pattern Recognition", "journal": "Academic Press", "year": "1990", "authors": "K Fukunaga"}, {"ref_id": "b15", "title": "Bobick, \\Real-Time Closed-World Tracking", "journal": "", "year": "1997", "authors": "S S Intille; J W Davis; A F "}, {"ref_id": "b16", "title": "\\Condensation -Conditional Density Propagation for Visual Tracking", "journal": "Intern. J. Comp. Vis", "year": "1998", "authors": "M Isard; A Blake"}, {"ref_id": "b17", "title": "\\ICondensation: Unifying Low-Level and High-Level Tracking in a Stochastic Framework", "journal": "", "year": "1998", "authors": "M Isard; A Blake"}, {"ref_id": "b18", "title": "\\The Divergence and Bhattacharyya Distance Measures in Signal Selection", "journal": "IEEE Trans. Commun. Tech", "year": "1967", "authors": "T Kailath"}, {"ref_id": "b19", "title": "\\Fun-damental Bounds on Edge Detection: An Information Theoretic Evaluation of Di erent Edge Cues", "journal": "", "year": "1999", "authors": "S Konishi; A L Yuille; J Coughlan; S C Zhu"}, {"ref_id": "b20", "title": "\\Moving Target Classi cation and Tracking from Real-Time Video", "journal": "IEEE Workshop on Applications of Computer Vision", "year": "1998", "authors": "A J Lipton; H Fujiyoshi; R S Patil"}, {"ref_id": "b21", "title": "\\Tracking Colour Objects using Adaptive Mixture Models", "journal": "Image and Vision Computing", "year": "1999", "authors": "S J Mckenna; Y Raja; S Gong"}, {"ref_id": "b22", "title": "\\Geodesic Active Regions for Motion Estimation and Tracking", "journal": "", "year": "1999", "authors": "N Paragios; R Deriche"}, {"ref_id": "b23", "title": "\\3D trajectory Recovery for Tracking Multiple Objects and Trajectory Guided Recognition of Actions", "journal": "", "year": "1999", "authors": "R Rosales; S Sclaro"}, {"ref_id": "b24", "title": "Multivariate Density Estimation", "journal": "Wiley", "year": "1992", "authors": "D W Scott"}, {"ref_id": "b25", "title": "", "journal": "Intern. J. Comp. Vis", "year": "1991", "authors": "M J Swain; D H Ballard;  Indexing"}, {"ref_id": "b26", "title": "W ells III, \\Alignment b y Maximization of Mutual Information", "journal": "", "year": "1995", "authors": "P ; W M "}, {"ref_id": "b27", "title": "Real-Time Tracking of the Human Body", "journal": "IEEE Trans. Pattern Analysis Machine Intell", "year": "1997", "authors": "C Wren; A Azarbayejani; T Darrell; A Pentland"}, {"ref_id": "b28", "title": "Time Tracking of Non-Rigid Objects using Mean Shift", "journal": "", "year": "", "authors": ""}], "figures": [{"figure_label": "", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "computing the mean shift vector M h G (x) and translating the cent e r o f k ernel G by M h G (x).Let us denote by y j j=1 2::: the sequence of successive locations of the kernel G2 : : :(14) is the weighted mean at y j computed with kernel G and y 1 is the center of the initial kernel. The density estimates computed with kernel K in the points (14) only implicitly de ned to obtain rf K . However we need them to prove the convergence of the sequences (14) and(15).", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "crete densityq = fq u g u=1:::m (with P m u=1q u = 1) from the m-bin histogram of the target model, whil\u00ea p(y) = fp u (y)g u=1:::m (with P m u=1p u = 1) is estimated at a given location y from the m-bin histogram of the target candidate. Hence, the sample estimate of the Bhattacharyya coe cient i s g i v en b\u0177 (", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "44Tracking AlgorithmWe assume in the sequel the support of two modules which should provide (a) detection and localization in the initial frame of the objects to track (targets) 21, 2 3 ], and (b) periodic analysis of each object to account f o r possible updates of the target models due to signi cant changes in color 22].4.1 Color RepresentationTarget Model Let fx ? i g i=1:::n be the pixel locations of the target model, centered at 0. We de ne a function b : R 2 ! f1 : : : m g which associates to the pixel at location x ? i the index b(x ? i ) of the histogram bin corresponding to the color of that pixel. The probability of the color u in the target model is derived by employing a convex and monotonic decreasing kernel pro le k which assigns a smaller weight to the locations that are farther from the center of the target. The weighting increases the robustness of the estimation, since the peripheral pixels are the least reliable, being often a ected by occlusions (clutter) or background. The radius of the kernel pro le is taken equal to one, by assuming that the generic coordinates x and y are normalized with h x and h y , respectively. Hence, we c a ? i k 2 ) b(x ? i ) ; u](19) where is the Kronecker delta function. The normalization constant C is derived by imposing the condition the summation of delta functions for u = 1 : : : m is equal to one.", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "2 .27 ) i s a p p r o ximated as (after some manipulawhere it is assumed that the target candidate fp u (y)g u=1:::m does not change drastically from the initial fp u (\u0177 0 )g u=1:::m , and thatp u (\u0177 0 ) > 0 for all u = 1 : : : m . Introducing now(21) in (23) we obtain pminimize the distance(18), the second term in equation(24) has to be maximized, the rst term being independent of y. The second term represents the density estimate computed with kernel pro le k at y in the current frame, with the data being weighted by w i(25). The maximization can be e ciently achieved based on the mean shift iterations, using the following algorithm.Bhattacharyya Coe cient p(y) q] MaximizationGiven the distribution fq u g u=1:::m of the target model and the estimated location\u0177 0 of the target in the previous frame: 1. Initialize the location of the target in the current frame with\u0177 0 , compute the distribution fp u (\u0177 0 )g u=1:::m , a n d e Derive t h e w eights fw i g i=1:::n h according to(25).", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "3 .3Based on the mean shift vector, derive the new location of the target (14) go to Step 1. The proposed optimization employs the mean shift vector in Step 3 to increase the value of the approximated Bhattacharyya coe cient expressed by (24). Since this operation does not necessarily increase the value of p(y) q], the test included in Step 4 is needed to validate the new location of the target. However, practical experiments (tracking di erent objects, for long perio d s o f t i m e ) s h o wed that the Bhattacharyya coe cient computed at the location de ned by equation (26) was almost always larger than the coe cient corresponding to\u0177 0 . Less than 0:1% of the performed maximizations yielded cases where the Step 4 iterations were necessary. The termination threshold used in Step 5 is derived by constraining the vectors representing\u0177 0 and\u0177 1 to be within the same pixel in image coordinates.", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Figure 1 :1Figure 1: Football sequence: Tracking the player no. 75 with initial window o f 7 1 53 pixels. The frames 30, 75, 105, 140, and 150 are shown.", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "Figure 2 :2Figure 2: The number of mean shift iterations function of the frame index for the Football sequence. The mean number of iterations is 4:19 per frame.The number of mean shift iterations necessary for each frame (one scale) in the Football sequence is shown in Figure2. One can identify two central peaks, corresponding to the movement o f the player to the center of the image and back to the left side. The last and largest peak is due to the fast movement from the left to the right side.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "Figure 3 :3Figure 3: Values of the Bhattacharyya coe cient corresponding to the marked region (81 81 pixels) in frame 105 from Figure1. The surface is asymmetric, due to the player colors that are similar to the target. Four mean shift iterations were necessary for the algorithm to converge from the initial location (circle).To demonstrate the e ciency of our approach, Figure3presents the surface obtained by computing the Bhattacharyya coe cient for the rectangle marked in Figure1, frame 105. The target model (the selected elliptical region in frame 30) has been compared with the target candidates obtained by s w eeping the elliptical region in frame 105 inside the rectangle. While most of the tracking approaches based on regions 3, 1 4 ,2 1 ]    ", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_10", "figure_caption": "Figure 4 :4Figure 4: Subway1 sequence: The frames 500, 529, 600, 633, and 686 are shown (left-right, top-down).", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_12", "figure_caption": "Figure 5 :5Figure 5: Subway2 sequence: The frames 3140, 3516, 3697, 5440, 6081, and 6681 are shown (left-right, topdown).", "figure_data": ""}, {"figure_label": "6", "figure_type": "figure", "figure_id": "fig_13", "figure_caption": "Figure 6 :6Figure 6: The detected minimum value of distance d function of the frame index for the 2 m i n ute Subway2 sequence. The peaks in the graph correspond to occlusions or rotations in depth of the target. For example, the peak of value d 0:6 corresponds to the partial occlusion in frame 3697, shown in Figure 5. At the end of the sequence, the person being tracked gets on the train, which produces a complete occlusion.and by employing (14) it results that f K (j + 1 ) ;f K (j)", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_14", "figure_caption": "According to the Jensen's inequality 8, p.25]  we h a ve (p q) = p q) exists for all discrete distributionsp and q, is positive, symmetric, and is equal to zero i p =q.The triangle inequality can be proven as follows. Let us consider the discrete distributionsp,q, andr, and de ne the associated m-dimensional points p unit hypersphere, centered at the origin. By taking into account the geometric interpretation of the Bhattacharyya coe cient, the triangle inequality d(p r) + d(q r) d(p q)", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "It is nearly optimal, due to its link to the Bayes error. Note that the widely used histogram intersection technique 26] has no such theoretical foundation. 2. It imposes a metric structure (see Appendix). The Bhattacharyya distance 15, p.99] or Kullback d ivergence 8, p.18] are not metrics since they violate at least one of the distance axioms. 3. Using discrete densities, (18) is invariant to the scale of the target (up to quantization e ects). Histogram intersection is scale variant 26]. 4. Being valid for arbitrary distributions, the distance (18) is superior to the Fisher linear discriminant, which yields useful results only for distributions that are separated by the mean-di erence 15, p.132]. Similar measures were already used in computer vision. The Cherno and Bhattacharyya bounds have been employedin 20]  to determine the e ectiveness of edge detectors. The Kullback divergence has been used in 27] for nding the pose of an object in an image.The next section shows how to minimize(18) as a function of y in the neighborhood of a given location, by exploiting the mean shift iterations. Only the distribution of the object colors will be considered, although the texture distribution can be integrated into the same framework.", "figure_data": ";pp 1 : : : pp m Using now (17) the distance between two distribu-> and ;pq 1 : : : pq m > . tions can be de ned as d(y) = p 1 ; p(y) q] : (18)The statistical measure (18) is well suited for the task of target localization since:1."}], "formulas": [{"formula_id": "formula_0", "formula_text": "f(x) = 1 nh d n X i=1 K x ; x i h : (1)", "formula_coordinates": [1.0, 368.4, 326.09, 183.96, 35.92]}, {"formula_id": "formula_1", "formula_text": "K E (x) = 1 2 c ;1 d (d + 2)(1 ; k xk 2 ) if kxk < 1 0 otherwise (2)", "formula_coordinates": [1.0, 322.56, 397.1, 229.8, 41.13]}, {"formula_id": "formula_2", "formula_text": "k E (x) = 1 2 c ;1 d (d + 2)(1 ; x) if x < 1 0", "formula_coordinates": [1.0, 326.52, 526.1, 186.24, 29.01]}, {"formula_id": "formula_3", "formula_text": "f K (x) = 1 nh d n X i=1 k x ; x i h 2 ! : (6)", "formula_coordinates": [1.0, 358.56, 617.3, 193.8, 38.59]}, {"formula_id": "formula_4", "formula_text": "G(x) = C g (kxk 2 ) (8", "formula_coordinates": [1.0, 393.6, 708.08, 154.52, 16.91]}, {"formula_id": "formula_5", "formula_text": ")", "formula_coordinates": [1.0, 548.12, 710.99, 4.24, 13.8]}, {"formula_id": "formula_6", "formula_text": "rf K (x) r f K (x) = 2 nh d+2 n X i=1 (x ; x i ) k 0 x ; x i h 2 ! = 2 nh d+2 n X i=1 (x i ; x) g x ; x i h 2 ! = 2 nh d+2 \" n X i=1 g x ; x i h 2 ! # 2 4 P n i=1 x i g x;xi h 2 P n i=1 g x;xi h 2 ;x 3 5 (9)", "formula_coordinates": [2.0, 57.36, 112.7, 242.4, 113.35]}, {"formula_id": "formula_9", "formula_text": "p u (y) = C h n h X i=1 k y ; x i h 2 ! b(x i ) ; u] (21)", "formula_coordinates": [3.0, 325.8, 547.1, 226.56, 38.47]}, {"formula_id": "formula_10", "formula_text": "P m u=1p u = 1 w e obtain C h = 1 P n h i=1 k(k y;xi h k 2 ) : (22)", "formula_coordinates": [3.0, 379.08, 617.18, 173.28, 51.43]}], "doi": ""}