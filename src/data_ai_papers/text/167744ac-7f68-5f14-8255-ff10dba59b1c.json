{"title": "The \"DGX\" Distribution for Mining Massive, Skewed Data", "authors": "Zhiqiang Bi; Christos Faloutsos; Flip Korn", "pub_date": "", "abstract": "Skewed distributions appear very often in practice. Unfortunately, the traditional Zipf distribution often fails to model them well. In this paper, we propose a new probability distribution, the Discrete Gaussian Exponential (DGX), to achieve excellent fits in a wide variety of settings; our new distribution includes the Zipf distribution as a special case. We present a statistically sound method for estimating the DGX parameters based on maximum likelihood estimation (MLE). We applied DGX to a wide variety of real world data sets, such as sales data from a large retailer chain, usage data from AT&T, and Internet clickstream data; in all cases, DGX fits these distributions very well, with almost a 99% correlation coefficient in quantile-quantile plots. Our algorithm also scales very well because it requires only a single pass over the data. Finally, we illustrate the power of DGX as a new tool for data mining tasks, such as outlier detection.", "sections": [{"heading": "INTRODUCTION", "text": "In countless cases we encounter skewed distributions, where a few products (or vocabulary words, or customers) are responsible for most of the revenue (or occurrences, or sales), while the rest have very little individual contributions. Zipf, in his milestone book [20], proposed the distribution in which the frequency is inversely proportional to the rank of vocabulary words (and city populations, length of articles, income distributions and so on). Although a significant step to the correct direction, the Zipf distribution often fails to model real data sets well. For example, in Figure 1, we make the \"frequency-rank plot\" and the \"count-frequency plot\" of words in the Bible. As explained in the survey section, the Zipf (or generalized-Zipf) distribution would expect the plots to be straight lines in logarithmic-logarithmic scales. However, we observe a clear tilting in Figure 1. Zipf himself had observed this deviation and even had a name for it (\"top concavity\"), and he devoted several paragraphs in his book to justify it, whenever it appeared in a data set. Similar deviations are observed in many other cases, as we shall see in section 4.\nOur goal in this paper is to find a more general model. We want a distribution that would have the following attractive properties:\n1. it should include the \"Zipf\" and \"generalized Zipf\" as special cases;\n2. it should fit well all the data sets that Zipf fits, and many many more;\n3. it should be parsimonious (i.e., few parameters); 4. it should be fast to compute its parameters, even if the given data sets are huge.\nThe rest of the paper is organized as follows: Section 2 describes the Zipf distribution and gives the literature survey. Section 3 presents our proposed method, along with the proofs and the algorithms. Section 4 gives the experiments on our real data sets, in Section 5 we give some discussion of our results and significance of our methods and Section 6 lists the conclusions and future research directions.", "publication_ref": ["b19"], "figure_ref": ["fig_2", "fig_2"], "table_ref": []}, {"heading": "BACKGROUND -SURVEY", "text": "First, we start with the description of the Zipf distribution, and then we describe related work.   ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Background: Zipf and generalized Zipf distributions", "text": "We describe the Zipf distribution and the two Zipf \"laws\": the rank-frequency one and the frequency-count one. The laws are best described with an example, such as words in a book (or the Bible, as we show in Figure 1) Let V be the vocabulary size, f1 the occurrence frequency of the most frequent vocabulary word, and f2 the second most frequent, and so on. Definition 1. The rank-frequency plot is the plot of the occurrence frequency fr versus the rank r, in logarithmiclogarithmic scales\nThe rank-frequency version of Zipf's law states that\nfr \u221d 1/r (1)\nThis is typically referred to as the Zipf 's law or the Zipf distribution. In log-log scales, the Zipf distribution gives a straight line with slope -1.\nThe generalized Zipf distribution (or \"Zipf-like\" distribution) is defined as\nfr \u221d 1/r \u03b8 (2)\nwhere the log-log plot can be linear with any slope. The second 'law', also known as the discrete Pareto distribution [16], involves the \"count-frequency\" plot: let cf be the count of vocabulary words that appear f times in the document. The second Zipf's law states that\ncf \u221d 1/f \u03c6 (3)\nThere are three observations:\n\u2022 The count-frequency plot actually corresponds to the PDF (probability density function) of the occurrence frequency of a word in a document;\n\u2022 It is a mathematical consequence of the first law. It can be shown, for example in [11] or [1], that \u03c6 = 1 + 1/\u03b8;\n\u2022 In log-log scales, the count-frequency plot of a Zipf distribution will be a straight line, with slope \u03c6.\nDespite the success and fame of the Zipf distribution, we note that, eg. in Figure 1, the words in the Bible do not follow the Zipf distribution exactly, but instead they have the \"top concavity\".\nFor the rest of this work, we only report the 'count-frequency' (= PDF) plots for all the upcoming data sets, since the PDF is a more familiar concept than the \"rank-frequency\" plot, and since the two \"laws\" are in fact sides of the same coin.", "publication_ref": ["b15", "b10", "b0"], "figure_ref": ["fig_2", "fig_2"], "table_ref": []}, {"heading": "Survey", "text": "There are significant past attempts to model skewed distributions. They form two classes of distributions: discrete and continuous.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Discrete distributions", "text": "This is the class that we are most interested in, since most of the data of interest are either inherently integer-valued, or rounded-off to integers: salaries and dollar amounts are down to pennies, products sell integer counts (\"1 loaf of bread\"), and so on: Distribution in this class include Zipf and its variations, the Yule distribution [19] , and the Pareto distribution [16]. Among these distributions, Zipf's law is most widely used because of its simple form. Zipf's law has been observed in many fields. For example, the population of cities and the rank of the population [2], the number of articles in rth largest journal versus the rank of the journal [17], the surnames of 4794 people in an area in England [6] are all reported to 'follow Zipf's law. Recently, Zipf's law has been applied to research on web caching. Studies [8,4,18,3] show that the number of requests the server of rank r receives versus r also has the Zipf-like behavior.", "publication_ref": ["b18", "b15", "b1", "b16", "b5", "b7", "b3", "b17", "b2"], "figure_ref": [], "table_ref": []}, {"heading": "Continuous distributions", "text": "Although not directly applicable, we mention them, mainly because of the \"lognormal\" distribution, which is extremely successful in modeling continuous data sets. The lognormal distribution [7] takes positive values, and can be generated as e X where X is a Gaussian variable. It has been used to model particle sizes in natural aggregates, dust concentration in industrial atmospheres, in geological applications, concentration of minerals in deposits, flood flows, weights of children, automobile insurance claims, the weight distribution of U.S. adult males and females (Page 238-239, [15]). Gibrat found the distribution useful to represent the distribution of size for varied kinds of \"natural\" economic units.(Page 238-239, [15])\nIn several cases, there are even theoretical arguments supporting the lognormal distribution [9,10,15] : For example, if we break a stick into two at a random point, and continue recursively, the length of the resulting pieces will follow a lognormal distribution. It is also considered a competitor to the Weibul distribution for lifetime distributions of manufactured products. In fact, it can also approximate the Gaussian distribution. (Page 238-239, [15])\nThere have been some attempts to fit this kind of skewed data with other probability distributions, such as parabolic fractal [13] and stretched exponentials [14]. These works, however, are based on continuous probability distribution functions which are not appropriate for a lot of real world data which can only take discrete values, such as the visits to web sites, number of certain products sold in a supermarket, etc. Secondly, they estimated the parameters by fitting a curve on the rank-frequency plot in log-log scale, which we believe is statistically ad hoc.", "publication_ref": ["b6", "b14", "b14", "b8", "b9", "b14", "b14", "b12", "b13"], "figure_ref": [], "table_ref": []}, {"heading": "PROPOSED METHOD -DGX", "text": "Our goal is to find a discrete distribution that will fit the PDF (a.k.a. frequency-count plot) of many, real data sets.\nHowever, it is unclear where we should start from: Should we try to fit a parabola in the rank-frequency plot? Or, maybe, a third degree polynomial? or a Gaussian, a sinusoid, a spline? or something else? Or should we try all these functions on the frequency-count plot?\nA deeper question is: even if one of these functions fits in a few cases, do we have \"a-priori\" reasons to believe that it will fit well, in multiple settings?\nThe answer to all this questions is our proposed DGX distribution. Judging from the success of the lognormal (also referred to as \"anti-lognormal\") distribution for continuous data, we propose the following thought experiment: Consider a random variable, say, the duration of a web-surfing session. This is a continuous variable, and, most likely, might follow a lognormal distribution. However, we need to store it with finite accuracy, and thus turn it into an integer (number of minutes, or seconds, or hours). This is exactly the motivation behind DGX. Consider a lognormal random variable (by creating a Gaussian variable, and exponentiating it); then, digitize it to the nearest integer. The same is true for everything else: salaries (digitized to penny accuracy), duration of hospital stays (rounded to days), body height (inches), body weight (pounds) and so on.\nThere is a subtle, but important point: If the lognormal random variable becomes zero after the rounding, we omit it. This is necessary, since, e.g., we don't know how many vocabulary words have not appeared in our document. Notice that this omission leads to the so-called \"truncated\" or \"veiled\" random variables, which are notoriously difficult with respect to their parameter estimations, in the continuous case.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Probability Distribution Function", "text": "We are now ready to present our proposed discrete PDF.\nWe propose a distribution with the following PDF:\nP (x = k) = A(\u00b5, \u03c3) k exp \u2212 (lnk \u2212 \u00b5) 2 2\u03c3 2 k = 1, 2, . . . (4)\nwhere\nA(\u00b5, \u03c3) = ( \u221e X k=1 1 k exp \u2212 (lnk \u2212 \u00b5) 2 2\u03c3 2 ) \u22121\nis a normalization constant depending on \u00b5 and \u03c3. This PDF has the following characteristics\n\u2022 It is discrete, which means it is suitable to model many real discrete distributions.\n\u2022 It is a discretized version of a known continuous distribution, the lognormal distribution. As we know, the PDF of a lognormal distribution is a parabola in log-log plot, which is next simplest model beyond a straight line.\n\u2022 This model has only two parameters to estimate, so it is not difficult to compute.\n\u2022 As we will show in next section, DGX includes Zipf's law as a special case.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Zipf's law as a special case", "text": "Lemma 1. The Discrete Gaussian Exponential (DGX) as defined by Eq.(4) reduces to Zipf 's law as \u00b5 \u2192 \u2212\u221e.\nProof: We first rewrite Eq.(4) as\nP (x = k) \u221d 1 k exp \u2212 lnk(lnk \u2212 2\u00b5) 2\u03c3 2\nAssume that lnk << |\u00b5|, the PDF becomes\nP (x = k) \u221d 1 k exp \u00b5lnk \u03c3 2 \u221d k \u22121+\u00b5/\u03c3 2\nwhich reduces to generalized Zipf distribution (See Eq.(3)) with slope \u03c6 = 1 \u2212 \u00b5/\u03c3 2 . QED As we will see later from the results of our experiments, DGX works well on real data sets both when their PDF has a clear curvature and when the PDF is straight in log-log plot.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Estimation of parameters", "text": "Two major methods have been used to fit the skewed data with proposed models. One is to fit the frequency-rank plot with linear or nonlinear regression [5], while the other is to fit the PDF with maximum likelihood estimation (MLE). We believe the second method is statistically sound, therefore we choose to use MLE to estimate parameters, \u00b5 and \u03c3, for DGX. If the data are x1, . . . , xn, the likelihood is\nL(\u00b5, \u03c3) = n Y i=1 P (xi) = A(\u00b5, \u03c3) n n Y i=1 1 xi exp \u2212 (lnxi \u2212 \u00b5) 2 2\u03c3 2(5)\nand its logarithm, the log-likelihood is\nl(\u00b5, \u03c3) = nlnA(\u00b5, \u03c3) \u2212 n X i=1 lnxi + (lnxi \u2212 \u00b5) 2 2\u03c3 2 (6)\nWe then maximize l(\u00b5, \u03c3) numerically to estimate parameters, \u00b5 and \u03c3. For clarity, we describe DGX on the countfrequency of words in documents, but, of course, the same algorithm applies to any setting. The full algorithm is as follows,\nAlgorithm DGX Estimator Input: A sequence (\"multiset\") of N words w(i), i = 1, . . . , N appeared in a document Output: Estimated parameters, \u00b5 and \u03c3 1. Create an associative array word count (as in Perl) to store the count of distinct words 2. Create another associative array y to store distinct word frequencies. 3. for i \u21901 to N 4.\nw id \u2190w(i) 5.\nword count(w id) \u2190word count(w id) + 1 6. ( * V is vocabulary size, i.e., the number of distinct words. * ) 7. V \u2190size(word count) 8. for i \u21901 to V 9.\nkey \u2190word count(i) Note that we only need to go over the data set once (step 3 to 5) to obtain the frequency vector, word count, and go over the frequency vector once to obtain the count vector, y. The estimation is then carried out only on the count vector. This computation can be done fast.\nIn Step 17, we called an optimization function, e.g. fminsearch [12] in Matlab, to which we pass the function loglikelihood func and its parameters para=(tolerance, \u00b50, \u03c30).", "publication_ref": ["b4", "b11"], "figure_ref": [], "table_ref": []}, {"heading": "EXPERIMENTS", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Experiment Setup", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Data Sets Description", "text": "The DGX is designed to fit a wide variety of data sets. We thus applied it to three data sets from completely different fields:\n\u2022 Text: the English Bible. There are totally about 800000 words and the size of the vocabulary is V \u2248 12500.\n\u2022 Sales data from a large retailer chain, in which there are hundreds of branches. This data set, which includes all sales information of the store in one week, is about 10GB large. We studied the count-frequency relation of the products. Here the products play the role of vocabulary words and the sales of products correspond to the count of vocabulary words.\n\u2022 Telecommunications data -customer data from an AT&T service of monthly usage volumes, broken down by customer. We used three instances of this data, each from a different geographic region, which we refer to as Region A, Region B, and Region C.\n\u2022 Clickstream data: This data set is obtained from an ISP which collects information about Internet users' browsing behavior. We studied this data set from two angles, the count-frequency relation of website traffic ( the distribution of web sites versus the number of visits they receive) and the count-frequency relation of user sessions (The distribution of users versus the number of web sites they visit). In the first case, the web sites play the role of vocabulary words and the number of visits they receive corresponds to the count of vocabulary words; in the second case, the web users play the role of vocabulary words, and the number of web sites they visit corresponds to the count of vocabulary words.\nAll these data sets show extremely skewed behavior, i.e., we expect to see that very few products, or web sites are really popular, while most products have low sales, and most web sites have low traffic. Therefore, it is meaningless to talk about the mean, median or variance of these data. To characterize these data, we need to use some skewed distribution. We also observe that Zipf's Law often fails, i.e., the PDF in log-log scale shows a clear curving trend. However, DGX gives excellent fits in all cases we tested, including when the data set is very Zipf-like as well as when it deviates from Zipf's law very much.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Goodness of Fit", "text": "The technique we used to test the goodness-of-fit is the traditional quantile-quantile plot (qqplot). The qqplot compares the quantiles of two data sets. If the two data sets are from the same distribution, the qqplot should be linear and the slope should be one. We first use the original data to estimate the parameters of DGX. We then use DGX and the estimated parameters to generate a synthetic data set. Next, we make a qqplot between the real and the synthetic data sets. Then, we fit the qqplot with a straight line and compute the slope and correlation coefficient. If both are close to one, we can claim that the real data and the synthetic data are from the same distribution.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Results", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Text data", "text": "We first apply DGX to text data from the Bible. The results are shown in Figure 2. We notice that the real data and the synthetic data are in agreement. The slope and the correlation coefficient of the qqplot are both very close to one, which indicates we obtain an excellent fit.", "publication_ref": [], "figure_ref": ["fig_6"], "table_ref": []}, {"heading": "Clickstream Data", "text": "We also apply DGX to the clickstream data. We study the count-frequency relation of the web sites and the users.      ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Sales data", "text": "We then applied DGX to sales data from the three largest branches of a retail chain. For each store, we use the sales data to estimate parameters \u00b5 and \u03c3 in our distribution. With the estimated parameters we generate a set of synthetic data. Then, for each branch, we make the countfrequency plot and the qqplot as in Figure 4. We notice that they have similar count-frequency plots. Their parameters, \u00b5 and \u03c3, have similar values. As we will see later, some other stores have very different parameters and their count-frequency plots have different shapes.\nFrom Figure 4, we observe an excellent fit between the synthetic data and the real data. In the count-frequency plot which is clearly not a straight line, DGX gives a nice fit. We also observe that the slope and correlation coefficient of the qqplot are very close to one, which also indicates the data is expressed with DGX very well.", "publication_ref": [], "figure_ref": ["fig_11", "fig_11"], "table_ref": []}, {"heading": "Telecommunication Data", "text": "We then apply DGX to customer data from an AT&T service of monthly usage volumes, broken down by customer. We used three instances of this data, each from a different geographic region, which we refer to as Region A, Region B, and Region C. Following the same procedures, we obtain the results shown in Figure 5. Again, this data set is fit very well with DGX.", "publication_ref": [], "figure_ref": ["fig_18"], "table_ref": []}, {"heading": "DISCUSSION", "text": "Skewed distributions, like the count-frequency data as we described above, exist in many fields of natural and social sciences. They are not represented well using standard statistical aggregates such as mean, median, or extrema. For example, most words appear only once in Bible while a few common words appear very often. The mean is 63.0, the median is 3, the maximum is 63924, and the minimum is           1. These aggregates do not give a sense of the distribution; for example, they do not indicate how the i-th frequency is related to the (i+1)-th frequency. We therefore propose a new discrete distribution, DGX, which seems to be an excellent tool to model skewed data. The features we obtain with DGX are \u00b5 and \u03c3, which can be used for data mining, such as clustering or outlier detection.\nTo illustrate the data mining power of DGX, we apply it to the sales data of all branches of the retail chain and obtain a (\u00b5, \u03c3) pair for every store. In Figure 6, we make a scatter plot of (\u00b5, \u03c3) pairs and mark a few outlier stores according to the parameters. Notice that store No. 4 and No. 31 are outliers in (\u00b5, \u03c3) plane.\nFigure 7 gives the count-frequency plots for these two as well as some other \"mainstream\" stores. It is clear that No. 4 and No. 31 have more linear plots while the others have curving plots. Moreover, closer inspection shows that these two have smaller sales volume. This shows that the outlier detection in (\u00b5, \u03c3) indeed successfully discovered some stores with \"abnormal\" distribute sales data.", "publication_ref": [], "figure_ref": ["fig_19", "fig_21"], "table_ref": []}, {"heading": "CONCLUSIONS", "text": "Skewed distributions appear very often in practice. They are often modeled well by \"power\" laws such as the (generalized) Zipf distribution. However, they often suffer from deviations, like 'top-concavity'.\nThe main contribution of this work is an alternative discrete distribution called DGX, which has the following features:\n\u2022 It includes the Zipf and generalized Zipf distributions as special cases -thus, it is applicable to all the previous settings that Zipf works well;\n\u2022 It is related to the \"lognormal\" distribution, which models a huge number of continuous distributions; it can also be derived from 'first principles', like the principle of \"proportional effects\" in economics ( [15], page 210);\n\u2022 It models several discrete, real-life distributions, from retailer sales data to telecommunication data to web-hits, with practically perfect correlation coefficient in the traditional quantile-quantile (\"qq\") plots;\n\u2022 It is parsimonious, requiring only two parameters (\u00b5 and \u03c3), to describe the distribution nearly perfectly;\n\u2022 Its parameters can be estimated with a single pass over the data set.\nWe provided a statistically sound method to estimate the parameters, using the Maximum Likelihood Estimation, and we showed how to use DGX to find patterns and outliers in a collection of many skewed distributions, like branches that have clearly different patterns than the rest.\nThe \u00b5 and \u03c3 parameters of DGX are valuable for clustering and detecting outliers, because they constitute concise, but accurate \"features\" of a discrete distribution. In contrast, for skewed distributions, the obvious 'features' of mean, median, minimum, maximum, and variance are practically useless: The minimum value is almost always '1'; the maximum value (eg., the salary of the Queen of England in a data set with salaries) is so large and so unrelated to the rest of the data that it is useless as a feature; the mean is 'high-jacked' by the few outliers; the standard deviation tends to infinity, because of the so-called \"heavy-tail\" property of the Pareto-like distributions; and the median is low, but it still fails to convey much information about the rest of the distribution.\nGiven the success of DGX in modeling 1-dimensional PDFs, future work could focus on extensions of it for higher dimensionalities.  In real world, these two stores are two of the smallest stores in terms of sales.", "publication_ref": ["b14"], "figure_ref": [], "table_ref": []}, {"heading": "ACKNOWLEDGEMENT", "text": "The authors would like to thank the anonymous retailer chain, the anonymous Internet Service Provider and AT&T for providing us their properly anonymized data. We also like to thank Dr. Bill Eddy and Dr. Alan Montgomery for some useful discussions and suggestions.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "", "journal": "", "year": "", "authors": "L Adamic;  Zipf"}, {"ref_id": "b1", "title": "Alternate explanations of urban rank size relations", "journal": "Annals of the Association of American Geographers", "year": "1958", "authors": "B Berry; W Garrison"}, {"ref_id": "b2", "title": "Web caching and zipf-like distributions: Evidence and implications", "journal": "", "year": "1999-03", "authors": "L Breslau; P Cao; L Fan; G Phillips; S Shenker"}, {"ref_id": "b3", "title": "Characteristics of www client-based traces", "journal": "", "year": "1995-04", "authors": "A B C Cunha; M Crovella"}, {"ref_id": "b4", "title": "On B-tree indices for skewed distributions", "journal": "", "year": "1992", "authors": "C Faloutsos; H Jagadish"}, {"ref_id": "b5", "title": "The distribution of surname frequencies", "journal": "International Statistical Review", "year": "1983", "authors": "W Fox; W Lasker"}, {"ref_id": "b6", "title": "The geometric mean in vital and social statistics", "journal": "Proceedings of the Royal Society of London", "year": "1879", "authors": " Galton"}, {"ref_id": "b7", "title": "A caching relay for the world wide web", "journal": "", "year": "1994-05", "authors": "S Glassman"}, {"ref_id": "b8", "title": "Random alms", "journal": "Annals of Mathematical Statistics", "year": "1944", "authors": "P Halmos"}, {"ref_id": "b9", "title": "Small Particle Statistics. Butterworth's, London", "journal": "", "year": "1960", "authors": "G Herdan"}, {"ref_id": "b10", "title": "The rank-frequency form of zipf's law", "journal": "Journal of the American Statistical Association", "year": "1974", "authors": "B Hill"}, {"ref_id": "b11", "title": "The MathWorks Inc. Matlab user's guide", "journal": "", "year": "", "authors": ""}, {"ref_id": "b12", "title": "parabolic fractal\" distributions in nature", "journal": "", "year": "", "authors": "J Laherr\u00e8re"}, {"ref_id": "b13", "title": "Stretched exponential distributions in nature and economy: \"fat tails\" with characteristic scales", "journal": "European Physical Journal", "year": "1998", "authors": "J Laherr\u00e8re; D Sornette"}, {"ref_id": "b14", "title": "Continuous Univariate Distributions Volume", "journal": "John Wiley & Sons, Inc., U.S.A", "year": "1994", "authors": "S K N I Johnson; N Balakrishnan"}, {"ref_id": "b15", "title": "Cours d'Economie Politique. Rouge and Cie", "journal": "Lausanne and Paris", "year": "", "authors": "V Pareto"}, {"ref_id": "b16", "title": "On a class of skew distribution functions", "journal": "Biometrika", "year": "1955", "authors": "H Simon"}, {"ref_id": "b17", "title": "Characterizing reference locality in the www", "journal": "", "year": "1996-12", "authors": "M C V Almeida; A Bestavros; A De Oliveira"}, {"ref_id": "b18", "title": "A mathematical theory of evolution, based on conclusions of dr. j.c. willis, f.r.s. Philosophical Transactions of the", "journal": "Royal Society of London", "year": "1923", "authors": "G ; Yule "}, {"ref_id": "b19", "title": "Human Behavior and Principle of Least Effort: An Introduction to Human Ecology", "journal": "Addison Wesley", "year": "1949", "authors": "G Zipf"}], "figures": [{"figure_label": "", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Rank-frequency plot of words in the Bible. We fit the straight line using least square method.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Count-frequency plot of words in the Bible.", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 1 :1Figure 1: Rank-frequency plot and count-frequency plot of words in English Bible. Although they both show Zipf-like skewed behavior, they clearly do not follow Zipf 's law exactly.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "10. y(key) \u2190y(key)+1 11. ( * para is used to pass parameters to loglikelihood function. * ) 12. ( * \u00b50 and \u03c30 are initial values for \u00b5 and \u03c3 * ) 13. ( * y is the count-frequency data * ) 14. ( * tolerance is used to set the stopping criterion * ) 15. para \u2190(\u00b50, \u03c30, y, tolerance) 16. ( * Call a maximization routine to find the optimal parameters, \u00b5 and \u03c3. Here the loglikelihood func is a function which evaluates the loglikelihood (as defined in Eq.(6)) given a certain (\u00b5, \u03c3) pair. * ) 17. [\u00b5, \u03c3] = Maximization(loglikelihood func, para) 18. Output [\u00b5, \u03c3] and exit.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "The count-frequency plot of website traffic, as shown in Figure 3-(a) shows a clear Zipf-like behavior, while the countfrequency plot 3-(b) of users deviates significantly from Zipf's law. However, both distributions can be fit well with DGX.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "qqplot of real and synthetic data for words in Bible", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Figure 2 :2Figure 2: Count-frequency plots of real data and synthetic data for words in Bible. Here, \u00b5 = \u22122.106 and \u03c3 = 3.23. We find that the synthetic data match the real data very well. The qqplot is practically linear, the slope and the correlation coefficient are close to unity. All indicate that DGX gives an excellent fit.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "Count-frequency plot of website visits. Estimated parameters are (\u00b5 = \u221260.35, \u03c3 = 7.68). We observe that this distribution is very Zipf-like and it has a large negative \u00b5. This seems to agree with Lemma 1.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "Count-frequency plot of user sessions. Estimated parameters are (\u00b5 = 2.86, \u03c3 = 1.42). We observe that this data set deviates significantly from Zipf's law, but it can still be modeled well with DGX.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "Figure 3 :3Figure 3: Count-frequency plots of website visitors and user sessions. They show very different behavior, but both can be modeled well with DGX", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_10", "figure_caption": "plot for store no. 96. \u00b5 = 0.999 and \u03c3 = plot for store no. 82. \u00b5 = 0.905 and \u03c3 = plot for store no. 101. \u00b5 = 0.788 and \u03c3 = and synthetic data for store no. 101.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_11", "figure_caption": "Figure 4 :4Figure 4: Count-frequency plots of real data and synthetic for store 96, 82 and 101 and their qqplots. We notice that the real and the synthetic data are in good agreement. The qqplot is almost linear, the slope and the correlation coefficient are close to one. All indicate that DGX gives an excellent fit.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_12", "figure_caption": "plot of real and synthetic data for Region A. \u00b5 = \u22120.712 and \u03c3 = 1.450.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_13", "figure_caption": "qqplot of real and synthetic data for Region A.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_14", "figure_caption": "plot of real and synthetic data for Region B. \u00b5 = \u22120.420 and \u03c3 = 1.387.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_15", "figure_caption": "qqplot of real and synthetic data for Region B.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_16", "figure_caption": "plot of real and synthetic data for Region C. \u00b5 = \u22120.64 and \u03c3 = 1.418.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_17", "figure_caption": "qqplot of real and synthetic data for Region C.", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_18", "figure_caption": "Figure 5 :5Figure5: Count-frequency plots of service usage data from AT&T. We show real data and synthetic for three regions and their qqplots. We notice that the real and the synthetic data are in good agreement. The qqplot is almost linear, the slope and the correlation coefficient are close to unity. All indicate that DGX gives an excellent fit.", "figure_data": ""}, {"figure_label": "6", "figure_type": "figure", "figure_id": "fig_19", "figure_caption": "Figure 6 :6Figure 6: Scatter plot of \u00b5 and \u03c3 of all branches of a retail chain. We clear see stored No. 4 and No. 31 are outliers compared to the majority.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_20", "figure_caption": "No. 4: (\u00b5, \u03c3) = (\u22120.65, 1.54) No.31: (\u00b5, \u03c3) = (\u22120.66, 1.59) 119:(\u00b5, \u03c3) = (0.60, 1.19)", "figure_data": ""}, {"figure_label": "7", "figure_type": "figure", "figure_id": "fig_21", "figure_caption": "Figure 7 :7Figure 7: Count-frequency plots of outlier stores according to the (\u00b5, \u03c3) pair in the DGX. We notice that the distributions for Store No.4 and Store. No. 31, which have small \u00b5 values are more Zipf-like than the others.In real world, these two stores are two of the smallest stores in terms of sales.", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "fr \u221d 1/r (1)", "formula_coordinates": [2.0, 156.0, 449.97, 136.8, 9.0]}, {"formula_id": "formula_1", "formula_text": "fr \u221d 1/r \u03b8 (2)", "formula_coordinates": [2.0, 154.08, 523.5, 138.72, 11.07]}, {"formula_id": "formula_2", "formula_text": "cf \u221d 1/f \u03c6 (3)", "formula_coordinates": [2.0, 153.12, 598.14, 139.68, 11.07]}, {"formula_id": "formula_3", "formula_text": "P (x = k) = A(\u00b5, \u03c3) k exp \u2212 (lnk \u2212 \u00b5) 2 2\u03c3 2 k = 1, 2, . . . (4)", "formula_coordinates": [3.0, 322.08, 72.57, 233.76, 22.08]}, {"formula_id": "formula_4", "formula_text": "A(\u00b5, \u03c3) = ( \u221e X k=1 1 k exp \u2212 (lnk \u2212 \u00b5) 2 2\u03c3 2 ) \u22121", "formula_coordinates": [3.0, 353.28, 107.04, 165.67, 37.5]}, {"formula_id": "formula_5", "formula_text": "P (x = k) \u221d 1 k exp \u2212 lnk(lnk \u2212 2\u00b5) 2\u03c3 2", "formula_coordinates": [3.0, 360.96, 395.25, 142.8, 21.0]}, {"formula_id": "formula_6", "formula_text": "P (x = k) \u221d 1 k exp \u00b5lnk \u03c3 2 \u221d k \u22121+\u00b5/\u03c3 2", "formula_coordinates": [3.0, 357.6, 440.37, 156.52, 20.76]}, {"formula_id": "formula_7", "formula_text": "L(\u00b5, \u03c3) = n Y i=1 P (xi) = A(\u00b5, \u03c3) n n Y i=1 1 xi exp \u2212 (lnxi \u2212 \u00b5) 2 2\u03c3 2(5)", "formula_coordinates": [3.0, 320.4, 627.36, 235.44, 40.41]}, {"formula_id": "formula_8", "formula_text": "l(\u00b5, \u03c3) = nlnA(\u00b5, \u03c3) \u2212 n X i=1 lnxi + (lnxi \u2212 \u00b5) 2 2\u03c3 2 (6)", "formula_coordinates": [3.0, 340.56, 687.36, 215.28, 30.54]}], "doi": ""}