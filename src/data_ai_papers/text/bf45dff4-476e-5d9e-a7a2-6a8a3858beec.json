{"title": "Towards Understanding Ensemble, Knowledge Distillation and Self-Distillation in Deep Learning", "authors": "Zeyuan Allen-Zhu; Yuanzhi Li", "pub_date": "2023-02-15", "abstract": "We formally study how ensemble of deep learning models can improve test accuracy, and how the superior performance of ensemble can be distilled into a single model using knowledge distillation. We consider the challenging case where the ensemble is simply an average of the outputs of a few independently trained neural networks with the same architecture, trained using the same algorithm on the same data set, and they only differ by the random seeds used in the initialization. We show that ensemble/knowledge distillation in deep learning works very differently from traditional learning theory (such as boosting or NTKs, neural tangent kernels). To properly understand them, we develop a theory showing that when data has a structure we refer to as \"multi-view\", then ensemble of independently trained neural networks can provably improve test accuracy, and such superior test accuracy can also be provably distilled into a single model by training a single model to match the output of the ensemble instead of the true label. Our result sheds light on how ensemble works in deep learning in a way that is completely different from traditional theorems, and how the \"dark knowledge\" is hidden in the outputs of the ensemble and can be used in distillation. In the end, we prove that self-distillation can also be viewed as implicitly combining ensemble and knowledge distillation to improve test accuracy.", "sections": [{"heading": "Introduction", "text": "Ensemble [25,41,50,67,70,70,71,73,91], also known as model averaging, is one of the oldest and most powerful techniques in practice to improve the performance of deep learning models. By simply averaging the output of merely a few (like 3 or 10) independently trained neural networks of the same architecture, using the same training method over the same training data, it can significantly boost the prediction accuracy over the test set comparing to individual models. The only difference is the randomness used to initialize these neural networks and/or the randomness during training. For example, on the standard CIFAR-100 data set, averaging the output of ten independently trained ResNet-34 can easily offer a 5% improvement in terms of test accuracy. Moreover, it is discovered by Hinton et al. [42] that such superior test-time performance of the ensemble can be transferred into a single model (of the same size as the individual models) using a technique called knowledge distillation: that is, simply train a single model to match the output of the ensemble (such as \"90% cat + 10% car\", also known as soft labels) as opposite to the true data labels, over the same training data.\nOn the theory side, there are lots of works studying the superior performance of ensemble from principled perspectives [11, 13, 28, 30-33, 36, 43, 46-48, 51, 72, 72, 75, 76]. However, most of these works only apply to: (1). Boosting: where the coefficients associated with the combinations of the single models are actually trained, instead of simply taking average; (2). Bootstrapping/Bagging: the training data are different for each single model; (3). Ensemble of models of different types and architectures; or (4). Ensemble of random features or decision trees.\nTo the best of our knowledge, none of these cited works apply to the particular type of ensemble that is widely used in deep learning: simply take a uniform average of the output of the learners, which are neural networks with the same architecture and are trained by stochastic gradient descent (SGD) over the same training set. In fact, very critically, for deep learning models:\n\u2022 Training average does not work: if one directly trains to learn an average of individual neural networks initialized by different seeds, the performance is much worse than ensemble.\n\u2022 Knowledge distillation works: the superior performance of ensemble in deep learning can be distilled into a single model [20,22,29,34,42,52,61].\n\u2022 Self-distillation works: even distilling a single model into another single model of the same size, there is performance boost. [35,63,89] We are unaware of any satisfactory theoretical explanation for the phenomena above. For instance, as we shall argue, some traditional view for why ensemble works, such as 'ensemble can enlarge the feature space in random feature mappings', even give contradictory explanations to the above phenomena, thus cannot explain knowledge distillation or ensemble in deep learning. Motivated by this gap between theory and practice we study the following question for multi-class classification: Our theoretical questions: How does ensemble improve the test-time performance in deep learning when we simply (unweightedly) average over a few independently trained neural networks? -Especially when all the neural networks have the same architecture, are trained over the same data set using the same standard training algorithm (i.e. gradient descent with the same learning rate and sample regularization) and only differ by the random seeds, and even when all single models already have 100% training accuracy? How can such superior test-time performance of ensemble be later \"distilled\" into a single neural network of the same architecture, simply by training the single model to match the output of the ensemble over the same training data set?  ", "publication_ref": ["b24", "b40", "b49", "b66", "b69", "b69", "b70", "b72", "b90", "b41", "b0", "b1", "b2", "b3", "b19", "b21", "b28", "b33", "b41", "b51", "b60", "b34", "b62", "b88"], "figure_ref": [], "table_ref": []}, {"heading": "Our Theoretical Results at a High Level", "text": "To the best of our knowledge, this paper makes a first step towards answering these questions in deep learning. On the theory side, we prove for certain multi-class classification tasks with a special structure we refer to as multi-view, with a training set Z consisting of N i.i.d. samples from some unknown distribution D, for certain two-layer convolutional network f with (smoothed-)ReLU activation as learner:\n\u2022 (Single model has bad test accuracy): there is a value \u00b5 > 0 such that when a single model f is trained over Z using the cross-entropy loss, via gradient descent (GD) starting from random Gaussian initialization, the model can reach zero training error efficiently. However, w.h.p. the prediction (classification) error of f over D is between 0.49\u00b5 and 0.51\u00b5.\n\u2022 (Ensemble provably improves test accuracy): let f 1 , f 2 , \u2022 \u2022 \u2022 , f L be L = \u2126(1) independently trained single models as above, then w.h.p. G = 1 L f has prediction error \u2264 0.01\u00b5 over D.\n\u2022 (Ensemble can be distilled into a single model): if we further train (using GD from random initialization) another single model f 0 (same architecture as each f ) to match the output of G = 1 L f merely over the same training data set Z, then f 0 can be trained efficiently and w.h.p. f 0 will have prediction error \u2264 0.01\u00b5 over D as well.\n\u2022 (Self-distillation also improves test accuracy): if we further train (using GD from random initialization) another single model f (same architecture as f 1 ) to match the output of the single model f 1 merely over the same training data set Z, then f can be trained efficiently and w.h.p. has prediction error at most \u2264 0.26\u00b5 over D. The main idea is that self-distillation is performing \"implicit ensemble + knowledge distillation\", as we shall argue in Section 4.2.\nThus, on the theory side, we make a step towards understanding ensemble and knowledge distillation in deep learning both computationally (training efficiency) and statistically (generalization error).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Our Empirical Results at a Glance", "text": "We defer discussions of our empirical results to Section 5. However, we highlight some of the empirical findings, as they shall confirm and justify our theoretical approach studying ensemble and knowledge distillation indeep learning. Specifically, we give empirical evidences showing that:\n\u2022 Knowledge distillation does not work for random feature mappings; and ensemble in deep learning is very different from ensemble in random feature mappings (see Figure 1).\n\u2022 Special structures in data (such as the \"multi-view\" structure we shall introduce) is needed for ensemble of neural networks to work.\n\u2022 The variance due to label noise or the non-convex landscape of training, in the independentlytrained models, may not be connected to the superior performance of ensemble in deep learning.", "publication_ref": [], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Our Methodology and Intuition 2.1 A Failure Attempt Using Random Feature Mappings", "text": "The recent advance in deep learning theory shows that under certain circumstances, neural networks can be treated as a linear function over random feature mappings [3,5,6,8,9,19,24,26,27,39,40,44,55,59,86,92]. In particular, the theory shows when f : R D+d \u2192 R is a neural network with inputs x \u2208 R d and weights W \u2208 R D , in some cases, f (W, x) can be approximated by:\nf (W, x) \u2248 f (W 0 , x) + W \u2212 W 0 , \u2207 W f (W 0 , x)\nwhere W 0 is the random initialization of the neural network, and \u03a6 W 0 (x) := \u2207 W f (W 0 , x) is the neural tangent kernel (NTK) feature mapping. This is known as the NTK approach. If this approximation holds, then training a neural network can be approximated by learning a linear function over random features \u03a6 W 0 (x), which is very theory-friendly.\nEnsemble works for random features / NTK. Traditional theorems [1,14,17,81] suggest that the ensemble of independently trained random feature models can indeed significantly improve test-time performance, as it enlarges the feature space from \u03a6 W 0 (x) to {\u03a6 W (i) 0\n(x)} i\u2208 [L] for L many independently sampled W (i) 0 . This can be viewed as a feature selection process [7,18,66,68,74], and we have confirmed it for NTK in practice, see Figure 1. Motivate by this line of research, we ask:\nCan we understand ensemble and knowledge distillation in deep learning as feature selections? (in particular, using the NTK approach?)\nUnfortunately, our empirical results provide many counter examples towards those arguments, see discussions below and Figure 1. (x) does improve test accuracy, however, such improvement is mainly due to the use of a larger set of random features, whose combinations contain functions that generalize better. To see this, we observe that an even superior performance (than the ensemble) can simply be obtained by directly training F (x) = 1 L f 1 + f 2 + \u2022 \u2022 \u2022 + f L from random initialization. In contrast, recall if f i (x)'s are multi-layer neural networks with different random seeds, then training their average barely gives any better performance comparing to individual networks f i , as now all the f i 's are capable of learning the same set of features. Contradiction 2: knowledge distillation does not work. For NTK feature mappings, we observe that the result obtained by ensemble cannot be distilled at all into individual models, indicating the features selected by ensemble is not contained in the feature \u03a6 W (i) 0 (x) of any individual model. In contrast, in actual deep learning, ensemble does not enlarge feature space: so an individual neural network is capable of learning the features of the ensemble model.\nIn sum, ensemble in deep learning may be very different from ensemble in random features. It may be more accurate to study ensemble / knowledge distillation in deep learning as a feature learning process, instead of a feature selection process (where the features are prescribed and only their linear combinations are trained). But still, we point out a fundamental difficulty:", "publication_ref": ["b2", "b4", "b5", "b7", "b8", "b18", "b23", "b25", "b26", "b38", "b39", "b43", "b54", "b58", "b85", "b91", "b0", "b13", "b16", "b80", "b6", "b17", "b65", "b67", "b73", "b0"], "figure_ref": ["fig_0", "fig_0"], "table_ref": []}, {"heading": "Key challenge:", "text": "If a single deep learning model is capable of-through knowledge distillation-learning the features of the ensemble model and achieving better test accuracy comparing to training the single model directly (and the same training accuracy, typically at global optimal of 100%), then why the single model cannot learn these features directly when we train the model to match the true data labels? What is the dark knowledge hidden in the output of ensemble (a.k.a. soft label) 1 comparing to the original hard label?", "publication_ref": ["b0"], "figure_ref": [], "table_ref": []}, {"heading": "Ensemble in Deep Learning: a Feature Learning Process", "text": "Before addressing the key challenge, we point out that prior works are very limited with respect to studying neural network training as a feature learning process, due to the extreme non-convexity obstacle in optimization.\nMost of the existing works proving that neural networks can learn features only focus on the case when the input is Gaussian or Gaussian-like [10, 12, 16, 37, 38, 45, 53, 54, 56, 56-58, 60, 69, 78-80, 84, 85, 87, 90]. However, as we demonstrate in Figure 7 on Page 15, Ensemble in DL might not improve test accuracy when inputs are Gaussian-like: Empirically, ensemble does not improve test accuracy in deep learning, in certain scenarios when the distribution of the input data is Gaussian or even mixture of Gaussians. This is true over various learner network structures (fully-connected, residual, convolution neural networks) and various labeling functions (when the labels are generated by linear functions, fully-connected, residual, convolutional networks, with/without label noise, with/without classification margin).\nBias variance view of ensemble: Some prior works also try to attribute the benefit of ensemble as reducing the variance of individual solutions [15,62,64,82,83] due to label noise or non-convex landscape of the training objective (so some individual models might simply not be trained very well by over-fitting to the label noise or stuck at a bad local minimal).\nHowever, reducing such variance can reduce a convex test loss (typically cross-entropy), but not necessarily the test classification error. Concretely, the synthetic experiments in Figure 7 show that, after applying ensemble over Gaussian-like inputs, the variance of the model outputs is reduced but the test accuracy is not improved. We give many more empirical evidences to show that the variance (either from label noise or from the non-convex landscape) is usually not the cause for why ensemble works in deep learning, see Section 5. Moreover, we point out that (see Figure 6) in practice, typically the individual neural networks are trained equally well, meaning that they all have perfect training accuracy and almost identical test error, yet ensemble these models still improves the test accuracy significantly.\nHence, to understand the true benefit of ensemble in deep learning in theory, we would like to study a setting that can approximate practical deep learning, where:\n\u2022 The input distribution is more structured than standard Gaussian and there is no label noise. (From above discussions, ensemble cannot work for deep learning distribution-freely, nor even under Gaussian distribution).\n\u2022 The individual neural networks all are well-trained, in the sense that the training accuracy in the end is 100%, and there is nearly no variance in the test accuracy for individual models.\n(So training never fails.) We would like to re-elaborate the key challenge: 'ensemble improves test accuracy' implies that different single models need to learn different sets of features; however, all these models have the same architecture, and trained using the same learning algorithm (SGD with momentum) with identical learning rates, and each the (learned) sets of features in each modellead to the perfect 100% training accuracy and an almost identical test accuracy. Thus, the difference of the features must not be due to 'difference in the data set', 'difference in the models', 'difference in the training algorithms', 'difference in the learning rates', 'failure in training occasionally', 'failure in generalization in some cases', etc. Additional principles need to be developed to incorporate the effect of ensemble in deep learning.\nIn this work, we propose to study a setting of data that we refer to as multi-view, where the above two conditions both hold when we train a two-layer neural networks with (smoothed-)ReLU activations. We also argue that the multi-view structure we consider is fairly common in the data sets used in practice, in particular for vision tasks. We give more details below.", "publication_ref": ["b14", "b61", "b63", "b81", "b82"], "figure_ref": ["fig_6", "fig_6"], "table_ref": []}, {"heading": "Our Approach: Learning Multi-View Data", "text": "Let us first give a thought experiment to illustrate our approach, and we present the precise mathematical definition of the \"multi-view\" structure in Section 3. Consider a binary classification problem and four \"features\" v 1 , v 2 , v 3 , v 4 . The first two features correspond to the first class label, and the next two features correspond to the second class label. In the data distribution:\n\u2022 When the label is class 1, then: We call the 80% of the data multi-view data: these are the data where multiple features exist and can be used to classify them correctly. We call the rest 20% of the data single-view data: some features for the correct labels are missing.\n2 \uf8f1 \uf8f2 \uf8f3 both v 1 , v\nMeaningfulness of our multi-view hypothesis. Such \"multi-view\" structure is very common in many of the datasets where deep learning excels. In vision datasets in particular, as illustrated in Figure 2, a car image can be classified as a car by looking at the headlights, the wheels, or the windows. For a typical placement of a car in images, we can observe all these features, and it suffices to use one of the features to classify it as a car. However, there are some car images taken  Figure 4: Ten independently trained ResNet-34 models (and their ensemble) detect car images through different reasonings, suggesting that the data has multi views, and independently trained neural networks do utilize this structure. The numerical experiments in Figure 9 also suggest the existence of multi views.\nfrom a particular angle, where one or more of these features are missing. For example, an image of a car facing forward might be missing the wheel feature. Moreover, some car might also have a small fraction of \"cat features\": for example, the headlight might appear similar to cat eyes the ear of a cat. This can be used as the \"dark knowledge\" by the single model to learn from the ensemble. In Figure 3, we visualize the learned features from an actual neural network to show that they can indeed capture different views. In Figure 4, we plot the \"heatmap\" for some car images to illustrate that single models (trained from different random seeds) indeed pick up different parts of the input image to classify it as a car. In Figure 9, we manually delete for instance 7/8 of the channels in some intermediate layer of a ResNet, and show that the test accuracy may not be affected by much after ensemble-thus supporting that the multi-view hypothesis can indeed exist even in the intermediate layers of a neural network and ensemble is indeed collecting all these views.\nHow individual neural networks learn. Under the multi-view data defined above, if we train a neural network using the cross-entropy loss via gradient descent (GD) from random initialization, during the training process of the individual networks, we show that:\n\u2022 The network will quickly pick up one of the feature v \u2208 {v 1 , v 2 } for the first label, and one of the features v \u2208 {v 3 , v 4 } for the second label. So, 90% of the training examples, consisting of all the multi-view data and half of the single-view data (those with feature v or v ), are classified correctly. Once classified correctly (with a large margin), these data begin to contribute negligible to gradient by the nature of the cross-entropy loss.\n\u2022 Next, the network will memorize (using e.g. the noise in the data) the remaining 10% of the training examples without learning any new features, due to insufficient amount of left-over samples after the first phase, thus achieving training accuracy 100% but test accuracy 90%.\nHow ensemble improves test accuracy. It is simple why ensemble works. Depending on the randomness of initialization, each individual network will pick up v 1 or v 2 each w.p. 50%. Hence, as long as we ensemble O(1) many independently trained models, w.h.p. their ensemble will pick up both features {v 1 , v 2 } and both features {v 3 , v 4 }. Thus, all the data will be classified correctly.\nHow knowledge distillation works. Perhaps less obvious is how knowledge distillation works.\nSince ensemble learns all the features v 1 , v 2 , v 3 , v 4 , given a multi-view data with label 1, the ensemble will actually output \u221d (2, 0.1), where the 2 comes from features v 1 , v 2 and 0.1 comes from one of v 3 , v 4 . On the other hand, an individual model learning only one of v 3 , v 4 will actually output \u221d (2, 0) when the feature v 3 or v 4 in the data does not match the one learned by the model. Hence, by training the individual model to match the output of the ensemble, the individual model is forced to learn both features v 3 , v 4 , even though it has already perfectly classified the training data. This is the \"dark knowledge\" hidden in the output of the ensemble model. (This theoretical finding is consistent with practice: Figure 8 suggests that models trained from knowledge distillation should have learned most of the features, and further computing their ensemble does not give much performance boost.)", "publication_ref": [], "figure_ref": ["fig_2", "fig_10", "fig_30", "fig_4", "fig_10", "fig_30", "fig_7"], "table_ref": []}, {"heading": "Significance of Our Technique", "text": "Our work belongs to the generic framework where one can prove that certain aspects of the learning algorithm (in this paper, the randomness of the initialization) affects the order where the features are learned, which we believe is also one of the key ingredients to understand the role of the learning algorithm in terms of generalization in deep learning. This is fundamentally different from convex optimization, such as kernel method, where (with an 2 regularization) there is an unique global minimum so the choice of optimization algorithm or the random seed of the initialization does not matter (thus, ensemble does not help at all). There are other works that consider other aspects, such as the choice of learning rate [59], that can affect the order where the features are picked in deep learning. In that work [59], the two \"features\" are asymmetric: a memorizable feature and a generalizable feature, so the learning rate will decide which feature to be picked. In our work, the features are \"symmetric\", so the randomness of the initialization will decide which feature to be picked. Our technique is fundamentally different from [59]: they only focus on the NTK setting, where only a linear function over the prescribed sequence of feature mappings is learned. In other words, their features are not learned (although their features change over time, following a Gaussian random process which is independent of the learning task); instead, we study a feature learning process in this paper. As we have argued and shown empirically, the NTK setting cannot be used to explain ensemble and distillation in deep learning.\nWe believe that our workextends the reach of traditional optimization and statistical machine learning theory, where typically the statistics (generalization) is separated from optimization (training). As we have pointed out, such \"separate\" treatment might not be possible to understand (at least ensemble or knowledge distillation in) deep learning.", "publication_ref": ["b58", "b58", "b58"], "figure_ref": [], "table_ref": []}, {"heading": "Problem Setup", "text": "In this paper, we consider the following data distribution with \"multi-view\", that allows us to formally prove our result on ensemble and knowledge distillation for two-layer neural networks. The data distribution is a straight-forward generalization of the intuitive setting in Section 2.3. For simplicity, in the main body, we use example choices of the parameters mainly a function of k (such as\nP = k 2 , \u03b3 = 1 k 1.5 , \u00b5 = k 1.2 N , \u03c1 = k \u22120.01 , \u03c3 0 = 1/\n\u221a k as we shall see), and we consider the case when k is sufficiently large. In our formal statements of the theorems in the appendix, we shall give a much larger range of parameters for the theorems to hold.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Data Distribution and Notations", "text": "We consider learning a k-class classification problem over P -patch inputs, where each patch has dimension d. In symbols, each labelled data is represented by (X, y) where X = (x 1 , x 2 , \u2022 \u2022 \u2022 , x P ) \u2208 (R d ) P is the data vector and y \u2208 [k] is the data label. For simplicity, we focus on the case when P = k 2 , and d = poly(k) for a large polynomial.\nWe consider the setting when k is sufficiently large. 3 We use \"w.h.p.\" to denote with probability at least 1 \u2212 e \u2212\u2126(log 2 k) , and use O, \u0398, \u2126 notions to hide polylogarithmic factors in k.\nWe first assume that each label class j \u2208 [k] has multiple associated features, say two features for the simplicity of math, represented by unit feature vectors v j,1 , v j,2 \u2208 R d . For notation simplicity, we assume that all the features are orthogonal, namely,\n\u2200j, j \u2208 [k], \u2200 , \u2208 [2]\n, v j, 2 = 1 and v j, \u22a5v j , when (j, ) = (j , ) although our work also extends to the \"incoherent\" case trivially. We denote by\nV def = {v j,1 , v j,2 } j\u2208[k] the set of all features.\nWe consider the following data and label distribution. Let C p be a global constant, s \u2208 [1, k 0.2 ] be a sparsity parameter. To be concise, we define the multi-view distribution D m and single-view distribution D s together. Due to space limitation, here we hide the specification of the random \"noise\", and defer the full definition to Appendix A. 4 Definition 3.1 (data distributions D m and D s ). Given D \u2208 {D m , D s }, we define (X, y) \u223c D as follows. First choose the label y \u2208 [k] uniformly at random. Then, the data vector X is generated as follows (also illustrated in Figure 5). 1. Denote V(X) = {v y,1 , v y,2 } \u222a V as the set of feature vectors used in this data vector X, where V is a set of features uniformly sampled from {v j ,1 , v j ,2 } j \u2208[k]\\{y} , each with probability s k .\n2. For each v \u2208 V(X), pick C p many disjoint patches in [P ] and denote it as P v (X) \u2282 [P ] (the distribution of these patches can be arbitrary). We denote P(X) = \u222a v\u2208V(X) P v (X).\n3. If D = D s is the single-view distribution, pick a value = (X) \u2208 [2] uniformly at random.", "publication_ref": ["b2", "b3"], "figure_ref": [], "table_ref": []}, {"heading": "4.", "text": "For each v \u2208 V(X) and p \u2208 P v (X), we set x p = z p v + \"noise\" \u2208 R d , where, the random coefficients z p \u2265 0 satisfy that:\nIn the case of multi-view distribution D = D m , \u2022 p\u2208Pv(X) z p \u2208 [1, O(1)] when v \u2208 {v y,1 , v y,2 }, 5 \u2022 p\u2208Pv(X) z p \u2208 [\u2126(1), 0.4] when v \u2208 V(X) \\ {v y,1 , v y,2 }, 6 In the case of single-view distribution D = D s , \u2022 p\u2208Pv(X) z p \u2208 [1, O(1)] when v = v y, , \u2022 p\u2208Pv(X) z p \u2208 [\u03c1, O(\u03c1)] when v = v y,3\u2212 , \u2022 p\u2208Pv(X) z p \u2208 [\u2126(\u0393), \u0393] when v \u2208 V(X) \\ {v y,1 , v y,2 }. 5.\nFor each p \u2208 [P ] \\ P(X), we set x p to consist only of \"noise\". Remark 3.2. The distribution of how to pick P(X) and assign p\u2208Pv(X) z p to each patch in p \u2208 P v (X) can be arbitrary (and can depend on other randomness in the data as well). In particular, we have allowed different features v j,1 , v j,2 to show up with different weights in the data (for example, for multi-view data, some view v y,1 can consistently have larger z p comparing to v y,2 ). Yet, we shall prove that the order to learn these features by the learner network can still be flipped depending on the randomness of network initialization.\nInterpretation of our data distribution. As we argue more in Appendix A, our setting can be tied to a down-sized version of convolutional networks applied to image classification data. With a small kernel size, good features in an image typically appear only at a few patches, and most other patches are random noise or low-magnitude feature noises. More importantly, our noise parameters shall ensure that, the concept class is not learnable by linear classifiers or constant degree polynomials. We believe a (convolutional) neural network with ReLU-like activation is somewhat necessary.\nOur final data distribution D, and the training data set Z are formally given as follows.\nDefinition 3.3 (D and Z). The distribution D consists of data from D m w.p. 1\u2212\u00b5 and from D s w.p. \u00b5. We are given N training samples from D, and denote the training data set as Z = Z m \u222aZ s where Z m and Z s respectively represent multi-view and single-view training data. We write (X, y) \u223c Z as (X, y) sampled uniformly at random from the empirical data set, and denote N s = |Z s |. We again for simplicity focus on the setting when \u00b5 = 1 poly(k) and we are given samples N = k 1.2 /\u00b5 so each label i appears at least \u2126(1) in Z s . Our result trivially applies to many other choices of N .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Learner Network", "text": "We consider a learner network using the following smoothed ReLU activation function ReLU: Definition 3.4. For integer q \u2265 2 and threshold = 1 polylog(k) , the smoothed function\nReLU(z) def = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 0 if z \u2264 0; z q q q\u22121 if z \u2208 [0, ]; z \u2212 (1 \u2212 1 q ) if z \u2265\nSince ReLU is smooth we denote its gradient as ReLU (z). We focus on q = 4 while our result applies to other constants q \u2265 3 (see appendix) or most other forms of smoothing. As mentioned in previous section, (smoothed) ReLU has a desired property such that ReLU(z) is linear when z is large, but becomes much smaller when z is small. This allows the network to effectively reduce the impact of low-magnitude feature noises from the input patches for better classification.\nThe learner network F (X) = (F 1 (X), . . . , F k (X)) \u2208 R k is a two-layer convolutional network parameterized by w i,r \u2208 R\nd for i \u2208 [k], r \u2208 [m], satisfying \u2200i \u2208 [k] : F i (X) = r\u2208[m] p\u2208[P ] ReLU( w i,r , x p )\nAlthough there exists network with m = 2 that can classify the data correctly (e.g. w i,r = v i,r for r \u2208 [2]), in this paper, for efficient optimization purpose it is convenient to work on a moderate level of over-parameterization: m \u2208 [polylog(k), k]. Our lower bounds hold for any m in this range and upper bounds hold even for small over-parameterization m = polylog(k).\nTraining a single model. We learn the concept class (namely, the labeled data distribution) using gradient descent with learning rate \u03b7 > 0, over the cross-entropy loss function L using N training data points Z = {(X i , y i )} i\u2208 [N ] . We denote the empirical loss as: X) . We randomly initialize the network F by letting each w\nL(F ) = 1 N i\u2208[N ] L(F ; X i , y i ) = E (X,y)\u223cZ [L(F ; X, y)] where L(F ; X, y) = \u2212 log e Fy (X) j\u2208[k] e F j (\n(0) i,r \u223c N (0, \u03c3 2 0 I) for \u03c3 2 0 = 1 k\n, which is the most standard initialization people use in practice. To train a single model, at each iteration t we update using gradient descent (GD): 7\nw (t+1) i,r \u2190 w (t) i,r \u2212 \u03b7 E (X,y)\u223cZ \u2207 w i,r L(F (t) ; X, y) (3.1)\nWe run the algorithm for T = poly(k) \u03b7 iterations. We use F (t) to denote the model F with hidden weights {w (t) i,r } at iteration t.\nNotations. We denote by logit i (F, X) X) . Using this, we can write down\ndef = e F i (X) j\u2208[k] e F j (\n\u2200i \u2208 [k], r \u2208 [m] : \u2212 \u2207 w i,r L(F ; X, y) = (1 i =y \u2212 logit i (F, X))\u2207 w i,r F i (X) .", "publication_ref": ["b1"], "figure_ref": [], "table_ref": []}, {"heading": "Main Theorems and Explanations", "text": "We now state the main theorems in this paper. 8 Recall the learner network and its learning process are given in Section 3.2, and the data distribution is in Section 3.1.\nTheorem 1 (single model). For every sufficiently large\nk > 0, every m \u2208 [polylog(k), k], every \u03b7 \u2264 1 poly(k)\n, suppose we train a single model using the gradient descent update (3.1) starting from the random initialization defined in Section 3.2, then after T = poly(k) \u03b7 many iterations, with probability \u2265 1 \u2212 e \u2212\u2126(log 2 k) , the model F (T ) satisfies:\n\u2022 (training accuracy is perfect): meaning for all (X, y) \u2208 Z, all i \u2208 [k]\\{y}: F (T ) y (X) > F (T ) i (X). 7 Our result also trivially extends to the case when there is a weight decay (i.e. 2 regularizer):\nw (t+1) i,r \u2190 (1 \u2212 \u03b7\u03bb)w (t)\ni,r \u2212 \u03b7 E (X,y)\u223cZ \u2207w i,r L(F (t) ; X, y) as long as \u03bb is not too large. We keep this basic version without weight decay to simplify the analysis. 8 We shall restate these theorems in the appendix with more details and wider range of parameters.\n\u2022 (test accuracy is consistently bad): meaning that:\nPr (X,y)\u223cD [\u2203i \u2208 [k] \\ {y} : F (T ) y (X) < F (T ) i (X)] \u2208 [0.49\u00b5, 0.51\u00b5] .\nWe shall give technical intuitions about why Theorem 1 holds in Appendix C. But, at a high-level, we shall construct a \"lottery winning\" set\nM \u2286 [k] \u00d7 [2] of cardinality |M| \u2208 [k(1 \u2212 o(1)), k].\nIt only depends on the random initialization of F . Then, with some effort we can prove that, for every (i, ) \u2208 M, at the end of the training F (T ) will learn feature v i, but not learn feature v i,3\u2212 . This means for those single-view data (X, y) with y = i and (X) = 3 \u2212 , the final network F (T ) will predict its label wrong. This is why the final test accuracy is around 0.5\u00b5. Note the property that test accuracy consistently belongs to the range [0.49\u00b5, 0.51\u00b5] should be reminiscent of message | in Figure 6, where multiple single models, although starting from different random initialization, in practice does have a relatively small variance in test accuracies.\nEnsemble. Suppose {F [ ] } \u2208[K] are K = \u2126(1) independently trained models of F with m = polylog(k) for T = O poly(k)\n\u03b7 iterations (i.e., the same setting as Theorem 1 except we only need a small over-parameterization m = polylog(k)). Let us define their ensemble\nG(X) = \u0398(1) K F [ ] (X) (4.1)\nOur next theorem states that the ensemble model has much higher test accuracy.\nTheorem 2 (ensemble). In the same setting as Theorem 1 except now we only need a small m = polylog(k), we have for the ensemble model G in (4.1), with probability at least 1 \u2212 e \u2212\u2126(log 2 k) :\n\u2022 (training accuracy is perfect): meaning for all (X, y) \u2208 Z, for all i \u2208 [k]\\{y}: G y (X) > G i (X).\n\u2022 (test accuracy is almost perfect): meaning that:\nPr (X,y)\u223cD [\u2203i \u2208 [k] \\ {y} : G y (X) < G i (X)] \u2264 0.001\u00b5 .\nAs we discussed in Section 2.3, the reason Theorem 2 holds attributes to the fact that those lottery winning sets M depend on the random initialization of the networks; and therefore, when multiple models are put together, their \"union\" of M shall cover all possible features {v i, } (i, )\u2208[k]\u00d7 [2] . Moreover, our theorem only requires individual K = \u2126(1) models for ensemble, which is indeed \"averaging the output of a few independently trained models\".\nRoadmap. We shall restate and prove the general versions of Theorem 1 and 2 in Appendix E, after establishing core lemmas in Appendix C and D.", "publication_ref": ["b7", "b6", "b7", "b1"], "figure_ref": [], "table_ref": []}, {"heading": "Knowledge Distillation for Ensemble", "text": "We consider a knowledge distillation algorithm given the existing ensemble model G (see (4.1)) as follows. For every label i \u2208 [k], let us define the truncated scaled logit as (for \u03c4 = 1 log 2 k ):\nlogit \u03c4 i (F, X) = e min{\u03c4 2 F i (X),1}/\u03c4 j\u2208[k] e min{\u03c4 2 F j (X),1}/\u03c4 (4.2)\n(This should be reminiscent of the logit function with temperature used by the original knowledge distillation work [42]; we use truncation instead which is easier to analyze.)\nNow, we train a new network F from random initialization (where the randomness is independent of all of those used in F [ ] ). At every iteration t, we update each weight w i,r by:\nw (t+1) i,r = w (t) i,r \u2212 \u03b7\u2207 w i,r L(F (t) ) \u2212 \u03b7 E (X,y)\u223cZ logit \u03c4 i (F (t) , X) \u2212 logit \u03c4 i (G, X) \u2212 \u2207 w i,r F (t) i (X) (4.3)\nNotation. Throughout the paper we denote by [a] + = max{0, a} and [a] \u2212 = min{0, a}. This knowledge distillation method (4.3) is almost identical to the one used in the original work [42], except we use a truncation during the training to make it more (theoretically) stable. Moreover, we update the distillation objective using a larger learning rate \u03b7 comparing to \u03b7 of the cross-entropy objective. This is also consistent with the training schedule used in [42].\nLet F (t) be the resulting network obtained by (4.3) at iteration t. We have the following theorem:\nTheorem 3 (ensemble distillation). Consider the distillation algorithm (4.3) in which G is the ensemble model defined in (4.1). For every k > 0, for m = polylog(k), for every \u03b7 \u2264 1 poly(k) , setting \u03b7 = \u03b7poly(k), after T = poly(k) \u03b7 many iterations with probability at least 1 \u2212 e \u2212\u2126(log 2 k) , for at least 90% of the iterations t \u2264 T :\n\u2022 (training accuracy is perfect): meaning for all (X, y) \u2208 Z, all i \u2208 [k] \\ {y}: F (t) y (X) > F (t) i (X).\n\u2022 (test accuracy is almost perfect): meaning that:\nPr (X,y)\u223cD [\u2203i \u2208 [k] \\ {y} : F (t) y (X) < F (t) i (X)] \u2264 0.001\u00b5 .\nWe shall restate the general version of Theorem 3 in Appendix F, and prove it in Appendix G.\nRemark. Theorem 3 necessarily means that the distilled model F has learned all the features {v i, } (i, )\u2208[k]\u00d7 [2] from the ensemble model G. This is consistent with our empirical findings in Figure 8: if one trains multiple individual models using knowledge distillation with different random seeds, then their ensemble gives no further performance boost.", "publication_ref": ["b41", "b41", "b41", "b1"], "figure_ref": ["fig_7"], "table_ref": []}, {"heading": "Self Knowledge Distillation as Implicit Ensemble", "text": "Self distillation [35,63] refers to training a single model to match the output of another single model. In this paper we also show that self-distillation can also improve test accuracy under our multi-view setting. Let us consider the following self-distillation algorithm.\nLet us now consider F = F (T ) , G = G (T ) be two single models trained in the same setting as Theorem 1 using independent random initializations (for simplicity, we override to notation a bit, so here G is a single model to be distilled from, instead of the ensemble). We scale them up by a small factor \u0398(1) similar to (4.1). Then, starting from F (T ) , we apply the following updates for another T iterations:\nw (t+1) i,r = w (t) i,r \u2212 \u03b7 E (X,y)\u223cZ logit \u03c4 i (F (t) , X) \u2212 logit \u03c4 i (G, X) \u2212 \u2207 w i,r F (t) i (X) (4.4)\nThis objective is considered as \"self-distillation\" since G is an individual model (trained using an identical manner as F , only from a different random initialization). In particular, if F = G, then logit \u03c4 i (F (t) , X) \u2212 logit \u03c4 i (G, X) = 0 so the weights are no longer updated. However, as we will actually prove, this training objective will actually learn an F that has better generalization comparing to G.\nThis time, for simplicity, let us make the following additional assumption on the data: Assumption 4.1 (balanced D m ). In Def. 3.1, for multi-view data (X, y), we additionally assume that the marginal distributions of p\u2208Pv(X) z q\np \u2208 [1, 1 + o(1)] for v \u2208 {v y,1 , v y,2 }.\nThe rationale for this assumption is quite simple. Suppose M is the aforementioned \"lottery winning\" set of training a single model without knowledge distillation. Assumption 4.1 will ensure that each (i, 1) and (i, 2) will belong to M F with relatively equal probability. If we train two models F and G, their combined lottery winning set M F \u222a M G shall be of cardinality around 3 2 k(1 \u2212 o(1)). Therefore, if we can distill the knowledge of G to F , the test accuracy can be improved from 1 \u2212 1 2 \u00b5 to 1 \u2212 1 4 \u00b5. See the following theorem: 9\nTheorem 4 (self-distillation). Under this additional Assumption 4.1, consider the distillation algorithm (4.4) where G is an independently trained single model (in the same setting as Theorem 1). For every k > 0, every m \u2208 [polylog(k), k], every \u03b7 \u2264 1 poly(k) , after T = poly(k) \u03b7 many iterations of algorithm (4.4), with probability at least 1 \u2212 e \u2212\u2126(log 2 k) :\n\u2022 (training accuracy is perfect): meaning for all (X, y) \u2208 Z, all i = y: F\n(T +T ) y (X) > F (T +T ) i (X).\n\u2022 (test accuracy is better): meaning that:\nPr (X,y)\u223cD [\u2203i \u2208 [k] \\ {y} : F (T +T ) y (X) < F (T +T ) i (X)] \u2264 0.26\u00b5\nRecall from Theorem 1, all individual models should have test error at least 0.49\u00b5 0.26\u00b5. Hence the model F generalizes better (comparing to both the original model F before self-distillation and the individual model G) after self-distillation to the individual model G. We shall restate the general version of Theorem 4 in Appendix F, and prove it in Appendix G.\nWhy does self-distillation improve test accuracy? Self-distillation is performing implicit ensemble + knowledge distillation. As the main idea of behind the proof, we actually show that self-distillation is performing implicit ensemble together with knowledge distillation. In particular, let M F , M G \u2286 V be the features learned by individual models F, G starting from (independent) random initializations W G respectively when trained on the original data set, now, if we further train the individual model F to match the output of individual model G, F is actually going to learn a larger set of features M G \u222aM F , where features in M F come from gradient of the original objective, and features in M G come from the gradient of the knowledge distillation objective w.r.t. G. This is equivalent to first ensemble F and G, then train an additional model H from random initialization to match the ensemble-Self-distillation implicitly merge \"ensemble individual models F , G and distill the ensemble to another individual model H\" into \"ensemble individual models F , G and distill the ensemble to the individual model F \" since F and H have the same structure. Then eventually it is merged directly into \"training an individual model F via self-distillation to match the output of an individual model G\".", "publication_ref": ["b34", "b62", "b2"], "figure_ref": [], "table_ref": []}, {"heading": "Our Empirical Results at a High Level", "text": "On the empirical side, to further justify our approach studying ensemble and knowledge distillation indeep learning, we show: 9 One can trivially relax Assumption 4.1 so that the two views have different distributions but with a constant ratio between their expectations; in this way the improved accuracy is no longer 1 \u2212 1 4 \u00b5 but shall depend on this constant ratio. For simplicity of this paper, we do not state the result of that more general case. \nG = \u2208[L]\nf directly? (As opposite to training each f independently and then average them.) Actually, this \"direct training\" approach in deep learning is unable to improve the test accuracy even comparing to single models, not to say the ensemble model. See Figure 6.\nIn contrast, when each f is a linear function over random feature mappings (e.g., the NTK feature mappings given by the random initialization of the network), although the ensemble of these random feature models does improve test accuracy, training directly over F = \u2208[L] f gives even superior test accuracy comparing to the ensemble. See Figure 6.\n\u2022 Knowledge distillation works for \"ensemble of neural networks\" but does not work  for \"ensemble of random feature mappings\" on standard data sets.\nWhen f is a linear function over random feature mappings (e.g., the NTK feature mappings), the superior test performance of ensemble cannot be distilled into a single model. In contrast, in deep learning, such superior performance can be distilled into a single model using [42]. The situation is similar for self-distillation, where it hardly works on improving test performance for neural kernel methods, but works quite well for real neural networks. See Figure 6. Together with the first point, experiments suggest that to understand the benefit of ensemble and knowledge distillation in deep learning, it is perhaps inevitable to study deep learning as a feature learning process, instead of feature selection process (e.g. NTK or other neural kernel methods) where only the linear combinations of prescribed features are trained.\n\u2022 Some prior works attribute the benefit of ensemble to reducing the variance of individual solutions [15,62,64,82,83] due to label noise or non-convex landscape of the training objective. We observe that this may not be the cause for \"ensemble in deep learning\" to work.\n-For standard deep learning datasets (e.g. CIFAR-10/100), individual neural networks (e.g. ResNets) trained by SGD typically have already converged to global optimas with 100% training accuracy and nearly zero training loss (no failure in training). -For standard deep learning datasets (e.g. CIFAR-10/100), ensemble helps even when there is essentially no label noise. In contrast, in our synthetic experiment Figure 7, ensemble does not help on Gaussian-like data even when there is label noise. -For standard neural networks (e.g. ResNets) trained on standard data set (e.g. CIFAR-10/100), when all the individual models are well-trained with the same learning rate/weight decay and only differ by their random seeds, there is almost no variance in test accuracy for individual models (e.g. 0.1 \u223c 0.4% std on CIFAR-100, see Figure 6). Hence with high probability, all individual models are learned almost equally well (no failure in generalization), yet ensemble still offers a huge benefit in test performance. -For neural networks trained on our Gaussian-like data, there is relatively higher variance (e.g. 0.5 \u223c 1.0% std in test accuracies, see Figure 12 in the appendix), yet ensemble offers no benefit at all. -For individual neural networks trained using knowledge distillation with different random seeds, ensemble does not improve their test accuracy by much (see Figure 8) -despite ", "publication_ref": ["b8", "b41", "b14", "b61", "b63", "b81", "b82"], "figure_ref": ["fig_6", "fig_0", "fig_7"], "table_ref": []}, {"heading": "\u2461 \u2462", "text": "Message \u2460: an ensemble over single models (independently trained) can be distilled into a single model with moderate accuracy loss. Message \u2461: an ensemble over models after knowledge distillation does not improve accuracy by much -in fact, not exceeding the ensemble accuracy of the original single models \u2462 -despite the training objective is still non-convex and different random seeds are used. This means, knowledge distillation models (i.e. simply matching the soft labels) have learned most of the features from the ensemble, and have less variety comparing to the original single models. This also means that \"(huge) non-convexity\" in neural networks and SGD with \"different random seeds\" even together do not guarantee ensemble advantage unconditionally; the structure of the data (and hard labels) is extremely important for ensemble to work as we mainly focus on in this paper. that the knowledge distillation objective is \"as non-convex as\" the original training objective and only the training labels are changed from hard to soft labels.\n\u2022 Special structure in data (such as the \"multi-view\" structure we shall introduce) is arguably necessary for ensemble to work. Over certain data sets with no multi-view structure, ensemble does not improve the test-time performance in deep learning -despite having a non-convex training objective and different random seeds are used. See Figure 7. In contrast, real-life data sets such as CIFAR-10/100 do have the multi-view structure, moreover, standard neural networks such as ResNet do utilize this structure during the training process in the same way as we show in our theory. See Figure 4.\n\u2022 For neural networks, knowledge distillation has learned most of the features from the ensemble, and the use of hard labels to train individual models is a key for why ensemble works in deep learning.\nSpecifically, as in Figure 8, if one evaluates an ensemble over models that are independently at random trained from knowledge distillation (i.e., using soft labels), its performance does not exceed the ensemble over the original single models. This means, models trained via knowledge distillation have learned most of the features from the ensemble, and has less variety comparing to the original models. We shall see this is consistent with our theoretical result.", "publication_ref": [], "figure_ref": ["fig_6", "fig_10", "fig_7"], "table_ref": []}, {"heading": "Conclusion and Discussion", "text": "In this work, we have shown, to the best of our knowledge, the first theoretical result towards understanding how ensemble work in deep learning. As our main contribution, we provide empirical evidence that ensemble might work very differently in deep learning comparing to ensemble in random feature models. Moreover, ensemble does not always improve test accuracy in deep learning, especially when the input data comes from Gaussian-like distribution.\nMotivated by these empirical observations, we propose a generic structure of the data we refer to as multi-view, and prove that ensemble improves test accuracy for two-layer neural networks in this setting. Moreover, we also prove that ensemble model can be distilled into a single model. Meaning that, through training a single model to \"simulate\" the output of the ensemble over the Figure 9: Justify the multi-view hypothesis in practice. We regard some intermediate layer of a pre-trained ResNet as \"input\" with multiple channels (this pre-trained network stays fixed and shared for all individual models).\nThen, we train a new model either starting from this input (i.e. the \"original \" column), or from a fraction of the input (i.e., \"split into 4 \" means using only 1/4 of the input channels), or from an average of the input (i.e., \"average over 4 \" means averaging every four channels). Details in Appendix B.3. Observation 1. Even when we significantly collapse the input channels (through averaging or throwing away most of them), most of the single model test accuracies do not drop by much. Moreover, it's known [65] that in ResNet, most channels are indeed learning different features (views) of the input, also see Figure 3 for an illustration. This indicates that many data can be classified correctly using different views. Observation 2. Even when single model accuracy drops noticeably, ensemble accuracy does not change by much. We believe this is a strong evidence that there are multiple views in the data (even at intermediate layers), and ensemble can collect all of them even when some models have missing views.\nsame training data set, single model is able to match the test accuracy of the ensemble, and thus being superior to any single model that is clean, directly trained on the original data's labels.\nWe believe that our framework can be applied to other settings as well, for example, data augmentation using random cropping could be potentially regarded as another way to enforce the network to learn \"multi-views\". We hope that our new theoretical insights on how neural networks pick up features during training can also help in practice design new, principled approach to improve test accuracy of a neural network, potentially matching that of the ensemble.", "publication_ref": ["b64"], "figure_ref": ["fig_30", "fig_4"], "table_ref": []}, {"heading": "Appendix I: Missing Details", "text": "In Section A, we give a formal definition of the data distribution: this expands the earlier Section 3.1 by giving more discussions and the full specifications of the noise parameters.\nIn Section B, we give the experiment setups and some additional experiments.\nAppendix II gives the full proofs, but it will start with Section C for technical intuitions and the proof plan.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A Data Distribution and Notations (Full Version)", "text": "We consider learning a k-class classification problem over P -patch inputs, where each patch has dimension d. In symbols, each labelled data is represented by (X, y) where X = (x 1 , x 2 , \u2022 \u2022 \u2022 , x P ) \u2208 (R d ) P is the data vector and y \u2208 [k] is the data label. For simplicity, we focus on the case when P = k 2 , and d = poly(k) for a large polynomial.\nWe consider the setting when k is sufficiently large. 10 We use \"w.h.p.\" to denote with probability at least 1 \u2212 e \u2212\u2126(log 2 k) , and use O, \u0398, \u2126 notions to hide polylogarithmic factors in k.\nWe first assume that each label class j \u2208 [k] has multiple associated features, say two features for the simplicity of math, represented by unit feature vectors v j,1 , v j,2 \u2208 R d . For notation simplicity, we assume that all the features are orthogonal, namely,\n\u2200j, j \u2208 [k], \u2200 , \u2208 [2]\n, v j, 2 = 1 and v j, \u22a5v j , when (j, ) = (j , ) although our work also extends to the \"incoherent\" case trivially. We denote by\nV def = {v j,1 , v j,2 } j\u2208[k]\nthe set of all features.\nWe now consider the following data and label distribution. Let C p be a global constant, s \u2208 [1, k 0.2 ] be a global parameter to control feature sparsity, \u03c3 p = 1 \u221a dpolylog(k) be a parameter to control magnitude of the random noise, \u03b3 = 1 k 1.5 be a parameter to control the feature noise. (Our proof in the appendix holds for a wider range of \u03b3.)\nTo be concise, we define the multi-view distribution D m and single-view distribution D s together.\nDefinition 3.1 (data distributions D m and D s ). Given D \u2208 {D m , D s }, we define (X, y) \u223c D as follows. First choose the label y \u2208 [k] uniformly at random. Then, the data vector X is generated as follows (also illustrated in Figure 5).\n1. Denote V(X) = {v y,1 , v y,2 } \u222a V as the set of feature vectors used in this data vector X, where V is a set of features uniformly sampled from {v j ,1 , v j ,2 } j \u2208[k]\\{y} , each with probability s k .\ncomment: (X, y) shall be primarily supported on two main features vy,1, vy,2 and \u223c O(s) minor features 2. For each v \u2208 V(X), pick C p many disjoint patches in [P ] and denote it as P v (X) \u2282 [P ] (the distribution of these patches can be arbitrary). We denote P(X) = \u222a v\u2208V(X) P v (X).\ncomment: the weights of X on each feature v shall be written on patches in Pv(X)\n3. If D = D s is the single-view distribution, pick a value = (X) \u2208 [2] uniformly at random.", "publication_ref": ["b9"], "figure_ref": [], "table_ref": []}, {"heading": "4.", "text": "For each v \u2208 V(X) and p \u2208 P v (X), we set\nx p = z p v + v \u2208V \u03b1 p,v v + \u03be p \u2208 R d\nAbove, each \u03b1 p,v \u2208 [0, \u03b3] is the feature noise, and \u03be p \u223c N (0, \u03c3 2 p I) is an (independent) random Gaussian noise. The coefficients z p \u2265 0 satisfy that:\nIn the case of multi-view distribution D = D m , \u2022 p\u2208Pv(X) z p \u2208 [1, O(1)\n] when v \u2208 {v y,1 , v y,2 }, and the marginal distribution of p\u2208Pv(X) z p is left-close; 11 \u2022 p\u2208Pv(X) z p \u2208 [\u2126(1), 0.4] when v \u2208 V(X) \\ {v y,1 , v y,2 }, and the marginal distribution of p\u2208Pv(X) z p is right-close. 12 comment: total weights on features vy,1, vy,2 are larger than those on minor features V(X) \\ {vy,1, vy,2}\nIn the case of single-view distribution D = D s ,\n\u2022 p\u2208Pv(X) z p \u2208 [1, O(1)] when v = v y, , \u2022 p\u2208Pv(X) z p \u2208 [\u03c1, O(\u03c1)] when v = v y,3\u2212 , comment: we consider \u03c1 = k \u22120.01 for simplicity \u2022 p\u2208Pv(X) z p \u2208 [\u2126(\u0393), \u0393] when v \u2208 V(X)\\{v y,1 , v y,2 }. we consider \u0393 = 1 polylog(k)\nfor simplicity comment: total weight on feature v y, is much larger than those on v y,3\u2212 or minor features 5. For each p \u2208 [P ] \\ P(X), we set:\nx p = v \u2208V \u03b1 p,v v + \u03be p\nwhere \u03b1 p,v \u2208 [0, \u03b3] is the feature noise and \u03be p \u223c N (0, \u03b3 2 k 2 d I) is (independent) Gaussian noise. Remark A.1. The distribution of how we pick P(X) and how to assign p\u2208Pv(X) z p to each patch in p \u2208 P v (X) can be arbitrary (and can depend on other randomness in the data as well). Except the marginal distributions of the sum of some z p 's are left-close or right-close, but we also do not have other restrictions on how z p 's are distributed within the summation. In particular, we have allowed different features v j,1 , v j,2 to show up with different weights in the data (for example, for multi-view data, some view v y,1 can consistently have larger z p comparing to v y,2 .) Yet, we shall prove that the order to learn these features by the learner network can still be flipped depending on the randomness of network initialization. We also do not have any restriction on the distribution of the feature noise \u03b1 p,v (they can depend on other randomness of the data distribution as well).\nGenerality and significance of our data distribution. Our setting is tied to a down-sized version of convolutional networks applied to image classification data. With a small kernel size, good features of an image typically appear only at a few patches, 13 and most other patches are simply random noise or low-magnitude feature noises that are less relevant to the label. 11 We say a distribution p over a real interval\n[a, b] for constants a, b is left-close, if there is a \u03b5 \u2264 1 polylog(k) such that Prz\u223cp[z \u2264 a + \u03b5] \u2265 1 polylog(k) , and is right-close if Prz\u223cp[z \u2265 b \u2212 \u03b5] \u2265 1 polylog(k)\n. For instance, here Z = p\u2208Pv (X) zp can be a uniform distribution over [1,2]. This assumption is simply to avoid the case when the distribution is too skewed.\n12 For instance, Z = p\u2208Pv (X) zp can be a uniform distribution over [0.2, 0.4]. 13 For example, in image classification when the image is of size 64 \u00d7 64, at the first layer, each patch can be a sub-image of size d = 48 = 4 \u00d7 4 \u00d7 3 (3 RGB channels), and there are 256 patches. At the second layer, we can have higher dimension d per patch, such as d = 4 \u00d7 4 \u00d7 64 when more channels are introduced. In convolutional networks, there are typically over-laps between patches, we point out that our setting is more general: In fact, for example for a data X = (a, b, c, d) with patches (a, b, c) and (b, c, d), we can simply define x1 = (a, b, c) and x2 = (b, c, d). Moreover, our X can also be viewed as intermediate output of the previous convolution layer in a convolution network.\nMore importantly, the above concept class (namely, labeled data distribution in Def. 3.1) is not learnable by linear classifiers or constant degree polynomials. Indeed, if we only use a linear classifier, then the total accumulated (low-magnitude) feature noise from all patches can be as large as \u03b3P 1 by our choice of \u03b3 = 1 k 1.5 and P = k 2 . This is much larger than the magnitude of the signal. On the other hand, by Markov brother's inequality, low-degree polynomials also lack the power to be approximately linear (to fit the signal) when the input is large, while being sub-linear when there are low-magnitude feature noises. We also conjecture that one can prove this concept class is not efficiently learnable by kernel methods in general, using the recent development of kernel lower bounds [2,4]. Thus, we believe a (convolutional) neural network with ReLU-like activation is in some sense necessary to learn this concept class.\nOur final data distribution D, and the training data set Z are formally given as follows. We again for simplicity focus on the setting when \u00b5 = 1 poly(k) and we are given samples N = k 1.2 /\u00b5 so each label i appears at least \u2126(1) in Z s . Although our result trivially applies to other choices of N .", "publication_ref": ["b10", "b11", "b12", "b10", "b0", "b1", "b12", "b1", "b3"], "figure_ref": [], "table_ref": []}, {"heading": "B Experiment Details", "text": "Our real-life experiments use the CIFAR-10/100 datasets [49]. The SimpleCNN architecture we have used comes from [8], and the (pre-activation) ResNet architecture we have used comes from the wide resnet work [88]. For instance, SimpleCNN-10-3 stands for the 10-layer architecture in [8] but widened by a factor of 3; and ResNet-34-2 stands for the 34-layer wide resnet architecture in [88] and the widening factor is 2.\nFor training regular neural networks, it is well-known that SGD with momentum and 0.1 learning rate is a state-of-the-art training method. We use batch size 125, train for 140 epochs, and decay the learning rate thrice at epochs 80, 100 and 120 each by a factor 0.2. 14 We use standard random crop, random flip, normalization, and cutout augmentation [77] for the training data.\nFor training neural-kernel models (NTKs), we find Adam a better training algorithm with an initial learning rate 0.001. We use batch size 50, train for 200 epochs, and decay the learning rate twice at epochs 140 and 170 each by a factor 0.2. We use ZCA data preprocessing which has been reported very helpful for improving neural kernel methods' performance together with cutout augmentation [77]. 15 ", "publication_ref": ["b48", "b7", "b87", "b7", "b87", "b13", "b76", "b76", "b14"], "figure_ref": [], "table_ref": []}, {"heading": "B.1 Real-Life Data: Single Model vs Ensemble vs Distillation", "text": "For our experiment inFigure 6, we compare the performance of neural kernel methods vs. real neural networks on the standard CIFAR-10/100 datasets.\nWhen presenting the single-model accuracies in Figure 6, we simply run the training algorithms 10 times from independently randomly initialized seeds. The NTK models we present the best accuracies among the 10 runs, and for ResNet models we present the mean and standard deviations.\nWhen presenting the ensemble accuracies in Figure 6, we simply take an average of the 10 independently training models' outputs and use that to predict test labels.\nWhen presenting the \"directly train f \" result in Figure 6, we directly train a larger network consists of averaging 10 single models (separately, independently initialized). We use the same training algorithm as that for training single models. For some of the NTK models, our 16GB GPU memory sometimes only allows us to train an average of fewer than 10 single models; and when we do so, we have put a \u2666 remark in Figure 6. 16 When presenting the \"knowledge distillation\" result in Figure 6, we adopt the original knowledge distillation objective of [42]. It is very similar to (4.3) that we used in our theoretical proof (see (4.3). It has a weight parameter for the ratio between standard cross-entropy vs the distillation objective (known as \u03b7 \u03b7 in (4.3)), and they have a temperature parameter that controls the distillation objective (that is very similar to our \u03c4 parameter in (4.3)). We have tuned both parameters in a reasonable range to get the best distillation accuracy.\nWhen presenting the \"self-distillation\" result in Figure 6, we divide the training process of a single model into two stages: in the first stage it uses the original cross-entropy loss with hard training labels and records the best model in the checkpoints, and in the second stage it trains another single model from random initialization using the distillation objective of [42] to match the output of the previously recorded best model. Remark B.1. We confirm two more experimental findings that we did not include in Figure 6. First, one can repeat self-distillation multiple times but the test accuracy gain becomes very incremental. Second, one can alternatively use a three-stage process for self-distillation like we did in our theoretical result (see Section 4.2): namely, train two independent single models F and G, and then continue to train G by distilling it to match the output of F . The resulting test accuracy is extremely close to that of the two-stage process.", "publication_ref": ["b15", "b41", "b41"], "figure_ref": [], "table_ref": []}, {"heading": "B.2 Real-life Data: Ensemble over Distillations of Ensemble", "text": "For our experiment inFigure 8, we have studied the process of (1) training 10 independent single models, (2) evaluating their ensemble, (3) training 10 independent single models using knowledge distillations to match the outputs of (2), and (4) evaluating their ensemble.\nThe process of ( 1) and ( 2) are identical to that in Section B.1.\nTo present (3), we first apply parameter tuning for the knowledge distillation objective (see Section B.1). Then, we fix the best-selected parameters and perform knowledge distillation 10 times. In other words, these 10 runs differ only in the random seeds used in their initialization and SGD, but are identical in learning rate, weight decay, knowledge distillation parameters, and all other parameters.\nFinally, ( 4) is a simple (unweighted) average over the 10 models produced by (3).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B.3 Real-life Data: Justifying the Multi-View Assumption", "text": "We also perform an experiment inFigure 9 to justify that in real-life training, there is strong evidence that there are multiple views of the data-even at some intermediate layers-to justify the image labels.\nRecall that ResNet has three blocks of layers. In the (a) version of the experiment, we take a pre-trained model, and view its output at the end of the first block as \"input\", to train a new model where the trainable parameters are the second and third blocks. In the (b) version of the experiment, ew view the pre-trained model's output at the end of the second block as \"input\", to train a new model where the trainable parameters are in the third block only.\nSpecifically, we consider ResNet-28-M version (a) and (b) for M \u2208 {1, 2, 4, 10}. For instance, the new \"input\" has N = 32 channels for the case of \"ResNet-28-2 version (a)\", and has N = 320 channels for the case of \"ResNet-28-10 version (b).\"\nFor each of the settings above, we \u2022 split the input into 8 chunks (with N/8 channels) and train 1 model each, totaling 8 models;\n\u2022 split the input into 4 chunks (with N/4 channels) and train 2 models each, totaling 8 models;\n\u2022 split the input into 2 chunks (with N/2 channels) and train 4 models each, totaling 8 models;\n\u2022 average the input into N/8 channels (by averaging over every 8 channels) and train 8 models;\n\u2022 average the input into N/4 channels (by averaging over every 4 channels) and train 8 models;\n\u2022 average the input into N/2 channels (by averaging over every 2 channels) and train 8 models.\nWe call those 8 models \"single models\" and present their accuracies in the first half of the rows of Figure 9.\nNext, we also present the ensemble accuracy of these 8 single models in the second half of the rows of Figure 9. (Note for the 8 single models, also use 8 different seeds for the upper-layer pre-trained models. This allows us to compare the ensemble accuracies in a more fair manner.)", "publication_ref": [], "figure_ref": ["fig_30", "fig_30"], "table_ref": []}, {"heading": "B.4 Synthetic Data: Whether Ensemble Improves Accuracy over Gaussian-Like Data", "text": "Recall inFigure 7 we have shown that ensemble does not seem to improve test accuracy on Gaussian-like data. We explain how we perform this experiment.\nSynthetic data generation. We generate synthetic data with k = 10 labels.\n\u2022 We consider inputs that are generated as either Gaussian or mixture of Gaussian with different means.\n\u2022 We consider inputs that are either uniformly generated, or generated through rejection sampling (so as to make different labels to have roughly the same number of data).\n\u2022 We consider data that are either without label noise, or with 10% of the label randomly flipped.\n\u2022 We consider data that are generated from a relatively small (but unknown to the learner) ground-truth network, that are either linear, or fully-connected (e.g. fc2 for 2 layers), or convolutional (e.g. conv3 for 3 layers), or residual (e.g. res3 for 3-layered residual and resconv3 for 3-layered residual convolutional).\n\u2022 We consider data that are either generated as above, or generated with margin across labels.\n\u2022 Finally, for each of the settings above, we select a dimension d so that the single-model testing accuracy is around 60% \u223c 80%.\nLearner networks. We also consider fully-connected, convolutional, as well as residual networks with m = 200 neurons to learn the given data distribution. For each data/learner pair, we use SGD with momentum 0.9, and tune the learning rate together with weight decay parameters so as to maximize test accuracy. We run for 10 single models and compare their (best) accuracy to their ensemble accuracy.\nResult: single vs ensemble. Our detailed comparison tables are in Figure 10 (for non-convolutional inputs) and Figure 11 (for convolutional inputs). To make the result more easily interpretable, we have included in Figure 7 an abbreviated table which, for each data distribution, picks the best single and best ensemble model across all learner networks. It is clear from these reported results that, for a plethora of settings of Gaussian-like datasets, the accuracy given by ensemble barely exceeds that of single models.\nResult: accuracy consistency on single models. For our synthetic datasets, we have also computed the mean and standard deviation for the 10 trained single models from different random initializations. We observe that their standard deviation is also negligible comparing the already not-so-great accuracy: for instance, a standard deviation of 1.0% is quite small comparing to a 70% test accuracy model on the test data. See Figure 12.  6), yet ensemble still offers nearly no benefit.\nAppendix II: Complete Proofs C Single Model: Proof Plan and Induction Hypothesis\nOur main proof relies on an induction hypothesis for every iteration t = 0, 1, 2, . . . , T . Before we state it, let us introduce several notations. Let us denote\n\u039b (t) i def = max r\u2208[m], \u2208[2] [ w (t) i,r , v i, ] + and \u039b (t) i, def = max r\u2208[m] [ w (t) i,r , v i, ] + (C.1) Suppose m \u2264 poly(k). For every i \u2208 [k], let us denote M (0) i def = r \u2208 [m] \u2203 \u2208 [2] : w (0) i,r , v i, \u2265 \u039b (0) i, 1 \u2212 O 1 log k Intuition. If a neuron r \u2208 [m] is not in M (0)\ni , it means that for both \u2208 {1, 2}, the correlation w (0) i,r , v i, at the random initialization is, by a non-trivial factor, smaller than \u039b (0) i, -the largest correlation between w i,r , v i, among all neurons. In words, this means the magnitude of v i,1 and v i,2 inside the random initialization w (0) i,r is non-trivially lagging behind, comparing to other neurons. We shall prove that, through the course of the training, those neurons r will lose the lottery and not learn anything useful for the output label i \u2208 \nM def = (i, * ) \u2208 [k] \u00d7 [2] \u039b (0) i, * \u2265 \u039b (0) i,3\u2212 * S i,3\u2212 * S i, * 1 q\u22122 1 + 1 log 2 (m) (C.2)\nIntuition. If (i, ) \u2208 M, we shall prove that the feature v i, has a higher chance than v i,3\u2212 to be learned by the model. (This is because, after an appropriate scaling factor defined by the training data, v i, correlates more with the network's random initialization comparing to v i,3\u2212 .)\nOur next proposition states that, for every i \u2208 [k], with decent probability at least one of (i, 1) or (i, 2) shall be in M. But more importantly, our later Induction Hypothesis C.3e ensures that, during the entire training process, if (i, 3 \u2212 ) \u2208 M, then v i, must be missing from the learner network. They together imply that test accuracy on single-view data cannot exceed 49.99%, as one of the views shall be missing.\nOn the other hand, our next proposition also ensures that the \"weaker\" feature among the two, still has some non-negligible chance to be picked up by the random initialization. This is behind the reason that why ensemble works in our later proofs. Proposition C.2. Suppose m \u2264 poly(k). We have the following properties about M.\n\u2022 For every i \u2208 [k], at most one of (i, 1) or (i, 2) is in M (obvious).\n\u2022\nFor every i \u2208 [k], suppose S i, \u2265 S i,3\u2212 , then Pr (i, 3 \u2212 ) \u2208 M \u2265 m \u2212O(1) . \u2022 For every i \u2208 [k], Pr (i, 1) \u2208 M or (i, 3) \u2208 M \u2265 1 \u2212 o(1).\n(Proposition C.2 is a result of the anti-concentration of the maximum of Gaussian, see Appendix H.)\nWe are now ready to state our induction hypothesis.", "publication_ref": [], "figure_ref": ["fig_0", "fig_0", "fig_6", "fig_0"], "table_ref": []}, {"heading": "Induction Hypothesis C.3. For every \u2208 [2]", "text": ", for every r \u2208 [m], for every (X, y) \u2208 Z m and i \u2208 [k], or for every (X, y) \u2208 Z s and i \u2208 [k] \\ {y}:\n(a) For every p \u2208 P v i, (X), we have:\nw (t) i,r , x p = w (t) i,r , v i, z p \u00b1 o (\u03c3 0 ).\n(b) For every p \u2208 P(X) \\ P v i,1 (X) \u222a P v i,2 (X) , we have\n: | w (t) i,r , x p | \u2264 O(\u03c3 0 ).\n(c) For every p \u2208 [P ] \\ P(X), we have\n: | w (t) i,r , x p | \u2264 O(\u03c3 0 \u03b3k). In addition, for every (X, y) \u2208 Z s , every i \u2208 [k], every r \u2208 [m], every \u2208 [2],\n(d) For every p \u2208 P v i, (X), we have:\nw (t) i,r , x p = w (t) i,r , v i, z p + w (t) i,r , \u03be p \u00b1 O(\u03c3 0 \u03b3k) (e) For every p \u2208 P v i, (X), if (i, 3 \u2212 ) \u2208 M we have: | w (t) i,r , x p | \u2264 O(\u03c3 0 ). (f ) For every p \u2208 P v i, (X), if r \u2208 [m] \\ M (0) i we have: | w (t) i,r , x p | \u2264 O(\u03c3 0 ). Moreover, we have for every i \u2208 [k], (g) \u039b (t) i \u2265 \u2126(\u03c3 0 ) and \u039b (t) i \u2264 O(1). (h) for every r \u2208 [m], every \u2208 [2], it holds that w (t) i,r , v i, \u2265 \u2212 O(\u03c3 0 ). (i) for every r \u2208 [m] \\ M (0) i , every \u2208 [2], it holds that w (t) i,r , v i, \u2264 O(\u03c3 0 ).\nIntuition. The first three items in Induction Hypothesis C.3 essentially say that, when studying the correlation between w i,r with a multi-view data, or between w i,r with a single-view data (but y = i), the correlation is about w i,r , v i,1 and w i,r , v i,2 and the remaining terms are sufficiently small. (Of course, this requires a careful proof.) We shall later prove that at least one of \u039b\n(t) i,1 or \u039b (t)\ni,2 is large after training. Therefore, using the first three items, we can argue that all multi-view data are classified correctly.\nThe middle three items in Induction Hypothesis C.3 essentially say that, when studying the correlation between w i,r with a single-view data (X, y) with y = i, then the correlation also has a significant noise term w (t) i,r , \u03be p . This term shall become useful for us to argue that single-view data can be all memorized (through for instance memorizing the noise).\nThe remaining items in Induction Hypothesis C.3 are just some regularization statements.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "D Single Model: Technical Proofs", "text": "We devote this section to prove that Induction Hypothesis C.3 holds for every iteration t \u2264 T , and in the next Section E, we state how the induction hypothesis easily implies our main theorems for single model and ensemble model.\nParameter D.1. We state the range of parameters for our proofs in this section to hold.\n\u2022 = 1 polylog(k)\n(recall is the threshold for the smoothed ReLU activation)\n\u2022 \u0393 = 1 polylog(k)\n(recall \u0393 controls off-target feature magnitude in Def. 3.1)\n\u2022 q \u2265 3 and \u03c3 q\u22122\n0 = 1 k (recall w (0) i,r \u223c N (0, \u03c3 2 0 I) gives the initialization magnitude) \u2022 N s \u2264 o(k/\u03c1) and N s \u2264 k 2 s \u03c1 q\u22121 .\n(recall Ns is the size of single-view training data)\n\u2022 \u03b3 \u2264 O( \u03c3 0 k ) and \u03b3 q \u2264 \u0398 1 k q\u22121 mP\n(recall \u03b3 controls feature noise in Def. 3.1)\n\u2022 polylog(k) \u2264 s \u2264 k 0.2 (recall s controls feature sparsity in Def. 3.1)\n\u2022 \u03c1 q\u22121 \u2265 1 k (recall \u03c1 controls on-target feature magnitude of single-view data in Def. 3.1)\n\u2022 N \u2265 N s \u2022 poly(k), \u03b7T \u2265 N \u2022 poly(k), and\n\u221a d \u2265 \u03b7T \u2022 poly(k). \u2022 polylog(k) \u2264 m \u2264 O( s\u03c3 q 0 ).\nExample. A reasonable set of parameters is, up to polylogarithmic factors:\nq = 4, \u03c3 0 = 1 \u221a k , \u03c1 = 1 k 0.2 , m \u2264 k, s \u2264 k 0.2 , N s \u2264 k 1.2 , P \u2264 k 2 , \u03b3 \u2264 1 k 1.5 . Theorem D.2. Under Parameter D.1, for any m \u2208 \u2126(1), O( 1 s\u03c3 q 0\n) and sufficiently small \u03b7 \u2264 1 poly(k) , our Induction Hypothesis C.3 holds for all iterations t = 0, 1, . . . , T .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "D.1 Gradient Calculations and Function Approximation", "text": "Gradient calculations. Recall logit i (F, X) def = e F i (X) j\u2208[k] e F j (X) . Recall also Fact D.3. Given data point (X, y) \u2208 D, for every i \u2208 [k], r \u2208 [m], \u2212\u2207 w i,r L(F ; X, y) = (1 \u2212 logit i (F, X)) p\u2208[P ] ReLU ( w i,r , x p )x p when i = y (D.1) \u2212\u2207 w i,r L(F ; X, y) = \u2212logit i (F, X) p\u2208[P ] ReLU ( w i,r , x p )x p when i = y (D.2)\nNow, we also have the following observations: \n\u03c3 0 k(mP ) 1/q ) , then \u2022 for every (X, y) \u2208 Z and every i \u2208 [k]: logit i (F (t) , X) = O e O(\u039b (t) i )m 0 e O(\u039b (t) i )m 0 +k \u2022 for every (X, y) \u2208 Z s and i \u2208 [k] \\ {y}: logit i (F (t) , X) = O 1 k 1 \u2212 logit y (F (t) , X) Proof of Claim D.4. Recall F (t) i (X) = r\u2208[m] p\u2208[P ] ReLU( w (t) i,r , x p ). For every r \u2208 M1\ni , using Induction Hypothesis C.3i we have\np\u2208[P ] ReLU( w (t) i,r , x p ) \u2264 O(\u03c3 q 0 ) \u2022 s + O((\u03c3 0 \u03b3k) q ) \u2022 P \u2264 1 mpolylog(k)\nso they sum up to at most\n1 polylog(k) . For any r \u2208 M (0) i , we have p\u2208[P ] ReLU( w (t) i,r , x p ) \u2264 \u2208[2] w (t) i,r , v i, + \u2022 p\u2208P v i , (X) z p + o(\u03c3 0 ) + O(\u03c3 q 0 ) \u2022 s + O((\u03c3 0 \u03b3k) q ) \u2022 P \u2264 \u2208[2] w (t) i,r , v i, + \u2022 p\u2208P v i , (X) z p + O( 1 m 0 )\nRecall from Def. 3.1 we have p\u2208P v i , (X) z p \u2264 O(1); and furthermore when (X, y) \u2208 Z s and i \u2208\n[k] \\ {y} we have p\u2208P v i , (X) z p \u2264 \u0393 = 1 polylog(k) . In the former case, we have\n0 \u2264 F (t) i (X) \u2264 m 0 \u2022 \u039b (t) i \u2022 O(1) + O(1)\nand this proves the first bound; in the latter case we have\n0 \u2264 F (t) i (X) \u2264 m 0 \u2022 \u039b (t) i \u2022 \u0393 + O(1) \u2264 O(1) (D.3)\nand this proves the second bound.\nDefinition D.5. For each data point X, we consider a value V i,r, (X) given as:\nV i,r, (X) def = 1 v i, \u2208V(X) p\u2208Pv i, (X)\nReLU ( w i,r , x p )z p Definition D.6. We define four error terms that shall be used frequently in our proofs.\nE 1 := O(\u03c3 q\u22121 0 )\u03b3s E 2,i,r (X) := O(\u03b3(V i,r,1 (X) + V i,r,2 (X)\n))\nE 3 := O(\u03c3 0 \u03b3k) q\u22121 \u03b3P E 4,j, (X) := O(\u03c3 0 ) q\u22121 1 v j, \u2208V(X)\nwe first bound the positive gradient (namely for i = y):\nClaim D.7 (positive gradient). Suppose Induction Hypothesis C.3 holds at iteration t. For every (X, y) \u2208 Z, every r \u2208 [m], every \u2208 [2], and i = y, we have\n(a) \u2212\u2207 w i,r L F (t) ; X, y , v i, \u2265 V i,r, (X) \u2212 O(\u03c3 p P ) 1 \u2212 logit i (F (t) , X) (b) \u2212\u2207 w i,r L F (t) ; X, y , v i, \u2264 (V i,r, (X) + E 1 + E 3 ) 1 \u2212 logit i (F (t) , X) (c) For every j \u2208 [k] \\ {i}, \u2207 w i,r L(F (t) , X, y), v j, \u2264 1 \u2212 logit i F (t) , X (E 2,i,r (X) + E 1 + E 3 + E 4,j, (X))\nProof of Claim D.7. We drop the superscript (t) for notational simplicity. Using the gradient formula from (D.1) (in the case of i = y), and the orthogonality among feature vectors, we have\n\u2212\u2207 w i,r L (F ; X, y) , v j, = (1 \u2212 logit i (F, X))\u00d7 \uf8eb \uf8ec \uf8ed1 v j, \u2208V(X) p\u2208Pv j, (X) ReLU ( w i,r , x p )z p + p\u2208[P ] ReLU ( w i,r , x p )\u03b1 p,v j, \u00b1 p\u2208[P ] | v j, , \u03be p | \uf8f6 \uf8f7 \uf8f8\nUsing the randomness of \u03be p , we have (recalling\n\u03c3 p = 1 \u221a dpolylog(k) and \u03b3 \u2264 1 k ) p\u2208[P ] | v j, , \u03be p | \u2264 O(\u03c3 p \u2022 s + \u03b3k \u221a d \u2022 P ) O(\u03c3 p \u2022 P )\nWhen j = i we have v i, \u2208 V(X) so this proves Claim D.7a. Using Induction Hypothesis C.3, we have \u2022 For every p \u2208 P v i,1 (X) \u222a P v i,2 (X), we have:\nReLU ( w i,r , x p ) \u2208 [0, 1].\n\u2022 For every p \u2208 P(X) \\ P v i,1 (X) \u222a P v i,2 (X) , we have:\nReLU ( w (t) i,r , x p ) \u2208 0, O(\u03c3 q\u22121 0 ) .\n\u2022 For every p \u2208 [P ] \\ P(X), we have:\nReLU ( w (t) i,r , x p ) \u2208 0, O((\u03c3 0 \u03b3k) q\u22121 )\n]. Using the sparsity from Def. 3.1, we have |P(X) \\ P v i,1 (X) \u222a P v i,2 (X) | \u2264 O(s). Combining this with \u03b1 p,v \u2264 \u03b3, and setting j = i, this proves Claim D.7b.\nFinally, when j = i, using Induction Hypothesis C.3 we additionally have\n\u2022 When v j, \u2208 V(X) and p \u2208 P v j, (X), we have ReLU ( w i,r , x p ) \u2264 O(\u03c3 q\u22121 0 )\n\u2022 For p \u2208 P v i,1 (X) \u222a P v i,2 (X), we have a more precise bound using Induction Hypothesis C.3a:\np\u2208Pv i, (X) ReLU ( w i,r , x p ) \u2264 p\u2208Pv i, (X) ReLU ( w i,r , v i, + o(\u03c3 0 )) \u2264 p\u2208Pv i, (X) ReLU ( w i,r , v i, + o(\u03c3 0 ))z p \u2264 p\u2208Pv i, (X) ReLU ( w i,r , x p )z p + o(\u03c3 0 ) = V i,r, (X)\nPutting them together proves Claim D.7c.\nWe also have the following claim about the negative gradient (namely for i = y), whose proof is completely symmetric to that of Claim D.7 so we ignore here.\nClaim D.8 (negative gradient). Suppose Induction Hypothesis C.3 holds at iteration t. For every\n(X, y) \u2208 Z, every r \u2208 [m], every \u2208 [2], and i \u2208 [k] \\ {y}, we have (a) \u2212\u2207 w i,r L F (t) , X, y , v i, \u2265 \u2212logit i F (t) , X E 1 + E 3 + 1 v i, \u2208P(X) V i,r, (X) (b) For every j \u2208 [k]: \u2212\u2207 w i,r L F (t) , X, y , v j, \u2264 logit i F (t) , X O(\u03c3 p P ) (c) For every j \u2208 [k] \\ {i}: \u2212\u2207 w i,r L F (t) , X, y , v j, \u2265 \u2212logit i F (t) , X (E 1 + E 3 + E 4,j, (X)) Function approximations. Let us denote \u03a6 (t) i, def = r\u2208[m] [ w (t) i,r , v i, ] + and \u03a6 (t) i def = \u2208[2] \u03a6 (t) i, (D.4)\nOne can easily derive that Claim D.9 (function approximation). Suppose Induction Hypothesis C.3 holds at iteration t and supposes \u2264 O( 1\n\u03c3 q 0 m ) and \u03b3 \u2264 O( 1 \u03c3 0 k(mP ) 1/q ). Let Z (t) i, (X) def = 1 v i, \u2208V(X)\np\u2208Pv i, (X) z p , we have: \u2022 for every t, every (X, y) \u2208 Z m and i \u2208 [k], or for every (X, y) \u2208 Z s and i \u2208 [k] \\ {y},\nF (t) i (X) = \u2208[2] \u03a6 (t) i, \u00d7 Z (t) i, (X) \u00b1 O(\u03c3 0 + \u03c3 q 0 sm + (\u03c3 0 \u03b3k) q \u2022 P m) = \u2208[2] \u03a6 (t) i, \u00d7 Z (t) i, (X) \u00b1 O( 1 polylog(k)\n)\n\u2022 for every (X, y) \u223c D, with probability at least 1 \u2212 e \u2212\u2126(log 2 k) it satisfies for every i \u2208 [k],\nF (t) i (X) = \u2208[2] \u03a6 (t) i, \u00d7 Z (t) i, (X) \u00b1 O( 1 polylog(k) )", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "D.2 Useful Claims as Consequences of the Induction Hypothesis", "text": "In this sub-section we state some consequences of our Induction Hypothesis C.3. They shall be useful in our later proof of the induction hypothesis.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "D.2.1 Correlation Growth", "text": "Claim D.10 (growth). Suppose Induction Hypothesis C.3 holds at iteration t, then for every i \u2208\n[k], suppose \u039b (t) i \u2264 O(1/m 0 ), then it satisfies \u039b (t+1) i = \u039b (t) i + \u0398 \u03b7 k ReLU (\u039b (t) i ) Proof of Claim D.10. Recall \u039b (t) i def = max r\u2208[m], \u2208[2] [ w (t) i,r , v i, ]\n+ . Now, let us take any r \u2208 [m] and \u2208 [2] so that w (t) i,r , v i, \u2265 \u2126(\u03c3 0 ). We first show a lower bound on the increment. By Claim D.7 and Claim D.8,\nw (t+1) i,r , v i, \u2265 w (t) i,r , v i, + \u03b7 E (X,y)\u223cZ 1 y=i V i,r, (X) \u2212 O(\u03c3 p P ) 1 \u2212 logit i (F (t) , X) \u22121 y =i E 1 + E 3 + 1 v i, \u2208P(X) V i,r, (X) logit i F (t) , X (D.5) Recall V i,r, (X) = p\u2208Pv i, (X) ReLU ( w (t) i,r , x p )z p .\nUsing Induction Hypothesis C.3, we know that as long as (X, y) \u2208 Z m , or when (X, y) \u2208 Z s but i = y, it satisfies\nV i,r, (X) = p\u2208Pv i, (X) ReLU w (t) i,r , v i, z p \u00b1 o (\u03c3 0 ) z p \u2022 When i = y\nis the correct label, at least when (X, y) \u2208 Z m , we have p\u2208Pv i, (X) z p \u2265 1, and together with\n|P v i, | \u2264 C p = O(1), this tells us V i,r, (X) \u2265 \u2126(1) \u2022 ReLU w (t) i,r , v i, .\n\u2022 When i = y is the wrong label and when v i, \u2208 P(X), we can use\nz p \u2264 O(1) to derive that V i,r, (X) \u2264 O(1) \u2022 ReLU w (t) i,r , v i, . Together with logit i F (t) , X \u2264 O( 1 k ) from Claim D.4, we can derive that w (t+1) i,r , v i, \u2265 w (t) i,r , v i, +\u03b7 E (X,y)\u223cZ 1 y=i \u2022 \u2126(1) \u2212 O(1) \u2022 1 y =i 1 v i, \u2208P(X) 1 k \u2022 ReLU w (t) i,r , v i, \u2212\u03b7 O \u03c3 p P + E 1 + E 3 k\nFinally, recall the property of our distribution Pr (X,y)\u223cD v i, \u2208 P(X\n) | i = y = s k o(1), we derive that w (t+1) i,r , v i, \u2265 w (t) i,r , v i, + \u2126 \u03b7 k ReLU w (t)\ni,r , v i, As for the lower bound, using Claim D.7 and Claim D.8 again, we have\nw (t+1) i,r , v i, \u2264 w (t) i,r , v i, + \u03b7 E (X,y)\u223cZ 1 y=i (V i,r, (X) + E 1 + E 3 ) 1 \u2212 logit i (F (t) , X) \u22121 y =i O(\u03c3 p P ) logit i F (t) , X so a completely symmetric argument also shows w (t+1) i,r , v i, \u2264 w (t) i,r , v i, + O \u03b7 k ReLU w (t) i,r , v i,\nClaim D.10 immediately gives the following corollary (using \u2126(\u03c3 0 ) \u2264 \u039b \n\u039b \u2212 \u2205 def = \u0398 log k = \u0398(1) and \u039b + \u2205 def = \u0398 1 m 0 = \u0398(1)\nLet T 0,i be the first iteration so that \u039b\n(t) i \u2265 2\u039b \u2212 \u2205 , and T 0 def = \u0398 k \u03b7\u03c3 q\u22122 0 (noticing T 0 \u2265 T 0,i ) Then, \u2022 for every i \u2208 [k] and t \u2265 T 0 , it satisfies \u039b (t) i \u2265 \u039b + \u2205 \u2022 for every i \u2208 [k] and t \u2265 T 0,i , it satisfies \u039b (t) i \u2265 \u039b \u2212 \u2205 D.2.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Single-View Error Till the End", "text": "In this subsection we present a claim to bound the \"convergence\" (namely, the 1 \u2212 logit y F (t) , X part) for every single-view data from T 0 till the end.\nClaim D.12 (single view till the end). Suppose Induction Hypothesis C.3 holds for all iterations t < T and \u03b3 \u2264 O(\u03c3 0 k). We have that (a) for every (X, y) \u2208 Z s , for every r \u2208 [m], every \u2208 [2], every p \u2208 P v y, (X)\nT t=T 0 1 \u2212 logit y F (t) , X ReLU ( w y,r , x p ) \u2264 O N \u03b7 (b) for every (X, y) \u2208 Z s , T t=T 0 1 \u2212 logit y F (t) , X \u2264 O N \u03b7\u03c1 q\u22121\nBefore proving Claim D.12, we first establish a simple claim to bound how the (correlation with the) noise term grows on single view data. This is used to show that the learner learns most single-view data through memorization.\nClaim D.13 (noise lower bound). Suppose Induction Hypothesis C.3 holds at iteration t.\n(a) For every (X, y) \u2208 Z s , every \u2208 [2], for every p \u2208 P v y, (X),\nw (t+1) i,r , \u03be p \u2265 w (t) i,r , \u03be p \u2212 \u03b7 \u221a d + \u2126 \u03b7 N ReLU ( w (t) i,r , x p ) 1 \u2212 logit i (F (t) , X * ) \u2265 \u2022 \u2022 \u2022 \u2265 \u2212 \u03b7T \u221a d (b) For every (X, y) \u2208 Z s , every \u2208 [2], p\u2208Pv y, (X) w (t+1) y,r , \u03be p \u2265 p\u2208Pv y, (X) w (t) y,r , \u03be p \u2212 O(\u03b7) \u221a d + \u2126 \u03b7 N ReLU \u03c1 \u2022 w (t) y,r , v y, \u2212 O(\u03b7T / \u221a d + \u03c3 0 \u03b3k) 1 \u2212 logit y (F (t) , X)\nProof of Claim D.13. For every (X * , y * ) \u2208 Z s , every i \u2208 [k], every \u2208 [2], and every p * \u2208 P v i, (X * ), one can calculate that\nw (t+1) i,r , \u03be p * = w (t) i,r , \u03be p * + \u03b7 E (X,y)\u223cZ 1 y=i \uf8eb \uf8ed p\u2208[P ] ReLU ( w (t) i,r , x p ) x p , \u03be p * \uf8f6 \uf8f8 1 \u2212 logit i (F (t) , X) \u22121 y =i \uf8eb \uf8ed p\u2208[P ] ReLU ( w (t) i,r , x p ) x p , \u03be p * \uf8f6 \uf8f8 logit i F (t) , X Note when X = X * , we have | x p , \u03be p * | \u2264 O(\u03c3 p ) \u2264 o 1 \u221a d\n; and when X = X * but p = p * , we also\nhave | x p , \u03be p * | \u2264 O(\u03c3 p ) \u2264 o 1 \u221a d . Therefore, when i = y * , w (t+1) i,r , \u03be p * = w (t) i,r , \u03be p * + \u0398 \u03b7 N ReLU ( w (t) i,r , x p * ) 1 \u2212 logit i (F (t) , X * ) \u00b1 \u03b7 \u221a d (D.6)\nUsing the non-negativity of ReLU we arrive at the first conclusion. Next, using Induction Hypothesis C.3d, we have w\n(t) i,r , x p * = w (t) i,r , v i, z p * + w (t)\ni,r , \u03be p * \u00b1 O(\u03c3 0 \u03b3k). Also, recall from Def. 3.1 that p * \u2208Pv i, (X * ) z p * \u2265 \u2126(\u03c1). Therefore, when summing over constantly many p * \u2208 P v i, (X * ) we have\np * \u2208Pv i, (X * ) w (t+1) i,r , \u03be p * \u2265 p * \u2208Pv i, (X * ) w (t) i,r , \u03be p * \u2212 O(\u03b7) \u221a d + \u2126 \u03b7 N ReLU \u03c1 \u2022 w (t) i,r , v i, \u2212 O(\u03b7T / \u221a d + \u03c3 0 \u03b3k) 1 \u2212 logit i (F (t) , X * )\nThis arrives at our second conclusion.\nProof of Claim D.12. We now prove Claim D.12 using Claim D.13. Let us denote i = y. Claim D.12a is in fact a direct corollary of Claim D.13a, because once the summation has reached \u2126( N \u03b7 ) at some iteration t = t 0 , then according to Claim D.13a, we must have already satisfied\n\u2200t \u2265 t 0 : w (t) i,r , \u03be p \u2265 polylog(k) but according to w (t) i,r , x p = w (t) i,r , v i, z p + w (t)\ni,r , \u03be p \u00b1 O(\u03c3 0 \u03b3k) from Induction Hypothesis C.3c, and using w (t) i,r , v i, \u2265 \u22121 from Induction Hypothesis C.3h, we immediately have\nF (t) i (X) \u2265 w (t) i,r , x p * \u2212 O(1) \u2265 polylog(k)\nwhile at the same time, one can easily derive (recall (D.3)) that\nF (t) j (X) \u2264 m 0 \u2022 \u039b (t) i \u2022 \u0393 \u2264 O(1)\nfor every j = i. Therefore, we have 1 \u2212 logit y F (t) , X \u2264 e \u2212 log 5 k for every t \u2265 t 1 . This proves the Claim D.12a.\nNext, we move to Claim D.12b. We prove by way of contradiction and suppose\nt\u2265T 0 1 \u2212 logit i F (t) , X \u2265 \u2126 N \u03b7\u03c1 q\u22121 Using \u039b (t) i = max r\u2208[m], \u2208[2] [ w (t) i,r , v i, ] + \u2265 \u2126(1) from Claim D.11 and the definition of M (0) i , we have (r, )\u2208M (0) i \u00d7[2] 1 w (t) i,r ,v i, \u2265 \u2126(1) t\u2265T 0 1 \u2212 logit i F (t) , X \u2265 \u2126 N \u03b7\u03c1 q\u22121\nNote that when w (t) i,r , v i, \u2265 \u2126(1) and p\u2208Pv i, (X) w (t) i,r , \u03be p \u2265 polylog(k) simultaneously hold, there must exists some p * \u2208 P v i, (X) so that w (t) i,r , \u03be p * \u2265 polylog(k), but according to Induction Hypothesis C.3d, we have (noticing ReLU is in the linear regime now because w\n(t) i,r , v i, \u2265 0) F (t) i (X) \u2265 w (t) i,r , x p * \u2212 O(1) = w (t) i,r , v i, z p * + w (t) i,r , \u03be p * \u00b1 O(\u03c3 0 \u03b3k) \u2212 O(1) \u2265 polylog(k) In contrast, one can derive (recall (D.3)) that F (t) j (X) \u2264 m 0 \u2022 \u039b (t) i \u2022 \u0393 \u2264 O(1) for every j = i. This means 1 \u2212 logit i F (t)\n, X e \u2212 log 5 k . In other words,\nt\u2265T 0 (r, )\u2208M (0) i \u00d7[2] 1 w (t) i,r ,v i, \u2265 \u2126(1) 1 p\u2208Pv i, (X) w (t) i,r ,\u03bep \u2264polylog(k) 1 \u2212 logit i F (t) , X \u2265 \u2126 N \u03b7\u03c1 q\u22121\nNow we partition the iterations between T 0 and T into 4m 0 stages of consecutive iterations, denoted by T 1 , . . . T 4m 0 , so that each of them have a similar partial sum in the above summation. In symbols:\n\u2200g \u2208 [4m 0 ] : t\u2208Tg (r, )\u2208M (0) i \u00d7[2] 1 w (t) i,r ,v i, \u2265 \u2126(1) 1 p\u2208Pv i, (X) w (t) i,r ,\u03bep \u2264polylog(k) 1 \u2212 logit i F (t) , X \u2265 \u2126 N \u03b7\u03c1 q\u22121 (D.7)\nLet us first look at stage T 1 . By averaging, there exists some (r, ) = (r\n* 1 , * 1 ) \u2208 M (0) i \u00d7 [2] so that t\u2208T 1 1 w (t) i,r ,v i, \u2265 \u2126(1) 1 p\u2208Pv i, (X) w (t) i,r ,\u03bep \u2264polylog(k) 1 \u2212 logit i F (t) , X \u2265 \u2126 N \u03b7\u03c1 q\u22121\nApplying Claim D.13b, we know that after stage T 1 (namely, for any t \u2208 max T 1 , T ), it satisfies for (r, ) = (r * 1 , * 1 )\np\u2208Pv i, (X) w (t) i,r , \u03be p \u2265 \u2126 N \u03b7\u03c1 q\u22121 \u2022 \u2126 \u03b7 N \u03c1 q\u22121 > polylog(k)\nContinuing to stage T 2 , by averaging again, we can find some other (r, ) = (r\n* 2 , * 2 ) \u2208 M (0) i \u00d7 [2] so that t\u2208T 2 1 w (t) i,r ,v i, \u2265 \u2126(1) 1 p\u2208Pv i, (X) w (t) i,r ,\u03bep \u2264polylog(k) 1 \u2212 logit i F (t) , X \u2265 \u2126 N \u03b7\u03c1 q\u22121\nFrom the conclusion of of the previous stage, it must satisfy that (r * 2 , * 2 ) = (r * 1 , * 1 ). A similar derivation also tells us that after stage T 2 (namely, for any t \u2208 max T 2 , T ), it satisfies for (r, ) = (r * 2 , * 2 )\np\u2208Pv i, (X) w (t) i,r , \u03be p > polylog(k)\nWe continue this argument until we finish stage T 2m 0 . At this point, we know for every t \u2208 max T 2m 0 , T for all (r, ) \u2208 M\n(0) i \u00d7 [2] p\u2208Pv i, (X) w (t) i,r , \u03be p > polylog(k)\nThis contradicts (D.7) for any g > 2m 0 .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "D.2.3 Multi-View Error Till the End", "text": "In this subsection we present a claim to bound the \"convergence\" (namely, the 1 \u2212 logit y F (t) , X part) for the average multi-view data from T 0 till the end.\nClaim D.14 (multi-view till the end). Suppose Induction Hypothesis C.3 holds for every iteration t < T , and\nsupposeN s \u2264 k 2 \u03c1 q\u22121 s , then T t=T 0 E (X,y)\u223cZm 1 \u2212 logit y F (t) , X \u2264 O k \u03b7 + O sN s \u03b7k\u03c1 q\u22121 \u2264 O k \u03b7\nIn fact, Claim D.14 is a direct corollary of the following claim, combined with \u039b (t) i = O(1) from Induction Hypothesis C.3g, and with the convergence Claim D.12b for single-view data.\nClaim D.15. Suppose Induction Hypothesis C.3 holds at iteration t and t \u2265 T 0 , then\ni\u2208[k] \u039b (t+1) i \u2265 i\u2208[k] \u039b (t) i + \u2126(\u03b7) \u00d7 E (X,y)\u223cZm 1 \u2212 logit y F (t) , X \u2212 \u03b7O s k N s N E (X,y)\u223cZs 1 \u2212 logit y F (t) , X Proof of Claim D.15. Recall \u039b (t) i def = max r\u2208[m], \u2208[2] [ w (t) i,r , v i, ] + .\nLet us take r, to be this argmax so that Claim D.11 tells us w\n(t) i,r , v i, \u2265 \u039b + \u2205 = \u0398(1)\n. By Claim D.7 and Claim D.8,\nw (t+1) i,r , v i, \u2265 w (t) i,r , v i, + \u03b7 E (X,y)\u223cZ 1 y=i V i,r, (X) \u2212 O(\u03c3 p P ) 1 \u2212 logit i (F (t) , X) \u22121 y =i E 1 + E 3 + 1 v i, \u2208P(X) V i,r, (X) logit i F (t) , X Recall V i,r, (X) = p\u2208Pv i, (X) ReLU ( w (t) i,r , x p )z p .\nUsing Induction Hypothesis C.3a, we know that as long as (X, y) \u2208 Z m , or when (X, y) \u2208 Z s but i = y, it satisfies\nV i,r, (X) = p\u2208Pv i, (X) ReLU w (t) i,r , v i, z p \u00b1 o (\u03c3 0 ) z p Since w (t) i,r , v i, \u2265 \u039b + \u2205 = \u0398( 1 m 0 ) (see Claim D.11) and since |P v i, (X)| \u2264 O(1)\n, for most of p \u2208 P v i, we must be already in the linear regime of ReLU so\n0.9 p\u2208Pv i, (X) z p \u2264 V i,r, (X) \u2264 p\u2208Pv i, (X) z p\nAccording to our choice of the distribution (see Def. 3.1):\n\u2022 When (X, y) \u2208 Z m and y = i, we have V i,r, (X) \u2265 0.9.\n\u2022 When (X, y) \u2208 Z s and y = i, we have V i,r, (X) \u2265 0.\n\u2022 When (X, y) \u2208 Z m , y = i and v i, \u2208 P(X), we have V i,r, (X) \u2264 0.4.\n\u2022 When (X, y) \u2208 Z s , y = i and v i, \u2208 P(X), we have V i,r, (X) \u2264 \u0393 \u2264 1.\nTogether, we derive that\nw (t+1) i,r , v i, \u2265 w (t) i,r , v i, + \u03b7 E (X,y)\u223cZm 0.89 \u2022 1 y=i 1 \u2212 logit i (F (t) , X) \u2212 \u03b7 E (X,y)\u223cZm 1 y =i (E 1 + E 3 + 0.41 v i, \u2208P(X) )logit i F (t) , X \u2212 O \u03b7N s N E (X,y)\u223cZs 1 y=i \u2022 O(\u03c3 p P ) 1 \u2212 logit y F (t) , X \u2212 O \u03b7N s kN E (X,y)\u223cZs 1 y =i E 1 + E 3 + 1 v i, \u2208P(X) 1 \u2212 logit y F (t) , X (D.8)\nAbove, we have applied Claim D.4 which says for (X, y) \u2208 Z s , it holds that logit i (F (t) , X) \u2264 O 1 k 1 \u2212 logit y (F (t) , X) . Finally, substituting 1 v i, \u2208P(X) with the naive upper bound E 1 + E 3 + 0.41 v i, \u2208P(X) \u2264 0.41, we have\nw (t+1) i,r , v i, \u2265 w (t) i,r , v i, + \u03b7 E (X,y)\u223cZm 0.89 \u2022 1 y=i 1 \u2212 logit i (F (t) , X) \u2212 0.41 \u2022 1 y =i logit i F (t) , X \u2212 O \u03b7N s kN E (X,y)\u223cZs k1 y=i \u2022 O(\u03c3 p P ) + 1 y =i E 1 + E 3 + 1 v i, \u2208P(X) 1 \u2212 logit y F (t) , X\nSumming up over all i \u2208 [k], and using v i, \u2208 P(X) with probability s k when i = y, we finish the proof.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "D.2.4 Multi-View Individual Error", "text": "Our next claim states that up to a polynomial factor, the error on any individual multi-view data is bounded by the training error.\nClaim D.16 (multi-view individual error). For every t \u2265 0, every (X, y) \u2208 Z m , 1 \u2212 logit y F (t) , X \u2264 O k 4 s 2 \u2022 E (X,y)\u223cZm 1 \u2212 logit y F (t) , X\n(The same also holds w.p. \u2265 1 \u2212 e \u2212\u2126(log 2 k) for every (X, y) \u223c D m on the left hand side.) Furthermore, if E (X,y)\u223cZm 1 \u2212 logit y F (t) , X \u2264 1 k 4 is sufficiently small, we have 0.4\u03a6\n(t) i \u2212 \u03a6 (t) j \u2264 \u2212\u2126(log k) for every pair i, j \u2208 [k].\nProof. For a data point (X, y) \u2208 Z m , let us denote by H(X) be the set of all\ni \u2208 [k] \\ {y} such that, \u2208[2] p\u2208Pv i, (X) z p \u2265 0.8 \u2212 1 100 log(k) , \u2208[2] p\u2208Pv y, (X) z p \u2264 2 + 1 100 log(k) Now, suppose 1 \u2212 logit y F (t) , X = \u03be(X), then using min{1, \u03b2} \u2264 2 1 \u2212 1 1+\u03b2 , we have min 1, i\u2208[k]\\{y} e F (t) i (X)\u2212F (t) y (X) \u2264 2\u03be(X)\nBy Claim D.9 and our definition of H(X), this implies that min 1, i\u2208H(X) e 0.4\u03a6 (t)\ni \u2212\u03a6 (t) y \u2264 4\u03be(X)\nIf we denote by \u03c8 = E (X,y)\u223cZm 1 \u2212 logit y F (t) , X , then\nE (X,y)\u223cZm min 1, i\u2208H(X) e 0.4\u03a6 (t) i \u2212\u03a6 (t) y \u2264 4\u03c8 =\u21d2 E (X,y)\u223cZm i\u2208H(X) min 1 k , e 0.4\u03a6 (t) i \u2212\u03a6 (t) y \u2264 4\u03c8\nNotice that we can rewrite the LHS so that\nE (X,y)\u223cZm j\u2208[k] 1 j=y i\u2208[k] 1 i\u2208H(X) min 1 k , e 0.4\u03a6 (t) i \u2212\u03a6 (t) j \u2264 4\u03c8 =\u21d2 j\u2208[k] i\u2208[k] 1 i =y E (X,y)\u223cZm 1 j=y 1 i\u2208H(X) min 1 k , e 0.4\u03a6 (t) i \u2212\u03a6 (t) j \u2264 4\u03c8\nNote however, that for every i = j \u2208 [k], the probability of generating a multi-view sample (X, y) \u2208 Z m with y = j and i \u2208 H(X)\nis at least \u2126 1 k \u2022 s 2 k 2 . This implies j\u2208[k] i\u2208[k]\\i min 1 k , e 0.4\u03a6 (t) i \u2212\u03a6 (t) j \u2264 O k 3 s 2 \u03c8 (D.9) Finally, using 1 \u2212 1 1+\u03b2 \u2264 min{1, \u03b2}, it is easy to see for every (X, y) \u2208 Z m 1 \u2212 logit y F (t) , X = min 1, i\u2208[k]\\{y} 2e 0.4\u03a6 (t) i \u2212\u03a6 (t) y \u2264 k \u2022 i\u2208[k]\\{y} min 1 k , e 0.4\u03a6 (t) i \u2212\u03a6 (t) y \u2264 O k 4 s 2 \u03c8\nWe complete the proof.\nNote that if one replaces (X, y) \u2208 Z m with (X, y) \u2208 D m , we also have\n1 \u2212 logit y F (t) , X = min 1, i\u2208[k]\\{y} 2e 0.4\u03a6 (t) i \u2212\u03a6 (t) y\nwith high probability, so the same result also holds. Note also (D.9) implies if E (X,y)\u223cZm 1 \u2212 logit y F (t) , X \u2264 1 k 4 is sufficiently small, we have 0.4\u03a6\n(t) i \u2212 \u03a6 (t) j \u2264 \u2212\u2126(log k) for every pair i = j. Using the non-negativity of \u03a6 (t)\ni , we know the relationship holds also when i = j.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "D.2.5 Multi-View Error in Stage 2", "text": "As we shall see later, our final proof is divided into three stages for each index i \u2208 [k]: the first stage is for t \u2264 T 0,i , the second stage is for all t \u2208 [T 0,i , T 0 ], and the third iteration is for t > T 0 . We have the following claim to bound the maximum error of multi-view data during the second stage.\nClaim D.17 (multi-view stage 2). Suppose Induction Hypothesis C.3 holds for every iteration t \u2264 T 0 , and\n\u03a5 = \u0398( 1 k 0.2 ) is a parameter. Then, for every i \u2208 [k] (a) T 0 t=T 0,i E (X,y)\u223cZm 1 y=i 1 \u2212 logit y F (t) , X \u2264 O s k T 0 \u03a5 + O 1 \u03b7 (b) for every t \u2208 [T 0,i , T 0 ], every j \u2208 [k] \\ {i}, every \u2208 [2], E (X,y)\u223cZm 1 y =i logit i F (t) , X \u2264 O( 1 k ) E (X,y)\u223cZm 1 y =i 1 v j, \u2208P(X) logit i F (t) , X \u2264 O( s k 2 )\nIn order to prove Claim D.17 we first establish the following claim.\nClaim D.18. Let \u03a5 be any \u03a5 \u2208 1 k , 1 s , and recall\n\u03a6 (t) i def = r\u2208[m], \u2208[2] [ w (t) i,r , v i, ] + from (D.4\n). Then, letting T 1 def = \u0398 k 2.5 \u03a5 2.5 \u03b7 and suppose Induction Hypothesis C.3 holds for all iterations t \u2264 T 1 . Then,\n\u2200t \u2264 T 1 , \u2200i \u2208 [k] : e 0.4\u03a6 (t) i \u2264 k\u03a5 . (Note when \u03a5 \u2264 O(k \u22120.2 ) we have T 0 \u2264 T 1 .) Proof of Claim D.18. Recall from Induction Hypothesis C.3i that for those r \u2208 [m] \\ M (0) i and \u2208 [2], it satisfies [ w (t) i,r , v i, ] + \u2264 O(\u03c3 0 )\nand their summation does not exceed 1 polylog(k) due to our choice of m. Thus, to prove this claim, it suffices to slightly abuse the notation and think of\n\u03a6 (t) = max i\u2208[k] (r, )\u2208M (0) i \u00d7[2] [ w (t) i,r , v i, ] + Let i be this argmax in \u03a6 (t) . For every (r, ) \u2208 M (0) i \u00d7 [2]\n, by Claim D.7 and Claim D.8,\nw (t+1) i,r , v i, \u2264 w (t) i,r , v i, + \u03b7 E (X,y)\u223cZ 1 y=i (V i,r, (X) + E 1 + E 3 ) 1 \u2212 logit i (F (t) , X) +1 y =i O(\u03c3 p P ) logit i F (t) , X (D.10)\nwhere recall\nV i,r, (X) = p\u2208Pv i, (X) ReLU ( w i,r , x p )z p \u2264 p\u2208Pv i, (X) z p \u2264 O(1)\nTherefore,\nw (t+1) i,r , v i, \u2264 w (t) i,r , v i, + O(\u03b7) E (X,y)\u223cZ 1 y=i 1 \u2212 logit y (F (t) , X) + O(\u03c3 p P )\nNote that single-view data contribute to at most O( \u03b7Ns kN ) on the RHS of (D.10), so we only focus on those (X, y) \u2208 Z m . By Claim D.9 we know F\n(t) y (X) \u2265 \u03a6 (t) y \u2212 1 polylog(k) and for j \u2208 [k] \\ {y}, \u2022 W.p. 1 \u2212 (1 \u2212 s k ) 2\n, both v j,1 , v j,2 \u2208 P(X), and in this case\nF (t) j (X) \u2264 1 polylog(k) ; \u2022 W.p. (1 \u2212 s k ) 2\n, at least one of v j,1 , v j,2 \u2208 P(X), and in this case\nF (t) j (X) \u2264 0.4\u03a6 (t) j + 1 polylog(k) ;\nTogether, and using the inequality 1 \u2212 logit y (F (t) , X) \u2264 j =y e F (t)\nj (X) e F (t) y (X)\n, and conclude that\nE (X,y)\u223cZm 1 i=y 1 \u2212 logit y (F (t) , X) \u2264 1 k \u2022 O se 0.4 \u03a6 (t) + k e \u03a6 (t)\nSumming up over all (r, ) \u2208 M\n(0) i \u00d7 [2] with |M (0) i | \u2264 m 0 \u2264 O(1), we have \u03a6 (t+1) \u2264 \u03a6 (t) + \u03b7 1 k O se 0.4 \u03a6 (t) + k e \u03a6 (t) + N s N\nThis implies whenever e \u03a6 (t) = \u2126 k 2.5 \u03a5 2.5 , we have\n\u03a6 (t+1) \u2264 \u03a6 (t) + \u03b7 O 1 k 2.5 \u03a5 2.5\nThis finishes the proof of Claim D.18.\nProof of Claim D.17. We first prove Claim D.17a and the proof of Claim D.17b is only simpler.\nUsing (D.8) in the proof of Claim D.15, we know as long as t \u2265 T 0,i (so\n\u039b (t) i \u2265 \u039b \u2205 ), 17 \u039b (t+1) i \u2265 \u039b (t) i + \u03b7 E (X,y)\u223cZm \u2126(1) \u2022 1 y=i 1 \u2212 logit i (F (t) , X) \u2212 \u03b7 E (X,y)\u223cZm 1 y =i (E 1 + E 3 + 0.41 v i,1 or v i,2 \u2208P(X) )logit i F (t) , X \u2212 O \u03b7N s N E (X,y)\u223cZs 1 y=i \u2022 O(\u03c3 p P ) 1 \u2212 logit y F (t) , X \u2212 O \u03b7N s kN E (X,y)\u223cZs 1 y =i E 1 + E 3 + 1 v i,1 or v i,2 \u2208P(X) 1 \u2212 logit y F (t) , X\nApplying Claim D.9, we have for (X, y) \u2208 Z m and i = y, if at least one of\n{v i,1 , v i,2 } is in P(X), then F (t) i (X) \u2264 0.4\u03a6 (t) i + 1 polylog(k) . Therefore, E (X,y)\u223cZm 1 y =i 1 v i,1 or v i,2 \u2208P(X) logit i F (t) , X \u2264 E (X,y)\u223cZm 1 y =i 1 v i,1 or v i,2 \u2208P(X) 1 1 + j\u2208[k] e F (t) j (X)\u22120.4\u03a6 (t) i \u2264 E (X,y)\u223cZm 1 y =i 1 v i,1 or v i,2 \u2208P(X) O(\u03a5) \u2264 O( s\u03a5 k ) (D.11)\nAbove, the last inequality uses F (t) j (X) \u2265 0 and Claim D.18 which says e 0.4\u03a6 (t) i \u2264 O(k\u03a5). Also, for obvious reason\nE (X,y)\u223cZs k1 y=i \u2022 O(\u03c3 p P ) + 1 y =i E 1 + E 3 + 1 {v i,1 ,v i,2 }\u2208P(X) 1 \u2212 logit y F (t) , X \u2264 O( s k )\nTogether, we arrive at the conclusion that\n\u039b (t+1) i \u2265 \u039b (t) i + \u2126(\u03b7) E (X,y)\u223cZm 1 y=i 1 \u2212 logit i (F (t) , X) \u2212 O s\u03a5 k + s k 2 N s N Using \u039b (t) i \u2264 O(1)\nfrom Induction Hypothesis C.3g we immediate finish the proof of Claim D.17a. As for the first part of Claim D.17b, note that when v i,1 \u2208 P (x) and v i,2 \u2208 P (x), we have\nlogit i F (t) , X \u2264 O( 1 k )\n; but if one of them belongs to P (X) the probability is s k and we have (D.11). They together (and using s\u03a5 \u2264 1) imply the first part of Claim D.17b.\nAs for the second part of Claim D.17b, it is similar to the first part once we take into account Pr[v j, \u2208 P(X)] = s k .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "D.3 Tensor Power Method Bound", "text": "In this subsection we establish a lemma for comparing the growth speed of two sequences of updates of the form\nx t+1 \u2190 x t + \u03b7C t x q\u22121 t\n. This should be reminiscent of the classical analysis of the growth of eigenvalues on the (incremental) tensor power method of degree q.\nLemma D.19. Let q \u2265 3 be a constant and x 0 , y 0 = o(1). Let {x t , y t } t\u22650 be two positive sequences updated as\n\u2022 x t+1 \u2265 x t + \u03b7C t x q\u22121 t\nfor some C t = \u0398(1), and\n\u2022 y t+1 \u2264 y t + \u03b7SC t y q\u22121 t\nfor some constant S = \u0398(1).\nSuppose x 0 \u2265 y 0 S 1 q\u22122 (1 + 1 polylog(k)\n), then we must have for every A = O(1), let T x be the first iteration such that x t \u2265 A, then\ny Tx \u2264 O(y 0 \u2022 polylog(k))\nWe first establish a claim before proving Lemma D.19.\nClaim D.20. Consider an increasing sequence x t \u2265 0 defined as x t+1 = x t + \u03b7C t x q\u22121 t for some C t = \u0398(1), then we have for every A > x 0 , every \u03b4 \u2208 (0, 1), and every \u03b7 \u2208 (0, 1):\nt\u22650,xt\u2264A \u03b7C t \u2265 \u03b4(1 + \u03b4) \u22121 (1 + \u03b4) q\u22122 \u2212 1 1 \u2212 (1 + \u03b4)x 0 A q\u22122 \u2212 O(\u03b7A q\u22121 ) x 0 log A x 0 log(1 + \u03b4) \u2022 1 x q\u22122 0 t\u22650,xt\u2264A \u03b7C t \u2264 (1 + \u03b4) q\u22122 (q \u2212 2) + O(\u03b7A q\u22121 ) x 0 log A x 0 log(1 + \u03b4) \u2022 1 x q\u22122 0\nProof of Claim D.20. For every g = 0, 1, 2, . . . , let T g be the first iteration such that x t \u2265 (1+\u03b4) g x 0 .\nLet b be the smallest integer such that (1 + \u03b4) b x 0 \u2265 A. Suppose for notation simplicity that we replace x t with exactly A whenever x t \u2265 A.\nBy the definition of T g , we have\nt\u2208[Tg,T g+1 ) \u03b7C t [(1 + \u03b4) g x 0 ] (q\u22121) \u2264 x T g+1 \u2212 x Tg \u2264 \u03b4(1 + \u03b4) g x 0 + O(\u03b7A q\u22121 ) t\u2208[Tg,T g+1 ) \u03b7C t [(1 + \u03b4) g+1 x 0 ] (q\u22121) \u2265 x T g+1 \u2212 x Tg \u2265 \u03b4(1 + \u03b4) g x 0 \u2212 O(\u03b7A q\u22121 )\nThese imply that\nt\u2208[Tg,T g+1 ) \u03b7C t \u2264 \u03b4 (1 + \u03b4) g(q\u22122) 1 x q\u22122 0 + O(\u03b7A q\u22121 ) x q\u22121 0 t\u2208[Tg,T g+1 ) \u03b7C t \u2265 \u03b4 (1 + \u03b4) g(q\u22122) (1 + \u03b4) q\u22121 1 x q\u22122 0 \u2212 O(\u03b7A q\u22121 ) x q\u22121 0 Recall b is the smallest integer such that (1 + \u03b4) b x 0 \u2265 A, so we can calculate t\u22650,xt\u2264A \u03b7C t \u2264 b\u22121 g=0 \u03b4 (1 + \u03b4) g(q\u22122) 1 x q\u22122 0 + O(\u03b7A q\u22121 ) x q\u22121 0 b = \u03b4 1 \u2212 1 (1+\u03b4) q\u22122 1 x q\u22122 0 + O(\u03b7A q\u22121 ) x q\u22121 0 b = \u03b4(1 + \u03b4) q\u22122 (1 + \u03b4) q\u22122 \u2212 1 1 x q\u22122 0 + O(\u03b7A q\u22121 ) x q\u22121 0 b \u2264 (1 + \u03b4) q\u22122 (q \u2212 2) 1 x q\u22122 0 + O(\u03b7A q\u22121 ) x q\u22121 0 b t\u22650,xt\u2264A \u03b7C t \u2265 b\u22122 q=0 \u03b4 (1 + \u03b4) g(q\u22122) (1 + \u03b4) q\u22121 1 x q\u22122 0 \u2212 O(\u03b7A q\u22121 ) x q\u22121 0 b \u2265 \u03b4(1 + \u03b4) \u22121 1 \u2212 1 (1+\u03b4) (q\u22122)(b\u22121) (1 + \u03b4) q\u22122 \u2212 1 1 x q\u22122 0 \u2212 O(\u03b7A q\u22121 ) x q\u22121 0 b \u2265 \u03b4(1 + \u03b4) \u22121 1 \u2212 (1+\u03b4)x 0 A q\u22122 (1 + \u03b4) q\u22122 \u2212 1 1 x q\u22122 0 \u2212 O(\u03b7A q\u22121 ) x q\u22121 0 b Proof of Lemma D.19.\nLet us apply Claim D.20 twice, once for the x t sequence with C t and threshold A, and the other time for the y t sequence with C t = SC t and threshold A = y 0 \u2022 polylog(k).\nLet T x be the first iteration t in which x t \u2265 A, and T y be the first iteration t in which y t \u2265 A .\nAccording to Claim D.20, we know\nTx t=0 \u03b7C t \u2264 (1 + \u03b4) q\u22122 (q \u2212 2) + O(\u03b7A q\u22121 ) x 0 log A x 0 log(1 + \u03b4) \u2022 1 x q\u22122 0 \u2264 1 + O(\u03b4) (q \u2212 2)x q\u22122 0 + O \u03b7 log(1/x 0 ) \u03b4x q\u22121 0 Ty t=0 \u03b7C t = Ty t=0 \u03b7SC t \u2265 \u03b4(1 + \u03b4) \u22121 (1 + \u03b4) q\u22122 \u2212 1 1 \u2212 (1 + \u03b4)y 0 A q\u22122 \u2212 O(\u03b7(A ) q\u22121 ) y 0 log A y 0 log(1 + \u03b4) \u2022 1 y q\u22122 0 \u2265 1 \u2212 O(\u03b4 + 1 polylog(k) ) (q \u2212 2)y q\u22122 0 \u2212 O \u03b7 \u03b4\nTherefore, choosing \u03b4 = 1 polylog(k) and \u03b7 \u2264\nx 0 log(1/x 0 )polylog(k) , together with the assumption x 0 \u2265 y 0 S 1 q\u22122 (1 + 1 polylog(k)\n), we immediately have that T x < T y so we finish the proof.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "D.4 Main Lemmas for Proving the Induction Hypothesis", "text": "In this subsection, we begin to provide key technical lemmas that, when combined together, shall prove Induction Hypothesis C.3. (We combine the analysis in the next subsection, Section D.5.)\nD.4.1 Lambda Lemma Recall \u039b (t) i def = max r\u2208[m], \u2208[2] [ w (t) i,r , v i, ] + . Our first lemma shows that \u039b (t) i cannot go above O(1).\nLemma D.21. Suppose Induction Hypothesis C.3 holds for all iterations < t and supposeN s \u2264 o(k/\u03c1) . Then, letting\n\u03a6 (t) i, def = r\u2208[m] [ w (t) i,r , v i, ] + , we have \u2200i \u2208 [k], \u2200 \u2208 [2] : \u03a6 (t) i, \u2264 O(1) This implies \u039b (t) i \u2264 O(1) as well.\nProof of Lemma D.21. We make a simple observation:\n\u2022 For those r \u2208 [m] \\ M (0) i and \u2208 [2], recall Induction Hypothesis C.3i says [ w (t) i,r , v i, ]\n+ \u2264 O(\u03c3 0 ) and their summation does not exceed 1 polylog(k) due to our choice of m. Therefore, to prove this claim, it suffices to slightly abuse the notation and prove \u03a6\n(t) i, \u2264 O(1) for \u03a6 (t) i, def = r\u2208M (0) i w (t) i,r , v i, + = \u03a6 (t) i, \u00b1 1 poly(k)\nRecall gradient descent update gives\nw (t+1) i,r , v i, = w (t) i,r , v i, + \u03b7 E (X,y)\u223cZ \u2212\u2207 w i,r L(F (t) ; X, y), v i,\nwhen taking the positive part, we know there exists \u2206\n(t) i,r, \u2208 [0, 1] such that w (t+1) i,r , v i, + = w (t) i,r , v i, + + \u03b7\u2206 (t) i,r, E (X,y)\u223cZ \u2212\u2207 w i,r L(F (t) ; X, y), v i,\nNow in each iteration t, for every pair (i, ), we define a special subset Z s,i, of the single-view data as\nZ s,i, def = (X, y) \u2208 Z s | y = i \u2227 (X) = 3 \u2212\nFor analysis purpose, from iteration t = 0 onwards, we define two sequences of quantities\n\u2022 define A (0) i, def = r\u2208M (0) i w (0) i,r , v i, +and B (0)\ni, = 0. \u2022 when t \u2265 0, define\nA (t+1) i, def = A (t) i, + \u03b7 r\u2208M (0) i \u2206 (t) i,r, E (X,y)\u223cZ 1 (X,y) \u2208Z s,i, \u2022 \u2212\u2207 w i,r L(F (t) ; X, y), v i, B (t+1) i, def = B (t) i, + \u03b7 r\u2208M (0) i \u2206 (t) i,r, E (X,y)\u223cZ 1 (X,y)\u2208Z s,i, \u2022 \u2212\u2207 w i,r L(F (t) ; X, y), v i,\nFor obvious reason, we have \u03a6\n(t) i, = A (t) i, + B (t) i, .\nBound the B sequence. Applying Claim D.7, we have\nB (t+1) i, = B (t) i, + \u03b7 r\u2208M (0) i \u2206 (t) i,r, E (X,y)\u223cZ 1 (X,y)\u2208Z s,i, \u2022 (V i,r, (X) \u00b1 (E 1 + E 3 )) 1 \u2212 logit i (F (t) , X)\nbut according to the definition of Z s,i, (which implies (X) = 3 \u2212 ), we must have\n0 \u2264 V i,r, (X) = p\u2208Pv i, (X) ReLU ( w i,r , x p )z p \u2264 O(\u03c1) \u2022 p\u2208Pv i, (X) ReLU ( w i,r , x p )\nThis means, we must have\n|B (t+1) i, \u2212 B (t) i, | \u2264 O \u03b7\u03c1N s N r\u2208M (0) i E (X,y)\u223cZs 1 (X,y)\u2208Z s,i, 1 \u2212 logit i (F (t) , X) E 1 + E 3 + p\u2208Pv i, (X)\nReLU ( w i,r , x p ) Applying Claim D.12a (and noticing T 0 \u2264 O( N \u03b7 )), we conclude that (using our parameter assumption)\n\u2200t \u2265 0 : |B (t) i, | \u2264 O \u03c1N s k < 1 polylog(k)\nBound the A sequence. So far we have derived that \u03a6\n(t) i, = A (t) i, \u00b1 1 polylog(k) (because |B (t) i, |, |\u03a6 (t) i, \u2212 \u03a6 (t) i, | \u2264 1 polylog(k)\n. So, it suffices to bound the A sequence. Let us denote by\n\u03a6 (t) def = max i\u2208[k], \u2208[2] \u03a6 (t) i,\nin the remainder of the proof. Suppose we are now at some iteration t \u2265 T 0 , let\n(i, ) = arg max i\u2208[k], \u2208[2] A (t) i,\nApplying Claim D.7 and Claim D.8, and using V i,r, (X) \u2208 [0, 1], we have\nA (t+1) i, \u2264 A (t) i, + O(\u03b7) E (X,y)\u223cZ 1 y=i 1 (X,y) \u2208Z s,i, 1 \u2212 logit y (F (t) , X) + O(\u03c3 p P )\nObserve that, whenever A\ni, > polylog(k), we also have \u03a6 (t) \u2265 polylog(k) and thus \u2022 for every (X, y) \u2208 Z m with y = i, recall from Claim D.9 that\nF (t) j (X) = \u2208[2] \u03a6 (t) j, \u00d7 1 v j, \u2208V(X) p\u2208Pv j, (X) z p \u00b1 O( 1 polylog(k)\n) By our choice of the distribution, this implies -F (t) j (X) \u2264 0.8001\u03a6 (t) for j = i, and -F (t) i (X) \u2265 0.9999\u03a6 (t) because (i, ) is the argmax of A (t) i, and\nA (t) i, is close to \u03a6 (t) i, .\n\u2022 for every (X, y) \u2208 Z s with y = i and (X) = , we can also use Claim D.9 to derive -\nF (t) j (X) \u2264 0.8001\u03a6 (t) for j = i.\nHowever, on the i-th output, for every p \u2208 P v i, (X), using w\n(t) i,r , x p = w (t) i,r , v i, z p + w (t)\ni,r , \u03be p \u00b1 O(\u03c3 0 \u03b3k) from Induction Hypothesis C.3d and using w (t) i,r , \u03be p \u2265 \u2212 1 polylog(k) from Claim D.13a, and p\u2208Pv i, (X) z p \u2265 1 from Def. 3.1, we also have\n-F (t) i (X) \u2265 \u03a6 (t) i, \u2212 0.0001 \u2265 0.9999\u03a6 (t) .\nIn both cases, we have 1 \u2212 logit i F (t) , X = e \u2212\u2126(log 5 k) which is negligible. Therefore, we derived that whenever max\ni\u2208[k], \u2208[2] A (t) i, \u2265 polylog(k) max i\u2208[k], \u2208[2] A (t+1) i, \u2264 max i\u2208[k], \u2208[2] A (t)\ni, + O \u03b7\u2022e \u2212\u2126(log 5 k) +\u03b7\u03c3 p P .\nThis finishes the proof that all A (t) i, \u2264 O(1).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "D.4.2 Off-Diagonal Correlations are Small", "text": "Our previous subsection upper bounds the \"diagonal\" correlations w (t) i,r , v i, , and in this subsection we bound the \"off-diagonal\" correlations w (t) i,r , v j, for i = j. Lemma D.22. Suppose Parameter D.1 holds and suppose Induction Hypothesis C.3 holds for all iterations < t. Then, \n\u2200i \u2208 [k] , \u2200r \u2208 [m] , \u2200j \u2208 [k] \\ {i} : | w (t) i,r , v\n(t+1) i,r , v j, | \u2264 | w (t) i,r , v j, | + \u03b7 E (X,y)\u223cZ 1 y=i E 2,i,r (X) + E 1 + E 3 + E 4,j, (X) 1 \u2212 logit i F (t) , X +1 y =i E 1 + E 3 + E 4,j, (X) logit i F (t) , X Stage 1.\nIn the first stage, namely when t \u2264 T 0,i , we have\nlogit i F (t) , X \u2264 O( 1 k ) (see Claim D.4), have E 2,i,r (X) \u2264 O \u03b3(\u039b (t) i ) q\u22121 , and have E 4,i,r (X) \u2264 O(\u03c3 0 ) q\u22121 1 v j, \u2208V(X) , so | w (t+1) i,r , v j, | \u2264 | w (t) i,r , v j, | + O \u03b7 k \u03b3 \u039b (t) i q\u22121 + (\u03c3 q\u22121 0 )\u03b3s + O (\u03c3 0 \u03b3k) q\u22121 \u03b3P + (\u03c3 0 ) q\u22121 s k (D.12) Recall in the first stage \u039b (t+1) i = \u039b (t) i + \u0398 \u03b7 k ReLU (\u039b (t)\ni ) (see Claim D.10) and therefore\nt\u2264T 0,i \u03b7 \u039b (t) i q\u22121 \u2264 O(k)\nHence, together with T 0,i \u2264 T (Note that all of them are satisfied by Parameter D.1). Plugging them back to (D.12), we have we have\nR (t) i \u2264 R (0) i + O(\u03c3 0 ) + O \u03b7 k T 0 (\u03c3 q\u22121 0 )\u03b3s + O (\u03c3 0 \u03b3k) q\u22121 \u03b3P + (\u03c3 0 ) q\u22121 s k \u2264 O(\u03c3 0 )\nfor every t \u2264 T 0,i .\nStage 2. In the second stage, namely when t \u2208 [T 0,i , T 0 ], we have the naive upper bounds\nE 2,i,r (X) \u2264 O(\u03b3) and E 4,i,r (X) \u2264 O(\u03c3 0 ) q\u22121 1 v j, \u2208V(X) , so | w (t+1) i,r , v j, | \u2264 | w (t) i,r , v j, | + \u03b7 E (X,y)\u223cZ 1 y=i O(\u03b3) + E 1 + E 3 + O(\u03c3 0 ) q\u22121 1 v j, \u2208V(X) 1 \u2212 logit i F (t) , X +1 y =i E 1 + E 3 + O(\u03c3 0 ) q\u22121 1 v j, \u2208V(X) logit i F (t) , X\nRecall that for every (X, y) \u2208 Z s and i = y, it satisfies logit i (F (t) , X)\n= O 1 k 1 \u2212 logit y (F (t) , X) (see Claim D.4). Therefore, | w (t+1) i,r , v j, | \u2264 | w (t) i,r , v j, | + \u03b7 E (X,y)\u223cZm 1 y=i O(\u03b3) + E 1 + E 3 + O(\u03c3 0 ) q\u22121 1 v j, \u2208V(X) 1 \u2212 logit y F (t) , X +1 y =i E 1 + E 3 + O(\u03c3 0 ) q\u22121 1 v j, \u2208V(X) logit i F (t) , X +O \u03b7N s kN E (X,y)\u223cZs k1 y=i O(\u03b3) + E 1 + E 3 + O(\u03c3 0 ) q\u22121 1 v j, \u2208V(X) 1 \u2212 logit y F (t) , X +1 y =i E 1 + E 3 + O(\u03c3 0 ) q\u22121 1 v j, \u2208V(X) 1 \u2212 logit y F (t) , X (D.14)\nNext, one can naively verify E (X,y)\u223cZs\n1 y=i 1 v j, \u2208V(X) \u2264 O s k 2 and E (X,y)\u223cZs 1 y =i 1 v j, \u2208V(X) \u2264 O s k\nFurthermore, by Claim D.17, we have\n\u2200t \u2208 [T 0,i , T 0 ] : E (X,y)\u223cZm 1 y =i logit i F (t) , X \u2264 O( 1 k ) \u2200t \u2208 [T 0,i , T 0 ] : E (X,y)\u223cZm 1 y =i 1 v j, \u2208P(X) logit i F (t) , X \u2264 O( s k 2 ) T 0 t=T 0,i E (X,y)\u223cZm 1 y=i 1 \u2212 logit y F (t) , X \u2264 O s k T 0 \u03a5 + O 1 \u03b7\nPutting these back to (D.14), we immediately conclude (using N s N ) that \nR (t) i \u2264 R (T 0,i ) i + O \u03b7T 0 \u2022 s k 2 \u03c3 q\u22121 0 + \u03b7 O s k T 0 \u03a5 + O 1 \u03b7 O \u03b3 + (\u03c3 q\u22121 0 )\u03b3s + O (\u03c3 0 \u03b3k) q\u22121 \u03b3P + (\u03c3 0 ) q\u22121 s k Hence, recalling that T 0 = \u0398 k \u03b7\u03c3 q\n| w (t+1) i,r , v j, | \u2264 | w (t) i,r , v j, | + \u03b7 E (X,y)\u223cZm O(\u03b3) + E 1 + E 3 + O(\u03c3 0 ) q\u22121 1 \u2212 logit y F (t) , X +O \u03b7N s kN E (X,y)\u223cZs k1 y=i O(\u03b3) + E 1 + E 3 + O(\u03c3 0 ) q\u22121 1 \u2212 logit y F (t) , X +1 y =i E 1 + E 3 + O(\u03c3 0 ) q\u22121 1 \u2212 logit y F (t) , X (D.16)\nIf we denote by\nS (t) def = E (X,y)\u223cZm 1 \u2212 logit y F (t) , X G (t) i def = E (X,y)\u223cZs 1 i=y \u2022 1 \u2212 logit y F (t) , X\nthen we can simplify (D.16) into\nR (t+1) i \u2264 R (t) i + \u03b7 \uf8eb \uf8ed S (t) + N s N G (t) i + N s kN i \u2208[k] G (t) i \uf8f6 \uf8f8 O \u03b3 + \u03c3 q\u22121 0 \u03b3s + (\u03c3 0 \u03b3k) q\u22121 \u03b3P + (\u03c3 0 ) q\u22121 .\n(D.17)", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Recall", "text": "Claim D.14 =\u21d2\nt\u2265T 0 S (t) \u2264 O k \u03b7 Claim D.12 =\u21d2 \u2200i \u2208 [k] : t\u2265T 0 G (t) i \u2264 O N \u03b7k\u03c1 q\u22121\nPutting them back to (D.17), we know that as long as 19\nk\u03b3 = O(\u03c3 0 ), \u03b3 = O(\u03c3 q\u22121 0 ), N s k\u03c1 q\u22121 \u2264 O 1 \u03c3 q\u22122 0 (D.18) it satisfies R (t) i \u2264 O(\u03c3 0 ) for all t \u2265 T 0 . D.4.3 View Lottery Winning Recall \u039b (t) i, def = max r\u2208[m] [ w (t) i,r , v i, ] + . Also recall M def = (i, * ) \u2208 [k] \u00d7 [2] \u039b (0) i, * \u2265 \u039b (0) i,3\u2212 * S i,3\u2212 S i, 1 q\u22122 + 1 polylog(k)\nin which S i, = E (X,y)\u223cZm 1 y=i p\u2208Pv i, (X) z q p .\nOur next lemma shows that when (i, * ) \u2208 M, we have \u039b \n\u039b (t) i,3\u2212 * = max r\u2208[m] [ w (t) i,r , v i,3\u2212 * ] + \u2264 O(\u03c3 0 )\nProof of Lemma D. 23. By Claim D.7 and Claim D.8,\nw (t+1) i,r , v i, = w (t) i,r , v i, + \u03b7 E (X,y)\u223cZ 1 y=i V i,r, (X) \u00b1 O E 1 + E 3 1 \u2212 logit i (F (t) , X) \u00b1 O(1) \u2022 1 y =i E 1 + E 3 + 1 v i, \u2208P(X) V i,r, (X) logit i F (t) , X (D.19)\nwhere V i,r, (X) = p\u2208Pv i, (X)\nReLU ( w i,r , x p )z p Stage 1. In the first stage, namely when t \u2264 T 0,i , we have \u039b\n(t) i \u2264 \u039b \u2212 \u2205 O( 1 m 0 ) (see Claim D.11). This implies logit i F (t) , X \u2264 O( 1 k ) from Claim D.4\n. Also, we have Pr[v i, \u2208 P(X) | y = i] = s k . Thus, we can simplify (D. 19) as and thus\nw (t+1) i,r , v i, = w (t) i,r , v i, + \u03b7 E (X,y)\u223cZ 1 i=y V i,r, (X)(1 \u2212 O( 1 k )) \u00b1 O 1 k 1 i =y 1 v i, \u2208P(X) V i,r, (X) \u00b1 O E 1 + E 3 k\nSince N s N , we can ignore single-view data and only focus on (X, y) \u2208 Z m . Using Induction Hypothesis C.3, we know for (X, y) \u2208 Z m ,\nV i,r, (X) = p\u2208Pv i, (X) ReLU w (t) i,r , v i, z p \u00b1 o (\u03c3 0 ) z p\nand furthermore since we are in stage 1, it satisfies w\n(t) i,r , v i, z p \u2264 O(\u039b \u2212 \u2205 ) (see Claim D.11) so V i,r, (X) = 1 q\u22121 ([ w (t) i,r , v i, ] + ) q\u22121 p\u2208Pv i, (X) z q p \u00b1 O(\u03c3 0 ) Therefore, w (t+1) i,r , v i, = w (t) i,r , v i, + \u03b7 q\u22121 ([ w (t) i,r , v i, ] + ) q\u22121 (1 \u2212 O( 1 k )) E (X,y)\u223cZm 1 i=y p\u2208Pv i, (X) z q p \u00b1 O( s k 2 ) \u00b1 O E 1 + E 3 k \u2022 \u03b7 = w (t) i,r , v i, + \u03b7 q\u22121 ([ w (t) i,r , v i, ] + ) q\u22121 1 \u2212 O 1 polylog(k) S i, \u00b1 o \u03c3 0 k \u03b7 (D.20)\nThis means, if we take r * = arg max r\u2208[m] w (0) i,r , v i, * and an arbitrary r \u2208 [m], we can define\n\u2022 x t = w (t) i,r * , v i, * \u2022 (S i, * / q\u22121 ) 1 q\u22122 \u2022 y t = max w (t) i,r , v i,3\u2212 * , \u03c3 0 \u2022 (S i,3\u2212 * / q\u22121 ) 1 q\u22122\nThen by (D.20) we know\nx t+1 \u2265 x t + \u03b7C t x q\u22121 t and y t+1 \u2264 y t + \u03b7SC t y q\u22121 t for some C t = 1 \u2212 O( 1 polylog(k)\n) \u2208 [0.9, 1] (where the value in the big O notion can vary per iteration) and constant S =\nS i,3\u2212 * S i, * 1 + 1 polylog(k) that does not depend on t. Now, since \u039b (0) i, * \u2265 \u039b (0) i,3\u2212 * S i,3\u2212 * S i, * 1 q\u22122 + 1 polylog(k) implies x 0 \u2265 y 0 S 1 q\u22122 (1 + 1 polylog(k)\n) and we can apply Lemma D.19 to derive that \u2022 when w (t) i,r * , v i, * reaches \u2126(1), which necessarily is an iteration t \u2265 T 0,i , we still have that\ny t \u2264 O(y 0 ) =\u21d2 w (t) i,r , v i,3\u2212 * \u2264 O(\u03c3 0 ) (This uses | w (0) i,r , v i,3\u2212 * | \u2264 O(\u03c3 0 ).\n) Therefore, we finished the proof that for every t \u2264 T 0,i , \u039b \nw (t+1) i,r , v i, = w (t) i,r , v i, + \u03b7 E (X,y)\u223cZ 1 y=i V i,r, (X) \u00b1 O E 1 + E 3 1 \u2212 logit i (F (t) , X) \u00b1 1 y =i E 1 + E 3 + 1 v i, \u2208P(X) V i,r, (X) logit i F (t) , X (D.21)\nwhere V i,r, (X) = p\u2208Pv i, (X)\nReLU ( w i,r , x p )z p\n\u2022 Using Induction Hypothesis C. 3 ", "publication_ref": ["b22", "b18", "b2"], "figure_ref": [], "table_ref": []}, {"heading": "and \u039b", "text": "(t) i,3\u2212 * \u2264 O(\u03c3 0 ), we know for (X, y) \u2208 Z m , and for\n(X, y) \u2208 Z s but y = i, V i,r, (X) = p\u2208Pv i, (X) ReLU w (t) i,r , v i, z p \u00b1 o (\u03c3 0 ) z p \u2264 O(\u03c3 q\u22121 0 )\n\u2022 Otherwise for (X, y) \u223c Z s and y = i, we can use = 3 \u2212 * and Induction Hypothesis C.3e to derive V i,r, (X) =\np\u2208Pv i, (X) ReLU w (t) i,r , x p z p \u2264 O(\u03c3 q\u22121 0 ) (D.22)\n\u2022 For (X, y) \u223c Z s and y = i, we have\nlogit i F (t) , X \u2264 O 1 k (1 \u2212 logit y F (t) , X ) (see Claim D.4)\nPutting these back to (D.21), we have\n| w (t+1) i,r , v i, | \u2264 | w (t) i,r , v i, | + O(\u03b7) E (X,y)\u223cZm 1 y=i O(\u03c3 q\u22121 0 ) + O E 1 + E 3 1 \u2212 logit y (F (t) , X) + 1 y =i O(\u03c3 q\u22121 0 )logit i (F (t) , X) +O \u03b7N s N E (X,y)\u223cZs 1 y=i O(\u03c3 q\u22121 0 ) \u2022 1 \u2212 logit y F (t) , X (D.23) + 1 y =i E 1 + E 3 + O(\u03c3 q\u22121 0 ) k 1 \u2212 logit y F (t) , X\nSince N s N , we can ignore single-view data and only focus on (X, y) \u2208 Z m . Applying Claim D.17, we can conclude that | w \n(t+1) i,r , v i, | \u2264 | w (T 0,i ) i,r , v i, | + \u03b7O s k T 0 \u03a5 + T 0 k \u2022 O(\u03c3 q\u22121 0 ) + O(\u03c3 0 ) Recall that T 0 = \u0398 k \u03b7\u03c3 q\ni,3\u2212 * \u2264 O(\u03c3 0 ) for every t \u2208 [T 0,i , T i ]. Stage 3. At the third stage, namely when t \u2265 T 0 , we can continue from (D.23) but this time we do not ignore single-view data, and apply the naive bound logit i (F (t) , X) \u2264 1 \u2212 logit y (F (t) , X) for (X, y) \u2208 Z m and i = y. Recall again we denote = 3 \u2212 * for notational simplicity. If we denote by\nS (t) def = E (X,y)\u223cZm 1 \u2212 logit y F (t) , X G (t) i def = E (X,y)\u223cZs 1 i=y \u2022 1 \u2212 logit y F (t) , X then we have \u039b (t+1) i,3\u2212 * \u2264 \u039b (t) i,3\u2212 * + O \u03b7S (t) \u03c3 q\u22121 0 + O \u03b7N s N \u2022 G (t) i + j\u2208[k] G (t) j k \u2022 O(\u03c3 q\u22121 0 ) (D.24) Recall Claim D.14 =\u21d2 t\u2265T 0 S (t) \u2264 O k \u03b7 Claim D.12 =\u21d2 \u2200i \u2208 [k] : t\u2265T 0 G (t) i \u2264 O N \u03b7k\u03c1 q\u22121\nPutting them back to (D.24), we know that as long as \n\u2200i \u2208 [k], \u2200 \u2208 [2], \u2200r \u2208 [m] \\ M (0) i : w (t) i,r , v i, \u2264 O(\u03c3 0 )\nProof of Lemma D.24. The proof is nearly identical to that of Lemma D.23.\nStage 1. In the first stage, namely when t \u2264 T 0,i , the proof is nearly identical to stage 1 of the proof of Lemma D. 23. At a high level, this time we instead compare two sequences x t = w (t) i,r * , v i, and y t = w ", "publication_ref": ["b22"], "figure_ref": [], "table_ref": []}, {"heading": "D.4.5 Noise Correlation is Small", "text": "In this subsection, we prove that the neurons correlate negligibly with the random noise, that is w (t) i,r , \u03be p is small, except for those single-view data on the lottery winning views. (Recall singleview data are learned through memorization, so the learner network can correlate with their noise \u03be p significantly.) Lemma D.25. Suppose Parameter D.1 holds and suppose Induction Hypothesis C.3 holds for all iterations < t. 21 For every \u2208 [2], for every r \u2208 [m], for every (X, y) \u2208 Z m and i \u2208 [k], or for every (X, y) \u2208 Z s and i \u2208 [k] \\ {y}:\n(a) For every p \u2208 P v i, (X), we have:\nw (t) i,r , \u03be p \u2264 o (\u03c3 0 ).\n(b) For every p \u2208 P(X) \\ P v i,1 (X) \u222a P v i,2 (X) , we have: | w  i,r , x p | \u2264 A for every t < t 0 where t 0 is any iteration t 0 \u2264 T . Then,\n\u2022 If (X, y) \u2208 Z m then w (t) i,r , \u03be p \u2264 O kA q\u22121 N \u03c3 q\u22122 0 + k 5 A q\u22121 s 2 N + \u03b7T \u221a d \u2022 If (X, y) \u2208 Z s then w (t) i,r , \u03be p \u2264 O kA q\u22121 N \u03c3 q\u22122 0 + A q\u22121 \u03c1 q\u22121 + \u03b7T \u221a d\nWe first prove Lemma D.25 using Claim D.26 (which is trivial), and then we prove Claim D.26.\nProof of Lemma D.25.\n\u2022 In the case of Lemma D.25a, since we have | w Proof of Claim D.26. Recall from our earlier calculation (see (D.6)) that for every (X, y) \u2208 Z and\np \u2208 [P ], if y = i then w (t+1) i,r , \u03be p = w (t) i,r , \u03be p + \u0398 \u03b7 N ReLU ( w (t) i,r , x p ) 1 \u2212 logit i (F (t) , X) \u00b1 \u03b7 \u221a d for similar reason, if y = i, then w (t+1) i,r , \u03be p = w (t) i,r , \u03be p \u2212 \u0398 \u03b7 N ReLU ( w (t) i,r , x p )logit i (F (t) , X) \u00b1 \u03b7 \u221a d\nNote by our assumption, we have ReLU ( w\n(t) i,r , x p ) \u2264 O(A q\u22121 )\n. For obvious reason, when\nt = T 0 = \u0398 k \u03b7\u03c3 q\u22122 0 (see Claim D.11) w (t) i,r , \u03be p \u2264 O \u03b7 N A q\u22121 T 0 + \u03b7T 0 \u221a d \u2264 O kA q\u22121 N \u03c3 q\u22122 0 + \u03b7T 0 \u221a d\nCase 1: multi-view data. We first consider (X, y) \u2208 Z m . Using Claim D.16 and Claim D.14, we have\ny = i =\u21d2 T t=T 0 1 \u2212 logit y F (t) , X \u2264 O k 4 s 2 \u2022 T t=T 0 E (X,y)\u223cZm 1 \u2212 logit y F (t) , X \u2264 O k 5 s 2 \u03b7 y = i =\u21d2 T t=T 0 logit i F (t) , X \u2264 T t=T 0 1 \u2212 logit y F (t) , X \u2264 O k 5 s 2 \u03b7\nCombining this with the bound at t = T 0 , we have\nw (t) i,r , \u03be p \u2264 O kA q\u22121 N \u03c3 q\u22122 0 + k 5 A q\u22121 s 2 N + \u03b7T \u221a d\nCase 2: single-view data. Let us now consider (X, y) \u2208 Z s . Recall from Claim D.12b that\nT t=T 0 1 \u2212 logit y F (t) , X \u2264 O N \u03b7\u03c1 q\u22121\nso using the same analysis, we have Proof of Lemma D.27. Let us consider any iteration t so that w (t) i,r , v i, \u2264 \u2212 \u2126(\u03c3 0 ). We start from this iteration to see how negative the next iterations can be. Without loss of generality we consider the case when w (t ) i,r , v i, \u2264 \u2212 \u2126(\u03c3 0 ) holds for every t \u2265 t. By Claim D.7 and Claim D.8,\nw (t) i,r , \u03be p \u2264 O kA q\u22121 N \u03c3 q\u22122 0 + A q\u22121 \u03c1 q\u22121 + \u03b7T \u221a d D.\nw (t+1) i,r , v i, \u2265 w (t) i,r , v i, + \u03b7 E (X,y)\u223cZ 1 y=i V i,r, (X) \u2212 O(\u03c3 p P ) 1 \u2212 logit i (F (t) , X) \u22121 y =i E 1 + E 3 + 1 v i, \u2208P(X) V i,r, (X) logit i F (t) , X Recall V i,r, (X) = p\u2208Pv i, (X) ReLU ( w (t)\ni,r , x p )z p . Since V i,r, (X) \u2265 0 we can ignore it in the first occurence corresponding to 1 y=i . Also, applying Induction Hypothesis C.3, we know that as long as (X, y) \u2208 Z and y = i, it satisfies \nV i,r, (X) = p\u2208Pv i, (X) ReLU w (t) i,r , v i, z p \u00b1 o (\u03c3 0 ) z p = 0 because we have assumed w (t) i,r , v i, \u2264 \u2212 \u2126(\u03c3 0 ). Therefore, w (t+1) i,r , v i, \u2265 w (t) i,r , v i, \u2212 \u03b7 E (X,y)\u223cZ 1 y=i O(\u03c3 p P ) 1 \u2212 logit i (F (t) , X) +1 y =i (E 1 + E 3 ) logit i (F (t) , X) Lemma D.24+Lemma D.27 =\u21d2 \u2200i \u2208 [k], \u2200 \u2208 [2], \u2200r \u2208 [m] \\ M (0) i : | w (t) i,r , v\n(t) i \u2264 O(1/m 0 ), then it must grow by \u039b (t+1) i \u2265 \u039b (t) i + \u0398 \u03b7 k ReLU (\u039b (t) i )) implies \u039b (t) i \u2265 \u2126(\u039b(0)\ni ) \u2265 \u2126(\u03c3 0 ). \u2022 To prove C.3h, it suffices to invoke (D.30).\n\u2022 To prove C.3i, it suffices to invoke (D.31).", "publication_ref": ["b20"], "figure_ref": [], "table_ref": []}, {"heading": "E Single Model and Ensemble: Theorem Statements", "text": "We can now state the general version of the main theorem for single model, as below:\nTheorem 1 (single model, restated). For sufficiently large k > 0, every m \u2208 polylog(k),\n1 s\u03c3 q 0 polylog(k) , every \u03b7 \u2264 1 poly(k) , after T = poly(k)\n\u03b7 many iterations, when Parameter D.1 is satisfied, with probability at least 1 \u2212 e \u2212\u2126(log 2 k) :\n\u2022 (training accuracy is perfect) for every (X, y) \u2208 Z:\n\u2200i = y : F (T ) y (X) \u2265 F (T ) i (X) + \u2126(log k). \u2022 (multi-view testing is good) for every i, j \u2208 [k] we have O(1) \u2265 \u03a6 (T ) i \u2265 0.4\u03a6 (T )\nj + \u2126(log k), and thus Pr (X,y)\u2208Dm\nF (T ) y (X) \u2265 max j =y F (T ) j (X) + \u2126(log k) \u2265 1 \u2212 e \u2212\u2126(log 2 k)\n\u2022 (single-view testing is bad) for every (i, ) \u2208 M we have \u03a6 \nF (T ) y (X) \u2265 max j =y F (T ) j (X) \u2212 1 polylog(k) \u2264 1 2 1 + o(1)\nWe also state the general version of the main theorem for ensemble model, as below:\nTheorem 2 (ensemble accuracy, restated). In the same setting as above, suppose {F [w] } w\u2208[K] are K independently randomly trained models with m \u2208 log \u2126(1) (k), log O(1) k for T = poly(k) \u03b7 iterations each. Let us define G(X) = 1 K w F [w] (X).\n\u2022 (training is perfect) same as the single model;\n\u2022 (multi-view testing is good) same as the single model;\n\u2022 (single-view testing is good) when K \u2265 polylog(k), ensemble model satisfies\nPr (X,y)\u223cDs G y (X) \u2265 max i\u2208[k]\\{y} G i (X) + 1 polylog(k) \u2265 1 \u2212 e \u2212\u2126(log 2 k)", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "E.1 Proof of Theorem 1", "text": "Since Theorem D.2 implies the induction hypothesis holds for every t \u2264 T , we have according to Claim D.14 and Claim D.12b that\nT t=T 0 E (X,y)\u223cZm 1 \u2212 logit y F (t) , X \u2264 O k \u03b7 T t=T 0 E (X,y)\u223cZs 1 \u2212 logit y F (t) , X \u2264 O N \u03b7\u03c1 q\u22121 (E.1) Also recall that our training objective is L(F (t) ) = E (X,y)\u223cZ [\u2212 log logit y (F (t) , X)]\nNow, since for every data,\n\u2022 if logit y (F (t) , X) \u2265 1 2 then \u2212 log logit y (F (t) , X) \u2264 O 1 \u2212 logit y (F (t) , X) ; \u2022 if logit y (F (t) , X) \u2264 1 2 , this cannot happen for too many tuples (X, y, t) thanks to (E.1), and when this happens we have a naive bound \u2212 log logit y (F (t) , X) \u2208 [0, O(1)] using Claim D.4.\nTherefore, we can safely conclude using (E.1) that, when T \u2265 poly(k)/\u03b7,\n1 T T t=T 0 E (X,y)\u223cZ [\u2212 log logit y (F (t) , X)] \u2264 1 poly(k)\nOn the other hand, since we are using full gradient descent and the objective function is O(1)-Lipscthiz continuous, it means the objective value is monotonically non-increasing. In other words, we have\nE (X,y)\u223cZ 1 \u2212 logit y F (T ) , X \u2264 E (X,y)\u223cZ [\u2212 log logit y (F (T ) , X)] \u2264 1 poly(k)\nalso for the last iteration T . This immediately implies that the training accuracy is perfect.\nAs for the multi-view test accuracy, we recall from Claim D.16 that 0.4\u03a6\n(T ) i \u2212 \u03a6 (T ) j\n\u2264 \u2212\u2126(log k) for every i = j. This combined with the function approximation Claim D.9 shows that with high probability F (T ) y (X) \u2265 max j =y F (T ) j (X) + \u2126(log k) for every (X, y) \u2208 D m . As for the single-view test accuracy, whenever (i, ) \u2208 M, using Lemma D.23 we have \u039b\n(T ) i,3\u2212 \u2264 O(\u03c3 0 ) so \u03a6 (T ) i,3\u2212 \u2264 O(\u03c3 0 m).\nNow, for every single-view data (X, y) \u2208 D s with y = i, we know that with half probability (X) = 3 \u2212 . When this happens, according to Claim D.9, we have F For every other j = y, whenever suppose = arg max \u2208[2] {\u03a6 (T ) j, }, we have \u03a6 (T ) j, \u2265 \u2126(log k) by a few lines above. This means, as long as v j, \u2208 V(X) (which happens with probability s/k for every j), invoking Claim D.9 again, that F (T ) j (X) \u2265 \u2126(\u0393). In other words, when this happens for some j \u2208 [k] \\ {i} (which happens with probability at least 1 \u2212 e \u2212\u2126(log 2 k) , we have\nF (T ) y (X) \u2264 max j =y F (T ) j (X) \u2212 1 polylog(k) (E.2)\nTo sum up, we have shown for every (i, ) \u2208 M, for every (X, y) \u2208 D s with y = i, we know that with probability at least 1 2 (1 \u2212 o(1)), inequality (E.2) holds. Since the size |M| \u2265 k(1 \u2212 o( 1)) (see Proposition C.2), we finish the proof.", "publication_ref": ["b0"], "figure_ref": [], "table_ref": []}, {"heading": "E.2 Proof of Theorem 2", "text": "Recall from Proposition C.2 that for every i \u2208 [k], \u2208 [2] and every model F [w] , the probability for (i, ) to be included in the set M [w] (defined by model F [w] ) is at least m \u2212O (1) . When this happens, we also have \u03a6\n(T ) i, \u2265 \u2126(log k) for this model (because \u03a6 (T ) i \u2265 \u2126(log k) while \u03a6 (T ) i,3\u2212 1). Let us denote it as \u03a6 [w] i, .\nNow, for every (X, y) \u2208 D s , with probability at least 1 \u2212 e \u2212\u2126(log 2 k) , letting = (X), we have (see Claim D.9) for every F [w] with \u03a6\n[w] y, \u2265 \u2126(log k) =\u21d2 F [w] y (X) \u2265 \u03a6 [w] y, \u2212 1 polylog(k) \u2265 \u2126(log k) for every F [w] with i = y =\u21d2 F [w] i (X) \u2264 \u0393(\u03a6 i,1 + \u03a6 i,2 ) + 1 polylog(k) \u2264 O(\u0393)\nTherefore, once we have K \u2265 m \u2126(1) models in the ensemble, and suppose \u0393 \u2264 1 m \u2126(1) , after taking average, we shall have G\ny (X) \u2265 G i (X) + 1 polylog(k) for every i = [k].", "publication_ref": ["b1", "b0"], "figure_ref": [], "table_ref": []}, {"heading": "F Knowledge Distillation: Theorem Statement", "text": "In this section we show how knowledge distillation (both for ensemble and for self-distillation) can improve the final generalization accuracy. For every i, let us define the truncated scaled logit as (for \u03c4 = 1 log 2 k ):\nlogit \u03c4 i (F, X) =\ne min{\u03c4 2 F i (X),1}/\u03c4 j\u2208[k] e min{\u03c4 2 F j (X),1}/\u03c4 This logit function should be reminiscent of the logit function with temperature used by the seminal knowledge distillation paper by [42]; we use the truncation function instead which is easier to analyze.", "publication_ref": ["b41"], "figure_ref": [], "table_ref": []}, {"heading": "F.1 Using Ensemble for Knowledge Distillation", "text": "Suppose {F [i] } i\u2208[K] are K = \u0398(1) independently trained models of F for T = O poly(k) \u03b7 iterations (i.e., the same setting as Theorem 1). Let us define their ensemble\nG(X) = \u039e K i F [i] (X) for some \u039e = \u0398(1) (F.1)\nRecall from (4.3) that we train a new network F from random initialization, and at every iteration t, we update each weight w i,r by:\nw (t+1) i,r = w (t) i,r \u2212 \u03b7\u2207 w i,r L(F (t) ) \u2212 \u03b7 E (X,y)\u223cZ logit \u03c4 i (F (t) , X) \u2212 logit \u03c4 i (G, X) \u2212 \u2207 w i,r F (t) i (X) (4.3) restated\nLet F (t) be the resulted network obtained by distilling G using algorithm (4.3) at iteration t. We have the following theorem: Theorem 3 (ensemble distillation, restated). For sufficiently large k > 0, for every m \u2208 log \u2126(1) (k), log O(1) k , every \u03b7 \u2264 1 poly(k) , setting \u03b7 = \u03b7poly(k), after T = poly(k) \u03b7 many iterations, when Parameter G.2 is satisfied, with probability at least 1 \u2212 e \u2212\u2126(log 2 k) , for at least 90% of the iterations t \u2264 T :\n\u2022 (training accuracy is perfect) for every (X, y) \u2208 Z:\n\u2200i = y : F (t) y (X) \u2265 F (t)\ni (X) + \u2126(log k).\n\u2022 (multi-view testing is good) for every i, j \u2208\n[k] we have O(1) \u2265 \u03a6 (t) i \u2265 0.4\u03a6 (t)\nj + \u2126(log k), and thus Pr (X,y)\u2208Dm\nF (t) y (X) \u2265 max j =y F (t) j (X) + \u2126(log k) \u2265 1 \u2212 e \u2212\u2126(log 2 k) \u2022 (single-view testing is good) for every i \u2208 [k] and \u2208 [2] we have \u03a6 (t)\ni, \u2265 \u2126(log k) and thus Pr (X,y)\u2208Ds\nF (T ) y (X) \u2265 max j =y F (T ) j (X) + \u2126(log k) \u2264 1 \u2212 e \u2212\u2126(log 2 k)\nOur proof to Theorem 3 is in the next Section G.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "F.2 Self-Distillation: Using a Single Model to Distill Itself", "text": "Recall in the self-distillation case, we made an additional assumption for simplicity: \nM G def = (i, * ) \u2208 [k] \u00d7 [2] \u039b (0) i, * \u2265 \u039b (0) i,3\u2212 * 1 + 2 log 2 (m) (F.2) which only depends on \u039b (0) i, * which in terms depends on G's random initialization. (Note M G is provably a subset of M defined in (C.2).)\nAs for F , we break its update into two stages.\n1. (Learn.) In the first stage, in the same way as Theorem 1, we start from random initialization and update\nw (t+1) i,r = w (t) i,r \u2212 \u03b7\u2207 w i,r L(F (t) ) for T = poly(k) \u03b7 iterations\nWe let M F be the \"lottery winning\" set of network F at the end of stage 1 defined in the same way as (F.2) (which now depends only on F 's random initialization).\n2. (Distill.) In the second stage, for another T = poly(k) \u03b7 iterations, we update\nw (t+1) i,r = w (t) i,r \u2212 \u03b7 E (X,y)\u223cZ (logit \u03c4 i (F, X) \u2212 logit \u03c4 i (G, X)) \u2212 \u2207 w i,r F (t) i (X) (4.4) restated\nTheorem 4 (self distillation, restated). Suppose the data satisfies Assumption 4.1. For sufficiently large k > 0, for every m \u2208 log \u2126(1) (k), k , every \u03b7 \u2264 1 poly(k) , setting T = poly(k) \u03b7 and T = poly(k) \u03b7 , when Parameter D.1 is satisfied, with probability at least 1 \u2212 e \u2212\u2126(log 2 k) :\n\u2022 (training accuracy is perfect) for every (X, y) \u2208 Z: \u2200i = y : F (T +T ) y (X) \u2265 F (T +T ) i (X) + \u2126(log k).\n\u2022 (multi-view testing is good) for every i, j \u2208\n[k] we have O(1) \u2265 \u03a6 (T +T ) i \u2265 0.4\u03a6 (T +T ) j\n+\u2126(log k), and thus Pr (X,y)\u2208Dm\nF (T +T ) y (X) \u2265 max j =y F (T +T ) j (X) + \u2126(log k) \u2265 1 \u2212 e \u2212\u2126(log 2 k) \u2022 (single-view testing is better) for every (i, ) \u2208 M F \u222a M G we have \u03a6 (T +T ) i, \u2265 \u2126 1 log k , and since |M F \u222a M G | \u2265 1.5k(1 \u2212 o(1)), we have Pr (X,y)\u2208Ds F (T +T ) y (X) \u2265 max j =y F (T +T ) j (X) + \u2126(log k) \u2265 3 4 1 \u2212 o(1)\nThe proof of Theorem 4 is quite easy once the reader is familiar with the proofs of Theorem 1 and Theorem 3. We include it at the end of the next Section G.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "G Knowledge Distillation Proof for Ensemble", "text": "Our proof structure of Theorem 3 is the same as that for the single model case, but is a lot simpler thanks to our special choice of the truncated distillation function.\nSpecifically, we maintain the following set of simpler induction hypothesis.\nInduction Hypothesis G.1. For every \u2208 [2], for every r \u2208 [m], for every (X, y) \u2208 Z and i \u2208 [k],\n(a) For every p \u2208 P v i, (X), we have:\nw (t) i,r , x p = w (t) i,r , v i, z p \u00b1 o (\u03c3 0 ).\n(b) For every p \u2208 P(X) \\ P v i,1 (X) \u222a P v i,2 (X) , we have: | w  Fact G.5. Given data point (X, y) \u2208 D, for every i \u2208 [k], r \u2208 [m], up to a negligible additive error 1 k \u2126(log k) , we have \u2212\u2207 w i,r L(F ; X, y) = 1 y=i \u2212 logit i (F, X) + \u03b7 \u03b7 1 v i,1 ,v i,2 \u2208V(X) 1 s(X) \u2212 logit \u03c4 i (F, X) + \u2207 w i,r F i (X) when (X, y) \u2208 Z m \u2212\u2207 w i,r L(F ; X, y) = 1 y=i \u2212 logit i (F, X) + \u03b7 \u03b7 1 y=i (1 \u2212 logit \u03c4 i (F, X)) + \u2207 w i,r F i (X) when (X, y) \u2208 Z s where recall \u2207 w i,r F i (X) = p\u2208[P ] ReLU ( w i,r , x p )x p Because 1 k \u2126(log k) is negligible, for proof simplicity, we ignore it in the rest of the proof. We also summarize a simple calculation that is analogous to Claim D.7 and Claim D.8.\ni \u2208 [k], every \u2208 [2], (g) \u03a6 (t) i, \u2265 \u2126(\u03c3 0 ) and \u03a6 (t) i, \u2264 O(1). (h) for every r \u2208 [m], it holds that w (t) i,r , v i, \u2265 \u2212 O(\u03c3 0 ). (Recall \u03a6 (t) i, def = r\u2208[m] [ w (t) i,r , v i, ] + .) Parameter G.\nClaim G.6 (gradient, c.f. Claim D.7 and D.8). For every t \u2264 T , for every (X, y) \u2208 Z, every i \u2208 [k], r \u2208 [m] and \u2208 [2], we have:\n\u2022 If v i,1 , v i,2 \u2208 V(X) then \u2207 w i,r F (t) i (X), v i, \u2265 V i,r, (X) \u2212 O(\u03c3 p P ) \u2022 \u2207 w i,r F (t) i (X), v i, \u2264 1 v i, \u2208V(X) V i,r, (X) + E 1 + E 3 \u2022 for every j \u2208 [k] \\ {i}, \u2212\u2207 w i,r F (t) i (X), v j, \u2264 (E 2,i,r (X) + E 1 + E 3 + E 4,j, (X))\nNotation. Throughout the remainder of the proof, let us use v i,1 , v i,2 \u2208 V(X) to denote that at least one of v i,1 , v i,2 is in V. i, (X) := 1 v i, \u2208V(X) p\u2208Pv i, (X) z p , we have: for every t, every i \u2208 [k], every (X, y) \u2208 Z (or for every new sample (X, y) \u223c D, with probability at least 1 \u2212 e \u2212\u2126(log 2 k) ):\nF (t) i (X) = \u2208[2] \u03a6 (t) i, \u00d7 Z (t) i, (X) \u00b1 O(\u03c3 0 \u2022 m) = \u2208[2] \u03a6 (t) i, \u00d7 Z (t) i, (X) \u00b1 O( 1 polylog(k) )", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "G.2 Useful Claims as Consequences of the Induction Hypothesis", "text": "Recall we had five useful claims in Section D.2 for the proof of the single model case. This time, we only have three and they are also easier than their counterparts in Section D.2.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "G.2.1 Lambda Growth", "text": "Claim G.8 (growth, c.f. Claim D.10). Suppose Induction Hypothesis G.1 holds at iteration t, then for every i \u2208 [k], \u2208 [2], suppose \u03a6 (t) i, \u2264 1 \u03c4 , then it satisfies\n\u03a6 (t+1) i, \u2265 \u03a6 (t) i, + \u2126 \u03b7 k ReLU (\u03a6 (t) i, )\nProof of Claim D.10. Using the same calculation as (D.5), but this time substituting the new gradient formula in Fact G.5, we have\nw (t+1) i,r , v i, \u2265 w (t) i,r , v i, \u2212 O(\u03b7 + \u03b7 N s N )\n+ \u2126(\u03b7 ) E (X,y)\u223cZm\n1 v i,1\n,v i,2 \u2208V(X) V i,r, (X) \u2212 O(\u03c3 p P ) 1 s(X) \u2212 logit \u03c4 i (F (t) , X)\n+\nLet us now consider r \u2208 [m] to be the arg max r\u2208[m] w (t) i,r , v i, , so we have w (t) i,r , v i, \u2265 \u2126(\u03a6 (t) i, ). Following a similar analysis as before, we can derive that as long as 1 v i,1 ,v i,2 \u2208V(X) = 1, we have\nV i,r, (X) \u2265 \u2126(1) \u2022 ReLU w (t) i,r , v i, \u2265 \u2126 ReLU (\u03a6 (t) i, ) . Now, since \u03a6 (t) i, \u2264 1\n\u03c4 , we know that as long as v i, \u2208 V(X) and v i,3\u2212 \u2208 V(X) (which happens for \u0398( s k ) fraction of the multi-view training data), it satisfies (see Claim G.7):\nF (t) i (X) \u2264 \u03a6 (t) i, \u00d7 Z (t) i, (X) \u2212 O(\u03c3 0 m) = O 1 \u03c4 \u2212 O(\u03c3 0 m) \u2264 O 1 \u03c4 .\nWhen this happens, we know logit \u03c4 i (F (t) , X) \u2264 O( 1 k ). This implies, after summing over r \u2208 [m],\n\u03a6 (t+1) i, \u2265 \u03a6 (t) i, + \u2126 \u03b7 k ReLU (\u03a6 (t) i, )\nNow we can define T 0 as follows. Claim G.10 (single-view after T 0 ). Suppose Induction Hypothesis G.1 holds for all iterations < t and t \u2265 T 0 . For every single-view data (X, y) \u2208 Z s (or any (X, y) \u2208 D s but with probability 1 \u2212 e \u2212\u2126(log 2 k) ), we have\nF (t) y (X) \u2265 max i\u2208[k]\\{y} F (t)\ni (X) + \u2126(log k) and 1 \u2212 logit y (F (t) , X) \u2264", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "poly(k)", "text": "Proof. This is because for single-view data (X, y) \u2208 Z s , it satisfies Z (t) i, (X) \u2264 \u0393 as long as i = y. As a result, applying Claim G.9, we must have\nF (t) y (X) \u2265 \u2126( 1 \u03c4 ) \u2265 \u2126(log k) but F (t) i (X) \u2264 O(1) for i = y (using \u0393 < 1 polylog(k)\n). (Similar for (X, y) \u2208 D s .)", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "G.2.3 Multi-View Error Till the End", "text": "Claim G.11 (multi till the end, c.f. Claim D.14). Suppose Induction Hypothesis G.1 holds for every iteration t < T , then\n\u2022 \u03b7 T t=T 0 E (X,y)\u223cZm 1 y=i 1 \u2212 logit y (F (t) , X) \u2264 O (1)\n\u2022 \u03b7 Ns N T t=T 0 E (X,y)\u223cZs 1 y=i 1 \u2212 logit \u03c4 i (F (t) , X)\n+ \u2264 O (1)\n\u2022 \u03b7 T t=T 0 E (X,y)\u223cZm 1 v i,1 ,v i,2 \u2208V(X) 1 s(X) \u2212 logit \u03c4 i (F (t) , X)\n+ \u2264 O (1)\nProof of Claim G.11. By Fact G.5 and Claim G.6 again (similar to the calculation in the proof of Claim G.8), we have\nw (t+1) i,r , v i, \u2265 w (t) i,r , v i, \u2212 1 poly(k)\n+ \u2126(\u03b7) E (X,y)\u223cZm 1 y=i V i,r, (X) \u2212 O(\u03c3 p P ) 1 \u2212 logit i (F (t) , X)\n+ \u2126( \u03b7 N s N ) E\n(X,y)\u223cZs 1 y=i V i,r, (X) \u2212 O(\u03c3 p P ) 1 \u2212 logit \u03c4 i (F (t) , X)\n+\n+ \u2126(\u03b7 ) E\n(X,y)\u223cZm\n1 v i,1 ,v i,2 \u2208V(X) V i,r, (X) \u2212 O(\u03c3 p P ) 1 s(X)\n\u2212 logit \u03c4 i (F (t) , X)\n+\nIn the above formula, we can ignore the single-view data for the 1 \u2212 logit i (F (t) , X) term because they are extremely small (see Claim G.10). Now, if we take r = arg max r\u2208[m] w (t) i,r , v i, , we must have (whenever v i,1 , v i,2 \u2208 V(X)) V i,r, (X) \u2265 \u2126(1) \u2022 ReLU w (t) i,r , v i, \u2265 \u2126 1 . Therefore, when summing up over all possible r \u2208 [m], we have\n\u03a6 (t+1) i, \u2265 \u03a6 (t) i, \u2212 \u03b7 poly(k) + \u2126(\u03b7) E (X,y)\u223cZm 1 y=i 1 \u2212 logit i (F (t) , X) + \u2126( \u03b7 N s N ) E\n(X,y)\u223cZs 1 y=i 1 \u2212 logit \u03c4 i (F (t) , X)\n+\n+ \u2126(\u03b7 ) E (X,y)\u223cZm\n1 v i,1 ,v i,2 \u2208V(X) 1 s(X)\n\u2212 logit \u03c4 i (F (t) , X)\n+\nAfter telescoping, and using \u03a6 (t) \u2264 O(1), we finish the proof.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "G.3 Main Lemmas for Proving the Induction Hypothesis", "text": "In this subsection, we provide key technical lemmas that, when combined together, shall prove that Induction Hypothesis G.1 holds for every iteration (and thus prove Theorem G.3). 24", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "G.3.1 Correlation Growth", "text": "Lemma G.12 (c.f. Lemma D.21). Suppose Parameter G.2 holds and suppose Induction Hypothesis G.1 holds for all iterations < t. Then, letting\n\u03a6 (t) i, def = r\u2208[m] [ w (t) i,r , v i, ] + , we have \u2200i \u2208 [k], \u2200 \u2208 [2] : \u03a6 (t) i, \u2264 O(1)\nProof of Lemma G.12. Let us denote by \u03a6 (t) = max i\u2208[k], \u2208[2] \u03a6 (t) i, . Suppose t is some iteration so that \u03a6 (t) \u2265 10 \u03c4 2 but \u03a6 (t) \u2264 O(1). We wish to prove that if we continue from iteration t for at most T iterations, then \u03a6 (t ) \u2264 O(1) for every t \u2208 [t, T ].\nWithout loss of generality, we assume that \u03a6 (t) \u2265 10 \u03c4 2 always holds from iteration t onwards (because otherwise we can start with the next iteration t so that \u03a6 (t) goes above 10 \u03c4 2 .)\nProof of Lemma G.13. We separately treat t \u2264 T (X,y)\u223cZm E 2,i,r (X) + E 1 + E 3 + E 4,j, (X) 1 v i,1 ,v i,2 \u2208V(X) 1 s(X) \u2212 logit \u03c4 i (F, X)\n+ Using the property that v i,1 , v i,2 \u2208 V(X) with probability \u0398( s k ) over a sample (X, y) \u2208 Z m , and using the trivial bound + O(\u03b7 ) E (X,y)\u223cZm E 2,i,r (X) + E 1 + E 3 + E 4,j, (X) 1 v i,1 ,v i,2 \u2208V(X) 1 s(X) \u2212 logit \u03c4 i (F, X)\n+\nIn the above formula, we can ignore the single-view data for the 1 \u2212 logit y (F (t) , X) and logit i (F (t) , X) (for i = y) terms because they are extremely small (see Claim G.10). Now, applying the naive upper bounds E 2,i,r (X) \u2264 \u03b3 and E 4,j, (X) \u2264 O(\u03c3 q\u22121 0 ), and telescoping for all t \u2265 T 0 and applying Claim G.11, we immediately have | w ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "G.3.3 Noise Correlation is Small", "text": "Lemma G.14 (c.f. Lemma D.25). Suppose Parameter G.2 holds and suppose Induction Hypothesis G.1 holds for all iterations < t. For every \u2208 [2], for every r \u2208 [m], for every (X, y) \u2208 Z and i \u2208 [k]:\n(a) For every p \u2208 P v i, (X), we have: w (t) i,r , \u03be p \u2264 o (\u03c3 0 ).\n(b) For every p \u2208 P(X) \\ P v i,1 (X) \u222a P v i,2 (X) , we have: | w ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "G.4 Proof of Theorem 3", "text": "First of all, applying Claim G.11 and T \u2265 poly(k) \u03b7 , we know there are at most 90% of the iterations t \u2264 T 0 satisfying E (X,y)\u223cZm 1 \u2212 logit y (F (t) , X) \u2264 1 poly(k) Applying Claim D.16, we immediately have the test accuracy result for multi-view data.\nApplying Claim G.10 (which uses \u03a6 (t) i, \u2265 \u2126(log k)), we immediately have the test accuracy result for single-view data.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "G.5 Proof of Theorem 4", "text": "We assume the readers are now familiar with the proofs of the single model Theorem 1 and of the ensemble distill Theorem 3. They easily imply Theorem 4 for reasons we explain below. \u2265 \u2126(log k). At the end of stage 1, also recall for every (i, ) \u2208 M, for any single-view data (X, y) \u2208 D s with y = i and (X) = , with high probability F predicts correctly on (X, y). Let us remind the readers from (C.2) that\nM def = (i, * ) \u2208 [k] \u00d7 [2] \u039b (0) i, * \u2265 \u039b (0) i,3\u2212 * S i,3\u2212 * S i, * 1 q\u22122 1 + 1 log 2 (m)\nwhere S i, def = E (X,y)\u223cZm 1 y=i p\u2208Pv i, (X) z q p . Since in this self-distillation theorem, we have Assumption 4.1 which says the distribution of p\u2208Pv(X) z q p for v \u2208 {v y,1 , v y,2 } are the same over multi-view data, by standard concentration, we know with high probability S i,1 = S i,2 1 \u00b1 1 2 log 2 k for every i \u2208 [k]. This means, we can alternatively define\nM F def = (i, * ) \u2208 [k] \u00d7 [2] \u039b (0) i, * \u2265 \u039b (0) i,3\u2212 * 1 + 2 log 2 (m)\n(which is a subset of M) and all the statements about M also apply to M F .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "H Simple Probability Lemmas", "text": "We first state a simple proposition that directly implies Fact C.1.\nProposition H.1. Given m i.i.d. standard Gaussian random variables g 1 , . . . , g m \u223c N (0, 1), with probability at least 1 \u2212 \u03b4, we have that except for at most O(log(1/\u03b4)) indices i \u2208 [m], we have\ng i \u2264 max j\u2208[m] {g j } \u2022 1 \u2212 \u2126 1 log(m/ log(1/\u03b4))\nProof of Proposition H.1. Recall for every x > 0\n1 x \u2212 1 x 3 e \u2212x 2 /2 \u221a 2\u03c0 \u2264 Pr g [g > x] \u2264 1 x e \u2212x 2 /2 \u221a 2\u03c0 (H.1)\nThe probability for one of them to exceed Pr[max\ni g i > x] = 1 \u2212 (1 \u2212 Pr g [g > x]) m\nLet us choose x * so that Pr[max i g i > x] = 1 \u2212 \u03b4/2. By the asymptotic bound above, it is easy to derive that x * = \u0398( log(m/ log(1/\u03b4))) and Pr[g > x * ] = \u0398( log(1/\u03b4) m\n). Now, consider x = x * \u2212 1\nx * = x * (1 \u2212 1 (x * ) 2 ). By the asymptotic bound above, it is not hard to see\nPr[g > x] \u2264 O(1) \u2022 Pr[g > x * ] \u2264 O( log(1/\u03b4) m )\nBy Chernoff bound, we know with probability at least 1 \u2212 \u03b4, it satisfies that Proof of Proposition H.2. The case of \u03c3 \u2264 1 is trivial and is simply by symmetry.\nThe case of \u03c3 > 1. For any threshold x > 0, we have\nPr[max i g i > x] = 1 \u2212 (1 \u2212 Pr g\u223cN (0,1) [g > x]) m Pr[max i h i < x] = (1 \u2212 Pr h\u223cN (0,\u03c3 2 ) [h > x]) m\nLet x * > \u03c3 be a threshold satisfying \u03c3\nx * e \u2212(x * ) 2 /2\u03c3 2 \u221a 2\u03c0 = 1 m . By the earlier Gaussian tail bound (H.1), it is easy to verify\nPr[max i h i < x * ] = (1 \u2212 Pr h\u223cN (0,\u03c3 2 ) [h > x * ]) m \u2265 \u2126(1)\nUsing the earlier Gaussian tail bound (H.1), one can also verify that\nPr g\u223cN (0,1) [g > x * ] \u2265 1 2x * e \u2212(x * ) 2 /2 \u221a 2\u03c0 \u2265 1 2\u03c3 1 m \u03c3 2 Therefore, Pr[max i g i > x * ] = 1 \u2212 (1 \u2212 Pr g\u223cN (0,1) [g > x * ]) m \u2265 1 \u2212 1 \u2212 \u2126(m) \u2022 1 \u03c3m \u03c3 2\nCombining both, we have\nPr[max i h i < x * < max i g i ] = Pr[max i h i < x * ] \u2022 Pr[max i g i > x * ] \u2265 \u2126(1) \u03c3m \u03c3 2 \u22121\nThe case of \u03c3 \u2264 1. Let us first generate h and then generate g. Since \u03c3 \u2264 1, we have with probability at least 1 \u2212 1 poly(m) , it satisfies that 0 < max i\u2208[m] h i \u2264 O( \u221a log m). When this happens, denoting by z = max i\u2208[m] h i , we can apply a known anti-concentration result for the maximum of Gaussian variables [21,Theorem 3]: \u2022 For every i \u2208 [k], at most one of (i, 1) or (i, 2) is in M (obvious).\nPr max i\u2208[m] g i \u2208 [z(1 \u2212 \u03c4 ), z(1 + \u03c4 )] \u2264 O(z\u03c4 ) \u2022 O(E[max i\u2208[m]\n\u2022 For every i \u2208 [k], suppose S i, \u2265 S i,3\u2212 , then\n-Pr (i, 3 \u2212 ) \u2208 M \u2265 m \u2212O(1) . -Pr (i, ) \u2208 M or (i, 3 \u2212 ) \u2208 M \u2265 1 \u2212 o(1)\nProof of Proposition C.2. We only prove the second item since the first one is trivial. Suppose S i, \u2265 S i,3\u2212 . By our assumption on the data distribution, it is easy to verify S i,1 /S i,2 > 0 is a constant for every i \u2208 ", "publication_ref": ["b20"], "figure_ref": [], "table_ref": []}, {"heading": "", "text": "We first consider every t \u2264 T 0 def = \u0398 k \u03b7\u03c3 q\u22122 0 (recall Claim D.11). Using Claim D. 4 we have logit i (F (t) , X) = O( 1k ). This implies\n(Above, the last inequality uses our earlier parameter choices, see (D.12).) As for t \u2265 T 0 , we combining this with logit i F (t) , X \u2264 1 \u2212 logit y F (t) , X for i = y and (X, y) \u2208 Z m , and logit i F (t) , X \u2264 O 1 k 1 \u2212 logit y F (t) , X for i = y and (X, y) \u2208 Z s , we have\n(X,y)\u223cZs 1 y=i O(\u03c3 p P ) 1 \u2212 logit y (F (t) , X)\nFinally, recall Claim D.14 =\u21d2\nTherefore, we know for every t \u2208 [T 0 , T ]:\n(Above, the inequality x uses our earlier parameter choices, see (D.18).)", "publication_ref": ["b3"], "figure_ref": [], "table_ref": []}, {"heading": "D.5 Putting All Together", "text": "We are now ready to restate Theorem D.2 and prove it.\nTheorem D.2. Under Parameter D.1, for any m \u2208 \u2126(1), o( 1 \u03c3 0 ) and sufficiently small \u03b7 \u2264 1 poly(k) , our Induction Hypothesis C.3 holds for all iterations t = 0, 1, . . . , T .\nProof of Theorem D.2. At iteration t, we first calculate\nIt is easy to verify Induction Hypothesis C.3 holds at iteration t = 0 (merely some simple high probability bounds on Gaussian random variables). Suppose Induction Hypothesis C.3 holds for all iterations < t. We have established several lemmas", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "30)", "text": "\u2022 m = polylog(k).\nExplanation: we do not need the model to have too much over-parameterization.\n\u2022 \u03b7 = \u03b7poly(k).\nTheorem G.3. Under Parameter G.2, for any m = polylog(k) and sufficiently small \u03b7 \u2264 1 poly(k)\nand \u03b7 = \u03b7poly(k), our Induction Hypothesis G.1 holds for all iterations t = 0, 1, . . . , T .\nThis entire section is denoted to proving Theorem G.3, and we shall explain in the end of this section how Theorem G.3 implies Theorem 3.\nDisclaimer. To make this paper more concise, in the rest of this section we highlight the key technical claims/lemmas that we need to prove Induction Hypothesis G.1. Some of the proofs we give in this section are more \"sketched\" because we assume the readers are already familiar with our proof languages used in Section D.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "G.1 Gradient Calculations and Function Approximation", "text": "Claim G.4. There exists some parameter \u039e = polylog(k) in (F.1) so that for every\n(Recall with high probability s(X) = \u0398(s).) And, for every (X, y) \u2208 Z s ,\nProof of Claim G.4. Using the same analysis as the proof of Theorem 2, we know after ensemble,\nand therefore there exists some scale-up factor \u039e = polylog(k) for (F.1) so that for every (X, y)\nand at the same time, for every (X, y)\nPlugging this into the threshold logit function (4.2) finishes the proof.\nNote that our update rule (4.3) is not precisely the gradient of a function (due to our truncation to the negative part for simpler analysis). However, in the remainder of the proof, slightly abusing notation, let us denote by\nso that when\nThen, for every (X, y) \u2208 Z m , (G.7) tells us that\nfor every i such that v i,1 , v i,2 \u2208 V(X). Therefore,\nAlso, for every (X, y) \u2208 Z s , for similar reason we have\nTherefore, at this iteration t, up to negligible 1 k \u2126(log k) terms, we have according to Claim G.7:\nThis is already identical to what we had in the single-model case (without distillation). This time, we can calculate (using Claim G.6)\n\u2022 For every (X, y) \u2208 Z m with y = i, recall from Claim G.7 that\nTogether, and summing up over all r \u2208 [m], we have\nso if we continue this for T iterations we still have \u03a6 (T ) \u2264 O(1).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "G.3.2 Off-Diagonal Correlations are Small", "text": "Lemma G.13 (c.f. Lemma D.22). Suppose Parameter G.2 holds and suppose Induction Hypothesis G.1 holds for all iterations < t. Then,\nBase Model G. For a similar reason, if (i, ) \u2208 M G for the distill model G, then we have that the quantity \u03a6 (T ) i, \u2265 polylog(k) for network G (recall G is scaled up by a polylog(k) factor). Using a similar analysis to Claim G.4, we can derive that:\n\u2022 for every (X, y) \u2208 Z m , we have\nwhere recall s(X) is the number of indices i \u2208 [k] such that v i,1 or v i,2 is in V(X), and we newly define s (X) as the number of indices i \u2208 [k] such that (i, ) \u2208 M G and v i, \u2208 V(X) for some \u2208 [2]. One can derive using concentration that with high probability s 2 \u2264 s (X) \u2264 s(X) \u2264 3s for all multi-view training data. 25 Stage 2 of F . Similar to the proof of Theorem 3, we can ignore single-view data's contribution to the gradient updates (since they are negligible) and only focus on multi-view data. Using a similar gradient calculation to Fact G.5, we know that, up to some small error,\n\u2022 the quantity \u03a6 i, = r\u2208[m] w i,r , v i, + never decreases during stage 2.\n\u2022 the quantity \u03a6 i = r\u2208[m], \u2208[2] w i,r , v i, + no longer changes during stage 2, when it reaches\n26 Recall after stage 1, we have \u03a6 i \u2265 \u2126(log k) for network F ; but since at the beginning of stage 2 we have scaled up F by a factor of log 4 k, this means \u03a6 i \u2265 2 \u03c4 2 is already satisfied at the beginning of stage 2 (up to small error), so it does not change during stage 2. As a result, at the end of stage 2, network F should give the same (nearly perfect) accuracy on multi-view data as claimed in Theorem 1.\nFurthermore, through a similar analysis to Claim G.8 and Claim G.9 (and combining with (G.1)), we know that for when (i, ) \u2208 M G , the quantity \u03a6 i, must increase to at least 1 2\u03c4 \u2265 \u2126(log 2 k). This allows us to conclude that, when (i, ) \u2208 M G , at the end of stage 2, for those singleview data (X, y) \u2208 D s with y = i and (X) = , with high probability F y (X) \u2265 \u2126(log 2 k) F j (X) for j = y, so F predicts correctly on (X, y).\nAt the same time, for every (i, ) \u2208 M F , we have \u03a6 i, \u2265 \u2126(log k) is already satisfied at the end of stage 1, so at the end of stage 2 it must also satisfy \u03a6 i, \u2265 \u2126(log 5 k) (the extra factors are due to scale-up). Thus, F also predicts correctly on those single-view data (X, y) \u2208 D s with y = i and (X) = .\nFinally, using |M\n), together with the fact that they are totally independent random sets, we obtain\n). This means, learned model F (T +T ) at the end of stage 2 through self-distillation has an accuracy of \u2265 3 4 (1 \u2212 o(1)) over single-view data. 25 We remark here that MG does not depend on the randomness of the training set, so the lower bound s 10 \u2264 s (X) can be derived trivially using |MG| \u2265 k(1 \u2212 o(1)). 26 Whenever \u03a6i \u2265 2 \u03c4 2 for network F , one can verify that Fi(X) \u2265 1 \u03c4 2 for every multi-view data (X, y) \u2208 Zm with vi,1, vi,2 \u2208 V(X). This means logit \u03c4 i (F, X) \u2265 1 s(X) \u2212 k \u2212\u2126(log k) for every multi-view data (X, y) with vi,1, vi,2 \u2208 V(X). When this happens, combining with (G.2), we have logit \u03c4 i (G, X) \u2212 10logit \u03c4 i (F, X) + = 0 so (up to small error) there is no gradient and wi,r, v i, stays unchanged.", "publication_ref": ["b1", "b24", "b2", "b24", "b25"], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Fast decorrelated neural network ensembles with random weights", "journal": "Information Sciences", "year": "2014", "authors": "Monther Alhamdoosh; Dianhui Wang"}, {"ref_id": "b1", "title": "What Can ResNet Learn Efficiently, Going Beyond Kernels?", "journal": "", "year": "2019", "authors": "Zeyuan Allen-Zhu; Yuanzhi Li"}, {"ref_id": "b2", "title": "Can SGD Learn Recurrent Neural Networks with Provable Generalization?", "journal": "", "year": "2019", "authors": "Zeyuan Allen-Zhu; Yuanzhi Li"}, {"ref_id": "b3", "title": "Backward feature correction: How deep learning performs deep learning", "journal": "", "year": "2020", "authors": "Zeyuan Allen-Zhu; Yuanzhi Li"}, {"ref_id": "b4", "title": "On the convergence rate of training recurrent neural networks. In NeurIPS", "journal": "", "year": "2019", "authors": "Zeyuan Allen-Zhu; Yuanzhi Li; Zhao Song"}, {"ref_id": "b5", "title": "A convergence theory for deep learning via overparameterization", "journal": "", "year": "2019", "authors": "Zeyuan Allen-Zhu; Yuanzhi Li; Zhao Song"}, {"ref_id": "b6", "title": "Semantic road segmentation via multi-scale ensembles of learned features", "journal": "Springer", "year": "2012", "authors": "Yann Jose M Alvarez; Theo Lecun; Antonio M Gevers;  Lopez"}, {"ref_id": "b7", "title": "On exact computation with an infinitely wide neural net", "journal": "", "year": "2019", "authors": "Sanjeev Arora; S Simon; Wei Du; Zhiyuan Hu; Ruslan Li; Ruosong Salakhutdinov;  Wang"}, {"ref_id": "b8", "title": "Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks. CoRR, abs", "journal": "", "year": "1901", "authors": "Sanjeev Arora; Simon S Du; Wei Hu; Zhiyuan Li; Ruosong Wang"}, {"ref_id": "b9", "title": "Learning two layer rectified neural networks in polynomial time", "journal": "", "year": "2018", "authors": "Ainesh Bakshi; Rajesh Jayaram; David P Woodruff"}, {"ref_id": "b10", "title": "Ensembles for feature selection: A review and future trends", "journal": "Information Fusion", "year": "2019", "authors": "Amparo Ver\u00f3nica Bol\u00f3n-Canedo;  Alonso-Betanzos"}, {"ref_id": "b11", "title": "Theoretical properties of the global optimizer of two layer neural network", "journal": "", "year": "2017", "authors": "Digvijay Boob; Guanghui Lan"}, {"ref_id": "b12", "title": "Bagging predictors", "journal": "Machine learning", "year": "1996", "authors": "Leo Breiman"}, {"ref_id": "b13", "title": "Diversity creation methods: a survey and categorisation", "journal": "Information Fusion", "year": "2005", "authors": "Gavin Brown; Jeremy Wyatt; Rachel Harris; Xin Yao"}, {"ref_id": "b14", "title": "Managing diversity in regression ensembles", "journal": "Journal of machine learning research", "year": "2005-09", "authors": "Gavin Brown; Jeremy L Wyatt; Peter Ti\u0148o"}, {"ref_id": "b15", "title": "Globally optimal gradient descent for a convnet with gaussian inputs", "journal": "", "year": "2017", "authors": "Alon Brutzkus; Amir Globerson"}, {"ref_id": "b16", "title": "Attribute bagging: improving accuracy of classifier ensembles by using random feature subsets", "journal": "Pattern recognition", "year": "2003", "authors": "Robert Bryll; Ricardo Gutierrez-Osuna; Francis Quek"}, {"ref_id": "b17", "title": "Feature selection in machine learning: A new perspective", "journal": "Neurocomputing", "year": "2018", "authors": "Jie Cai; Jiawei Luo; Shulin Wang; Sheng Yang"}, {"ref_id": "b18", "title": "Generalization bounds of stochastic gradient descent for wide and deep neural networks", "journal": "", "year": "2019", "authors": "Yuan Cao; Quanquan Gu"}, {"ref_id": "b19", "title": "Distilling knowledge from ensembles of neural networks for speech recognition", "journal": "", "year": "2016", "authors": "Yevgen Chebotar; Austin Waters"}, {"ref_id": "b20", "title": "Comparison and anti-concentration bounds for maxima of gaussian random vectors. Probability Theory and Related Fields", "journal": "", "year": "2015", "authors": "Victor Chernozhukov; Denis Chetverikov; Kengo Kato"}, {"ref_id": "b21", "title": "Knowledge distillation across ensembles of multilingual models for low-resource languages", "journal": "IEEE", "year": "2017", "authors": "Jia Cui; Brian Kingsbury; Bhuvana Ramabhadran; George Saon; Tom Sercu; Kartik Audhkhasi; Abhinav Sethy; Markus Nussbaum-Thom; Andrew Rosenberg"}, {"ref_id": "b22", "title": "Sgd learns the conjugate kernel class of the network", "journal": "", "year": "2017", "authors": "Amit Daniely"}, {"ref_id": "b23", "title": "Toward deeper understanding of neural networks: The power of initialization and a dual view on expressivity", "journal": "", "year": "2016", "authors": "Amit Daniely; Roy Frostig; Yoram Singer"}, {"ref_id": "b24", "title": "Ensemble methods in machine learning", "journal": "Springer", "year": "2000", "authors": "G Thomas;  Dietterich"}, {"ref_id": "b25", "title": "Gradient descent finds global minima of deep neural networks", "journal": "", "year": "2018-11", "authors": "Jason D Simon S Du; Haochuan Lee; Liwei Li; Xiyu Wang;  Zhai"}, {"ref_id": "b26", "title": "Gradient descent provably optimizes over-parameterized neural networks", "journal": "", "year": "2018", "authors": "Xiyu Simon S Du; Barnabas Zhai; Aarti Poczos;  Singh"}, {"ref_id": "b27", "title": "Bootstrapping regression models", "journal": "The Annals of Statistics", "year": "1981", "authors": " David A Freedman"}, {"ref_id": "b28", "title": "Ensemble distillation for neural machine translation", "journal": "", "year": "2017", "authors": "Markus Freitag; Yaser Al-Onaizan; Baskaran Sankaran"}, {"ref_id": "b29", "title": "A decision-theoretic generalization of on-line learning and an application to boosting", "journal": "Journal of computer and system sciences", "year": "1997", "authors": "Yoav Freund; Robert E Schapire"}, {"ref_id": "b30", "title": "A short introduction to boosting", "journal": "Journal-Japanese Society For Artificial Intelligence", "year": "1999", "authors": "Yoav Freund; Robert Schapire; Naoki Abe"}, {"ref_id": "b31", "title": "Additive logistic regression: a statistical view of boosting (with discussion and a rejoinder by the authors). The annals of statistics", "journal": "", "year": "2000", "authors": "Jerome Friedman; Trevor Hastie; Robert Tibshirani"}, {"ref_id": "b32", "title": "Greedy function approximation: a gradient boosting machine", "journal": "Annals of statistics", "year": "2001", "authors": "H Jerome;  Friedman"}, {"ref_id": "b33", "title": "Jia Cui, and Bhuvana Ramabhadran. Efficient knowledge distillation from an ensemble of teachers", "journal": "", "year": "2017", "authors": "Takashi Fukuda; Masayuki Suzuki; Gakuto Kurata; Samuel Thomas"}, {"ref_id": "b34", "title": "Laurent Itti, and Anima Anandkumar. Born again neural networks", "journal": "", "year": "2018", "authors": "Tommaso Furlanello; C Zachary; Michael Lipton;  Tschannen"}, {"ref_id": "b35", "title": "A review on ensembles for the class imbalance problem: bagging-, boosting-, and hybrid-based approaches", "journal": "IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)", "year": "2011", "authors": "Mikel Galar; Alberto Fernandez; Edurne Barrenechea; Humberto Bustince; Francisco Herrera"}, {"ref_id": "b36", "title": "Learning one-hidden-layer neural networks with landscape design", "journal": "", "year": "2017", "authors": "Rong Ge; Jason D Lee; Tengyu Ma"}, {"ref_id": "b37", "title": "Learning two-layer neural networks with symmetric inputs", "journal": "", "year": "2018", "authors": "Rong Ge; Rohith Kuditipudi; Zhize Li; Xiang Wang"}, {"ref_id": "b38", "title": "Linearized two-layers neural networks in high dimension", "journal": "", "year": "2019", "authors": "Behrooz Ghorbani; Song Mei; Theodor Misiakiewicz; Andrea Montanari"}, {"ref_id": "b39", "title": "Finite depth and width corrections to the neural tangent kernel", "journal": "", "year": "2019", "authors": "Boris Hanin; Mihai Nica"}, {"ref_id": "b40", "title": "Neural network ensembles. IEEE transactions on pattern analysis and machine intelligence", "journal": "", "year": "1990", "authors": "Lars Kai Hansen; Peter Salamon"}, {"ref_id": "b41", "title": "Distilling the knowledge in a neural network", "journal": "", "year": "2015", "authors": "Geoffrey Hinton; Oriol Vinyals; Jeff Dean"}, {"ref_id": "b42", "title": "The random subspace method for constructing decision forests", "journal": "", "year": "1998", "authors": "Kam Tin;  Ho"}, {"ref_id": "b43", "title": "Neural tangent kernel: Convergence and generalization in neural networks", "journal": "", "year": "2018", "authors": "Arthur Jacot; Franck Gabriel; Cl\u00e9ment Hongler"}, {"ref_id": "b44", "title": "Deep learning without poor local minima", "journal": "", "year": "2016", "authors": "Kenji Kawaguchi"}, {"ref_id": "b45", "title": "On combining classifiers", "journal": "", "year": "1998", "authors": "Josef Kittler; Mohamad Hatef; P W Robert; Jiri Duin;  Matas"}, {"ref_id": "b46", "title": "Wrappers for feature subset selection", "journal": "Artificial intelligence", "year": "1997", "authors": "Ron Kohavi; H George;  John"}, {"ref_id": "b47", "title": "Dynamic weighted majority: An ensemble method for drifting concepts", "journal": "Journal of Machine Learning Research", "year": "2007-12", "authors": "Zico Kolter; Marcus A Maloof"}, {"ref_id": "b48", "title": "Learning multiple layers of features from tiny images", "journal": "", "year": "2009", "authors": "Alex Krizhevsky"}, {"ref_id": "b49", "title": "Neural network ensembles, cross validation, and active learning", "journal": "", "year": "1994", "authors": "Anders Krogh; Jesper Vedelsby"}, {"ref_id": "b50", "title": "Combining pattern classifiers: methods and algorithms", "journal": "John Wiley & Sons", "year": "2014", "authors": "I Ludmila;  Kuncheva"}, {"ref_id": "b51", "title": "Knowledge distillation by on-the-fly native ensemble", "journal": "", "year": "2018", "authors": "Xu Lan; Xiatian Zhu; Shaogang Gong"}, {"ref_id": "b52", "title": "When can wasserstein gans minimize wasserstein distance? arXiv preprint", "journal": "", "year": "2020", "authors": "Yuanzhi Li; Zehao Dou"}, {"ref_id": "b53", "title": "Provable alternating gradient descent for non-negative matrix factorization with strong correlations", "journal": "", "year": "2017", "authors": "Yuanzhi Li; Yingyu Liang"}, {"ref_id": "b54", "title": "Learning overparameterized neural networks via stochastic gradient descent on structured data", "journal": "", "year": "2018", "authors": "Yuanzhi Li; Yingyu Liang"}, {"ref_id": "b55", "title": "Convergence analysis of two-layer neural networks with relu activation", "journal": "", "year": "2017", "authors": "Yuanzhi Li; Yang Yuan"}, {"ref_id": "b56", "title": "Recovery guarantee of non-negative matrix factorization via alternating updates", "journal": "", "year": "2016", "authors": "Yuanzhi Li; Yingyu Liang; Andrej Risteski"}, {"ref_id": "b57", "title": "Algorithmic regularization in over-parameterized matrix sensing and neural networks with quadratic activations", "journal": "", "year": "2018", "authors": "Yuanzhi Li; Tengyu Ma; Hongyang Zhang"}, {"ref_id": "b58", "title": "Towards explaining the regularization effect of initial large learning rate in training neural networks", "journal": "", "year": "2019", "authors": "Yuanzhi Li; Colin Wei; Tengyu Ma"}, {"ref_id": "b59", "title": "Learning over-parametrized two-layer relu neural networks beyond ntk", "journal": "", "year": "2020", "authors": "Yuanzhi Li; Tengyu Ma; Hongyang R Zhang"}, {"ref_id": "b60", "title": "Improving multi-task deep neural networks via knowledge distillation for natural language understanding", "journal": "", "year": "2019", "authors": "Xiaodong Liu; Pengcheng He; Weizhu Chen; Jianfeng Gao"}, {"ref_id": "b61", "title": "A high-bias, low-variance introduction to machine learning for physicists", "journal": "Physics reports", "year": "2019", "authors": "Pankaj Mehta; Marin Bukov; Ching-Hao Wang; G R Alexandre; Clint Day;  Richardson; K Charles; David J Fisher;  Schwab"}, {"ref_id": "b62", "title": "Self-distillation amplifies regularization in hilbert space", "journal": "", "year": "2020", "authors": "Hossein Mobahi; Mehrdad Farajtabar; Peter L Bartlett"}, {"ref_id": "b63", "title": "On feature selection, bias-variance, and bagging", "journal": "", "year": "", "authors": "Arthur Munson; Rich Caruana"}, {"ref_id": "b64", "title": "Feature visualization", "journal": "Distill", "year": "2017", "authors": "Chris Olah; Alexander Mordvintsev; Ludwig Schubert"}, {"ref_id": "b65", "title": "Feature selection for ensembles: A hierarchical multi-objective genetic algorithm approach", "journal": "Citeseer", "year": "2003", "authors": "S Luiz; Robert Oliveira; Fl\u00e1vio Sabourin; Ching Y Bortolozzi;  Suen"}, {"ref_id": "b66", "title": "Popular ensemble methods: An empirical study", "journal": "Journal of artificial intelligence research", "year": "1999", "authors": "David Opitz; Richard Maclin"}, {"ref_id": "b67", "title": "Feature selection for ensembles", "journal": "", "year": "1999", "authors": "W David;  Opitz"}, {"ref_id": "b68", "title": "Towards moderate overparameterization: global convergence guarantees for training shallow neural networks", "journal": "", "year": "2019", "authors": "Samet Oymak; Mahdi Soltanolkotabi"}, {"ref_id": "b69", "title": "When networks disagree: Ensemble methods for hybrid neural networks", "journal": "", "year": "1992", "authors": "P Michael; Leon N Perrone;  Cooper"}, {"ref_id": "b70", "title": "Ensemble based systems in decision making. IEEE Circuits and systems magazine", "journal": "", "year": "2006", "authors": "Robi Polikar"}, {"ref_id": "b71", "title": "Rotation forest: A new classifier ensemble method", "journal": "", "year": "2006", "authors": "Juan Jos\u00e9 Rodriguez; I Ludmila; Carlos J Kuncheva;  Alonso"}, {"ref_id": "b72", "title": "Ensemble-based classifiers", "journal": "Artificial intelligence review", "year": "2010", "authors": "Lior Rokach"}, {"ref_id": "b73", "title": "Pattern classification using ensemble methods", "journal": "World Scientific", "year": "2010", "authors": "Lior Rokach"}, {"ref_id": "b74", "title": "Data mining with decision trees: theory and applications", "journal": "World scientific", "year": "2008", "authors": "Lior Rokach;  Oded Z Maimon"}, {"ref_id": "b75", "title": "Boosting the margin: A new explanation for the effectiveness of voting methods. The annals of statistics", "journal": "", "year": "1998", "authors": "Yoav Robert E Schapire; Peter Freund; Wee Bartlett;  Sun Lee"}, {"ref_id": "b76", "title": "Neural kernels without tangents", "journal": "", "year": "2020", "authors": "Vaishaal Shankar; Alex Fang; Wenshuo Guo; Sara Fridovich-Keil; Ludwig Schmidt; Jonathan Ragan-Kelley; Benjamin Recht"}, {"ref_id": "b77", "title": "Theoretical insights into the optimization landscape of over-parameterized shallow neural networks", "journal": "", "year": "2017", "authors": "Mahdi Soltanolkotabi; Adel Javanmard; Jason D Lee"}, {"ref_id": "b78", "title": "No bad local minima: Data independent training error guarantees for multilayer neural networks", "journal": "", "year": "2016", "authors": "Daniel Soudry; Yair Carmon"}, {"ref_id": "b79", "title": "An analytical formula of population gradient for two-layered relu network and its applications in convergence and critical point analysis", "journal": "", "year": "2017", "authors": "Yuandong Tian"}, {"ref_id": "b80", "title": "Diversity in search strategies for ensemble feature selection. Information fusion", "journal": "", "year": "2005", "authors": "Alexey Tsymbal; Mykola Pechenizkiy; P\u00e1draig Cunningham"}, {"ref_id": "b81", "title": "An experimental bias-variance analysis of svm ensembles based on resampling techniques", "journal": "IEEE Transactions on Systems, Man, and Cybernetics", "year": "2005", "authors": "Giorgio Valentini"}, {"ref_id": "b82", "title": "Bias-variance analysis of support vector machines for the development of svm-based ensemble methods", "journal": "Journal of Machine Learning Research", "year": "2004-07", "authors": "Giorgio Valentini; G Thomas;  Dietterich"}, {"ref_id": "b83", "title": "Polynomial convergence of gradient descent for training one-hiddenlayer neural networks", "journal": "", "year": "2018", "authors": "Santosh Vempala; John Wilmes"}, {"ref_id": "b84", "title": "Diversity leads to generalization in neural networks", "journal": "", "year": "2016", "authors": "Bo Xie; Yingyu Liang; Le Song"}, {"ref_id": "b85", "title": "Scaling limits of wide neural networks with weight sharing: Gaussian process behavior, gradient independence, and neural tangent kernel derivation", "journal": "", "year": "2019", "authors": "Greg Yang"}, {"ref_id": "b86", "title": "On the power and limitations of random features for understanding neural networks", "journal": "", "year": "2019", "authors": "Gilad Yehudai; Ohad Shamir"}, {"ref_id": "b87", "title": "", "journal": "", "year": "2016", "authors": "Sergey Zagoruyko; Nikos Komodakis"}, {"ref_id": "b88", "title": "Be your own teacher: Improve the performance of convolutional neural networks via self distillation", "journal": "", "year": "2019", "authors": "Linfeng Zhang; Jiebo Song; Anni Gao; Jingwei Chen; Chenglong Bao; Kaisheng Ma"}, {"ref_id": "b89", "title": "Recovery guarantees for one-hidden-layer neural networks", "journal": "", "year": "2017", "authors": "Kai Zhong; Zhao Song; Prateek Jain; L Peter; Inderjit S Bartlett;  Dhillon"}, {"ref_id": "b90", "title": "Ensembling neural networks: many could be better than all", "journal": "Artificial intelligence", "year": "2002", "authors": "Zhi-Hua Zhou; Jianxin Wu; Wei Tang"}, {"ref_id": "b91", "title": "Stochastic gradient descent optimizes overparameterized deep relu networks", "journal": "", "year": "2018", "authors": "Difan Zou; Yuan Cao; Dongruo Zhou; Quanquan Gu"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 :1Figure 1: Ensemble in deep learning is very different from ensemble in random feature mappings. Details in Figure 6.", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Contradiction 1 :1training average works even better. Although ensemble of linear functions over NTK features with different random seeds: f i (x) = W (i) , \u03a6 W (i) 0", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 2 :2Figure 2: Illustration of images with multiple views (features) in the ImageNet dataset.", "figure_data": ""}, {"figure_label": "234", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "2 \uf8f3 both v 3 , v 4234appears with weight 1, one of v 3 , v 4 appears with weight 0.1 w.p. 80%; only v 1 appears with weight 1, one of v 3 , v 4 appears with weight 0.1 w.p. 10%; only v 2 appears with weight 1, one of v 3 , v 4 appears with weight 0.1 w.p. 10%. \u2022 When the label is class 2, then \uf8f1 \uf8f2 appears with weight 1, one of v 1 , v 2 appears with weight 0.1 w.p. 80%; only v 3 appears with weight 1, one of v 1 , v 2 appears with weight 0.1 w.p. 10%; only v 4 appears with weight 1, one of v 1 , v 2 appears with weight 0.1 w.p. 10%.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 3 :3Figure 3: Visualization of the channels in layer-23 of a ResNet-34 trained on CIFAR-10, picture from [4].", "figure_data": ""}, {"figure_label": "7", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Figure 7 :7Figure 7: When data is Gaussian-like, and when the target label is generated by some fully-connected(fc) / residual(res) / convolutional(conv) network, ensemble does not improve test accuracy. \"xx % (yy %)\" means xx% accuracy for single model and yy% for ensemble. More experiments in Appendix B.4 (Figure 10 and 11).", "figure_data": ""}, {"figure_label": "8", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "Figure 8 :8Figure 8: Single models (+ their ensemble) vs. Knowledge distillations (+ their ensemble). Details in Appendix B.2.", "figure_data": ""}, {"figure_label": "33", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "Definition 3 . 3 (33D and Z). We assume that the final distribution D consists of data from D m w.p. 1 \u2212 \u00b5 and from D s w.p. \u00b5. We are given N training samples from D, and denote the training data set as Z = Z m \u222a Z s where Z m and Z s respectively represent multi-view and single-view training data. We write (X, y) \u223c Z as (X, y) sampled uniformly at random from the empirical data set, and denote N s = |Z s |.", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "Fact C. 1 .1[k]. (This corresponds to Induction Hypothesis C.3i later.) With probability at least 1 \u2212 e \u2212\u2126(log 5 k) , we have |M(0) i | \u2264 m 0 def = O(log 5 k).(The proof of Fact C.1 follows from standard analysis on Gaussian variables, see Proposition H.1.) Suppose we denote by S i, def = E (X,y)\u223cZm 1 y=i p\u2208Pv i, (X) z q p . Then, define", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_10", "figure_caption": "Claim D. 4 .4If Induction Hypothesis C.3 holds at iteration t, and ifs \u2264 O( 1 \u03c3 q 0 m ) and \u03b3 \u2264 O(", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_11", "figure_caption": "i\u2264 O(\u03c3 0 )): Claim D.11. Suppose Induction Hypothesis C.3 holds for every iteration. Define thresholds (noticing \u039b \u2212 \u2205 \u2264 \u039b + \u2205 ):", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_12", "figure_caption": "j, | \u2264 O(\u03c3 0 ) Proof of Lemma D.22. Let us denote by R (t) i def = max r\u2208[m],j\u2208[k]\\{i} | w (t) i,r , v j, |. By Claim D.7 and Claim D.8, | w", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_13", "figure_caption": "0 = \u0398 k \u03b7\u03c3 q\u2212 2 0(2see Claim D.11), as long as \u03b3 = O(\u03c3 0 ), \u03b3 = O(1/s), (\u03b3k) q\u22121 \u03b3P = O(1) (D.13)", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_14", "figure_caption": "\u2212 2 0(=2see Claim D.11), as long as (D.13) together with s \u2264 k and 18 O(\u03c3 0 ) , s\u03a5 \u2264 O(1) (D.15)Then, we also have R(t) i \u2264 O(\u03c3 0 ) for every t \u2208 [T 0,i , T i ].Stage 3. At the third stage, namely when t \u2265 T 0 , we can continue from (D.14) (and apply the naive bound 1 y=i \u2264 1 and 1 v j, \u2208V(X) \u2264 1) to derive that", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_15", "figure_caption": "\u2212 * \u2264 O(\u03c3 0 ). (In other words, view wins the lottery and view 3 \u2212 is negligible, on label i.) Lemma D.23. Suppose Parameter D.1 holds and suppose Induction Hypothesis C.3 holds for all iterations < t. Then, \u2200i, * \u2208 M :", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_16", "figure_caption": "\u2212 \u2264 O(\u03c3 0 ). Stage 2. In the second stage, namely when t \u2208 [T 0,i , T i ], let us denote = 3 \u2212 * for abbreviation. Suppose we want to prove \u039b (t+1) i,3\u2212 * \u2264 O(\u03c3 0 ). By Claim D.7 and Claim D.8 again (but this time only using the upper bound part),", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_17", "figure_caption": "\u2212 2 02from Claim D.11, and recall we have s\u03a5 \u2264 O(1) (from (D.15)), we finish the proof that | w (t+1) i,r , v i, | \u2264 O(\u03c3 0 ). This means, \u039b", "figure_data": ""}, {"figure_label": "12201", "figure_type": "figure", "figure_id": "fig_18", "figure_caption": "Ns k\u03c1 q\u22121 \u2264 O 1 \u03c3 q\u2212 2 0( 20 k\u03c3 q\u2212 1 0=12201already satisfied in (D.18)) and additionally In this subsection, we prove that the neurons outside M (0) i for each index i \u2208 [k] is negligible. (They did not win the lottery so only the neurons in M (0) i count.) Lemma D.24. Suppose Parameter D.1 holds and suppose Induction Hypothesis C.3 holds for all iterations < t. Then,", "figure_data": ""}, {"figure_label": "23", "figure_type": "figure", "figure_id": "fig_19", "figure_caption": "Stage 2 .Stage 3 .23(t) i,r , v i, for r * = arg max r\u2208[m] w (0) i,r , v i, and r \u2208 M (0) i, .We skip the details for the sake of cleanness. In the second stage, namely when t \u2208 [T 0,i , T 0 ], we can also completely reuse the stage 2 of the proof of Lemma D.23. The only slight difference is that in order to derive (D.22), this time we instead use Induction Hypothesis C.3f. In the third stage, namely when t \u2265 T 0 , we can also completely reuse the stage 3 of the proof of Lemma D.23. The only slight difference is that in order to derive (D.22), this time we instead use Induction Hypothesis C.3f.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_20", "figure_caption": ", \u03be p | \u2264 O(\u03c3 0 ).(c) For every p \u2208 [P ] \\ P(X), we have: | w (t) i,r , \u03be p | \u2264 O(\u03c3 0 \u03b3k). In addition, for every (X, y) \u2208 Z s , every i \u2208 [k], every r \u2208 [m], every \u2208 [2], (d) For every p \u2208 P v i, (X), if (i, 3 \u2212 ) \u2208 M we have: | w (t) i,r , \u03be p | \u2264 O(\u03c3 0 ).20 This is the place in our proof that we require \u03c3 q\u22122 0 \u2264 1 k . For simplicity, we have chosen\u03c3 q\u22122 0 \u2264 1 k in Parameter D.1.21 In particular, we need to ensure(\u03c30) q\u22122 \u2264 \u03c1 q\u22121 and N \u2265 \u2126 k 5 \u03c3 q\u22121 0 in the proof of this lemma.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_21", "figure_caption": "(e) For every p \u2208 Pv i, (X), if r \u2208 [m] \\ M (0) i we have: | w (t) i,r , \u03be p | \u2264 O(\u03c3 ).We prove Lemma D.25 after we establish the following claim.Claim D.26. For every (X, y) \u2208 Z, i \u2208 [k], r \u2208 [m], and p \u2208 [P ], suppose it satisfies | w (t)", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_22", "figure_caption": ", x p | \u2264 O(1) for every t < t according to our Induction Hypothesis C.3a and C.3g, by applying Claim D.26 we immediately have| w (t) i,r , \u03be p | \u2264 o(\u03c3 0 ) once we plug in A = O(1), N \u2265 \u03c9 k \u03c3 q\u22121 0, and N \u2265 \u03c9 k 5 \u03c3 0 .\u2022 In the case of Lemma D.25b, since we have | w(t ) i,r , x p | \u2264 O(\u03c3 0) for every t < t according to our Induction Hypothesis C.3b, by applying Claim D.26 we immediately have | w(t) i,r , \u03be p | \u2264 O(\u03c3 0 ) once we plug in A = O(\u03c3 0 ), N \u2265 k 5 and (\u03c3 0 ) q\u22122 \u2264 \u03c1 q\u22121 .\u2022 In the case of Lemma D.25c, since we have | w(t ) i,r , x p | \u2264 O(\u03c3 0 \u03b3k) for every t < t according to our Induction Hypothesis C.3c, by applying Claim D.26 we immediately have | w (t) i,r , \u03be p | \u2264 O(\u03c3 0 \u03b3k) once we plug in A = O(\u03c3 0 \u03b3k), N \u2265 k 5 and (\u03c3 0 \u03b3k) q\u22122 \u2264 \u03c1 q\u22121 . \u2022 In the case of Lemma D.25d, since we have | w (t ) i,r , x p | \u2264 O(\u03c3 0 ) for every t < t according to our Induction Hypothesis C.3e, by applying Claim D.26 we immediately have | w (t) i,r , \u03be p | \u2264 O(\u03c3 0 ) once we plug in A = O(\u03c3 0 ), N \u2265 k 5 and (\u03c3 0 ) q\u22122 \u2264 \u03c1 q\u22121 . \u2022 In the case of Lemma D.25e, since we have | w (t ) i,r , x p | \u2264 O(\u03c3 0 ) for every t < t according to our Induction Hypothesis C.3f, by applying Claim D.26 we immediately have | w (t) i,r , \u03be p | \u2264 O(\u03c3 0 ) once we plug in A = O(\u03c3 0 ), N \u2265 k 5 and (\u03c3 0 ) q\u22122 \u2264 \u03c1 q\u22121 .", "figure_data": ""}, {"figure_label": "46", "figure_type": "figure", "figure_id": "fig_23", "figure_caption": "4 . 646Diagonal Correlations are Nearly Non-Negative Lemma D.27. Suppose Parameter D.1 holds and suppose Induction Hypothesis C.3 holds for all iterations < t. Then, \u2200i \u2208 [k] , \u2200r \u2208 [m] , \u2200 \u2208 [2] : w (t) i,r , v i, \u2265 \u2212 O(\u03c3 0 ) .", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_24", "figure_caption": "\u2022i, | \u2264 O(\u03c3 0 ) (D.31) To prove C.3a, it suffices to plug (D.27), (D.28) into (D.25), use \u03b1 p,v \u2208 [0, \u03b3], use |V| = 2k, and use | w (t) i,r , \u03be p | \u2264 o(\u03c3 0 ) from Lemma D.25a. \u2022 To prove C.3b, it suffices to plug (D.27), (D.28) into (D.25), use \u03b1 p,v \u2208 [0, \u03b3], use |V| = 2k, and use | w (t) i,r , \u03be p | \u2264 O(\u03c3 0 ) from Lemma D.25b. \u2022 To prove C.3c, it suffices to plug (D.27), (D.28) into (D.26), use \u03b1 p,v \u2208 [0, \u03b3], use |V| = 2k, and use | w (t) i,r , \u03be p | \u2264 O(\u03c3 0 \u03b3k) from Lemma D.25c. \u2022 To prove C.3d, it suffices to plug (D.27), (D.28) into (D.25), use \u03b1 p,v \u2208 [0, \u03b3], use |V| = 2k. \u2022 To prove C.3e, it suffices to plug (D.27), (D.29) into (D.25), use \u03b1 p,v \u2208 [0, \u03b3], use |V| = 2k, and use | w (t) i,r , \u03be p | \u2264 O(\u03c3 0 ) from Lemma D.25d. \u2022 To prove C.3f, it suffices to plug (D.27), (D.31) into (D.25), use \u03b1 p,v \u2208 [0, \u03b3], use |V| = 2k, and use | w (t) i,r , \u03be p | \u2264 O(\u03c3 0 ) from Lemma D.25e. \u2022 To prove C.3g, it suffices to note that (D.28) exactly implies \u039b (t) i \u2264 O(1), and note that Claim D.10 (which says as long as \u039b", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_25", "figure_caption": "\u2264 O \u03c3 0 m 1 polylog1(k) , and since |M| \u2265 k(1 \u2212 o(1)), we have 22 Pr (X,y)\u2208Ds", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_26", "figure_caption": "(T ) y (X) \u2264 O(\u03c1) + 1 polylog(k)(using Def. 3.1 for the single-view distribution).", "figure_data": ""}, {"figure_label": "41", "figure_type": "figure", "figure_id": "fig_27", "figure_caption": "Assumption 4 . 1 (41balanced D m , restated). In Def. 3.1, for multi-view data (X, y), we additionally assume that the marginal distributions of p\u2208Pv(X) z qp \u2208 [1, O(1)] for v \u2208 {v y,1 , v y,2 }.Let G be a single model trained in the same way as Theorem 1. At the end of training, we scale it up by a small factor G \u2190 log 4 k \u2022 G. Define a \"lottery winning\" set", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_28", "figure_caption": ", x p | \u2264 O(\u03c3 0 ). (c) For every p \u2208 [P ] \\ P(X), we have: | w (t) i,r , x p | \u2264 O(\u03c3 0 \u03b3k). Moreover, we have for every", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_29", "figure_caption": "2 .2The parameter range for our proofs in this section to hold is the same as Parameter D.1, except that\u2022 N \u2265 \u03b7T \u2022 poly(k) and \u03b7T \u2265 poly(k). (Instead of \u03b7T \u2265 N \u2022 poly(k).)Explanation: single models need a longer training time because they need to memorize singleview data; instead, here ensemble distillation can truly learn all the training data so the training time T can be shorter.23 ", "figure_data": ""}, {"figure_label": "9", "figure_type": "figure", "figure_id": "fig_30", "figure_caption": "Claim G. 9 .\u20229Define iteration threshold T 0 for every i \u2208 [k], \u2208 [2] and t \u2265 T 0 , it satisfies \u03a6 (t) i, \u2265 1 2\u03c4 G.2.2 Single-View Error Till the End", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_31", "figure_caption": "0 and t \u2265 T 0 . (This should be reminiscent of the three-stage proof in the single model case.) Consider t \u2264 T 0 . By Fact G.5 and Claim G.6", "figure_data": ""}, {"figure_label": "22", "figure_type": "figure", "figure_id": "fig_32", "figure_caption": "E 2 E 222\u03c3 q\u22121 0 )\u03b3s + O (\u03c3 0 \u03b3k) q\u22121 \u03b3P + (\u03c3 0 ) q\u22121 s k Finally, using T 0 = \u0398 k \u03b7 \u03c3 q\u22122 0 , N s \u2264 N poly(k), and using \u03b7 \u2264 \u03b7 poly(k) , together with the same parameter choices as before, we conclude that | w(t+1) i,r , v j, | \u2264 O(\u03c3 0 ) for every t \u2264 T 0 .Consider t > T 0 . By Fact G.5 and Claim G.6 again ,i,r (X) +E 1 + E 3 + E 4,j, (X) 1 y=i (1 \u2212 logit i (F, X)) + O(\u03b7) E (X,y)\u223cZmE 2,i,r (X) + E 1 + E 3 + E 4,j, (X) 1 y =i (logit i (F, X)) ,i,r (X) + E 1 + E 3 + E 4,j, (X) 1 y=i (1 \u2212 logit \u03c4 i (F, X)) +", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_33", "figure_caption": ", v j, | \u2264 | w (T 0 ) i,r , v j, | + O(\u03c3 0 ).", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_34", "figure_caption": ", \u03be p | \u2264 O(\u03c3 0 ). (c) For every p \u2208 [P ] \\ P(X), we have: | w (t) i,r , \u03be p | \u2264 O(\u03c3 0 \u03b3k).Proof. From a similar calculation (see (D.6)) we have for every (X, y) \u2208 Z and p \u2208 [P ], After telescoping and using N T from Parameter G.2, we immediately finish the proof. (If one instead wishes to consider the case of T \u2265 N , she has to do a more careful calculation here. We skip it to keep this paper concise.G.3.4 Diagonal Correlations are Nearly Non-NegativeLemma G.15 (c.f. Lemma D.27). Suppose Parameter G.2 holds and suppose Induction Hypothesis G.1 holds for all iterations < t. Then,\u2200i \u2208 [k] , \u2200r \u2208 [m] , \u2200 \u2208 [2] : w (t) i,r , v i, \u2265 \u2212 O(\u03c3 0 ) .The proof of Lemma G.15 is almost identical to Lemma D.27 so we skip here.", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_35", "figure_caption": "Stage 11of F . Recall Theorem 1 (and Lemma D.21) imply that, at the end of the stage 1 for training a network F , the quantity \u03a6(T ) i \u2208 \u2126(log k), O(1) for every i \u2208 [k]; thus, if (i, ) \u2208 M, we must have \u03a6 (T ) i,", "figure_data": ""}, {"figure_label": "112", "figure_type": "figure", "figure_id": "fig_36", "figure_caption": "Pr m i=1 1 1 m \u03c3 2112g>x \u2265 \u2126(log(1/\u03b4)) \u2264 \u03b4/2We next state a proposition that shall be used to prove Proposition C.2.Proposition H.2. Consider two sequences of i.i.d. Gaussian, g 1 , . . . , g m \u223c N (0, 1) and h 1 , . . . , h m \u223c N (0, \u03c3 2 ). Then,\u2022 when \u03c3 > 1, we have Prmax i\u2208[m] g i > max i\u2208[m] h i \u2265 \u2126 1 \u03c3 \u22121 . \u2022 when \u03c3 \u2264 1, given \u03c4 > 0, we have Pr max i\u2208[m] g i = (1 \u00b1 O(\u03c4 )) max i\u2208[m] h i \u2264 O(\u03c4 log m + 1 poly(m) ).", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_37", "figure_caption": "2 .2g i ]) \u2264 O(z\u03c4 log m)This finishes the proof.Let us restate Proposition C.2 for the readers' convenience. Suppose we denote by S i,def = E (X,y)\u223cZm 1 y=i p\u2208Pv i, (X) z q p . Then, define M def = (i, * ) \u2208 [k] \u00d7 [2] \u039b Suppose m \u2264 poly(k).We have the following properties about M.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_38", "figure_caption": "[k]. Therefore, (i, 3 \u2212 ) \u2208 M with probability at least 1 m O(1) following the first item of Proposition H.2. Finally, if neither (i, ) or (i, 3 \u2212 ) is in M, it necessarily implies \u039b but according to the second item of Proposition H.2, this happens with probability at most 1 log m .", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "for neural nets, ensemble helps on improving test accuracies, and this accuracy gain cannot be matched by training the sum of the individuals directly. In other words, the benefit of using ensemble comes from somewhere other than enlarging the model. Message \u2464: for neural nets, the superior test performance of ensemble can be distilled into single model by a large extent. Message \u2465: for neural nets, self-distillation clearly improves the test performance of single models. Message \u2466: for neural nets, the superior performance of ensemble does not come from the variance of test accuracies in single models.", "figure_data": "CIFAR10 test accuracyCIFAR100 test accuracyfinite-width neuralsingle modelensembletrain \u2211 \u2113 \u2113knowledgeself-single modelensembletrain \u2211 \u2113 \u2113knowledgeself-kernel models(best of 10)(over 10)(over 10)distillationdistill(best of 10)(over 10)(over 10)distillationdistillSimpleCNN-10-3-NTK ResNet10-2-NTK64.36% 69.15%67.38% 73.29%69.37% 74.71%64.63% 65.24% 68.82% 66.09%out of memoryResNet16-2-NTK ResNet16-5-NTK ResNet10-10-NTK SimpleCNN10-6-NTK' ResNet10-4-NTK' SimpleCNN-10-6-GP ResNet-10-4-GP neural networks ResNet-28-2 ResNet-34 ResNet-34-2 ResNet-16-10 ResNet-22-10 ResNet-28-10 Message \u2460: for neural kernel methods, ensemble helps on improving test accuracies, but ensemble is not better than training the sum of 68.32% 73.79% 74.62% (over 7) \u25ca 66.12% 70.61% 74.21% 78.46% out of memory 70.23% 75.66% 76.66% 80.39% out of memory 77.25% 74.46% 59.92% 63.43% 65.69% 59.12% 57.81% 18.99% 26.54% 28.28% 18.27% 18.40% 66.68% 70.54% 72.86% 66.01% 62.91% 31.90% 38.32% 41.47% 31.38% 27.64% 30.48% 35.33% 40.08% 29.43% 29.10% 9.82% 11.82% 12.22% 8.95% 9.33% 42.17% 48.60% 53.17% 39.45% 41.63% 18.89% 22.92% 25.88% 16.91% 16.59% single model (over 10) ensemble (over 10) train \u2211 \u2113 \u2113 (over 10) knowledge distillation self-distill single model (over 10) ensemble (over 10) train \u2211 \u2113 \u2113 (over 10) knowledge distillation self-distill 95.22\u00b10.14% 96.33% 95.02% 96.16% 95.78% 76.38\u00b10.23% 81.13% 73.18% 79.03% 78.12% 93.65\u00b10.19% 94.97% 93.12% 94.59% 94.21% 71.66\u00b10.43% 76.85% 68.88% 73.74% 73.14% 95.45\u00b10.14% 96.55% 95.00% 96.08% 95.86% 77.01\u00b10.35% 81.48% 72.99% 79.23% 79.07% 96.08\u00b10.16% 96.80% 95.88% (over 6) \u25ca 96.81% 96.62% 80.03\u00b10.17% 83.18% 80.53% (over 6) \u25ca 82.67% 82.25% 96.44\u00b10.09% 97.12% 96.41% (over 5) \u25ca 97.09% 97.05% 81.17\u00b10.23% 84.33% 81.59% (over 5) \u25ca 83.71% 83.26% 96.70\u00b10.21% 97.20% 96.46% (over 4) \u25ca 97.22% 97.13% 81.51\u00b10.16% 84.69% 81.83% (over 4) \u25ca 83.81% 83.56% \u2460 \u2460 \u2460 \u2460 \u2461 \u2461 \u2462 \u2462 the individuals directly. In other words, the benefit of using ensemble here merely comes from the richer set of prescribed features. Message \u2461: for neural kernel methods, the superior test performance of ensemble cannot be distilled into a single model. Message \u2462: for neural kernel methods, self-distillation is generally no better than a single model's test performance. \u2463 \u2463 \u2463 \u2463 \u2464 \u2464 \u2465 \u2465 \u2113 over fewer than 10 models. Message \u2463: \u25ca due to memory restriction, trained \u2211 \u2113 \u2466 \u2466Figure 6: Comparing the performances of (1) training 10 independent single models f1, . . . , f10, (2) their ensemble,(3) training f1 + \u2022 \u2022 \u2022 + f10 directly, (4) knowledge distillation of the ensemble into a single model, and (5)training a single model using self-distillation.(NTK' = the original finite-width neural network first-order approximation [6], NTK = the more popularvariant where for each output label one learns a different linear function over the NTK features (e.g. [8]),and GP = training only the last layer of a finite-width random neural network [23]. All the neural networksin these experiments are trained to \u223c 100% training accuracy, and the single model performances matchthe state-of-the-art for these models on CIFAR-10/100. For experiment details, see Appendix B.1.)\u2022 Ensemble (i.e. model averaging) in deep learning works very differently fromensemble in random feature mappings -in particular, different from the neural tangentkernel (NTK) approach [3, 5, 6, 8, 9, 19, 24, 26, 27, 39, 40, 44, 55, 59, 86, 92].Let us do a thought experiment. If ensemble works, can we obtain the same test performance ofensemble by training the sum of over L neural networks"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "3% (79.6%) 80.7% (80.1%) 78.9% (78.6%) 80.7% (80.7%) 74.3% (74.1%) 73.6% (74.0%) 72.9% (72.2%) 74.2% (73.7%) fc2 67.7% (65.1%) 67.7% (64.9%) 66.3% (64.5%) 67.6% (66.9%) 64.3% (63.2%) 70.1% (66.7%) 64.6% (63.5%) 66.2% (63.3%) fc3 68.9% (69.0%) 64.0% (64.4%) 76.8% (76.6%) 73.2% (73.1%) 66.5% (66.4%) 63.0% (62.4%) 72.5% (72.0%) 78.1% (78.6%) res3 69.1% (68.0%) 70.7% (71.2%) 69.3% (69.0%) 69.9% (69.4%) 68.7% (65.9%) 66.9% (63.8%) 68.1% (68.1%) 68.8% (69.5%) conv2 65.4% (65.7%) 67.0% (66.8%) 68.3% (68.2%) 68.3% (68.2%) 67.1% (66.2%) 65.1% (65.5%) 65.8% (66.0%) 67.5% (67.9%)", "figure_data": "no label noisewith 10% label noiseuniform samplingrejection samplinguniform samplingrejection samplinggaussianmixture ofgaussianmixture ofgaussianmixture ofgaussianmixture ofinputgaussianinputgaussianinputgaussianinputgaussiandata without marginlinear 80.conv3 68.7% (68.5%)70.7% (71.2%)77.8% (77.1%)80.3% (80.3%)67.5% (68.2%)67.7% (67.5%)73.6% (73.4%)71.8% (72.1%)resconv378.3% (78.3%)79.6% (79.3%)83.8% (82.6%)82.1% (81.8%)74.1% (73.9%)73.4% (73.1%)78.7% (78.5%)79.2% (78.5%)linear79.0% (78.0%)79.0% (77.2%)78.4% (77.3%)80.0% (80.0%)82.1% (81.7%)80.7% (80.0%)81.6% (80.2%)84.1% (82.4%)fc280.6% (79.0%)80.4% (78.4%)78.4% (76.6%)78.4% (77.0%)77.4% (75.3%)73.7% (73.9%)74.7% (72.2%)75.7% (71.4%)datafc376.0% (75.8%)80.4% (80.1%)76.9% (77.0%)73.3% (72.9%)70.7% (70.8%)73.9% (74.6%)70.4% (70.5%)67.5% (66.4%)withres380.7% (80.8%)84.7% (83.9%)84.6% (84.0%)84.4% (83.7%)75.5% (74.0%)76.9% (76.4%)76.8% (74.8%)76.4% (74.5%)marginconv270.6% (70.3%)74.5% (73.6%)67.8% (67.8%)69.6% (69.4%)68.8% (67.5%)73.3% (71.7%)67.0% (66.6%)67.6% (67.2%)conv376.2% (76.2%)75.3% (76.1%)79.6% (79.1%)84.3% (83.6%)72.2% (72.1%)81.2% (81.3%)73.0% (72.3%)74.4% (75.1%)resconv392.1% (91.7%)92.1% (92.3%)93.9% (93.8%)95.5% (95.1%)85.2% (85.1%)83.5% (84.4%)87.3% (86.8%)85.6% (85.9%)"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "95.22\u00b10.14% 96.33% 95.89\u00b10.07% 96.21% 76.38\u00b10.23% 81.13% 78.94\u00b10.21% 80.35% ResNet-34 93.65\u00b10.19% 94.97% 94.37\u00b10.13% 94.88% 71.66\u00b10.43% 76.85% 73.57\u00b10.34% 75.60% ResNet-34-2 95.45\u00b10.14% 96.55% 96.00\u00b10.12% 96.42% 77.01\u00b10.35% 81.48% 79.43\u00b10.23% 81.56% ResNet-16-10 96.08\u00b10.16% 96.80% 96.73\u00b10.07% 96.76% 80.03\u00b10.17% 83.18% 82.51\u00b10.14% 83.36% ResNet-22-10 96.44\u00b10.09% 97.12% 97.01\u00b10.09% 97.09% 81.17\u00b10.23% 84.33% 83.54\u00b10.19% 84.27%", "figure_data": "CIFAR10 test accuracyCIFAR100 test accuracysingle modelensemble10 runs ofensemble oversingle modelensemble10 runs ofensemble over(over 10)(over 10)knowledge distillknowledge distill(over 10)(over 10)knowledge distillknowledge distillResNet-28-2 ResNet-28-10 96.70\u00b10.21% 97.20%97.06\u00b10.08%97.24%81.51\u00b10.16% 84.69%83.75\u00b10.16%84.87%"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "44\u00b10.29% 68.77\u00b10.25% 66.70\u00b10.66% -69.00\u00b10.43% 66.45\u00b10.15% -ResNet-28 (b) 32 70.49\u00b10.29% 67.62\u00b10.89% 63.28\u00b10.50% -67.99\u00b10.15% 63.89\u00b10.31% -", "figure_data": "CIFAR100# input channelsoriginalsplit to 2split to 4split to 8avg over 2 avg over 4 avg over 8ResNet-28 (a) ResNet-28 (b) ResNet-28-2 (a)16 32 32single model test accuracy 70.ensemble 75.52% 74.47% 80.33%74.07% 73.58% 79.73%73.63% 72.17% 79.58%--78.75%74.05% 71.97% 79.24%70.98% 68.03% 78.19%--76.31%ResNet-28-2 (b)64model79.63%80.18%79.17%78.20%78.42%76.81%72.90%ResNet-28-4 (a)64test82.64%82.81%82.56%82.24%82.26%82.12%81.71%ResNet-28-4 (b)128accuracy81.84%82.06%81.89%81.74%81.28%80.63%79.14%ResNet-28-10 (a)16084.05%84.08%83.65%83.51%83.79%84.12%83.69%ResNet-28-10 (b)32083.10%83.40%83.81%83.53%83.21%83.00%82.19%"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_7", "figure_caption": "gauss, linear79.4% (79.4%) 0.0% 79.9% (79.2%) -0.7% 78.0% (77.8%) -0.3% 80.3% (79.2%) -1.1% 80.1% (79.6%) -0.5% gauss, fc265.4% (64.9%) -0.4% 65.0% (64.2%) -0.8% 64.2% (64.4%) 0.2% 67.7% (65.1%) -2.6% 64.7% (64.2%) -0.5% gauss, fc366.6% (66.7%) 0.1% 68.9% (68.2%) -0.6% 68.6% (69.0%) 0.5% 67.7% (67.5%) -0.2% 68.4% (68.1%) -0.3% gauss, res3 67.1% (67.0%) -0.1% 68.8% (68.0%) -0.8% 66.7% (66.3%) -0.5% 69.1% (67.1%) -2.0% 67.5% (67.8%) 0.3% gauss, linear, margin 79.0% (77.9%) -1.2% 78.8% (77.8%) -1.0% 77.8% (77.3%) -0.5% 77.8% (77.3%) -0.5% 78.7% (78.0%) -0.8% gauss, fc2, margin 80.6% (78.7%) -1.9% 78.9% (79.0%) 0.2% 78.6% (78.5%) -0.1% 78.8% (78.7%) -0.1% 79.0% (78.8%) -0.3% gauss, fc3, margin 75.2% (75.8%) 0.5% 76.0% (75.2%) -0.8% 75.9% (75.6%) -0.4% 76.0% (75.4%) -0.7% 75.8% (75.4%) -0.3% gauss, res3, margin80.5% (80.8%) 0.3% 80.4% (80.0%) -0.3% 80.4% (79.2%) -1.2% 80.7% (80.8%) 0.1% 80.1% (79.9% (70.4%) 0.5% 70.7% (71.2%) 0.5% 70.2% (70.4%) 0.1% 70.2% (71.2%) 1.0% 70.6% (70.7%) 0.1% mixture, linear, margin 77.5% (77.2%) -0.3% 77.8% (77.0%) -0.8% 78.0% (76.4%) -1.6% 77.8% (76.9%) -0.9% 79.0% (76.6%) -2.4% mixture, fc2, margin 79.9% (78.0%) -1.9% 78.8% (78.4%) -0.5% 76.5% (76.3%) -0.2% 80.4% (77.4%) -3.0% 77.4% (77.6%) 0.2% mixture, fc3, margin 79.1% (78.6%) -0.5% 79.9% (80.1%) 0.2% 79.5% (79.4%) -0.1% 79.6% (79.6%) 0.0% 80.4% (79.4%) -0.9% mixture, res3, margin 82.8% (82.8%) 0.0% 84.7% (83.9%) -0.8% 83.7% (83.7%) 0.0% 84.1% (83.5%) -0.6% 83.1% (82.5% gauss, linear, margin 77.7% (77.3%) -0.4% 77.6% (77.0%) -0.6% 76.9% (76.4%) -0.5% 78.4% (77.2%) -1.2% 77.5% (77.3%) -0.2% 5% mixture, linear, margin 79.9% (79.3%) -0.6% 79.7% (79.5%) -0.2% 79.0% (79.2%) 0.2% 79.9% (80.0%) 0.0% 80.0% (79.7%) -0.3% 3% gauss, linear, margin 82.1% (81.7%) -0.4% 80.9% (80.5%) -0.4% 78.4% (78.9%) 0.5% 80.0% (80.3%) 0.3% 79.8% (80.1%) 0.3% 4% mixture, linear, margin 80.7% (79.7%) -1.0% 79.4% (80.0%) 0.7% 78.1% (77.0%) -1.1% 78.8% (79.0%) 0.2% 78.5% (78.6%) 0.1% 0% gauss, linear, margin 81.6% (80.2%) -1.4% 81.3% (78.8%) -2.5% 76.7% (76.7%) 0.0% 78.1% (78.0%) -0.1% 77.4% (77.4%) 0.1% gauss, fc2, margin 72.1% (72.2%) 0.1% 72.1% (71.5%) -0.6% 71.5% (71.6%) 0.1% 74.2% (71.6%) -2.6% 74.7% (71.3%) -3.5% gauss, fc3, margin 66.6% (66.9%) 0.3% 70.4% (70.5%) 0.1% 64.4% (64.5%) 0.1% 65.4% (66.1%) 0.6% 63.8% (64.5%) 0.7% gauss, res3, margin 76.8% (73.6%) -3.2% 74.1% (74.3%) 0.3% 74.3% (74.8%) 0.5% 70.6% (71.1%) 0.5% 70.1% (71.1%) 1.0% mixture, linear 74.2% (73.7%) -0.5% 73.8% (73.5%) -0.3% 72.5% (72.6%) 0.1% 73.5% (72.4%) -1.1% 69.6% (70.7%) 1.1% mixture, fc2 62.3% (62.3%) 0.0% 66.0% (63.3%) -2.8% 66.2% (62.0%) -4.2% 62.3% (63.1%) 0.8% 61.6% (61.5%) -0.1% mixture, fc3 71.9% (71.3%) -0.5% 75.3% (74.8%) -0.5% 78.1% (78.6%) 0.5% 73.4% (73.5%) 0.1% 74.4% (73.9%) -0.5% mixture, res3 66.0% (65.9%) -0.1% 68.5% (69.5%) 1.1% 68.8% (69.4%) 0.5% 64.6% (65.9%) 1.3% 63.5% (64.9%) 1.4% mixture, linear, margin 84.1% (81.5%) -2.6% 82.0% (82.3%) 0.3% 82.7% (82.4%) -0.3% 80.8% (80.7%) -0.1% 80.5% (80.6%) 0.1% mixture, fc2, margin 75.7% (71.4%) -4.3% 71.6% (70.9%) -0.7% 71.0% (71.4%) 0.4% 69.9% (69.7%) -0.2% 69.0% (70.1%) 1.1% mixture, fc3, margin 65.2% (65.5%) 0.3% 66.8% (66.4%) -0.5% 66.1% (66.3%) 0.2% 67.5% (64.0%) -3.5% 62.6% (62.8%) 0.2% mixture, res3, margin 75.6% (72.4%) -3.2% 74.1% (74.5%) 0.4% 72.4% (73.2%) 0.8% 76.4% (72.6%) -3.8% 75.0% (71.9%) -3.1% For synthetic Gaussian-like data, ensemble barely helps on improving test accuracy. In this table, we give a closer look at how ensemble performs with respect to each individual learner network, when the data is generated from a target convolutional network. This gives evidence that, having convolutional data may alone be necessarily for ensemble to work either. 0\u00b10.2% 79.4\u00b10.3% 77.5\u00b10.4% 79.5\u00b10.3% 79.4\u00b10.3% 74.4\u00b10.6% 73.7\u00b10.7% 74.3\u00b10.5% gauss, fc2 65.0\u00b10.2% 64.5\u00b10.3% 63.8\u00b10.3% 64.7\u00b11.2% 64.3\u00b10.3% 62.1\u00b10.4% 62.1\u00b10.5% 62.5\u00b10.5% gauss, fc3 66.4\u00b10.1% 68.4\u00b10.3% 68.0\u00b10.3% 67.3\u00b10.3% 67.3\u00b10.5% 59.4\u00b10.3% 62.6\u00b10.8% 61.1\u00b10.6% gauss, res3 66.4\u00b10.3% 67.3\u00b10.6% 66.1\u00b10.6% 67.3\u00b10.7% 66.8\u00b10.5% 60.9\u00b10.4% 60.3\u00b10.7% 60.9\u00b10.5% gauss, linear, margin 78.2\u00b10.3% 78.0\u00b10.3% 77.2\u00b10.4% 77.0\u00b10.3% 77.8\u00b10.4% 70.3\u00b11.0% 69.6\u00b10.8% 69.7\u00b10.9% gauss, fc2, margin 78.5\u00b10.8% 78.4\u00b10.3% 78.2\u00b10.4% 78.3\u00b10.4% 78.3\u00b10.3% 75.0\u00b10.3% 74.6\u00b10.4% 74.0\u00b10.3% gauss, fc3, margin 75.0\u00b10.1% 75.2\u00b10.4% 75.2\u00b10.4% 75.2\u00b10.4% 75.3\u00b10.4% 67.9\u00b10.4% 68.2\u00b10.7% 66.6\u00b10.8% gauss, res3, margin 80.1\u00b10.3% 80.0\u00b10.3% 77.7\u00b13.0% 80.2\u00b10.3% 79.6\u00b10.3% 71.9\u00b10.4% 71.3\u00b10.6% 71.8\u00b10.5% mixture, linear 80.0\u00b10.3% 79.8\u00b10.3% 78.1\u00b10.5% 80.2\u00b10.3% 79.3\u00b10.3% 75.3\u00b10.5% 72.8\u00b10.5% 74.8\u00b10.5% mixture, fc2 64.2\u00b10.4% 64.2\u00b10.5% 63.0\u00b10.5% 64.4\u00b11.2% 63.5\u00b10.4% 60.9\u00b10.3% 60.6\u00b10.5% 59.9\u00b10.4% mixture, fc3 62.3\u00b10.3% 63.4\u00b10.4% 63.1\u00b10.3% 62.5\u00b10.5% 63.0\u00b10.4% 58.3\u00b10.3% 60.2\u00b10.6% 60.2\u00b10.6% mixture, res3 69.5\u00b10.4% 70.3\u00b10.4% 69.9\u00b10.3% 69.7\u00b10.3% 69.8\u00b10.5% 63.2\u00b10.4% 61.5\u00b10.6% 63.1\u00b10.5% mixture, linear, margin 76.8\u00b10.3% 76.8\u00b10.5% 76.4\u00b10.7% 77.0\u00b10.5% 76.9\u00b10.8% 69.7\u00b10.7% 69.8\u00b10.6% 69.7\u00b11.0% mixture, fc2, margin 77.2\u00b11.1% 77.3\u00b10.6% 75.9\u00b10.4% 77.1\u00b11.2% 76.4\u00b10.4% 74.0\u00b10.4% 73.2\u00b10.4% 73.9\u00b10.5% mixture, fc3, margin 78.4\u00b10.3% 79.6\u00b10.2% 79.1\u00b10.4% 79.1\u00b10.3% 79.1\u00b10.6% 71.8\u00b10.6% 72.0\u00b10.4% 72.1\u00b10.5% mixture, res3, margin 82.5\u00b10.2% 83.7\u00b10.5% 82.5\u00b11.2% 83.2\u00b10.5% 82.7\u00b10.3% 74.7\u00b10.4% 73.9\u00b10.6% 73.4\u00b10.5% gauss, linear 78.2\u00b10.5% 78.0\u00b10.4% 76.2\u00b10.3% 78.4\u00b10.3% 78.0\u00b10.3% 73.9\u00b10.5% 72.3\u00b10.9% 73.4\u00b10.7% gauss, fc2 63.7\u00b11.0% 63.9\u00b10.8% 63.1\u00b10.7% 63.8\u00b10.9% 63.0\u00b10.4% 59.6\u00b10.2% 59.3\u00b10.6% 59.4\u00b10.7% gauss, fc3 68.4\u00b10.3% 75.1\u00b10.2% 76.1\u00b10.3% 72.2\u00b10.3% 73.6\u00b10.6% 56.8\u00b10.3% 65.1\u00b10.4% 63.6\u00b10.5% gauss, res3 67.9\u00b10.5% 68.9\u00b10.3% 67.0\u00b10.5% 67.9\u00b10.3% 67.5\u00b10.4% 58.3\u00b10.3% 59.7\u00b10.6% 59.6\u00b10.7% gauss, linear, margin 77.2\u00b10.3% 76.9\u00b10.3% 76.3\u00b10.4% 77.3\u00b10.4% 77.0\u00b10.3% 70.4\u00b10.9% 69.5\u00b10.5% 68.5\u00b10.8% gauss, fc2, margin 76.4\u00b10.8% 76.4\u00b10.4% 76.2\u00b10.3% 76.4\u00b10.3% 76.1\u00b10.3% 72.2\u00b10.4% 70.3\u00b10.7% 72.0\u00b10.5% gauss, fc3, margin 72.5\u00b10.2% 76.2\u00b10.3% 75.8\u00b10.5% 74.6\u00b10.3% 74.6\u00b10.4% 58.9\u00b10.8% 63.7\u00b11.0% 62.9\u00b10.5% gauss, res3, margin 82.5\u00b10.3% 83.7\u00b10.4% 82.4\u00b10.4% 82.7\u00b10.1% 82.6\u00b10.5% 72.5\u00b10.5% 72.2\u00b10.6% 73.7\u00b10.7% mixture, linear 80.2\u00b10.3% 80.0\u00b10.2% 78.4\u00b11.6% 80.1\u00b10.3% 78.8\u00b10.3% 74.5\u00b10.6% 73.9\u00b11.0% 74.7\u00b10.5% mixture, fc2 66.2\u00b10.5% 66.3\u00b10.4% 66.0\u00b10.4% 66.0\u00b10.3% 65.6\u00b10.5% 62.6\u00b10.5% 62.0\u00b10.6% 62.6\u00b10.6% mixture, fc3 65.1\u00b10.3% 72.2\u00b10.7% 72.8\u00b10.3% 67.7\u00b10.4% 69.8\u00b10.6% 52.1\u00b10.3% 61.8\u00b10.4% 60.0\u00b10.4% mixture, res3 67.7\u00b10.3% 68.9\u00b10.2% 67.7\u00b10.4% 67.6\u00b10.9% 67.9\u00b10.5% 59.8\u00b10.4% 59.5\u00b10.6% 59.8\u00b10.5% mixture, linear, margin 79.3\u00b10.3% 79.2\u00b10.3% 78.4\u00b10.3% 79.5\u00b10.2% 79.5\u00b10.3% 71.2\u00b10.7% 71.0\u00b10.7% 70.7\u00b11.2% mixture, fc2, margin 75.6\u00b10.2% 76.2\u00b10.4% 76.0\u00b10.3% 76.0\u00b10.9% 75.7\u00b10.3% 72.8\u00b10.4% 71.9\u00b10.5% 72.4\u00b10.7% mixture, fc3, margin 71.4\u00b10.3% 72.8\u00b10.5% 71.5\u00b10.6% 71.5\u00b10.4% 71.4\u00b10.4% 62.0\u00b10.3% 63.4\u00b10.8% 61.9\u00b10.4% mixture, res3, margin 81.4\u00b10.5% 83.1\u00b10.5% 81.7\u00b10.3% 81.6\u00b10.4% 82.3\u00b10.5% 71.3\u00b10.6% 71.0\u00b10.7% 71.3\u00b10.4% gauss, linear 73.2\u00b10.5% 71.1\u00b10.5% 67.3\u00b10.5% 69.8\u00b10.4% 68.2\u00b10.5% 67.3\u00b10.4% 66.0\u00b10.7% 67.5\u00b10.4% gauss, fc2 62.8\u00b10.5% 61.7\u00b11.0% 59.6\u00b10.5% 61.7\u00b10.6% 60.0\u00b10.7% 61.3\u00b10.6% 60.7\u00b10.3% 61.1\u00b10.4% gauss, fc3 65.7\u00b10.2% 66.2\u00b10.2% 63.9\u00b10.6% 65.6\u00b10.5% 65.0\u00b10.6% 60.5\u00b10.4% 61.4\u00b10.5% 60.9\u00b10.3% gauss, res3 66.4\u00b10.2% 65.6\u00b10.5% 63.4\u00b10.5% 64.8\u00b11.4% 62.6\u00b10.6% 62.3\u00b10.9% 61.7\u00b10.8% 62.5\u00b10.6% gauss, linear, margin 81.5\u00b10.3% 80.1\u00b10.4% 77.9\u00b10.3% 79.4\u00b10.4% 78.8\u00b10.5% 75.0\u00b10.4% 73.8\u00b10.6% 74.9\u00b10.6% gauss, fc2, margin 75.3\u00b10.3% 74.6\u00b10.5% 73.1\u00b10.3% 74.5\u00b11.1% 73.2\u00b10.4% 73.6\u00b10.2% 72.9\u00b10.6% 73.1\u00b10.6% gauss, fc3, margin 70.4\u00b10.2% 70.3\u00b10.3% 67.9\u00b10.5% 69.2\u00b10.3% 68.1\u00b10.7% 66.4\u00b10.3% 66.0\u00b10.5% 66.2\u00b10.5% gauss, res3, margin 72.8\u00b10.7% 72.3\u00b10.4% 70.1\u00b10.4% 71.0\u00b11.6% 69.4\u00b10.6% 68.4\u00b10.4% 67.3\u00b10.7% 68.6\u00b10.5% mixture, linear 72.3\u00b10.5% 72.6\u00b10.5% 68.2\u00b10.6% 71.2\u00b11.0% 70.3\u00b10.9% 69.4\u00b10.5% 67.4\u00b10.9% 68.0\u00b10.6% mixture, fc2 66.2\u00b11.1% 65.2\u00b11.2% 62.2\u00b11.4% 64.4\u00b12.0% 63.5\u00b10.4% 64.2\u00b10.3% 63.9\u00b10.4% 63.7\u00b10.6% mixture, fc3 61.1\u00b10.8% 59.9\u00b10.7% 59.0\u00b10.5% 59.3\u00b10.9% 57.9\u00b10.6% 57.9\u00b10.5% 58.1\u00b10.7% 57.5\u00b10.3% mixture, res3 63.2\u00b11.3% 62.2\u00b11.9% 60.3\u00b10.4% 61.3\u00b11.8% 60.3\u00b10.7% 59.2\u00b10.3% 60.0\u00b10.8% 59.8\u00b10.9% mixture, linear, margin 79.2\u00b10.5% 78.8\u00b10.4% 76.5\u00b11.6% 77.9\u00b10.6% 77.5\u00b10.6% 72.4\u00b10.6% 71.8\u00b10.9% 72.0\u00b10.8% mixture, fc2, margin 72.8\u00b10.5% 72.5\u00b10.3% 71.2\u00b10.6% 71.9\u00b10.5% 71.8\u00b10.4% 70.6\u00b10.5% 69.8\u00b10.5% 70.2\u00b10.4% mixture, fc3, margin 72.4\u00b10.5% 72.9\u00b10.6% 70.8\u00b10.7% 71.4\u00b10.4% 70.6\u00b10.5% 69.5\u00b10.5% 69.2\u00b10.6% 69.1\u00b10.6% mixture, res3, margin 75.5\u00b10.3% 75.8\u00b10.6% 73.9\u00b11.7% 74.2\u00b10.6% 73.6\u00b10.6% 72.0\u00b10.4% 71.7\u00b10.7% 71.3\u00b10.6% gauss, linear 71.8\u00b10.5% 70.2\u00b11.0% 66.0\u00b10.4% 68.6\u00b11.4% 65.8\u00b12.3% 65.1\u00b10.7% 64.0\u00b10.9% 65.3\u00b10.7% gauss, fc2 62.2\u00b10.3% 62.0\u00b10.5% 59.2\u00b10.6% 60.7\u00b11.1% 60.1\u00b11.7% 59.9\u00b10.5% 59.0\u00b10.4% 59.8\u00b10.4% gauss, fc3 64.6\u00b10.4% 69.3\u00b10.4% 71.3\u00b10.7% 66.9\u00b10.2% 68.3\u00b10.9% 54.7\u00b10.5% 62.7\u00b11.1% 60.0\u00b10.7% gauss, res3 66.5\u00b10.5% 67.5\u00b10.3% 66.1\u00b10.5% 63.8\u00b10.4% 63.3\u00b10.7% 59.2\u00b10.4% 58.6\u00b10.9% 59.7\u00b10.6% gauss, linear, margin 80.3\u00b10.6% 78.3\u00b11.2% 76.2\u00b10.4% 77.5\u00b10.4% 76.9\u00b10.2% 73.4\u00b10.8% 72.2\u00b10.6% 73.4\u00b11.0% gauss, fc2, margin 71.8\u00b10.2% 71.6\u00b10.3% 70.1\u00b11.2% 71.0\u00b11.2% 69.9\u00b11.7% 69.4\u00b10.6% 68.9\u00b10.5% 69.5\u00b10.5% gauss, fc3, margin 66.2\u00b10.2% 69.5\u00b10.5% 63.5\u00b10.5% 64.6\u00b10.4% 63.1\u00b10.5% 58.3\u00b10.5% 60.5\u00b11.0% 59.3\u00b10.5% gauss, res3, margin 73.4\u00b11.2% 73.6\u00b10.3% 73.5\u00b10.5% 70.1\u00b10.3% 69.1\u00b10.6% 67.6\u00b10.3% 68.1\u00b10.6% 68.4\u00b10.8% mixture, linear 72.3\u00b10.8% 70.8\u00b11.2% 69.2\u00b13.1% 70.0\u00b11.3% 68.9\u00b10.6% 67.9\u00b10.5% 66.3\u00b10.5% 67.4\u00b10.7% mixture, fc2 61.9\u00b10.3% 62.2\u00b11.4% 59.8\u00b12.3% 61.6\u00b10.7% 59.6\u00b10.8% 59.3\u00b10.7% 59.8\u00b10.4% 59.9\u00b10.7% mixture, fc3 71.4\u00b10.2% 74.9\u00b10.3% 77.2\u00b10.6% 72.6\u00b10.4% 73.6\u00b10.5% 61.7\u00b10.2% 69.0\u00b10.2% 67.3\u00b10.5% mixture, res3 64.9\u00b10.6% 67.6\u00b10.7% 67.0\u00b11.0% 63.9\u00b10.4% 62.2\u00b10.7% 60.4\u00b10.6% 60.6\u00b10.8% 59.8\u00b10.7% mixture, linear, margin 81.1\u00b11.1% 81.5\u00b10.4% 80.7\u00b12.0% 80.3\u00b10.3% 79.9\u00b10.4% 75.0\u00b11.2% 73.4\u00b11.2% 74.1\u00b11.1% mixture, fc2, margin 70.8\u00b11.8% 70.5\u00b10.6% 69.9\u00b10.6% 69.0\u00b10.6% 68.2\u00b10.6% 68.6\u00b10.7% 68.2\u00b10.6% 67.5\u00b10.7% mixture, fc3, margin 64.7\u00b10.3% 65.4\u00b10.7% 65.0\u00b10.6% 63.3\u00b11.5% 61.5\u00b10.6% 60.7\u00b10.7% 61.4\u00b10.6% 60.0\u00b10.7% mixture, res3, margin 71.6\u00b11.4% 73.3\u00b10.6% 71.2\u00b10.7% 70.6\u00b12.1% 69.3\u00b12.2% 68.1\u00b10.4% 67.8\u00b10.7% 67.6\u00b10.6%", "figure_data": "learner networksfc2 learner fc3 learner fc4 learner res3 learner res4 learner conv2 learner conv3 learner resconv3 learner5%) -0.6% 80.7% (80.0%) -0.7% 80.5% (79.7%) -0.8% 78.8% (78.4%) -0.4% 80.7% (80.1%) -0.6% 79.8% (79.1%) -0.8% 65.1% (64.5%) -0.5% 65.2% (64.9%) -0.4% 64.2% (64.5%) 0.3% 67.7% (64.7%) -3.0% 64.1% (63.5%) -0.6% 62.8% (62.8%) 0.0% 64.0% (63.7%) -0.3% 63.4% (64.2%) 0.8% 63.3% (62.7%) -0.6% 63.7% (64.4%) 0.7% 69.9%) -0.3% 78.9% (78.6%) -0.4% 78.7% (78.5%) -0.2% 76.7% (76.7%) 0.0% 78.9% (78.3%) -0.7% 78.6% (78.4%) -0.2% 66.without mixture, linear mixture, fc2 mixture, fc3 mixture, res3 gauss, linear gauss, fc2 label noise With 10% label noise rejection sampling uniform sampling rejection sampling uniform sampling fc2 learner fc3 learner fc4 learner res3 learner res4 learner without label noise rejection sampling uniform sampling without label noise rejection sampling uniform sampling fc2 fc3 fc4 res3 res4 conv2 conv3 2% (85.9%) 1.6% 84.9% (84.7%) -0.2% 100 With 10% label noise rejection sampling uniform sampling rejection Figure 11: synthetic data resconv3 gauss, linear label noise sampling uniform 79.without sampling"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_8", "figure_caption": "This simplifies our notations. Claim G.7 (function approximation, c.f. Claim D.9). Under the new Induction Hypothesis G.1, let us define Z", "figure_data": "Recall\u03a6(t) i,def =[ w(t) i,r , v i, ] + and \u03a6(t) idef =\u03a6(t) i,r\u2208[m]\u2208[2]and this time we have(t)"}], "formulas": [{"formula_id": "formula_0", "formula_text": "f (W, x) \u2248 f (W 0 , x) + W \u2212 W 0 , \u2207 W f (W 0 , x)", "formula_coordinates": [4.0, 196.76, 181.03, 214.23, 10.68]}, {"formula_id": "formula_1", "formula_text": "2 \uf8f1 \uf8f2 \uf8f3 both v 1 , v", "formula_coordinates": [6.0, 107.56, 450.83, 141.23, 55.18]}, {"formula_id": "formula_2", "formula_text": "P = k 2 , \u03b3 = 1 k 1.5 , \u00b5 = k 1.2 N , \u03c1 = k \u22120.01 , \u03c3 0 = 1/", "formula_coordinates": [9.0, 125.78, 249.16, 234.9, 16.79]}, {"formula_id": "formula_3", "formula_text": "\u2200j, j \u2208 [k], \u2200 , \u2208 [2]", "formula_coordinates": [9.0, 138.76, 457.73, 102.45, 9.57]}, {"formula_id": "formula_4", "formula_text": "V def = {v j,1 , v j,2 } j\u2208[k] the set of all features.", "formula_coordinates": [9.0, 191.93, 493.96, 222.33, 14.03]}, {"formula_id": "formula_5", "formula_text": "In the case of multi-view distribution D = D m , \u2022 p\u2208Pv(X) z p \u2208 [1, O(1)] when v \u2208 {v y,1 , v y,2 }, 5 \u2022 p\u2208Pv(X) z p \u2208 [\u2126(1), 0.4] when v \u2208 V(X) \\ {v y,1 , v y,2 }, 6 In the case of single-view distribution D = D s , \u2022 p\u2208Pv(X) z p \u2208 [1, O(1)] when v = v y, , \u2022 p\u2208Pv(X) z p \u2208 [\u03c1, O(\u03c1)] when v = v y,3\u2212 , \u2022 p\u2208Pv(X) z p \u2208 [\u2126(\u0393), \u0393] when v \u2208 V(X) \\ {v y,1 , v y,2 }. 5.", "formula_coordinates": [10.0, 80.3, 156.82, 314.31, 123.88]}, {"formula_id": "formula_6", "formula_text": "ReLU(z) def = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 0 if z \u2264 0; z q q q\u22121 if z \u2208 [0, ]; z \u2212 (1 \u2212 1 q ) if z \u2265", "formula_coordinates": [10.0, 206.38, 651.14, 193.07, 45.15]}, {"formula_id": "formula_7", "formula_text": "d for i \u2208 [k], r \u2208 [m], satisfying \u2200i \u2208 [k] : F i (X) = r\u2208[m] p\u2208[P ] ReLU( w i,r , x p )", "formula_coordinates": [11.0, 184.11, 158.39, 243.78, 35.86]}, {"formula_id": "formula_8", "formula_text": "L(F ) = 1 N i\u2208[N ] L(F ; X i , y i ) = E (X,y)\u223cZ [L(F ; X, y)] where L(F ; X, y) = \u2212 log e Fy (X) j\u2208[k] e F j (", "formula_coordinates": [11.0, 72.0, 307.16, 360.03, 43.71]}, {"formula_id": "formula_9", "formula_text": "(0) i,r \u223c N (0, \u03c3 2 0 I) for \u03c3 2 0 = 1 k", "formula_coordinates": [11.0, 79.81, 352.73, 124.37, 16.5]}, {"formula_id": "formula_10", "formula_text": "w (t+1) i,r \u2190 w (t) i,r \u2212 \u03b7 E (X,y)\u223cZ \u2207 w i,r L(F (t) ; X, y) (3.1)", "formula_coordinates": [11.0, 199.63, 389.06, 340.36, 16.0]}, {"formula_id": "formula_11", "formula_text": "def = e F i (X) j\u2208[k] e F j (", "formula_coordinates": [11.0, 269.37, 453.6, 58.36, 21.17]}, {"formula_id": "formula_12", "formula_text": "\u2200i \u2208 [k], r \u2208 [m] : \u2212 \u2207 w i,r L(F ; X, y) = (1 i =y \u2212 logit i (F, X))\u2207 w i,r F i (X) .", "formula_coordinates": [11.0, 126.94, 482.78, 358.13, 11.65]}, {"formula_id": "formula_13", "formula_text": "k > 0, every m \u2208 [polylog(k), k], every \u03b7 \u2264 1 poly(k)", "formula_coordinates": [11.0, 72.0, 577.6, 468.0, 26.45]}, {"formula_id": "formula_14", "formula_text": "w (t+1) i,r \u2190 (1 \u2212 \u03b7\u03bb)w (t)", "formula_coordinates": [11.0, 72.0, 665.34, 468.0, 24.01]}, {"formula_id": "formula_15", "formula_text": "Pr (X,y)\u223cD [\u2203i \u2208 [k] \\ {y} : F (T ) y (X) < F (T ) i (X)] \u2208 [0.49\u00b5, 0.51\u00b5] .", "formula_coordinates": [12.0, 172.56, 93.19, 289.55, 20.53]}, {"formula_id": "formula_16", "formula_text": "M \u2286 [k] \u00d7 [2] of cardinality |M| \u2208 [k(1 \u2212 o(1)), k].", "formula_coordinates": [12.0, 278.88, 140.4, 246.55, 9.57]}, {"formula_id": "formula_17", "formula_text": "Ensemble. Suppose {F [ ] } \u2208[K] are K = \u2126(1) independently trained models of F with m = polylog(k) for T = O poly(k)", "formula_coordinates": [12.0, 72.0, 254.35, 468.0, 28.08]}, {"formula_id": "formula_18", "formula_text": "G(X) = \u0398(1) K F [ ] (X) (4.1)", "formula_coordinates": [12.0, 245.36, 306.75, 294.64, 24.43]}, {"formula_id": "formula_19", "formula_text": "Pr (X,y)\u223cD [\u2203i \u2208 [k] \\ {y} : G y (X) < G i (X)] \u2264 0.001\u00b5 .", "formula_coordinates": [12.0, 196.64, 434.15, 241.41, 16.82]}, {"formula_id": "formula_20", "formula_text": "logit \u03c4 i (F, X) = e min{\u03c4 2 F i (X),1}/\u03c4 j\u2208[k] e min{\u03c4 2 F j (X),1}/\u03c4 (4.2)", "formula_coordinates": [12.0, 213.17, 637.62, 326.83, 31.48]}, {"formula_id": "formula_21", "formula_text": "w (t+1) i,r = w (t) i,r \u2212 \u03b7\u2207 w i,r L(F (t) ) \u2212 \u03b7 E (X,y)\u223cZ logit \u03c4 i (F (t) , X) \u2212 logit \u03c4 i (G, X) \u2212 \u2207 w i,r F (t) i (X) (4.3)", "formula_coordinates": [13.0, 85.1, 106.04, 454.9, 38.31]}, {"formula_id": "formula_22", "formula_text": "\u2022 (training accuracy is perfect): meaning for all (X, y) \u2208 Z, all i \u2208 [k] \\ {y}: F (t) y (X) > F (t) i (X).", "formula_coordinates": [13.0, 83.8, 310.12, 456.2, 16.0]}, {"formula_id": "formula_23", "formula_text": "Pr (X,y)\u223cD [\u2203i \u2208 [k] \\ {y} : F (t) y (X) < F (t) i (X)] \u2264 0.001\u00b5 .", "formula_coordinates": [13.0, 190.72, 349.58, 253.25, 20.54]}, {"formula_id": "formula_24", "formula_text": "w (t+1) i,r = w (t) i,r \u2212 \u03b7 E (X,y)\u223cZ logit \u03c4 i (F (t) , X) \u2212 logit \u03c4 i (G, X) \u2212 \u2207 w i,r F (t) i (X) (4.4)", "formula_coordinates": [13.0, 123.77, 601.97, 416.23, 24.18]}, {"formula_id": "formula_25", "formula_text": "p \u2208 [1, 1 + o(1)] for v \u2208 {v y,1 , v y,2 }.", "formula_coordinates": [14.0, 286.78, 89.06, 165.89, 10.63]}, {"formula_id": "formula_26", "formula_text": "(T +T ) y (X) > F (T +T ) i (X).", "formula_coordinates": [14.0, 420.09, 262.93, 121.83, 16.0]}, {"formula_id": "formula_27", "formula_text": "Pr (X,y)\u223cD [\u2203i \u2208 [k] \\ {y} : F (T +T ) y (X) < F (T +T ) i (X)] \u2264 0.26\u00b5", "formula_coordinates": [14.0, 179.32, 302.55, 276.04, 20.54]}, {"formula_id": "formula_28", "formula_text": "G = \u2208[L]", "formula_coordinates": [15.0, 364.54, 591.51, 54.21, 12.22]}, {"formula_id": "formula_29", "formula_text": "\u2200j, j \u2208 [k], \u2200 , \u2208 [2]", "formula_coordinates": [19.0, 138.76, 359.79, 102.45, 9.57]}, {"formula_id": "formula_30", "formula_text": "V def = {v j,1 , v j,2 } j\u2208[k]", "formula_coordinates": [19.0, 202.93, 396.03, 89.91, 14.03]}, {"formula_id": "formula_31", "formula_text": "x p = z p v + v \u2208V \u03b1 p,v v + \u03be p \u2208 R d", "formula_coordinates": [20.0, 234.62, 92.29, 164.95, 14.17]}, {"formula_id": "formula_32", "formula_text": "In the case of multi-view distribution D = D m , \u2022 p\u2208Pv(X) z p \u2208 [1, O(1)", "formula_coordinates": [20.0, 94.68, 143.65, 220.96, 34.62]}, {"formula_id": "formula_33", "formula_text": "\u2022 p\u2208Pv(X) z p \u2208 [1, O(1)] when v = v y, , \u2022 p\u2208Pv(X) z p \u2208 [\u03c1, O(\u03c1)] when v = v y,3\u2212 , comment: we consider \u03c1 = k \u22120.01 for simplicity \u2022 p\u2208Pv(X) z p \u2208 [\u2126(\u0393), \u0393] when v \u2208 V(X)\\{v y,1 , v y,2 }. we consider \u0393 = 1 polylog(k)", "formula_coordinates": [20.0, 106.48, 274.88, 433.52, 46.95]}, {"formula_id": "formula_34", "formula_text": "x p = v \u2208V \u03b1 p,v v + \u03be p", "formula_coordinates": [20.0, 262.07, 367.18, 110.03, 12.22]}, {"formula_id": "formula_35", "formula_text": "[a, b] for constants a, b is left-close, if there is a \u03b5 \u2264 1 polylog(k) such that Prz\u223cp[z \u2264 a + \u03b5] \u2265 1 polylog(k) , and is right-close if Prz\u223cp[z \u2265 b \u2212 \u03b5] \u2265 1 polylog(k)", "formula_coordinates": [20.0, 72.0, 598.31, 468.0, 25.02]}, {"formula_id": "formula_36", "formula_text": "\u039b (t) i def = max r\u2208[m], \u2208[2] [ w (t) i,r , v i, ] + and \u039b (t) i, def = max r\u2208[m] [ w (t) i,r , v i, ] + (C.1) Suppose m \u2264 poly(k). For every i \u2208 [k], let us denote M (0) i def = r \u2208 [m] \u2203 \u2208 [2] : w (0) i,r , v i, \u2265 \u039b (0) i, 1 \u2212 O 1 log k Intuition. If a neuron r \u2208 [m] is not in M (0)", "formula_coordinates": [28.0, 72.0, 190.58, 468.0, 90.71]}, {"formula_id": "formula_37", "formula_text": "M def = (i, * ) \u2208 [k] \u00d7 [2] \u039b (0) i, * \u2265 \u039b (0) i,3\u2212 * S i,3\u2212 * S i, * 1 q\u22122 1 + 1 log 2 (m) (C.2)", "formula_coordinates": [28.0, 145.5, 439.04, 394.5, 23.41]}, {"formula_id": "formula_38", "formula_text": "For every i \u2208 [k], suppose S i, \u2265 S i,3\u2212 , then Pr (i, 3 \u2212 ) \u2208 M \u2265 m \u2212O(1) . \u2022 For every i \u2208 [k], Pr (i, 1) \u2208 M or (i, 3) \u2208 M \u2265 1 \u2212 o(1).", "formula_coordinates": [28.0, 83.8, 658.6, 368.56, 29.81]}, {"formula_id": "formula_39", "formula_text": "w (t) i,r , x p = w (t) i,r , v i, z p \u00b1 o (\u03c3 0 ).", "formula_coordinates": [29.0, 259.05, 103.6, 152.01, 16.0]}, {"formula_id": "formula_40", "formula_text": ": | w (t) i,r , x p | \u2264 O(\u03c3 0 ).", "formula_coordinates": [29.0, 344.4, 125.4, 104.52, 16.0]}, {"formula_id": "formula_41", "formula_text": ": | w (t) i,r , x p | \u2264 O(\u03c3 0 \u03b3k). In addition, for every (X, y) \u2208 Z s , every i \u2208 [k], every r \u2208 [m], every \u2208 [2],", "formula_coordinates": [29.0, 72.0, 147.2, 364.95, 30.76]}, {"formula_id": "formula_42", "formula_text": "w (t) i,r , x p = w (t) i,r , v i, z p + w (t) i,r , \u03be p \u00b1 O(\u03c3 0 \u03b3k) (e) For every p \u2208 P v i, (X), if (i, 3 \u2212 ) \u2208 M we have: | w (t) i,r , x p | \u2264 O(\u03c3 0 ). (f ) For every p \u2208 P v i, (X), if r \u2208 [m] \\ M (0) i we have: | w (t) i,r , x p | \u2264 O(\u03c3 0 ). Moreover, we have for every i \u2208 [k], (g) \u039b (t) i \u2265 \u2126(\u03c3 0 ) and \u039b (t) i \u2264 O(1). (h) for every r \u2208 [m], every \u2208 [2], it holds that w (t) i,r , v i, \u2265 \u2212 O(\u03c3 0 ). (i) for every r \u2208 [m] \\ M (0) i , every \u2208 [2], it holds that w (t) i,r , v i, \u2264 O(\u03c3 0 ).", "formula_coordinates": [29.0, 72.0, 181.87, 403.95, 136.31]}, {"formula_id": "formula_43", "formula_text": "(t) i,1 or \u039b (t)", "formula_coordinates": [29.0, 72.0, 366.64, 468.0, 30.84]}, {"formula_id": "formula_44", "formula_text": "\u2022 = 1 polylog(k)", "formula_coordinates": [29.0, 83.8, 592.73, 68.84, 15.19]}, {"formula_id": "formula_45", "formula_text": "\u2022 \u0393 = 1 polylog(k)", "formula_coordinates": [29.0, 83.8, 613.32, 70.02, 15.19]}, {"formula_id": "formula_46", "formula_text": "0 = 1 k (recall w (0) i,r \u223c N (0, \u03c3 2 0 I) gives the initialization magnitude) \u2022 N s \u2264 o(k/\u03c1) and N s \u2264 k 2 s \u03c1 q\u22121 .", "formula_coordinates": [29.0, 83.8, 634.93, 456.2, 35.08]}, {"formula_id": "formula_47", "formula_text": "\u2022 \u03b3 \u2264 O( \u03c3 0 k ) and \u03b3 q \u2264 \u0398 1 k q\u22121 mP", "formula_coordinates": [29.0, 83.8, 674.43, 156.08, 15.53]}, {"formula_id": "formula_48", "formula_text": "\u221a d \u2265 \u03b7T \u2022 poly(k). \u2022 polylog(k) \u2264 m \u2264 O( s\u03c3 q 0 ).", "formula_coordinates": [30.0, 83.8, 66.21, 292.05, 42.89]}, {"formula_id": "formula_49", "formula_text": "q = 4, \u03c3 0 = 1 \u221a k , \u03c1 = 1 k 0.2 , m \u2264 k, s \u2264 k 0.2 , N s \u2264 k 1.2 , P \u2264 k 2 , \u03b3 \u2264 1 k 1.5 . Theorem D.2. Under Parameter D.1, for any m \u2208 \u2126(1), O( 1 s\u03c3 q 0", "formula_coordinates": [30.0, 77.38, 134.0, 432.67, 63.65]}, {"formula_id": "formula_50", "formula_text": "Gradient calculations. Recall logit i (F, X) def = e F i (X) j\u2208[k] e F j (X) . Recall also Fact D.3. Given data point (X, y) \u2208 D, for every i \u2208 [k], r \u2208 [m], \u2212\u2207 w i,r L(F ; X, y) = (1 \u2212 logit i (F, X)) p\u2208[P ] ReLU ( w i,r , x p )x p when i = y (D.1) \u2212\u2207 w i,r L(F ; X, y) = \u2212logit i (F, X) p\u2208[P ] ReLU ( w i,r , x p )x p when i = y (D.2)", "formula_coordinates": [30.0, 72.0, 262.16, 468.0, 111.16]}, {"formula_id": "formula_51", "formula_text": "\u03c3 0 k(mP ) 1/q ) , then \u2022 for every (X, y) \u2208 Z and every i \u2208 [k]: logit i (F (t) , X) = O e O(\u039b (t) i )m 0 e O(\u039b (t) i )m 0 +k \u2022 for every (X, y) \u2208 Z s and i \u2208 [k] \\ {y}: logit i (F (t) , X) = O 1 k 1 \u2212 logit y (F (t) , X) Proof of Claim D.4. Recall F (t) i (X) = r\u2208[m] p\u2208[P ] ReLU( w (t) i,r , x p ). For every r \u2208 M1", "formula_coordinates": [30.0, 72.0, 405.17, 479.6, 104.26]}, {"formula_id": "formula_53", "formula_text": "p\u2208[P ] ReLU( w (t) i,r , x p ) \u2264 O(\u03c3 q 0 ) \u2022 s + O((\u03c3 0 \u03b3k) q ) \u2022 P \u2264 1 mpolylog(k)", "formula_coordinates": [30.0, 149.99, 526.85, 310.83, 30.17]}, {"formula_id": "formula_54", "formula_text": "1 polylog(k) . For any r \u2208 M (0) i , we have p\u2208[P ] ReLU( w (t) i,r , x p ) \u2264 \u2208[2] w (t) i,r , v i, + \u2022 p\u2208P v i , (X) z p + o(\u03c3 0 ) + O(\u03c3 q 0 ) \u2022 s + O((\u03c3 0 \u03b3k) q ) \u2022 P \u2264 \u2208[2] w (t) i,r , v i, + \u2022 p\u2208P v i , (X) z p + O( 1 m 0 )", "formula_coordinates": [30.0, 81.52, 566.06, 447.45, 91.46]}, {"formula_id": "formula_55", "formula_text": "0 \u2264 F (t) i (X) \u2264 m 0 \u2022 \u039b (t) i \u2022 O(1) + O(1)", "formula_coordinates": [30.0, 217.08, 703.61, 177.84, 16.0]}, {"formula_id": "formula_56", "formula_text": "0 \u2264 F (t) i (X) \u2264 m 0 \u2022 \u039b (t) i \u2022 \u0393 + O(1) \u2264 O(1) (D.3)", "formula_coordinates": [31.0, 206.4, 92.59, 333.6, 16.0]}, {"formula_id": "formula_57", "formula_text": "V i,r, (X) def = 1 v i, \u2208V(X) p\u2208Pv i, (X)", "formula_coordinates": [31.0, 187.85, 159.85, 146.14, 28.31]}, {"formula_id": "formula_58", "formula_text": "E 1 := O(\u03c3 q\u22121 0 )\u03b3s E 2,i,r (X) := O(\u03b3(V i,r,1 (X) + V i,r,2 (X)", "formula_coordinates": [31.0, 133.62, 215.57, 334.02, 15.42]}, {"formula_id": "formula_59", "formula_text": "E 3 := O(\u03c3 0 \u03b3k) q\u22121 \u03b3P E 4,j, (X) := O(\u03c3 0 ) q\u22121 1 v j, \u2208V(X)", "formula_coordinates": [31.0, 133.62, 235.06, 307.06, 14.73]}, {"formula_id": "formula_60", "formula_text": "(a) \u2212\u2207 w i,r L F (t) ; X, y , v i, \u2265 V i,r, (X) \u2212 O(\u03c3 p P ) 1 \u2212 logit i (F (t) , X) (b) \u2212\u2207 w i,r L F (t) ; X, y , v i, \u2264 (V i,r, (X) + E 1 + E 3 ) 1 \u2212 logit i (F (t) , X) (c) For every j \u2208 [k] \\ {i}, \u2207 w i,r L(F (t) , X, y), v j, \u2264 1 \u2212 logit i F (t) , X (E 2,i,r (X) + E 1 + E 3 + E 4,j, (X))", "formula_coordinates": [31.0, 74.73, 313.29, 437.65, 73.63]}, {"formula_id": "formula_61", "formula_text": "\u2212\u2207 w i,r L (F ; X, y) , v j, = (1 \u2212 logit i (F, X))\u00d7 \uf8eb \uf8ec \uf8ed1 v j, \u2208V(X) p\u2208Pv j, (X) ReLU ( w i,r , x p )z p + p\u2208[P ] ReLU ( w i,r , x p )\u03b1 p,v j, \u00b1 p\u2208[P ] | v j, , \u03be p | \uf8f6 \uf8f7 \uf8f8", "formula_coordinates": [31.0, 88.93, 436.75, 441.11, 59.21]}, {"formula_id": "formula_62", "formula_text": "\u03c3 p = 1 \u221a dpolylog(k) and \u03b3 \u2264 1 k ) p\u2208[P ] | v j, , \u03be p | \u2264 O(\u03c3 p \u2022 s + \u03b3k \u221a d \u2022 P ) O(\u03c3 p \u2022 P )", "formula_coordinates": [31.0, 190.54, 504.76, 241.03, 54.44]}, {"formula_id": "formula_63", "formula_text": "ReLU ( w i,r , x p ) \u2208 [0, 1].", "formula_coordinates": [31.0, 305.48, 598.26, 116.69, 10.75]}, {"formula_id": "formula_64", "formula_text": "ReLU ( w (t) i,r , x p ) \u2208 0, O(\u03c3 q\u22121 0 ) .", "formula_coordinates": [31.0, 352.65, 616.93, 154.04, 16.0]}, {"formula_id": "formula_65", "formula_text": "ReLU ( w (t) i,r , x p ) \u2208 0, O((\u03c3 0 \u03b3k) q\u22121 )", "formula_coordinates": [31.0, 265.76, 640.02, 170.75, 16.0]}, {"formula_id": "formula_66", "formula_text": "p\u2208Pv i, (X) ReLU ( w i,r , x p ) \u2264 p\u2208Pv i, (X) ReLU ( w i,r , v i, + o(\u03c3 0 )) \u2264 p\u2208Pv i, (X) ReLU ( w i,r , v i, + o(\u03c3 0 ))z p \u2264 p\u2208Pv i, (X) ReLU ( w i,r , x p )z p + o(\u03c3 0 ) = V i,r, (X)", "formula_coordinates": [32.0, 105.86, 98.76, 425.98, 61.54]}, {"formula_id": "formula_67", "formula_text": "(X, y) \u2208 Z, every r \u2208 [m], every \u2208 [2], and i \u2208 [k] \\ {y}, we have (a) \u2212\u2207 w i,r L F (t) , X, y , v i, \u2265 \u2212logit i F (t) , X E 1 + E 3 + 1 v i, \u2208P(X) V i,r, (X) (b) For every j \u2208 [k]: \u2212\u2207 w i,r L F (t) , X, y , v j, \u2264 logit i F (t) , X O(\u03c3 p P ) (c) For every j \u2208 [k] \\ {i}: \u2212\u2207 w i,r L F (t) , X, y , v j, \u2265 \u2212logit i F (t) , X (E 1 + E 3 + E 4,j, (X)) Function approximations. Let us denote \u03a6 (t) i, def = r\u2208[m] [ w (t) i,r , v i, ] + and \u03a6 (t) i def = \u2208[2] \u03a6 (t) i, (D.4)", "formula_coordinates": [32.0, 72.0, 243.93, 468.0, 132.32]}, {"formula_id": "formula_68", "formula_text": "\u03c3 q 0 m ) and \u03b3 \u2264 O( 1 \u03c3 0 k(mP ) 1/q ). Let Z (t) i, (X) def = 1 v i, \u2208V(X)", "formula_coordinates": [32.0, 141.69, 417.47, 263.54, 19.3]}, {"formula_id": "formula_69", "formula_text": "F (t) i (X) = \u2208[2] \u03a6 (t) i, \u00d7 Z (t) i, (X) \u00b1 O(\u03c3 0 + \u03c3 q 0 sm + (\u03c3 0 \u03b3k) q \u2022 P m) = \u2208[2] \u03a6 (t) i, \u00d7 Z (t) i, (X) \u00b1 O( 1 polylog(k)", "formula_coordinates": [32.0, 162.93, 458.79, 308.82, 61.81]}, {"formula_id": "formula_70", "formula_text": "F (t) i (X) = \u2208[2] \u03a6 (t) i, \u00d7 Z (t) i, (X) \u00b1 O( 1 polylog(k) )", "formula_coordinates": [32.0, 200.33, 554.3, 234.02, 16.64]}, {"formula_id": "formula_71", "formula_text": "[k], suppose \u039b (t) i \u2264 O(1/m 0 ), then it satisfies \u039b (t+1) i = \u039b (t) i + \u0398 \u03b7 k ReLU (\u039b (t) i ) Proof of Claim D.10. Recall \u039b (t) i def = max r\u2208[m], \u2208[2] [ w (t) i,r , v i, ]", "formula_coordinates": [32.0, 72.0, 684.18, 315.0, 43.41]}, {"formula_id": "formula_72", "formula_text": "w (t+1) i,r , v i, \u2265 w (t) i,r , v i, + \u03b7 E (X,y)\u223cZ 1 y=i V i,r, (X) \u2212 O(\u03c3 p P ) 1 \u2212 logit i (F (t) , X) \u22121 y =i E 1 + E 3 + 1 v i, \u2208P(X) V i,r, (X) logit i F (t) , X (D.5) Recall V i,r, (X) = p\u2208Pv i, (X) ReLU ( w (t) i,r , x p )z p .", "formula_coordinates": [33.0, 72.0, 124.75, 468.0, 86.98]}, {"formula_id": "formula_73", "formula_text": "V i,r, (X) = p\u2208Pv i, (X) ReLU w (t) i,r , v i, z p \u00b1 o (\u03c3 0 ) z p \u2022 When i = y", "formula_coordinates": [33.0, 83.8, 231.71, 346.4, 47.71]}, {"formula_id": "formula_74", "formula_text": "|P v i, | \u2264 C p = O(1), this tells us V i,r, (X) \u2265 \u2126(1) \u2022 ReLU w (t) i,r , v i, .", "formula_coordinates": [33.0, 162.59, 286.77, 332.2, 16.0]}, {"formula_id": "formula_75", "formula_text": "z p \u2264 O(1) to derive that V i,r, (X) \u2264 O(1) \u2022 ReLU w (t) i,r , v i, . Together with logit i F (t) , X \u2264 O( 1 k ) from Claim D.4, we can derive that w (t+1) i,r , v i, \u2265 w (t) i,r , v i, +\u03b7 E (X,y)\u223cZ 1 y=i \u2022 \u2126(1) \u2212 O(1) \u2022 1 y =i 1 v i, \u2208P(X) 1 k \u2022 ReLU w (t) i,r , v i, \u2212\u03b7 O \u03c3 p P + E 1 + E 3 k", "formula_coordinates": [33.0, 72.0, 310.76, 468.0, 110.41]}, {"formula_id": "formula_76", "formula_text": ") | i = y = s k o(1), we derive that w (t+1) i,r , v i, \u2265 w (t) i,r , v i, + \u2126 \u03b7 k ReLU w (t)", "formula_coordinates": [33.0, 72.0, 427.94, 468.0, 51.91]}, {"formula_id": "formula_77", "formula_text": "w (t+1) i,r , v i, \u2264 w (t) i,r , v i, + \u03b7 E (X,y)\u223cZ 1 y=i (V i,r, (X) + E 1 + E 3 ) 1 \u2212 logit i (F (t) , X) \u22121 y =i O(\u03c3 p P ) logit i F (t) , X so a completely symmetric argument also shows w (t+1) i,r , v i, \u2264 w (t) i,r , v i, + O \u03b7 k ReLU w (t) i,r , v i,", "formula_coordinates": [33.0, 72.0, 501.72, 428.23, 90.73]}, {"formula_id": "formula_78", "formula_text": "\u039b \u2212 \u2205 def = \u0398 log k = \u0398(1) and \u039b + \u2205 def = \u0398 1 m 0 = \u0398(1)", "formula_coordinates": [33.0, 171.55, 654.31, 268.89, 25.5]}, {"formula_id": "formula_79", "formula_text": "(t) i \u2265 2\u039b \u2212 \u2205 , and T 0 def = \u0398 k \u03b7\u03c3 q\u22122 0 (noticing T 0 \u2265 T 0,i ) Then, \u2022 for every i \u2208 [k] and t \u2265 T 0 , it satisfies \u039b (t) i \u2265 \u039b + \u2205 \u2022 for every i \u2208 [k] and t \u2265 T 0,i , it satisfies \u039b (t) i \u2265 \u039b \u2212 \u2205 D.2.", "formula_coordinates": [33.0, 83.8, 685.02, 442.77, 39.78]}, {"formula_id": "formula_80", "formula_text": "T t=T 0 1 \u2212 logit y F (t) , X ReLU ( w y,r , x p ) \u2264 O N \u03b7 (b) for every (X, y) \u2208 Z s , T t=T 0 1 \u2212 logit y F (t) , X \u2264 O N \u03b7\u03c1 q\u22121", "formula_coordinates": [34.0, 75.28, 212.57, 366.42, 65.01]}, {"formula_id": "formula_81", "formula_text": "w (t+1) i,r , \u03be p \u2265 w (t) i,r , \u03be p \u2212 \u03b7 \u221a d + \u2126 \u03b7 N ReLU ( w (t) i,r , x p ) 1 \u2212 logit i (F (t) , X * ) \u2265 \u2022 \u2022 \u2022 \u2265 \u2212 \u03b7T \u221a d (b) For every (X, y) \u2208 Z s , every \u2208 [2], p\u2208Pv y, (X) w (t+1) y,r , \u03be p \u2265 p\u2208Pv y, (X) w (t) y,r , \u03be p \u2212 O(\u03b7) \u221a d + \u2126 \u03b7 N ReLU \u03c1 \u2022 w (t) y,r , v y, \u2212 O(\u03b7T / \u221a d + \u03c3 0 \u03b3k) 1 \u2212 logit y (F (t) , X)", "formula_coordinates": [34.0, 75.28, 375.83, 475.24, 115.37]}, {"formula_id": "formula_82", "formula_text": "w (t+1) i,r , \u03be p * = w (t) i,r , \u03be p * + \u03b7 E (X,y)\u223cZ 1 y=i \uf8eb \uf8ed p\u2208[P ] ReLU ( w (t) i,r , x p ) x p , \u03be p * \uf8f6 \uf8f8 1 \u2212 logit i (F (t) , X) \u22121 y =i \uf8eb \uf8ed p\u2208[P ] ReLU ( w (t) i,r , x p ) x p , \u03be p * \uf8f6 \uf8f8 logit i F (t) , X Note when X = X * , we have | x p , \u03be p * | \u2264 O(\u03c3 p ) \u2264 o 1 \u221a d", "formula_coordinates": [34.0, 72.0, 529.21, 459.3, 107.12]}, {"formula_id": "formula_83", "formula_text": "have | x p , \u03be p * | \u2264 O(\u03c3 p ) \u2264 o 1 \u221a d . Therefore, when i = y * , w (t+1) i,r , \u03be p * = w (t) i,r , \u03be p * + \u0398 \u03b7 N ReLU ( w (t) i,r , x p * ) 1 \u2212 logit i (F (t) , X * ) \u00b1 \u03b7 \u221a d (D.6)", "formula_coordinates": [34.0, 72.0, 637.49, 468.0, 46.84]}, {"formula_id": "formula_84", "formula_text": "(t) i,r , x p * = w (t) i,r , v i, z p * + w (t)", "formula_coordinates": [34.0, 122.84, 706.81, 140.07, 16.0]}, {"formula_id": "formula_85", "formula_text": "p * \u2208Pv i, (X * ) w (t+1) i,r , \u03be p * \u2265 p * \u2208Pv i, (X * ) w (t) i,r , \u03be p * \u2212 O(\u03b7) \u221a d + \u2126 \u03b7 N ReLU \u03c1 \u2022 w (t) i,r , v i, \u2212 O(\u03b7T / \u221a d + \u03c3 0 \u03b3k) 1 \u2212 logit i (F (t) , X * )", "formula_coordinates": [35.0, 72.0, 94.87, 468.08, 60.35]}, {"formula_id": "formula_86", "formula_text": "\u2200t \u2265 t 0 : w (t) i,r , \u03be p \u2265 polylog(k) but according to w (t) i,r , x p = w (t) i,r , v i, z p + w (t)", "formula_coordinates": [35.0, 72.0, 239.26, 311.43, 37.51]}, {"formula_id": "formula_87", "formula_text": "F (t) i (X) \u2265 w (t) i,r , x p * \u2212 O(1) \u2265 polylog(k)", "formula_coordinates": [35.0, 207.93, 301.82, 196.14, 16.0]}, {"formula_id": "formula_88", "formula_text": "F (t) j (X) \u2264 m 0 \u2022 \u039b (t) i \u2022 \u0393 \u2264 O(1)", "formula_coordinates": [35.0, 380.09, 325.33, 143.23, 16.0]}, {"formula_id": "formula_89", "formula_text": "t\u2265T 0 1 \u2212 logit i F (t) , X \u2265 \u2126 N \u03b7\u03c1 q\u22121 Using \u039b (t) i = max r\u2208[m], \u2208[2] [ w (t) i,r , v i, ] + \u2265 \u2126(1) from Claim D.11 and the definition of M (0) i , we have (r, )\u2208M (0) i \u00d7[2] 1 w (t) i,r ,v i, \u2265 \u2126(1) t\u2265T 0 1 \u2212 logit i F (t) , X \u2265 \u2126 N \u03b7\u03c1 q\u22121", "formula_coordinates": [35.0, 72.0, 390.39, 468.0, 105.92]}, {"formula_id": "formula_90", "formula_text": "(t) i,r , v i, \u2265 0) F (t) i (X) \u2265 w (t) i,r , x p * \u2212 O(1) = w (t) i,r , v i, z p * + w (t) i,r , \u03be p * \u00b1 O(\u03c3 0 \u03b3k) \u2212 O(1) \u2265 polylog(k) In contrast, one can derive (recall (D.3)) that F (t) j (X) \u2264 m 0 \u2022 \u039b (t) i \u2022 \u0393 \u2264 O(1) for every j = i. This means 1 \u2212 logit i F (t)", "formula_coordinates": [35.0, 72.0, 541.48, 468.0, 79.06]}, {"formula_id": "formula_91", "formula_text": "t\u2265T 0 (r, )\u2208M (0) i \u00d7[2] 1 w (t) i,r ,v i, \u2265 \u2126(1) 1 p\u2208Pv i, (X) w (t) i,r ,\u03bep \u2264polylog(k) 1 \u2212 logit i F (t) , X \u2265 \u2126 N \u03b7\u03c1 q\u22121", "formula_coordinates": [35.0, 77.21, 628.16, 447.86, 35.18]}, {"formula_id": "formula_92", "formula_text": "\u2200g \u2208 [4m 0 ] : t\u2208Tg (r, )\u2208M (0) i \u00d7[2] 1 w (t) i,r ,v i, \u2265 \u2126(1) 1 p\u2208Pv i, (X) w (t) i,r ,\u03bep \u2264polylog(k) 1 \u2212 logit i F (t) , X \u2265 \u2126 N \u03b7\u03c1 q\u22121 (D.7)", "formula_coordinates": [36.0, 76.8, 95.04, 463.2, 64.2]}, {"formula_id": "formula_93", "formula_text": "* 1 , * 1 ) \u2208 M (0) i \u00d7 [2] so that t\u2208T 1 1 w (t) i,r ,v i, \u2265 \u2126(1) 1 p\u2208Pv i, (X) w (t) i,r ,\u03bep \u2264polylog(k) 1 \u2212 logit i F (t) , X \u2265 \u2126 N \u03b7\u03c1 q\u22121", "formula_coordinates": [36.0, 107.29, 168.69, 427.82, 52.77]}, {"formula_id": "formula_94", "formula_text": "p\u2208Pv i, (X) w (t) i,r , \u03be p \u2265 \u2126 N \u03b7\u03c1 q\u22121 \u2022 \u2126 \u03b7 N \u03c1 q\u22121 > polylog(k)", "formula_coordinates": [36.0, 221.4, 249.42, 279.14, 32.87]}, {"formula_id": "formula_95", "formula_text": "* 2 , * 2 ) \u2208 M (0) i \u00d7 [2] so that t\u2208T 2 1 w (t) i,r ,v i, \u2265 \u2126(1) 1 p\u2208Pv i, (X) w (t) i,r ,\u03bep \u2264polylog(k) 1 \u2212 logit i F (t) , X \u2265 \u2126 N \u03b7\u03c1 q\u22121", "formula_coordinates": [36.0, 72.0, 290.9, 468.0, 63.07]}, {"formula_id": "formula_96", "formula_text": "p\u2208Pv i, (X) w (t) i,r , \u03be p > polylog(k)", "formula_coordinates": [36.0, 288.16, 393.92, 145.63, 29.24]}, {"formula_id": "formula_97", "formula_text": "(0) i \u00d7 [2] p\u2208Pv i, (X) w (t) i,r , \u03be p > polylog(k)", "formula_coordinates": [36.0, 243.67, 463.68, 205.44, 29.24]}, {"formula_id": "formula_98", "formula_text": "supposeN s \u2264 k 2 \u03c1 q\u22121 s , then T t=T 0 E (X,y)\u223cZm 1 \u2212 logit y F (t) , X \u2264 O k \u03b7 + O sN s \u03b7k\u03c1 q\u22121 \u2264 O k \u03b7", "formula_coordinates": [36.0, 126.82, 599.64, 341.28, 58.27]}, {"formula_id": "formula_99", "formula_text": "i\u2208[k] \u039b (t+1) i \u2265 i\u2208[k] \u039b (t) i + \u2126(\u03b7) \u00d7 E (X,y)\u223cZm 1 \u2212 logit y F (t) , X \u2212 \u03b7O s k N s N E (X,y)\u223cZs 1 \u2212 logit y F (t) , X Proof of Claim D.15. Recall \u039b (t) i def = max r\u2208[m], \u2208[2] [ w (t) i,r , v i, ] + .", "formula_coordinates": [37.0, 72.0, 92.89, 380.14, 82.69]}, {"formula_id": "formula_100", "formula_text": "(t) i,r , v i, \u2265 \u039b + \u2205 = \u0398(1)", "formula_coordinates": [37.0, 216.2, 177.12, 98.12, 16.0]}, {"formula_id": "formula_101", "formula_text": "w (t+1) i,r , v i, \u2265 w (t) i,r , v i, + \u03b7 E (X,y)\u223cZ 1 y=i V i,r, (X) \u2212 O(\u03c3 p P ) 1 \u2212 logit i (F (t) , X) \u22121 y =i E 1 + E 3 + 1 v i, \u2208P(X) V i,r, (X) logit i F (t) , X Recall V i,r, (X) = p\u2208Pv i, (X) ReLU ( w (t) i,r , x p )z p .", "formula_coordinates": [37.0, 72.0, 200.94, 436.55, 72.43]}, {"formula_id": "formula_102", "formula_text": "V i,r, (X) = p\u2208Pv i, (X) ReLU w (t) i,r , v i, z p \u00b1 o (\u03c3 0 ) z p Since w (t) i,r , v i, \u2265 \u039b + \u2205 = \u0398( 1 m 0 ) (see Claim D.11) and since |P v i, (X)| \u2264 O(1)", "formula_coordinates": [37.0, 72.0, 293.34, 404.27, 42.89]}, {"formula_id": "formula_103", "formula_text": "0.9 p\u2208Pv i, (X) z p \u2264 V i,r, (X) \u2264 p\u2208Pv i, (X) z p", "formula_coordinates": [37.0, 197.2, 359.16, 217.1, 14.92]}, {"formula_id": "formula_104", "formula_text": "w (t+1) i,r , v i, \u2265 w (t) i,r , v i, + \u03b7 E (X,y)\u223cZm 0.89 \u2022 1 y=i 1 \u2212 logit i (F (t) , X) \u2212 \u03b7 E (X,y)\u223cZm 1 y =i (E 1 + E 3 + 0.41 v i, \u2208P(X) )logit i F (t) , X \u2212 O \u03b7N s N E (X,y)\u223cZs 1 y=i \u2022 O(\u03c3 p P ) 1 \u2212 logit y F (t) , X \u2212 O \u03b7N s kN E (X,y)\u223cZs 1 y =i E 1 + E 3 + 1 v i, \u2208P(X) 1 \u2212 logit y F (t) , X (D.8)", "formula_coordinates": [37.0, 76.3, 484.0, 463.7, 121.48]}, {"formula_id": "formula_105", "formula_text": "w (t+1) i,r , v i, \u2265 w (t) i,r , v i, + \u03b7 E (X,y)\u223cZm 0.89 \u2022 1 y=i 1 \u2212 logit i (F (t) , X) \u2212 0.41 \u2022 1 y =i logit i F (t) , X \u2212 O \u03b7N s kN E (X,y)\u223cZs k1 y=i \u2022 O(\u03c3 p P ) + 1 y =i E 1 + E 3 + 1 v i, \u2208P(X) 1 \u2212 logit y F (t) , X", "formula_coordinates": [37.0, 76.24, 672.29, 480.19, 50.49]}, {"formula_id": "formula_106", "formula_text": "Claim D.16 (multi-view individual error). For every t \u2265 0, every (X, y) \u2208 Z m , 1 \u2212 logit y F (t) , X \u2264 O k 4 s 2 \u2022 E (X,y)\u223cZm 1 \u2212 logit y F (t) , X", "formula_coordinates": [38.0, 72.0, 174.5, 382.02, 43.26]}, {"formula_id": "formula_107", "formula_text": "(t) i \u2212 \u03a6 (t) j \u2264 \u2212\u2126(log k) for every pair i, j \u2208 [k].", "formula_coordinates": [38.0, 72.0, 241.15, 468.0, 32.93]}, {"formula_id": "formula_108", "formula_text": "i \u2208 [k] \\ {y} such that, \u2208[2] p\u2208Pv i, (X) z p \u2265 0.8 \u2212 1 100 log(k) , \u2208[2] p\u2208Pv y, (X) z p \u2264 2 + 1 100 log(k) Now, suppose 1 \u2212 logit y F (t) , X = \u03be(X), then using min{1, \u03b2} \u2264 2 1 \u2212 1 1+\u03b2 , we have min 1, i\u2208[k]\\{y} e F (t) i (X)\u2212F (t) y (X) \u2264 2\u03be(X)", "formula_coordinates": [38.0, 88.94, 284.35, 451.07, 97.35]}, {"formula_id": "formula_109", "formula_text": "i \u2212\u03a6 (t) y \u2264 4\u03be(X)", "formula_coordinates": [38.0, 317.41, 409.27, 82.34, 14.4]}, {"formula_id": "formula_110", "formula_text": "E (X,y)\u223cZm min 1, i\u2208H(X) e 0.4\u03a6 (t) i \u2212\u03a6 (t) y \u2264 4\u03c8 =\u21d2 E (X,y)\u223cZm i\u2208H(X) min 1 k , e 0.4\u03a6 (t) i \u2212\u03a6 (t) y \u2264 4\u03c8", "formula_coordinates": [38.0, 179.18, 457.14, 256.27, 41.35]}, {"formula_id": "formula_111", "formula_text": "E (X,y)\u223cZm j\u2208[k] 1 j=y i\u2208[k] 1 i\u2208H(X) min 1 k , e 0.4\u03a6 (t) i \u2212\u03a6 (t) j \u2264 4\u03c8 =\u21d2 j\u2208[k] i\u2208[k] 1 i =y E (X,y)\u223cZm 1 j=y 1 i\u2208H(X) min 1 k , e 0.4\u03a6 (t) i \u2212\u03a6 (t) j \u2264 4\u03c8", "formula_coordinates": [38.0, 127.51, 524.3, 359.62, 46.67]}, {"formula_id": "formula_112", "formula_text": "is at least \u2126 1 k \u2022 s 2 k 2 . This implies j\u2208[k] i\u2208[k]\\i min 1 k , e 0.4\u03a6 (t) i \u2212\u03a6 (t) j \u2264 O k 3 s 2 \u03c8 (D.9) Finally, using 1 \u2212 1 1+\u03b2 \u2264 min{1, \u03b2}, it is easy to see for every (X, y) \u2208 Z m 1 \u2212 logit y F (t) , X = min 1, i\u2208[k]\\{y} 2e 0.4\u03a6 (t) i \u2212\u03a6 (t) y \u2264 k \u2022 i\u2208[k]\\{y} min 1 k , e 0.4\u03a6 (t) i \u2212\u03a6 (t) y \u2264 O k 4 s 2 \u03c8", "formula_coordinates": [38.0, 72.0, 591.41, 468.0, 106.68]}, {"formula_id": "formula_113", "formula_text": "1 \u2212 logit y F (t) , X = min 1, i\u2208[k]\\{y} 2e 0.4\u03a6 (t) i \u2212\u03a6 (t) y", "formula_coordinates": [39.0, 180.23, 92.61, 243.27, 28.17]}, {"formula_id": "formula_114", "formula_text": "(t) i \u2212 \u03a6 (t) j \u2264 \u2212\u2126(log k) for every pair i = j. Using the non-negativity of \u03a6 (t)", "formula_coordinates": [39.0, 93.82, 155.71, 376.14, 16.0]}, {"formula_id": "formula_115", "formula_text": "\u03a5 = \u0398( 1 k 0.2 ) is a parameter. Then, for every i \u2208 [k] (a) T 0 t=T 0,i E (X,y)\u223cZm 1 y=i 1 \u2212 logit y F (t) , X \u2264 O s k T 0 \u03a5 + O 1 \u03b7 (b) for every t \u2208 [T 0,i , T 0 ], every j \u2208 [k] \\ {i}, every \u2208 [2], E (X,y)\u223cZm 1 y =i logit i F (t) , X \u2264 O( 1 k ) E (X,y)\u223cZm 1 y =i 1 v j, \u2208P(X) logit i F (t) , X \u2264 O( s k 2 )", "formula_coordinates": [39.0, 74.73, 294.17, 398.77, 129.23]}, {"formula_id": "formula_116", "formula_text": "\u03a6 (t) i def = r\u2208[m], \u2208[2] [ w (t) i,r , v i, ] + from (D.4", "formula_coordinates": [39.0, 327.56, 449.8, 202.63, 16.0]}, {"formula_id": "formula_117", "formula_text": "\u2200t \u2264 T 1 , \u2200i \u2208 [k] : e 0.4\u03a6 (t) i \u2264 k\u03a5 . (Note when \u03a5 \u2264 O(k \u22120.2 ) we have T 0 \u2264 T 1 .) Proof of Claim D.18. Recall from Induction Hypothesis C.3i that for those r \u2208 [m] \\ M (0) i and \u2208 [2], it satisfies [ w (t) i,r , v i, ] + \u2264 O(\u03c3 0 )", "formula_coordinates": [39.0, 72.0, 499.69, 468.0, 73.32]}, {"formula_id": "formula_118", "formula_text": "\u03a6 (t) = max i\u2208[k] (r, )\u2208M (0) i \u00d7[2] [ w (t) i,r , v i, ] + Let i be this argmax in \u03a6 (t) . For every (r, ) \u2208 M (0) i \u00d7 [2]", "formula_coordinates": [39.0, 72.0, 590.93, 334.2, 41.86]}, {"formula_id": "formula_119", "formula_text": "w (t+1) i,r , v i, \u2264 w (t) i,r , v i, + \u03b7 E (X,y)\u223cZ 1 y=i (V i,r, (X) + E 1 + E 3 ) 1 \u2212 logit i (F (t) , X) +1 y =i O(\u03c3 p P ) logit i F (t) , X (D.10)", "formula_coordinates": [39.0, 109.5, 639.13, 430.51, 42.77]}, {"formula_id": "formula_120", "formula_text": "V i,r, (X) = p\u2208Pv i, (X) ReLU ( w i,r , x p )z p \u2264 p\u2208Pv i, (X) z p \u2264 O(1)", "formula_coordinates": [39.0, 147.27, 710.43, 317.46, 15.04]}, {"formula_id": "formula_121", "formula_text": "w (t+1) i,r , v i, \u2264 w (t) i,r , v i, + O(\u03b7) E (X,y)\u223cZ 1 y=i 1 \u2212 logit y (F (t) , X) + O(\u03c3 p P )", "formula_coordinates": [40.0, 118.02, 92.44, 373.69, 20.53]}, {"formula_id": "formula_122", "formula_text": "(t) y (X) \u2265 \u03a6 (t) y \u2212 1 polylog(k) and for j \u2208 [k] \\ {y}, \u2022 W.p. 1 \u2212 (1 \u2212 s k ) 2", "formula_coordinates": [40.0, 83.8, 136.2, 435.59, 37.96]}, {"formula_id": "formula_123", "formula_text": "F (t) j (X) \u2264 1 polylog(k) ; \u2022 W.p. (1 \u2212 s k ) 2", "formula_coordinates": [40.0, 83.8, 157.65, 384.47, 38.64]}, {"formula_id": "formula_124", "formula_text": "F (t) j (X) \u2264 0.4\u03a6 (t) j + 1 polylog(k) ;", "formula_coordinates": [40.0, 401.18, 179.79, 138.83, 16.64]}, {"formula_id": "formula_125", "formula_text": "j (X) e F (t) y (X)", "formula_coordinates": [40.0, 357.68, 204.67, 42.76, 27.41]}, {"formula_id": "formula_126", "formula_text": "E (X,y)\u223cZm 1 i=y 1 \u2212 logit y (F (t) , X) \u2264 1 k \u2022 O se 0.4 \u03a6 (t) + k e \u03a6 (t)", "formula_coordinates": [40.0, 161.33, 237.42, 279.16, 30.07]}, {"formula_id": "formula_127", "formula_text": "(0) i \u00d7 [2] with |M (0) i | \u2264 m 0 \u2264 O(1), we have \u03a6 (t+1) \u2264 \u03a6 (t) + \u03b7 1 k O se 0.4 \u03a6 (t) + k e \u03a6 (t) + N s N", "formula_coordinates": [40.0, 203.97, 275.83, 225.06, 51.41]}, {"formula_id": "formula_128", "formula_text": "\u03a6 (t+1) \u2264 \u03a6 (t) + \u03b7 O 1 k 2.5 \u03a5 2.5", "formula_coordinates": [40.0, 235.13, 356.19, 133.53, 24.43]}, {"formula_id": "formula_129", "formula_text": "\u039b (t) i \u2265 \u039b \u2205 ), 17 \u039b (t+1) i \u2265 \u039b (t) i + \u03b7 E (X,y)\u223cZm \u2126(1) \u2022 1 y=i 1 \u2212 logit i (F (t) , X) \u2212 \u03b7 E (X,y)\u223cZm 1 y =i (E 1 + E 3 + 0.41 v i,1 or v i,2 \u2208P(X) )logit i F (t) , X \u2212 O \u03b7N s N E (X,y)\u223cZs 1 y=i \u2022 O(\u03c3 p P ) 1 \u2212 logit y F (t) , X \u2212 O \u03b7N s kN E (X,y)\u223cZs 1 y =i E 1 + E 3 + 1 v i,1 or v i,2 \u2208P(X) 1 \u2212 logit y F (t) , X", "formula_coordinates": [40.0, 86.93, 419.4, 417.3, 129.41]}, {"formula_id": "formula_130", "formula_text": "{v i,1 , v i,2 } is in P(X), then F (t) i (X) \u2264 0.4\u03a6 (t) i + 1 polylog(k) . Therefore, E (X,y)\u223cZm 1 y =i 1 v i,1 or v i,2 \u2208P(X) logit i F (t) , X \u2264 E (X,y)\u223cZm 1 y =i 1 v i,1 or v i,2 \u2208P(X) 1 1 + j\u2208[k] e F (t) j (X)\u22120.4\u03a6 (t) i \u2264 E (X,y)\u223cZm 1 y =i 1 v i,1 or v i,2 \u2208P(X) O(\u03a5) \u2264 O( s\u03a5 k ) (D.11)", "formula_coordinates": [40.0, 72.0, 556.84, 468.0, 123.24]}, {"formula_id": "formula_131", "formula_text": "E (X,y)\u223cZs k1 y=i \u2022 O(\u03c3 p P ) + 1 y =i E 1 + E 3 + 1 {v i,1 ,v i,2 }\u2208P(X) 1 \u2212 logit y F (t) , X \u2264 O( s k )", "formula_coordinates": [41.0, 78.57, 102.93, 454.86, 24.43]}, {"formula_id": "formula_132", "formula_text": "\u039b (t+1) i \u2265 \u039b (t) i + \u2126(\u03b7) E (X,y)\u223cZm 1 y=i 1 \u2212 logit i (F (t) , X) \u2212 O s\u03a5 k + s k 2 N s N Using \u039b (t) i \u2264 O(1)", "formula_coordinates": [41.0, 72.0, 152.29, 410.66, 49.21]}, {"formula_id": "formula_133", "formula_text": "logit i F (t) , X \u2264 O( 1 k )", "formula_coordinates": [41.0, 72.0, 214.06, 114.85, 15.05]}, {"formula_id": "formula_134", "formula_text": "x t+1 \u2190 x t + \u03b7C t x q\u22121 t", "formula_coordinates": [41.0, 127.76, 317.05, 97.34, 15.19]}, {"formula_id": "formula_135", "formula_text": "\u2022 x t+1 \u2265 x t + \u03b7C t x q\u22121 t", "formula_coordinates": [41.0, 83.8, 383.05, 107.44, 15.19]}, {"formula_id": "formula_136", "formula_text": "\u2022 y t+1 \u2264 y t + \u03b7SC t y q\u22121 t", "formula_coordinates": [41.0, 83.8, 401.08, 112.49, 15.19]}, {"formula_id": "formula_137", "formula_text": "Suppose x 0 \u2265 y 0 S 1 q\u22122 (1 + 1 polylog(k)", "formula_coordinates": [41.0, 72.0, 418.32, 167.16, 18.25]}, {"formula_id": "formula_138", "formula_text": "y Tx \u2264 O(y 0 \u2022 polylog(k))", "formula_coordinates": [41.0, 249.87, 454.64, 112.27, 10.81]}, {"formula_id": "formula_139", "formula_text": "t\u22650,xt\u2264A \u03b7C t \u2265 \u03b4(1 + \u03b4) \u22121 (1 + \u03b4) q\u22122 \u2212 1 1 \u2212 (1 + \u03b4)x 0 A q\u22122 \u2212 O(\u03b7A q\u22121 ) x 0 log A x 0 log(1 + \u03b4) \u2022 1 x q\u22122 0 t\u22650,xt\u2264A \u03b7C t \u2264 (1 + \u03b4) q\u22122 (q \u2212 2) + O(\u03b7A q\u22121 ) x 0 log A x 0 log(1 + \u03b4) \u2022 1 x q\u22122 0", "formula_coordinates": [41.0, 101.73, 533.3, 406.84, 79.68]}, {"formula_id": "formula_140", "formula_text": "t\u2208[Tg,T g+1 ) \u03b7C t [(1 + \u03b4) g x 0 ] (q\u22121) \u2264 x T g+1 \u2212 x Tg \u2264 \u03b4(1 + \u03b4) g x 0 + O(\u03b7A q\u22121 ) t\u2208[Tg,T g+1 ) \u03b7C t [(1 + \u03b4) g+1 x 0 ] (q\u22121) \u2265 x T g+1 \u2212 x Tg \u2265 \u03b4(1 + \u03b4) g x 0 \u2212 O(\u03b7A q\u22121 )", "formula_coordinates": [41.0, 138.16, 682.44, 347.19, 34.86]}, {"formula_id": "formula_141", "formula_text": "t\u2208[Tg,T g+1 ) \u03b7C t \u2264 \u03b4 (1 + \u03b4) g(q\u22122) 1 x q\u22122 0 + O(\u03b7A q\u22121 ) x q\u22121 0 t\u2208[Tg,T g+1 ) \u03b7C t \u2265 \u03b4 (1 + \u03b4) g(q\u22122) (1 + \u03b4) q\u22121 1 x q\u22122 0 \u2212 O(\u03b7A q\u22121 ) x q\u22121 0 Recall b is the smallest integer such that (1 + \u03b4) b x 0 \u2265 A, so we can calculate t\u22650,xt\u2264A \u03b7C t \u2264 b\u22121 g=0 \u03b4 (1 + \u03b4) g(q\u22122) 1 x q\u22122 0 + O(\u03b7A q\u22121 ) x q\u22121 0 b = \u03b4 1 \u2212 1 (1+\u03b4) q\u22122 1 x q\u22122 0 + O(\u03b7A q\u22121 ) x q\u22121 0 b = \u03b4(1 + \u03b4) q\u22122 (1 + \u03b4) q\u22122 \u2212 1 1 x q\u22122 0 + O(\u03b7A q\u22121 ) x q\u22121 0 b \u2264 (1 + \u03b4) q\u22122 (q \u2212 2) 1 x q\u22122 0 + O(\u03b7A q\u22121 ) x q\u22121 0 b t\u22650,xt\u2264A \u03b7C t \u2265 b\u22122 q=0 \u03b4 (1 + \u03b4) g(q\u22122) (1 + \u03b4) q\u22121 1 x q\u22122 0 \u2212 O(\u03b7A q\u22121 ) x q\u22121 0 b \u2265 \u03b4(1 + \u03b4) \u22121 1 \u2212 1 (1+\u03b4) (q\u22122)(b\u22121) (1 + \u03b4) q\u22122 \u2212 1 1 x q\u22122 0 \u2212 O(\u03b7A q\u22121 ) x q\u22121 0 b \u2265 \u03b4(1 + \u03b4) \u22121 1 \u2212 (1+\u03b4)x 0 A q\u22122 (1 + \u03b4) q\u22122 \u2212 1 1 x q\u22122 0 \u2212 O(\u03b7A q\u22121 ) x q\u22121 0 b Proof of Lemma D.19.", "formula_coordinates": [42.0, 72.0, 91.75, 436.25, 303.98]}, {"formula_id": "formula_142", "formula_text": "Tx t=0 \u03b7C t \u2264 (1 + \u03b4) q\u22122 (q \u2212 2) + O(\u03b7A q\u22121 ) x 0 log A x 0 log(1 + \u03b4) \u2022 1 x q\u22122 0 \u2264 1 + O(\u03b4) (q \u2212 2)x q\u22122 0 + O \u03b7 log(1/x 0 ) \u03b4x q\u22121 0 Ty t=0 \u03b7C t = Ty t=0 \u03b7SC t \u2265 \u03b4(1 + \u03b4) \u22121 (1 + \u03b4) q\u22122 \u2212 1 1 \u2212 (1 + \u03b4)y 0 A q\u22122 \u2212 O(\u03b7(A ) q\u22121 ) y 0 log A y 0 log(1 + \u03b4) \u2022 1 y q\u22122 0 \u2265 1 \u2212 O(\u03b4 + 1 polylog(k) ) (q \u2212 2)y q\u22122 0 \u2212 O \u03b7 \u03b4", "formula_coordinates": [42.0, 80.17, 446.16, 450.9, 146.45]}, {"formula_id": "formula_143", "formula_text": "x 0 log(1/x 0 )polylog(k) , together with the assumption x 0 \u2265 y 0 S 1 q\u22122 (1 + 1 polylog(k)", "formula_coordinates": [42.0, 72.0, 597.54, 468.0, 34.85]}, {"formula_id": "formula_144", "formula_text": "D.4.1 Lambda Lemma Recall \u039b (t) i def = max r\u2208[m], \u2208[2] [ w (t) i,r , v i, ] + . Our first lemma shows that \u039b (t) i cannot go above O(1).", "formula_coordinates": [43.0, 72.0, 75.48, 460.18, 32.88]}, {"formula_id": "formula_145", "formula_text": "\u03a6 (t) i, def = r\u2208[m] [ w (t) i,r , v i, ] + , we have \u2200i \u2208 [k], \u2200 \u2208 [2] : \u03a6 (t) i, \u2264 O(1) This implies \u039b (t) i \u2264 O(1) as well.", "formula_coordinates": [43.0, 72.0, 129.72, 316.24, 63.69]}, {"formula_id": "formula_146", "formula_text": "\u2022 For those r \u2208 [m] \\ M (0) i and \u2208 [2], recall Induction Hypothesis C.3i says [ w (t) i,r , v i, ]", "formula_coordinates": [43.0, 83.8, 217.61, 436.13, 16.0]}, {"formula_id": "formula_147", "formula_text": "(t) i, \u2264 O(1) for \u03a6 (t) i, def = r\u2208M (0) i w (t) i,r , v i, + = \u03a6 (t) i, \u00b1 1 poly(k)", "formula_coordinates": [43.0, 198.85, 255.5, 336.61, 44.47]}, {"formula_id": "formula_148", "formula_text": "w (t+1) i,r , v i, = w (t) i,r , v i, + \u03b7 E (X,y)\u223cZ \u2212\u2207 w i,r L(F (t) ; X, y), v i,", "formula_coordinates": [43.0, 158.46, 323.0, 286.57, 20.54]}, {"formula_id": "formula_149", "formula_text": "(t) i,r, \u2208 [0, 1] such that w (t+1) i,r , v i, + = w (t) i,r , v i, + + \u03b7\u2206 (t) i,r, E (X,y)\u223cZ \u2212\u2207 w i,r L(F (t) ; X, y), v i,", "formula_coordinates": [43.0, 134.72, 352.58, 338.6, 44.31]}, {"formula_id": "formula_150", "formula_text": "Z s,i, def = (X, y) \u2208 Z s | y = i \u2227 (X) = 3 \u2212", "formula_coordinates": [43.0, 198.93, 434.4, 199.89, 13.59]}, {"formula_id": "formula_151", "formula_text": "\u2022 define A (0) i, def = r\u2208M (0) i w (0) i,r , v i, +and B (0)", "formula_coordinates": [43.0, 83.8, 470.43, 229.46, 20.34]}, {"formula_id": "formula_152", "formula_text": "A (t+1) i, def = A (t) i, + \u03b7 r\u2208M (0) i \u2206 (t) i,r, E (X,y)\u223cZ 1 (X,y) \u2208Z s,i, \u2022 \u2212\u2207 w i,r L(F (t) ; X, y), v i, B (t+1) i, def = B (t) i, + \u03b7 r\u2208M (0) i \u2206 (t) i,r, E (X,y)\u223cZ 1 (X,y)\u2208Z s,i, \u2022 \u2212\u2207 w i,r L(F (t) ; X, y), v i,", "formula_coordinates": [43.0, 132.28, 512.29, 357.36, 67.54]}, {"formula_id": "formula_153", "formula_text": "(t) i, = A (t) i, + B (t) i, .", "formula_coordinates": [43.0, 217.18, 591.75, 78.34, 16.99]}, {"formula_id": "formula_154", "formula_text": "B (t+1) i, = B (t) i, + \u03b7 r\u2208M (0) i \u2206 (t) i,r, E (X,y)\u223cZ 1 (X,y)\u2208Z s,i, \u2022 (V i,r, (X) \u00b1 (E 1 + E 3 )) 1 \u2212 logit i (F (t) , X)", "formula_coordinates": [43.0, 76.51, 633.65, 445.49, 31.54]}, {"formula_id": "formula_155", "formula_text": "0 \u2264 V i,r, (X) = p\u2208Pv i, (X) ReLU ( w i,r , x p )z p \u2264 O(\u03c1) \u2022 p\u2208Pv i, (X) ReLU ( w i,r , x p )", "formula_coordinates": [43.0, 118.19, 698.39, 375.63, 25.62]}, {"formula_id": "formula_156", "formula_text": "|B (t+1) i, \u2212 B (t) i, | \u2264 O \u03b7\u03c1N s N r\u2208M (0) i E (X,y)\u223cZs 1 (X,y)\u2208Z s,i, 1 \u2212 logit i (F (t) , X) E 1 + E 3 + p\u2208Pv i, (X)", "formula_coordinates": [44.0, 75.03, 92.59, 393.45, 55.44]}, {"formula_id": "formula_157", "formula_text": "\u2200t \u2265 0 : |B (t) i, | \u2264 O \u03c1N s k < 1 polylog(k)", "formula_coordinates": [44.0, 208.32, 185.93, 194.17, 24.43]}, {"formula_id": "formula_158", "formula_text": "(t) i, = A (t) i, \u00b1 1 polylog(k) (because |B (t) i, |, |\u03a6 (t) i, \u2212 \u03a6 (t) i, | \u2264 1 polylog(k)", "formula_coordinates": [44.0, 72.0, 222.47, 468.0, 36.0]}, {"formula_id": "formula_159", "formula_text": "\u03a6 (t) def = max i\u2208[k], \u2208[2] \u03a6 (t) i,", "formula_coordinates": [44.0, 259.87, 266.42, 91.76, 20.53]}, {"formula_id": "formula_160", "formula_text": "(i, ) = arg max i\u2208[k], \u2208[2] A (t) i,", "formula_coordinates": [44.0, 233.37, 312.67, 138.39, 16.26]}, {"formula_id": "formula_161", "formula_text": "A (t+1) i, \u2264 A (t) i, + O(\u03b7) E (X,y)\u223cZ 1 y=i 1 (X,y) \u2208Z s,i, 1 \u2212 logit y (F (t) , X) + O(\u03c3 p P )", "formula_coordinates": [44.0, 114.65, 355.04, 376.18, 20.54]}, {"formula_id": "formula_163", "formula_text": "F (t) j (X) = \u2208[2] \u03a6 (t) j, \u00d7 1 v j, \u2208V(X) p\u2208Pv j, (X) z p \u00b1 O( 1 polylog(k)", "formula_coordinates": [44.0, 154.94, 423.25, 319.35, 18.67]}, {"formula_id": "formula_164", "formula_text": "A (t) i, is close to \u03a6 (t) i, .", "formula_coordinates": [44.0, 411.03, 486.97, 93.44, 16.26]}, {"formula_id": "formula_165", "formula_text": "F (t) j (X) \u2264 0.8001\u03a6 (t) for j = i.", "formula_coordinates": [44.0, 117.35, 533.88, 146.71, 16.0]}, {"formula_id": "formula_166", "formula_text": "(t) i,r , x p = w (t) i,r , v i, z p + w (t)", "formula_coordinates": [44.0, 379.01, 558.73, 132.74, 16.0]}, {"formula_id": "formula_167", "formula_text": "-F (t) i (X) \u2265 \u03a6 (t) i, \u2212 0.0001 \u2265 0.9999\u03a6 (t) .", "formula_coordinates": [44.0, 105.63, 618.85, 190.88, 16.26]}, {"formula_id": "formula_168", "formula_text": "i\u2208[k], \u2208[2] A (t) i, \u2265 polylog(k) max i\u2208[k], \u2208[2] A (t+1) i, \u2264 max i\u2208[k], \u2208[2] A (t)", "formula_coordinates": [44.0, 119.91, 676.2, 317.25, 20.54]}, {"formula_id": "formula_169", "formula_text": "\u2200i \u2208 [k] , \u2200r \u2208 [m] , \u2200j \u2208 [k] \\ {i} : | w (t) i,r , v", "formula_coordinates": [45.0, 161.29, 165.72, 229.81, 16.0]}, {"formula_id": "formula_170", "formula_text": "(t+1) i,r , v j, | \u2264 | w (t) i,r , v j, | + \u03b7 E (X,y)\u223cZ 1 y=i E 2,i,r (X) + E 1 + E 3 + E 4,j, (X) 1 \u2212 logit i F (t) , X +1 y =i E 1 + E 3 + E 4,j, (X) logit i F (t) , X Stage 1.", "formula_coordinates": [45.0, 72.0, 225.06, 464.3, 69.52]}, {"formula_id": "formula_171", "formula_text": "logit i F (t) , X \u2264 O( 1 k ) (see Claim D.4), have E 2,i,r (X) \u2264 O \u03b3(\u039b (t) i ) q\u22121 , and have E 4,i,r (X) \u2264 O(\u03c3 0 ) q\u22121 1 v j, \u2208V(X) , so | w (t+1) i,r , v j, | \u2264 | w (t) i,r , v j, | + O \u03b7 k \u03b3 \u039b (t) i q\u22121 + (\u03c3 q\u22121 0 )\u03b3s + O (\u03c3 0 \u03b3k) q\u22121 \u03b3P + (\u03c3 0 ) q\u22121 s k (D.12) Recall in the first stage \u039b (t+1) i = \u039b (t) i + \u0398 \u03b7 k ReLU (\u039b (t)", "formula_coordinates": [45.0, 72.0, 282.73, 468.0, 96.91]}, {"formula_id": "formula_172", "formula_text": "t\u2264T 0,i \u03b7 \u039b (t) i q\u22121 \u2264 O(k)", "formula_coordinates": [45.0, 255.48, 384.9, 112.56, 17.16]}, {"formula_id": "formula_173", "formula_text": "R (t) i \u2264 R (0) i + O(\u03c3 0 ) + O \u03b7 k T 0 (\u03c3 q\u22121 0 )\u03b3s + O (\u03c3 0 \u03b3k) q\u22121 \u03b3P + (\u03c3 0 ) q\u22121 s k \u2264 O(\u03c3 0 )", "formula_coordinates": [45.0, 104.97, 480.91, 402.05, 24.43]}, {"formula_id": "formula_174", "formula_text": "E 2,i,r (X) \u2264 O(\u03b3) and E 4,i,r (X) \u2264 O(\u03c3 0 ) q\u22121 1 v j, \u2208V(X) , so | w (t+1) i,r , v j, | \u2264 | w (t) i,r , v j, | + \u03b7 E (X,y)\u223cZ 1 y=i O(\u03b3) + E 1 + E 3 + O(\u03c3 0 ) q\u22121 1 v j, \u2208V(X) 1 \u2212 logit i F (t) , X +1 y =i E 1 + E 3 + O(\u03c3 0 ) q\u22121 1 v j, \u2208V(X) logit i F (t) , X", "formula_coordinates": [45.0, 72.0, 541.54, 496.05, 65.51]}, {"formula_id": "formula_175", "formula_text": "= O 1 k 1 \u2212 logit y (F (t) , X) (see Claim D.4). Therefore, | w (t+1) i,r , v j, | \u2264 | w (t) i,r , v j, | + \u03b7 E (X,y)\u223cZm 1 y=i O(\u03b3) + E 1 + E 3 + O(\u03c3 0 ) q\u22121 1 v j, \u2208V(X) 1 \u2212 logit y F (t) , X +1 y =i E 1 + E 3 + O(\u03c3 0 ) q\u22121 1 v j, \u2208V(X) logit i F (t) , X +O \u03b7N s kN E (X,y)\u223cZs k1 y=i O(\u03b3) + E 1 + E 3 + O(\u03c3 0 ) q\u22121 1 v j, \u2208V(X) 1 \u2212 logit y F (t) , X +1 y =i E 1 + E 3 + O(\u03c3 0 ) q\u22121 1 v j, \u2208V(X) 1 \u2212 logit y F (t) , X (D.14)", "formula_coordinates": [45.0, 72.0, 616.14, 510.06, 108.06]}, {"formula_id": "formula_176", "formula_text": "1 y=i 1 v j, \u2208V(X) \u2264 O s k 2 and E (X,y)\u223cZs 1 y =i 1 v j, \u2208V(X) \u2264 O s k", "formula_coordinates": [46.0, 166.27, 126.93, 315.56, 24.43]}, {"formula_id": "formula_177", "formula_text": "\u2200t \u2208 [T 0,i , T 0 ] : E (X,y)\u223cZm 1 y =i logit i F (t) , X \u2264 O( 1 k ) \u2200t \u2208 [T 0,i , T 0 ] : E (X,y)\u223cZm 1 y =i 1 v j, \u2208P(X) logit i F (t) , X \u2264 O( s k 2 ) T 0 t=T 0,i E (X,y)\u223cZm 1 y=i 1 \u2212 logit y F (t) , X \u2264 O s k T 0 \u03a5 + O 1 \u03b7", "formula_coordinates": [46.0, 108.87, 175.26, 384.85, 93.06]}, {"formula_id": "formula_178", "formula_text": "R (t) i \u2264 R (T 0,i ) i + O \u03b7T 0 \u2022 s k 2 \u03c3 q\u22121 0 + \u03b7 O s k T 0 \u03a5 + O 1 \u03b7 O \u03b3 + (\u03c3 q\u22121 0 )\u03b3s + O (\u03c3 0 \u03b3k) q\u22121 \u03b3P + (\u03c3 0 ) q\u22121 s k Hence, recalling that T 0 = \u0398 k \u03b7\u03c3 q", "formula_coordinates": [46.0, 72.0, 291.37, 412.19, 76.21]}, {"formula_id": "formula_179", "formula_text": "| w (t+1) i,r , v j, | \u2264 | w (t) i,r , v j, | + \u03b7 E (X,y)\u223cZm O(\u03b3) + E 1 + E 3 + O(\u03c3 0 ) q\u22121 1 \u2212 logit y F (t) , X +O \u03b7N s kN E (X,y)\u223cZs k1 y=i O(\u03b3) + E 1 + E 3 + O(\u03c3 0 ) q\u22121 1 \u2212 logit y F (t) , X +1 y =i E 1 + E 3 + O(\u03c3 0 ) q\u22121 1 \u2212 logit y F (t) , X (D.16)", "formula_coordinates": [46.0, 72.0, 466.25, 468.0, 87.99]}, {"formula_id": "formula_180", "formula_text": "S (t) def = E (X,y)\u223cZm 1 \u2212 logit y F (t) , X G (t) i def = E (X,y)\u223cZs 1 i=y \u2022 1 \u2212 logit y F (t) , X", "formula_coordinates": [46.0, 193.54, 579.39, 207.71, 34.99]}, {"formula_id": "formula_181", "formula_text": "R (t+1) i \u2264 R (t) i + \u03b7 \uf8eb \uf8ed S (t) + N s N G (t) i + N s kN i \u2208[k] G (t) i \uf8f6 \uf8f8 O \u03b3 + \u03c3 q\u22121 0 \u03b3s + (\u03c3 0 \u03b3k) q\u22121 \u03b3P + (\u03c3 0 ) q\u22121 .", "formula_coordinates": [46.0, 78.97, 638.2, 454.07, 37.71]}, {"formula_id": "formula_182", "formula_text": "t\u2265T 0 S (t) \u2264 O k \u03b7 Claim D.12 =\u21d2 \u2200i \u2208 [k] : t\u2265T 0 G (t) i \u2264 O N \u03b7k\u03c1 q\u22121", "formula_coordinates": [47.0, 180.73, 92.08, 242.32, 38.96]}, {"formula_id": "formula_183", "formula_text": "k\u03b3 = O(\u03c3 0 ), \u03b3 = O(\u03c3 q\u22121 0 ), N s k\u03c1 q\u22121 \u2264 O 1 \u03c3 q\u22122 0 (D.18) it satisfies R (t) i \u2264 O(\u03c3 0 ) for all t \u2265 T 0 . D.4.3 View Lottery Winning Recall \u039b (t) i, def = max r\u2208[m] [ w (t) i,r , v i, ] + . Also recall M def = (i, * ) \u2208 [k] \u00d7 [2] \u039b (0) i, * \u2265 \u039b (0) i,3\u2212 * S i,3\u2212 S i, 1 q\u22122 + 1 polylog(k)", "formula_coordinates": [47.0, 72.0, 156.96, 468.0, 129.5]}, {"formula_id": "formula_184", "formula_text": "\u039b (t) i,3\u2212 * = max r\u2208[m] [ w (t) i,r , v i,3\u2212 * ] + \u2264 O(\u03c3 0 )", "formula_coordinates": [47.0, 254.54, 381.49, 185.31, 20.54]}, {"formula_id": "formula_185", "formula_text": "w (t+1) i,r , v i, = w (t) i,r , v i, + \u03b7 E (X,y)\u223cZ 1 y=i V i,r, (X) \u00b1 O E 1 + E 3 1 \u2212 logit i (F (t) , X) \u00b1 O(1) \u2022 1 y =i E 1 + E 3 + 1 v i, \u2208P(X) V i,r, (X) logit i F (t) , X (D.19)", "formula_coordinates": [47.0, 76.24, 427.52, 463.76, 58.29]}, {"formula_id": "formula_186", "formula_text": "(t) i \u2264 \u039b \u2212 \u2205 O( 1 m 0 ) (see Claim D.11). This implies logit i F (t) , X \u2264 O( 1 k ) from Claim D.4", "formula_coordinates": [47.0, 72.0, 548.46, 468.0, 32.3]}, {"formula_id": "formula_187", "formula_text": "w (t+1) i,r , v i, = w (t) i,r , v i, + \u03b7 E (X,y)\u223cZ 1 i=y V i,r, (X)(1 \u2212 O( 1 k )) \u00b1 O 1 k 1 i =y 1 v i, \u2208P(X) V i,r, (X) \u00b1 O E 1 + E 3 k", "formula_coordinates": [47.0, 76.24, 598.04, 498.33, 24.43]}, {"formula_id": "formula_188", "formula_text": "V i,r, (X) = p\u2208Pv i, (X) ReLU w (t) i,r , v i, z p \u00b1 o (\u03c3 0 ) z p", "formula_coordinates": [47.0, 181.3, 662.42, 248.89, 29.24]}, {"formula_id": "formula_189", "formula_text": "(t) i,r , v i, z p \u2264 O(\u039b \u2212 \u2205 ) (see Claim D.11) so V i,r, (X) = 1 q\u22121 ([ w (t) i,r , v i, ] + ) q\u22121 p\u2208Pv i, (X) z q p \u00b1 O(\u03c3 0 ) Therefore, w (t+1) i,r , v i, = w (t) i,r , v i, + \u03b7 q\u22121 ([ w (t) i,r , v i, ] + ) q\u22121 (1 \u2212 O( 1 k )) E (X,y)\u223cZm 1 i=y p\u2208Pv i, (X) z q p \u00b1 O( s k 2 ) \u00b1 O E 1 + E 3 k \u2022 \u03b7 = w (t) i,r , v i, + \u03b7 q\u22121 ([ w (t) i,r , v i, ] + ) q\u22121 1 \u2212 O 1 polylog(k) S i, \u00b1 o \u03c3 0 k \u03b7 (D.20)", "formula_coordinates": [48.0, 72.0, 72.53, 472.02, 168.01]}, {"formula_id": "formula_190", "formula_text": "\u2022 x t = w (t) i,r * , v i, * \u2022 (S i, * / q\u22121 ) 1 q\u22122 \u2022 y t = max w (t) i,r , v i,3\u2212 * , \u03c3 0 \u2022 (S i,3\u2212 * / q\u22121 ) 1 q\u22122", "formula_coordinates": [48.0, 83.8, 271.25, 234.28, 40.46]}, {"formula_id": "formula_191", "formula_text": "x t+1 \u2265 x t + \u03b7C t x q\u22121 t and y t+1 \u2264 y t + \u03b7SC t y q\u22121 t for some C t = 1 \u2212 O( 1 polylog(k)", "formula_coordinates": [48.0, 72.0, 335.06, 352.79, 35.73]}, {"formula_id": "formula_192", "formula_text": "S i,3\u2212 * S i, * 1 + 1 polylog(k) that does not depend on t. Now, since \u039b (0) i, * \u2265 \u039b (0) i,3\u2212 * S i,3\u2212 * S i, * 1 q\u22122 + 1 polylog(k) implies x 0 \u2265 y 0 S 1 q\u22122 (1 + 1 polylog(k)", "formula_coordinates": [48.0, 88.94, 372.24, 389.77, 42.59]}, {"formula_id": "formula_193", "formula_text": "y t \u2264 O(y 0 ) =\u21d2 w (t) i,r , v i,3\u2212 * \u2264 O(\u03c3 0 ) (This uses | w (0) i,r , v i,3\u2212 * | \u2264 O(\u03c3 0 ).", "formula_coordinates": [48.0, 72.0, 453.81, 337.42, 43.99]}, {"formula_id": "formula_194", "formula_text": "w (t+1) i,r , v i, = w (t) i,r , v i, + \u03b7 E (X,y)\u223cZ 1 y=i V i,r, (X) \u00b1 O E 1 + E 3 1 \u2212 logit i (F (t) , X) \u00b1 1 y =i E 1 + E 3 + 1 v i, \u2208P(X) V i,r, (X) logit i F (t) , X (D.21)", "formula_coordinates": [48.0, 90.02, 570.56, 449.98, 58.29]}, {"formula_id": "formula_195", "formula_text": "(X, y) \u2208 Z s but y = i, V i,r, (X) = p\u2208Pv i, (X) ReLU w (t) i,r , v i, z p \u00b1 o (\u03c3 0 ) z p \u2264 O(\u03c3 q\u22121 0 )", "formula_coordinates": [49.0, 94.68, 75.51, 374.19, 47.99]}, {"formula_id": "formula_196", "formula_text": "p\u2208Pv i, (X) ReLU w (t) i,r , x p z p \u2264 O(\u03c3 q\u22121 0 ) (D.22)", "formula_coordinates": [49.0, 246.83, 166.12, 293.17, 29.24]}, {"formula_id": "formula_197", "formula_text": "logit i F (t) , X \u2264 O 1 k (1 \u2212 logit y F (t) , X ) (see Claim D.4)", "formula_coordinates": [49.0, 94.68, 208.1, 445.32, 25.41]}, {"formula_id": "formula_198", "formula_text": "| w (t+1) i,r , v i, | \u2264 | w (t) i,r , v i, | + O(\u03b7) E (X,y)\u223cZm 1 y=i O(\u03c3 q\u22121 0 ) + O E 1 + E 3 1 \u2212 logit y (F (t) , X) + 1 y =i O(\u03c3 q\u22121 0 )logit i (F (t) , X) +O \u03b7N s N E (X,y)\u223cZs 1 y=i O(\u03c3 q\u22121 0 ) \u2022 1 \u2212 logit y F (t) , X (D.23) + 1 y =i E 1 + E 3 + O(\u03c3 q\u22121 0 ) k 1 \u2212 logit y F (t) , X", "formula_coordinates": [49.0, 75.44, 261.82, 464.56, 106.99]}, {"formula_id": "formula_199", "formula_text": "(t+1) i,r , v i, | \u2264 | w (T 0,i ) i,r , v i, | + \u03b7O s k T 0 \u03a5 + T 0 k \u2022 O(\u03c3 q\u22121 0 ) + O(\u03c3 0 ) Recall that T 0 = \u0398 k \u03b7\u03c3 q", "formula_coordinates": [49.0, 72.0, 405.48, 398.73, 49.23]}, {"formula_id": "formula_201", "formula_text": "S (t) def = E (X,y)\u223cZm 1 \u2212 logit y F (t) , X G (t) i def = E (X,y)\u223cZs 1 i=y \u2022 1 \u2212 logit y F (t) , X then we have \u039b (t+1) i,3\u2212 * \u2264 \u039b (t) i,3\u2212 * + O \u03b7S (t) \u03c3 q\u22121 0 + O \u03b7N s N \u2022 G (t) i + j\u2208[k] G (t) j k \u2022 O(\u03c3 q\u22121 0 ) (D.24) Recall Claim D.14 =\u21d2 t\u2265T 0 S (t) \u2264 O k \u03b7 Claim D.12 =\u21d2 \u2200i \u2208 [k] : t\u2265T 0 G (t) i \u2264 O N \u03b7k\u03c1 q\u22121", "formula_coordinates": [49.0, 72.0, 525.92, 468.0, 148.67]}, {"formula_id": "formula_202", "formula_text": "\u2200i \u2208 [k], \u2200 \u2208 [2], \u2200r \u2208 [m] \\ M (0) i : w (t) i,r , v i, \u2264 O(\u03c3 0 )", "formula_coordinates": [50.0, 164.95, 243.01, 282.11, 16.0]}, {"formula_id": "formula_203", "formula_text": "w (t) i,r , \u03be p \u2264 o (\u03c3 0 ).", "formula_coordinates": [50.0, 259.05, 584.55, 81.32, 16.0]}, {"formula_id": "formula_204", "formula_text": "\u2022 If (X, y) \u2208 Z m then w (t) i,r , \u03be p \u2264 O kA q\u22121 N \u03c3 q\u22122 0 + k 5 A q\u22121 s 2 N + \u03b7T \u221a d \u2022 If (X, y) \u2208 Z s then w (t) i,r , \u03be p \u2264 O kA q\u22121 N \u03c3 q\u22122 0 + A q\u22121 \u03c1 q\u22121 + \u03b7T \u221a d", "formula_coordinates": [51.0, 83.8, 150.09, 296.45, 51.83]}, {"formula_id": "formula_205", "formula_text": "p \u2208 [P ], if y = i then w (t+1) i,r , \u03be p = w (t) i,r , \u03be p + \u0398 \u03b7 N ReLU ( w (t) i,r , x p ) 1 \u2212 logit i (F (t) , X) \u00b1 \u03b7 \u221a d for similar reason, if y = i, then w (t+1) i,r , \u03be p = w (t) i,r , \u03be p \u2212 \u0398 \u03b7 N ReLU ( w (t) i,r , x p )logit i (F (t) , X) \u00b1 \u03b7 \u221a d", "formula_coordinates": [51.0, 72.0, 552.03, 416.68, 86.4]}, {"formula_id": "formula_206", "formula_text": "(t) i,r , x p ) \u2264 O(A q\u22121 )", "formula_coordinates": [51.0, 306.07, 645.65, 94.64, 16.0]}, {"formula_id": "formula_207", "formula_text": "t = T 0 = \u0398 k \u03b7\u03c3 q\u22122 0 (see Claim D.11) w (t) i,r , \u03be p \u2264 O \u03b7 N A q\u22121 T 0 + \u03b7T 0 \u221a d \u2264 O kA q\u22121 N \u03c3 q\u22122 0 + \u03b7T 0 \u221a d", "formula_coordinates": [51.0, 72.0, 662.74, 369.97, 57.54]}, {"formula_id": "formula_208", "formula_text": "y = i =\u21d2 T t=T 0 1 \u2212 logit y F (t) , X \u2264 O k 4 s 2 \u2022 T t=T 0 E (X,y)\u223cZm 1 \u2212 logit y F (t) , X \u2264 O k 5 s 2 \u03b7 y = i =\u21d2 T t=T 0 logit i F (t) , X \u2264 T t=T 0 1 \u2212 logit y F (t) , X \u2264 O k 5 s 2 \u03b7", "formula_coordinates": [52.0, 72.0, 104.1, 458.5, 74.23]}, {"formula_id": "formula_209", "formula_text": "w (t) i,r , \u03be p \u2264 O kA q\u22121 N \u03c3 q\u22122 0 + k 5 A q\u22121 s 2 N + \u03b7T \u221a d", "formula_coordinates": [52.0, 211.11, 203.26, 196.47, 30.7]}, {"formula_id": "formula_210", "formula_text": "T t=T 0 1 \u2212 logit y F (t) , X \u2264 O N \u03b7\u03c1 q\u22121", "formula_coordinates": [52.0, 205.87, 263.69, 190.54, 34.61]}, {"formula_id": "formula_211", "formula_text": "w (t) i,r , \u03be p \u2264 O kA q\u22121 N \u03c3 q\u22122 0 + A q\u22121 \u03c1 q\u22121 + \u03b7T \u221a d D.", "formula_coordinates": [52.0, 72.0, 323.22, 330.2, 55.92]}, {"formula_id": "formula_212", "formula_text": "w (t+1) i,r , v i, \u2265 w (t) i,r , v i, + \u03b7 E (X,y)\u223cZ 1 y=i V i,r, (X) \u2212 O(\u03c3 p P ) 1 \u2212 logit i (F (t) , X) \u22121 y =i E 1 + E 3 + 1 v i, \u2208P(X) V i,r, (X) logit i F (t) , X Recall V i,r, (X) = p\u2208Pv i, (X) ReLU ( w (t)", "formula_coordinates": [52.0, 72.0, 507.69, 436.55, 72.46]}, {"formula_id": "formula_213", "formula_text": "V i,r, (X) = p\u2208Pv i, (X) ReLU w (t) i,r , v i, z p \u00b1 o (\u03c3 0 ) z p = 0 because we have assumed w (t) i,r , v i, \u2264 \u2212 \u2126(\u03c3 0 ). Therefore, w (t+1) i,r , v i, \u2265 w (t) i,r , v i, \u2212 \u03b7 E (X,y)\u223cZ 1 y=i O(\u03c3 p P ) 1 \u2212 logit i (F (t) , X) +1 y =i (E 1 + E 3 ) logit i (F (t) , X) Lemma D.24+Lemma D.27 =\u21d2 \u2200i \u2208 [k], \u2200 \u2208 [2], \u2200r \u2208 [m] \\ M (0) i : | w (t) i,r , v", "formula_coordinates": [52.0, 72.0, 613.1, 397.63, 103.98]}, {"formula_id": "formula_214", "formula_text": "(t) i \u2264 O(1/m 0 ), then it must grow by \u039b (t+1) i \u2265 \u039b (t) i + \u0398 \u03b7 k ReLU (\u039b (t) i )) implies \u039b (t) i \u2265 \u2126(\u039b(0)", "formula_coordinates": [54.0, 94.68, 312.32, 445.32, 33.55]}, {"formula_id": "formula_215", "formula_text": "1 s\u03c3 q 0 polylog(k) , every \u03b7 \u2264 1 poly(k) , after T = poly(k)", "formula_coordinates": [54.0, 72.0, 463.15, 476.88, 34.49]}, {"formula_id": "formula_216", "formula_text": "\u2200i = y : F (T ) y (X) \u2265 F (T ) i (X) + \u2126(log k). \u2022 (multi-view testing is good) for every i, j \u2208 [k] we have O(1) \u2265 \u03a6 (T ) i \u2265 0.4\u03a6 (T )", "formula_coordinates": [54.0, 83.8, 536.09, 380.42, 42.45]}, {"formula_id": "formula_217", "formula_text": "F (T ) y (X) \u2265 max j =y F (T ) j (X) + \u2126(log k) \u2265 1 \u2212 e \u2212\u2126(log 2 k)", "formula_coordinates": [54.0, 214.22, 593.17, 252.47, 20.56]}, {"formula_id": "formula_218", "formula_text": "F (T ) y (X) \u2265 max j =y F (T ) j (X) \u2212 1 polylog(k) \u2264 1 2 1 + o(1)", "formula_coordinates": [54.0, 211.5, 661.19, 250.35, 24.43]}, {"formula_id": "formula_219", "formula_text": "Pr (X,y)\u223cDs G y (X) \u2265 max i\u2208[k]\\{y} G i (X) + 1 polylog(k) \u2265 1 \u2212 e \u2212\u2126(log 2 k)", "formula_coordinates": [55.0, 164.5, 203.0, 305.19, 24.43]}, {"formula_id": "formula_220", "formula_text": "T t=T 0 E (X,y)\u223cZm 1 \u2212 logit y F (t) , X \u2264 O k \u03b7 T t=T 0 E (X,y)\u223cZs 1 \u2212 logit y F (t) , X \u2264 O N \u03b7\u03c1 q\u22121 (E.1) Also recall that our training objective is L(F (t) ) = E (X,y)\u223cZ [\u2212 log logit y (F (t) , X)]", "formula_coordinates": [55.0, 72.0, 296.47, 468.0, 79.42]}, {"formula_id": "formula_221", "formula_text": "1 T T t=T 0 E (X,y)\u223cZ [\u2212 log logit y (F (t) , X)] \u2264 1 poly(k)", "formula_coordinates": [55.0, 191.67, 468.47, 228.65, 15.96]}, {"formula_id": "formula_222", "formula_text": "E (X,y)\u223cZ 1 \u2212 logit y F (T ) , X \u2264 E (X,y)\u223cZ [\u2212 log logit y (F (T ) , X)] \u2264 1 poly(k)", "formula_coordinates": [55.0, 128.19, 536.88, 354.43, 15.19]}, {"formula_id": "formula_223", "formula_text": "(T ) i \u2212 \u03a6 (T ) j", "formula_coordinates": [55.0, 433.06, 569.8, 45.11, 16.0]}, {"formula_id": "formula_224", "formula_text": "(T ) i,3\u2212 \u2264 O(\u03c3 0 ) so \u03a6 (T ) i,3\u2212 \u2264 O(\u03c3 0 m).", "formula_coordinates": [55.0, 72.0, 615.72, 468.0, 34.06]}, {"formula_id": "formula_225", "formula_text": "F (T ) y (X) \u2264 max j =y F (T ) j (X) \u2212 1 polylog(k) (E.2)", "formula_coordinates": [56.0, 216.1, 109.69, 323.9, 24.43]}, {"formula_id": "formula_226", "formula_text": "(T ) i, \u2265 \u2126(log k) for this model (because \u03a6 (T ) i \u2265 \u2126(log k) while \u03a6 (T ) i,3\u2212 1). Let us denote it as \u03a6 [w] i, .", "formula_coordinates": [56.0, 72.0, 244.6, 467.99, 34.06]}, {"formula_id": "formula_227", "formula_text": "[w] y, \u2265 \u2126(log k) =\u21d2 F [w] y (X) \u2265 \u03a6 [w] y, \u2212 1 polylog(k) \u2265 \u2126(log k) for every F [w] with i = y =\u21d2 F [w] i (X) \u2264 \u0393(\u03a6 i,1 + \u03a6 i,2 ) + 1 polylog(k) \u2264 O(\u0393)", "formula_coordinates": [56.0, 146.86, 313.37, 366.44, 53.04]}, {"formula_id": "formula_228", "formula_text": "y (X) \u2265 G i (X) + 1 polylog(k) for every i = [k].", "formula_coordinates": [56.0, 189.46, 389.64, 203.1, 15.19]}, {"formula_id": "formula_229", "formula_text": "logit \u03c4 i (F, X) =", "formula_coordinates": [56.0, 213.17, 506.63, 71.63, 14.19]}, {"formula_id": "formula_230", "formula_text": "G(X) = \u039e K i F [i] (X) for some \u039e = \u0398(1) (F.1)", "formula_coordinates": [56.0, 196.79, 646.1, 343.21, 29.46]}, {"formula_id": "formula_231", "formula_text": "w (t+1) i,r = w (t) i,r \u2212 \u03b7\u2207 w i,r L(F (t) ) \u2212 \u03b7 E (X,y)\u223cZ logit \u03c4 i (F (t) , X) \u2212 logit \u03c4 i (G, X) \u2212 \u2207 w i,r F (t) i (X) (4.3) restated", "formula_coordinates": [57.0, 83.14, 93.38, 456.86, 38.31]}, {"formula_id": "formula_232", "formula_text": "\u2200i = y : F (t) y (X) \u2265 F (t)", "formula_coordinates": [57.0, 226.69, 242.09, 107.76, 15.44]}, {"formula_id": "formula_233", "formula_text": "[k] we have O(1) \u2265 \u03a6 (t) i \u2265 0.4\u03a6 (t)", "formula_coordinates": [57.0, 302.84, 268.07, 160.06, 16.0]}, {"formula_id": "formula_234", "formula_text": "F (t) y (X) \u2265 max j =y F (t) j (X) + \u2126(log k) \u2265 1 \u2212 e \u2212\u2126(log 2 k) \u2022 (single-view testing is good) for every i \u2208 [k] and \u2208 [2] we have \u03a6 (t)", "formula_coordinates": [57.0, 83.8, 298.69, 379.84, 45.73]}, {"formula_id": "formula_235", "formula_text": "F (T ) y (X) \u2265 max j =y F (T ) j (X) + \u2126(log k) \u2264 1 \u2212 e \u2212\u2126(log 2 k)", "formula_coordinates": [57.0, 212.7, 353.9, 252.47, 20.56]}, {"formula_id": "formula_236", "formula_text": "M G def = (i, * ) \u2208 [k] \u00d7 [2] \u039b (0) i, * \u2265 \u039b (0) i,3\u2212 * 1 + 2 log 2 (m) (F.2) which only depends on \u039b (0) i, * which in terms depends on G's random initialization. (Note M G is provably a subset of M defined in (C.2).)", "formula_coordinates": [57.0, 72.0, 517.73, 468.0, 51.93]}, {"formula_id": "formula_237", "formula_text": "w (t+1) i,r = w (t) i,r \u2212 \u03b7\u2207 w i,r L(F (t) ) for T = poly(k) \u03b7 iterations", "formula_coordinates": [57.0, 183.46, 621.0, 267.76, 24.55]}, {"formula_id": "formula_238", "formula_text": "w (t+1) i,r = w (t) i,r \u2212 \u03b7 E (X,y)\u223cZ (logit \u03c4 i (F, X) \u2212 logit \u03c4 i (G, X)) \u2212 \u2207 w i,r F (t) i (X) (4.4) restated", "formula_coordinates": [57.0, 112.41, 703.41, 427.59, 20.54]}, {"formula_id": "formula_239", "formula_text": "[k] we have O(1) \u2265 \u03a6 (T +T ) i \u2265 0.4\u03a6 (T +T ) j", "formula_coordinates": [58.0, 295.89, 169.62, 192.54, 16.0]}, {"formula_id": "formula_240", "formula_text": "F (T +T ) y (X) \u2265 max j =y F (T +T ) j (X) + \u2126(log k) \u2265 1 \u2212 e \u2212\u2126(log 2 k) \u2022 (single-view testing is better) for every (i, ) \u2208 M F \u222a M G we have \u03a6 (T +T ) i, \u2265 \u2126 1 log k , and since |M F \u222a M G | \u2265 1.5k(1 \u2212 o(1)), we have Pr (X,y)\u2208Ds F (T +T ) y (X) \u2265 max j =y F (T +T ) j (X) + \u2126(log k) \u2265 3 4 1 \u2212 o(1)", "formula_coordinates": [58.0, 83.8, 202.04, 456.2, 92.58]}, {"formula_id": "formula_241", "formula_text": "w (t) i,r , x p = w (t) i,r , v i, z p \u00b1 o (\u03c3 0 ).", "formula_coordinates": [58.0, 259.05, 456.0, 152.01, 16.0]}, {"formula_id": "formula_242", "formula_text": "i \u2208 [k], every \u2208 [2], (g) \u03a6 (t) i, \u2265 \u2126(\u03c3 0 ) and \u03a6 (t) i, \u2264 O(1). (h) for every r \u2208 [m], it holds that w (t) i,r , v i, \u2265 \u2212 O(\u03c3 0 ). (Recall \u03a6 (t) i, def = r\u2208[m] [ w (t) i,r , v i, ] + .) Parameter G.", "formula_coordinates": [58.0, 72.0, 519.78, 271.97, 97.11]}, {"formula_id": "formula_243", "formula_text": "\u2022 If v i,1 , v i,2 \u2208 V(X) then \u2207 w i,r F (t) i (X), v i, \u2265 V i,r, (X) \u2212 O(\u03c3 p P ) \u2022 \u2207 w i,r F (t) i (X), v i, \u2264 1 v i, \u2208V(X) V i,r, (X) + E 1 + E 3 \u2022 for every j \u2208 [k] \\ {i}, \u2212\u2207 w i,r F (t) i (X), v j, \u2264 (E 2,i,r (X) + E 1 + E 3 + E 4,j, (X))", "formula_coordinates": [60.0, 83.8, 302.06, 395.64, 65.76]}, {"formula_id": "formula_244", "formula_text": "F (t) i (X) = \u2208[2] \u03a6 (t) i, \u00d7 Z (t) i, (X) \u00b1 O(\u03c3 0 \u2022 m) = \u2208[2] \u03a6 (t) i, \u00d7 Z (t) i, (X) \u00b1 O( 1 polylog(k) )", "formula_coordinates": [60.0, 102.48, 532.65, 407.04, 30.17]}, {"formula_id": "formula_245", "formula_text": "\u03a6 (t+1) i, \u2265 \u03a6 (t) i, + \u2126 \u03b7 k ReLU (\u03a6 (t) i, )", "formula_coordinates": [60.0, 222.04, 700.29, 167.92, 24.43]}, {"formula_id": "formula_246", "formula_text": "w (t+1) i,r , v i, \u2265 w (t) i,r , v i, \u2212 O(\u03b7 + \u03b7 N s N )", "formula_coordinates": [61.0, 76.24, 105.61, 187.0, 24.43]}, {"formula_id": "formula_247", "formula_text": "1 v i,1", "formula_coordinates": [61.0, 238.02, 141.93, 19.38, 12.05]}, {"formula_id": "formula_248", "formula_text": "+", "formula_coordinates": [61.0, 532.91, 131.28, 6.59, 6.99]}, {"formula_id": "formula_249", "formula_text": "V i,r, (X) \u2265 \u2126(1) \u2022 ReLU w (t) i,r , v i, \u2265 \u2126 ReLU (\u03a6 (t) i, ) . Now, since \u03a6 (t) i, \u2264 1", "formula_coordinates": [61.0, 72.0, 199.71, 263.18, 36.08]}, {"formula_id": "formula_250", "formula_text": "F (t) i (X) \u2264 \u03a6 (t) i, \u00d7 Z (t) i, (X) \u2212 O(\u03c3 0 m) = O 1 \u03c4 \u2212 O(\u03c3 0 m) \u2264 O 1 \u03c4 .", "formula_coordinates": [61.0, 146.33, 254.59, 319.35, 24.43]}, {"formula_id": "formula_251", "formula_text": "\u03a6 (t+1) i, \u2265 \u03a6 (t) i, + \u2126 \u03b7 k ReLU (\u03a6 (t) i, )", "formula_coordinates": [61.0, 222.04, 305.53, 167.92, 24.43]}, {"formula_id": "formula_252", "formula_text": "F (t) y (X) \u2265 max i\u2208[k]\\{y} F (t)", "formula_coordinates": [61.0, 127.31, 506.69, 106.62, 20.54]}, {"formula_id": "formula_253", "formula_text": "F (t) y (X) \u2265 \u2126( 1 \u03c4 ) \u2265 \u2126(log k) but F (t) i (X) \u2264 O(1) for i = y (using \u0393 < 1 polylog(k)", "formula_coordinates": [61.0, 72.0, 557.05, 468.0, 30.19]}, {"formula_id": "formula_254", "formula_text": "+ \u2264 O (1)", "formula_coordinates": [61.0, 324.49, 671.27, 52.98, 14.34]}, {"formula_id": "formula_255", "formula_text": "+ \u2264 O (1)", "formula_coordinates": [61.0, 374.41, 695.44, 52.98, 16.95]}, {"formula_id": "formula_256", "formula_text": "w (t+1) i,r , v i, \u2265 w (t) i,r , v i, \u2212 1 poly(k)", "formula_coordinates": [62.0, 76.24, 105.79, 161.46, 24.43]}, {"formula_id": "formula_257", "formula_text": "+", "formula_coordinates": [62.0, 481.44, 163.16, 6.59, 6.99]}, {"formula_id": "formula_258", "formula_text": "1 v i,1 ,v i,2 \u2208V(X) V i,r, (X) \u2212 O(\u03c3 p P ) 1 s(X)", "formula_coordinates": [62.0, 238.02, 195.5, 200.86, 24.43]}, {"formula_id": "formula_259", "formula_text": "+", "formula_coordinates": [62.0, 532.91, 192.23, 6.59, 6.99]}, {"formula_id": "formula_260", "formula_text": "\u03a6 (t+1) i, \u2265 \u03a6 (t) i, \u2212 \u03b7 poly(k) + \u2126(\u03b7) E (X,y)\u223cZm 1 y=i 1 \u2212 logit i (F (t) , X) + \u2126( \u03b7 N s N ) E", "formula_coordinates": [62.0, 134.88, 308.94, 253.09, 81.8]}, {"formula_id": "formula_261", "formula_text": "+", "formula_coordinates": [62.0, 411.6, 366.31, 6.59, 6.99]}, {"formula_id": "formula_262", "formula_text": "1 v i,1 ,v i,2 \u2208V(X) 1 s(X)", "formula_coordinates": [62.0, 272.86, 398.66, 96.18, 24.43]}, {"formula_id": "formula_263", "formula_text": "+", "formula_coordinates": [62.0, 463.07, 395.38, 6.59, 6.99]}, {"formula_id": "formula_264", "formula_text": "\u03a6 (t) i, def = r\u2208[m] [ w (t) i,r , v i, ] + , we have \u2200i \u2208 [k], \u2200 \u2208 [2] : \u03a6 (t) i, \u2264 O(1)", "formula_coordinates": [62.0, 223.76, 559.0, 218.75, 40.18]}, {"formula_id": "formula_265", "formula_text": "+", "formula_coordinates": [64.0, 557.37, 458.12, 6.59, 6.99]}, {"formula_id": "formula_266", "formula_text": "M def = (i, * ) \u2208 [k] \u00d7 [2] \u039b (0) i, * \u2265 \u039b (0) i,3\u2212 * S i,3\u2212 * S i, * 1 q\u22122 1 + 1 log 2 (m)", "formula_coordinates": [65.0, 145.5, 560.75, 306.02, 23.41]}, {"formula_id": "formula_267", "formula_text": "M F def = (i, * ) \u2208 [k] \u00d7 [2] \u039b (0) i, * \u2265 \u039b (0) i,3\u2212 * 1 + 2 log 2 (m)", "formula_coordinates": [65.0, 173.18, 663.58, 250.66, 17.59]}, {"formula_id": "formula_268", "formula_text": "g i \u2264 max j\u2208[m] {g j } \u2022 1 \u2212 \u2126 1 log(m/ log(1/\u03b4))", "formula_coordinates": [67.0, 202.74, 152.66, 192.29, 24.43]}, {"formula_id": "formula_269", "formula_text": "1 x \u2212 1 x 3 e \u2212x 2 /2 \u221a 2\u03c0 \u2264 Pr g [g > x] \u2264 1 x e \u2212x 2 /2 \u221a 2\u03c0 (H.1)", "formula_coordinates": [67.0, 215.65, 204.77, 324.35, 29.05]}, {"formula_id": "formula_270", "formula_text": "i g i > x] = 1 \u2212 (1 \u2212 Pr g [g > x]) m", "formula_coordinates": [67.0, 238.45, 257.28, 160.08, 18.58]}, {"formula_id": "formula_271", "formula_text": "Pr[g > x] \u2264 O(1) \u2022 Pr[g > x * ] \u2264 O( log(1/\u03b4) m )", "formula_coordinates": [67.0, 198.57, 339.45, 214.87, 24.43]}, {"formula_id": "formula_272", "formula_text": "Pr[max i g i > x] = 1 \u2212 (1 \u2212 Pr g\u223cN (0,1) [g > x]) m Pr[max i h i < x] = (1 \u2212 Pr h\u223cN (0,\u03c3 2 ) [h > x]) m", "formula_coordinates": [67.0, 201.63, 594.16, 208.25, 43.78]}, {"formula_id": "formula_273", "formula_text": "Pr[max i h i < x * ] = (1 \u2212 Pr h\u223cN (0,\u03c3 2 ) [h > x * ]) m \u2265 \u2126(1)", "formula_coordinates": [67.0, 184.42, 682.33, 243.16, 19.43]}, {"formula_id": "formula_274", "formula_text": "Pr g\u223cN (0,1) [g > x * ] \u2265 1 2x * e \u2212(x * ) 2 /2 \u221a 2\u03c0 \u2265 1 2\u03c3 1 m \u03c3 2 Therefore, Pr[max i g i > x * ] = 1 \u2212 (1 \u2212 Pr g\u223cN (0,1) [g > x * ]) m \u2265 1 \u2212 1 \u2212 \u2126(m) \u2022 1 \u03c3m \u03c3 2", "formula_coordinates": [68.0, 72.0, 91.84, 398.07, 76.19]}, {"formula_id": "formula_275", "formula_text": "Pr[max i h i < x * < max i g i ] = Pr[max i h i < x * ] \u2022 Pr[max i g i > x * ] \u2265 \u2126(1) \u03c3m \u03c3 2 \u22121", "formula_coordinates": [68.0, 130.18, 191.92, 349.94, 25.02]}, {"formula_id": "formula_276", "formula_text": "Pr max i\u2208[m] g i \u2208 [z(1 \u2212 \u03c4 ), z(1 + \u03c4 )] \u2264 O(z\u03c4 ) \u2022 O(E[max i\u2208[m]", "formula_coordinates": [68.0, 129.51, 288.54, 255.69, 16.83]}, {"formula_id": "formula_277", "formula_text": "-Pr (i, 3 \u2212 ) \u2208 M \u2265 m \u2212O(1) . -Pr (i, ) \u2208 M or (i, 3 \u2212 ) \u2208 M \u2265 1 \u2212 o(1)", "formula_coordinates": [68.0, 105.63, 470.59, 221.85, 26.47]}], "doi": "10.23915/distill.00007"}