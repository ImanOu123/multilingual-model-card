{"title": "Fast subtree kernels on graphs", "authors": "Nino Shervashidze; Karsten M Borgwardt", "pub_date": "", "abstract": "In this article, we propose fast subtree kernels on graphs. On graphs with n nodes and m edges and maximum degree d, these kernels comparing subtrees of height h can be computed in O(mh), whereas the classic subtree kernel by Ramon & G\u00e4rtner scales as O(n 2 4 d h). Key to this efficiency is the observation that the Weisfeiler-Lehman test of isomorphism from graph theory elegantly computes a subtree kernel as a byproduct. Our fast subtree kernels can deal with labeled graphs, scale up easily to large graphs and outperform state-of-the-art graph kernels on several classification benchmark datasets in terms of accuracy and runtime.", "sections": [{"heading": "Introduction", "text": "Graph kernels have recently evolved into a branch of kernel machines that reaches deep into graph mining. Several different graph kernels have been defined in machine learning which can be categorized into three classes: graph kernels based on walks [5,7] and paths [2], graph kernels based on limited-size subgraphs [6,11], and graph kernels based on subtree patterns [9,10].\nWhile fast computation techniques have been developed for graph kernels based on walks [12] and on limited-size subgraphs [11], it is unclear how to compute subtree kernels efficiently. As a consequence, they have been applied to relatively small graphs representing chemical compounds [9] or handwritten digits [1], with approximately twenty nodes on average. But could one speed up subtree kernels to make them usable on graphs with hundreds of nodes, as they arise in protein structure models or in program flow graphs?\nIt is a general limitation of graph kernels that they scale poorly to large, labeled graphs with more than 100 nodes. While the efficient kernel computation strategies from [11,12] are able to compare unlabeled graphs efficiently, the efficient comparison of large, labeled graphs remains an unsolved challenge. Could one speed up subtree kernels to make them the kernel of choice for comparing large, labeled graphs?\nThe goal of this article is to address both of the aforementioned questions, that is, to develop a fast subtree kernel that scales up to large, labeled graphs.\nThe remainder of this article is structured as follows. In Section 2, we review the subtree kernel from the literature and its runtime complexity. In Section 3, we describe an alternative subtree kernel and its efficient computation based on the Weisfeiler-Lehman test of isomorphism. In Section 4, we compare these two subtree kernels to each other, as well as to a set of four other state-of-the-art graph kernels and report results on kernel computation runtime and classification accuracy on graph benchmark datasets.", "publication_ref": ["b4", "b6", "b1", "b5", "b10", "b8", "b9", "b11", "b10", "b8", "b0", "b10", "b11"], "figure_ref": [], "table_ref": []}, {"heading": "The Ramon-G\u00e4rtner subtree kernel", "text": "Terminology We define a graph G as a triplet (V, E, L), where V is the set of vertices, E the set of undirected edges, and L : V \u2192 \u03a3 a function that assigns labels from an alphabet \u03a3 to nodes in the graph 1 . The neighbourhood N (v) of a node v is the set of nodes to which v is connected by an edge, that is N (v) = {v |(v, v ) \u2208 E}. For simplicity, we assume that every graph has n nodes, m edges, a maximum degree of d, and that there are N graphs in our given set of graphs.\nA walk is a sequence of nodes in a graph, in which consecutive nodes are connected by an edge. A path is a walk that consists of distinct nodes only. A (rooted) subtree is a subgraph of a graph, which has no cycles, but a designated root node. A subtree of G can thus be seen as a connected subset of distinct nodes of G with an underlying tree structure. The height of a subtree is the maximum distance between the root and any other node in the graph plus one. The notion of walk is extending the notion of path by allowing nodes to be equal. Similarly, the notion of subtrees can be extended to subtree patterns (also called 'tree-walks' [1]), which can have nodes that are equal. These repetitions of the same node are then treated as distinct nodes, such that the pattern is still a cycle-free tree. Note that all subtree kernels compare subtree patterns in two graphs, not (strict) subtrees. Let S(G) refer to the set of all subtree patterns in graph G.\nDefinition The first subtree kernel on graphs was defined by [10]. It compares all pairs of nodes from graphs G = (V, E, L) and G = (V , E , L ) by iteratively comparing their neighbourhoods:\nk (h) Ramon (G, G ) = v\u2208V v \u2208V k h (v, v ),(1)\nwhere\nk h (v, v ) = \u03b4(L(v), L (v )), if h = 1 \u03bb r \u03bb s R\u2208M(v,v ) (w,w )\u2208R k h\u22121 (w, w ), if h > 1 (2)\nand\nM(v, v ) = {R \u2286 N (v) \u00d7 N (v )|(\u2200(u, u ), (w, w ) \u2208 R : u = w \u21d4 u = w ) \u2227(\u2200(u, u ) \u2208 R : L(u) = L (u ))}.(3)\nIntuitively, k Ramon iteratively compares all matchings M(v, v ) between neighbours of two nodes v from G and v from G .\nComplexity The runtime complexity of the subtree kernel for a pair of graphs is O(n 2 h4 d ), including a comparison of all pairs of nodes (n 2 ), and a pairwise comparison of all matchings in their neighbourhoods in O(4 d ), which is repeated in h iterations. h is a multiplicative factor, not an exponent, as one can implement the subtree kernel recursively, starting with k 1 and recursively computing k h from k h\u22121 . For a dataset of N graphs, the resulting runtime complexity is then obviously in O(N 2 n 2 h4 d ).", "publication_ref": ["b0", "b0", "b9"], "figure_ref": [], "table_ref": []}, {"heading": "Related work", "text": "The subtree kernels in [9] and [1] refine the above definition for applications in chemoinformatics and hand-written digit recognition. Mah\u00e9 and Vert [9] define extensions of the classic subtree kernel that avoid tottering [8] and consider unbalanced subtrees. Both [9] and [1] propose to consider \u03b1-ary subtrees with at most \u03b1 children per node. This restricts the set of matchings to matchings of up to \u03b1 nodes, but the runtime complexity is still exponential in this parameter \u03b1, which both papers describe as feasible on small graphs (with approximately 20 nodes) with many distinct node labels. We present a subtree kernel that is efficient to compute on graphs with hundreds and thousands of nodes next.\n3 Fast subtree kernels", "publication_ref": ["b8", "b0", "b8", "b7", "b8", "b0"], "figure_ref": [], "table_ref": []}, {"heading": "The Weisfeiler-Lehman test of isomorphism", "text": "Our algorithm for computing a fast subtree kernel builds upon the Weisfeiler-Lehman test of isomorphism [14], more specifically its 1-dimensional variant, also known as \"naive vertex refinement\", which we describe in the following.\nAssume we are given two graphs G and G and we would like to test whether they are isomorphic. The 1-dimensional Weisfeiler-Lehman test proceeds in iterations, which we index by h and which comprise the following steps:\nAlgorithm 1 One iteration of the 1-dimensional Weisfeiler-Lehman test of graph isomorphism 1: Multiset-label determination\n\u2022 For h = 1, set M h (v) := l 0 (v) = L(v)\nfor labeled graphs, and\nM h (v) := l 0 (v) = | N (v)| for unlabeled graphs. \u2022 For h > 1, assign a multiset-label M h (v) to each node v in G and G which consists of the multiset {l h\u22121 (u)|u \u2208 N (v)}. 2: Sorting each multiset \u2022 Sort elements in M h (v)\nin ascending order and concatenate them into a string s h (v).\n\u2022 Add l h\u22121 (v) as a prefix to s h (v).", "publication_ref": ["b13"], "figure_ref": [], "table_ref": []}, {"heading": "3: Sorting the set of multisets", "text": "\u2022 Sort all of the strings s h (v) for all v from G and G in ascending order. 4: Label compression\n\u2022 Map each string s h (v) to a new compressed label, using a function f :\n\u03a3 * \u2192 \u03a3 such that f (s h (v)) = f (s h (w)) if and only if s h (v) = s h (w). 5: Relabeling \u2022 Set l h (v) := f (s h (v)\n) for all nodes in G and G .\nThe sorting step 3 allows for a straightforward definition and implementation of f for the compression step 4: one keeps a counter variable for f that records the number of distinct strings that f has compressed before. f assigns the current value of this counter to a string if an identical string has been compressed before, but when one encounters a new string, one increments the counter by one and f assigns its value to the new string. The sorted order from step 3 guarantees that all identical strings are mapped to the same number, because they occur in a consecutive block.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "The Weisfeiler-Lehman algorithm terminates after step 5 of iteration", "text": "h if {l h (v)|v \u2208 V } = {l h (v )|v \u2208 V },\nthat is, if the sets of newly created labels are not identical in G and G . The graphs are then not isomorphic. If the sets are identical after n iterations, the algorithm stops without giving an answer.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Complexity The runtime complexity of Weisfeiler-Lehman algorithm with h iterations is O(hm).", "text": "Defining the multisets in step 1 for all nodes is an O(m) operation. Sorting each multiset is an O(m) operation for all nodes. This efficiency can be achieved by using Counting Sort, which is an instance of Bucket Sort, due to the limited range that the elements of the multiset are from. The elements of each multiset are a subset of {f (s h (v))|v \u2208 V }. For a fixed h, the cardinality of this set is upper-bounded by n, which means that we can sort all multisets in O(m) by the following procedure: We assign the elements of all multisets to their corresponding buckets, recording which multiset they came from. By reading through all buckets in ascending order, we can then extract the sorted multisets for all nodes in a graph. The runtime is O(m) as there are O(m) elements in the multisets of a graph in iteration h. Sorting the resulting strings is of time complexity O(m) via the Radix Sort. The label compression requires one pass over all strings and their characters, that is O(m). Hence all these steps result in a total runtime of O(hm) for h iterations.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "The Weisfeiler-Lehman kernel on pairs of graphs", "text": "Based on the Weisfeiler-Lehman algorithm, we define the following kernel function.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Definition 1", "text": "The Weisfeiler-Lehman kernel on two graphs G and G is defined as:\nk (h) W L (G, G ) = |{(s i (v), s i (v ))|f (s i (v)) = f (s i (v )), i \u2208 {1, . . . , h}, v \u2208 V, v \u2208 V }|,(4)\nwhere f is injective and the sets {f\n(s i (v))|v \u2208 V \u222a V } and {f (s j (v))|v \u2208 V \u222a V } are disjoint for all i = j.\nThat is, the Weisfeiler-Lehman kernel counts common multiset strings in two graphs.\nTheorem 2 The Weisfeiler-Lehman kernel is positive definite.\nProof Intuitively, k\nW L is a kernel because it counts matching subtree patterns of up to height h in two graphs. More formally, let us define a mapping \u03c6 that counts the occurrences of a particular label sequence s in G (generated in h iterations of Weisfeiler-Lehman). Let \u03c6 (h) s (G) denote the number of occurrences of s in G, and analogously \u03c6\n(h) s (G ) for G . Then k (h) s (G, G ) = \u03c6 (h) s (G)\u03c6 (h) s (G ) = = |{(s i (v), s i (v ))|s i (v) = s i (v ), i \u2208 {1, . . . , h}, v \u2208 V, v \u2208 V }|,(5)\nand if we sum over all s from \u03a3 * , we obtain\nk (h) W L (G, G ) = s\u2208\u03a3 * k (h) s (G, G ) = s\u2208\u03a3 * \u03c6 (h) s (G)\u03c6 (h) s (G ) = = |{(s i (v), s i (v ))|s i (v) = s i (v ), i \u2208 {1, . . . , h}, v \u2208 V, v \u2208 V }| = = |{(s i (v), s i (v ))|f (s i (v)) = f (s i (v )), i \u2208 {1, . . . , h}, v \u2208 V, v \u2208 V }|,(6)\nwhere the last equality follows from the fact that f is injective.\nAs f (s) = s and hence each string s corresponds to exactly one subtree pattern t, k\nW L defines a kernel with corresponding feature map \u03c6\n(h) W L , such that \u03c6 (h) W L (G) = (\u03c6 (h) s (G)) s\u2208\u03a3 * = (\u03c6 (h) t (G)) t\u2208S(G) .(7)\nTheorem 3 The Weisfeiler-Lehman kernel on a pair of graphs G and G can be computed in O(hm).\nProof This follows directly from the definition of the Weisfeiler-Lehman kernel and the runtime complexity of the Weisfeiler-Lehman test, as described in Section 3.1. The number of matching multiset strings can be counted as part of step 3, as they occur consecutively in the sorted order.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "The Weisfeiler-Lehman kernel on N graphs", "text": "For computing the Weisfeiler-Lehman kernel on N graphs we propose the following algorithm which improves over the naive, N 2 -fold application of the kernel from (4). We now process all N graphs simultaneously and conduct the steps given in the Algorithm 2 in each of h iterations on each graph G.\nThe hash function g can be implemented efficiently: it again keeps a counter variable x which counts the number of distinct strings that g has mapped to compressed labels so far. If g is applied to a string that is different from all previous ones, then the string is mapped to x + 1, and x increments. As before, g is required to keep sets of compressed labels from different iterations disjoint.\nTheorem 4 For N graphs, the Weisfeiler-Lehman kernel on all pairs of these graphs can be computed in O(N hm + N 2 hn).\nProof Naive application of the kernel from definition (4) for computing an N \u00d7 N kernel matrix would require a runtime of O(N 2 hm). One can improve upon this runtime complexity by computing \u03c6 (h) W L explicitly. This can be achieved by replacing the compression mapping f in the classic Weisfeiler-Lehman algorithm by a hash function g that is applied to all N graphs simultaneously. ", "publication_ref": ["b3"], "figure_ref": [], "table_ref": []}, {"heading": "Link to the Ramon-G\u00e4rtner kernel", "text": "The Weisfeiler-Lehman kernel can be defined in a recursive fashion which elucidates its relation to the Ramon-G\u00e4rtner kernel.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Theorem 5 The kernel k", "text": "(h) recursive defined as k (h) recursive (G, G ) = h i=1 v\u2208V v \u2208V k i (v, v ),(8)\nwhere\nk i (v, v ) = \uf8f1 \uf8f2 \uf8f3 \u03b4(L(v), L (v )), if i = 1 k i\u22121 (v, v ) max R\u2208M(v,v ) (w,w )\u2208R k i\u22121 (w, w ), if i > 1 and M = \u2205 0, if i > 1 and M = \u2205(9)\nand\nM(v, v ) = {R \u2286 N (v) \u00d7 N (v )|(\u2200(u, u ), (w, w ) \u2208 R : u = w \u21d4 u = w ) \u2227(\u2200(u, u ) \u2208 R : L(u) = L (u ) \u2227 |R| = | N (v)| = | N (v )|)}(10)\nis equivalent to the Weisfeiler-Lehman kernel k (h) W L . Proof We prove this theorem by induction over h. Induction initialisation: h = 1:\nk (1) W L = |{(s 1 (v), s 1 (v ))|f (s 1 (v)) = f (s 1 (v )), v \u2208 V, v \u2208 V }| = (11) = v\u2208V v \u2208V \u03b4(L(v), L (v )) = k (1)\nrecursive .\nThe equality follows from the definition of M(v, v ). where the equality of ( 13) and ( 14) follows from the fact that k h+1 (v, v ) = 1 if and only if the neigborhoods of v and v are identical, that is if f (s h+1 (v)) = f (s h+1 (v )).\nInduction step h \u2192 h + 1: Assume that k (h) W L = k (h) recursive . Then k (h+1) recursive = v\u2208V v \u2208V k h+1 (v, v ) + h i=1 v\u2208V v \u2208V k i (v, v ) = (13) = |{(s h+1 (v), s h+1 (v ))|f (s h+1 (v)) = f (s h+1 (v )), v \u2208 V, v \u2208 V }| + k (h) W L = k (h+1) W L , (14\n)\nTheorem 5 highlights the following differences between the Weisfeiler-Lehman and the Ramon-G\u00e4rtner kernel: In (8), Weisfeiler-Lehman considers all subtrees up to height h and the Ramon-G\u00e4rtner kernel the subtrees of exactly height h. In ( 9) and ( 10), the Weisfeiler-Lehman kernel checks whether the neighbourhoods of v and v match exactly, whereas the Ramon-G\u00e4rtner kernel considers all pairs of matching subsets of the neighbourhoods of v and v in (3). In our experiments, we next examine the empirical differences between these two kernels in terms of runtime and prediction accuracy on classification benchmark datasets.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Experiments", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Runtime behaviour of Weisfeiler-Lehman kernel", "text": "Methods We empirically compared the runtime behaviour of our two variants of the Weisfeiler-Lehman (WL) kernel. The first variant computes kernel values pairwise in O(N 2 hm). The second variant computes the kernel values in O(N hm + N 2 hn) on the dataset simultaneously. We will refer to the former variant as the 'pairwise' WL, and the latter as 'global' WL.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Experimental setup", "text": "We assessed the behaviour on randomly generated graphs with respect to four parameters: dataset size N , graph size n, subtree height h and graph density c. The density of an undirected graph of n nodes without self-loops is defined as the number of its edges divided by n(n \u2212 1)/2, the maximal number of edges. We kept 3 out of 4 parameters fixed at their default values and varied the fourth parameter. The default values we used were 10 for N , 100 for n, 5 for h and 0.4 for the graph density c. In more detail, we varied N and n in range {10, 100, 1000}, h in {2, 4, 8} and c in {0.1, 0.2, . . . , 0.9}.\nFor each individual experiment, we generated N graphs with n nodes, and inserted edges randomly until the number of edges reached cn(n \u2212 1)/2 . We then computed the pairwise and the global WL kernel on these synthetic graphs. We report CPU runtimes in seconds in Figure 1, as measured in Matlab R2008a on an Apple MacPro with 3.0GHz Intel 8-Core with 16GB RAM.\nResults Empirically, we observe that the pairwise kernel scales quadratically with dataset size N . Interestingly, the global kernel scales linearly with N . The N 2 sparse vector multiplications that have to be performed for kernel computation with global WL do not dominate runtime here. This result on synthetic data indicates that the global WL kernel has attractive scalability properties for large datasets.\nWhen varying the number of nodes n per graph, we observe that the runtime of global WL scales linearly with n, and is much faster than the pairwise WL for large graphs.\nWe observe the same picture for the height h of the subtree patterns. The runtime of both kernels grows linearly with h, but the global WL is more efficient in terms of runtime in seconds.\nVarying the graph density c, both methods show again a linearly increasing runtime, although the runtime of the global WL kernel is close to constant. The density c seems to be a graph property that affects the runtime of the pairwise kernel more severely than that of global WL. Across all different graph properties, the global WL kernel from Section 3.3 requires less runtime than the pairwise WL kernel from Section 3.2. Hence the global WL kernel is the variant of our Weisfeiler-Lehman kernel that we use in the following graph classification tasks.", "publication_ref": [], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "Graph classification", "text": "Datasets We employed the following datasets in our experiments: MUTAG, NCI1, NCI109, and D&D. MUTAG [3] is a dataset of 188 mutagenic aromatic and heteroaromatic nitro compounds labeled according to whether or not they have a mutagenic effect on the Gram-negative bacterium Salmonella typhimurium. We also conducted experiments on two balanced subsets of NCI1 and NCI109, which classify compounds based on whether or not they are active in an anti-cancer screen ( [13] and http://pubchem.ncbi.nlm.nih.gov). D&D is a dataset of 1178 protein structures [4]. Each protein is represented by a graph, in which the nodes are amino acids and two nodes are connected by an edge if they are less than 6 Angstroms apart. The prediction task is to classify the protein structures into enzymes and non-enzymes.\nExperimental setup On these datasets, we compared our Weisfeiler-Lehman kernel to the Ramon-G\u00e4rtner kernel (\u03bb r = \u03bb s = 1), as well as to several state-of-the-art graph kernels for large graphs: the fast geometric random walk kernel from [12] that counts common labeled walks (with \u03bb chosen from the set {10 \u22122 , 10 \u22123 , . . . , 10 \u22126 } by cross-validation on the training set), the graphlet kernel from [11] that counts common induced labeled connected subgraphs of size 3, and the shortest path kernel from [2] that counts pairs of labeled nodes with identical shortest path distance.\nWe performed 10-fold cross-validation of C-Support Vector Machine Classification, using 9 folds for training and 1 for testing. All parameters of the SVM were optimised on the training dataset only. To exclude random effects of fold assignments, we repeated the whole experiment 10 times. We report average prediction accuracies and standard errors in Tables 1 and 2.\nWe choose h for our Weisfeiler-Lehman kernel by cross-validation on the training dataset for h \u2208 {1, . . . , 10}, which means that we computed 10 different WL kernel matrices in each experiment. We report the total runtime of this computation (not the average per kernel matrix).", "publication_ref": ["b2", "b12", "b3", "b11", "b10", "b1"], "figure_ref": [], "table_ref": ["tab_1"]}, {"heading": "Results", "text": "In terms of runtime the Weisfeiler-Lehman kernel can easily scale up even to graphs with thousands of nodes. On D&D, subtree-patterns of height up to 10 were computed in 11 minutes, while no other comparison method could handle this dataset in less than half an hour. The shortest path kernel is competitive to the WL kernel on smaller graphs (MUTAG, NCI1, NCI109), but on D&D its runtime degenerates to more than 23 hours. The Ramon and G\u00e4rtner kernel was computable on MUTAG in approximately 40 minutes, but for the large NCI datasets it only finished computation on a subsample of 100 graphs within two days. On D&D, it did not even finish on a subsample of 100 graphs within two days. The random walk kernel is competitive on MUTAG, but as the Ramon-G\u00e4rtner kernel, does not finish computation on the full NCI datasets and on D&D within two days. The graphlet kernel is faster than our WL kernel on MUTAG and the NCI datasets, and about a   factor of 3 slower on D&D. However, this efficiency comes at a price, as the kernel based on size-3 graphlets turns out to lead to poor accuracy levels on three datasets. Using larger graphlets with 4 or 5 nodes that might have been more expressive led to infeasible runtime requirements in initial experiments (not shown here).\nOn NCI1, NCI109 and D&D, the Weisfeiler-Lehman kernel reached the highest accuracy. On D&D the shortest path and graphlet kernels yielded similarly good results, while on NCI1 and NCI109 the Weisfeiler-Lehman kernel improves by more than 8% the best accuracy attained by other methods. On MUTAG, it reaches the third best accuracy among all methods considered. We could not assess the performance of the Ramon & G\u00e4rtner kernel and the random walk kernel on larger datasets, as their computation did not finish in 48 hours. The labeled size-3 graphlet kernel achieves low accuracy levels, except on D&D.\nTo summarize, the WL kernel turns out to be competitive in terms of runtime on all smaller datasets, fastest on the large protein dataset, and its accuracy levels are highest on three out of four datasets.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Conclusions", "text": "We have defined a fast subtree kernel on graphs that combines scalability with the ability to deal with node labels. It is competitive with state-of-the-art kernels on several classification benchmark datasets in terms of accuracy, even reaching the highest accuracy level on three out of four datasets, and outperforms them significantly in terms of runtime on large graphs, even the efficient computation schemes for random walk kernels [12] and graphlet kernels [11] that were recently defined.\nThis new kernel opens the door to applications of graph kernels on large graphs in bioinformatics, for instance, protein function prediction via detailed graph models of protein structure on the amino acid level, or on gene networks for phenotype prediction. An exciting algorithmic question for further studies will be to consider kernels on graphs with continuous or high-dimensional node labels and their efficient computation.", "publication_ref": ["b11", "b10"], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgements", "text": "The authors would like to thank Kurt Mehlhorn, Pascal Schweitzer, and Erik Jan van Leeuwen for fruitful discussions.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Graph kernels between point clouds", "journal": "", "year": "2008", "authors": "F R Bach"}, {"ref_id": "b1", "title": "Shortest-path kernels on graphs", "journal": "", "year": "2005", "authors": "K M Borgwardt; H.-P Kriegel"}, {"ref_id": "b2", "title": "Structure-activity relationship of mutagenic aromatic and heteroaromatic nitro compounds. correlation with molecular orbital energies and hydrophobicity", "journal": "J Med Chem", "year": "1991", "authors": "A K Debnath; R L Lopez De Compadre; G Debnath; A J Shusterman; C Hansch"}, {"ref_id": "b3", "title": "Distinguishing enzyme structures from non-enzymes without alignments", "journal": "J Mol Biol", "year": "2003-07", "authors": "P D Dobson; A J Doig"}, {"ref_id": "b4", "title": "On graph kernels: Hardness results and efficient alternatives", "journal": "Springer", "year": "2003", "authors": "T G\u00e4rtner; P A Flach; S Wrobel"}, {"ref_id": "b5", "title": "Cyclic pattern kernels for predictive graph mining", "journal": "", "year": "2004", "authors": "T Horvath; T G\u00e4rtner; S Wrobel"}, {"ref_id": "b6", "title": "Marginalized kernels between labeled graphs", "journal": "", "year": "2003", "authors": "H Kashima; K Tsuda; A Inokuchi"}, {"ref_id": "b7", "title": "Extensions of marginalized graph kernels", "journal": "", "year": "2004", "authors": "P Mah\u00e9; N Ueda; T Akutsu; J.-L Perret; J.-P Vert"}, {"ref_id": "b8", "title": "Graph kernels based on tree patterns for molecules. q-bio/0609024", "journal": "", "year": "2006-09", "authors": "P Mah\u00e9; J.-P Vert"}, {"ref_id": "b9", "title": "Expressivity versus efficiency of graph kernels", "journal": "", "year": "2003", "authors": "J Ramon; T G\u00e4rtner"}, {"ref_id": "b10", "title": "Efficient graphlet kernels for large graph comparison", "journal": "", "year": "2009", "authors": "N Shervashidze; S V N Vishwanathan; T Petri; K Mehlhorn; K M Borgwardt"}, {"ref_id": "b11", "title": "Fast computation of graph kernels", "journal": "MIT Press", "year": "2007", "authors": "S V N Vishwanathan; Karsten Borgwardt; Nicol N Schraudolph"}, {"ref_id": "b12", "title": "Comparison of descriptor spaces for chemical compound retrieval and classification", "journal": "", "year": "2006", "authors": "N Wale; G Karypis"}, {"ref_id": "b13", "title": "A reduction of a graph to a canonical form and an algebra arising during this reduction. Nauchno-Technicheskaya Informatsia", "journal": "", "year": "1968", "authors": "B Weisfeiler; A A Lehman"}], "figures": [{"figure_label": "2", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Algorithm 22One iteration of the Weisfeiler-Lehman kernel on N graphs 1: Multiset-label determination\u2022 Assign a multiset-label M h (v) to each node v in G which consists of the multiset {l h\u22121 (u)|u \u2208 N (v)}.2: Sorting each multiset\u2022 Sort elements in M h (v) in ascending order and concatenate them into a string s h (v).\u2022 Add l h\u22121 (v) as a prefix to s h (v).3: Label compression\u2022 Map each string s h (v) to a compressed label using a hash function g : \u03a3 * \u2192 \u03a3 such that g(s h (v)) = g(s h (w)) if and only if s h (v) = s h (w).4: Relabeling \u2022 Set l h (v) := g(s h (v)) for all nodes in G. This has the following effects on the runtime of Weisfeiler-Lehman: Step 1, the multiset-label determination, still requires O(N m). Step 2, the sorting of the elements in each multiset can be done via a joint Bucket Sort (Counting Sort) of all strings, requiring O(N n + N m) time. The use of the hash function g renders the sorting of all strings unnecessary (Step 3 from Section 3.1), as identical strings will be mapped to the same (compressed) label anyway. Step 4 and Step 5 remain unchanged. The effort of computing \u03c6 (h) W L on all N graphs in h iterations is then O(N hm), assuming that m > n. To get all pairwise kernel values we have to multiply all feature vectors, which requires a runtime of O(N 2 hn), as each graph G has at most hn non-zero entries in \u03c6 (h) W L (G).", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 1 :1Figure 1: Runtime in seconds for kernel matrix computation on synthetic graphs using the pairwise (red, dashed) and the global (green) Weisfeiler-Lehman kernel (Default values: dataset size N = 10, graph size n = 100, subtree height h = 5, graph density c = 0.4).", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "Lehman 82.05 (\u00b10.36) 82.19 (\u00b1 0.18) 82.46 (\u00b10.24) 79.78 (\u00b10.36) Ramon & G\u00e4rtner 85.72 (\u00b10.", "figure_data": "Method/Dataset MUTAGNCI1NCI109D & DWeisfeiler-49) ------Graphlet count 75.61 (\u00b10.49) 66.00 (\u00b10.07)66.59 (\u00b10.08) 78.59 (\u00b10.12)Random walk 80.72 (\u00b10.38) ------Shortest path 87.28 (\u00b10.55) 73.47 (\u00b10.11)73.07 (\u00b10.11) 78.45 (\u00b10.26)--: did not finish in 2 days."}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "Prediction accuracy (\u00b1 standard error) on graph classification benchmark datasets", "figure_data": "Dataset MUTAGNCI1NCI109D & DMaximum # nodes281111115748Average # nodes17.9329.8729.68284.32# labels7375489Number of graphs188100411010041271001178Weisfeiler-Lehman6\"5\"7'20\"5\"7'21\"58\"11'Ramon & G\u00e4rtner40'6\"25'9\" 29 days  *26'40\"31 days  *----Graphlet count3\"2\"1'27\"2\"1'27\"2'40\"30'21\"Random walk12\"58'30\" 68 days  *  2h 9'41\" 153 days  *----Shortest path2\"3\"4'38\"3\"4'39\"58'45\" 23h 17'2\"--: did not finish in 2 days, * = extrapolated."}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "CPU runtime for kernel computation on graph classification benchmark datasets", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "k (h) Ramon (G, G ) = v\u2208V v \u2208V k h (v, v ),(1)", "formula_coordinates": [2.0, 228.44, 332.2, 275.56, 23.2]}, {"formula_id": "formula_1", "formula_text": "k h (v, v ) = \u03b4(L(v), L (v )), if h = 1 \u03bb r \u03bb s R\u2208M(v,v ) (w,w )\u2208R k h\u22121 (w, w ), if h > 1 (2)", "formula_coordinates": [2.0, 163.72, 388.22, 340.28, 22.11]}, {"formula_id": "formula_2", "formula_text": "M(v, v ) = {R \u2286 N (v) \u00d7 N (v )|(\u2200(u, u ), (w, w ) \u2208 R : u = w \u21d4 u = w ) \u2227(\u2200(u, u ) \u2208 R : L(u) = L (u ))}.(3)", "formula_coordinates": [2.0, 148.38, 444.98, 355.62, 24.45]}, {"formula_id": "formula_3", "formula_text": "\u2022 For h = 1, set M h (v) := l 0 (v) = L(v)", "formula_coordinates": [3.0, 139.11, 246.46, 164.89, 9.65]}, {"formula_id": "formula_4", "formula_text": "M h (v) := l 0 (v) = | N (v)| for unlabeled graphs. \u2022 For h > 1, assign a multiset-label M h (v) to each node v in G and G which consists of the multiset {l h\u22121 (u)|u \u2208 N (v)}. 2: Sorting each multiset \u2022 Sort elements in M h (v)", "formula_coordinates": [3.0, 112.98, 246.46, 382.29, 64.45]}, {"formula_id": "formula_5", "formula_text": "\u03a3 * \u2192 \u03a3 such that f (s h (v)) = f (s h (w)) if and only if s h (v) = s h (w). 5: Relabeling \u2022 Set l h (v) := f (s h (v)", "formula_coordinates": [3.0, 112.98, 354.48, 372.99, 44.1]}, {"formula_id": "formula_6", "formula_text": "h if {l h (v)|v \u2208 V } = {l h (v )|v \u2208 V },", "formula_coordinates": [3.0, 108.0, 489.73, 396.0, 20.61]}, {"formula_id": "formula_7", "formula_text": "k (h) W L (G, G ) = |{(s i (v), s i (v ))|f (s i (v)) = f (s i (v )), i \u2208 {1, . . . , h}, v \u2208 V, v \u2208 V }|,(4)", "formula_coordinates": [4.0, 123.58, 100.14, 380.42, 14.22]}, {"formula_id": "formula_8", "formula_text": "(s i (v))|v \u2208 V \u222a V } and {f (s j (v))|v \u2208 V \u222a V } are disjoint for all i = j.", "formula_coordinates": [4.0, 108.0, 119.02, 396.0, 19.7]}, {"formula_id": "formula_10", "formula_text": "(h) s (G ) for G . Then k (h) s (G, G ) = \u03c6 (h) s (G)\u03c6 (h) s (G ) = = |{(s i (v), s i (v ))|s i (v) = s i (v ), i \u2208 {1, . . . , h}, v \u2208 V, v \u2208 V }|,(5)", "formula_coordinates": [4.0, 144.5, 228.68, 359.5, 45.67]}, {"formula_id": "formula_11", "formula_text": "k (h) W L (G, G ) = s\u2208\u03a3 * k (h) s (G, G ) = s\u2208\u03a3 * \u03c6 (h) s (G)\u03c6 (h) s (G ) = = |{(s i (v), s i (v ))|s i (v) = s i (v ), i \u2208 {1, . . . , h}, v \u2208 V, v \u2208 V }| = = |{(s i (v), s i (v ))|f (s i (v)) = f (s i (v )), i \u2208 {1, . . . , h}, v \u2208 V, v \u2208 V }|,(6)", "formula_coordinates": [4.0, 118.39, 294.97, 385.61, 53.45]}, {"formula_id": "formula_13", "formula_text": "(h) W L , such that \u03c6 (h) W L (G) = (\u03c6 (h) s (G)) s\u2208\u03a3 * = (\u03c6 (h) t (G)) t\u2208S(G) .(7)", "formula_coordinates": [4.0, 209.63, 385.25, 294.38, 33.34]}, {"formula_id": "formula_14", "formula_text": "(h) recursive defined as k (h) recursive (G, G ) = h i=1 v\u2208V v \u2208V k i (v, v ),(8)", "formula_coordinates": [5.0, 208.92, 418.17, 295.08, 48.17]}, {"formula_id": "formula_15", "formula_text": "k i (v, v ) = \uf8f1 \uf8f2 \uf8f3 \u03b4(L(v), L (v )), if i = 1 k i\u22121 (v, v ) max R\u2208M(v,v ) (w,w )\u2208R k i\u22121 (w, w ), if i > 1 and M = \u2205 0, if i > 1 and M = \u2205(9)", "formula_coordinates": [5.0, 118.7, 480.91, 385.3, 34.41]}, {"formula_id": "formula_16", "formula_text": "M(v, v ) = {R \u2286 N (v) \u00d7 N (v )|(\u2200(u, u ), (w, w ) \u2208 R : u = w \u21d4 u = w ) \u2227(\u2200(u, u ) \u2208 R : L(u) = L (u ) \u2227 |R| = | N (v)| = | N (v )|)}(10)", "formula_coordinates": [5.0, 148.38, 534.96, 355.62, 24.45]}, {"formula_id": "formula_17", "formula_text": "k (1) W L = |{(s 1 (v), s 1 (v ))|f (s 1 (v)) = f (s 1 (v )), v \u2208 V, v \u2208 V }| = (11) = v\u2208V v \u2208V \u03b4(L(v), L (v )) = k (1)", "formula_coordinates": [5.0, 169.96, 601.27, 334.04, 40.93]}, {"formula_id": "formula_19", "formula_text": "Induction step h \u2192 h + 1: Assume that k (h) W L = k (h) recursive . Then k (h+1) recursive = v\u2208V v \u2208V k h+1 (v, v ) + h i=1 v\u2208V v \u2208V k i (v, v ) = (13) = |{(s h+1 (v), s h+1 (v ))|f (s h+1 (v)) = f (s h+1 (v )), v \u2208 V, v \u2208 V }| + k (h) W L = k (h+1) W L , (14", "formula_coordinates": [5.0, 108.0, 663.69, 396.0, 67.16]}, {"formula_id": "formula_20", "formula_text": ")", "formula_coordinates": [5.0, 499.85, 720.09, 4.15, 8.64]}], "doi": ""}