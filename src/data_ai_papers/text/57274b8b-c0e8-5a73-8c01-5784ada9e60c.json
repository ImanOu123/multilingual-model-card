{"title": "Graph Cut based Inference with Co-occurrence Statistics", "authors": "Lubor Ladicky; Chris Russell; Pushmeet Kohli; Philip H S Torr; Oxford Brookes; Microsoft Research", "pub_date": "", "abstract": "Markov and Conditional random fields (CRFs) used in computer vision typically model only local interactions between variables, as this is computationally tractable. In this paper we consider a class of global potentials defined over all variables in the CRF. We show how they can be readily optimised using standard graph cut algorithms at little extra expense compared to a standard pairwise field. This result can be directly used for the problem of class based image segmentation which has seen increasing recent interest within computer vision. Here the aim is to assign a label to each pixel of a given image from a set of possible object classes. Typically these methods use random fields to model local interactions between pixels or super-pixels. One of the cues that helps recognition is global object co-occurrence statistics, a measure of which classes (such as chair or motorbike) are likely to occur in the same image together. There have been several approaches proposed to exploit this property, but all of them suffer from different limitations and typically carry a high computational cost, preventing their application on large images. We find that the new model we propose produces an improvement in the labelling compared to just using a pairwise model.Class based image segmentation is a highly active area of computer vision research as is shown by a spate of recent publications [11,22,29,31,34]. In this problem, every pixel of the image is assigned a choice of object class label, such as grass, person, or dining table. Formulating this problem as a likelihood, in order to perform inference, is a difficult problem, as the cost or energy associated with any labelling of the image should take into account a variety of cues at different scales. A good labelling should take account of: low-level cues such as colour or texture [29], that govern the labelling of single pixels; mid-level cues such as region continuity, symmetry [23] or shape [2] that govern the assignment of regions within the image; and high-level statistics that encode inter-object relationships, such as which objects can occur together in a scene. This combination of cues makes for a multi-scale cost function that is difficult to optimise.", "sections": [{"heading": "", "text": "Current state of the art low-level approaches typically follow the methodology proposed in Texton-boost [29], in which weakly predictive features such as colour, location, and texton response are used to learn a classifier which provides costs for a single pixel taking a particular label. These costs are combined in a contrast sensitive Conditional Random Field CRF [19].\nThe majority of mid-level inference schemes [25,20] do not consider pixels directly, rather they assume that the image has been segmented into super-pixels [5,8,28]. A labelling problem is then defined over the set of regions. A significant disadvantage of such approaches is that mistakes in the initial over-segmentation, in which regions span multiple object classes, cannot be recovered from. To overcome this [10] proposed a method of reshaping super-pixels to recover from the errors, while the work [17] proposed a novel hierarchical framework which allowed for the integration of multiple region-based CRFs with a low-level pixel based CRF, and the elimination of inconsistent regions.\nThese approaches can be improved by the inclusion of costs based on high level statistics, including object class co-occurrence, which capture knowledge of scene semantics that humans often take for granted: for example the knowledge that cows and sheep are not kept together and less likely to appear in the same image; or that motorbikes are unlikely to occur near televisions. In this paper we consider object class co-occurrence to be a measure of how likely it is for a given set of object classes to occur together in an image. They can also be used to encode scene specific information such as the facts that computer monitors and stationary are more likely to occur in offices, or that trees and grass occur outside. The use of such costs can help prevent some of the most glaring failures in object class segmentation, such as the labelling of a cow as half cow and half sheep, or the mistaken labelling of a boat surrounded by water as a book.\nAs well as penalising strange combinations of objects appearing in an image, cooccurrence potentials can also be used to impose an MDL 1 prior that encourages a parsimonious description of an image using fewer labels. As discussed eloquently in the recent work [4], the need for a bias towards parsimony becomes increasingly important as the number of classes to be considered increases.\nFigure 1 illustrates the importance of co-occurrence statistics in image labelling. The promise of co-occurrence statistics has not been ignored by the vision community. In [22] Rabinovich et al. proposed the integration of such co-occurrence costs that characterise the relationship between two classes. Similarly Torralba et al. [31] proposed scene-based costs that penalised the existence of particular classes in a context dependent manner. We shall discuss these approaches, and some problems with them in the next section.", "publication_ref": ["b28", "b18", "b24", "b19", "b4", "b7", "b27", "b9", "b16", "b0", "b3", "b21", "b30"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "CRFs and Co-occurrence", "text": "A conventional CRF is defined over a set of random variables V = {1, 2, 3, . . . , n} where each variable takes a value from the label set L = {l 1 , l 2 , . . . , l k } corresponding  [17] that does not take into account co-occurrence; (c) A labelling of the same model using co-occurrence statistics. The use of co-occurrence statistics to guide the segmentation results in a labelling that is more parsimonious and more likely to be correct. These co-occurrence statistics suppress the appearance of small unexpected classes in the labelling. Top left: a mistaken hypothesis of a cow is suppressed Top right: Many small classes are suppressed in the image of a building. Note that the use of co-occurrence typically changes labels, but does not alter silhouettes.\nto the set of object classes. An assignment of labels to the set of random variables will be referred to as a labelling, and denoted as x \u2208 L |V| . We define a cost function E(x) over the CRF of the form:\nE(x) = c\u2208C \u03c8 c (x c )(1)\nwhere the potential \u03c8 c is a cost function defined over a set of variables (called a clique) c, and x c is the state of the set of random variables that lie within c. The set C of cliques is a subset of the power set of V, i.e. C \u2286 P (V). In the majority of vision problems, the potentials are defined over a clique of size at most 2. Unary potentials are defined over a clique of size one, and typically based upon classifier responses (such as ada-boost [29] or kernel SVMs [27]), while pairwise potentials are defined over cliques of size two and model the correlation between pairs of random variables.", "publication_ref": ["b16", "b28", "b26"], "figure_ref": [], "table_ref": []}, {"heading": "Incorporating Co-occurrence Potentials", "text": "To model object class co-occurrence statistics a new term K(x) is added to the energy:\nE(x) = \u03c8 c (x c ) + K(x).(2)\nThe question naturally arises as to what form an energy involving co-occurrence terms should take. We now list a set of desiderata that we believe are intuitive for any cooccurrence cost.\n(i) Global Energy: We would like a formulation of co-occurrence that allows us to estimate the segmentation using all the data directly, by minimising a single cost function of the form (2). Rather than any sort of two stage process in which a hard decision is made of which objects are present in the scene a priori as in [31].\n(ii) Invariance: The co-occurrence cost should depend only on the labels present in an image, it should be invariant to the number and location of pixels that object occupies. To reuse an example from [32], the surprise at seeing a polar bear in a street scene should not not vary with the number of pixels that represent the bear in the image.\n(iii) Efficiency: Inference should be tractable, i.e. the use of co-occurrence should not be the bottle-neck preventing inference. As the memory requirements of any conventional inference algorithm [30] is typically O(|V|) for vision problems, the memory requirements of a formulation incorporating co-occurrence potentials should also be O(|V|).\n(iv) Parsimony: The cost should follow the principle of parsimony in the following way: if several solutions are almost equally likely then the solution that can describe the image using the fewest distinct labels should be chosen. Whilst this might not seem important when classifying pixels into a few classes, as the set of putative labels for an image increases the chance of speckle noise due to misclassification will increase unless a parsimonious solution is encouraged.\nWhile these properties seem uncontroversial, no prior work exhibits property (ii). Similarly, no approaches satisfy properties (i) and (iii) simultaneously. In order to satisfy condition (ii) the co-occurrence cost K(x) defined over x must be a function defined on the set of labels L(x) = {l \u2208 L : \u2203x i = l} present in the labelling x; this guarantees invariance to the size of an object:\nK(x) = C(L(x))(3)\nEmbedding the co-occurrence term in the CRF cost function (1), we have:\nE(x) = c\u2208C \u03c8 c (x c ) + C(L(x)).(4)\nTo satisfy the parsimony condition (iv) potentials must act to penalise the unexpected appearance of combinations of labels in a labelling. This observation can be formalised as the statement that the cost C(L) monotonically increasing with respect to the label set L i.e. :\nL 1 \u2282 L 2 =\u21d2 C(L 1 ) \u2264 C(L 2 ).(5)\nThe new potential C(L(x)) can be seen as a particular higher order potential defined over a clique which includes the whole of V, i.e. \u03c8 V (x).", "publication_ref": ["b1", "b30", "b31", "b29"], "figure_ref": [], "table_ref": []}, {"heading": "Prior Work", "text": "There are two existing approaches to co-occurrence potentials, neither of which uses potentials defined over a clique of size greater than two. The first makes an initial hard estimate of the type of scene, and updates the unary potentials associated with each pixel to encourage or discourage particular choices of label, on the basis of how likely they are to occur in the scene. The second approach models object co-occurrence as a pairwise potential between regions of the image. Torralba et al. [31] proposed the use of additional unary potentials to capture scene based occurrence priors. Their costs took the form:\nK(x) = i\u2208V \u03c6(x i ).(6)\nWhile the complexity of inference over such potentials scales linearly with the size of the graph, they are prone to over counting costs, violating (ii), and require an initial hard decision of scene type before inference, which violates (i). As it encourages the appearance of all labels which are common to a scene, it does not necessarily encourage parsimony (iv).\nA similar approach was seen in the Pascal VOC2008 object segmentation challenge, where the best performing method, by Csurka [6], worked in two stages. Initially the set of object labels present in the image was estimated, and in the second stage, a label from the estimated label set was assigned to each image pixel. As no cost function K(\u2022) was proposed, it is open to debate if it satisfied (ii) or (iv).", "publication_ref": ["b30", "b5"], "figure_ref": [], "table_ref": []}, {"heading": "Method", "text": "Global energy (i)\nInvariance (ii) Efficiency (iii) Parsimony (iv)\nUnary [31] Pairwise [22,9,32] Csurka [6] --Our approach Fig. 2. A comparison of the capabilities of existing image co-occurrence formulations against our new approach. See section 2.2 for details.\nRabinovich et al. [9,22], and independently [32], proposed co-occurrence as a soft constraint that approximated C(L(x)) as a pairwise cost defined over a fully connected graph that took the form:\nK(x) = i,j\u2208V \u03c6(x i , x j ),(7)\nwhere \u03c6 was some potential which penalised labels that should not occur together in an image. Unlike our model (4) the penalty cost for the presence of pairs of labels, that rarely occur together, appearing in the same image grows with the number of random variables taking these labels, violating assumption (ii). While this serves as a functional penalty that prevents the occurrence of many classes in the same labelling, it does not accurately model the co-occurrence costs we described earlier. The memory requirements of inference scales badly with the size of a fully connected graph. It grows with complexity O(|V| 2 ) rather than O(|V|) with the size of the graph, violating constraint (iii). Providing the pairwise potentials are semi-metric [3], it does satisfy the parsimony condition (iv).\nTo minimise these difficulties, previous approaches defined variables over segments rather than pixels. Such segment based methods work under the assumption that some segments share boundaries with objects in the image. This is not always the case, and this assumption may result in dramatic errors in the labelling. The relationship between previous approaches and the desiderata can be seen in figure 2.\nTwo efficient schemes [7,12] have been proposed for the minimisation of the number of classes or objects present in a scene. While neither of them directly models class based co-occurrence relationships, their optimisation approaches do satisfy our desiderata.\nOne such approach was proposed by Hoiem et al. [12], who used a cost based on the number of objects in the scene, in which the presence of any instance of any object incurs a uniform penalty cost. For example, the presence of both a motorbike and a bus in a single image is penalised as much as the presence of two buses. Minimising the number of objects in a scene is a good method of encouraging consistent labellings, but does not capture any co-occurrence relationship between object classes.\nIn a recent work, appearing at the same time as ours, Delong et al. [7] proposed the use of a soft cost over the number of labels present in an image for clustering. While the mathematical formulation they propose is more flexible than this, they do not suggest any applications of this increased flexibility. Moreover, their formulation is less general than ours as it does not support the full range of monotonically increasing label set costs.", "publication_ref": ["b30", "b21", "b8", "b31", "b5", "b8", "b21", "b31", "b2", "b6", "b11", "b11", "b6"], "figure_ref": [], "table_ref": []}, {"heading": "Inference on global co-occurrence potentials", "text": "Consider the energy (4) defined in section 2.1. The inference problem becomes:\nx * = arg min x\u2208L |V| c\u2208C \u03c8 c (x c ) + C(L(x)) s.t. x \u2208 L |V| , L(x) = {l \u2208 L : \u2203x i = l}.(8)\nIn the general case the problem of minimising this energy can be reformulated as an integer program and approximately solved as an LP-relaxation [16]. This LP-formulation can be transformed using a Lagrangian relaxation into a pairwise energy, allowing algorithms, such as Belief Propagation [33] or TRW-S [14], that can minimise arbitrary pairwise energies to be applied [16]. However, reparameterisation methods such as these perform badly on densely connected graphs [15,26].\nIn this section we show that under assumption, that C(L) is monotonically increasing with respect to L, the problem can be solved efficiently using \u03b1\u03b2-swap and \u03b1expansion moves [3], where the number of additional edges of the graph grows linearly with the number of variables in the graph. In contrast to [22], these algorithms can be applied to large graphs with more than 200, 000 variables.\nMove making algorithms project the problem into a smaller subspace in which a sub-problem is efficiently solvable. Solving this sub-problem proposes optimal moves which guarantee that the energy decreases after each move and must eventually converge. The performance of move making algorithms depends dramatically on the size of the move space. The expansion and swap move algorithms we consider project the problem into two label sub-problem and under the assumption that the projected energy is pairwise and submodular, it can be solved using graph cuts. Because the energy (4) is additive, we derive graph constructions only for term C(L(x)). Both the application of swap and expansion moves to minimise the energy, and the graph construction for the other terms proceed as described in [3].", "publication_ref": ["b15", "b32", "b13", "b15", "b14", "b25", "b2", "b21", "b2"], "figure_ref": [], "table_ref": []}, {"heading": "\u03b1\u03b2-Swap Moves", "text": "The swap and expansion move algorithms can be encoded as a vector of binary variables t ={t i , \u2200i \u2208 V}. The transformation function T (x p , t) of a move algorithm takes the current labelling x p and a move t and returns the new labelling x which has been induced by the move.\nIn an \u03b1\u03b2-swap move every random variable x i whose current label is \u03b1 or \u03b2 can transition to a new label of \u03b1 or \u03b2. One iteration of the algorithm involves making moves for all pairs (\u03b1, \u03b2) in L 2 successively. The transformation function T \u03b1\u03b2 (x i , t i ) for an \u03b1\u03b2-swap transforms the label of a random variable x i as:\nT \u03b1\u03b2 (x i , t i ) = \u03b1 if x i = \u03b1 or \u03b2 and t i = 0, \u03b2 if x i = \u03b1 or \u03b2 and t i = 1.(9)\nConsider a swap move over the labels \u03b1 and \u03b2, starting from an initial label set L(x). We assume that either \u03b1 or \u03b2 is present in the image. Then, after a swap move the labels present must be an element of S which we define as:\nS = {L(x) \u222a {\u03b1} \\ {\u03b2}, L(x) \u222a {\u03b2} \\ {\u03b1}, L(x) \u222a {\u03b1, \u03b2}} .(10)\nLet V \u03b1\u03b2 be the set of variables currently taking label \u03b1 or \u03b2. The move energy for C(L(x)) is:\nE(t) = \uf8f1 \uf8f2 \uf8f3 C \u03b1 = C(L(x) \u222a {\u03b1} \\ {\u03b2}) if \u2200i \u2208 V \u03b1\u03b2 , t i = 0, C \u03b2 = C(L(x) \u222a {\u03b2} \\ {\u03b1}) if \u2200i \u2208 V \u03b1\u03b2 , t i = 1, C \u03b1\u03b2 = C(L(x) \u222a {\u03b1, \u03b2}) otherwise. (11\n)\nNote that, if C(L) is monotonically increasing with respect to L then, by definition, C \u03b1 \u2264 C \u03b1\u03b2 and C \u03b2 \u2264 C \u03b1\u03b2 .\nLemma 1. For a function C(L), monotonically increasing with respect to L, the move energy can be represented as a binary submodular pairwise cost with two auxiliary variables z \u03b1 and z \u03b2 as:\nE(t) = C \u03b1 + C \u03b2 \u2212 C \u03b1\u03b2 + min z\u03b1,z \u03b2 (C \u03b1\u03b2 \u2212 C \u03b1 )z \u03b2 + (C \u03b1\u03b2 \u2212 C \u03b2 )(1 \u2212 z \u03b1 ) + i\u2208V \u03b1\u03b2 (C \u03b1,\u03b2 \u2212 C \u03b1 )t i (1 \u2212 z \u03b2 ) + i\u2208V \u03b1\u03b2 (C \u03b1\u03b2 \u2212 C \u03b2 )(1 \u2212 t i )z \u03b1 ) .(12)\nProof. See appendix. This binary function is pairwise submodular and thus can be solved efficiently using graph cuts.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "\u03b1-Expansion Moves", "text": "In an \u03b1-expansion move every random variable can either retain its current label or transition to label \u03b1. One iteration of the algorithm involves making moves for all \u03b1 in L successively. The transformation function T \u03b1 (x i , t i ) for an \u03b1-expansion move transforms the label of a random variable x i as:\nT \u03b1 (x i , t i ) = \u03b1 if t i = 0 x i if t i = 1. (13\n)\nTo derive a graph-construction that approximates the true cost of an \u03b1-expansion move we rewrite C(L) as:\nC(L) = B\u2286L k B ,(14)\nwhere the coefficients k B are calculated recursively as:\nk B = C(B) \u2212 B \u2282B k B . (15\n)\nAs a simplifying assumption, let us first assume there is no variable currently taking label \u03b1. Let A be set of labels currently present in the image and \u03b4 l (t) be set to 1 if label l is present in the image after the move and 0 otherwise. Then:\n\u03b4 \u03b1 (t) = 1 if \u2203i \u2208 V s.t. t i = 0, 0 otherwise. (16\n)\n\u2200l \u2208 A , \u03b4 l (t) = 1 if \u2203i \u2208 V l s.t. t i = 1, 0 otherwise. (17\n)\nThe \u03b1-expansion move energy of C(L(x)) can be written as:\nE(t) = E new (t) \u2212 E old = B\u2286A\u222a{\u03b1} k B l\u2208B \u03b4 l (t) \u2212 C(A).\nIgnoring the constant term and decomposing the sum into parts with and without terms dependent on \u03b1 we have:\nE(t) = B\u2286A k B l\u2208B \u03b4 l (t) + B\u2286A k B\u222a{\u03b1} \u03b4 \u03b1 (t) l\u2208B \u03b4 l (t).(18)\nAs either \u03b1 or all subsets B \u2286 A are present after any move, the following statement holds:\n\u03b4 \u03b1 (t) l\u2208B \u03b4 l (t) = \u03b4 \u03b1 (t) + l\u2208B \u03b4 l (t) \u2212 1. (19\n)\nReplacing the term \u03b4 \u03b1 (t) l\u2208B \u03b4 l (t) and disregarding new constant terms, equation (18) becomes:\nE(t) = B\u2286A k B\u222a{\u03b1} \u03b4 \u03b1 (t)+ B\u2286A (k B +k B\u222a{\u03b1} ) l\u2208B \u03b4 l (t) = k \u03b1 \u03b4 \u03b1 (t)+ B\u2286A k B l\u2208B \u03b4 l (t), (20\n) where k \u03b1 = B\u2286A k B\u222a{\u03b1} = C(B \u222a {\u03b1}) \u2212 C(B) and k B = k B + k B\u222a{\u03b1} .\nE(t) is, in general, a higher-order non-submodular energy, and intractable. However, when proposing moves we can use the procedure described in [21,24] and overestimate second term K(A, t) = B\u2286A k B l\u2208B \u03b4 l (t) of the cost of moving from the current solution.\nFor any l \u2208 A we can overestimate K(A, t) by\nK(A, t) \u2264 K(A \\ {l }, t) + \u03b4 l (t) min S\u2286A\\{l } B\u2286S (k B\u222a{l } \u2212 k B ) = K(A \\ {l }, t) + k l \u03b4 l (t),(21)\nwhere k (l ) is always non-negative for all C(L) that are monotonically increasing with respect to L. By applying this decomposition iteratively for any ordering of labels l \u2208 A we obtain :\nK(A, t) \u2264 K + l\u2208A k l \u03b4 l (t).(22)\nThe constant term K can be ignored, because it does not affect the optimality of the move. Heuristically we pick l in each iteration as\nl = arg min l\u2208A min S\u2286A\\{l} B\u2286S (k B\u222a{l} \u2212 k B ).(23)\nFig. 3. Graph construction for \u03b1\u03b2-swap and \u03b1-expansion move. In \u03b1\u03b2-swap variable xi will take the label \u03b1 if corresponding ti are tied to the sink after the st-mincut and \u03b2 otherwise. In \u03b1-expansion variable xi changes the label to \u03b1 if it is tied to the sink after the st-mincut and remains the same otherwise. Colours represent the label of the variables before the move.\nLemma 2. For all C(L) monotonically increasing with respect to L the move energy can be represented as a binary pairwise graph with |A| auxiliary variables z as:  [17] that does not take into account co-occurrence; (c) A labelling of the same model using co-occurrence statistics. Note that the co-occurrence potentials perform in a similar way across different data sets, suppressing the smaller classes (see also figure 1) if they appear together in an uncommon combination with other classes such as a car with a monitor, a train with a chair or a dog with a bird. This results in a qualitative rather than quantitative difference.\nE (t) = min z k \u03b1 (1\u2212z \u03b1 )+ l\u2208A k l z l + i\u2208V k \u03b1 (1\u2212t i )z \u03b1 + l\u2208A i\u2208V l k l t i (1\u2212z l ) ,(24)\nwhere V l is the set of pixels currently taking label l.\nProof. See appendix. This binary function is pairwise submodular and thus can be solved efficiently using graph cuts. For co-occurrence potentials monotonically increasing with respect to L(x) the problem can be modelled using one binary variable z l per class indicating the presence of pixels of that class in the labelling, infinite edges for x i = l and z l = 0 and hyper-graph over all z l modelling C(L(x)). The derived \u03b1-expansion construction can be seen as a graph taking into account costs over all auxiliary variables z l for each move and over-estimating the hyper-graph energy using unary potentials. Note that the energy approximation is exact, unless existing classes are removed from the labelling. Consequentially, the only effect our approximation can have on the final labelling is to over estimate the number of classes present in an image. In practice the solutions found by expansion were generally local optima of the exact swap moves.", "publication_ref": ["b17", "b20", "b23", "b16"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Experiments", "text": "We performed a controlled test evaluating the performance of CRF models both with and without co-occurrence potentials. As a base line we used the segment-based CRF and the associative hierarchical random field (AHRF) model proposed in [17] and the inference method [26], which currently offers state of the art performance on the MSRC data set [29]. On the VOC data set, the baseline also makes use of the detector potentials of [18]. The costs C(L) were created from the training set as follows: let M be the number of images, x (m) the ground truth labelling of an image m and\nz (m) l = \u03b4(l \u2208 L(x (m) ))(25)\nan indicator function for label l appearing in an image m. The associated cost was trained as:\nC(L) = \u2212w log 1 M 1 + M m=1 l\u2208L z (m) l , (26\n)\nwhere w is the weight of the co-occurrence potential. The form guarantees, that C(L) is monotonically increasing with respect to L. To avoid over-fitting we approximated the potential C(L) as a second order function:\nC (L) = l\u2208L c l + k,l\u2208L,k<l c kl ,(27)\nwhere c l and c lk minimise the mean-squared error between C(L) and C (L).\nOn the MSRC data set we observed a 3% overall and 4% average per class increase in the recall and 6% in the intersection vs. union measure with the of the segmentbased CRF and a 1% overall, 2% average per class and 2% in the intersection vs. union measure with the AHRF. The comparison on the VOC2009 data set was performed on the validation set, as the test set is not published and the number of permitted submissions is limited. Performance improved by 3.5% in the intersection vs. union measure used in the challenge. The performance on the test set was 32.11% which is comparable with current state-of-the-art methods. Results for both data sets are given in tables 5 and 6.\nBy adding a co-occurrence cost into the CRF we observe constant improvement in pixel classification for almost all classes in all measures. In accordance with desiderata (iv), the co-occurrence potentials tend to suppress uncommon combination of classes and produce more coherent images in the labels space. This results in a qualitative rather than quantitative difference. Although the unary potentials already capture textural context [29], the incorporation of co-occurrence potentials leads to a significant improvement in accuracy.\nIt is not computationally feasible to perform a direct comparison between the work [22] and our potentials, as the AHRF model is defined over individual pixels, and it is not possible to minimise the resulting fully connected graph which would contain approximately 4 \u00d7 10 10 edges. Similarly, without their scene classification potentials it was not possible to do a like for like comparison with [31].\nAverage running time on the MSRC data set without co-occurrence was 5.1s in comparison to 16.1s with co-occurrence cost. On the VOC2009 data set the average times were 107s and 388s for inference without respectively with co-occurrence costs. We compared the performance of \u03b1-expansion with LP relaxation using solver given in [1] for general co-occurrence potential on the sub-sampled images [16]. Both methods produced similar results in terms of energy, however \u03b1-expansion was approximately 42, 000 times faster.", "publication_ref": ["b16", "b25", "b28", "b17", "b28", "b21", "b30", "b0", "b15"], "figure_ref": [], "table_ref": []}, {"heading": "Conclusion", "text": "The importance of co-occurrence statistics has been well established [31,22,6]. In this work we have examined the use of co-occurrence statistics and how they might be incorporated into a global energy or likelihood model such as a conditional random field. We  have discovered that they can naturally be encoded by the use of higher order cliques, without a significant computational overhead. Our new framework provides significant advantages over state of the art approaches including efficient scalable inference. We performed a controlled test evaluating the performance of CRF models both with and without co-occurrence potentials and the incorporation of these potentials results in quantitatively better and visually more coherent labellings.", "publication_ref": ["b30", "b21", "b5"], "figure_ref": [], "table_ref": []}, {"heading": "Appendix", "text": "Lemma 1 Proof. First we show that:\nand the minimum cost cost 0 occurs when z \u03b1 = 1. If \u2203i \u2208 V \u03b1\u03b2 , t i = 0 the minimum cost labelling occurs when z \u03b1 = 0 and the minimum cost is C \u03b1\u03b2 \u2212 C \u03b2 .\nSimilarly:\nand the minimum cost cost 0 occurs when z \u03b2 = 0. If \u2203i \u2208 V \u03b1\u03b2 , t i = 1 the minimum cost labelling occurs when z \u03b2 = 1 and the minimum cost is C \u03b1\u03b2 \u2212 C \u03b1 . For all three cases (all pixels take label \u03b1, all pixels take label \u03b2 and mixed labelling)\nThe construction of the \u03b1\u03b2-swap move is similar to the Robust P N model [13]. See figure 3 for graph construction.\nLemma 2 Proof. Similarly to the \u03b1\u03b2-swap proof we can show:\nIf \u2203i \u2208 Vs.t.t i = 0, then i\u2208V k \u03b1 (1 \u2212 t i ) \u2265 k \u03b1 , the minimum is reached when z \u03b1 = 0 and the cost is k \u03b1 . If \u2200i \u2208 V : t i = 1 then k \u03b1 (1 \u2212 t i )z \u03b1 = 0, the minimum is reached when z \u03b1 = 1 and the cost becomes 0. For all other l \u2208 A:\nIf \u2203i \u2208 V l s.t. t i = 1, then i\u2208V l k l t i \u2265 k l , the minimum is reached when z l = 1 and the cost is k l . If \u2200i \u2208 V l : t i = 0 then i\u2208V l k l t i (1 \u2212 z l ) = 0, the minimum is reached when z l = 1 and the cost becomes 0. By summing up the cost E \u03b1 (t) and |A| costs E l (t) we get E (t) = E \u03b1 (t) +\nl\u2208A E l (t). If \u03b1 is already present in the image k \u03b1 = 0 and edges with this weight and variable z \u03b1 can be ignored. See figure 3 for graph construction.", "publication_ref": ["b12"], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "An exact primal-dual penalty method approach to warmstarting interior-point methods for linear programming", "journal": "Comput. Optim. Appl", "year": "2007", "authors": "H Y Benson; D F Shanno"}, {"ref_id": "b1", "title": "Shape guided object segmentation", "journal": "", "year": "2006", "authors": "E Borenstein; J Malik"}, {"ref_id": "b2", "title": "Fast approximate energy minimization via graph cuts. PAMI", "journal": "", "year": "2001", "authors": "Y Boykov; O Veksler; R Zabih"}, {"ref_id": "b3", "title": "Exploiting hierarchical context on a large database of object categories", "journal": "", "year": "2010", "authors": "M J Choi; J J Lim; A Torralba; A S Willsky"}, {"ref_id": "b4", "title": "Mean shift: A robust approach toward feature space analysis", "journal": "PAMI", "year": "2002", "authors": "D Comaniciu; P Meer"}, {"ref_id": "b5", "title": "A simple high performance approach to semantic segmentation", "journal": "", "year": "2008", "authors": "G Csurka; F Perronnin"}, {"ref_id": "b6", "title": "Fast approximate energy minimization with label costs", "journal": "CVPR", "year": "2010", "authors": "A Delong; A Osokin; H Isack; Y Boykov"}, {"ref_id": "b7", "title": "Efficient graph-based image segmentation", "journal": "IJCV", "year": "2004", "authors": "P F Felzenszwalb; D P Huttenlocher"}, {"ref_id": "b8", "title": "Object categorization using co-occurrence, location and appearance", "journal": "", "year": "2008", "authors": "C Galleguillos; A Rabinovich; S Belongie"}, {"ref_id": "b9", "title": "Decomposing a scene into geometric and semantically consistent regions", "journal": "", "year": "2009", "authors": "S Gould; R Fulton; D Koller"}, {"ref_id": "b10", "title": "Learning spatial context: Using stuff to find things", "journal": "", "year": "2008", "authors": "D K G Heitz"}, {"ref_id": "b11", "title": "3d layoutcrf for multi-view object class recognition and segmentation", "journal": "", "year": "2007", "authors": "D Hoiem; C Rother; J M Winn"}, {"ref_id": "b12", "title": "Robust higher order potentials for enforcing label consistency", "journal": "", "year": "2008", "authors": "P Kohli; L Ladicky; P Torr"}, {"ref_id": "b13", "title": "Convergent tree-reweighted message passing for energy minimization. PAMI", "journal": "", "year": "2006", "authors": "V Kolmogorov"}, {"ref_id": "b14", "title": "Comparison of energy minimization algorithms for highly connected graphs", "journal": "", "year": "2006", "authors": "V Kolmogorov; C C Rother"}, {"ref_id": "b15", "title": "Graph Cut based Inference with Co-occurrence Statistics", "journal": "", "year": "2010", "authors": "L Ladicky; C Russell; P Kohli; P Torr"}, {"ref_id": "b16", "title": "Associative hierarchical crfs for object class image segmentation", "journal": "", "year": "2009", "authors": "L Ladicky; C Russell; P Kohli; P H Torr"}, {"ref_id": "b17", "title": "What, where and how many? Combining object detectors and CRFs. ECCV", "journal": "", "year": "2010", "authors": "L Ladicky; C Russell; P Sturgess; K Alahari; P Torr"}, {"ref_id": "b18", "title": "Conditional random fields: Probabilistic models for segmenting and labelling sequence data", "journal": "", "year": "2001", "authors": "J Lafferty; A Mccallum; F Pereira"}, {"ref_id": "b19", "title": "Combining appearance models and markov random fields for category level object segmentation", "journal": "", "year": "2008", "authors": "D Larlus; F Jurie"}, {"ref_id": "b20", "title": "A submodular-supermodular procedure with applications to discriminative structure learning", "journal": "", "year": "2005", "authors": "M Narasimhan; J A Bilmes"}, {"ref_id": "b21", "title": "Objects in context", "journal": "", "year": "2005", "authors": "A Rabinovich; A Vedaldi; C Galleguillos; E Wiewiora; S Belongie"}, {"ref_id": "b22", "title": "Mid-level cues improve boundary detection", "journal": "", "year": "2001", "authors": "X Ren; C Fowlkes; J Malik"}, {"ref_id": "b23", "title": "Digital tapestry", "journal": "", "year": "2005", "authors": "C Rother; S Kumar; V Kolmogorov; A Blake"}, {"ref_id": "b24", "title": "Using multiple segmentations to discover objects and their extent in image collections", "journal": "", "year": "2006", "authors": "B Russell; W Freeman; A Efros; J Sivic; A Zisserman"}, {"ref_id": "b25", "title": "Exact and approximate inference in associative hierarchical networks using graph cuts", "journal": "UAI", "year": "2010", "authors": "C Russell; L Ladicky; P Kohli; P Torr"}, {"ref_id": "b26", "title": "Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond. Adaptive Computation and Machine Learning", "journal": "MIT Press", "year": "2001", "authors": "B Schlkopf; A J Smola"}, {"ref_id": "b27", "title": "Normalized cuts and image segmentation. PAMI", "journal": "", "year": "2000", "authors": "J Shi; J Malik"}, {"ref_id": "b28", "title": "TextonBoost: Joint appearance, shape and context modeling for multi-class object recognition and segmentation", "journal": "", "year": "2003", "authors": "J Shotton; J Winn; C Rother; A Criminisi"}, {"ref_id": "b29", "title": "A comparative study of energy minimization methods for markov random fields", "journal": "", "year": "2006", "authors": "R Szeliski; R Zabih; D Scharstein; O Veksler; V Kolmogorov; A Agarwala; M Tappen; C Rother"}, {"ref_id": "b30", "title": "Context-based vision system for place and object recognition", "journal": "", "year": "2003", "authors": "A Torralba; K P Murphy; W T Freeman; M A Rubin"}, {"ref_id": "b31", "title": "Random field model for integration of local information and global information", "journal": "PAMI", "year": "2008", "authors": "T Toyoda; O Hasegawa"}, {"ref_id": "b32", "title": "On the optimality of solutions of the max-product beliefpropagation algorithm in arbitrary graphs", "journal": "Transactions on Information Theory", "year": "2001", "authors": "Y Weiss; W Freeman"}, {"ref_id": "b33", "title": "Multiple class segmentation using a unified framework over mean-shift patches", "journal": "", "year": "2007", "authors": "L Yang; P Meer; D J Foran"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Fig. 1 .1Fig. 1. Best viewed in colour: Qualitative results of object co-occurrence statistics. (a) Typical images taken from the MSRC data set [29]; (b) A labelling based upon a pixel based random field model[17] that does not take into account co-occurrence; (c) A labelling of the same model using co-occurrence statistics. The use of co-occurrence statistics to guide the segmentation results in a labelling that is more parsimonious and more likely to be correct. These co-occurrence statistics suppress the appearance of small unexpected classes in the labelling. Top left: a mistaken hypothesis of a cow is suppressed Top right: Many small classes are suppressed in the image of a building. Note that the use of co-occurrence typically changes labels, but does not alter silhouettes.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Fig. 4 .4Fig. 4. Best viewed in colour: (a) Typical images taken from the VOC-2009 data set [29]; (b) A labelling based upon a pixel based random field model[17] that does not take into account co-occurrence; (c) A labelling of the same model using co-occurrence statistics. Note that the co-occurrence potentials perform in a similar way across different data sets, suppressing the smaller classes (see also figure1) if they appear together in an uncommon combination with other classes such as a car with a monitor, a train with a chair or a dog with a bird. This results in a qualitative rather than quantitative difference.", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Fig. 5 .5Fig. 5. Quantitative results on the MSRC data set, average per class recall measure, defined as", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "96 87 72 84 100 77 92 86 87 87 95 95 27 85 33 93 43 80 62 17 Hierarchical CRF with CO 87 77 82 95 88 73 88 100 83 92 88 87 88 96 96 27 85 37 93 49 80 65 20Fig. 6. Quantitative analysis of VOC2009 results on validation set, intersection vs. union measure, defined as True Positive True Positive + False Negative + False Positive . Incorporation of co-occurrence potential led to labellings, which visually look more coherent, but are not necessarily correct. Quantitatively the performance improved significantly, on average by 3.5% per class. 77.7 38.3 9.6 24.0 35.8 31.0 59.2 36.5 21.2 8.3 1.7 22.7 14.3 17.0 26.7 21.1 15.5 16.3 14.6 48.5 33.1 Hierarchical CRF with CO 30.8 82.3 49.3 11.8 19.3 37.7 30.8 63.2 46.0 23.7 10.0 0.5 23.1 14.1 22.4 33.9 35.7 18.4 12.1 22.5 53.1 37.5", "figure_data": "GlobalAverageBuildingGrassTreeCowSheepSkyAeroplaneWaterFaceCarBicycleFlowerSignBirdBookChairRoadCatDogBodyBoatSegment CRF77 64 70 95 78 55 76 95 63 81 76 67 72 73 82 35 72 17 88 29 62 45 17Segment CRF with CO80 68 77 96 80 69 82 98 69 82 79 75 75 81 85 35 76 17 89 25 61 50 22Hierarchical CRF86 75 81 Average Background AeroplaneBicycleBirdBoatBottleBusCarCatChairCowDining tableDogHorseMotor bikePersonPotted plantSheepSofaTrainTV/monitorHierarchical CRF27.3"}], "formulas": [{"formula_id": "formula_0", "formula_text": "E(x) = c\u2208C \u03c8 c (x c )(1)", "formula_coordinates": [3.0, 267.95, 364.22, 212.64, 20.06]}, {"formula_id": "formula_1", "formula_text": "E(x) = \u03c8 c (x c ) + K(x).(2)", "formula_coordinates": [3.0, 248.99, 537.19, 231.6, 9.65]}, {"formula_id": "formula_2", "formula_text": "K(x) = C(L(x))(3)", "formula_coordinates": [4.0, 271.47, 341.62, 209.12, 8.96]}, {"formula_id": "formula_3", "formula_text": "E(x) = c\u2208C \u03c8 c (x c ) + C(L(x)).(4)", "formula_coordinates": [4.0, 242.4, 384.91, 238.19, 20.06]}, {"formula_id": "formula_4", "formula_text": "L 1 \u2282 L 2 =\u21d2 C(L 1 ) \u2264 C(L 2 ).(5)", "formula_coordinates": [4.0, 241.37, 465.84, 239.22, 9.65]}, {"formula_id": "formula_5", "formula_text": "K(x) = i\u2208V \u03c6(x i ).(6)", "formula_coordinates": [4.0, 268.8, 647.67, 211.8, 20.06]}, {"formula_id": "formula_6", "formula_text": "Invariance (ii) Efficiency (iii) Parsimony (iv)", "formula_coordinates": [5.0, 308.74, 274.87, 122.99, 18.53]}, {"formula_id": "formula_7", "formula_text": "K(x) = i,j\u2208V \u03c6(x i , x j ),(7)", "formula_coordinates": [5.0, 258.9, 455.46, 221.69, 20.06]}, {"formula_id": "formula_8", "formula_text": "x * = arg min x\u2208L |V| c\u2208C \u03c8 c (x c ) + C(L(x)) s.t. x \u2208 L |V| , L(x) = {l \u2208 L : \u2203x i = l}.(8)", "formula_coordinates": [6.0, 211.4, 375.69, 269.19, 28.57]}, {"formula_id": "formula_9", "formula_text": "T \u03b1\u03b2 (x i , t i ) = \u03b1 if x i = \u03b1 or \u03b2 and t i = 0, \u03b2 if x i = \u03b1 or \u03b2 and t i = 1.(9)", "formula_coordinates": [7.0, 216.3, 246.5, 264.29, 21.61]}, {"formula_id": "formula_10", "formula_text": "S = {L(x) \u222a {\u03b1} \\ {\u03b2}, L(x) \u222a {\u03b2} \\ {\u03b1}, L(x) \u222a {\u03b1, \u03b2}} .(10)", "formula_coordinates": [7.0, 183.22, 327.25, 297.37, 8.96]}, {"formula_id": "formula_11", "formula_text": "E(t) = \uf8f1 \uf8f2 \uf8f3 C \u03b1 = C(L(x) \u222a {\u03b1} \\ {\u03b2}) if \u2200i \u2208 V \u03b1\u03b2 , t i = 0, C \u03b2 = C(L(x) \u222a {\u03b2} \\ {\u03b1}) if \u2200i \u2208 V \u03b1\u03b2 , t i = 1, C \u03b1\u03b2 = C(L(x) \u222a {\u03b1, \u03b2}) otherwise. (11", "formula_coordinates": [7.0, 184.93, 382.19, 291.52, 35.52]}, {"formula_id": "formula_12", "formula_text": ")", "formula_coordinates": [7.0, 476.44, 396.52, 4.15, 8.64]}, {"formula_id": "formula_13", "formula_text": "E(t) = C \u03b1 + C \u03b2 \u2212 C \u03b1\u03b2 + min z\u03b1,z \u03b2 (C \u03b1\u03b2 \u2212 C \u03b1 )z \u03b2 + (C \u03b1\u03b2 \u2212 C \u03b2 )(1 \u2212 z \u03b1 ) + i\u2208V \u03b1\u03b2 (C \u03b1,\u03b2 \u2212 C \u03b1 )t i (1 \u2212 z \u03b2 ) + i\u2208V \u03b1\u03b2 (C \u03b1\u03b2 \u2212 C \u03b2 )(1 \u2212 t i )z \u03b1 ) .(12)", "formula_coordinates": [7.0, 158.94, 517.83, 321.66, 48.63]}, {"formula_id": "formula_14", "formula_text": "T \u03b1 (x i , t i ) = \u03b1 if t i = 0 x i if t i = 1. (13", "formula_coordinates": [8.0, 251.2, 152.15, 225.25, 21.61]}, {"formula_id": "formula_15", "formula_text": ")", "formula_coordinates": [8.0, 476.44, 158.55, 4.15, 8.64]}, {"formula_id": "formula_16", "formula_text": "C(L) = B\u2286L k B ,(14)", "formula_coordinates": [8.0, 272.59, 212.31, 208.0, 20.08]}, {"formula_id": "formula_17", "formula_text": "k B = C(B) \u2212 B \u2282B k B . (15", "formula_coordinates": [8.0, 256.7, 264.95, 219.74, 20.06]}, {"formula_id": "formula_18", "formula_text": ")", "formula_coordinates": [8.0, 476.44, 265.27, 4.15, 8.64]}, {"formula_id": "formula_19", "formula_text": "\u03b4 \u03b1 (t) = 1 if \u2203i \u2208 V s.t. t i = 0, 0 otherwise. (16", "formula_coordinates": [8.0, 221.81, 342.52, 254.63, 20.91]}, {"formula_id": "formula_20", "formula_text": ")", "formula_coordinates": [8.0, 476.44, 348.91, 4.15, 8.64]}, {"formula_id": "formula_21", "formula_text": "\u2200l \u2208 A , \u03b4 l (t) = 1 if \u2203i \u2208 V l s.t. t i = 1, 0 otherwise. (17", "formula_coordinates": [8.0, 204.09, 377.24, 272.35, 20.91]}, {"formula_id": "formula_22", "formula_text": ")", "formula_coordinates": [8.0, 476.44, 383.63, 4.15, 8.64]}, {"formula_id": "formula_23", "formula_text": "E(t) = E new (t) \u2212 E old = B\u2286A\u222a{\u03b1} k B l\u2208B \u03b4 l (t) \u2212 C(A).", "formula_coordinates": [8.0, 188.49, 432.1, 238.37, 20.53]}, {"formula_id": "formula_24", "formula_text": "E(t) = B\u2286A k B l\u2208B \u03b4 l (t) + B\u2286A k B\u222a{\u03b1} \u03b4 \u03b1 (t) l\u2208B \u03b4 l (t).(18)", "formula_coordinates": [8.0, 193.41, 501.26, 287.18, 20.14]}, {"formula_id": "formula_25", "formula_text": "\u03b4 \u03b1 (t) l\u2208B \u03b4 l (t) = \u03b4 \u03b1 (t) + l\u2208B \u03b4 l (t) \u2212 1. (19", "formula_coordinates": [8.0, 226.21, 558.11, 250.24, 20.14]}, {"formula_id": "formula_26", "formula_text": ")", "formula_coordinates": [8.0, 476.44, 558.42, 4.15, 8.64]}, {"formula_id": "formula_27", "formula_text": "E(t) = B\u2286A k B\u222a{\u03b1} \u03b4 \u03b1 (t)+ B\u2286A (k B +k B\u222a{\u03b1} ) l\u2208B \u03b4 l (t) = k \u03b1 \u03b4 \u03b1 (t)+ B\u2286A k B l\u2208B \u03b4 l (t), (20", "formula_coordinates": [8.0, 134.77, 622.16, 355.19, 30.96]}, {"formula_id": "formula_28", "formula_text": ") where k \u03b1 = B\u2286A k B\u222a{\u03b1} = C(B \u222a {\u03b1}) \u2212 C(B) and k B = k B + k B\u222a{\u03b1} .", "formula_coordinates": [8.0, 134.76, 644.48, 345.83, 22.78]}, {"formula_id": "formula_29", "formula_text": "K(A, t) \u2264 K(A \\ {l }, t) + \u03b4 l (t) min S\u2286A\\{l } B\u2286S (k B\u222a{l } \u2212 k B ) = K(A \\ {l }, t) + k l \u03b4 l (t),(21)", "formula_coordinates": [9.0, 178.3, 188.06, 302.29, 36.83]}, {"formula_id": "formula_30", "formula_text": "K(A, t) \u2264 K + l\u2208A k l \u03b4 l (t).(22)", "formula_coordinates": [9.0, 249.17, 269.4, 231.42, 20.17]}, {"formula_id": "formula_31", "formula_text": "l = arg min l\u2208A min S\u2286A\\{l} B\u2286S (k B\u222a{l} \u2212 k B ).(23)", "formula_coordinates": [9.0, 224.48, 328.04, 256.12, 20.08]}, {"formula_id": "formula_32", "formula_text": "E (t) = min z k \u03b1 (1\u2212z \u03b1 )+ l\u2208A k l z l + i\u2208V k \u03b1 (1\u2212t i )z \u03b1 + l\u2208A i\u2208V l k l t i (1\u2212z l ) ,(24)", "formula_coordinates": [9.0, 139.75, 647.14, 340.85, 20.73]}, {"formula_id": "formula_33", "formula_text": "z (m) l = \u03b4(l \u2208 L(x (m) ))(25)", "formula_coordinates": [10.0, 260.47, 652.98, 220.12, 14.3]}, {"formula_id": "formula_34", "formula_text": "C(L) = \u2212w log 1 M 1 + M m=1 l\u2208L z (m) l , (26", "formula_coordinates": [11.0, 221.74, 139.86, 254.71, 30.55]}, {"formula_id": "formula_35", "formula_text": ")", "formula_coordinates": [11.0, 476.44, 150.59, 4.15, 8.64]}, {"formula_id": "formula_36", "formula_text": "C (L) = l\u2208L c l + k,l\u2208L,k<l c kl ,(27)", "formula_coordinates": [11.0, 244.7, 224.07, 235.89, 20.14]}], "doi": ""}