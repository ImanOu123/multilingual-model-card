{"title": "Gradient Estimation with Discrete Stein Operators", "authors": "Jiaxin Shi; Yuhao Zhou; Jessica Hwang; Michalis K Titsias; Lester Mackey", "pub_date": "2024-04-14", "abstract": "Gradient estimation-approximating the gradient of an expectation with respect to the parameters of a distribution-is central to the solution of many machine learning problems. However, when the distribution is discrete, most common gradient estimators suffer from excessive variance. To improve the quality of gradient estimation, we introduce a variance reduction technique based on Stein operators for discrete distributions. We then use this technique to build flexible control variates for the REINFORCE leave-one-out estimator. Our control variates can be adapted online to minimize variance and do not require extra evaluations of the target function. In benchmark generative modeling tasks such as training binary variational autoencoders, our gradient estimator achieves substantially lower variance than state-of-the-art estimators with the same number of function evaluations. We first provide a general recipe for constructing practical Stein operators for discrete distributions (Table 1), generalizing the prior literature [6,8,9,16,25,46,67]. We then develop a gradient estimation framework-RODEO-that augments REINFORCE estimators with mean-zero CVs generated from Stein operators. Finally, inspired by Double CV [60], we extend our method to develop CVs for REINFORCE leave-one-out estimators [30,49] to further reduce the variance.", "sections": [{"heading": "Introduction", "text": "Modern machine learning relies heavily on gradient methods to optimize the parameters of a learning system. However, exact gradient computation is often difficult. For example, in variational inference for training latent variable models [29,43], policy gradient algorithms in reinforcement learning [65], and combinatorial optimization [40], the exact gradient features an intractable sum or integral introduced by an expectation under an evolving probability distribution. To make progress, one resorts to estimating the gradient by drawing samples from that distribution [39,50].\nThe two main classes of gradient estimators used in machine learning are the pathwise or reparameterization gradient estimators [29,47,58] and the REINFORCE or score function estimators [18,65]. The pathwise estimators have shown great success in training variational autoencoders [29] but are only applicable to continuous probability distributions. The REINFORCE estimators are more generalpurpose and easily accommodate discrete distributions but often suffer from excessively high variance.\nTo improve the quality of REINFORCE estimators, we develop a new variance reduction technique for discrete expectations. Our method is based upon Stein operators [see, e.g., 1,55], computable functionals that generate mean-zero functions under a target distribution and provide a natural way of designing control variates (CVs) for stochastic estimation. Table 1: Discrete Stein operators that generate mean-zero functions under q (i.e., E q [(Ah)(x)] = 0).", "publication_ref": ["b28", "b42", "b64", "b39", "b38", "b49", "b28", "b46", "b57", "b17", "b64", "b28", "b0", "b54"], "figure_ref": [], "table_ref": []}, {"heading": "Stein Operator", "text": "(Ah)(x)\nGibbs (4) 1 d d i=1 y \u2212i =x \u2212i q(yi|x\u2212i)h(y) \u2212 h(x) MPF (6)\ny\u2208Nx,y\u0338 =x q(y)/q(x)(h(y) \u2212 h(x)) Barker (6) y\u2208Nx,y\u0338 =x q(y) q(x)+q(y) (h(y) \u2212 h(x)) Difference ( 8)\n1 d d i=1 h(deci(x)) \u2212 q(inc i (x)) q(x) h(x)\nThe benefits of using Stein operators to construct discrete CVs are twofold. First, the operator structure permits us to learn CVs with a flexible functional form such as those parameterized by neural networks. Second, since our operators are derived from Markov chains on the discrete support, they naturally incorporate information from neighboring states of the process for variance reduction.\nWe evaluate RODEO on 15 benchmark tasks, including training binary variational autoencoders (VAEs) with one or more stochastic layers. In most cases and with the same number of function evaluations, RODEO delivers lower variance and better training objectives than the state-of-the-art gradient estimators DisARM [14,69], ARMS [13], Double CV [60], and RELAX [20].", "publication_ref": ["b5", "b13", "b68", "b12", "b59", "b19"], "figure_ref": [], "table_ref": []}, {"heading": "Background", "text": "We consider the problem of maximizing the objective function E q\u03b7 [f (x)] with respect to the parameters \u03b7 of a discrete distribution q \u03b7 (x). Throughout the paper we assume f (x) is a differentiable function of real-valued inputs x \u2208 R d but is only evaluated at a discrete subset X d due to the discreteness of q \u03b7 . 2 Exact computation of the expectation is typically intractable due to the complex nature of f (x) and q \u03b7 (x). The standard workaround is to rewrite the gradient as \u2207 \u03b7 E q\u03b7 [f (x)] = E q\u03b7 [f (x)\u2207 \u03b7 log q \u03b7 (x)] and employ the Monte Carlo gradient estimator known as the score function or REINFORCE estimator [18,65]: (1) , . . . , x (K) i.i.d.\n1 K K k=1 (f (x (k) ) \u2212 b)\u2207 \u03b7 log q \u03b7 (x (k) ) for x\n\u223c q \u03b7 .\nHere, b is a constant called the \"baseline\" introduced to reduce the variance of the estimator by reducing the scaling effect of f (x (k) ). Since E q\u03b7 [\u2207 \u03b7 log q \u03b7 (x)] = 0, the REINFORCE estimator is unbiased for any choice of b, and the term b\u2207 \u03b7 log q \u03b7 (x) is known as a control variate (CV) [42,Ch. 8]. The optimal baseline can be estimated using additional function evaluations [7,45,64]. A simpler approach is to use moving averages of f from historical evaluations or to train function approximators to mimic those values [37]. When K \u2265 2, a powerful variant of REINFORCE is obtained by replacing b with the leave-one-out average of function values:\n1 K K k=1 f (x (k) ) \u2212 1 K\u22121 j\u0338 =k f (x (j) ) \u2207 \u03b7 log q \u03b7 (x (k) ). (RLOO\n)\nThis approach is often called the REINFORCE leave-one-out (RLOO) estimator [30,48,49] and was recently observed to have very strong performance in training discrete latent variable models [14,48].\nAll the above methods construct a baseline that is independent of the point x (k) under consideration, but there are other ways to preserve the unbiasedness of the estimator. We are free to use a sampledependent baseline b(x (k) ) as long as the expectation\nc \u225c E q\u03b7 [b(x (k) )\u2207 \u03b7 log q \u03b7 (x (k)\n)] is easily computed or has a low-variance unbiased estimate. In this case, we can correct for any bias introduced by b(x (k) ) by adding in this expectation:\n1 K K k=1 (f (x (k) ) \u2212 b(x (k) ))\u2207 \u03b7 log q \u03b7 (x (k) ) + c. For example, b(x (k)\n) can be a lower bound or a Taylor expansion of f (x (k) ) [22,43]. Taking this a step further, the Double CV estimator [60] proposed to treat f (x (k) ) \u2212 b(x (k) ) as the effective objective function and apply the leave-one-out idea:\n1 K K k=1 f (x (k) ) \u2212b k (x (k) ) \u2212 1 K\u22121 j\u0338 =k f (x (j) ) \u2212b j (x (j) ) \u2207 \u03b7 log q \u03b7 (x (k) ) + c.\nThe resulting estimator adds two CVs to RLOO: the global CV b k (x (k) )\u2207 \u03b7 log q \u03b7 (x (k) ) and the local CV b k (x (j) ). Intuitively, b k (x (j) ) is aimed at reducing the variance of the LOO average. This is motivated by the fact that replacing 1 K\u22121 j\u0338 =k f (x (j) ) with E q\u03b7 [f ] in RLOO leads to lower variance [60,Prop 1]. To obtain a tractable correction term c, Titsias and Shi [60] adopt a linear design of b k :\nb k (x) = \u03b1 \u2022 1 K\u22121 j\u0338 =k f (x (j) )(x \u2212 \u00b5) for \u00b5 = E q\u03b7 [x]\nand a coefficient \u03b1. Although the Double CV framework points to a promising new direction for developing better REINFORCE estimators, one only obtains significant reduction in variance when b k is strongly correlated with f . This may fail to hold for the above linear b k and a highly nonlinear f , especially in applications like training deep generative models.\nIn the following two sections, we will introduce a method that allows us to use very flexible CVs while still maintaining a tractable correction term. Our method enables online adaptation of CVs to minimize gradient variance (similar to RELAX [20]) but does not assume q \u03b7 has a continuous reparameterization. We then apply it to generalize the linear CVs in Double CV to very flexible ones such as neural networks. Moreover, we provide an effective CV design based on surrogate functions that requires no additional evaluation of f compared to RLOO.", "publication_ref": ["b1", "b17", "b64", "b0", "b41", "b6", "b44", "b63", "b36", "b29", "b47", "b48", "b13", "b47", "b21", "b42", "b59", "b59", "b59", "b19"], "figure_ref": [], "table_ref": []}, {"heading": "Control Variates from Discrete Stein Operators", "text": "At the heart of our new estimator is a technique for generating flexible discrete CVs, that is for generating a rich class of functions that have known expectations under a given discrete distribution q. One way to achieve this is to identify any discrete-time Markov chain (X (t) ) \u221e t=0 with stationary distribution q. Then, the transition matrix P , defined via P xy = P (X (t+1) = y|X (t) = x), satisfies\nP \u22a4 q = q and hence E q [(P \u2212 I)h] = 0,(1)\nfor any integrable function h. We overload our notation so that, for any suitable matrix A, (Ah)(x) \u225c y A xy h(y). In other words, for any integrable h, the function (P \u2212 I)h is a valid CV as it has known mean under q. Moreover, the linear operator P \u2212 I is an example of a Stein operator [1,55] in the sense that it generates mean-zero functions under q. In fact, both Stein et al. [56] and Dellaportas and Kontoyiannis [12] developed CVs of the form (P \u2212 I)h based on reversible discrete-time Markov chains and linear input functions h(x) = x i .\nMore generally, Barbour [3] and Henderson [23] observed that if we identify a continuous-time Markov chain (X (t) ) t\u22650 with q as its stationary distribution, then the generator A, defined via\n(Ah)(x) = lim t\u21920 E[h(X (t) )|X (0) =x]\u2212h(x) t ,(2)\nsatisfies A \u22a4 q = 0 and hence E q [Ah] = 0 for all integrable h. Therefore, A is also a Stein operator suitable for generating CVs. Moreover, since any discrete-time chain with transition matrix P can be embedded into a continuous-time chain with transition rate matrix A = P \u2212 I, this continuous-time construction is strictly more general [57,Ch. 4].", "publication_ref": ["b0", "b54", "b55", "b11", "b22", "b56"], "figure_ref": [], "table_ref": []}, {"heading": "Discrete Stein operators", "text": "We next present several examples of broadly applicable discrete Stein operators (summarized in Table 1) that can serve as practical defaults.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Gibbs Stein operator", "text": "The transition kernel of the random-scan Gibbs sampler with stationary distribution q [see, e.g., 17] is\nP xy = 1 d d i=1 q(y i |x \u2212i )1(y \u2212i = x \u2212i ),(3)\nwhere 1(\u2022) is the indicator function, x \u2212i denotes all elements of x except x i . The associated Stein operator is A = P \u2212 I with\n(Ah)(x) = 1 d d i=1 y\u2212i=x\u2212i q(y i |x \u2212i )h(y) \u2212 h(x).(4)\nIn the binary variable setting, (4) recovers the operator Bresler and Nagaraj [8], Reinert and Ross [46] used to bound distances between the stationary distributions of Glauber dynamics Markov chains.\nZanella Stein operator Zanella [70] studied continuous-time Markov chains with generator\nA xy = \u03ba (q(y)/q(x)) 1(y \u2208 N x , y \u0338 = x) \u2212 z\u0338 =x A xz 1(y = x),(5)\nwhere N x denotes the transition neighborhood of x and \u03ba is a continuous positive function satisfying \u03ba(t) = t\u03ba(1/t). Conveniently, the neighborhood structure can be arbitrarily sparse. Moreover, the \u03ba constraint ensures that the chain satisfies detailed balance (i.e., q(x)A xy = q(y)A yx ) and hence that A \u22a4 q = 0. Hodgkinson et al. [24] call the associated operator the Zanella Stein operator:\n(Ah)(x) = y\u2208Nx,y\u0338 =x \u03ba q(y) q(x) (h(y) \u2212 h(x)).(6)\nImportant special cases include the minimum probability flow [53] (MPF) Stein operator (\u03ba(t) = \u221a t) discussed in Barp et al. [6] and the Barker [4] Stein operator (\u03ba(t) = t t+1 ). Birth-death Stein operator Let e 1 , . . . , e d represent the standard basis vectors on R d . For any finite-cardinality space, we may index the elements of X = {s 0 , . . . , s m\u22121 }, let idx(x i ) return the index of the element that x i represents, and define the increment and decrement operators\ninc i (x) = x + e i (s (idx(xi)+1) mod m \u2212 x i ) and dec i (x) = x + e i (s (idx(xi)\u22121) mod m \u2212 x i ).\nThen the product birth-death process [28] on X d with birth rates b\ni,x = q(inci(x)) q(x)\n, death rates d i,x = 1, and generator\nA xy = 1 d d i=1 b i,x 1(y = inc i (x)) + d i,x 1(y = dec i (x)) \u2212 (b i,x + d i,x )1(y = x),\nhas q as a stationary distribution, as A \u22a4 q = 0. This construction yields the birth-death Stein operator\n(Ag)(x) = 1 d d i=1 b i,x (g(inc i (x)) \u2212 g(x)) \u2212 d i,x (g(x) \u2212 g(dec i (x))).(7)\nAn analogous operator is available for countably infinite X [24], and Brown and Xia [9], Eichelsbacher and Reinert [16], Holmes [25] used related operators to characterize convergence to discrete target distributions. Moreover, by substituting h(x) = g(x) \u2212 g(inc(x)) in ( 7), we recover the difference Stein operator proposed by Yang et al. [67] without reference to birth-death processes:\n(Ah)(x) = 1 d d i=1 h(dec i (x)) \u2212 b i,x h(x).(8)\nChoosing a Stein operator Despite being better-known, the difference and MPF operators often suffer from large variance and numerical instability due to their use of unbounded probability ratios q(y)/q(x). As a result, we recommend the numerically stable Gibbs operator when each component of x is binary or takes on a small number of values. When x i takes on a large number of values (m), the Gibbs operator suffers from linear scaling with m. In this case, we recommend the Barker operator where a sparse neighborhood structure can be specified, such as\nN x = {inc i (x), dec i (x) for i \u2208 [d]}.\nThe Barker operator is numerically stable as its \u03ba( q(y) q(x) ) = q(y) q(x)+q(y) .", "publication_ref": ["b7", "b45", "b69", "b23", "b52", "b3", "b27", "b23", "b8", "b15", "b24", "b66"], "figure_ref": [], "table_ref": []}, {"heading": "Gradient Estimation with Discrete Stein Operators", "text": "Recall that REINFORCE estimates the gradient\nE q\u03b7 [f (x)\u2207 \u03b7 log q \u03b7 (x)].\nDue to the existence of \u2207 \u03b7 log q \u03b7 (x) as a weighting function, we apply a discrete Stein operator to a vector-valued functio\u00f1 h : X \u2192 R d per dimension to construct the following estimator with a mean-zero CV:\nE q\u03b7 [f (x)\u2207 \u03b7i log q \u03b7 (x) + (Ah i )(x)].(9)\nIdeally, we want to choose theh such that Ah i strongly correlates with f (x)\u2207 \u03b7i log q \u03b7 (x) to reduce its variance. The optimalh i that yields zero variance is given by the solution of Poisson equation\nE q\u03b7 [f \u2207 \u03b7i log q \u03b7 ] \u2212 f \u2207 \u03b7i log q \u03b7 = Ah i .(10)\nWe could learn a separateh i per dimension to approximate the solution of (10). However, this poses a difficult optimization problem that requires simultaneously solving d Poisson equations. Instead, we will incorporate knowledge about the structure of the solution to simplify the optimization.\nTo determine a candidate functional form forh, we draw inspiration from an \"optimal\" Markov chain in which the current state is ignored entirely and the new state is generated independently from q \u03b7 . In\nAlgorithm 1 Optimizing E q\u03b7 [f \u03b8 (x)] with RODEO gradients input: Objective f \u03b8 , sample points x (1:K) i.i.d. \u223c q \u03b7 , Stein operator A, step sizes \u03b1 t , \u03b2 t for t = 1 : T do 1: {f \u03b8 (x (k) ), \u2207 \u03b8 f \u03b8 (x (k) ), \u2207f \u03b8 (x (k) )} K k=1 \u2190 autodiff(f \u03b8 , x (1:K) ). 2: Compute the surrogates h k (x (j) ), h \u22c6 k (x (j)\n) of ( 13), ( 14) for j \u0338 = k and j, k = 1, \u2022 \u2022 \u2022 , K. 3: Compute the RODEO gradient estimator g \u03b3 (x (1:K) ).\n4: \u03b8 \u2190 \u03b8 + \u03b1 t 1 K K k=1 \u2207 \u03b8 f (x (k) ). 5: \u03b7 \u2190 \u03b7 + \u03b1 t g \u03b3 (x (1:K) ). 6: Update hyperparameters: \u03b3 \u2190 \u03b3 \u2212 \u03b2 t \u2207 \u03b3 \u2225g \u03b3 (x (1:K) )\u2225 2 2 .\nthis case, (P \u2212 I)h i becomes E q\u03b7 [h i ] \u2212h i , and the optimal solution ish i = f \u2207 \u03b7i log q \u03b7 . Inspired by this, we considerh of the formh\n(x) = h(x)\u2207 \u03b7 log q \u03b7 (x),(11)\nwhere we now only need to learn a scalar-valued function h. Notably, when h exactly equals f and A = P \u2212 I for any discrete time Markov chain kernel P , our CV adjustment amounts to Rao-Blackwellization [42, Sec. 8.7], as we end up replacing f (x)\u2207 \u03b7i log q \u03b7 (x) with its conditional expectation P (f\n\u2207 \u03b7i log q \u03b7 )(x) = E Xt+1|Xt=x [f (X t+1 )\u2207 \u03b7i log q \u03b7 (X t+1 )]\n. This yields a guaranteed variance reduction.\nSurrogate function design Based on the above reasoning, we can view h as a surrogate for f . We avoid directly setting h = f because our Stein operators evaluate h at all neighbors of the sample points, and f can be very expensive to evaluate [see, e.g., 51]. To avoid this problem, we first observe thath ( 11) can be made sample-specific, i.e., we can use a differenth k for each sample point x (k) :\n1 K K k=1 [f (x (k) )\u2207 \u03b7 log q \u03b7 (x (k) ) + (Ah k )(x (k) )].(12)\nWe then consider the following choices of h k that are informed about f while being cheap to evaluate:\nh k (y) = 1 K\u22121 j\u0338 =k H(f (x (j) ), \u2207f (x (j) ) \u22a4 (y \u2212 x (j) )).(13)\nHere H belongs to a flexible parametric family of functions such as neural networks and is chosen to have significantly lower cost than f . y will take on the values of x (k) and its neighbors in the Markov chain. We omit x (k) in the sum (13) to ensure that the function h k is independent of x (k) and hence that E q\u03b7 [ 1\nK K k=1 (Ah k )(x (k)\n)] = 0. Moreover, this surrogate function design introduces no additional evaluations of f beyond those required for the usual RLOO estimator. Also, as observed by Titsias and Shi [60], for many applications, including VAE training, where f has parameters \u03b8 learned through gradient-based optimization, {\u2207f (x (k) )} K k=1 can be obtained \"for free\" from the same backpropagation used to compute \u2207 \u03b8 f \u03b8 (x (k) ) (see Algorithm 1).\nRODEO We can further improve the estimator by leveraging discrete Stein operators and the above surrogate function design to construct both the global and local CVs in the Double CV framework [60] (see Section 2). We call our final estimator RODEO for RLOO with Discrete StEin Operators:\n1 K K k=1 [(f (x (k) )\u2212 1 K\u22121 j\u0338 =k (f (x (j) )+(Ah j )(x (j) )))\u2207 \u03b7 log q \u03b7 (x (k) )+(Ah \u22c6 k )(x (k) )], (RODEO) whereh \u22c6 k (y) = h \u22c6 k (y)\u2207 \u03b7 log q \u03b7 (y) and {h k , h \u22c6 k } K k=1 are scalar-valued functions.\nHere, (Ah j )(x (j) ) is a scalar-valued CV introduced to reduce the variance of the leave-one-out baseline 1\nK\u22121 j\u0338 =k f (x (j) ), while (Ah \u22c6 k )(x (k)\n) acts as a global CV to further reduce the variance of the gradient estimate. We adopt the aforementioned design of h (13) andh (11) for the two CVs. In Appendix B, we show that the RODEO estimator is unbiased for \u2207 \u03b7 E q\u03b7 [f (x)] when each h k is defined as in ( 13) and\nh \u22c6 k (y) = 1 K\u22121 j\u0338 =k H \u22c6 (f (x (j) ), \u2207f (x (j) ) \u22a4 (y \u2212 x (j) )).(14)\nOptimization with RODEO In practice, we let the functions H and H \u22c6 share a neural network architecture with two output units. Since the estimator is unbiased, we can optimize the parameters \u03b3 of the network in an online fashion to minimize the variance of the estimator (similar to [20]). Specifically, if we denote the RODEO gradient estimate by g \u03b3 (x\n(1:K) ), then \u2207 \u03b3 Tr(Var(g \u03b3 (x (1:K) ))) = E[\u2207 \u03b3 \u2225g \u03b3 (x (1:K) )\u2225 2 2 ].\nIn Algorithm 1, we use an unbiased estimate of this hyperparameter gradient, \u2207 \u03b3 \u2225g \u03b3 (x (1:K) )\u2225 2 2 , to update \u03b3 after each optimization step of \u03b7.", "publication_ref": ["b12", "b59", "b59", "b19", "b1"], "figure_ref": [], "table_ref": []}, {"heading": "Related Work", "text": "As we have seen in Section 2, there is a long history of designing CVs for REINFORCE estimators using \"baselines\" [7,37,45,64]. Recent progress is mostly driven by leave-one-out [30,38,48,49] and sample-dependent baselines [20,22,43,60,62]. REBAR [62] constructs the baseline through continuous relaxation of the discrete distribution [26,35] and applies reparameterization gradients to the correction term. As a result REBAR uses three evaluations of f for each x (k) instead of the usual single evaluation (see Appendix A for a detailed explanation). The RELAX [20] estimator generalizes REBAR by noticing that their continuous relaxation can be replaced with a free-form CV. However, in order to get strong performance, RELAX still includes the continuous relaxation in their CV and only adds a small deviation to it. Therefore, RELAX also uses three evaluations of f for each x (k) and is usually considered more expensive than other estimators.\nAn attractive property of the RODEO estimator is that it incorporates information from neighboring states thanks to the Stein operator while avoiding additional costly f evaluations thanks to the learned surrogate functions h k . Estimators based on analytic local expectation [59,61] and GO gradients [11] also use neighborhood information but only at the cost of many additional target function evaluations.\nIn fact, the local expectation gradient [59] can be viewed as a Stein CV adjustment RODEO with a Gibbs Stein operator and the target function f used directly instead of the surrogate h. The downside of these approaches is that f must be evaluated Kd times per training step instead of K times as in RODEO, a prohibitive cost when f is expensive and d \u2265 200 as in Section 6.\nPrior work has also studied variance reduction methods based on sampling without replacement [31] and antithetic sampling [13][14][15]68] for gradient estimation. DisARM [14,69] was shown to outperform RLOO estimators when K = 2 and ARMS [13] generalizes DisARM to K > 2.\nStein operators for continuous distributions have also been leveraged for effective variance reduction in a variety of learning tasks [2,5,36,41,52,54] including gradient estimation [27,34]. In particular, the gradient estimator of Liu et al. [34] is based on the Langevin Stein operator [19] for continuous distributions and coincides with the continuous counterpart of RELAX [20]. In contrast, our approach considers discrete Stein operators for Monte Carlo estimation in discrete distributions with exponentially large state spaces. Recently, Parmas and Sugiyama [44, App. E.4] used a probability flow perspective to characterize all unbiased gradient estimators satisfying a mild technical condition; our estimators fall into this broad class but were not specifically investigated.", "publication_ref": ["b6", "b36", "b44", "b63", "b29", "b37", "b47", "b48", "b19", "b21", "b42", "b59", "b61", "b61", "b25", "b34", "b19", "b58", "b60", "b10", "b58", "b30", "b12", "b13", "b14", "b67", "b13", "b68", "b12", "b1", "b4", "b35", "b40", "b51", "b53", "b26", "b33", "b33", "b18", "b19"], "figure_ref": [], "table_ref": []}, {"heading": "Experiments", "text": "Python code replicating all experiments can be found at https://github.com/thjashin/rodeo.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Training Bernoulli VAEs", "text": "Following Dong et al. [14] and Titsias and Shi [60], we conduct experiments on training variational auto-encoders [29,47] (VAEs) with Bernoulli latent variables. VAEs are models with a joint density p \u03b8 (y, x), where x is the latent variable and \u03b8 denotes model parameters. They are typically learned through maximizing the evidence lower bound (ELBO) E q\u03b7(x|y) [f (x)] for an auxiliary inference network q \u03b7 (x|y) and f (x) \u225c log p \u03b8 (y, x) \u2212 log q \u03b7 (x|y). In our experiments, p(x) and q \u03b7 (x|y) are high-dimensional distributions where each dimension of the random variable is an independent Bernoulli. Since exact gradient computations are intractable, we will use gradient estimators to learn the parameters \u03b7 of the inference network. The VAE architecture and training experimental setup follows Titsias and Shi [60], and details are given in Appendix D. The dimensionality of the latent variable x is d = 200. The functions H (13) and H * (14) share a neural network architecture with two output units and a single hidden layer with 100 units. For the numerical stability and variance reasons discussed in Section 3, we use the Gibbs Stein operator (4) as a default choice in our experiments, but we revisit this choice in Section 6.3.\nWe consider the MNIST [33], Fashion-MNIST [66] and Omniglot [32] datasets using their standard train, validation, and test splits. We use both binary and continuous VAE outputs (y) as in Titsias and Shi [60]. In the binary output setting, data are dynamically binarized, and the Bernoulli likelihood is used; in the continuous output setting, data are centered between [\u22121, 1], and the Gaussian likelihood with learnable diagonal covariance parameters is used.", "publication_ref": ["b13", "b59", "b28", "b46", "b59", "b32", "b65", "b31", "b59"], "figure_ref": [], "table_ref": []}, {"heading": "200K 400K 600K 800K 1M", "text": "Training Step   2 shows, on all three datasets, RODEO achieves the best training ELBOs. In Figure 1 (left), we plot the gradient variance and average training ELBOs against training steps for all estimators on dynamically binarized MNIST. RODEO outperforms DisARM and Double CV by a large margin in gradient variance.\nNext, we consider VAEs with Gaussian likelihoods trained on non-binarized datasets. In this case the gradient estimates suffer from even higher variance due to the large range of values f (x) can take. The results are plotted in Figure 2. We see that RODEO has substantially lower variance than DisARM and Double CV, leading to significant improvements in training ELBOs. In Appendix Figure 7, we find that RODEO also consistently yields the best test set performance in all six settings.\nK = 3\nIn the second set of experiments we compare RELAX [20], which uses three evaluations of f per training step, with RODEO, Double CV, and ARMS [13] for K = 3. Figure 1 (right) and Table 2 demonstrate that RODEO outperforms the three previous methods and generally leads to the lowest variance. Although RELAX was often observed to have very strong performance in prior work [14,60], our results in Figure 1 suggest that, for dynamically binarized datasets, much larger gains can be achieved by using the same number of function evaluations in other estimators.\nFor the experiments mentioned above, we report final training ELBOs in Table 2, test log-likelihood bounds in Appendix Table 4, and binarized MNIST average running time in Appendix Table 5. For K = 3, RODEO has the best final performance in 5 out of 6 tasks and runtime nearly identical to RELAX. For K = 2, RODEO has the best final performance for all tasks and is 1.5 times slower than Double CV and DisARM. We attribute the runtime gap to the Gibbs operator (4) which performs 2d evaluations of the auxiliary functions H and H * in ( 13) and (14). While this results in some extra cost, the network parameterizing H and H * takes only 2-dimensional inputs, produces scalar outputs, and is typically small relative to the VAE model. As a result, the evaluation of H and H * is  significantly cheaper than that of f , and its relative contribution to runtime shrinks as the cost of f grows. To demonstrate this, we include a wall clock time comparison of our method with RLOO in Appendix C.1. In this experiment we replace the two-layer MLP-based VAE with a ResNet VAE, where the cost of f is significantly higher than the single-layer MLP of H, H * . In this case, RODEO and RLOO have very close per-iteration time (0.025s vs. 0.023s). And RODEO achieves better training ELBOs than RLOO for the same amount of time.", "publication_ref": ["b19", "b12", "b13", "b59", "b13"], "figure_ref": ["fig_2", "fig_7"], "table_ref": ["tab_0", "tab_0", "tab_0", "tab_6"]}, {"heading": "Training hierarchical Bernoulli VAEs", "text": "To investigate the performance of RODEO when scaling to hierarchical discrete latent variable models, we follow DisARM [14,68]   We plot the results on VAEs with four stochastic layers on Fashion-MNIST in Figure 3. The results for other datasets and for 2 and 3 stochastic layers can be found in Appendix E. RODEO generally achieves the best training ELBOs. One difference we noticed when comparing the variance results with those obtained from single-stochastic-layer VAEs is that these estimators have very different behaviors towards the beginning and the end of training. For example, in Figure 3, Double CV starts with lower variance than DisARM, but the gap diminishes after around 100K steps, and DisARM start to perform better as the training proceeds. In contrast, RODEO has the lowest variance in both phases for all datasets save Omniglot, where DisARM overtakes it in the long run.", "publication_ref": ["b13", "b67"], "figure_ref": ["fig_3", "fig_3"], "table_ref": []}, {"heading": "Ablation study", "text": "Finally, we conduct an ablation study to gain more insight into the impact of each component of RODEO. In each experiment we train binary latent VAEs with K = 2.  Impact of surrogate functions To tease apart the benefits of our new surrogate functions (13) and the remaining RODEO components, we replace the surrogate function c \u03d5 (z) in RELAX [20] with our surrogates, which only requires a single evaluation of f per x (k) (see Appendix A for more details). Figure 4c compares the performance of RODEO and this modified RELAX on binarized MNIST. Since the surrogate functions are matched, the consistent improvements over modified RELAX can be attributed to the Stein and double CV components of RODEO. In Appendix C.2, we also experiment with increasing the complexity of H and H * by using two hidden layers instead of a single hidden layer in the MLP. We did not observe significant improvements in variance reduction.", "publication_ref": ["b12", "b19"], "figure_ref": ["fig_4"], "table_ref": []}, {"heading": "Conclusions, Limitations, and Future Work", "text": "This work tackles the gradient estimation problem for discrete distributions. We proposed a variance reduction technique which exploits Stein operators to generate control variates for REINFORCE leave-one-out estimators. Our RODEO estimator does not rely on continuous reparameterization of the distribution, requires no additional function evaluations per sample point, and can be adapted online to learn very flexible control variates parameterized by neural networks.\nOne potential drawback of our surrogate function constructions (13) and ( 14) is the need to evaluate an auxiliary function (H or H * ) at K \u2212 1 locations. This cost can be comfortably borne when H and H * are much cheaper to evaluate than f , such as in the ResNet VAE example in Appendix C.1 and many large VAE models used in practice [63]. And, in our experiments with the most common sample sizes, the runtime of RODEO was no worse than that of RELAX. To obtain a more favorable cost for large K, one could employ alternative surrogates that require only a constant number of auxiliary function evaluations, e.g.,\nh k (y) = H 1 K\u22121 j\u0338 =k f (x (j) ), 1 K\u22121 j\u0338 =k \u2207f (x (j) ) \u22a4 (y \u2212 x (j) ) .\nThe runtime of RODEO could also be improved by varying the Stein operator employed. For example, the Gibbs operator (Ah)(x) (4) used in our experiments evaluated its surrogate function h at d neighboring locations of x. This evaluation complexity could be reduced by subsampling neighbors, resulting in a cheaper but still valid Stein operator, or by employing the numerically stable Barker operator (6) with fewer neighbors. Either strategy would introduce a speed-variance trade-off worthy of study in follow-up work. Finally, we have restricted our focus in this work to differentiable target functions f . In future work, this limitation could be overcome by designing effective surrogate functions that make no use of derivative information.", "publication_ref": ["b12", "b62"], "figure_ref": [], "table_ref": []}, {"heading": "A Sample-dependent Baselines in REBAR and RELAX", "text": "We start with the REINFORCE estimator with the sample-dependent baseline b k :\n1 K K k=1 (f (x (k) ) \u2212 b k )\u2207 \u03b7 log q \u03b7 (x (k) ) + E[b k \u2207 \u03b7 log q \u03b7 (x (k) )].(15)\nREBAR [62] introduces indirect independence on\nx (k) in b k through the continuous reparameteriza- tion x = H(z), z (k) \u223c q \u03b7 (z|x = x (k)\n), where z is a continuous variable and H is an argmax-like thresholding function. Specifically, b k = f (\u03c3 \u03bb (z (k) )), where \u03c3 \u03bb is a continuous relaxation of H controlled by the parameter \u03bb. The correction term decomposes into two parts:\nE x (k) [E z (k) |x (k) [f (\u03c3 \u03bb (z (k) ))]\u2207 \u03b7 log q \u03b7 (x (k) )] = \u2207 \u03b7 E q\u03b7(z) [f (\u03c3 \u03bb (z))] \u2212 E x (k) [\u2207 \u03b7 E q\u03b7(z (k) |x (k) ) [f (\u03c3 \u03bb (z (k) ))]].\nBoth parts can be estimated with the reparameterization trick [29,47,58] which often has low variance. The RELAX [20] estimator generalizes REBAR by noticing that f (\u03c3 \u03bb (z)) can be replaced with a free-form differentiable function c \u03d5 (z). However, RELAX still relies on parameterizing c \u03d5 (z) as f (\u03c3 \u03bb (z)) + r \u03b8 (z) to achieve strong performance, as noted in Dong et al. [14].\nTo form modified RELAX in Section 6.3, we replace b\nk = c \u03d5 (z (k) ) with b k = h k (\u03c3 \u03bb (z (k)\n)) for h k defined in (13).", "publication_ref": ["b61", "b28", "b46", "b57", "b19", "b13", "b12"], "figure_ref": [], "table_ref": []}, {"heading": "B Proof of Unbiasedness of RODEO", "text": "Recall our estimator defined in RODEO is\n1 K K k=1 [(f (x (k) ) \u2212 1 K \u2212 1 j\u0338 =k (f (x (j) ) + (Ah j )(x (j) ))) \u2022 \u2207 \u03b7 log q \u03b7 (x (k) ) + (Ah \u22c6 k )(x (k) )].(16)\nTo show the unbiasedness, we compute its expectation under q \u03b7 as\n1 K K k=1 E q\u03b7 [f (x (k) )\u2207 \u03b7 log q \u03b7 (x (k) )] \u2212 1 K(K \u2212 1) K k=1 j\u0338 =k E q\u03b7 [(f (x (j) ) + (Ah j )(x (j) ))\u2207 \u03b7 log q \u03b7 (x (k) )] + 1 K K k=1 E q\u03b7 [(Ah \u22c6 k )(x (k) )].\nSince the first term is the desired gradient \u2207 \u03b7 E q\u03b7 [f (x)] and the third term is zero, it suffices to show that the second term also vanishes. Using the law of total expectations, we find for j \u0338 = k,\nE q\u03b7 [(f (x (j) ) + (Ah j )(x (j) ))\u2207 \u03b7 log q \u03b7 (x (k) )] = E x (k) \u223cq\u03b7 [E q\u03b7 [f (x (j) ) + (Ah j )(x (j) ) | x (k) ]\u2207 \u03b7 log q \u03b7 (x (k) )] = E x (k) \u223cq\u03b7 [E q\u03b7 [f (x (j) ) | x (k) ]\u2207 \u03b7 log q \u03b7 (x (k) )] = E q\u03b7 [f (x (j) )\u2207 \u03b7 log q \u03b7 (x (k) )] = E x (j) \u223cq\u03b7 [f (x (j) )E x (k) \u223cq\u03b7 [\u2207 \u03b7 log q \u03b7 (x (k) ) | x (j) ]] = 0,\nwhich completes the proof.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C Additional Experiments", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C.1 Wall clock time comparison with RLOO", "text": "Besides necessary target function evaluations, the RODEO estimator comes with the additional cost of evaluating the neural network-based H, H * . Therefore, RODEO is most suited to the problems  ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C.2 Impact of neural network architectures of surrogate functions", "text": "We conduct one more ablation study to investigate the impact of neural network architectures used by H, H * . Specifically, we replace the single-hidden-layer control variate network used in previous experiments with a two-hidden-layer MLP (each layer has 100 units) and compare their performance on binarized MNIST with K = 2. We keep other settings the same as in Section 6.1. The results are plotted in Figure 6. We do not observe significant difference between the two versions of RODEO.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "D Experimental Details", "text": "Our implementation is based on the open-source code of DisARM [14] ", "publication_ref": ["b13"], "figure_ref": [], "table_ref": []}, {"heading": "D.1 Details of VAE experiments", "text": "VAEs are models with a joint density p(y, x) = p(y|x)p(x), where x denotes the latent variable.\nx is assigned a uniform factorized Bernoulli prior. The likelihood p \u03b8 (y|x) is parameterized by the output of a neural network with x as input and parameters \u03b8. The VAE has two hidden layers with 200 units activated by LeakyReLU with the coefficient 0.3. To optimize the VAE we use Adam with base learning rate 10 \u22124 for non-binarized data and 10 \u22123 for dynamically binarized data, except for binarized Fashion-MNIST we decreased the learning rate to 3 \u00d7 10 \u22124 because otherwise the training is very unstable for all estimators. We use Adam with the same learning rate 10 \u22123 for adapting our control variate network in all experiments. The batch size is 100. The settings of other estimators are kept the same with Titsias and Shi [60].\nIn the minimum probability flow (MPF) and Barker Stein operator (6), we choose the neighborhood N x to be the states that differ in only one coordinate from x. Let y \u2208 N x be an element in this neighborhood such that y i \u0338 = x i and y \u2212i = x \u2212i . For the MPF Stein estimator and the difference Stein estimator (8), the density ratio q(y) q(x) can be simplified to q(yi|x\u2212i) q(xi|x\u2212i) . We further replace it with q(yi|x\u2212i) q(xi|x\u2212i)+10 \u22123 to alleviate numerical instability. The Barker Stein estimator does not suffer from the numerical issue since the coefficient is bounded in the Bernoulli case:\nq(y) q(x)+q(y) = q(yi|x\u2212i) q(xi|x\u2212i)+q(yi|x\u2212i) = q(y i |x \u2212i ).\nIn our experiments, we find that the difference Stein estimator is highly unstable and may diverge as the iteration proceeds.", "publication_ref": ["b59"], "figure_ref": [], "table_ref": []}, {"heading": "D.2 Details of hierarchical VAE experiments", "text": "We optimize the hierarchical VAE using Adam with base learning rate 10 \u22124 . Our control variate network is optimized using Adam with learning rate 10 \u22123 . Settings of training multilayer VAEs are kept the same with Dong et al. [14], except that we do not optimize the prior distribution of the VAE hidden layer and use a larger batch size 100.", "publication_ref": ["b13"], "figure_ref": [], "table_ref": []}, {"heading": "E Additional Results", "text": "In this section, we measure test set performance using 100 test points and the marginal log-likelihood bound of Burda et al. [10], which provides a tighter estimate of marginal log likelihood than the ELBO. Throughout, we call this the \"test log-likelihood bound.\"        ", "publication_ref": ["b9"], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgments and Disclosure of Funding", "text": "We thank Heishiro Kanagawa for suggesting appropriate names for the Barker Stein operator.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Stein's method meets statistics: A review of some recent developments", "journal": "", "year": "2021", "authors": "Andreas Anastasiou; Alessandro Barp; Fran\u00e7ois-Xavier Briol; Bruno Ebner; Robert E Gaunt; Fatemeh Ghaderinezhad; Jackson Gorham; Arthur Gretton; Christophe Ley; Qiang Liu; Lester Mackey"}, {"ref_id": "b1", "title": "Zero-variance principle for Monte Carlo algorithms", "journal": "Phys. Rev. Lett", "year": "1999-12", "authors": "Roland Assaraf; Michel Caffarel"}, {"ref_id": "b2", "title": "Stein's method and Poisson process convergence", "journal": "J. Appl. Probab", "year": "1988", "authors": "A D Barbour"}, {"ref_id": "b3", "title": "Monte Carlo calculations of the radial distribution functions for a proton? electron plasma", "journal": "Australian Journal of Physics", "year": "1965", "authors": "A Av;  Barker"}, {"ref_id": "b4", "title": "", "journal": "", "year": "2018", "authors": "Alessandro Barp; Chris Oates; Emilio Porcu; Mark Girolami"}, {"ref_id": "b5", "title": "Minimum Stein discrepancy estimators", "journal": "", "year": "2019", "authors": "Alessandro Barp; Francois-Xavier Briol; Andrew Duncan; Mark Girolami; Lester Mackey"}, {"ref_id": "b6", "title": "Estimating or propagating gradients through stochastic neurons for conditional computation", "journal": "", "year": "2013", "authors": "Yoshua Bengio; Nicholas L\u00e9onard; Aaron Courville"}, {"ref_id": "b7", "title": "Stein's method for stationary distributions of Markov chains and application to Ising models", "journal": "The Annals of Applied Probability", "year": "2019", "authors": "Guy Bresler; Dheeraj Nagaraj"}, {"ref_id": "b8", "title": "Stein's Method and Birth-Death Processes", "journal": "The Annals of Probability", "year": "2001", "authors": "Timothy C Brown; Aihua Xia"}, {"ref_id": "b9", "title": "Importance weighted autoencoders. International Conference on Learning Representations", "journal": "", "year": "2015", "authors": "Yuri Burda; Roger Grosse; Ruslan Salakhutdinov"}, {"ref_id": "b10", "title": "GO gradient for expectation-based objectives", "journal": "", "year": "2019", "authors": "Yulai Cong; Miaoyun Zhao; Ke Bai; Lawrence Carin"}, {"ref_id": "b11", "title": "Control variates for estimation based on reversible Markov chain Monte Carlo samplers", "journal": "Journal of the Royal Statistical Society: Series B (Statistical Methodology)", "year": "2012", "authors": "Petros Dellaportas; Ioannis Kontoyiannis"}, {"ref_id": "b12", "title": "ARMS: Antithetic-REINFORCE-Multi-Sample gradient for binary variables", "journal": "", "year": "2021", "authors": "Aleksandar Dimitriev; Mingyuan Zhou"}, {"ref_id": "b13", "title": "DisARM: An antithetic gradient estimator for binary latent variables", "journal": "", "year": "2020", "authors": "Zhe Dong; Andriy Mnih; George Tucker"}, {"ref_id": "b14", "title": "Coupled gradient estimators for discrete latent variables", "journal": "", "year": "2021", "authors": "Zhe Dong; Andriy Mnih; George Tucker"}, {"ref_id": "b15", "title": "Stein's method for discrete Gibbs measures", "journal": "The Annals of Applied Probability", "year": "2008", "authors": "Peter Eichelsbacher; Gesine Reinert"}, {"ref_id": "b16", "title": "Introduction to Markov chain Monte Carlo", "journal": "CRC Press", "year": "2011", "authors": "Charles J Geyer"}, {"ref_id": "b17", "title": "Likelihood ratio gradient estimation for stochastic systems", "journal": "Commun. ACM", "year": "1990-10", "authors": "W Peter;  Glynn"}, {"ref_id": "b18", "title": "Measuring sample quality with Stein's method", "journal": "", "year": "2015", "authors": "Jackson Gorham; Lester Mackey"}, {"ref_id": "b19", "title": "Backpropagation through the void: Optimizing control variates for black-box gradient estimation", "journal": "", "year": "2018", "authors": "W Grathwohl; D Choi; Y Wu; G Roeder; D Duvenaud"}, {"ref_id": "b20", "title": "Oops I took a gradient: Scalable sampling for discrete distributions", "journal": "", "year": "2021", "authors": "Will Grathwohl; Kevin Swersky; Milad Hashemi; David Duvenaud; Chris Maddison"}, {"ref_id": "b21", "title": "MuProp: Unbiased backpropagation for stochastic neural networks", "journal": "", "year": "2016", "authors": "Shixiang Gu; Sergey Levine; Ilya Sutskever; Andriy Mnih"}, {"ref_id": "b22", "title": "Variance reduction via an approximating Markov process", "journal": "", "year": "1997", "authors": "G Shane;  Henderson"}, {"ref_id": "b23", "title": "The reproducing stein kernel approach for post-hoc corrected sampling", "journal": "", "year": "2020", "authors": "Liam Hodgkinson; Robert Salomone; Fred Roosta"}, {"ref_id": "b24", "title": "Stein's method for birth and death chains", "journal": "", "year": "2004", "authors": "Susan Holmes"}, {"ref_id": "b25", "title": "Categorical reparameterization with Gumbel-softmax. International Conference on Learning Representations", "journal": "", "year": "2017", "authors": "Eric Jang; Shixiang Gu; Ben Poole"}, {"ref_id": "b26", "title": "Pathwise derivatives beyond the reparameterization trick", "journal": "PMLR", "year": "2018", "authors": "Martin Jankowiak; Fritz Obermeyer"}, {"ref_id": "b27", "title": "The classification of birth and death processes. Transactions of the", "journal": "American Mathematical Society", "year": "1957", "authors": "Samuel Karlin; James Mcgregor"}, {"ref_id": "b28", "title": "Auto-encoding variational Bayes", "journal": "", "year": "2014", "authors": "P Diederik; Max Kingma;  Welling"}, {"ref_id": "b29", "title": "Buy 4 REINFORCE samples, get a baseline for free! In DeepRLStructPred@ICLR", "journal": "", "year": "2019", "authors": "W Kool; H V Hoof; M Welling"}, {"ref_id": "b30", "title": "Estimating gradients for discrete random variables by sampling without replacement", "journal": "", "year": "2020", "authors": "Wouter Kool; Max Herke Van Hoof;  Welling"}, {"ref_id": "b31", "title": "Human-level concept learning through probabilistic program induction", "journal": "Science", "year": "2015", "authors": "Ruslan Brenden M Lake; Joshua B Salakhutdinov;  Tenenbaum"}, {"ref_id": "b32", "title": "Gradient-based learning applied to document recognition", "journal": "Proceedings of the IEEE", "year": "1998", "authors": "Yann Lecun; L\u00e9on Bottou; Yoshua Bengio; Patrick Haffner"}, {"ref_id": "b33", "title": "Action-depedent control variates for policy optimization via Stein's identity", "journal": "", "year": "2017", "authors": "Hao Liu; Yihao Feng; Yi Mao; Dengyong Zhou; Jian Peng; Qiang Liu"}, {"ref_id": "b34", "title": "The concrete distribution: A continuous relaxation of discrete random variables", "journal": "", "year": "2017", "authors": "Andriy Chris J Maddison; Yee Whye Mnih;  Teh"}, {"ref_id": "b35", "title": "Zero variance Markov chain Monte Carlo for Bayesian estimators", "journal": "Statistics and Computing", "year": "2013", "authors": "Antonietta Mira; Reza Solgi; Daniele Imparato"}, {"ref_id": "b36", "title": "Neural variational inference and learning in belief networks", "journal": "", "year": "2014", "authors": "Andriy Mnih; Karol Gregor"}, {"ref_id": "b37", "title": "Variational inference for Monte Carlo objectives", "journal": "", "year": "2016", "authors": "Andriy Mnih; Danilo Rezende"}, {"ref_id": "b38", "title": "Monte Carlo gradient estimation in machine learning", "journal": "Journal of Machine Learning Research", "year": "2020", "authors": "Shakir Mohamed; Mihaela Rosca; Michael Figurnov; Andriy Mnih"}, {"ref_id": "b39", "title": "Implicit MLE: backpropagating through discrete exponential family distributions", "journal": "", "year": "2021", "authors": "Mathias Niepert; Pasquale Minervini; Luca Franceschi"}, {"ref_id": "b40", "title": "Control functionals for Monte Carlo integration", "journal": "Journal of the Royal Statistical Society: Series B (Statistical Methodology)", "year": "2017", "authors": "J Chris; Mark Oates; Nicolas Girolami;  Chopin"}, {"ref_id": "b41", "title": "Monte Carlo theory, methods and examples", "journal": "", "year": "2013", "authors": "Art B Owen"}, {"ref_id": "b42", "title": "Variational Bayesian inference with stochastic search", "journal": "", "year": "2012", "authors": "John Paisley; M David; Michael I Jordan Blei"}, {"ref_id": "b43", "title": "A unified view of likelihood ratio and reparameterization gradients", "journal": "PMLR", "year": "2021", "authors": "Paavo Parmas; Masashi Sugiyama"}, {"ref_id": "b44", "title": "Black box variational inference", "journal": "", "year": "2014", "authors": "Rajesh Ranganath; Sean Gerrish; David Blei"}, {"ref_id": "b45", "title": "Approximating stationary distributions of fast mixing Glauber dynamics, with applications to exponential random graphs", "journal": "The Annals of Applied Probability", "year": "2019", "authors": "Gesine Reinert; Nathan Ross"}, {"ref_id": "b46", "title": "Stochastic backpropagation and approximate inference in deep generative models", "journal": "", "year": "2014", "authors": "Danilo J Rezende; Shakir Mohamed; Daan Wierstra"}, {"ref_id": "b47", "title": "VarGrad: A low-variance gradient estimator for variational inference", "journal": "", "year": "2020", "authors": "Lorenz Richter; Ayman Boustati; Nikolas N\u00fcsken; Francisco Ruiz; Omer Deniz Akyildiz"}, {"ref_id": "b48", "title": "On using control variates with stochastic approximation for variational Bayes and its connection to stochastic linear regression", "journal": "", "year": "2014", "authors": "Tim Salimans; A David;  Knowles"}, {"ref_id": "b49", "title": "Gradient estimation using stochastic computation graphs", "journal": "Advances in Neural Information Processing Systems", "year": "2015", "authors": "John Schulman; Nicolas Heess; Theophane Weber; Pieter Abbeel"}, {"ref_id": "b50", "title": "Outrageously large neural networks: The sparsely-gated mixture-of-experts layer", "journal": "", "year": "2017", "authors": "Noam Shazeer; Azalia Mirhoseini; Krzysztof Maziarz; Andy Davis; Quoc Le; Geoffrey Hinton; Jeff Dean"}, {"ref_id": "b51", "title": "Scalable control variates for Monte Carlo methods via stochastic optimization", "journal": "", "year": "2020", "authors": "Shijing Si; Chris Oates; B Andrew; Lawrence Duncan; Fran\u00e7ois-Xavier Carin;  Briol"}, {"ref_id": "b52", "title": "Minimum probability flow learning", "journal": "", "year": "2011", "authors": "Jascha Sohl-Dickstein; Peter Battaglino;  Michael R Deweese"}, {"ref_id": "b53", "title": "Regularised zero-variance control variates for high-dimensional variance reduction", "journal": "", "year": "2018", "authors": "F Leah; Chris J South; Antonietta Oates; Christopher Mira;  Drovandi"}, {"ref_id": "b54", "title": "A bound for the error in the normal approximation to the distribution of a sum of dependent random variables", "journal": "", "year": "1972", "authors": "Charles Stein"}, {"ref_id": "b55", "title": "Use of exchangeable pairs in the analysis of simulations", "journal": "", "year": "2004", "authors": "Charles Stein; Persi Diaconis; Susan Holmes; Gesine Reinert"}, {"ref_id": "b56", "title": "Stochastic processes and models", "journal": "OUP", "year": "2005", "authors": "David Stirzaker"}, {"ref_id": "b57", "title": "Doubly stochastic variational Bayes for non-conjugate inference", "journal": "", "year": "2014", "authors": "K Michalis; Miguel Titsias;  L\u00e1zaro-Gredilla"}, {"ref_id": "b58", "title": "Local expectation gradients for black box variational inference", "journal": "", "year": "2015", "authors": "K Michalis; Miguel Titsias;  L\u00e1zaro-Gredilla"}, {"ref_id": "b59", "title": "Double control variates for gradient estimation in discrete latent variable models", "journal": "", "year": "2022", "authors": "K Michalis; Jiaxin Titsias;  Shi"}, {"ref_id": "b60", "title": "Evaluating the variance of likelihood-ratio gradient estimators", "journal": "", "year": "2017", "authors": "Seiya Tokui; Issei Sato"}, {"ref_id": "b61", "title": "REBAR: Low-variance, unbiased gradient estimates for discrete latent variable models", "journal": "", "year": "2017", "authors": "G Tucker; A Mnih; C J Maddison; J Sohl-Dickstein"}, {"ref_id": "b62", "title": "NVAE: A deep hierarchical variational autoencoder", "journal": "", "year": "2020", "authors": "Arash Vahdat; Jan Kautz"}, {"ref_id": "b63", "title": "The optimal reward baseline for gradient-based reinforcement learning", "journal": "", "year": "2001", "authors": "Lex Weaver; Nigel Tao"}, {"ref_id": "b64", "title": "Simple statistical gradient-following algorithms for connectionist reinforcement learning", "journal": "Machine learning", "year": "1992", "authors": "J Ronald;  Williams"}, {"ref_id": "b65", "title": "Fashion-MNIST: a novel image dataset for benchmarking machine learning algorithms", "journal": "", "year": "2017", "authors": "Han Xiao; Kashif Rasul; Roland Vollgraf"}, {"ref_id": "b66", "title": "Goodness-of-fit testing for discrete distributions via Stein discrepancy", "journal": "PMLR", "year": "2018", "authors": "Jiasen Yang; Qiang Liu; Vinayak Rao; Jennifer Neville"}, {"ref_id": "b67", "title": "ARM: Augment-REINFORCE-merge gradient for stochastic binary networks", "journal": "", "year": "2019", "authors": "Mingzhang Yin; Mingyuan Zhou"}, {"ref_id": "b68", "title": "Probabilistic best subset selection via gradient-based optimization", "journal": "", "year": "2020", "authors": "Mingzhang Yin; Nhat Ho; Bowei Yan; Xiaoning Qian; Mingyuan Zhou"}, {"ref_id": "b69", "title": "Informed proposals for local MCMC in discrete spaces", "journal": "Journal of the American Statistical Association", "year": "2020", "authors": "Giacomo Zanella"}], "figures": [{"figure_label": "12", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 :K = 212Figure 1: Training binary latent VAEs with 2 or 3 f evaluations per step on binarized MNIST.K = 2 In the first set of experiments we focus on the most common setting of K = 2 sample points and compare our variance reduction method to its counterparts including DisARM[14] and Double CV[60]. Results for RLOO are omitted since it is consistently outperformed by Double CV [see 60]. Table2shows, on all three datasets, RODEO achieves the best training ELBOs. In Figure1(left), we plot the gradient variance and average training ELBOs against training steps for all estimators on dynamically binarized MNIST. RODEO outperforms DisARM and Double CV by a large margin in gradient variance.", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 2 :2Figure 2: Training binary latent VAEs with Gaussian likelihoods, K = 2, and non-binarized datasets.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 3 :3Figure 3: Training hierarchical binary latent VAEs with four stochastic layers on Fashion-MNIST. In this experiment, the estimators have very different behaviors towards the beginning and the end of training. We show this on the right by zooming into the first 50K steps of the gradient variance plot.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 4 :4Figure 4: Ablation study of impact of RODEO components: (a) Stein operators, (b) LOO baseline and global and local CVs, (c) surrogate functions on binary VAE training performance.", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Figure 5 :5Figure 5: Comparing the performance of RODEO and RLOO on more expensive ResNet VAE models trained on binarized MNIST with K = 2. The middle plot shows the average wall clock performance over 5 trials.", "figure_data": ""}, {"figure_label": "7", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "Figure 7 :7Figure 7: Average 100-point test log-likelihood bounds for binary latent VAEs trained on (top) dynamically binarized and (bottom) non-binarized MNIST, Fashion-MNIST, and Omniglot using K = 2.", "figure_data": ""}, {"figure_label": "9", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "Figure 9 :9Figure 9: Average 100-point test log-likelihood bounds for binary latent VAEs trained on (top) dynamically binarized and (bottom) non-binarized MNIST, Fashion-MNIST, and Omniglot with three evaluations of f per step using RODEO/Double CV/ARMS with K = 3 or RELAX.", "figure_data": ""}, {"figure_label": "10", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "Figure 10 :10Figure 10: Training hierarchical binary latent VAEs with two stochastic layers on dynamically binarized MNIST, Fashion-MNIST and Omniglot. We plot (left) the average ELBO on training examples and (middle) variance of gradient estimates. We zoom into the first 50K steps of the variance plot on the right figure.", "figure_data": ""}, {"figure_label": "11", "figure_type": "figure", "figure_id": "fig_10", "figure_caption": "Figure 11 :11Figure 11: Training hierarchical binary latent VAEs with three stochastic layers. on dynamically binarized MNIST, Fashion-MNIST and Omniglot. We plot the average ELBO on training examples (left) and variance of gradient estimates (middle). We zoom into the first 50K steps of the variance plot on the right figure.", "figure_data": ""}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "Training binary latent VAEs with K = 2, 3 (except for RELAX which uses 3 evaluations) on MNIST, Fashion-MNIST, and Omniglot. We report the average ELBO (\u00b11 standard error) on the training set after 1M steps over 5 independent runs. Test data bounds are reported in Table4. DisARM \u2212102.75 \u00b1 0.08 \u2212237.68 \u00b1 0.13 \u2212116.50 \u00b1 0.04 668.03 \u00b1 0.61 182.65 \u00b1 0.47 446.61 \u00b1 1.16 Double CV \u2212102.14 \u00b1 0.06 \u2212237.55 \u00b1 0.16 \u2212116.39 \u00b1 0.10 676.87 \u00b1 1.18 186.35 \u00b1 0.64 447.65 \u00b1 0.87 RODEO (Ours) \u2212101.89 \u00b1 0.17 \u2212237.44 \u00b1 0.09 \u2212115.93 \u00b1 0.06 681.95 \u00b1 0.37 191.81 \u00b1 0.67 454.74 \u00b1 1.11 ARMS \u2212100.84 \u00b1 0.14 \u2212237.05 \u00b1 0.12 \u2212115.21 \u00b1 0.07 683.55 \u00b1 1.01 193.07 \u00b1 0.34 457.98 \u00b1 1.03 Double CV \u2212100.94 \u00b1 0.09 \u2212237.40 \u00b1 0.11 \u2212115.06 \u00b1 0.12 686.48 \u00b1 0.68 193.93 \u00b1 0.20 457.44 \u00b1 0.79 RODEO (Ours) \u2212100.46 \u00b1 0.13 \u2212236.88 \u00b1 0.12 \u2212115.01 \u00b1 0.05 692.37 \u00b1 0.39 196.56 \u00b1 0.42 461.87 \u00b1 0.90 RELAX (3 evals) \u2212101.99 \u00b1 0.04 \u2212237.74 \u00b1 0.12 \u2212115.70 \u00b1 0.08 688.58 \u00b1 0.52 196.38 \u00b1 0.66 462.23 \u00b1 0.63", "figure_data": "Bernoulli LikelihoodsGaussian LikelihoodsMNISTFashion-MNISTOmniglotMNISTFashion-MNISTOmniglotK = 2K = 3"}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "Architecture of the ResNet VAE in Appendix C.1. 3x3xC means kernel size 3x3 and C output channels. Each (De)conv Res block is composed of two (de)convolutional layers with strides 1, same padding, and ReLU activations, plus a skip connection with identity map. For Res blocks with downsample and upsample functions, the first convolutional layer has strides 2, and the skip connection is replaced by a convolutional layer with 2x2 kernel size and strides 2. of evaluating f dominates that of evaluating H, H * . This is often the case in practice. For example, state-of-the-art variational autoencoders [e.g., 63] are often built on expensive neural architectures such as deep residual networks (ResNets). Here, to demonstrate the practical advantage of our method as the complexity of f grows, we replace the two-layer MLP VAEs used in previous experiments with a ResNet VAE (architecture shown in Table3), while the neural network used by H, H * remains a single-layer MLP with 100 hidden units. We then compare the wall clock performance of RODEO with RLOO. The latent variables in this experiment remain binary and have 200 dimensions.The results are shown in Figure5. RODEO achieves better training ELBOs than RLOO in the same amount of time. In fact, for this VAE architecture, the per-iteration time of RODEO is 25.2ms, which is very close to the 23.1ms of RLOO. This indicates that the cost of f is significantly higher than that of H, H * .", "figure_data": "EncoderDecoderConv 3x3x16, strides 1, padding 1Fully connected, 7x7x64 unitsConv Res block 3x3x16Deconv Res block 3x3x64Conv Res block 3x3x16Deconv Res block 3x3x64Conv Res block 3x3x32 (downsample by 2) Deconv Res block 3x3x32 (upsample by 2)Conv Res block 3x3x32Deconv Res block 3x3x32Conv Res block 3x3x64 (downsample by 2) Deconv Res block 3x3x16 (upsample by 2)Conv Res block 3x3x64Deconv Res block 3x3x16Fully connected, 200 unitsDeconv 3x3x1, strides 1, padding 1where the cost"}, {"figure_label": "5", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "Average running time across 10 4 steps on an NVIDIA 3080Ti GPU with an AMD 5950X CPU for the VAE experiment on binary MNIST in Section 6.1.", "figure_data": "Double CVDisARM/ARMS RODEO (Ours) RELAX (3 evals)K = 2 2.11 ms/step K = 3 2.28 ms/step1.89 ms/step 1.91 ms/step3.08 ms/step 4.72 ms/step4.71 ms/step"}, {"figure_label": "6", "figure_type": "table", "figure_id": "tab_7", "figure_caption": "Average running time across 10 4 steps on an NVIDIA 3080Ti GPU with an AMD 5950X CPU when training hierarchical VAEs with K = 2.", "figure_data": "Double CVDisARMRODEO (Ours)Two layers4.33 ms/step3.54 ms/step6.79 ms/stepThree layers7.69 ms/step6.09 ms/step10.61 ms/stepFour layers 11.67 ms/step 9.53 ms/step14.91 ms/step"}, {"figure_label": "7", "figure_type": "table", "figure_id": "tab_8", "figure_caption": "Training hierarchical binary latent VAEs on dynamically binarized MNIST, Fashion-MNIST, and Omniglot. We report the average (\u00b11 standard error) training ELBOs and 100-point test loglikelihood bounds after 1M steps over 5 independent runs. \u00b1 0.06 \u2212239.82 \u00b1 0.07 \u2212114.06 \u00b1 0.04 \u221297.62 \u00b1 0.08 \u2212237.65 \u00b1 0.06 \u2212110.48 \u00b1 0.04 DisARM \u2212103.39 \u00b1 0.12 \u2212239.67 \u00b1 0.06 \u2212113.67 \u00b1 0.05 \u221297.56 \u00b1 0.07 \u2212237.61 \u00b1 0.06 \u2212110.15 \u00b1 0.04 RODEO (Ours) \u2212103.15 \u00b1 0.07 \u2212239.76 \u00b1 0.09 \u2212113.84 \u00b1 0.11 \u221297.43 \u00b1 0.03 \u2212237.63 \u00b1 0.07 \u2212110.32 \u00b1 0.10 Three layers Double CV \u221297.59 \u00b1 0.15 \u2212234.34 \u00b1 0.07 \u2212108.66 \u00b1 0.06 \u221293.71 \u00b1 0.12 \u2212234.34 \u00b1 0.07 \u2212107.48 \u00b1 0.07 DisARM \u221297.95 \u00b1 0.30 \u2212234.45 \u00b1 0.05 \u2212108.60 \u00b1 0.08 \u221294.12 \u00b1 0.28 \u2212234.46 \u00b1 0.06 \u2212107.32 \u00b1 0.10 RODEO (Ours) \u221297.21 \u00b1 0.17 \u2212234.11 \u00b1 0.10 \u2212108.51 \u00b1 0.04 \u221293.52 \u00b1 0.16 \u2212234.19 \u00b1 0.07 \u2212107.26 \u00b1 0.06 Four layers Double CV \u221298.73 \u00b1 0.06 \u2212235.69 \u00b1 0.07 \u2212110.92 \u00b1 0.06 \u221293.28 \u00b1 0.03 \u2212234.63 \u00b1 0.03 \u2212107.86 \u00b1 0.03 DisARM \u221298.97 \u00b1 0.02 \u2212235.50 \u00b1 0.04 \u2212110.85 \u00b1 0.07 \u221293.56 \u00b1 0.04 \u2212234.52 \u00b1 0.04 \u2212107.87 \u00b1 0.05 RODEO (Ours) \u221298.67 \u00b1 0.14 \u2212235.39 \u00b1 0.05 \u2212110.79 \u00b1 0.03 \u221293.27 \u00b1 0.09 \u2212234.39 \u00b1 0.06 \u2212107.77 \u00b1 0.02 MNIST", "figure_data": "Training ELBOTest Log-Likelihood BoundMNISTFashion-MNISTOmniglotMNISTFashion-MNISTOmniglotDouble CV\u2212103.52Two layers"}], "formulas": [{"formula_id": "formula_0", "formula_text": "Gibbs (4) 1 d d i=1 y \u2212i =x \u2212i q(yi|x\u2212i)h(y) \u2212 h(x) MPF (6)", "formula_coordinates": [2.0, 192.06, 105.12, 225.64, 26.18]}, {"formula_id": "formula_1", "formula_text": "1 d d i=1 h(deci(x)) \u2212 q(inc i (x)) q(x) h(x)", "formula_coordinates": [2.0, 272.35, 153.49, 135.73, 12.59]}, {"formula_id": "formula_2", "formula_text": "1 K K k=1 (f (x (k) ) \u2212 b)\u2207 \u03b7 log q \u03b7 (x (k) ) for x", "formula_coordinates": [2.0, 137.28, 406.52, 190.72, 14.56]}, {"formula_id": "formula_4", "formula_text": "1 K K k=1 f (x (k) ) \u2212 1 K\u22121 j\u0338 =k f (x (j) ) \u2207 \u03b7 log q \u03b7 (x (k) ). (RLOO", "formula_coordinates": [2.0, 190.02, 509.75, 309.02, 14.56]}, {"formula_id": "formula_5", "formula_text": ")", "formula_coordinates": [2.0, 499.04, 513.03, 5.63, 8.64]}, {"formula_id": "formula_6", "formula_text": "c \u225c E q\u03b7 [b(x (k) )\u2207 \u03b7 log q \u03b7 (x (k)", "formula_coordinates": [2.0, 333.29, 580.73, 126.62, 11.23]}, {"formula_id": "formula_7", "formula_text": "1 K K k=1 (f (x (k) ) \u2212 b(x (k) ))\u2207 \u03b7 log q \u03b7 (x (k) ) + c. For example, b(x (k)", "formula_coordinates": [2.0, 108.0, 603.18, 396.17, 25.2]}, {"formula_id": "formula_8", "formula_text": "1 K K k=1 f (x (k) ) \u2212b k (x (k) ) \u2212 1 K\u22121 j\u0338 =k f (x (j) ) \u2212b j (x (j) ) \u2207 \u03b7 log q \u03b7 (x (k) ) + c.", "formula_coordinates": [2.0, 122.09, 658.54, 369.02, 14.56]}, {"formula_id": "formula_9", "formula_text": "b k (x) = \u03b1 \u2022 1 K\u22121 j\u0338 =k f (x (j) )(x \u2212 \u00b5) for \u00b5 = E q\u03b7 [x]", "formula_coordinates": [3.0, 108.0, 97.53, 221.56, 13.47]}, {"formula_id": "formula_10", "formula_text": "P \u22a4 q = q and hence E q [(P \u2212 I)h] = 0,(1)", "formula_coordinates": [3.0, 108.0, 317.11, 396.67, 22.13]}, {"formula_id": "formula_11", "formula_text": "(Ah)(x) = lim t\u21920 E[h(X (t) )|X (0) =x]\u2212h(x) t ,(2)", "formula_coordinates": [3.0, 227.87, 444.09, 276.79, 18.73]}, {"formula_id": "formula_12", "formula_text": "P xy = 1 d d i=1 q(y i |x \u2212i )1(y \u2212i = x \u2212i ),(3)", "formula_coordinates": [3.0, 225.64, 598.28, 279.03, 14.56]}, {"formula_id": "formula_13", "formula_text": "(Ah)(x) = 1 d d i=1 y\u2212i=x\u2212i q(y i |x \u2212i )h(y) \u2212 h(x).(4)", "formula_coordinates": [3.0, 197.23, 641.37, 307.44, 14.56]}, {"formula_id": "formula_14", "formula_text": "A xy = \u03ba (q(y)/q(x)) 1(y \u2208 N x , y \u0338 = x) \u2212 z\u0338 =x A xz 1(y = x),(5)", "formula_coordinates": [3.0, 176.55, 708.82, 328.12, 11.18]}, {"formula_id": "formula_15", "formula_text": "(Ah)(x) = y\u2208Nx,y\u0338 =x \u03ba q(y) q(x) (h(y) \u2212 h(x)).(6)", "formula_coordinates": [4.0, 209.36, 127.57, 295.31, 14.38]}, {"formula_id": "formula_16", "formula_text": "inc i (x) = x + e i (s (idx(xi)+1) mod m \u2212 x i ) and dec i (x) = x + e i (s (idx(xi)\u22121) mod m \u2212 x i ).", "formula_coordinates": [4.0, 109.87, 223.96, 392.26, 9.99]}, {"formula_id": "formula_17", "formula_text": "i,x = q(inci(x)) q(x)", "formula_coordinates": [4.0, 388.06, 243.67, 63.68, 14.38]}, {"formula_id": "formula_18", "formula_text": "A xy = 1 d d i=1 b i,x 1(y = inc i (x)) + d i,x 1(y = dec i (x)) \u2212 (b i,x + d i,x )1(y = x),", "formula_coordinates": [4.0, 137.4, 278.15, 337.21, 14.56]}, {"formula_id": "formula_19", "formula_text": "(Ag)(x) = 1 d d i=1 b i,x (g(inc i (x)) \u2212 g(x)) \u2212 d i,x (g(x) \u2212 g(dec i (x))).(7)", "formula_coordinates": [4.0, 159.4, 319.77, 345.27, 14.56]}, {"formula_id": "formula_20", "formula_text": "(Ah)(x) = 1 d d i=1 h(dec i (x)) \u2212 b i,x h(x).(8)", "formula_coordinates": [4.0, 218.0, 392.14, 286.67, 14.56]}, {"formula_id": "formula_21", "formula_text": "N x = {inc i (x), dec i (x) for i \u2208 [d]}.", "formula_coordinates": [4.0, 354.62, 473.9, 151.13, 9.65]}, {"formula_id": "formula_22", "formula_text": "E q\u03b7 [f (x)\u2207 \u03b7 log q \u03b7 (x)].", "formula_coordinates": [4.0, 309.09, 540.56, 94.96, 9.65]}, {"formula_id": "formula_23", "formula_text": "E q\u03b7 [f (x)\u2207 \u03b7i log q \u03b7 (x) + (Ah i )(x)].(9)", "formula_coordinates": [4.0, 232.12, 585.92, 272.55, 9.65]}, {"formula_id": "formula_24", "formula_text": "E q\u03b7 [f \u2207 \u03b7i log q \u03b7 ] \u2212 f \u2207 \u03b7i log q \u03b7 = Ah i .(10)", "formula_coordinates": [4.0, 225.77, 640.95, 278.9, 9.65]}, {"formula_id": "formula_25", "formula_text": "Algorithm 1 Optimizing E q\u03b7 [f \u03b8 (x)] with RODEO gradients input: Objective f \u03b8 , sample points x (1:K) i.i.d. \u223c q \u03b7 , Stein operator A, step sizes \u03b1 t , \u03b2 t for t = 1 : T do 1: {f \u03b8 (x (k) ), \u2207 \u03b8 f \u03b8 (x (k) ), \u2207f \u03b8 (x (k) )} K k=1 \u2190 autodiff(f \u03b8 , x (1:K) ). 2: Compute the surrogates h k (x (j) ), h \u22c6 k (x (j)", "formula_coordinates": [5.0, 107.64, 75.39, 349.18, 68.84]}, {"formula_id": "formula_26", "formula_text": "4: \u03b8 \u2190 \u03b8 + \u03b1 t 1 K K k=1 \u2207 \u03b8 f (x (k) ). 5: \u03b7 \u2190 \u03b7 + \u03b1 t g \u03b3 (x (1:K) ). 6: Update hyperparameters: \u03b3 \u2190 \u03b3 \u2212 \u03b2 t \u2207 \u03b3 \u2225g \u03b3 (x (1:K) )\u2225 2 2 .", "formula_coordinates": [5.0, 112.98, 156.57, 237.44, 39.57]}, {"formula_id": "formula_27", "formula_text": "(x) = h(x)\u2207 \u03b7 log q \u03b7 (x),(11)", "formula_coordinates": [5.0, 258.49, 252.13, 246.18, 9.65]}, {"formula_id": "formula_28", "formula_text": "\u2207 \u03b7i log q \u03b7 )(x) = E Xt+1|Xt=x [f (X t+1 )\u2207 \u03b7i log q \u03b7 (X t+1 )]", "formula_coordinates": [5.0, 172.37, 300.71, 232.12, 9.96]}, {"formula_id": "formula_29", "formula_text": "1 K K k=1 [f (x (k) )\u2207 \u03b7 log q \u03b7 (x (k) ) + (Ah k )(x (k) )].(12)", "formula_coordinates": [5.0, 206.5, 377.17, 298.17, 14.56]}, {"formula_id": "formula_30", "formula_text": "h k (y) = 1 K\u22121 j\u0338 =k H(f (x (j) ), \u2207f (x (j) ) \u22a4 (y \u2212 x (j) )).(13)", "formula_coordinates": [5.0, 194.22, 411.05, 310.45, 13.47]}, {"formula_id": "formula_31", "formula_text": "K K k=1 (Ah k )(x (k)", "formula_coordinates": [5.0, 170.76, 463.99, 81.61, 14.56]}, {"formula_id": "formula_32", "formula_text": "1 K K k=1 [(f (x (k) )\u2212 1 K\u22121 j\u0338 =k (f (x (j) )+(Ah j )(x (j) )))\u2207 \u03b7 log q \u03b7 (x (k) )+(Ah \u22c6 k )(x (k) )], (RODEO) whereh \u22c6 k (y) = h \u22c6 k (y)\u2207 \u03b7 log q \u03b7 (y) and {h k , h \u22c6 k } K k=1 are scalar-valued functions.", "formula_coordinates": [5.0, 107.64, 567.54, 397.03, 44.97]}, {"formula_id": "formula_33", "formula_text": "K\u22121 j\u0338 =k f (x (j) ), while (Ah \u22c6 k )(x (k)", "formula_coordinates": [5.0, 127.36, 625.78, 154.09, 13.17]}, {"formula_id": "formula_34", "formula_text": "h \u22c6 k (y) = 1 K\u22121 j\u0338 =k H \u22c6 (f (x (j) ), \u2207f (x (j) ) \u22a4 (y \u2212 x (j) )).(14)", "formula_coordinates": [5.0, 191.93, 677.77, 312.74, 13.47]}, {"formula_id": "formula_35", "formula_text": "(1:K) ), then \u2207 \u03b3 Tr(Var(g \u03b3 (x (1:K) ))) = E[\u2207 \u03b3 \u2225g \u03b3 (x (1:K) )\u2225 2 2 ].", "formula_coordinates": [6.0, 108.0, 249.43, 396.0, 24.9]}, {"formula_id": "formula_36", "formula_text": "K = 3", "formula_coordinates": [7.0, 108.0, 565.87, 31.38, 8.77]}, {"formula_id": "formula_37", "formula_text": "h k (y) = H 1 K\u22121 j\u0338 =k f (x (j) ), 1 K\u22121 j\u0338 =k \u2207f (x (j) ) \u22a4 (y \u2212 x (j) ) .", "formula_coordinates": [10.0, 168.53, 92.49, 274.93, 13.47]}, {"formula_id": "formula_38", "formula_text": "1 K K k=1 (f (x (k) ) \u2212 b k )\u2207 \u03b7 log q \u03b7 (x (k) ) + E[b k \u2207 \u03b7 log q \u03b7 (x (k) )].(15)", "formula_coordinates": [14.0, 182.16, 112.67, 322.51, 30.55]}, {"formula_id": "formula_39", "formula_text": "x (k) in b k through the continuous reparameteriza- tion x = H(z), z (k) \u223c q \u03b7 (z|x = x (k)", "formula_coordinates": [14.0, 108.0, 148.31, 397.65, 23.22]}, {"formula_id": "formula_40", "formula_text": "E x (k) [E z (k) |x (k) [f (\u03c3 \u03bb (z (k) ))]\u2207 \u03b7 log q \u03b7 (x (k) )] = \u2207 \u03b7 E q\u03b7(z) [f (\u03c3 \u03bb (z))] \u2212 E x (k) [\u2207 \u03b7 E q\u03b7(z (k) |x (k) ) [f (\u03c3 \u03bb (z (k) ))]].", "formula_coordinates": [14.0, 179.42, 199.88, 253.15, 29.9]}, {"formula_id": "formula_41", "formula_text": "k = c \u03d5 (z (k) ) with b k = h k (\u03c3 \u03bb (z (k)", "formula_coordinates": [14.0, 326.5, 284.29, 141.97, 11.23]}, {"formula_id": "formula_42", "formula_text": "1 K K k=1 [(f (x (k) ) \u2212 1 K \u2212 1 j\u0338 =k (f (x (j) ) + (Ah j )(x (j) ))) \u2022 \u2207 \u03b7 log q \u03b7 (x (k) ) + (Ah \u22c6 k )(x (k) )].(16)", "formula_coordinates": [14.0, 117.88, 360.08, 386.79, 30.55]}, {"formula_id": "formula_43", "formula_text": "1 K K k=1 E q\u03b7 [f (x (k) )\u2207 \u03b7 log q \u03b7 (x (k) )] \u2212 1 K(K \u2212 1) K k=1 j\u0338 =k E q\u03b7 [(f (x (j) ) + (Ah j )(x (j) ))\u2207 \u03b7 log q \u03b7 (x (k) )] + 1 K K k=1 E q\u03b7 [(Ah \u22c6 k )(x (k) )].", "formula_coordinates": [14.0, 171.03, 412.18, 272.16, 102.27]}, {"formula_id": "formula_44", "formula_text": "E q\u03b7 [(f (x (j) ) + (Ah j )(x (j) ))\u2207 \u03b7 log q \u03b7 (x (k) )] = E x (k) \u223cq\u03b7 [E q\u03b7 [f (x (j) ) + (Ah j )(x (j) ) | x (k) ]\u2207 \u03b7 log q \u03b7 (x (k) )] = E x (k) \u223cq\u03b7 [E q\u03b7 [f (x (j) ) | x (k) ]\u2207 \u03b7 log q \u03b7 (x (k) )] = E q\u03b7 [f (x (j) )\u2207 \u03b7 log q \u03b7 (x (k) )] = E x (j) \u223cq\u03b7 [f (x (j) )E x (k) \u223cq\u03b7 [\u2207 \u03b7 log q \u03b7 (x (k) ) | x (j) ]] = 0,", "formula_coordinates": [14.0, 178.72, 545.05, 254.56, 81.3]}, {"formula_id": "formula_45", "formula_text": "q(y) q(x)+q(y) = q(yi|x\u2212i) q(xi|x\u2212i)+q(yi|x\u2212i) = q(y i |x \u2212i ).", "formula_coordinates": [16.0, 109.2, 426.88, 179.47, 14.47]}], "doi": ""}