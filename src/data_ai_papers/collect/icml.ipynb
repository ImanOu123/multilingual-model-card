{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import rich\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_section_block(soup):\n",
    "    section_block = {}\n",
    "    section_block['abstact'] = soup.find_all('div', class_='abstract-section')\n",
    "    section_block['display_card'] = soup.find_all('div', class_='displaycards touchup-date')\n",
    "    section_block['collapse'] = soup.find_all('div', class_='collapse')\n",
    "    \n",
    "    return section_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://icml.cc/virtual/2022/awards_detail\"\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Raises an HTTPError for bad responses\n",
    "html_content = response.text\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "section_blocks = gain_section_block(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 17/24 [00:00<00:00, 68.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "No Best Paper Awards found for year 2016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:04<00:00,  4.92it/s]\n"
     ]
    }
   ],
   "source": [
    "award_paper_by_year = {}\n",
    "for year in tqdm(range(2000, 2024)):\n",
    "    if year >= 2019 <= 2023:\n",
    "        url = f\"https://icml.cc/virtual/{year}/awards_detail\"\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to retrieve data for year {year}\")\n",
    "            continue\n",
    "        \n",
    "        response.raise_for_status() \n",
    "        html_content = response.text\n",
    "\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        paper_rows = soup.find_all('tr')\n",
    "\n",
    "        papers_data = []\n",
    "\n",
    "        for row in paper_rows:\n",
    "            award_div = row.find('div')\n",
    "            if award_div:\n",
    "                award = award_div.text.strip()\n",
    "                paper_section = row.find('a', class_='small-title')\n",
    "                if paper_section:\n",
    "                    paper_title = paper_section.text.strip()\n",
    "                    link = paper_section.get('href', None)\n",
    "                    \n",
    "                    papers_data.append({\n",
    "                        'title': paper_title,\n",
    "                        'venue': \"NeurIPS\",\n",
    "                        'year': year,\n",
    "                        'award': award,\n",
    "                        'link': None\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"No Best Paper Awards section found for year {year}\")\n",
    "        award_paper_by_year[year] = papers_data\n",
    "    elif year == 2018:\n",
    "        url = f\"https://icml.cc/Conferences/{year}/Awards\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to retrieve data for year {year}\")\n",
    "            continue\n",
    "\n",
    "        html_content = response.text\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        papers_data = []\n",
    "\n",
    "        awards = ['Best Paper Awards', 'Best Paper Runner Up Awards']\n",
    "\n",
    "        for award in awards:\n",
    "            award_section = soup.find('h4', string=award)\n",
    "            \n",
    "            if award_section:\n",
    "                current_award = award_section.text.strip()\n",
    "                paper_paragraphs = award_section.find_next_siblings('p')\n",
    "                \n",
    "                for paragraph in paper_paragraphs:\n",
    "                    if paragraph.find('strong') and paragraph.find('em'):\n",
    "                        paper_title = paragraph.find('strong').text.strip()\n",
    "                        \n",
    "                        papers_data.append({\n",
    "                            'title': paper_title,\n",
    "                            'venue': \"ICML\",\n",
    "                            'year': year,\n",
    "                            'award': current_award,\n",
    "                            'link': None\n",
    "                        })\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "        award_paper_by_year[year] = papers_data\n",
    "\n",
    "        if not papers_data:\n",
    "            print(f\"No awards found for year {year}\")\n",
    "    elif year == 2017:\n",
    "        url = f\"https://icml.cc/Conferences/{year}/Awards\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to retrieve data for year {year}\")\n",
    "            continue\n",
    "\n",
    "        html_content = response.text\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        papers_data = []\n",
    "\n",
    "        # 找到ICML Awards的h3标签\n",
    "        awards_section = soup.find('h3', string=lambda text: 'ICML' in text and 'Awards' in text)\n",
    "\n",
    "        if awards_section:\n",
    "            current_award = \"\"\n",
    "            for element in awards_section.find_next_siblings():\n",
    "                if element.name == 'h4':\n",
    "                    award_title = element.text.strip()\n",
    "                    if 'Test of Time Award' in award_title:\n",
    "                        current_award = 'Test of Time Award'\n",
    "                    elif 'Best Paper Award' in award_title:\n",
    "                        current_award = 'Best Paper Award'\n",
    "                    elif 'Honorable Mentions' in award_title:\n",
    "                        if 'Test of Time Award' in current_award:\n",
    "                            current_award = 'Honorable Mention for Test of Time Award'\n",
    "                        elif 'Best Paper Award' in current_award:\n",
    "                            current_award = 'Honorable Mention for Best Paper Award'\n",
    "                elif element.name == 'p' and element.find('strong'):\n",
    "                    paper_title = element.find('strong').text.strip()\n",
    "                    papers_data.append({\n",
    "                        'title': paper_title,\n",
    "                        'venue': \"ICML\",\n",
    "                        'year': year,\n",
    "                        'award': current_award,\n",
    "                        'link': None\n",
    "                    })\n",
    "\n",
    "        award_paper_by_year[year] = papers_data\n",
    "\n",
    "        if not papers_data:\n",
    "            print(f\"No awards found for year {year}\")\n",
    "    elif year == 2016:\n",
    "        url = f\"https://icml.cc/Conferences/{year}/index.html%3Fp=2009.html\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to retrieve data for year {year}\")\n",
    "            continue\n",
    "\n",
    "        response.raise_for_status() \n",
    "        html_content = response.text\n",
    "\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        papers_data = []\n",
    "\n",
    "        # 查找包含 \"Best paper\" 的 h2 标签\n",
    "        best_paper_section = soup.find(['h2', 'h3', 'h4'], string=lambda text: text and 'Best paper' in text.lower())\n",
    "\n",
    "        if not best_paper_section:\n",
    "            # 如果找不到标题，尝试直接查找包含 \"Best paper\" 的 ul\n",
    "            best_paper_section = soup.find('ul', string=lambda text: text and 'Best paper' in text.lower())\n",
    "        print(best_paper_section)\n",
    "        if best_paper_section:\n",
    "            # 如果找到的是 ul，直接使用；否则查找下一个 ul\n",
    "            paper_list = best_paper_section if best_paper_section.name == 'ul' else best_paper_section.find_next('ul')\n",
    "            \n",
    "            if paper_list:\n",
    "                for paper_item in paper_list.find_all('li'):\n",
    "                    title_span = paper_item.find('span', class_='titlepaper')\n",
    "                    \n",
    "                    if title_span:\n",
    "                        paper_title = title_span.find('a').text.strip()\n",
    "                        link = title_span.find('a')['href']\n",
    "                        pdf_link = paper_item.find('a', href=lambda href: href and href.endswith('.pdf'))\n",
    "                        pdf_url = pdf_link['href'] if pdf_link else None\n",
    "                        \n",
    "                        papers_data.append({\n",
    "                            'title': paper_title,\n",
    "                            'venue': \"ICML\",\n",
    "                            'year': year,\n",
    "                            'award': \"Best Paper\",\n",
    "                            'link': link,\n",
    "                            'pdf': pdf_url\n",
    "                        })\n",
    "\n",
    "        if not papers_data:\n",
    "            print(f\"No Best Paper Awards found for year {year}\")\n",
    "        else:\n",
    "            award_paper_by_year[year] = papers_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2016",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# award_paper_by_year.keys()\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43maward_paper_by_year\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2016\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 2016"
     ]
    }
   ],
   "source": [
    "# award_paper_by_year.keys()\n",
    "award_paper_by_year[2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017 7\n",
      "2018 10\n",
      "2019 4\n",
      "2020 5\n",
      "2021 10\n",
      "2022 31\n",
      "2023 8\n"
     ]
    }
   ],
   "source": [
    "for key in award_paper_by_year.keys():\n",
    "    print(key, len(award_paper_by_year[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_list = []\n",
    "sorted_years = sorted(award_paper_by_year.keys(), reverse=True) \n",
    "for year in sorted_years:\n",
    "    for paper in award_paper_by_year[year]:\n",
    "        paper_list.append(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_papers = {}\n",
    "for paper in paper_list:\n",
    "    key = (paper['title'], paper['year'])\n",
    "    if key not in unique_papers:\n",
    "        unique_papers[key] = paper\n",
    "\n",
    "paper_list = list(unique_papers.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paper_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_f = open('icml_best_papers.json', 'w')\n",
    "json.dump(paper_list, out_f, indent=2)\n",
    "out_f.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_persona",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
