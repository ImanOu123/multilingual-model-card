[
  {
    "title": "Privacy Auditing with One (1) Training Run",
    "venue": "NeurIPS",
    "year": "2023",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "Are Emergent Abilities of Large Language Models a Mirage?",
    "venue": "NeurIPS",
    "year": "2023",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "Is Out-of-distribution Detection Learnable?",
    "venue": "NeurIPS",
    "year": "2022",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding",
    "venue": "NeurIPS",
    "year": "2022",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "Elucidating the Design Space of Diffusion-Based Generative Models",
    "venue": "NeurIPS",
    "year": "2022",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "ProcTHOR: Large-Scale Embodied AI Using Procedural Generation",
    "venue": "NeurIPS",
    "year": "2022",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "Using natural language and program abstractions to instill human inductive biases in machines",
    "venue": "NeurIPS",
    "year": "2022",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "A Neural Corpus Indexer for Document Retrieval",
    "venue": "NeurIPS",
    "year": "2022",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "High-dimensional limit theorems for SGD: Effective dynamics and critical scaling",
    "venue": "NeurIPS",
    "year": "2022",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "Riemannian Score-Based Generative Modelling",
    "venue": "NeurIPS",
    "year": "2022",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "Gradient Estimation with Discrete Stein Operators",
    "venue": "NeurIPS",
    "year": "2022",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "An empirical analysis of compute-optimal large language model training",
    "venue": "NeurIPS",
    "year": "2022",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "Beyond neural scaling laws: beating power law scaling via data pruning",
    "venue": "NeurIPS",
    "year": "2022",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "On-Demand Sampling: Learning Optimally from Multiple Distributions",
    "venue": "NeurIPS",
    "year": "2022",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "A Universal Law of Robustness via Isoperimetry",
    "venue": "NeurIPS",
    "year": "2021",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "On the Expressivity of Markov Reward",
    "venue": "NeurIPS",
    "year": "2021",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "Deep Reinforcement Learning at the Edge of the Statistical Precipice",
    "venue": "NeurIPS",
    "year": "2021",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "MAUVE: Measuring the Gap Between Neural Text and Human Text using Divergence Frontiers",
    "venue": "NeurIPS",
    "year": "2021",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "Continuized Accelerations of Deterministic and Stochastic Gradient Descents, and of Gossip Algorithms",
    "venue": "NeurIPS",
    "year": "2021",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "Moser Flow: Divergence-based Generative Modeling on Manifolds",
    "venue": "NeurIPS",
    "year": "2021",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "Reduced, Reused and Recycled: The Life of a Dataset in Machine Learning Research",
    "venue": "NeurIPS",
    "year": "2021",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "ATOM3D: Tasks on Molecules in Three Dimensions",
    "venue": "NeurIPS",
    "year": "2021",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "No-Regret Learning Dynamics for Extensive-Form Correlated Equilibrium",
    "venue": "NeurIPS",
    "year": "2020",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "Improved guarantees and a multiple-descent curve for the Column Subset Selection Problem and the Nystr\u00f6m method",
    "venue": "NeurIPS",
    "year": "2020",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "Language Models are Few-Shot Learners",
    "venue": "NeurIPS",
    "year": "2020",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "Distribution-Independent PAC Learning of Halfspaces with Massart Noise",
    "venue": "NeurIPS",
    "year": "2019",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "Non-delusional Q-learning and Value-iteration",
    "venue": "NeurIPS",
    "year": "2018",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "Optimal Algorithms for Non-Smooth Distributed Optimization in Networks",
    "venue": "NeurIPS",
    "year": "2018",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "Nearly Tight Sample Complexity Bounds for Learning Mixtures of Gaussians via Sample Compression Schemes",
    "venue": "NeurIPS",
    "year": "2018",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "Neural Ordinary Differential Equations",
    "venue": "NeurIPS",
    "year": "2018",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "Safe and Nested Subgame Solving for Imperfect-Information Games",
    "venue": "NeurIPS",
    "year": "2017",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "Variance-based Regularization with Convex Objectives",
    "venue": "NeurIPS",
    "year": "2017",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "A Linear-Time Kernel Goodness-of-Fit Test",
    "venue": "NeurIPS",
    "year": "2017",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "Value Iteration Networks",
    "venue": "NeurIPS",
    "year": "2016",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "Competitive Distribution Estimation: Why is Good-Turing Good",
    "venue": "NeurIPS",
    "year": "2015",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "Fast Convergence of Regularized Learning in Games",
    "venue": "NeurIPS",
    "year": "2015",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "Asymmetric LSH (ALSH) for Sublinear Time Maximum Inner Product Search (MIPS)",
    "venue": "NeurIPS",
    "year": "2014",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "A* Sampling",
    "venue": "NeurIPS",
    "year": "2014",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "A memory frontier for complex synapses",
    "venue": "NeurIPS",
    "year": "2013",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "Submodular Optimization with Submodular Cover and Submodular Knapsack Constraints",
    "venue": "NeurIPS",
    "year": "2013",
    "award": "Best Paper Award",
    "link": null
  },
  {
    "title": "Scalable Influence Estimation in Continuous-Time Diffusion Networks",
    "venue": "NeurIPS",
    "year": "2013",
    "award": "Best Paper Award",
    "link": null
  }
]