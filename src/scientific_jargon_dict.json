{
    "Chinese": {
        "Transformer encoder": "变压器编码器",
        "GELU nonlinearities": "GELU非线性",
        "parameter-reduction techniques": "参数减少技术",
        "BERT": "BERT",
        "GLUE": "粘合剂",
        "RACE": "种族",
        "SQuAD": "队伍",
        "self-supervised loss": "自我监督的损失",
        "inter-sentence coherence": "句子之间的连贯性",
        "Factorized embedding parameterization": "分数化嵌入参数化",
        "Cross-layer parameter sharing": "跨层参数共享",
        "Next sentence prediction (NSP)": "下一句预测 (NSP)",
        "Sentence order prediction (SOP": "句子顺序预测 (SOP)",
        "Attention heads": "注意头部",
        "Vocabulary embedding size": "词汇嵌入大小",
        "Feed-forward/filter size": "前进/过滤器的大小",
        "Training hyperparameters": "训练超参数",
        "LAMB optimizer": "LAMB优化器",
        "Cloud TPU V3": "云TPU V3",
        "Tokenization": "令牌化",
        "Masked Language Modeling (MLM)": "掩盖语言建模 (MLM)",
        "N-gram masking": "N-克掩盖",
        "Maximum input length": "最大输入长度",
        "Sentence Order Prediction (SOP)": "判决顺序预测 (SOP)",
        "Dropout": "辍学",
        "Batch normalization": "批次正常化",
        "Model distillation": "蒸<unk>模型",
        "Vocabulary size": "词汇量",
        "Embedding matrix": "嵌入矩阵",
        "General Language Understanding Evaluation (GLUE) benchmark": "一般语言理解评估 (GLUE) 基准",
        "BOOKCORPUS": "书籍库",
        "English Wikipedia": "英语维基百科",
        "Environmental Impact": "环境影响",
        "Compute Infrastructure": "计算基础设施"
    },
    "Russian": {
        "Transformer encoder": "Кодер трансформатора",
        "GELU nonlinearities": "Нелинейности GELU",
        "parameter-reduction techniques": "методы снижения параметров",
        "BERT": "БЕРТ",
        "GLUE": "КЛЮК",
        "RACE": "РАСА",
        "SQuAD": "Команды",
        "self-supervised loss": "самоконтролируемые потери",
        "inter-sentence coherence": "согласованность между предложениями",
        "Factorized embedding parameterization": "Факторизированная параметризация встраивания",
        "Cross-layer parameter sharing": "Совместное использование параметров между уровнями",
        "Next sentence prediction (NSP)": "Предсказание следующего предложения (NSP)",
        "Sentence order prediction (SOP": "Предсказание порядка предложений (SOP)",
        "Attention heads": "Внимание, главы.",
        "Vocabulary embedding size": "Размер встраивания словарного запаса",
        "Feed-forward/filter size": "Передача/размер фильтра",
        "Training hyperparameters": "Гиперпараметры обучения",
        "LAMB optimizer": "Оптимизатор LAMB",
        "Cloud TPU V3": "Cloud TPU V3 (облачный TPU)",
        "Tokenization": "Токенизация",
        "Masked Language Modeling (MLM)": "Маскированное языковое моделирование (MLM)",
        "N-gram masking": "Маскировка N-грамм",
        "Maximum input length": "Максимальная входная длина",
        "Sentence Order Prediction (SOP)": "Предсказание порядка вынесения приговора (SOP)",
        "Dropout": "Отсев",
        "Batch normalization": "Нормализация партии",
        "Model distillation": "Модельная дистилляция",
        "Vocabulary size": "Размер словарного запаса",
        "Embedding matrix": "Матрица встраивания",
        "General Language Understanding Evaluation (GLUE) benchmark": "Базовый показатель оценки общего понимания языка (GLUE)",
        "BOOKCORPUS": "Книжный корпус",
        "English Wikipedia": "Английская Википедия",
        "Environmental Impact": "Влияние на окружающую среду",
        "Compute Infrastructure": "Вычислительная инфраструктура"
    },
    "Japanese": {
        "Transformer encoder": "トランスフォーマーエンコーダー",
        "GELU nonlinearities": "GELUの非線形性",
        "parameter-reduction techniques": "パラメータ削減技術",
        "BERT": "BERT (ベルト)",
        "GLUE": "グルー",
        "RACE": "ラス",
        "SQuAD": "スクアッド",
        "self-supervised loss": "自己監督された損失",
        "inter-sentence coherence": "句間連結性",
        "Factorized embedding parameterization": "因数化埋め込みパラメトリ化",
        "Cross-layer parameter sharing": "クラスレイヤーパラメータの共有",
        "Next sentence prediction (NSP)": "次の文の予測 (NSP)",
        "Sentence order prediction (SOP": "句順予測 (SOP)",
        "Attention heads": "注意して",
        "Vocabulary embedding size": "語の埋め込みサイズ",
        "Feed-forward/filter size": "フィードフォワード/フィルターのサイズ",
        "Training hyperparameters": "トレーニングハイパーパラメータ",
        "LAMB optimizer": "LAMBオプティマイザー",
        "Cloud TPU V3": "クラウドTPU V3",
        "Tokenization": "トークン化",
        "Masked Language Modeling (MLM)": "マスクされた言語モデリング (MLM)",
        "N-gram masking": "Nグラムのマッキング",
        "Maximum input length": "最大入力長さ",
        "Sentence Order Prediction (SOP)": "判決順序予測 (SOP)",
        "Dropout": "退学する",
        "Batch normalization": "バッチの正常化",
        "Model distillation": "モデル蒸留",
        "Vocabulary size": "語の大きさ",
        "Embedding matrix": "インベージングマトリックス",
        "General Language Understanding Evaluation (GLUE) benchmark": "一般言語理解評価 (GLUE) のベンチマーク",
        "BOOKCORPUS": "ブックコープス",
        "English Wikipedia": "英語のウィキペディア",
        "Environmental Impact": "環境への影響",
        "Compute Infrastructure": "コンピューターインフラ"
    },
    "French": {
        "Transformer encoder": "Encodeur de transformateur",
        "GELU nonlinearities": "Non-linéarités GELU",
        "parameter-reduction techniques": "techniques de réduction des paramètres",
        "BERT": "Le BERT",
        "GLUE": "La colle",
        "RACE": "La race",
        "SQuAD": "Squad",
        "self-supervised loss": "perte sous auto-surveillance",
        "inter-sentence coherence": "cohérence entre les phrases",
        "Factorized embedding parameterization": "Paramétrisation d'intégration factorialisée",
        "Cross-layer parameter sharing": "Partage de paramètres entre couches",
        "Next sentence prediction (NSP)": "Prédiction de la prochaine phrase (NSP)",
        "Sentence order prediction (SOP": "Prédiction de l'ordre des phrases (SOP)",
        "Attention heads": "Attention aux têtes.",
        "Vocabulary embedding size": "Taille d'intégration du vocabulaire",
        "Feed-forward/filter size": "Taille de l'alimentation en avant/filtre",
        "Training hyperparameters": "Hyperparamètres de formation",
        "LAMB optimizer": "Optimiseur LAMB",
        "Cloud TPU V3": "Cloud TPU V3",
        "Tokenization": "La tokenisation",
        "Masked Language Modeling (MLM)": "Modélisation du langage masqué (MLM)",
        "N-gram masking": "Masquage N-gramme",
        "Maximum input length": "Longueur d'entrée maximale",
        "Sentence Order Prediction (SOP)": "Prédiction de l'ordre de la peine (SOP)",
        "Dropout": "Abandon scolaire",
        "Batch normalization": "Normalisation du lot",
        "Model distillation": "Modèle de distillation",
        "Vocabulary size": "Taille du vocabulaire",
        "Embedding matrix": "Matrice d'intégration",
        "General Language Understanding Evaluation (GLUE) benchmark": "Évaluation de la compréhension générale des langues (GLUE)",
        "BOOKCORPUS": "Le corps de la livre",
        "English Wikipedia": "Wikipédia en anglais",
        "Environmental Impact": "Impact sur l'environnement",
        "Compute Infrastructure": "Infrastructure de calcul"
    },
    "Arabic": {
        "Transformer encoder": "رمز محول",
        "GELU nonlinearities": "غير الخطية GELU",
        "parameter-reduction techniques": "تقنيات خفض المعلمات",
        "BERT": "(بيرت)",
        "GLUE": "الغراء",
        "RACE": "السباق",
        "SQuAD": "فرقة",
        "self-supervised loss": "الخسارة الخاضعة للإشراف الذاتي",
        "inter-sentence coherence": "الاتساق بين الجمل",
        "Factorized embedding parameterization": "تحديد معلمات التضمين المصنعة",
        "Cross-layer parameter sharing": "مشاركة المعلمات عبر الطبقات",
        "Next sentence prediction (NSP)": "التنبؤ بالجملة التالية (NSP)",
        "Sentence order prediction (SOP": "التنبؤ بترتيب الجمل (SOP)",
        "Attention heads": "انتبهوا",
        "Vocabulary embedding size": "حجم تضمين المفردات",
        "Feed-forward/filter size": "حجم التغذية الأمامية/المرشح",
        "Training hyperparameters": "المعلمات الفائقة للتدريب",
        "LAMB optimizer": "محسن LAMB",
        "Cloud TPU V3": "سحابة TPU V3",
        "Tokenization": "توكينيزات",
        "Masked Language Modeling (MLM)": "نمذجة اللغة المقنعة (MLM)",
        "N-gram masking": "إخفاء N-gram",
        "Maximum input length": "أقصى طول مدخل",
        "Sentence Order Prediction (SOP)": "التنبؤ بترتيب الجملة (SOP)",
        "Dropout": "التسرب",
        "Batch normalization": "تطبيع الدفعة",
        "Model distillation": "التقطير النموذجي",
        "Vocabulary size": "حجم المفردات",
        "Embedding matrix": "مصفوفة التضمين",
        "General Language Understanding Evaluation (GLUE) benchmark": "معيار تقييم الفهم العام للغة (GLUE)",
        "BOOKCORPUS": "مجموعة الكتب",
        "English Wikipedia": "ويكيبيديا الإنجليزية",
        "Environmental Impact": "التأثير البيئي",
        "Compute Infrastructure": "البنية التحتية للحوسبة"
    }
}