[
  {
    "question": "summary",
    "chain": "generation",
    "answer": "The microsoft/trocr-base-printed model is an end-to-end Transformer-based OCR model for printed text recognition. It leverages pre-trained image and text Transformers to achieve state-of-the-art results on printed text recognition tasks without relying on complex pre/post-processing steps.",
    "answer_Chinese": "microsoft/trocr-base-printed 模型是一种基于 Transformer 的端到端 OCR 模型，用于打印文本识别。它利用预先训练的图像和文本 Transformer 在打印文本识别任务上实现最先进的结果，而无需依赖复杂的预处理/后处理步骤。",
    "answer_Arabic": "النموذج المطبوع من Microsoft/trocr-base هو نموذج التعرف الضوئي على الحروف (OCR) القائم على المحول من طرف إلى طرف للتعرف على النص المطبوع. فهو يستفيد من محولات الصور والنصوص المدربة مسبقًا لتحقيق أحدث النتائج في مهام التعرف على النص المطبوع دون الاعتماد على خطوات ما قبل/ما بعد المعالجة المعقدة.",
    "answer_French": "Le modèle Microsoft/Trocr-base-printed est un modèle OCR de bout en bout basé sur Transformer pour la reconnaissance de texte imprimé. Il exploite des transformateurs d'images et de texte pré-entraînés pour obtenir des résultats de pointe sur les tâches de reconnaissance de texte imprimé sans recourir à des étapes complexes de pré/post-traitement.",
    "answer_Russian": "Модель microsoft/trocr-base-printed представляет собой комплексную модель оптического распознавания символов на основе Transformer для распознавания печатного текста. Он использует предварительно обученные преобразователи изображений и текста для достижения самых современных результатов в задачах распознавания печатного текста, не полагаясь на сложные этапы предварительной и последующей обработки.",
    "answer_Japanese": "Microsoft/trocr-base-printed モデルは、印刷されたテキスト認識のためのエンドツーエンドの Transformer ベースの OCR モデルです。事前トレーニングされた画像とテキストのトランスフォーマーを利用して、複雑な前処理/後処理ステップに依存せずに、印刷テキスト認識タスクで最先端の結果を達成します。"
  },
  {
    "question": "description",
    "chain": "generation",
    "answer": "Model Architecture:\nTrOCR is built with the Transformer encoder-decoder architecture. The encoder is an image Transformer that extracts visual features from image patches. The decoder is a text Transformer for language modeling that generates the wordpiece sequence guided by the visual features and previous predictions.\n\nTraining Procedures:\n1. Pre-training Phase:\n   - Stage 1: Pre-train TrOCR on a large-scale synthetic dataset of hundreds of millions of printed textline images.\n   - Stage 2: Further pre-train separate models on task-specific datasets (printed and handwritten) containing millions of textline images each, initialized by the Stage 1 model.\n2. Fine-tuning: Pre-trained TrOCR models are fine-tuned on downstream text recognition tasks, except for scene text recognition experiments.\n\nParameters:\n[More Information Needed]\n\nImportant Disclaimers:\n- The outputs of TrOCR models are based on Byte Pair Encoding (BPE) and SentencePiece, and do not rely on any task-related vocabularies.\n- TrOCR achieves state-of-the-art results on printed, handwritten, and scene text image datasets without complex pre/post-processing steps.\n- TrOCR can be easily extended for multilingual text recognition by leveraging multilingual pre-trained models in the decoder-side and expanding the dictionary.\n\nFor more information and access to the TrOCR models and code, please visit https://aka.ms/trocr.",
    "answer_Chinese": "模型架构：\nTrOCR 采用 Transformer 编码器-解码器架构构建。编码器是一个图像 Transformer，它从图像块中提取视觉特征。解码器是用于语言建模的文本转换器，它根据视觉特征和先前的预测生成单词序列。\n\n培训程序：\n1.预训练阶段：\n   - 第 1 阶段：在包含数亿张打印文本行图像的大规模合成数据集上预训练 TrOCR。\n   - 第 2 阶段：在特定于任务的数据集（打印和手写）上进一步预训练单独的模型，每个数据集包含数百万个文本行图像，由第 1 阶段模型初始化。\n2.微调：预训练的TrOCR模型在下游文本识别任务上进行微调，场景文本识别实验除外。\n\n参数：\n[需要更多信息]\n\n重要免责声明：\n- TrOCR模型的输出基于字节对编码（BPE）和SentencePiece，并且不依赖于任何与任务相关的词汇表。\n- TrOCR 在打印、手写和场景文本图像数据集上实现了最先进的结果，无需复杂的预处理/后处理步骤。\n- 通过利用解码器端的多语言预训练模型并扩展字典，TrOCR 可以轻松扩展为多语言文本识别。\n\n有关更多信息以及访问 TrOCR 模型和代码，请访问 https://aka.ms/trocr。",
    "answer_Arabic": "العمارة النموذجية:\nتم تصميم TrOCR باستخدام بنية وحدة فك ترميز وتشفير Transformer. برنامج التشفير عبارة عن محول للصور يستخرج الميزات المرئية من تصحيحات الصورة. وحدة فك التشفير عبارة عن محول نصي لنمذجة اللغة يقوم بإنشاء تسلسل الكلمات مسترشدًا بالميزات المرئية والتنبؤات السابقة.\n\nإجراءات التدريب:\n1. مرحلة ما قبل التدريب:\n   - المرحلة 1: تدريب TrOCR مسبقًا على مجموعة بيانات تركيبية واسعة النطاق تضم مئات الملايين من صور النصوص المطبوعة.\n   - المرحلة 2: المزيد من النماذج المنفصلة قبل التدريب على مجموعات البيانات الخاصة بالمهام (المطبوعة والمكتوبة بخط اليد) التي تحتوي على ملايين من صور النصوص لكل منها، والتي تمت تهيئتها بواسطة نموذج المرحلة 1.\n2. الضبط الدقيق: يتم ضبط نماذج TrOCR المدربة مسبقًا بشكل دقيق على مهام التعرف على النص النهائية، باستثناء تجارب التعرف على نص المشهد.\n\nحدود:\n[مطلوب مزيد من المعلومات]\n\nإخلاء المسؤولية الهامة:\n- تعتمد مخرجات نماذج TrOCR على تشفير زوج البايت (BPE) وSentencePiece، ولا تعتمد على أي مفردات متعلقة بالمهمة.\n- يحقق TrOCR أحدث النتائج على مجموعات بيانات الصور النصية المطبوعة والمكتوبة بخط اليد والمشهد دون خطوات معقدة قبل / بعد المعالجة.\n- يمكن توسيع TrOCR بسهولة للتعرف على النص متعدد اللغات من خلال الاستفادة من النماذج متعددة اللغات المدربة مسبقًا في جانب وحدة فك التشفير وتوسيع القاموس.\n\nلمزيد من المعلومات والوصول إلى نماذج وأكواد TrOCR، يرجى زيارة https://aka.ms/trocr.",
    "answer_French": "Architecture du modèle :\nTrOCR est construit avec l'architecture encodeur-décodeur Transformer. L'encodeur est un transformateur d'image qui extrait les caractéristiques visuelles des patchs d'image. Le décodeur est un transformateur de texte pour la modélisation du langage qui génère la séquence de mots guidée par les caractéristiques visuelles et les prédictions précédentes.\n\nProcédures de formation :\n1. Phase de pré-formation :\n   - Étape 1 : Pré-entraîner TrOCR sur un ensemble de données synthétiques à grande échelle de centaines de millions d'images de lignes de texte imprimées.\n   - Étape 2 : Pré-entraîner davantage des modèles distincts sur des ensembles de données spécifiques à une tâche (imprimés et manuscrits) contenant chacun des millions d'images de lignes de texte, initialisés par le modèle de l'étape 1.\n2. Affinement : les modèles TrOCR pré-entraînés sont affinés sur les tâches de reconnaissance de texte en aval, à l'exception des expériences de reconnaissance de texte de scène.\n\nParamètres:\n[Plus d'informations nécessaires]\n\nAvertissements importants :\n- Les sorties des modèles TrOCR sont basées sur Byte Pair Encoding (BPE) et SentencePièce, et ne reposent sur aucun vocabulaire lié aux tâches.\n- TrOCR obtient des résultats de pointe sur les ensembles de données d'images de texte imprimées, manuscrites et de scène sans étapes complexes de pré/post-traitement.\n- TrOCR peut être facilement étendu pour la reconnaissance de texte multilingue en exploitant des modèles multilingues pré-entraînés côté décodeur et en élargissant le dictionnaire.\n\nPour plus d'informations et accéder aux modèles et au code TrOCR, veuillez visiter https://aka.ms/trocr.",
    "answer_Russian": "Модельная архитектура:\nTrOCR построен на архитектуре кодера-декодера Transformer. Кодер — это преобразователь изображений, который извлекает визуальные особенности из фрагментов изображения. Декодер — это текстовый преобразователь для языкового моделирования, который генерирует последовательность слов, руководствуясь визуальными особенностями и предыдущими предсказаниями.\n\nПроцедуры обучения:\n1. Фаза предварительной подготовки:\n   - Этап 1: Предварительная подготовка TrOCR на крупномасштабном синтетическом наборе данных, состоящем из сотен миллионов печатных текстовых изображений.\n   - Этап 2: Дальнейшая предварительная подготовка отдельных моделей на наборах данных для конкретных задач (напечатанных и рукописных), содержащих миллионы текстовых изображений каждое, инициализированных моделью этапа 1.\n2. Точная настройка. Предварительно обученные модели TrOCR точно настраиваются для последующих задач распознавания текста, за исключением экспериментов по распознаванию текста в сценах.\n\nПараметры:\n[Требуется дополнительная информация]\n\nВажные заявления об отказе от ответственности:\n— Выходные данные моделей TrOCR основаны на кодировании пар байтов (BPE) и SentencePiece и не полагаются на какие-либо словари, связанные с задачами.\n- TrOCR достигает самых современных результатов на наборах данных изображений печатных, рукописных и текстовых изображений без сложных этапов предварительной и постобработки.\n- TrOCR можно легко расширить для распознавания многоязычного текста, используя многоязычные предварительно обученные модели на стороне декодера и расширяя словарь.\n\nДля получения дополнительной информации и доступа к моделям и коду TrOCR посетите https://aka.ms/trocr.",
    "answer_Japanese": "モデルのアーキテクチャ:\nTrOCR は、Transformer エンコーダ/デコーダ アーキテクチャを使用して構築されています。エンコーダーは、画像パッチから視覚的特徴を抽出する画像トランスフォーマーです。デコーダは、視覚的特徴と以前の予測に基づいて単語列を生成する言語モデリング用のテキスト トランスフォーマーです。\n\nトレーニング手順:\n1. 事前トレーニング段階:\n   - ステージ 1: 数億の印刷されたテキストライン画像からなる大規模な合成データセットで TrOCR を事前トレーニングします。\n   - ステージ 2: ステージ 1 モデルによって初期化された、それぞれ数百万のテキストライン画像を含むタスク固有のデータセット (印刷および手書き) で個別のモデルをさらに事前トレーニングします。\n2. 微調整: 事前トレーニングされた TrOCR モデルは、シーン テキスト認識実験を除き、下流のテキスト認識タスクで微調整されます。\n\nパラメーター：\n[さらに詳しい情報が必要です]\n\n重要な免責事項:\n- TrOCR モデルの出力は、バイト ペア エンコーディング (BPE) と SentencePiece に基づいており、タスク関連の語彙には依存しません。\n- TrOCR は、複雑な前処理/後処理ステップを行わずに、印刷物、手書き、およびシーン テキスト画像データセットで最先端の結果を実現します。\n- TrOCR は、デコーダー側で多言語の事前トレーニング済みモデルを活用し、辞書を拡張することで、多言語テキスト認識用に簡単に拡張できます。\n\nTrOCR モデルとコードの詳細とアクセスについては、https://aka.ms/trocr を参照してください。"
  },
  {
    "question": "funded_by",
    "chain": "generation",
    "answer": "Based on the provided references, it appears that the TrOCR model, including microsoft/trocr-base-printed, is a project from Microsoft. The model and code are publicly available, and the contact persons listed for communications related to TrOCR are Lei Cui and Furu Wei, both with Microsoft email addresses.\n\nHowever, there is no explicit mention in the given references of what specific people or organizations funded the development of the microsoft/trocr-base-printed model.\n\n[More Information Needed]",
    "answer_Chinese": "根据提供的参考资料，TrOCR 模型（包括 microsoft/trocr-base-printed）似乎是 Microsoft 的一个项目。该模型和代码是公开的，与 TrOCR 相关的通信所列出的联系人是 Lei Cui 和 Furu Wei，两人都拥有 Microsoft 电子邮件地址。\n\n然而，在给定的参考文献中没有明确提及哪些特定的人或组织资助了 microsoft/trocr-base-print 模型的开发。\n\n[需要更多信息]",
    "answer_Arabic": "استنادًا إلى المراجع المتوفرة، يبدو أن نموذج TrOCR، بما في ذلك microsoft/trocr-base-printed، هو مشروع من Microsoft. النموذج والكود متاحان للعامة، وأشخاص الاتصال المدرجون للاتصالات المتعلقة بـ TrOCR هما Lei Cui وFuru Wei، وكلاهما لديه عناوين بريد إلكتروني من Microsoft.\n\nومع ذلك، لا يوجد ذكر صريح في المراجع المحددة للأشخاص أو المنظمات المحددة التي قامت بتمويل تطوير نموذج Microsoft/trocr-base-printed.\n\n[مطلوب مزيد من المعلومات]",
    "answer_French": "Sur la base des références fournies, il semble que le modèle TrOCR, y compris microsoft/trocr-base-printed, soit un projet de Microsoft. Le modèle et le code sont accessibles au public et les personnes à contacter répertoriées pour les communications liées à TrOCR sont Lei Cui et Furu Wei, tous deux possédant des adresses e-mail Microsoft.\n\nCependant, il n'y a aucune mention explicite dans les références données des personnes ou organisations spécifiques qui ont financé le développement du modèle imprimé Microsoft/Trocr.\n\n[Plus d'informations nécessaires]",
    "answer_Russian": "Судя по предоставленным ссылкам, создается впечатление, что модель TrOCR, включая microsoft/trocr-base-printed, является проектом Microsoft. Модель и код общедоступны, а контактными лицами, указанными для связи, связанной с TrOCR, являются Лэй Цуй и Фуру Вэй, оба имеют адреса электронной почты Microsoft.\n\nОднако в приведенных ссылках нет явного упоминания о том, какие конкретные люди или организации финансировали разработку печатной модели microsoft/trocr.\n\n[Требуется дополнительная информация]",
    "answer_Japanese": "提供された参考資料に基づくと、microsoft/trocr-base-printed を含む TrOCR モデルは Microsoft のプロジェクトであるようです。モデルとコードは公開されており、TrOCR に関連する連絡先として記載されている連絡先担当者は Lei Cui と Fur Wei で、どちらも Microsoft の電子メール アドレスを使用しています。\n\nただし、指定された参考文献には、microsoft/trocr-base-printed モデルの開発にどのような特定の人物または組織が資金を提供したかについて明確な言及はありません。\n\n[さらに詳しい情報が必要です]"
  },
  {
    "question": "shared_by",
    "chain": "generation",
    "answer": "Based on the provided references, the main contributors who made the TrOCR model available are:\n\nMinghao Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun Li, and Furu Wei\n\nFor help or issues using TrOCR, the references indicate to contact Lei Cui (lecu@microsoft.com) and Furu Wei (fuwei@microsoft.com).\n\nThe exact GitHub repository for the microsoft/trocr-base-printed model is [More Information Needed], as it is not explicitly provided in the references. The references mention a general link https://aka.ms/trocr for the TrOCR models and code being publicly available, but do not specify the exact repo path for this particular model.",
    "answer_Chinese": "根据提供的参考资料，使 TrOCR 模型可用的主要贡献者是：\n\n李明浩、吕腾超、崔磊、卢一娟、Dinei Florencio、张茶、李周军、魏福如\n\n如需使用 TrOCR 的帮助或问题，请联系 Lei Cui (lecu@microsoft.com) 和 Furu Wei (fuwei@microsoft.com)。\n\nmicrosoft/trocr-base-printed 模型的确切 GitHub 存储库是[需要更多信息]，因为参考文献中没有明确提供它。参考文献提到了 TrOCR 模型和代码的通用链接 https://aka.ms/trocr 是公开可用的，但没有指定该特定模型的确切存储库路径。",
    "answer_Arabic": "استنادا إلى المراجع المقدمة، المساهمين الرئيسيين الذين جعلوا نموذج TrOCR متاحا هم:\n\nمينغاو لي، وتنغشاو إل في، ولي كوي، وييجوان لو، وديني فلورينسيو، وتشا تشانغ، وتشوجون لي، وفورو وي\n\nللحصول على مساعدة أو مشاكل في استخدام TrOCR، تشير المراجع إلى الاتصال بـ Lei Cui (lecu@microsoft.com) وFuru Wei (fuwei@microsoft.com).\n\nمستودع GitHub الدقيق للنموذج المطبوع بواسطة Microsoft/trocr-base هو [بحاجة إلى مزيد من المعلومات]، لأنه لم يتم توفيره بشكل صريح في المراجع. تشير المراجع إلى رابط عام https://aka.ms/trocr لنماذج TrOCR والتعليمات البرمجية المتوفرة للعامة، ولكنها لا تحدد مسار الريبو الدقيق لهذا النموذج المحدد.",
    "answer_French": "Sur la base des références fournies, les principaux contributeurs qui ont rendu le modèle TrOCR disponible sont :\n\nMinghao Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun Li et Furu Wei\n\nPour obtenir de l'aide ou des problèmes d'utilisation de TrOCR, les références indiquent de contacter Lei Cui (lecu@microsoft.com) et Furu Wei (fuwei@microsoft.com).\n\nLe référentiel GitHub exact pour le modèle imprimé Microsoft/Trocr-base est [Plus d'informations nécessaires], car il n'est pas explicitement fourni dans les références. Les références mentionnent un lien général https://aka.ms/trocr pour les modèles et le code TrOCR accessibles au public, mais ne précisent pas le chemin exact du dépôt pour ce modèle particulier.",
    "answer_Russian": "Судя по предоставленным ссылкам, основными участниками, сделавшими модель TrOCR доступной, являются:\n\nМинхао Ли, Тенчао Лв, Лэй Цуй, Ицзюань Лу, Диней Флоренсио, Ча Чжан, Чжоуцзюнь Ли и Фуру Вэй\n\nДля получения помощи или решения проблем с использованием TrOCR в ссылках указано, что следует обращаться к Лэй Цуй (lecu@microsoft.com) и Фуру Вэй (fuwei@microsoft.com).\n\nТочный репозиторий GitHub для модели, напечатанной на базе microsoft/trocr, — [Требуется дополнительная информация], поскольку он явно не указан в ссылках. В ссылках упоминается общая ссылка https://aka.ms/trocr для моделей TrOCR и общедоступного кода, но не указан точный путь репо для этой конкретной модели.",
    "answer_Japanese": "提供された参考資料に基づくと、TrOCR モデルを利用可能にした主な貢献者は次のとおりです。\n\nミンハオ・リー、テンチャオ・LV、レイ・クイ、イージュアン・ルー、ディネイ・フロレンシオ、チャ・チャン、ジョウジュン・リー、フル・ウェイ\n\nTrOCR を使用する際のヘルプや問題については、Lei Cui (lecu@microsoft.com) および Fur Wei (fuwei@microsoft.com) に問い合わせるように記載されています。\n\nMicrosoft/trocr-base-printed モデルの正確な GitHub リポジトリは、リファレンスで明示的に提供されていないため、[詳細情報が必要] です。参考資料には、一般に公開されている TrOCR モデルとコードの一般リンク https://aka.ms/trocr が記載されていますが、この特定のモデルの正確なリポジトリ パスは指定されていません。"
  },
  {
    "question": "model_type",
    "chain": "generation",
    "answer": "The microsoft/trocr-base-printed model is a Transformer-based OCR model that is pre-trained on a large-scale synthetic printed textline image dataset and fine-tuned on the SROIE dataset for printed text recognition, leveraging both computer vision and natural language processing modalities in an end-to-end manner.",
    "answer_Chinese": "microsoft/trocr-base-printed 模型是基于 Transformer 的 OCR 模型，在大规模合成打印文本行图像数据集上进行预训练，并在 SROIE 数据集上进行微调以进行打印文本识别，同时利用计算机视觉和自然识别以端到端的方式进行语言处理。",
    "answer_Arabic": "النموذج المطبوع بواسطة Microsoft/trocr-base هو نموذج التعرف الضوئي على الحروف القائم على المحول والذي تم تدريبه مسبقًا على مجموعة بيانات صور نصية مطبوعة اصطناعية واسعة النطاق وتم ضبطه بدقة على مجموعة بيانات SROIE للتعرف على النص المطبوع، مما يعزز رؤية الكمبيوتر والطبيعية طرق معالجة اللغة بطريقة شاملة.",
    "answer_French": "Le modèle Microsoft/Trocr-base-printed est un modèle OCR basé sur Transformer qui est pré-entraîné sur un ensemble de données d'images de lignes de texte imprimées synthétiques à grande échelle et affiné sur l'ensemble de données SROIE pour la reconnaissance de textes imprimés, en tirant parti à la fois de la vision par ordinateur et des technologies naturelles. modalités de traitement linguistique de bout en bout.",
    "answer_Russian": "Модель microsoft/trocr-base-printed представляет собой модель оптического распознавания символов на основе Transformer, которая предварительно обучена на крупномасштабном синтетическом наборе данных изображений печатных текстовых строк и точно настроена на наборе данных SROIE для распознавания печатного текста, используя как компьютерное зрение, так и естественное модальности обработки языка сквозным способом.",
    "answer_Japanese": "Microsoft/trocr-base-printed モデルは、大規模な合成印刷テキストライン画像データセットで事前トレーニングされ、印刷テキスト認識用に SROIE データセットで微調整された Transformer ベースの OCR モデルであり、コンピューター ビジョンと自然画像の両方を活用します。エンドツーエンド方式での言語処理モダリティ。"
  },
  {
    "question": "language",
    "chain": "generation",
    "answer": "The microsoft/trocr-base-printed model processes English text for printed text recognition in images.",
    "answer_Chinese": "microsoft/trocr-base-print 模型处理英文文本以识别图像中的打印文本。",
    "answer_Arabic": "يقوم النموذج المطبوع من Microsoft/trocr-base بمعالجة النص الإنجليزي للتعرف على النص المطبوع في الصور.",
    "answer_French": "Le modèle Microsoft/Trocr-base-printed traite le texte anglais pour la reconnaissance du texte imprimé dans les images.",
    "answer_Russian": "Модель microsoft/trocr-base-printed обрабатывает текст на английском языке для распознавания печатного текста на изображениях.",
    "answer_Japanese": "Microsoft/trocr-base-printed モデルは、画像内の印刷されたテキストを認識するために英語のテキストを処理します。"
  },
  {
    "question": "license",
    "chain": "generation",
    "answer": "This project is licensed under the license found in the LICENSE file in the root directory of this source tree. Portions of the source code are based on the [fairseq](https://github.com/pytorch/fairseq) project. [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct)",
    "answer_Chinese": "该项目是根据该源树根目录中的 LICENSE 文件中找到的许可证获得许可的。部分源代码基于 [fairseq](https://github.com/pytorch/fairseq) 项目。 [微软开源行为准则](https://opensource.microsoft.com/codeofconduct)",
    "answer_Arabic": "تم ترخيص هذا المشروع بموجب الترخيص الموجود في ملف الترخيص في الدليل الجذر لهذه الشجرة المصدر. تعتمد أجزاء من الكود المصدري على مشروع [fairseq](https://github.com/pytorch/fairseq). [قواعد سلوك Microsoft مفتوحة المصدر](https://opensource.microsoft.com/codeofconduct)",
    "answer_French": "Ce projet est sous licence sous la licence trouvée dans le fichier LICENSE dans le répertoire racine de cette arborescence source. Des parties du code source sont basées sur le projet [fairseq](https://github.com/pytorch/fairseq). [Code de conduite Microsoft Open Source](https://opensource.microsoft.com/codeofconduct)",
    "answer_Russian": "Этот проект лицензируется по лицензии, которая находится в файле LICENSE в корневом каталоге этого исходного дерева. Части исходного кода основаны на проекте [fairseq](https://github.com/pytorch/fairseq). [Кодекс поведения Microsoft с открытым исходным кодом](https://opensource.microsoft.com/codeofconduct)",
    "answer_Japanese": "このプロジェクトは、このソース ツリーのルート ディレクトリにある LICENSE ファイルにあるライセンスに基づいてライセンスされています。ソース コードの一部は、[fairseq](https://github.com/pytorch/fairseq) プロジェクトに基づいています。 [マイクロソフト オープンソース行動規範](https://opensource.microsoft.com/codeofconduct)"
  },
  {
    "question": "finetuned_from",
    "chain": "generation",
    "answer": "Based on the provided references, the microsoft/trocr-base-printed model is initialized and fine-tuned from pre-trained models in two stages:\n\n1. Encoder Initialization: The encoder is initialized using models like DeiT (Touvron et al. 2021) and BEiT (Bao, Dong, and Wei 2021).\n\n2. Decoder Initialization: The decoder is initialized using RoBERTa (Liu et al. 2019) models and MiniLM (Wang et al. 2020b) models.\n\nSpecifically, the model is first pre-trained on a large-scale synthetic printed textline image dataset. Then in the second stage, it is further pre-trained on a smaller printed text dataset before being fine-tuned for downstream tasks. (Reference 6-7)\n\nHowever, the exact model names and links for the base models used for initialization are not provided in the given references. [More Information Needed]",
    "answer_Chinese": "根据提供的参考资料，microsoft/trocr-base-printed 模型分两个阶段从预训练模型进行初始化和微调：\n\n1. 编码器初始化：编码器使用 DeiT (Touvron et al. 2021) 和 BEiT (Bao, Dong, and Wei 2021) 等模型进行初始化。\n\n2.解码器初始化：使用RoBERTa（Liu et al. 2019）模型和MiniLM（Wang et al. 2020b）模型初始化解码器。\n\n具体来说，该模型首先在大规模合成打印文本行图像数据集上进行预训练。然后在第二阶段，在针对下游任务进行微调之前，在较小的打印文本数据集上进一步进行预训练。 （参考6-7）\n\n但是，给定的参考文献中未提供用于初始化的基本模型的确切模型名称和链接。 [需要更多信息]",
    "answer_Arabic": "استنادًا إلى المراجع المتوفرة، تتم تهيئة النموذج المطبوع بواسطة Microsoft/trocr-base وضبطه من النماذج المدربة مسبقًا على مرحلتين:\n\n1. تهيئة جهاز التشفير: تتم تهيئة جهاز التشفير باستخدام نماذج مثل DeiT (Touvron et al. 2021) وBEiT (Bao, Dong, and Wei 2021).\n\n2. تهيئة وحدة فك التشفير: تتم تهيئة وحدة فك التشفير باستخدام نماذج RoBERTa (Liu et al. 2019) ونماذج MiniLM (Wang et al. 2020b).\n\nعلى وجه التحديد، تم تدريب النموذج أولاً مسبقًا على مجموعة بيانات صور نصية مطبوعة اصطناعية واسعة النطاق. ثم في المرحلة الثانية، يتم تدريبه مسبقًا على مجموعة بيانات نصية مطبوعة أصغر قبل ضبطه جيدًا للمهام النهائية. (المرجع 6-7)\n\nومع ذلك، لا يتم توفير أسماء النماذج الدقيقة والروابط الخاصة بالنماذج الأساسية المستخدمة للتهيئة في المراجع المحددة. [مطلوب مزيد من المعلومات]",
    "answer_French": "Sur la base des références fournies, le modèle Microsoft/trocr-base-printed est initialisé et affiné à partir de modèles pré-entraînés en deux étapes :\n\n1. Initialisation de l'encodeur : L'encodeur est initialisé à l'aide de modèles comme DeiT (Touvron et al. 2021) et BEiT (Bao, Dong et Wei 2021).\n\n2. Initialisation du décodeur : le décodeur est initialisé à l'aide des modèles RoBERTa (Liu et al. 2019) et MiniLM (Wang et al. 2020b).\n\nPlus précisément, le modèle est d'abord pré-entraîné sur un ensemble de données d'images de lignes de texte imprimées synthétiques à grande échelle. Puis, dans un deuxième temps, il est pré-entraîné sur un ensemble de données de texte imprimé plus petit avant d'être affiné pour les tâches en aval. (Référence 6-7)\n\nCependant, les noms exacts des modèles et les liens pour les modèles de base utilisés pour l'initialisation ne sont pas fournis dans les références données. [Plus d'informations nécessaires]",
    "answer_Russian": "На основе предоставленных ссылок модель, напечатанная на базе Microsoft/trocr, инициализируется и настраивается на основе предварительно обученных моделей в два этапа:\n\n1. Инициализация кодировщика. Кодер инициализируется с использованием таких моделей, как DeiT (Touvron et al., 2021) и BEiT (Bao, Dong и Wei, 2021).\n\n2. Инициализация декодера. Декодер инициализируется с использованием моделей RoBERTa (Лю и др., 2019) и моделей MiniLM (Ван и др., 2020b).\n\nВ частности, модель сначала предварительно обучается на крупномасштабном синтетическом наборе данных печатных текстовых изображений. Затем, на втором этапе, он дополнительно обучается на меньшем наборе печатных текстовых данных, прежде чем его настраивать для последующих задач. (Ссылка 6-7)\n\nОднако точные названия моделей и ссылки на базовые модели, используемые для инициализации, в приведенных ссылках не приведены. [Требуется дополнительная информация]",
    "answer_Japanese": "提供された参照に基づいて、microsoft/trocr-base-printed モデルは 2 段階で初期化され、事前トレーニングされたモデルから微調整されます。\n\n1. エンコーダーの初期化: エンコーダーは、DeiT (Touvron et al. 2021) や BEiT (Bao, Dong, and Wei 2021) などのモデルを使用して初期化されます。\n\n2. デコーダーの初期化: デコーダーは、RoBERTa (Liu et al. 2019) モデルおよび MiniLM (Wang et al. 2020b) モデルを使用して初期化されます。\n\n具体的には、モデルはまず大規模な合成印刷テキストライン画像データセットで事前トレーニングされます。次に、第 2 段階では、下流のタスクに合わせて微調整される前に、より小さな印刷テキスト データセットでさらに事前トレーニングが行われます。 (参考6-7)\n\nただし、初期化に使用されるベース モデルの正確なモデル名とリンクは、指定されたリファレンスには提供されていません。 [さらに詳しい情報が必要です]"
  },
  {
    "question": "demo_sources",
    "chain": "generation",
    "answer": "[More Information Needed]\n\nThe provided references do not contain a direct link to a demo of the model microsoft/trocr-base-printed. More information would be needed to provide a demo link for this specific model in the model card description.",
    "answer_Chinese": "[需要更多信息]\n\n提供的参考资料不包含指向 microsoft/trocr-base-printed 模型演示的直接链接。需要更多信息才能在模型卡描述中提供此特定模型的演示链接。",
    "answer_Arabic": "[مطلوب مزيد من المعلومات]\n\nلا تحتوي المراجع المقدمة على رابط مباشر لعرض توضيحي لنموذج Microsoft/trocr-base-printed. ستكون هناك حاجة إلى مزيد من المعلومات لتوفير رابط تجريبي لهذا النموذج المحدد في وصف بطاقة النموذج.",
    "answer_French": "[Plus d'informations nécessaires]\n\nLes références fournies ne contiennent pas de lien direct vers une démo du modèle microsoft/trocr-base-printed. Plus d'informations seraient nécessaires pour fournir un lien de démonstration pour ce modèle spécifique dans la description de la carte modèle.",
    "answer_Russian": "[Требуется дополнительная информация]\n\nПредоставленные ссылки не содержат прямой ссылки на демо-версию модели microsoft/trocr-base-printed. Для предоставления демо-ссылки на эту конкретную модель в описании карточки модели потребуется дополнительная информация.",
    "answer_Japanese": "[さらに詳しい情報が必要です]\n\n提供されている参考資料には、microsoft/trocr-base-printed モデルのデモへの直接リンクは含まれていません。モデル カードの説明にこの特定のモデルのデモ リンクを提供するには、さらに詳しい情報が必要です。"
  },
  {
    "question": "direct_use",
    "chain": "generation",
    "answer": "The microsoft/trocr-base-printed model can be used for text recognition tasks without requiring fine-tuning, post-processing, or plugging into a pipeline. The model takes textline images as input and directly outputs the predicted text.\n\nTo use the model for inference:\n\n```python\nPlease see detials in [pic_inference.py](https://github.com/microsoft/unilm/blob/master/trocr/pic_inference.py).\n```\n\nThe model outputs are based on Byte Pair Encoding (BPE) and SentencePiece, and do not rely on any task-related vocabularies. During inference, the decoder starts from the \"[BOS]\" token to predict the output iteratively while continuously taking the newly generated output as the next input, until the \"[EOS]\" token is predicted, indicating the end of the sentence.\n\n[More Information Needed] on the specific API usage and required input image format.",
    "answer_Chinese": "microsoft/trocr-base-printed 模型可用于文本识别任务，无需微调、后处理或​​插入管道。该模型以文本行图像作为输入，并直接输出预测的文本。\n\n使用模型进行推理：\n\n````蟒蛇\n请参阅 [pic_inference.py](https://github.com/microsoft/unilm/blob/master/trocr/pic_inference.py) 中的详细信息。\n````\n\n模型输出基于字节对编码 (BPE) 和 SentencePiece，并且不依赖于任何与任务相关的词汇表。在推理过程中，解码器从“[BOS]” token 开始迭代预测输出，同时不断将新生成的输出作为下一个输入，直到预测出“[EOS]” token，表示句子结束。\n\n[需要更多信息]有关具体 API 用法和所需的输入图像格式。",
    "answer_Arabic": "يمكن استخدام النموذج المطبوع من Microsoft/trocr-base لمهام التعرف على النص دون الحاجة إلى الضبط الدقيق أو المعالجة اللاحقة أو التوصيل بخط أنابيب. يأخذ النموذج صور النص كمدخل ويخرج النص المتوقع مباشرة.\n\nلاستخدام النموذج للاستدلال:\n\n```بيثون\nيرجى الاطلاع على التفاصيل في [pic_inference.py](https://github.com/microsoft/unilm/blob/master/trocr/pic_inference.py).\n```\n\nتعتمد مخرجات النموذج على تشفير زوج البايت (BPE) وSentencePiece، ولا تعتمد على أي مفردات متعلقة بالمهمة. أثناء الاستدلال، يبدأ جهاز فك التشفير من الرمز المميز \"[BOS]\" للتنبؤ بالإخراج بشكل متكرر مع أخذ الإخراج الذي تم إنشاؤه حديثًا بشكل مستمر كمدخل تالي، حتى يتم التنبؤ بالرمز المميز \"[EOS]\"، مما يشير إلى نهاية الجملة.\n\n[يلزم مزيد من المعلومات] حول استخدام واجهة برمجة التطبيقات (API) المحدد وتنسيق صورة الإدخال المطلوب.",
    "answer_French": "Le modèle Microsoft/Trocr-base-printed peut être utilisé pour des tâches de reconnaissance de texte sans nécessiter de réglage fin, de post-traitement ou de connexion à un pipeline. Le modèle prend des images de lignes de texte en entrée et génère directement le texte prédit.\n\nPour utiliser le modèle à des fins d'inférence :\n\n```python\nVeuillez consulter les détails dans [pic_inference.py](https://github.com/microsoft/unilm/blob/master/trocr/pic_inference.py).\n```\n\nLes sorties du modèle sont basées sur Byte Pair Encoding (BPE) et SentencePièce, et ne reposent sur aucun vocabulaire lié aux tâches. Pendant l'inférence, le décodeur part du jeton « [BOS] » pour prédire la sortie de manière itérative tout en prenant continuellement la sortie nouvellement générée comme entrée suivante, jusqu'à ce que le jeton « [EOS] » soit prédit, indiquant la fin de la phrase.\n\n[Plus d'informations nécessaires] sur l'utilisation spécifique de l'API et le format d'image d'entrée requis.",
    "answer_Russian": "Модель, напечатанную на базе Microsoft/trocr, можно использовать для задач распознавания текста, не требуя тонкой настройки, последующей обработки или подключения к конвейеру. Модель принимает изображения текстовых строк в качестве входных данных и напрямую выводит прогнозируемый текст.\n\nЧтобы использовать модель для вывода:\n\n``` питон\nПодробности см. в [pic_inference.py](https://github.com/microsoft/unilm/blob/master/trocr/pic_inference.py).\n```\n\nВыходные данные модели основаны на кодировании пар байтов (BPE) и SentencePiece и не полагаются на какие-либо словари, связанные с задачами. Во время вывода декодер начинает с токена «[BOS]», чтобы итеративно прогнозировать выходные данные, непрерывно принимая вновь сгенерированные выходные данные в качестве следующих входных данных, пока не будет предсказан токен «[EOS]», указывающий на конец предложения.\n\n[Требуется дополнительная информация] о конкретном использовании API и требуемом формате входного изображения.",
    "answer_Japanese": "Microsoft/trocr-base-printed モデルは、微調整、後処理、パイプラインへの接続を必要とせずに、テキスト認識タスクに使用できます。モデルはテキストライン画像を入力として受け取り、予測されたテキストを直接出力します。\n\nモデルを推論に使用するには:\n\n「」パイソン\n[pic_inference.py](https://github.com/microsoft/unilm/blob/master/trocr/pic_inference.py) の詳細を参照してください。\n「」\n\nモデルの出力はバイト ペア エンコーディング (BPE) と SentencePiece に基づいており、タスク関連の語彙には依存しません。推論中、デコーダーは「[BOS]」トークンから開始して、文の終わりを示す「[EOS]」トークンが予測されるまで、新しく生成された出力を次の入力として継続的に取得しながら、繰り返し出力を予測します。\n\n特定の API の使用法と必要な入力画像形式に関する [詳細情報が必要]。"
  },
  {
    "question": "downstream_use",
    "chain": "generation",
    "answer": "The microsoft/trocr-base-printed model can be fine-tuned for printed text recognition tasks. It is pre-trained on large-scale synthetic data and can be further fine-tuned on human-labeled datasets like SROIE for specific printed text recognition applications.\n\nWhen plugged into a larger ecosystem or app, the model can be used as an OCR component to extract text from printed images. It takes in textline images as input, extracts visual features using the encoder, and generates the recognized text using the decoder in an autoregressive manner.\n\n[More Information Needed] for a specific code snippet, as the references do not provide a direct code block for using the model in an application. However, the model is publicly available and can be integrated into OCR pipelines for printed text recognition.\n\nThe model achieves state-of-the-art performance on printed text benchmarks without requiring complex pre/post-processing steps, making it suitable for various text recognition scenarios in real-world applications.\n\nFor any further information or updates regarding the microsoft/trocr-base-printed model, please feel free to reach out to the project organizer.",
    "answer_Chinese": "microsoft/trocr-base-printed 模型可以针对打印文本识别任务进行微调。它在大规模合成数据上进行了预训练，并且可以在 SROIE 等人工标记数据集上进行进一步微调，以用于特定的印刷文本识别应用。\n\n当插入更大的生态系统或应用程序时，该模型可以用作 OCR 组件，从打印图像中提取文本。它将文本行图像作为输入，使用编码器提取视觉特征，并使用解码器以自回归方式生成识别的文本。\n\n[需要更多信息] 对于特定的代码片段，因为参考文献不提供在应用程序中使用模型的直接代码块。然而，该模型是公开可用的，并且可以集成到 OCR 管道中以进行打印文本识别。\n\n该模型在打印文本基准上实现了最先进的性能，无需复杂的预处理/后处理步骤，使其适用于现实应用中的各种文本识别场景。\n\n有关 microsoft/trocr-base-printed 模型的任何进一步信息或更新，请随时联系项目组织者。",
    "answer_Arabic": "يمكن ضبط النموذج المطبوع من Microsoft/trocr-base بشكل دقيق لمهام التعرف على النص المطبوع. تم تدريبه مسبقًا على البيانات الاصطناعية واسعة النطاق ويمكن تحسينه بشكل أكبر على مجموعات البيانات التي تحمل علامات بشرية مثل SROIE لتطبيقات محددة للتعرف على النصوص المطبوعة.\n\nعند توصيله بنظام بيئي أو تطبيق أكبر، يمكن استخدام النموذج كمكون للتعرف الضوئي على الحروف لاستخراج النص من الصور المطبوعة. فهو يأخذ صور الخطوط النصية كمدخلات، ويستخرج الميزات المرئية باستخدام أداة التشفير، ويقوم بإنشاء النص الذي تم التعرف عليه باستخدام وحدة فك التشفير بطريقة انحدارية.\n\n[يلزم مزيد من المعلومات] لمقتطف تعليمات برمجية محدد، حيث أن المراجع لا توفر كتلة تعليمات برمجية مباشرة لاستخدام النموذج في التطبيق. ومع ذلك، فإن النموذج متاح للعامة ويمكن دمجه في مسارات التعرف الضوئي على الحروف (OCR) للتعرف على النص المطبوع.\n\nيحقق النموذج أداءً متطورًا في معايير النص المطبوع دون الحاجة إلى خطوات معقدة قبل/بعد المعالجة، مما يجعله مناسبًا لمختلف سيناريوهات التعرف على النص في تطبيقات العالم الحقيقي.\n\nللحصول على مزيد من المعلومات أو التحديثات المتعلقة بالنموذج المطبوع من Microsoft/trocr-base، فلا تتردد في التواصل مع منظم المشروع.",
    "answer_French": "Le modèle Microsoft/Trocr-base-printed peut être affiné pour les tâches de reconnaissance de texte imprimé. Il est pré-entraîné sur des données synthétiques à grande échelle et peut être affiné davantage sur des ensembles de données étiquetés par l'homme comme SROIE pour des applications spécifiques de reconnaissance de texte imprimé.\n\nLorsqu'il est connecté à un écosystème ou à une application plus vaste, le modèle peut être utilisé comme composant OCR pour extraire le texte des images imprimées. Il prend en entrée les images de lignes de texte, extrait les caractéristiques visuelles à l'aide de l'encodeur et génère le texte reconnu à l'aide du décodeur de manière autorégressive.\n\n[Plus d'informations nécessaires] pour un extrait de code spécifique, car les références ne fournissent pas de bloc de code direct pour utiliser le modèle dans une application. Cependant, le modèle est accessible au public et peut être intégré aux pipelines OCR pour la reconnaissance de textes imprimés.\n\nLe modèle atteint des performances de pointe sur les références de texte imprimé sans nécessiter d'étapes complexes de pré/post-traitement, ce qui le rend adapté à divers scénarios de reconnaissance de texte dans des applications réelles.\n\nPour toute information complémentaire ou mise à jour concernant le modèle imprimé Microsoft/Trocr-base, n'hésitez pas à contacter l'organisateur du projet.",
    "answer_Russian": "Модель печати на базе Microsoft/trocr может быть точно настроена для задач распознавания печатного текста. Он предварительно обучен на крупномасштабных синтетических данных и может быть дополнительно настроен на наборах данных, размеченных человеком, таких как SROIE, для конкретных приложений распознавания печатного текста.\n\nПри подключении к более крупной экосистеме или приложению модель можно использовать в качестве компонента оптического распознавания символов для извлечения текста из печатных изображений. Он принимает изображения текстовых строк в качестве входных данных, извлекает визуальные особенности с помощью кодировщика и генерирует распознанный текст с помощью декодера авторегрессионным способом.\n\n[Требуется дополнительная информация] для конкретного фрагмента кода, поскольку ссылки не предоставляют прямой блок кода для использования модели в приложении. Однако модель общедоступна и может быть интегрирована в конвейеры OCR для распознавания печатного текста.\n\nМодель обеспечивает высочайшую производительность при тестировании печатного текста, не требуя сложных этапов предварительной и последующей обработки, что делает ее подходящей для различных сценариев распознавания текста в реальных приложениях.\n\nДля получения дополнительной информации или обновлений относительно модели, напечатанной на базе Microsoft/trocr, обращайтесь к организатору проекта.",
    "answer_Japanese": "Microsoft/trocr-base-printed モデルは、印刷されたテキスト認識タスク用に微調整できます。大規模な合成データで事前トレーニングされており、特定の印刷テキスト認識アプリケーション向けに、SROIE のような人間がラベル付けしたデータセットでさらに微調整することができます。\n\nより大きなエコシステムまたはアプリに接続すると、このモデルを OCR コンポーネントとして使用して、印刷された画像からテキストを抽出できます。入力としてテキストライン画像を取り込み、エンコーダーを使用して視覚的特徴を抽出し、デコーダーを使用して自己回帰方式で認識されたテキストを生成します。\n\nリファレンスでは、アプリケーションでモデルを使用するための直接のコード ブロックが提供されていないため、特定のコード スニペットについては [詳細情報が必要]。ただし、このモデルは公開されており、印刷されたテキストを認識するために OCR パイプラインに統合できます。\n\nこのモデルは、複雑な前処理/後処理ステップを必要とせずに、印刷テキストのベンチマークで最先端のパフォーマンスを実現し、現実世界のアプリケーションにおけるさまざまなテキスト認識シナリオに適しています。\n\nMicrosoft/trocr-base-printed モデルに関するさらなる情報や最新情報が必要な場合は、お気軽にプロジェクト主催者にお問い合わせください。"
  },
  {
    "question": "out_of_scope_use",
    "chain": "generation",
    "answer": "Based on the provided references, here are some potential ways the microsoft/trocr-base-printed model could foreseeably be misused and what users ought not do:\n\nThe model should not be used to recognize and extract text from images without permission, as this could violate copyright or privacy rights. Users should ensure they have the necessary rights and consents before applying the model to images.\n\nThe model should not be relied upon for recognizing text in high-stakes domains like healthcare or finance without extensive testing and human oversight. Incorrect text extraction in these areas could lead to serious consequences.\n\nUsers should be aware the model may exhibit biases based on the data it was trained on. It should not be deployed in ways that could discriminate against certain demographics or perpetuate harmful stereotypes.\n\nThe model should not be used as the sole authoritative source for text recognition. Its outputs should be treated as predictions to be verified by humans, not as ground truth.\n\n[More Information Needed] on the specific training data, intended use cases, and performance characteristics of microsoft/trocr-base-printed to fully assess potential misuse and limitations. The provided references focus more on technical model details rather than usage guidelines and societal implications. Consulting with the model developers and other relevant experts would help fill in these gaps to responsibly document and publish the model.",
    "answer_Chinese": "根据提供的参考资料，以下是 microsoft/trocr-base-printed 模型可能被滥用的一些潜在方式以及用户不应该做的事情：\n\n未经许可，不应使用该模型来识别和提取图像中的文本，因为这可能会侵犯版权或隐私权。在将模型应用于图像之前，用户应确保他们拥有必要的权利和同意。\n\n如果没有广泛的测试和人工监督，不应依赖该模型来识别医疗保健或金融等高风险领域的文本。这些区域中不正确的文本提取可能会导致严重的后果。\n\n用户应该意识到模型可能会根据其训练数据而表现出偏差。它的部署方式不应歧视某些人群或延续有害的陈规定型观念。\n\n该模型不应用作文本识别的唯一权威来源。其输出应被视为由人类验证的预测，而不是地面事实。\n\n[需要更多信息]有关 microsoft/trocr-base-printed 的具体训练数据、预期用例和性能特征，以充分评估潜在的误用和限制。提供的参考资料更多地关注技术模型细节，而不是使用指南和社会影响。咨询模型开发人员和其他相关专家将有助于填补这些空白，以负责任地记录和发布模型。",
    "answer_Arabic": "استنادًا إلى المراجع المتوفرة، فيما يلي بعض الطرق المحتملة التي يمكن من خلالها إساءة استخدام النموذج المطبوع بواسطة Microsoft/trocr-base وما لا يجب على المستخدمين فعله:\n\nلا ينبغي استخدام النموذج للتعرف على النص واستخراجه من الصور دون إذن، لأن ذلك قد ينتهك حقوق الطبع والنشر أو حقوق الخصوصية. يجب على المستخدمين التأكد من حصولهم على الحقوق والموافقات اللازمة قبل تطبيق النموذج على الصور.\n\nلا ينبغي الاعتماد على النموذج للتعرف على النص في المجالات عالية المخاطر مثل الرعاية الصحية أو التمويل دون اختبارات مكثفة وإشراف بشري. يمكن أن يؤدي استخراج النص بشكل غير صحيح في هذه المناطق إلى عواقب وخيمة.\n\nيجب أن يدرك المستخدمون أن النموذج قد يُظهر تحيزات بناءً على البيانات التي تم تدريبه عليها. ولا ينبغي نشره بطرق يمكن أن تنطوي على تمييز ضد فئات سكانية معينة أو تديم الصور النمطية الضارة.\n\nلا ينبغي استخدام النموذج كمصدر رسمي وحيد للتعرف على النص. ويجب التعامل مع مخرجاتها على أنها تنبؤات يمكن للبشر التحقق منها، وليس كحقيقة على أرض الواقع.\n\n[مطلوب مزيد من المعلومات] حول بيانات التدريب المحددة، وحالات الاستخدام المقصودة، وخصائص أداء Microsoft/trocr-base-printed لتقييم سوء الاستخدام والقيود المحتملة بشكل كامل. تركز المراجع المقدمة بشكل أكبر على تفاصيل النموذج الفني بدلاً من إرشادات الاستخدام والآثار المجتمعية. من شأن التشاور مع مطوري النماذج وغيرهم من الخبراء ذوي الصلة أن يساعد في سد هذه الثغرات لتوثيق النموذج ونشره بشكل مسؤول.",
    "answer_French": "Sur la base des références fournies, voici quelques façons potentielles dont le modèle Microsoft/trocr-base-printed pourrait être utilisé à mauvais escient et ce que les utilisateurs ne devraient pas faire :\n\nLe modèle ne doit pas être utilisé pour reconnaître et extraire du texte à partir d'images sans autorisation, car cela pourrait violer les droits d'auteur ou les droits à la vie privée. Les utilisateurs doivent s'assurer qu'ils disposent des droits et consentements nécessaires avant d'appliquer le modèle aux images.\n\nLe modèle ne doit pas être utilisé pour reconnaître du texte dans des domaines à enjeux élevés comme la santé ou la finance sans des tests approfondis et une surveillance humaine. Une extraction de texte incorrecte dans ces domaines pourrait entraîner de graves conséquences.\n\nLes utilisateurs doivent être conscients que le modèle peut présenter des biais en fonction des données sur lesquelles il a été formé. Il ne doit pas être déployé d’une manière qui pourrait discriminer certaines données démographiques ou perpétuer des stéréotypes néfastes.\n\nLe modèle ne doit pas être utilisé comme seule source faisant autorité pour la reconnaissance de texte. Ses résultats doivent être traités comme des prédictions devant être vérifiées par des humains, et non comme une vérité terrain.\n\n[Plus d'informations nécessaires] sur les données de formation spécifiques, les cas d'utilisation prévus et les caractéristiques de performances de Microsoft/trocr-base-printed pour évaluer pleinement les utilisations abusives et les limitations potentielles. Les références fournies se concentrent davantage sur les détails techniques du modèle plutôt que sur les directives d'utilisation et les implications sociétales. Consulter les développeurs du modèle et d’autres experts concernés permettrait de combler ces lacunes afin de documenter et de publier le modèle de manière responsable.",
    "answer_Russian": "Основываясь на предоставленных ссылках, вот несколько потенциальных способов неправильного использования модели, напечатанной на базе microsoft/trocr, и чего пользователям не следует делать:\n\nМодель не следует использовать для распознавания и извлечения текста из изображений без разрешения, поскольку это может нарушить авторские права или права на конфиденциальность. Пользователи должны убедиться, что у них есть необходимые права и согласия, прежде чем применять модель к изображениям.\n\nНа эту модель не следует полагаться для распознавания текста в таких важных областях, как здравоохранение или финансы, без тщательного тестирования и человеческого контроля. Неправильное извлечение текста в этих областях может привести к серьезным последствиям.\n\nПользователи должны знать, что модель может проявлять предвзятость в зависимости от данных, на которых она обучалась. Его не следует применять таким образом, чтобы это могло дискриминировать определенные демографические группы или закреплять вредные стереотипы.\n\nМодель не должна использоваться в качестве единственного авторитетного источника для распознавания текста. Его результаты следует рассматривать как прогнозы, которые должны быть проверены людьми, а не как основополагающую истину.\n\n[Требуется дополнительная информация] о конкретных данных обучения, предполагаемых вариантах использования и характеристиках производительности Microsoft/trocr-base, напечатанных для полной оценки потенциального неправильного использования и ограничений. Предоставленные ссылки больше сосредоточены на технических деталях модели, а не на рекомендациях по использованию и социальных последствиях. Консультации с разработчиками модели и другими соответствующими экспертами помогут заполнить эти пробелы и обеспечить ответственное документирование и публикацию модели.",
    "answer_Japanese": "提供された参考資料に基づいて、microsoft/trocr-base-printed モデルが悪用される可能性があると予想される方法と、ユーザーが行うべきではないことをいくつか示します。\n\n著作権やプライバシー権を侵害する可能性があるため、許可なく画像からテキストを認識して抽出するためにこのモデルを使用しないでください。ユーザーは、モデルを画像に適用する前に、必要な権利と同意があることを確認する必要があります。\n\nこのモデルは、広範なテストや人間による監視なしに、ヘルスケアや金融などのリスクの高い分野のテキストを認識するために依存すべきではありません。これらの領域でテキストが正しく抽出されないと、重大な結果が生じる可能性があります。\n\nユーザーは、モデルがトレーニングされたデータに基づいてバイアスを示す可能性があることに注意する必要があります。特定の層を差別したり、有害な固定観念を永続させたりする可能性のある方法で展開すべきではありません。\n\nこのモデルをテキスト認識の唯一の信頼できるソースとして使用しないでください。その出力は、地上の真実としてではなく、人間によって検証される予測として扱われる必要があります。\n\n潜在的な誤用と制限を完全に評価するには、microsoft/trocr-base-printed の特定のトレーニング データ、使用目的のケース、およびパフォーマンス特性に関する [詳細情報が必要です]。提供される参考資料は、使用ガイドラインや社会的影響よりも、技術モデルの詳細に重点を置いています。モデル開発者やその他の関連専門家と相談することは、これらのギャップを埋めて責任を持ってモデルを文書化し、公開するのに役立ちます。"
  },
  {
    "question": "bias_risks_limitations",
    "chain": "generation",
    "answer": "Based on the provided references about the TrOCR model (microsoft/trocr-base-printed), here are some potential issues and limitations:\n\nTechnical limitations:\n- The model relies on resizing input images to a fixed 384x384 size and splitting them into 16x16 patches. This may limit performance on text images of very different sizes or aspect ratios. [More Information Needed] on how well it handles varied image sizes.\n- [More Information Needed] on computational requirements and inference speed compared to other OCR approaches. The references don't provide details on efficiency.\n\nForeseeable misunderstandings and harms:\n- The model is trained on printed text recognition. Applying it to handwritten text or more complex scenes may lead to degraded performance and unreliable results. Users should be clearly informed of the intended use case.\n- [More Information Needed] on how the model handles text in different languages and scripts. Multilingual support is mentioned but details are lacking.\n- As with any AI system, overreliance on the model's outputs without human verification could lead to propagating errors in downstream applications. Human oversight is advised.\n\nSociotechnical considerations:\n- The training data sources and any potential biases therein are [More Information Needed]. Biases in training data could lead to biased or discriminatory model behavior.\n- [More Information Needed] on use of user data and privacy implications. How are user-provided images handled? Is any data retained?\n- Intended use cases and potential misuse scenarios should be clearly outlined to users, along with guidance on responsible deployment.\n\nIn summary, while TrOCR shows promising technical capabilities, more information is needed in several key areas to robustly assess limitations and sociotechnical implications. Responsible disclosure and oversight are advised.",
    "answer_Chinese": "根据提供的有关 TrOCR 模型 (microsoft/trocr-base-printed) 的参考资料，以下是一些潜在的问题和限制：\n\n技术限制：\n- 该模型依赖于将输入图像调整为固定的 384x384 大小并将其分割为 16x16 的块。这可能会限制尺寸或纵横比差异很大的文本图像的性能。 [需要更多信息]了解它如何处理不同的图像尺寸。\n- [需要更多信息] 与其他 OCR 方法相比的计算要求和推理速度。这些参考文献没有提供有关效率的详细信息。\n\n可预见的误解和伤害：\n- 该模型经过印刷文本识别训练。将其应用于手写文本或更复杂的场景可能会导致性能下降和结果不可靠。应清楚地告知用户预期的用例。\n- [需要更多信息] 关于模型如何处理不同语言和脚本的文本。提到了多语言支持，但缺乏细节。\n- 与任何人工智能系统一样，过度依赖未经人工验证的模型输出可能会导致下游应用程序传播错误。建议人工监督。\n\n社会技术考虑因素：\n- 训练数据源和其中的任何潜在偏差[需要更多信息]。训练数据中的偏差可能会导致模型行为出现偏差或歧视性。\n- [需要更多信息] 关于用户数据的使用和隐私影响。如何处理用户提供的图像？是否保留任何数据？\n- 应向用户清楚地概述预期的用例和潜在的误用场景，以及负责任的部署指南。\n\n总之，虽然 TrOCR 显示出有前途的技术能力，但在几个关键领域还需要更多信息来有力地评估其局限性和社会技术影响。建议负责任的披露和监督。",
    "answer_Arabic": "استنادًا إلى المراجع المتوفرة حول نموذج TrOCR (المطبوع بواسطة Microsoft/trocr-base)، إليك بعض المشكلات والقيود المحتملة:\n\nالقيود الفنية:\n- يعتمد النموذج على تغيير حجم الصور المدخلة إلى حجم ثابت 384x384 وتقسيمها إلى تصحيحات 16x16. قد يؤدي هذا إلى تقييد الأداء على الصور النصية ذات الأحجام أو نسب العرض إلى الارتفاع المختلفة جدًا. [بحاجة إلى مزيد من المعلومات] حول مدى جودة تعامله مع أحجام الصور المتنوعة.\n- [يلزم مزيد من المعلومات] حول المتطلبات الحسابية وسرعة الاستدلال مقارنة بأساليب التعرف الضوئي على الحروف الأخرى. المراجع لا تقدم تفاصيل عن الكفاءة.\n\nسوء الفهم والأضرار المتوقعة:\n- تم تدريب النموذج على التعرف على النص المطبوع. قد يؤدي تطبيقه على نص مكتوب بخط اليد أو مشاهد أكثر تعقيدًا إلى انخفاض الأداء ونتائج غير موثوقة. يجب أن يكون المستخدمون على علم بوضوح بحالة الاستخدام المقصودة.\n- [مطلوب مزيد من المعلومات] حول كيفية تعامل النموذج مع النص بلغات ونصوص مختلفة. تم ذكر الدعم متعدد اللغات ولكن التفاصيل غير متوفرة.\n- كما هو الحال مع أي نظام للذكاء الاصطناعي، قد يؤدي الاعتماد المفرط على مخرجات النموذج دون التحقق البشري إلى انتشار الأخطاء في التطبيقات النهائية. وينصح الإشراف البشري.\n\nالاعتبارات الاجتماعية التقنية:\n- مصادر بيانات التدريب وأي تحيزات محتملة فيها هي [بحاجة إلى مزيد من المعلومات]. يمكن أن تؤدي التحيزات في بيانات التدريب إلى سلوك نموذجي متحيز أو تمييزي.\n- [يلزم مزيد من المعلومات] حول استخدام بيانات المستخدم والآثار المترتبة على الخصوصية. كيف يتم التعامل مع الصور المقدمة من المستخدم؟ هل يتم الاحتفاظ بأي بيانات؟\n- ينبغي توضيح حالات الاستخدام المقصودة وسيناريوهات إساءة الاستخدام المحتملة للمستخدمين بشكل واضح، إلى جانب التوجيهات بشأن النشر المسؤول.\n\nباختصار، بينما يظهر TrOCR قدرات تقنية واعدة، هناك حاجة إلى مزيد من المعلومات في العديد من المجالات الرئيسية لتقييم القيود والآثار الاجتماعية التقنية بقوة. وينصح بالإفصاح المسؤول والرقابة.",
    "answer_French": "Sur la base des références fournies sur le modèle TrOCR (microsoft/trocr-base-printed), voici quelques problèmes et limitations potentiels :\n\nLimites techniques :\n- Le modèle repose sur le redimensionnement des images d'entrée à une taille fixe de 384 x 384 et leur division en patchs 16 x 16. Cela peut limiter les performances sur des images de texte de tailles ou de formats d'image très différents. [Plus d'informations nécessaires] sur la façon dont il gère différentes tailles d'image.\n- [Plus d'informations nécessaires] sur les exigences de calcul et la vitesse d'inférence par rapport aux autres approches OCR. Les références ne fournissent pas de détails sur l'efficacité.\n\nMalentendus et préjudices prévisibles :\n- Le modèle est formé à la reconnaissance de texte imprimé. L'appliquer à du texte manuscrit ou à des scènes plus complexes peut entraîner une dégradation des performances et des résultats peu fiables. Les utilisateurs doivent être clairement informés du cas d’utilisation prévu.\n- [Plus d'informations nécessaires] sur la façon dont le modèle gère le texte dans différentes langues et scripts. Le support multilingue est mentionné mais les détails manquent.\n- Comme pour tout système d'IA, une dépendance excessive aux résultats du modèle sans vérification humaine pourrait entraîner la propagation d'erreurs dans les applications en aval. Une surveillance humaine est conseillée.\n\nConsidérations sociotechniques :\n- Les sources de données de formation et tout biais potentiel qu'elles contiennent sont [Plus d'informations nécessaires]. Les biais dans les données de formation pourraient conduire à un comportement biaisé ou discriminatoire du modèle.\n- [Plus d'informations nécessaires] sur l'utilisation des données des utilisateurs et les implications en matière de confidentialité. Comment les images fournies par les utilisateurs sont-elles traitées ? Des données sont-elles conservées ?\n- Les cas d'utilisation prévus et les scénarios d'utilisation abusive potentiels doivent être clairement présentés aux utilisateurs, ainsi que des conseils sur un déploiement responsable.\n\nEn résumé, bien que TrOCR présente des capacités techniques prometteuses, davantage d’informations sont nécessaires dans plusieurs domaines clés pour évaluer de manière robuste les limites et les implications sociotechniques. Une divulgation et une surveillance responsables sont conseillées.",
    "answer_Russian": "На основе предоставленных ссылок на модель TrOCR (microsoft/trocr-base-printed) можно выделить некоторые потенциальные проблемы и ограничения:\n\nТехнические ограничения:\n- Модель основана на изменении размера входных изображений до фиксированного размера 384x384 и разделении их на фрагменты 16x16. Это может ограничить производительность текстовых изображений самых разных размеров или соотношений сторон. [Требуется дополнительная информация] о том, насколько хорошо он обрабатывает изображения различных размеров.\n- [Требуется дополнительная информация] о вычислительных требованиях и скорости вывода по сравнению с другими подходами OCR. В ссылках не содержится подробной информации об эффективности.\n\nПредвидимые недоразумения и вред:\n- Модель обучена распознаванию печатного текста. Применение его к рукописному тексту или более сложным сценам может привести к снижению производительности и ненадежным результатам. Пользователи должны быть четко проинформированы о предполагаемом варианте использования.\n- [Требуется дополнительная информация] о том, как модель обрабатывает текст на разных языках и алфавитах. Упоминается многоязычная поддержка, но подробностей нет.\n- Как и в случае с любой системой искусственного интеллекта, чрезмерная зависимость от результатов модели без проверки человеком может привести к распространению ошибок в последующих приложениях. Рекомендуется человеческий надзор.\n\nСоциотехнические соображения:\n- Источники данных обучения и любые потенциальные искажения в них [Необходима дополнительная информация]. Искажения в обучающих данных могут привести к предвзятому или дискриминационному поведению модели.\n- [Требуется дополнительная информация] об использовании пользовательских данных и последствиях для конфиденциальности. Как обрабатываются изображения, предоставленные пользователями? Сохраняются ли какие-либо данные?\n- Предполагаемые варианты использования и возможные сценарии неправильного использования должны быть четко изложены пользователям, а также даны рекомендации по ответственному развертыванию.\n\nТаким образом, хотя TrOCR демонстрирует многообещающие технические возможности, необходимо больше информации в нескольких ключевых областях для надежной оценки ограничений и социотехнических последствий. Рекомендуется ответственное раскрытие информации и надзор.",
    "answer_Japanese": "TrOCR モデルに関して提供されている参考資料 (microsoft/trocr-base-printed) に基づいて、潜在的な問題と制限をいくつか示します。\n\n技術的な制限:\n- このモデルは、入力画像を 384x384 の固定サイズにサイズ変更し、16x16 のパッチに分割することに依存しています。これにより、サイズやアスペクト比が大きく異なるテキスト画像のパフォーマンスが制限される可能性があります。さまざまな画像サイズをどの程度適切に処理できるかについて [さらに詳しい情報が必要です]。\n- 他の OCR アプローチと比較した計算要件と推論速度に関する [さらなる情報が必要]。参考文献には効率に関する詳細は記載されていません。\n\n予見される誤解と害:\n- モデルは印刷されたテキスト認識でトレーニングされています。手書きのテキストやより複雑なシーンに適用すると、パフォーマンスの低下や信頼性の低い結果が生じる可能性があります。ユーザーには、意図された使用例を明確に通知する必要があります。\n- モデルがさまざまな言語やスクリプトのテキストをどのように処理するかに関する [さらなる情報が必要]。多言語サポートについては言及されていますが、詳細は不明です。\n- 他の AI システムと同様、人間による検証を行わずにモデルの出力に過度に依存すると、下流のアプリケーションでエラーが伝播する可能性があります。人間による監視をお勧めします。\n\n社会技術的考慮事項:\n- トレーニング データ ソースとそこに含まれる潜在的なバイアスは [さらなる情報が必要] です。トレーニング データにバイアスがあると、モデルの動作が偏ったり差別的になったりする可能性があります。\n- ユーザーデータの使用とプライバシーへの影響に関する[さらなる情報が必要]。ユーザーが提供した画像はどのように処理されますか?データは保持されますか?\n- 意図された使用例と潜在的な誤用シナリオは、責任ある導入に関するガイダンスとともにユーザーに明確に説明される必要があります。\n\n要約すると、TrOCR は有望な技術的能力を示していますが、限界と社会技術的な影響を確実に評価するには、いくつかの重要な分野でより多くの情報が必要です。責任ある開示と監視が推奨されます。"
  },
  {
    "question": "bias_recommendations",
    "chain": "generation",
    "answer": "Based on the provided references about the TrOCR model (microsoft/trocr-base-printed), here are some recommendations regarding foreseeable issues:\n\n1. Bias and Fairness: [More Information Needed] The references do not provide details on what types of text images the model was trained and evaluated on. It's important to assess if the training data adequately represents diverse languages, scripts, fonts, handwriting styles, etc. to avoid biased performance. \n\n2. Robustness and Failure Modes: [More Information Needed] More analysis is needed on how the model performs on challenging text images - e.g. with background noise, distortions, low resolution, occlusion, etc. Understanding failure modes is important for real-world deployment.\n\n3. Computational Efficiency: The references mention using image patches of size 16x16 as input to the image Transformer encoder (ref 7). This may be computationally expensive, especially for high-resolution images. Efficiency optimizations and impact on latency should be studied.\n\n4. Responsible Usage: The ability to accurately recognize text in images could potentially be misused for unintended purposes like surveillance or privacy violation. Establishing usage guidelines and considering appropriate restrictions may be prudent.\n\n5. Explainability and Interpretability: [More Information Needed] To build trust with users and aid debugging, it would be valuable to explore techniques to explain the model's predictions and failure modes in an interpretable manner.\n\nIn summary, key areas to focus on are analyzing potential biases, robustness, computational efficiency, responsible usage policies, and model interpretability. More targeted testing and documentation in these areas would help identify and mitigate foreseeable issues before releasing the model.",
    "answer_Chinese": "根据提供的有关 TrOCR 模型的参考资料 (microsoft/trocr-base-printed)，以下是有关可预见问题的一些建议：\n\n1. 偏差和公平性：[需要更多信息] 参考文献没有提供有关模型训练和评估的文本图像类型的详细信息。评估训练数据是否充分代表不同的语言、脚本、字体、手写风格等非常重要，以避免性能出现偏差。 \n\n2. 鲁棒性和故障模式：[需要更多信息] 需要对模型如何在具有挑战性的文本图像上执行进行更多分析 - 例如背景噪声、失真、低分辨率、遮挡等。了解故障模式对于实际部署非常重要。\n\n3. 计算效率：参考文献提到使用大小为 16x16 的图像块作为图像 Transformer 编码器的输入（参考文献 7）。这可能在计算上是昂贵的，特别是对于高分辨率图像。应研究效率优化和对延迟的影响。\n\n4. 负责任的使用：准确识别图像中文本的能力可能会被滥用于监视或侵犯隐私等意外目的。建立使用指南并考虑适当的限制可能是谨慎的做法。\n\n5.可解释性和可解释性：[需要更多信息]为了与用户建立信任并帮助调试，探索以可解释的方式解释模型的预测和故障模式的技术将是有价值的。\n\n总之，需要关注的关键领域是分析潜在偏差、稳健性、计算效率、负责任的使用策略和模型可解释性。在这些领域进行更有针对性的测试和文档将有助于在发布模型之前识别和缓解可预见的问题。",
    "answer_Arabic": "استنادًا إلى المراجع المتوفرة حول نموذج TrOCR (المطبوع بواسطة Microsoft/trocr-base)، إليك بعض التوصيات بشأن المشكلات المتوقعة:\n\n1. التحيز والإنصاف: [بحاجة إلى مزيد من المعلومات] لا توفر المراجع تفاصيل حول أنواع الصور النصية التي تم تدريب النموذج وتقييمه عليها. من المهم تقييم ما إذا كانت بيانات التدريب تمثل اللغات المتنوعة والنصوص والخطوط وأنماط الكتابة اليدوية وما إلى ذلك بشكل مناسب لتجنب الأداء المتحيز. \n\n2. أوضاع المتانة والفشل: [بحاجة إلى مزيد من المعلومات] هناك حاجة إلى مزيد من التحليل حول كيفية أداء النموذج على الصور النصية الصعبة - على سبيل المثال. مع ضوضاء الخلفية، والتشوهات، والدقة المنخفضة، والانسداد، وما إلى ذلك. يعد فهم أوضاع الفشل أمرًا مهمًا للنشر في العالم الحقيقي.\n\n3. الكفاءة الحسابية: تشير المراجع إلى استخدام تصحيحات الصور بحجم 16 × 16 كمدخل لمشفر محول الصور (المرجع 7). قد يكون هذا مكلفًا من الناحية الحسابية، خاصة بالنسبة للصور عالية الدقة. ينبغي دراسة تحسينات الكفاءة والتأثير على الكمون.\n\n4. الاستخدام المسؤول: من المحتمل أن يتم إساءة استخدام القدرة على التعرف بدقة على النص الموجود في الصور لأغراض غير مقصودة مثل المراقبة أو انتهاك الخصوصية. قد يكون من الحكمة وضع إرشادات الاستخدام والنظر في القيود المناسبة.\n\n5. قابلية الشرح والتفسير: [بحاجة إلى مزيد من المعلومات] لبناء الثقة مع المستخدمين والمساعدة في تصحيح الأخطاء، سيكون من المفيد استكشاف تقنيات لشرح تنبؤات النموذج وأنماط الفشل بطريقة قابلة للتفسير.\n\nباختصار، المجالات الرئيسية التي يجب التركيز عليها هي تحليل التحيزات المحتملة، والمتانة، والكفاءة الحسابية، وسياسات الاستخدام المسؤولة، وقابلية تفسير النماذج. من شأن المزيد من الاختبارات والتوثيق المستهدف في هذه المجالات أن يساعد في تحديد المشكلات المتوقعة وتخفيفها قبل إصدار النموذج.",
    "answer_French": "Sur la base des références fournies sur le modèle TrOCR (microsoft/trocr-base-printed), voici quelques recommandations concernant les problèmes prévisibles :\n\n1. Biais et équité : [Plus d'informations nécessaires] Les références ne fournissent pas de détails sur les types d'images textuelles sur lesquelles le modèle a été formé et évalué. Il est important d'évaluer si les données d'entraînement représentent correctement les diverses langues, scripts, polices, styles d'écriture manuscrite, etc. pour éviter des performances biaisées. \n\n2. Robustesse et modes de défaillance : [Plus d'informations nécessaires] Une analyse plus approfondie est nécessaire sur la façon dont le modèle fonctionne sur des images de texte difficiles - par ex. avec bruit de fond, distorsions, basse résolution, occlusion, etc. Comprendre les modes de défaillance est important pour le déploiement dans le monde réel.\n\n3. Efficacité informatique : les références mentionnent l'utilisation de patchs d'image de taille 16x16 comme entrée de l'encodeur du transformateur d'image (réf. 7). Cela peut être coûteux en termes de calcul, en particulier pour les images haute résolution. Les optimisations d’efficacité et l’impact sur la latence doivent être étudiés.\n\n4. Utilisation responsable : la capacité à reconnaître avec précision le texte dans les images pourrait potentiellement être utilisée à des fins involontaires, comme la surveillance ou la violation de la vie privée. Il peut être prudent d’établir des directives d’utilisation et d’envisager les restrictions appropriées.\n\n5. Explicabilité et interprétabilité : [Plus d'informations nécessaires] Pour établir la confiance avec les utilisateurs et faciliter le débogage, il serait utile d'explorer des techniques permettant d'expliquer les prédictions et les modes de défaillance du modèle de manière interprétable.\n\nEn résumé, les domaines clés sur lesquels se concentrer sont l’analyse des biais potentiels, la robustesse, l’efficacité informatique, les politiques d’utilisation responsable et l’interprétabilité du modèle. Des tests et une documentation plus ciblés dans ces domaines aideraient à identifier et à atténuer les problèmes prévisibles avant de publier le modèle.",
    "answer_Russian": "На основе предоставленных ссылок на модель TrOCR (microsoft/trocr-base-printed) приведены некоторые рекомендации относительно прогнозируемых проблем:\n\n1. Предвзятость и справедливость: [Необходима дополнительная информация] В ссылках не содержится подробной информации о том, на каких типах текстовых изображений модель обучалась и оценивалась. Важно оценить, адекватно ли данные обучения представляют различные языки, алфавиты, шрифты, стили рукописного ввода и т. д., чтобы избежать предвзятости в производительности. \n\n2. Устойчивость и режимы отказа: [Необходимо больше информации] Необходим дополнительный анализ того, как модель работает со сложными текстовыми изображениями, например с фоновым шумом, искажениями, низким разрешением, окклюзией и т. д. Понимание режимов сбоя важно для реального развертывания.\n\n3. Эффективность вычислений. В ссылках упоминается использование фрагментов изображения размером 16x16 в качестве входных данных для кодировщика изображения Transformer (ссылка 7). Это может быть дорогостоящим в вычислительном отношении, особенно для изображений с высоким разрешением. Необходимо изучить оптимизацию эффективности и влияние на задержку.\n\n4. Ответственное использование. Способность точно распознавать текст на изображениях потенциально может быть использована не по назначению в непредвиденных целях, например для слежки или нарушения конфиденциальности. Может оказаться целесообразным установить рекомендации по использованию и учесть соответствующие ограничения.\n\n5. Объясняемость и интерпретируемость: [Необходимо больше информации] Чтобы завоевать доверие пользователей и помочь в отладке, было бы полезно изучить методы, позволяющие объяснить прогнозы модели и режимы сбоев в интерпретируемой форме.\n\nТаким образом, ключевыми областями, на которых следует сосредоточиться, являются анализ потенциальных ошибок, надежность, эффективность вычислений, политика ответственного использования и интерпретируемость модели. Более целенаправленное тестирование и документация в этих областях помогут выявить и смягчить прогнозируемые проблемы перед выпуском модели.",
    "answer_Japanese": "TrOCR モデルに関して提供されている参考資料 (microsoft/trocr-base-printed) に基づいて、予見される問題に関する推奨事項をいくつか示します。\n\n1. バイアスと公平性: [さらなる情報が必要] 参考文献には、モデルがどのようなタイプのテキスト画像でトレーニングおよび評価されたかについての詳細が記載されていません。パフォーマンスの偏りを避けるために、トレーニング データが多様な言語、スクリプト、フォント、手書きスタイルなどを適切に表しているかどうかを評価することが重要です。 \n\n2. 堅牢性と故障モード: [さらなる情報が必要] 困難なテキスト画像に対してモデルがどのように動作するかについて、さらなる分析が必要です。バックグラウンド ノイズ、歪み、低解像度、オクルージョンなどを伴います。実際の展開では、障害モードを理解することが重要です。\n\n3. 計算効率: 参考文献には、画像 Transformer エンコーダへの入力としてサイズ 16x16 の画像パッチを使用することが記載されています (参考文献 7)。これは、特に高解像度の画像の場合、計算コストが高くなる可能性があります。効率の最適化とレイテンシへの影響を調査する必要があります。\n\n4. 責任ある使用法: 画像内のテキストを正確に認識する機能は、監視やプライバシー侵害などの意図しない目的に悪用される可能性があります。使用ガイドラインを確立し、適切な制限を検討することが賢明かもしれません。\n\n5. 説明可能性と解釈可能性: [さらに多くの情報が必要] ユーザーとの信頼を構築し、デバッグを支援するには、モデルの予測と障害モードを解釈可能な方法で説明する手法を検討することが重要です。\n\n要約すると、焦点を当てる重要な領域は、潜在的なバイアス、堅牢性、計算効率、責任ある使用ポリシー、およびモデルの解釈可能性を分析することです。これらの分野でのよりターゲットを絞ったテストと文書化は、モデルをリリースする前に予見可能な問題を特定して軽減するのに役立ちます。"
  },
  {
    "question": "training_data",
    "chain": "generation",
    "answer": "The microsoft/trocr-base-printed model was pre-trained on a large-scale synthetic dataset of hundreds of millions of printed textline images, and further fine-tuned on two relatively small datasets corresponding to printed and receipt text, totaling 3.3M textlines. The training data was augmented using six kinds of image transformations to enhance variety.\n\n[More Information Needed] for links to documentation related to data pre-processing or additional filtering.",
    "answer_Chinese": "microsoft/trocr-base-printed 模型在包含数亿张打印文本行图像的大规模合成数据集上进行了预训练，并在对应于打印文本和收据文本的两个相对较小的数据集（总计 330 万条文本行）上进行了进一步微调。使用六种图像变换来增强训练数据以增强多样性。\n\n[需要更多信息] 获取与数据预处理或附加过滤相关的文档链接。",
    "answer_Arabic": "تم تدريب النموذج المطبوع بقاعدة Microsoft/trocr مسبقًا على مجموعة بيانات اصطناعية واسعة النطاق تضم مئات الملايين من صور الخطوط النصية المطبوعة، وتم ضبطه بشكل أكبر على مجموعتي بيانات صغيرتين نسبيًا تتوافق مع النص المطبوع والإيصالات، بإجمالي 3.3 مليون سطر نصي . وتمت زيادة بيانات التدريب باستخدام ستة أنواع من تحويلات الصور لتعزيز التنوع.\n\n[يلزم مزيد من المعلومات] للحصول على روابط للوثائق المتعلقة بالمعالجة المسبقة للبيانات أو التصفية الإضافية.",
    "answer_French": "Le modèle imprimé Microsoft/Trocr a été pré-entraîné sur un ensemble de données synthétiques à grande échelle de centaines de millions d'images de lignes de texte imprimées, puis affiné sur deux ensembles de données relativement petits correspondant au texte imprimé et au reçu, totalisant 3,3 millions de lignes de texte. . Les données de formation ont été enrichies à l'aide de six types de transformations d'images pour améliorer la variété.\n\n[Plus d'informations nécessaires] pour des liens vers la documentation relative au prétraitement des données ou au filtrage supplémentaire.",
    "answer_Russian": "Печатная модель microsoft/trocr-base была предварительно обучена на крупномасштабном синтетическом наборе данных, состоящем из сотен миллионов изображений печатных текстовых строк, а затем доработана на двух относительно небольших наборах данных, соответствующих печатному тексту и тексту квитанции, всего 3,3 миллиона текстовых строк. . Данные обучения были дополнены шестью видами преобразований изображений для увеличения разнообразия.\n\n[Требуется дополнительная информация] для ссылок на документацию, связанную с предварительной обработкой данных или дополнительной фильтрацией.",
    "answer_Japanese": "Microsoft/trocr-base-printed モデルは、数億の印刷されたテキスト行画像からなる大規模な合成データセットで事前トレーニングされ、印刷テキストと領収書のテキストに対応する 2 つの比較的小規模なデータセットでさらに微調整され、合計 330 万のテキスト行になりました。 。トレーニング データは、多様性を高めるために 6 種類の画像変換を使用して拡張されました。\n\nデータの前処理または追加のフィルタリングに関連するドキュメントへのリンクについては、[詳細情報が必要] を参照してください。"
  },
  {
    "question": "preprocessing",
    "chain": "generation",
    "answer": "Based on the provided references, here are the details about the preprocessing for the data of the model microsoft/trocr-base-printed:\n\nTokenization:\nThe outputs of the TrOCR models are based on Byte Pair Encoding (BPE) and SentencePiece for tokenization, and do not rely on any task-related vocabularies.\n\nResizing/Rewriting:\nThe printed dataset consists of 3.3M textline images, which are obtained through the following steps:\n1. Collect around 53K real-world receipt images \n2. Recognize the text on the receipts using commercial OCR engines\n3. Crop the textlines based on their coordinates from the OCR results\n4. Rectify the cropped textlines into normalized images\n5. Use TRDG to synthesize an additional 1M printed textline images with two receipt fonts and built-in printed fonts\n6. Apply six kinds of image transformations plus keeping the original images for data augmentation (Reference from Krishnan and Jawahar 2016)\n\n[More Information Needed] on the specific resizing dimensions or normalization techniques used.",
    "answer_Chinese": "根据提供的参考资料，以下是有关模型 microsoft/trocr-base-printed 数据预处理的详细信息：\n\n代币化：\nTrOCR 模型的输出基于字节对编码 (BPE) 和 SentencePiece 进行标记化，并且不依赖于任何与任务相关的词汇表。\n\n调整大小/重写：\n打印的数据集由 3.3M 文本行图像组成，这些图像是通过以下步骤获得的：\n1. 收集约 53K 张真实收据图像 \n2. 使用商业 OCR 引擎识别收据上的文字\n3. 根据 OCR 结果中的坐标裁剪文本行\n4.将裁剪后的文本线矫正为标准化图像\n5. 使用 TRDG 合成额外的 1M 打印文本行图像，具有两种收据字体和内置打印字体\n6. 应用六种图像变换并保留原始图像进行数据增强（参考 Krishnan 和 Jawahar 2016）\n\n[需要更多信息]有关具体调整尺寸或所使用的标准化技术。",
    "answer_Arabic": "بناءً على المراجع المتوفرة، فيما يلي تفاصيل حول المعالجة المسبقة لبيانات النموذج microsoft/trocr-base-printed:\n\nالترميز:\nتعتمد مخرجات نماذج TrOCR على تشفير زوج البايت (BPE) وSentencePiece للترميز، ولا تعتمد على أي مفردات متعلقة بالمهمة.\n\nتغيير الحجم/إعادة الكتابة:\nتتكون مجموعة البيانات المطبوعة من 3.3 مليون صورة نصية، والتي يتم الحصول عليها من خلال الخطوات التالية:\n1. اجمع حوالي 53 ألف صورة إيصال حقيقية \n2. التعرف على النص الموجود على الإيصالات باستخدام محركات التعرف الضوئي على الحروف التجارية\n3. قم بقص خطوط النص بناءً على إحداثياتها من نتائج التعرف الضوئي على الحروف\n4. قم بتصحيح خطوط النص التي تم اقتصاصها وتحويلها إلى صور طبيعية\n5. استخدم TRDG لتجميع مليون صورة نصية مطبوعة إضافية مع خطين للإيصالات وخطوط مطبوعة مدمجة\n6. تطبيق ستة أنواع من تحويلات الصور بالإضافة إلى الاحتفاظ بالصور الأصلية لزيادة البيانات (مرجع من كريشنان وجواهر 2016)\n\n[مطلوب مزيد من المعلومات] حول أبعاد تغيير الحجم المحددة أو تقنيات التسوية المستخدمة.",
    "answer_French": "Sur la base des références fournies, voici les détails sur le prétraitement des données du modèle microsoft/trocr-base-printed :\n\nTokenisation :\nLes sorties des modèles TrOCR sont basées sur Byte Pair Encoding (BPE) et SentencePièce pour la tokenisation, et ne reposent sur aucun vocabulaire lié aux tâches.\n\nRedimensionnement/Réécriture :\nL'ensemble de données imprimé se compose de 3,3 millions d'images de lignes de texte, obtenues selon les étapes suivantes :\n1. Collectez environ 53 000 images de reçus réels \n2. Reconnaître le texte sur les reçus à l'aide des moteurs OCR commerciaux\n3. Recadrez les lignes de texte en fonction de leurs coordonnées à partir des résultats OCR\n4. Rectifiez les lignes de texte recadrées en images normalisées\n5. Utilisez TRDG pour synthétiser 1 million d'images de ligne de texte imprimées supplémentaires avec deux polices de reçus et des polices imprimées intégrées.\n6. Appliquez six types de transformations d'image et conservez les images originales pour l'augmentation des données (référence de Krishnan et Jawahar 2016)\n\n[Plus d'informations nécessaires] sur les dimensions de redimensionnement spécifiques ou les techniques de normalisation utilisées.",
    "answer_Russian": "На основании предоставленных ссылок приводятся подробности предварительной обработки данных модели microsoft/trocr-base-printed:\n\nТокенизация:\nВыходные данные моделей TrOCR основаны на кодировании пар байтов (BPE) и SentencePiece для токенизации и не полагаются на какие-либо словари, связанные с задачами.\n\nИзменение размера/переписывание:\nРаспечатанный набор данных состоит из 3,3 млн текстовых изображений, которые получаются с помощью следующих шагов:\n1. Соберите около 53 тысяч реальных изображений квитанций. \n2. Распознавайте текст квитанций с помощью коммерческих систем оптического распознавания символов.\n3. Обрежьте текстовые строки по их координатам из результатов OCR.\n4. Преобразуйте обрезанные текстовые строки в нормализованные изображения.\n5. Используйте TRDG для синтеза дополнительных печатных текстовых изображений размером 1 миллион с двумя шрифтами квитанций и встроенными печатными шрифтами.\n6. Примените шесть видов преобразований изображений, а также сохраните исходные изображения для увеличения данных (ссылка из Кришнана и Джавахара, 2016 г.).\n\n[Требуется дополнительная информация] о конкретных размерах изменения размера или используемых методах нормализации.",
    "answer_Japanese": "提供された参考資料に基づいて、microsoft/trocr-base-printed モデルのデータの前処理の詳細を次に示します。\n\nトークン化:\nTrOCR モデルの出力は、バイト ペア エンコーディング (BPE) とトークン化のための SentencePiece に基づいており、タスク関連の語彙には依存しません。\n\nサイズ変更/書き換え:\n印刷されたデータセットは 330 万個のテキストライン画像で構成されており、これらは次の手順で取得されます。\n1. 約 53,000 枚の実際のレシート画像を収集する \n2. 市販の OCR エンジンを使用してレシートのテキストを認識します\n3. OCR 結果の座標に基づいてテキスト行をトリミングします。\n4. 切り取られたテキスト行を正規化された画像に修正します\n5. TRDG を使用して、2 つのレシート フォントと内蔵の印刷フォントを使用して、追加の 1M の印刷テキストライン画像を合成します。\n6. 6 種類の画像変換を適用し、さらにデータ拡張のために元の画像を保持します (Krishnan と Jawahar 2016 からの参照)\n\n使用される特定のサイズ変更次元または正規化手法に関する [詳細情報が必要]。"
  },
  {
    "question": "training_regime",
    "chain": "generation",
    "answer": "Based on the provided references, here are the training hyperparameters for the microsoft/trocr-base-printed model:\n\n- Batch size: 2,048\n- Learning rate: 5e-5\n- Image resolution: 384×384\n- Patch size: 16×16\n- Encoder: BEiT BASE with 12 layers, 768 hidden size, and 12 attention heads\n- Decoder: RoBERTa LARGE, using only the last 12 layers\n- Beam size: 10\n- Tokenizer: BPE and SentencePiece tokenizer from Fairseq\n\n[More Information Needed] on the exact number of training steps/epochs, optimizer, learning rate schedule, and other hyperparameters not explicitly mentioned in the provided references.\n\nThe model was trained on 32 V100 GPUs with 32GB memory for pre-training and 8 V100 GPUs for fine-tuning. The total number of parameters for the TrOCR BASE model is approximately 334M.",
    "answer_Chinese": "根据提供的参考资料，以下是 microsoft/trocr-base-printed 模型的训练超参数：\n\n- 批量大小：2,048\n- 学习率：5e-5\n- 图像分辨率：384×384\n- 贴片尺寸：16×16\n- 编码器：BEiT BASE，12层，768个隐藏尺寸，12个注意力头\n- 解码器：RoBERTa LARGE，仅使用最后 12 层\n- 光束尺寸：10\n- 分词器：Fairseq 的 BPE 和 SentencePiece 分词器\n\n[需要更多信息]关于训练步骤/时期的确切数量、优化器、学习率计划以及所提供的参考文献中未明确提及的其他超参数。\n\n该模型在具有 32GB 内存的 32 个 V100 GPU 上进行预训练，并在 8 个 V100 GPU 上进行微调。 TrOCR BASE模型的参数总数约为334M。",
    "answer_Arabic": "استنادًا إلى المراجع المتوفرة، إليك معلمات التدريب الفائقة للنموذج المطبوع من Microsoft/trocr-base:\n\n- حجم الدفعة : 2,048\n- معدل التعلم: 5e-5\n- دقة الصورة: 384×384\n- حجم الرقعة : 16×16\n- التشفير: BEiT BASE مكون من 12 طبقة و768 حجم مخفي و12 رأس انتباه\n- وحدة فك التشفير: RoBERTa LARGE، باستخدام آخر 12 طبقة فقط\n- حجم الشعاع : 10\n- Tokenizer: BPE وSentencePiece tokenizer من Fairseq\n\n[مطلوب مزيد من المعلومات] حول العدد الدقيق لخطوات/عصور التدريب، والمُحسِّن، وجدول معدل التعلم، والمعلمات الفائقة الأخرى التي لم يتم ذكرها صراحةً في المراجع المتوفرة.\n\nتم تدريب النموذج على 32 وحدة معالجة رسوميات V100 مع ذاكرة سعة 32 جيجابايت للتدريب المسبق و8 وحدات معالجة رسوميات V100 للضبط الدقيق. يبلغ إجمالي عدد المعلمات لنموذج TrOCR BASE حوالي 334 مليونًا.",
    "answer_French": "Sur la base des références fournies, voici les hyperparamètres de formation pour le modèle Microsoft/trocr-base-printed :\n\n- Taille du lot : 2 048\n- Taux d'apprentissage : 5e-5\n- Résolution de l'image : 384 × 384\n- Taille du patch : 16×16\n- Encodeur : BEiT BASE avec 12 couches, 768 tailles cachées et 12 têtes d'attention\n- Décodeur : RoBERTa LARGE, utilisant uniquement les 12 dernières couches\n- Taille du faisceau : 10\n- Tokenizer : tokenizer BPE et SentencePièce de Fairseq\n\n[Plus d'informations nécessaires] sur le nombre exact d'étapes/époques de formation, l'optimiseur, le calendrier de taux d'apprentissage et d'autres hyperparamètres non explicitement mentionnés dans les références fournies.\n\nLe modèle a été formé sur 32 GPU V100 avec 32 Go de mémoire pour le pré-entraînement et 8 GPU V100 pour le réglage fin. Le nombre total de paramètres pour le modèle TrOCR BASE est d'environ 334 millions.",
    "answer_Russian": "Основываясь на предоставленных ссылках, вот гиперпараметры обучения для модели, напечатанной на базе Microsoft/trocr:\n\n- Размер пакета: 2048\n- Скорость обучения: 5e-5\n- Разрешение изображения: 384×384\n- Размер патча: 16×16\n- Кодировщик: BEiT BASE с 12 слоями, скрытым размером 768 и 12 головками внимания.\n- Декодер: RoBERTa LARGE, использует только последние 12 слоев.\n- Размер луча: 10\n- Токенизатор: токенизатор BPE и SentencePiece от Fairseq.\n\n[Требуется дополнительная информация] о точном количестве шагов/эпох обучения, оптимизаторе, графике скорости обучения и других гиперпараметрах, явно не упомянутых в предоставленных ссылках.\n\nМодель обучалась на 32 графических процессорах V100 с 32 ГБ памяти для предварительного обучения и на 8 графических процессорах V100 для точной настройки. Общее количество параметров модели TrOCR BASE составляет примерно 334M.",
    "answer_Japanese": "提供された参考資料に基づいて、microsoft/trocr-base-printed モデルのトレーニング ハイパーパラメーターを次に示します。\n\n- バッチサイズ: 2,048\n- 学習率: 5e-5\n- 画像解像度: 384×384\n- パッチサイズ：16×16\n- エンコーダー: 12 レイヤー、768 隠しサイズ、12 個のアテンション ヘッドを備えた BEiT BASE\n- デコーダー: RoBERTa LARGE、最後の 12 レイヤーのみを使用\n- ビームサイズ: 10\n- トークナイザー: Fairseq の BPE および SentencePiece トークナイザー\n\nトレーニング ステップ/エポックの正確な数、オプティマイザー、学習率スケジュール、および提供された参考文献に明示的に記載されていないその他のハイパーパラメーターに関する [追加情報が必要]。\n\nモデルは、事前トレーニング用に 32 GB メモリを備えた 32 個の V100 GPU でトレーニングされ、微調整用に 8 個の V100 GPU が使用されました。 TrOCR BASE モデルのパラメータの総数は約 3 億 3,400 万個です。"
  },
  {
    "question": "speeds_sizes_times",
    "chain": "generation",
    "answer": "Here are the details about the model microsoft/trocr-base-printed based on the provided references:\n\nModel Architecture:\n- Uses a Transformer-based encoder-decoder architecture\n- Encoder: BEiT base model \n- Decoder: Transformer decoder initialized with RoBERTa base\n- Outperforms CNN-based feature extractors and RNN-based language modeling without complex pre/post-processing\n\nTraining:\n- Pre-trained on large-scale synthetic data\n- Fine-tuned on the SROIE dataset\n- Trained using 32 V100 GPUs with 32GB memory for pre-training\n- Fine-tuned using 8 V100 GPUs\n[More Information Needed] on exact training time\n\nModel Checkpoint:\n- Checkpoint file: trocr-base-printed.pt\n- Download link: https://layoutlm.blob.core.windows.net/trocr/model_zoo/fairseq/trocr-base-printed.pt\n[More Information Needed] on checkpoint size\n\nPerformance:\n- Achieves state-of-the-art performance on the SROIE leaderboard for printed text recognition\n[More Information Needed] on exact throughput metrics\n\nThe TrOCR model code and checkpoints are publicly available at https://aka.ms/trocr.",
    "answer_Chinese": "以下是根据提供的参考资料有关 microsoft/trocr-base-printed 模型的详细信息：\n\n模型架构：\n- 使用基于 Transformer 的编码器-解码器架构\n- 编码器：BEiT 基础模型 \n- 解码器：使用 RoBERTa 基础初始化的 Transformer 解码器\n- 优于基于 CNN 的特征提取器和基于 RNN 的语言建模，无需复杂的预处理/后处理\n\n训练：\n- 对大规模合成数据进行预训练\n- 在 SROIE 数据集上进行微调\n- 使用 32 个 V100 GPU 和 32GB 内存进行预训练进行训练\n- 使用 8 个 V100 GPU 进行微调\n[需要更多信息]关于确切的训练时间\n\n模型检查点：\n- 检查点文件：trocr-base-printed.pt\n- 下载链接：https://layoutlm.blob.core.windows.net/trocr/model_zoo/fairseq/trocr-base-printed.pt\n[需要更多信息]关于检查点的大小\n\n表现：\n- 在 SROIE 印刷文本识别排行榜上实现了最先进的性能\n[需要更多信息]关于确切的吞吐量指标\n\nTrOCR 模型代码和检查点可在 https://aka.ms/trocr 上公开获取。",
    "answer_Arabic": "فيما يلي تفاصيل حول نموذج Microsoft/trocr-base-printed بناءً على المراجع المتوفرة:\n\nالعمارة النموذجية:\n- يستخدم بنية التشفير وفك التشفير القائمة على المحولات\n- التشفير: النموذج الأساسي BEiT \n- وحدة فك التشفير: تمت تهيئة وحدة فك ترميز المحولات باستخدام قاعدة RoBERTa\n- يتفوق على مستخلصات الميزات المستندة إلى CNN ونمذجة اللغة المستندة إلى RNN دون معالجة مسبقة/لاحقة معقدة\n\nتمرين:\n- تم تدريبه مسبقًا على البيانات الاصطناعية واسعة النطاق\n- ضبط دقيق على مجموعة بيانات SROIE\n- تم التدريب باستخدام 32 وحدة معالجة رسومات V100 مع ذاكرة سعة 32 جيجابايت للتدريب المسبق\n- تم ضبطها بدقة باستخدام 8 وحدات معالجة رسوميات V100\n[بحاجة إلى مزيد من المعلومات] حول وقت التدريب المحدد\n\nنقطة التفتيش النموذجية:\n- ملف نقطة التفتيش: trocr-base-printed.pt\n- رابط التحميل: https://layoutlm.blob.core.windows.net/trocr/model_zoo/fairseq/trocr-base-printed.pt\n[بحاجة إلى مزيد من المعلومات] حول حجم نقطة التفتيش\n\nأداء:\n- يحقق أداءً متطورًا على لوحة المتصدرين SROIE للتعرف على النص المطبوع\n[مطلوب مزيد من المعلومات] حول مقاييس الإنتاجية الدقيقة\n\nرمز نموذج TrOCR ونقاط التفتيش متاحة للجمهور على https://aka.ms/trocr.",
    "answer_French": "Voici les détails sur le modèle microsoft/trocr-base-printed basés sur les références fournies :\n\nArchitecture du modèle :\n- Utilise une architecture encodeur-décodeur basée sur un transformateur\n- Encodeur : modèle de base BEiT \n- Décodeur : Décodeur transformateur initialisé avec la base RoBERTa\n- Surpasse les extracteurs de fonctionnalités basés sur CNN et la modélisation de langage basée sur RNN sans pré/post-traitement complexe\n\nEntraînement:\n- Pré-formé sur les données synthétiques à grande échelle\n- Affinement sur le jeu de données SROIE\n- Formé à l'aide de 32 GPU V100 avec 32 Go de mémoire pour la pré-formation\n- Affiné à l'aide de 8 GPU V100\n[Plus d'informations nécessaires] sur la durée exacte de la formation\n\nPoint de contrôle du modèle :\n- Fichier de point de contrôle : trocr-base-printed.pt\n- Lien de téléchargement : https://layoutlm.blob.core.windows.net/trocr/model_zoo/fairseq/trocr-base-printed.pt\n[Plus d'informations nécessaires] sur la taille du point de contrôle\n\nPerformance:\n- Atteint des performances de pointe dans le classement SROIE pour la reconnaissance de texte imprimé\n[Plus d'informations nécessaires] sur les mesures de débit exactes\n\nLe code du modèle TrOCR et les points de contrôle sont accessibles au public sur https://aka.ms/trocr.",
    "answer_Russian": "Вот подробности о модели microsoft/trocr-base, напечатанной на основе предоставленных ссылок:\n\nМодельная архитектура:\n- Использует архитектуру кодера-декодера на основе трансформатора.\n- Кодировщик: базовая модель BEiT \n- Декодер: декодер трансформатора, инициализированный с помощью базы RoBERTa.\n- Превосходит средства извлечения признаков на основе CNN и языковое моделирование на основе RNN без сложной предварительной/постобработки.\n\nОбучение:\n- Предварительное обучение на крупномасштабных синтетических данных\n- Точная настройка на наборе данных SROIE.\n- Обучение с использованием 32 графических процессоров V100 с 32 ГБ памяти для предварительного обучения.\n- Точная настройка с использованием 8 графических процессоров V100.\n[Требуется дополнительная информация] о точном времени обучения\n\nМодель КПП:\n- Файл контрольной точки: trocr-base-printed.pt.\n- Ссылка для скачивания: https://layoutlm.blob.core.windows.net/trocr/model_zoo/fairseq/trocr-base-printed.pt.\n[Требуется дополнительная информация] о размере контрольной точки\n\nПроизводительность:\n- Достигает самых высоких показателей в таблице лидеров SROIE по распознаванию печатного текста.\n[Требуется дополнительная информация] о точных показателях пропускной способности\n\nКод модели и контрольные точки TrOCR общедоступны по адресу https://aka.ms/trocr.",
    "answer_Japanese": "提供された参考資料に基づいた、microsoft/trocr-base-printed モデルの詳細は次のとおりです。\n\nモデルのアーキテクチャ:\n- Transformer ベースのエンコーダ/デコーダ アーキテクチャを使用\n- エンコーダー: BEiT ベースモデル \n- デコーダ: RoBERTa ベースで初期化されたトランス デコーダ\n- 複雑な前処理/後処理を行わずに、CNN ベースの特徴抽出機能や RNN ベースの言語モデリングよりも優れたパフォーマンスを発揮します。\n\nトレーニング：\n- 大規模な合成データで事前トレーニング済み\n- SROIE データセットで微調整\n- 事前トレーニング用に 32GB メモリを備えた 32 個の V100 GPU を使用してトレーニング\n- 8 個の V100 GPU を使用して微調整\n正確なトレーニング時間については[さらに詳しい情報が必要です]\n\nモデルのチェックポイント:\n- チェックポイント ファイル: trocr-base-printed.pt\n- ダウンロード リンク: https://layoutlm.blob.core.windows.net/trocr/model_zoo/fairseq/trocr-base-printed.pt\nチェックポイント サイズに関する [追加情報が必要]\n\nパフォーマンス：\n- 印刷されたテキスト認識の SROIE リーダーボードで最先端のパフォーマンスを達成\n正確なスループット指標に関する [追加情報が必要]\n\nTrOCR モデル コードとチェックポイントは、https://aka.ms/trocr で公開されています。"
  },
  {
    "question": "testing_data",
    "chain": "generation",
    "answer": "Based on the provided references, the TrOCR models were evaluated on the following benchmarks and datasets for printed text recognition:\n\n1. IAM Handwriting Database: The TrOCR models were evaluated on this dataset and compared against existing methods. The TrOCR LARGE model achieved better results than methods using CTC decoders.\n\n2. SROIE (Scanned Receipts OCR and Information Extraction) dataset (Task 2): This dataset focuses on text recognition in receipt images. The evaluation was performed on cropped images of textlines obtained from the ground truth bounding boxes.\n\n[More Information Needed] for other specific benchmarks or datasets used to evaluate the microsoft/trocr-base-printed model, as the provided references do not mention them explicitly.",
    "answer_Chinese": "根据提供的参考资料，TrOCR 模型在以下印刷文本识别基准和数据集上进行了评估：\n\n1. IAM 手写数据库：在此数据集上评估 TrOCR 模型，并与现有方法进行比较。 TrOCR LARGE 模型比使用 CTC 解码器的方法取得了更好的结果。\n\n2. SROIE（扫描收据 OCR 和信息提取）数据集（任务 2）：该数据集专注于收据图像中的文本识别。评估是对从地面真实边界框获得的文本行的裁剪图像进行的。\n\n[需要更多信息]用于评估 microsoft/trocr-base-printed 模型的其他特定基准或数据集，因为提供的参考文献没有明确提及它们。",
    "answer_Arabic": "بناءً على المراجع المقدمة، تم تقييم نماذج TrOCR بناءً على المعايير ومجموعات البيانات التالية للتعرف على النص المطبوع:\n\n1. قاعدة بيانات الكتابة اليدوية IAM: تم تقييم نماذج TrOCR على مجموعة البيانات هذه ومقارنتها بالطرق الحالية. حقق نموذج TrOCR LARGE نتائج أفضل من الطرق التي تستخدم أجهزة فك التشفير CTC.\n\n2. مجموعة بيانات SROIE (التعرف الضوئي على الحروف للإيصالات الممسوحة ضوئيًا واستخراج المعلومات) (المهمة 2): تركز مجموعة البيانات هذه على التعرف على النص في صور الإيصالات. تم إجراء التقييم على الصور المقطوعة لخطوط النص التي تم الحصول عليها من المربعات المحيطة بالحقيقة الأرضية.\n\n[يلزم مزيد من المعلومات] لمعايير أو مجموعات بيانات محددة أخرى تستخدم لتقييم النموذج المطبوع من Microsoft/trocr-base، حيث أن المراجع المقدمة لا تذكرها بشكل صريح.",
    "answer_French": "Sur la base des références fournies, les modèles TrOCR ont été évalués sur les références et ensembles de données suivants pour la reconnaissance de textes imprimés :\n\n1. Base de données d'écriture manuscrite IAM : les modèles TrOCR ont été évalués sur cet ensemble de données et comparés aux méthodes existantes. Le modèle TrOCR LARGE a obtenu de meilleurs résultats que les méthodes utilisant des décodeurs CTC.\n\n2. Ensemble de données SROIE (Scanned Receipts OCR and Information Extraction) (tâche 2) : cet ensemble de données se concentre sur la reconnaissance de texte dans les images de reçus. L'évaluation a été réalisée sur des images recadrées de lignes de texte obtenues à partir des cadres de vérité terrain.\n\n[Plus d'informations nécessaires] pour d'autres références ou ensembles de données spécifiques utilisés pour évaluer le modèle Microsoft/trocr-base-printed, car les références fournies ne les mentionnent pas explicitement.",
    "answer_Russian": "На основе предоставленных ссылок модели TrOCR были оценены по следующим критериям и наборам данных для распознавания печатного текста:\n\n1. База данных почерков IAM. Модели TrOCR были оценены на этом наборе данных и сравнены с существующими методами. Модель TrOCR LARGE дала лучшие результаты, чем методы, использующие декодеры CTC.\n\n2. Набор данных SROIE (оптическое распознавание текста и извлечение информации для сканированных квитанций) (задача 2). Этот набор данных ориентирован на распознавание текста на изображениях квитанций. Оценка проводилась на обрезанных изображениях текстовых строк, полученных из ограничивающих рамок основной истины.\n\n[Требуется дополнительная информация] для других конкретных тестов или наборов данных, используемых для оценки модели, напечатанной на базе Microsoft/trocr, поскольку в предоставленных ссылках они не упоминаются явно.",
    "answer_Japanese": "提供された参考資料に基づいて、TrOCR モデルは印刷テキスト認識用の次のベンチマークとデータセットで評価されました。\n\n1. IAM 手書きデータベース: TrOCR モデルはこのデータセットで評価され、既存の方法と比較されました。 TrOCR LARGE モデルは、CTC デコーダを使用する方法よりも優れた結果を達成しました。\n\n2. SROIE (Scanned Receipts OCR and Information Extraction) データセット (タスク 2): このデータセットは、レシート画像内のテキスト認識に焦点を当てています。評価は、グラウンド トゥルース境界ボックスから取得されたテキスト行のトリミングされた画像に対して実行されました。\n\nMicrosoft/trocr-base-printed モデルの評価に使用される他の特定のベンチマークまたはデータセットについては、提供されている参考文献に明示的に言及されていないため、[詳細情報が必要]。"
  },
  {
    "question": "testing_factors",
    "chain": "generation",
    "answer": "Based on the provided references, here are some foreseeable characteristics that may influence how the microsoft/trocr-base-printed model behaves:\n\n1. Domain and context: The model is designed for printed text recognition. It can handle scanned documents, photos of documents, scene photos, or subtitle text superimposed on images. The model's performance may vary depending on the specific domain and context of the input images.\n\n2. Text characteristics: The model's performance may be influenced by various text characteristics such as font, size, spacing, and layout. [More Information Needed] on how the model handles different text characteristics and if there are any disparities in performance.\n\n3. Image quality: The quality of input images, including resolution, contrast, and noise, can impact the model's text recognition accuracy. [More Information Needed] on how the model performs across different levels of image quality and if there are any performance disparities.\n\n4. Language and script: The model can be extended for multilingual text recognition by leveraging multilingual pre-trained models and expanding the dictionary. However, [More Information Needed] on the specific languages and scripts supported by the microsoft/trocr-base-printed model and if there are any performance disparities across different languages or scripts.\n\n5. Population subgroups: [More Information Needed] on how the model performs across different population subgroups, such as demographics, geographic regions, or socioeconomic factors. Ideally, evaluation should be disaggregated to uncover any potential disparities in performance.\n\nTo comprehensively assess the model's behavior and identify any disparities, further evaluation and disaggregation of results across various factors would be necessary. The provided references do not contain sufficient information to fully address all aspects of the question.",
    "answer_Chinese": "根据提供的参考资料，以下是一些可能影响 microsoft/trocr-base-printed 模型行为方式的可预见特征：\n\n1. 领域和上下文：该模型是为印刷文本识别而设计的。它可以处理扫描文档、文档照片、场景照片或叠加在图像上的字幕文本。模型的性能可能会根据输入图像的特定领域和上下文而有所不同。\n\n2. 文本特征：模型的性能可能会受到各种文本特征的影响，例如字体、大小、间距和布局。 [需要更多信息]关于模型如何处理不同的文本特征以及性能是否存在差异。\n\n3. 图像质量：输入图像的质量，包括分辨率、对比度和噪声，会影响模型的文本识别准确性。 [需要更多信息]关于模型在不同图像质量级别上的表现以及是否存在任何性能差异。\n\n4. 语言和文字：通过利用多语言预训练模型和扩展词典，可以将该模型扩展到多语言文本识别。但是，[需要更多信息] microsoft/trocr-base-printed 模型支持的特定语言和脚本，以及不同语言或脚本之间是否存在任何性能差异。\n\n5. 人口亚组：[需要更多信息]关于模型如何在不同人口亚组（例如人口统计、地理区域或社会经济因素）中表现。理想情况下，评估应进行分解，以发现绩效中任何潜在的差异。\n\n为了全面评估模型的行为并确定任何差异，有必要对各种因素的结果进行进一步评估和分解。提供的参考文献不包含足够的信息来完全解决问题的所有方面。",
    "answer_Arabic": "استنادًا إلى المراجع المتوفرة، إليك بعض الخصائص المتوقعة التي قد تؤثر على كيفية عمل النموذج المطبوع بواسطة Microsoft/trocr-base:\n\n1. المجال والسياق: تم تصميم النموذج للتعرف على النص المطبوع. يمكنه التعامل مع المستندات الممسوحة ضوئيًا أو صور المستندات أو صور المشهد أو نص الترجمة المتراكب على الصور. قد يختلف أداء النموذج وفقًا للمجال وسياق الصور المدخلة.\n\n2. خصائص النص: قد يتأثر أداء النموذج بخصائص النص المختلفة مثل الخط والحجم والتباعد والتخطيط. [مطلوب مزيد من المعلومات] حول كيفية تعامل النموذج مع خصائص النص المختلفة وما إذا كان هناك أي اختلافات في الأداء.\n\n3. جودة الصورة: يمكن أن تؤثر جودة الصور المدخلة، بما في ذلك الدقة والتباين والضوضاء، على دقة التعرف على النص في النموذج. [يلزم مزيد من المعلومات] حول كيفية أداء النموذج عبر مستويات مختلفة من جودة الصورة وما إذا كان هناك أي اختلافات في الأداء.\n\n4. اللغة والنص: يمكن توسيع النموذج للتعرف على النص متعدد اللغات من خلال الاستفادة من النماذج متعددة اللغات المدربة مسبقًا وتوسيع القاموس. ومع ذلك، [يلزم مزيد من المعلومات] حول اللغات والبرامج النصية المحددة التي يدعمها النموذج المطبوع من Microsoft/trocr-base وما إذا كان هناك أي اختلافات في الأداء عبر اللغات أو البرامج النصية المختلفة.\n\n5. المجموعات الفرعية السكانية: [بحاجة إلى مزيد من المعلومات] حول كيفية أداء النموذج عبر مجموعات سكانية فرعية مختلفة، مثل التركيبة السكانية أو المناطق الجغرافية أو العوامل الاجتماعية والاقتصادية. ومن الناحية المثالية، ينبغي أن يكون التقييم مصنفاً للكشف عن أي تباينات محتملة في الأداء.\n\nلإجراء تقييم شامل لسلوك النموذج وتحديد أي تباينات، سيكون من الضروري إجراء مزيد من التقييم وتصنيف النتائج عبر عوامل مختلفة. لا تحتوي المراجع المقدمة على معلومات كافية لمعالجة جميع جوانب السؤال بشكل كامل.",
    "answer_French": "Sur la base des références fournies, voici quelques caractéristiques prévisibles qui peuvent influencer le comportement du modèle Microsoft/trocr-base-printed :\n\n1. Domaine et contexte : Le modèle est conçu pour la reconnaissance de textes imprimés. Il peut gérer des documents numérisés, des photos de documents, des photos de scènes ou des sous-titres superposés sur des images. Les performances du modèle peuvent varier en fonction du domaine spécifique et du contexte des images d'entrée.\n\n2. Caractéristiques du texte : les performances du modèle peuvent être influencées par diverses caractéristiques du texte telles que la police, la taille, l'espacement et la mise en page. [Plus d'informations nécessaires] sur la façon dont le modèle gère les différentes caractéristiques du texte et s'il existe des disparités dans les performances.\n\n3. Qualité de l'image : la qualité des images d'entrée, notamment la résolution, le contraste et le bruit, peut avoir un impact sur la précision de la reconnaissance de texte du modèle. [Plus d'informations nécessaires] sur les performances du modèle sur différents niveaux de qualité d'image et s'il existe des disparités de performances.\n\n4. Langue et écriture : le modèle peut être étendu pour la reconnaissance de texte multilingue en tirant parti de modèles multilingues pré-entraînés et en élargissant le dictionnaire. Cependant, [Plus d'informations nécessaires] sur les langages et scripts spécifiques pris en charge par le modèle Microsoft/trocr-base-printed et s'il existe des disparités de performances entre les différents langages ou scripts.\n\n5. Sous-groupes de population : [Plus d'informations nécessaires] sur les performances du modèle dans différents sous-groupes de population, tels que les données démographiques, les régions géographiques ou les facteurs socio-économiques. Idéalement, l’évaluation devrait être désagrégée pour révéler toute disparité potentielle en matière de performance.\n\nPour évaluer de manière exhaustive le comportement du modèle et identifier les éventuelles disparités, une évaluation plus approfondie et une ventilation des résultats selon divers facteurs seraient nécessaires. Les références fournies ne contiennent pas suffisamment d’informations pour aborder pleinement tous les aspects de la question.",
    "answer_Russian": "Основываясь на предоставленных ссылках, вот некоторые прогнозируемые характеристики, которые могут повлиять на поведение модели, напечатанной на базе Microsoft/trocr:\n\n1. Область применения и контекст. Модель предназначена для распознавания печатного текста. Он может обрабатывать отсканированные документы, фотографии документов, фотографии сцен или текст субтитров, наложенный на изображения. Производительность модели может варьироваться в зависимости от конкретной области и контекста входных изображений.\n\n2. Характеристики текста. На производительность модели могут влиять различные характеристики текста, такие как шрифт, размер, интервал и макет. [Требуется дополнительная информация] о том, как модель обрабатывает различные характеристики текста и есть ли различия в производительности.\n\n3. Качество изображения. Качество входных изображений, включая разрешение, контрастность и шум, может повлиять на точность распознавания текста модели. [Требуется дополнительная информация] о том, как модель работает на разных уровнях качества изображения и есть ли какие-либо различия в производительности.\n\n4. Язык и письмо. Модель можно расширить для распознавания многоязычного текста за счет использования предварительно обученных многоязычных моделей и расширения словаря. Однако [необходима дополнительная информация] о конкретных языках и сценариях, поддерживаемых моделью, напечатанной на базе microsoft/trocr, а также о наличии каких-либо различий в производительности между разными языками или сценариями.\n\n5. Подгруппы населения: [Необходима дополнительная информация] о том, как модель работает в различных подгруппах населения, таких как демография, географические регионы или социально-экономические факторы. В идеале оценка должна быть дезагрегированной, чтобы выявить любые потенциальные различия в производительности.\n\nЧтобы всесторонне оценить поведение модели и выявить любые различия, потребуется дальнейшая оценка и дезагрегирование результатов по различным факторам. Предоставленные ссылки не содержат достаточной информации для полного освещения всех аспектов вопроса.",
    "answer_Japanese": "提供された参考資料に基づいて、microsoft/trocr-base-printed モデルの動作に影響を与える可能性があるいくつかの予測可能な特性を次に示します。\n\n1. ドメインとコンテキスト: モデルは印刷されたテキスト認識用に設計されています。スキャンした文書、文書の写真、場面写真、または画像に重ねられた字幕テキストを扱うことができます。モデルのパフォーマンスは、入力画像の特定のドメインとコンテキストに応じて異なる場合があります。\n\n2. テキストの特性: モデルのパフォーマンスは、フォント、サイズ、間隔、レイアウトなどのさまざまなテキストの特性に影響される可能性があります。モデルがさまざまなテキスト特性をどのように処理するか、およびパフォーマンスに差異があるかどうかについては、[さらなる情報が必要]。\n\n3. 画質: 解像度、コントラスト、ノイズなどの入力画像の品質は、モデルのテキスト認識精度に影響を与える可能性があります。さまざまな画質レベルでモデルがどのようにパフォーマンスを発揮するか、またパフォーマンスに差異があるかどうかについて、[さらなる情報が必要]。\n\n4. 言語とスクリプト: 多言語の事前トレーニング済みモデルを活用し、辞書を拡張することで、モデルを多言語テキスト認識用に拡張できます。ただし、microsoft/trocr-base-printed モデルでサポートされている特定の言語とスクリプト、および異なる言語またはスクリプト間でパフォーマンスの差異がある場合は、[詳細情報が必要] です。\n\n5. 人口サブグループ: 人口動態、地理的地域、社会経済的要因など、さまざまな人口サブグループにわたってモデルがどのように機能するかに関する [さらなる情報が必要]。理想的には、評価を細分化してパフォーマンスの潜在的な差異を明らかにする必要があります。\n\nモデルの動作を包括的に評価し、差異を特定するには、さまざまな要素にわたる結果をさらに評価して細分化する必要があります。提供された参考文献には、質問のすべての側面に完全に対処するのに十分な情報が含まれていません。"
  },
  {
    "question": "testing_metrics",
    "chain": "generation",
    "answer": "Based on the references provided, the evaluation metrics for the microsoft/trocr-base-printed model would likely be:\n\nFor printed text datasets like IAM:\n- Case-sensitive Character Error Rate (CER)\n\nFor scene text datasets: \n- Word Accuracy, using a 36-character lowercase alphanumeric charset for fair comparison\n\n[More Information Needed] on the specific tradeoffs considered between different error types for this particular model. The references discuss metrics used for OCR models in general, but do not provide model-specific information about error tradeoffs for microsoft/trocr-base-printed.",
    "answer_Chinese": "根据提供的参考资料，microsoft/trocr-base-printed 模型的评估指标可能是：\n\n对于 IAM 等打印文本数据集：\n- 区分大小写的字符错误率 (CER)\n\n对于场景文本数据集： \n- 单词准确性，使用 36 个字符的小写字母数字字符集进行公平比较\n\n[需要更多信息]关于此特定模型的不同错误类型之间考虑的具体权衡。这些参考文献讨论了一般用于 OCR 模型的指标，但没有提供有关 microsoft/trocr-base-printed 的错误权衡的特定于模型的信息。",
    "answer_Arabic": "استنادًا إلى المراجع المقدمة، من المرجح أن تكون مقاييس التقييم للنموذج المطبوع من Microsoft/trocr-base:\n\nبالنسبة لمجموعات البيانات النصية المطبوعة مثل IAM:\n- معدل خطأ الأحرف الحساس لحالة الأحرف (CER)\n\nبالنسبة لمجموعات بيانات نص المشهد: \n- دقة الكلمات، باستخدام مجموعة أحرف أبجدية رقمية صغيرة مكونة من 36 حرفًا لإجراء مقارنة عادلة\n\n[مطلوب مزيد من المعلومات] حول المفاضلات المحددة التي يتم أخذها في الاعتبار بين أنواع الأخطاء المختلفة لهذا النموذج بالتحديد. تناقش المراجع المقاييس المستخدمة لنماذج التعرف الضوئي على الحروف بشكل عام، ولكنها لا توفر معلومات خاصة بالنموذج حول مفاضلات الأخطاء لـ Microsoft/trocr-base-printed.",
    "answer_French": "Sur la base des références fournies, les mesures d'évaluation du modèle imprimé Microsoft/Trocr seraient probablement :\n\nPour les ensembles de données de texte imprimé comme IAM :\n- Taux d'erreur de caractères sensibles à la casse (CER)\n\nPour les ensembles de données de texte de scène : \n- Précision des mots, utilisant un jeu de caractères alphanumériques minuscules de 36 caractères pour une comparaison équitable\n\n[Plus d'informations nécessaires] sur les compromis spécifiques pris en compte entre les différents types d'erreurs pour ce modèle particulier. Les références traitent des métriques utilisées pour les modèles OCR en général, mais ne fournissent pas d'informations spécifiques au modèle sur les compromis d'erreur pour Microsoft/trocr-base-printed.",
    "answer_Russian": "Основываясь на предоставленных ссылках, оценочные показатели для модели, напечатанной на базе Microsoft/trocr, вероятно, будут следующими:\n\nДля наборов печатных текстовых данных, таких как IAM:\n- Частота ошибок символов с учетом регистра (CER)\n\nДля наборов текстовых данных сцены: \n- Точность слова: для объективного сравнения используется 36-значная строчная буквенно-цифровая кодировка.\n\n[Требуется дополнительная информация] о конкретных компромиссах, рассматриваемых между различными типами ошибок для этой конкретной модели. В ссылках обсуждаются метрики, используемые для моделей OCR в целом, но не предоставляется специфичная для модели информация о компромиссах по ошибкам для печати на базе Microsoft/trocr.",
    "answer_Japanese": "提供されている参考資料に基づくと、microsoft/trocr-base-printed モデルの評価指標は次のようになります。\n\nIAM などの印刷されたテキスト データセットの場合:\n- 大文字と小文字を区別する文字エラー率 (CER)\n\nシーン テキスト データセットの場合: \n- 単語の精度。公正な比較のために 36 文字の小文字の英数字の文字セットを使用します。\n\nこの特定のモデルのさまざまなエラー タイプ間で考慮される特定のトレードオフに関する [追加情報が必要]。参考資料では、OCR モデルに使用されるメトリクス全般について説明していますが、microsoft/trocr-base-printed のエラー トレードオフに関するモデル固有の情報は提供されていません。"
  },
  {
    "question": "results",
    "chain": "generation",
    "answer": "Here are the evaluation results for the microsoft/trocr-base-printed model based on the provided references:\n\nModel Architecture:\n- Encoder: BEiT BASE \n- Decoder: RoBERTa LARGE\n- Total parameters: 334M\n\nThe TrOCR BASE model consists of the BEiT BASE encoder and the RoBERTa LARGE decoder.\n\nPerformance:\nThe TrOCR models outperform existing SOTA models on printed text recognition tasks. Specifically:\n\n- TrOCR models achieve state-of-the-art results on the leaderboard of the SROIE dataset compared to CNN-based methods for visual feature extraction and RNN-based methods for language modeling.\n\n- Transformer-based TrOCR models are competitive with CNN-based networks for visual feature extraction and RNN-based networks for language modeling on printed text recognition without complex pre/post-processing.\n\nInference Speed:\n[More Information Needed]\n\nThe references do not provide specific inference speed metrics for the microsoft/trocr-base-printed model. More information would be needed to report inference speed.\n\nData and Fine-tuning:\n- The TrOCR model can be pre-trained on large-scale synthetic data and fine-tuned on human-labeled datasets for downstream text recognition tasks.\n\n- Fine-tuning is performed for printed text recognition tasks.\n\n- Outputs are based on Byte Pair Encoding (BPE) and SentencePiece tokenization, and do not rely on task-specific vocabularies.",
    "answer_Chinese": "以下是根据提供的参考资料对 microsoft/trocr-base-printed 模型的评估结果：\n\n模型架构：\n- 编码器：BEiT BASE \n- 解码器：RoBERTa LARGE\n- 总参数：334M\n\nTrOCR BASE 模型由 BEiT BASE 编码器和 RoBERTa LARGE 解码器组成。\n\n表现：\nTrOCR 模型在印刷文本识别任务上优于现有的 SOTA 模型。具体来说：\n\n- 与基于 CNN 的视觉特征提取方法和基于 RNN 的语言建模方法相比，TrOCR 模型在 SROIE 数据集的排行榜上取得了最先进的结果。\n\n- 基于 Transformer 的 TrOCR 模型与基于 CNN 的视觉特征提取网络和基于 RNN 的网络竞争，用于印刷文本识别的语言建模，无需复杂的预处理/后处理。\n\n推理速度：\n[需要更多信息]\n\n这些参考文献没有提供 microsoft/trocr-base-printed 模型的具体推理速度指标。需要更多信息来报告推理速度。\n\n数据和微调：\n- TrOCR 模型可以针对大规模合成数据进行预训练，并针对下游文本识别任务的人工标记数据集进行微调。\n\n- 针对打印文本识别任务进行微调。\n\n- 输出基于字节对编码 (BPE) 和 SentencePiece 标记化，并且不依赖于特定于任务的词汇表。",
    "answer_Arabic": "فيما يلي نتائج التقييم للنموذج المطبوع من Microsoft/trocr-base بناءً على المراجع المتوفرة:\n\nالعمارة النموذجية:\n- التشفير: BEiT BASE \n- وحدة فك التشفير: RoBERTa LARGE\n- إجمالي المعلمات: 334 م\n\nيتكون نموذج TrOCR BASE من جهاز التشفير BEiT BASE وجهاز فك التشفير RoBERTa LARGE.\n\nأداء:\nتتفوق نماذج TrOCR على نماذج SOTA الموجودة في مهام التعرف على النص المطبوع. خاصة:\n\n- تحقق نماذج TrOCR أحدث النتائج على لوحة المتصدرين لمجموعة بيانات SROIE مقارنة بالطرق المستندة إلى CNN لاستخراج الميزات المرئية والأساليب المستندة إلى RNN لنمذجة اللغة.\n\n- نماذج TrOCR القائمة على المحولات قادرة على المنافسة مع الشبكات المستندة إلى CNN لاستخراج الميزات المرئية والشبكات المستندة إلى RNN لنمذجة اللغة عند التعرف على النص المطبوع دون معالجة مسبقة/لاحقة معقدة.\n\nسرعة الاستدلال:\n[مطلوب مزيد من المعلومات]\n\nلا توفر المراجع مقاييس محددة لسرعة الاستدلال للنموذج المطبوع من Microsoft/trocr-base. ستكون هناك حاجة إلى مزيد من المعلومات للإبلاغ عن سرعة الاستدلال.\n\nالبيانات والضبط الدقيق:\n- يمكن تدريب نموذج TrOCR مسبقًا على البيانات الاصطناعية واسعة النطاق وضبطه بشكل دقيق على مجموعات البيانات التي تحمل علامات بشرية لمهام التعرف على النص النهائية.\n\n- يتم إجراء الضبط الدقيق لمهام التعرف على النص المطبوع.\n\n- تعتمد المخرجات على تشفير زوج البايت (BPE) والترميز SentencePiece، ولا تعتمد على مفردات خاصة بالمهمة.",
    "answer_French": "Voici les résultats de l’évaluation du modèle Microsoft/trocr-base-printed basés sur les références fournies :\n\nArchitecture du modèle :\n- Encodeur : BEiT BASE \n- Décodeur : RoBERTa LARGE\n- Paramètres totaux : 334M\n\nLe modèle TrOCR BASE se compose de l'encodeur BEiT BASE et du décodeur RoBERTa LARGE.\n\nPerformance:\nLes modèles TrOCR surpassent les modèles SOTA existants sur les tâches de reconnaissance de texte imprimé. Spécifiquement:\n\n- Les modèles TrOCR obtiennent des résultats de pointe dans le classement de l'ensemble de données SROIE par rapport aux méthodes basées sur CNN pour l'extraction de caractéristiques visuelles et aux méthodes basées sur RNN pour la modélisation du langage.\n\n- Les modèles TrOCR basés sur des transformateurs sont compétitifs avec les réseaux basés sur CNN pour l'extraction de caractéristiques visuelles et les réseaux basés sur RNN pour la modélisation du langage sur la reconnaissance de texte imprimé sans pré/post-traitement complexe.\n\nVitesse d'inférence :\n[Plus d'informations nécessaires]\n\nLes références ne fournissent pas de mesures de vitesse d’inférence spécifiques pour le modèle imprimé Microsoft/Trocr-base. Plus d’informations seraient nécessaires pour signaler la vitesse d’inférence.\n\nDonnées et mise au point :\n- Le modèle TrOCR peut être pré-entraîné sur des données synthétiques à grande échelle et affiné sur des ensembles de données étiquetés par l'homme pour les tâches de reconnaissance de texte en aval.\n\n- Un réglage fin est effectué pour les tâches de reconnaissance de texte imprimé.\n\n- Les sorties sont basées sur la tokenisation Byte Pair Encoding (BPE) et SentencePièce, et ne reposent pas sur des vocabulaires spécifiques à une tâche.",
    "answer_Russian": "Вот результаты оценки модели, напечатанной на базе microsoft/trocr, на основе предоставленных ссылок:\n\nМодельная архитектура:\n- Кодировщик: BEiT BASE \n- Декодер: ROBERTa LARGE\n- Общие параметры: 334M\n\nМодель TrOCR BASE состоит из кодера BEiT BASE и декодера RoBERTa LARGE.\n\nПроизводительность:\nМодели TrOCR превосходят существующие модели SOTA в задачах распознавания печатного текста. Конкретно:\n\n- Модели TrOCR достигают самых современных результатов в таблице лидеров набора данных SROIE по сравнению с методами на основе CNN для извлечения визуальных признаков и методами на основе RNN для языкового моделирования.\n\n- Модели TrOCR на основе трансформаторов конкурируют с сетями на основе CNN для извлечения визуальных признаков и сетями на основе RNN для языкового моделирования при распознавании печатного текста без сложной предварительной/постобработки.\n\nСкорость вывода:\n[Требуется дополнительная информация]\n\nВ ссылках не указаны конкретные показатели скорости вывода для модели, напечатанной на базе Microsoft/trocr. Чтобы сообщить о скорости вывода, потребуется больше информации.\n\nДанные и точная настройка:\n- Модель TrOCR может быть предварительно обучена на крупномасштабных синтетических данных и точно настроена на наборах данных, размеченных человеком, для последующих задач распознавания текста.\n\n- Выполняется тонкая настройка для задач распознавания печатного текста.\n\n— Выходные данные основаны на кодировании пар байтов (BPE) и токенизации SentencePiece и не полагаются на словари для конкретных задач.",
    "answer_Japanese": "提供された参考資料に基づく、microsoft/trocr-base-printed モデルの評価結果は次のとおりです。\n\nモデルのアーキテクチャ:\n- エンコーダー：BEiT BASE \n- デコーダー: RoBERTa LARGE\n- 総パラメータ: 334M\n\nTrOCR BASE モデルは、BEiT BASE エンコーダーと RoBERTa LARGE デコーダーで構成されます。\n\nパフォーマンス：\nTrOCR モデルは、印刷されたテキスト認識タスクにおいて既存の SOTA モデルよりも優れたパフォーマンスを発揮します。具体的には：\n\n- TrOCR モデルは、視覚特徴抽出のための CNN ベースの手法や言語モデリングのための RNN ベースの手法と比較して、SROIE データセットのリーダーボードで最先端の結果を達成します。\n\n- トランスフォーマーベースの TrOCR モデルは、複雑な前処理/後処理を必要としない、視覚的特徴抽出では CNN ベースのネットワーク、印刷テキスト認識の言語モデリングでは RNN ベースのネットワークと競合します。\n\n推論速度:\n[さらに詳しい情報が必要です]\n\nリファレンスでは、microsoft/trocr-base-printed モデルの特定の推論速度メトリクスは提供されていません。推論速度をレポートするには、より多くの情報が必要になります。\n\nデータと微調整:\n- TrOCR モデルは、大規模な合成データで事前トレーニングし、下流のテキスト認識タスクのために人間がラベル付けしたデータセットで微調整できます。\n\n- 印刷されたテキスト認識タスクの微調整が実行されます。\n\n- 出力はバイト ペア エンコーディング (BPE) と SentencePiece トークン化に基づいており、タスク固有の語彙には依存しません。"
  },
  {
    "question": "results_summary",
    "chain": "generation",
    "answer": "Based on the provided references, here is a summary of the evaluation results for the microsoft/trocr-base-printed model:\n\nThe TrOCR base models, which include microsoft/trocr-base-printed, achieve competitive performance on printed text recognition tasks compared to existing state-of-the-art models. Key points:\n\n- TrOCR models outperform existing SOTA models with pure Transformer structures on the IAM Handwriting Database\n- TrOCR base models have fast inference speed, though not as fast as the small model\n- Combining TrOCR with pre-trained vision models like BEiT further improves text recognition performance\n\nThe TrOCR architecture uses a standard Transformer encoder-decoder setup without relying on convolutions or complex pre/post-processing. This makes the model simple yet effective.\n\n[More Information Needed] on the specific performance metrics (e.g. character error rate) for the microsoft/trocr-base-printed model on benchmark datasets. The references discuss TrOCR models in general but do not provide detailed results for this particular base printed model.",
    "answer_Chinese": "根据提供的参考资料，以下是 microsoft/trocr-base-printed 模型的评估结果摘要：\n\nTrOCR 基础模型（包括 microsoft/trocr-base-printed）与现有最先进的模型相比，在打印文本识别任务上实现了具有竞争力的性能。关键点：\n\n- TrOCR 模型在 IAM 手写数据库上优于现有的具有纯 Transformer 结构的 SOTA 模型\n- TrOCR 基础模型具有较快的推理速度，但不如小模型快\n- 将 TrOCR 与 BEiT 等预训练视觉模型相结合，进一步提高文本识别性能\n\nTrOCR 架构使用标准 Transformer 编码器-解码器设置，不依赖于卷积或复杂的前/后处理。这使得该模型简单而有效。\n\n[需要更多信息] 关于基准数据集上 microsoft/trocr-base-printed 模型的具体性能指标（例如字符错误率）。这些参考文献总体上讨论了 TrOCR 模型，但没有提供该特定基础打印模型的详细结果。",
    "answer_Arabic": "بناءً على المراجع المتوفرة، فيما يلي ملخص لنتائج التقييم للنموذج المطبوع من Microsoft/trocr-base:\n\nتحقق نماذج TrOCR الأساسية، والتي تتضمن طباعة microsoft/trocr-base، أداءً تنافسيًا في مهام التعرف على النص المطبوع مقارنة بالنماذج الحديثة الحالية. النقاط الرئيسية:\n\n- تتفوق نماذج TrOCR على نماذج SOTA الحالية مع هياكل المحولات النقية في قاعدة بيانات الكتابة اليدوية IAM\n- تتمتع النماذج الأساسية لـ TrOCR بسرعة استدلال عالية، ولكنها ليست بنفس سرعة النموذج الصغير\n- يؤدي الجمع بين TrOCR ونماذج الرؤية المدربة مسبقًا مثل BEiT إلى تحسين أداء التعرف على النص\n\nتستخدم بنية TrOCR إعدادًا قياسيًا لوحدة فك ترميز وتشفير Transformer دون الاعتماد على التلافيفات أو المعالجة المسبقة/اللاحقة المعقدة. وهذا يجعل النموذج بسيطًا ولكنه فعال.\n\n[مطلوب مزيد من المعلومات] حول مقاييس الأداء المحددة (على سبيل المثال، معدل خطأ الأحرف) للنموذج المطبوع من Microsoft/trocr-base على مجموعات البيانات المعيارية. تناقش المراجع نماذج TrOCR بشكل عام ولكنها لا تقدم نتائج مفصلة لهذا النموذج المطبوع الأساسي.",
    "answer_French": "Sur la base des références fournies, voici un résumé des résultats de l'évaluation du modèle Microsoft/trocr-base-printed :\n\nLes modèles de base TrOCR, qui incluent Microsoft/trocr-base-printed, atteignent des performances compétitives sur les tâches de reconnaissance de texte imprimé par rapport aux modèles de pointe existants. Points clés:\n\n- Les modèles TrOCR surpassent les modèles SOTA existants avec des structures Transformer pures sur la base de données d'écriture manuscrite IAM\n- Les modèles de base TrOCR ont une vitesse d'inférence rapide, mais pas aussi rapide que le petit modèle\n- La combinaison de TrOCR avec des modèles de vision pré-entraînés comme BEiT améliore encore les performances de reconnaissance de texte\n\nL'architecture TrOCR utilise une configuration standard d'encodeur-décodeur Transformer sans recourir à des convolutions ou à un pré/post-traitement complexe. Cela rend le modèle simple mais efficace.\n\n[Plus d'informations nécessaires] sur les mesures de performances spécifiques (par exemple, le taux d'erreur de caractère) pour le modèle imprimé sur la base de Microsoft/Trocr sur des ensembles de données de référence. Les références traitent des modèles TrOCR en général mais ne fournissent pas de résultats détaillés pour ce modèle imprimé de base particulier.",
    "answer_Russian": "На основании предоставленных ссылок ниже приводится сводка результатов оценки модели, напечатанной на базе microsoft/trocr:\n\nБазовые модели TrOCR, в том числе microsoft/trocr-base-printed, обеспечивают конкурентоспособную производительность в задачах распознавания печатного текста по сравнению с существующими современными моделями. Ключевые моменты:\n\n- Модели TrOCR превосходят существующие модели SOTA с чистыми структурами Transformer в базе данных рукописного ввода IAM.\n- Базовые модели TrOCR имеют высокую скорость вывода, хотя и не такую ​​быструю, как маленькая модель.\n- Сочетание TrOCR с предварительно обученными моделями машинного зрения, такими как BEiT, еще больше повышает производительность распознавания текста.\n\nАрхитектура TrOCR использует стандартную настройку кодера-декодера Transformer, не полагаясь на свертки или сложную пред-/постобработку. Это делает модель простой, но эффективной.\n\n[Требуется дополнительная информация] о конкретных показателях производительности (например, частоте ошибок в символах) для модели, напечатанной на базе Microsoft/trocr, на наборах эталонных данных. В ссылках обсуждаются модели TrOCR в целом, но не приводятся подробные результаты для этой конкретной базовой печатной модели.",
    "answer_Japanese": "提供された参考資料に基づいて、microsoft/trocr-base-printed モデルの評価結果の概要を次に示します。\n\nMicrosoft/trocr-base-printed を含む TrOCR ベース モデルは、印刷テキスト認識タスクにおいて、既存の最先端モデルと比較して優れたパフォーマンスを達成します。キーポイント：\n\n- TrOCR モデルは、IAM 手書きデータベース上の純粋な Transformer 構造を備えた既存の SOTA モデルよりも優れたパフォーマンスを発揮します\n- TroOCR ベース モデルは推論速度が速いですが、小型モデルほどではありません。\n- TrOCR と BEiT のような事前トレーニング済み視覚モデルを組み合わせることで、テキスト認識パフォーマンスがさらに向上します\n\nTrOCR アーキテクチャは、畳み込みや複雑な前処理/後処理に依存せずに、標準の Transformer エンコーダ/デコーダ設定を使用します。これにより、モデルはシンプルでありながら効果的になります。\n\nベンチマーク データセット上の Microsoft/trocr-base-printed モデルの特定のパフォーマンス メトリクス (文字エラー率など) に関する [詳細情報が必要]。参考文献では、TrOCR モデル全般について説明していますが、この特定の基本印刷モデルの詳細な結果は提供していません。"
  },
  {
    "question": "model_examination",
    "chain": "generation",
    "answer": "Here is a possible answer for the \"Explainability/Interpretability\" section of the model card for microsoft/trocr-base-printed:\n\nThe TrOCR model uses a Transformer architecture that takes advantage of pre-trained image and text Transformer models. This allows the model to learn from large-scale unlabeled data for both image understanding and language modeling, without requiring an external language model. \n\nThe model does not rely on any convolutional networks or introduce image-specific inductive biases, which makes the architecture simpler and easier to interpret compared to previous approaches like CRNN that used convolutional layers for feature extraction.\n\n[More Information Needed] on specific explainability/interpretability techniques that have been applied to analyze the TrOCR model's predictions and internal representations. Future work could explore methods to visualize attention weights, generate explanations for predictions, and probe what the model has learned. Comparing the interpretability of TrOCR to other text recognition models would also provide useful insights.\n\nThe model outputs are based on Byte Pair Encoding (BPE) and SentencePiece tokenization rather than a fixed character vocabulary. [More Information Needed] on how the choice of tokenization affects the interpretability of the model's text generation process.",
    "answer_Chinese": "以下是 microsoft/trocr-base-printed 模型卡的“可解释性/可解释性”部分的可能答案：\n\nTrOCR 模型使用 Transformer 架构，利用预先训练的图像和文本 Transformer 模型。这使得模型能够从大规模未标记数据中学习，以进行图像理解和语言建模，而无需外部语言模型。 \n\n该模型不依赖于任何卷积网络，也不引入特定于图像的归纳偏差，这使得与之前使用卷积层进行特征提取的 CRNN 等方法相比，该架构更简单且更易于解释。\n\n[需要更多信息]有关已应用于分析 TrOCR 模型的预测和内部表示的特定可解释性/可解释性技术。未来的工作可以探索可视化注意力权重的方法，生成预测解释，并探究模型学到了什么。将 TrOCR 的可解释性与其他文本识别模型进行比较也将提供有用的见解。\n\n模型输出基于字节对编码 (BPE) 和 SentencePiece 标记化，而不是固定字符词汇表。 [需要更多信息]关于标记化的选择如何影响模型文本生成过程的可解释性。",
    "answer_Arabic": "فيما يلي إجابة محتملة لقسم \"قابلية التفسير/قابلية التفسير\" في البطاقة النموذجية لـ microsoft/trocr-base-printed:\n\nيستخدم نموذج TrOCR بنية المحولات التي تستفيد من نماذج محولات الصور والنصوص المدربة مسبقًا. يتيح ذلك للنموذج التعلم من البيانات غير المسماة واسعة النطاق لفهم الصور ونمذجة اللغة، دون الحاجة إلى نموذج لغة خارجي. \n\nلا يعتمد النموذج على أي شبكات تلافيفية أو يقدم تحيزات استقرائية خاصة بالصورة، مما يجعل البنية أبسط وأسهل في التفسير مقارنة بالأساليب السابقة مثل CRNN التي استخدمت الطبقات التلافيفية لاستخراج الميزات.\n\n[بحاجة إلى مزيد من المعلومات] حول تقنيات الشرح/قابلية التفسير المحددة التي تم تطبيقها لتحليل تنبؤات نموذج TrOCR والتمثيلات الداخلية. يمكن للعمل المستقبلي استكشاف طرق لتصور أوزان الانتباه، وإنشاء تفسيرات للتنبؤات، واستكشاف ما تعلمه النموذج. من شأن مقارنة إمكانية تفسير TrOCR مع نماذج التعرف على النص الأخرى أن توفر أيضًا رؤى مفيدة.\n\nتعتمد مخرجات النموذج على ترميز زوج البايت (BPE) ورمز SentencePiece بدلاً من مفردات الأحرف الثابتة. [يلزم مزيد من المعلومات] حول كيفية تأثير اختيار الرمز المميز على إمكانية تفسير عملية إنشاء النص الخاصة بالنموذج.",
    "answer_French": "Voici une réponse possible pour la section « Explicabilité/Interprétabilité » de la carte modèle pour Microsoft/trocr-base-printed :\n\nLe modèle TrOCR utilise une architecture Transformer qui tire parti des modèles Transformer d'image et de texte pré-entraînés. Cela permet au modèle d'apprendre à partir de données non étiquetées à grande échelle pour la compréhension des images et la modélisation du langage, sans nécessiter de modèle de langage externe. \n\nLe modèle ne repose sur aucun réseau convolutif et n'introduit pas de biais inductifs spécifiques à l'image, ce qui rend l'architecture plus simple et plus facile à interpréter par rapport aux approches précédentes comme le CRNN qui utilisaient des couches convolutives pour l'extraction de caractéristiques.\n\n[Plus d'informations nécessaires] sur les techniques d'explicabilité/interprétabilité spécifiques qui ont été appliquées pour analyser les prédictions et les représentations internes du modèle TrOCR. Des travaux futurs pourraient explorer des méthodes permettant de visualiser les poids d’attention, de générer des explications pour les prédictions et de sonder ce que le modèle a appris. Comparer l’interprétabilité de TrOCR à d’autres modèles de reconnaissance de texte fournirait également des informations utiles.\n\nLes sorties du modèle sont basées sur la tokenisation Byte Pair Encoding (BPE) et SentencePièce plutôt que sur un vocabulaire de caractères fixe. [Plus d'informations nécessaires] sur la manière dont le choix de la tokenisation affecte l'interprétabilité du processus de génération de texte du modèle.",
    "answer_Russian": "Вот возможный ответ для раздела «Объяснимость/интерпретируемость» карты модели для печати на базе microsoft/trocr:\n\nМодель TrOCR использует архитектуру Transformer, которая использует преимущества предварительно обученных моделей Transformer изображений и текста. Это позволяет модели учиться на крупномасштабных неразмеченных данных как для понимания изображений, так и для моделирования языка, не требуя внешней языковой модели. \n\nМодель не полагается на какие-либо сверточные сети и не вводит индуктивные смещения, специфичные для изображения, что делает архитектуру более простой и легкой для интерпретации по сравнению с предыдущими подходами, такими как CRNN, которые использовали сверточные слои для извлечения признаков.\n\n[Требуется дополнительная информация] о конкретных методах объяснимости/интерпретируемости, которые применялись для анализа прогнозов и внутренних представлений модели TrOCR. Будущая работа может изучить методы визуализации весов внимания, создания объяснений прогнозов и проверки того, чему научилась модель. Сравнение интерпретируемости TrOCR с другими моделями распознавания текста также даст полезную информацию.\n\nВыходные данные модели основаны на кодировании пар байтов (BPE) и токенизации SentencePiece, а не на словаре фиксированных символов. [Требуется дополнительная информация] о том, как выбор токенизации влияет на интерпретируемость процесса генерации текста модели.",
    "answer_Japanese": "以下は、microsoft/trocr-base-printed のモデル カードの「説明可能性/解釈可能性」セクションに対する考えられる回答です。\n\nTrOCR モデルは、事前トレーニングされた画像とテキストの Transformer モデルを活用する Transformer アーキテクチャを使用します。これにより、モデルは、外部言語モデルを必要とせずに、画像理解と言語モデリングの両方のために大規模なラベルなしデータから学習することができます。 \n\nこのモデルは、畳み込みネットワークに依存したり、画像固有の誘導バイアスを導入したりしないため、特徴抽出に畳み込み層を使用した CRNN などの以前のアプローチと比較して、アーキテクチャがシンプルで解釈しやすくなっています。\n\nTrOCR モデルの予測と内部表現を分析するために適用された特定の説明可能性/解釈可能性の手法に関する [さらなる情報が必要]。今後の研究では、注意の重みを視覚化し、予測の説明を生成し、モデルが学習した内容を調査する方法を検討する可能性があります。 TrOCR の解釈可能性を他のテキスト認識モデルと比較することも、有益な洞察を提供するでしょう。\n\nモデルの出力は、固定文字語彙ではなく、バイト ペア エンコーディング (BPE) と SentencePiece トークン化に基づいています。トークン化の選択がモデルのテキスト生成プロセスの解釈可能性にどのような影響を与えるかについては、[さらなる情報が必要です]。"
  },
  {
    "question": "hardware",
    "chain": "generation",
    "answer": "The model microsoft/trocr-base-printed is trained on 8 V100 GPUs for fine-tuning, as mentioned in the references:\n\n\"We use 32 V100 GPUs with the memory of 32GBs for pre-training and 8 V100 GPUs for fine-tuning.\"",
    "answer_Chinese": "模型 microsoft/trocr-base-printed 在 8 个 V100 GPU 上进行训练以进行微调，如参考文献中所述：\n\n“我们使用 32 个内存为 32GB 的 V100 GPU 进行预训练，并使用 8 个 V100 GPU 进行微调。”",
    "answer_Arabic": "تم تدريب نموذج microsoft/trocr-base-printed على 8 وحدات معالجة رسوميات V100 للضبط الدقيق، كما هو مذكور في المراجع:\n\n\"نحن نستخدم 32 وحدة معالجة رسوميات V100 مع ذاكرة تبلغ 32 جيجابايت للتدريب المسبق و8 وحدات معالجة رسوميات V100 للضبط الدقيق.\"",
    "answer_French": "Le modèle microsoft/trocr-base-printed est entraîné sur 8 GPU V100 pour un réglage fin, comme mentionné dans les références :\n\n\"Nous utilisons 32 GPU V100 avec une mémoire de 32 Go pour le pré-entraînement et 8 GPU V100 pour le réglage fin.\"",
    "answer_Russian": "Модель microsoft/trocr-base-printed обучена на 8 графических процессорах V100 для тонкой настройки, как указано в ссылках:\n\n«Мы используем 32 графических процессора V100 с памятью 32 ГБ для предварительного обучения и 8 графических процессоров V100 для точной настройки».",
    "answer_Japanese": "モデル Microsoft/trocr-base-printed は、参考文献に記載されているように、微調整のために 8 つの V100 GPU でトレーニングされています。\n\n「事前トレーニングには 32 GB のメモリを備えた 32 個の V100 GPU を使用し、微調整には 8 個の V100 GPU を使用します。」"
  },
  {
    "question": "software",
    "chain": "generation",
    "answer": "The TrOCR models, including microsoft/trocr-base-printed, are built upon the Fairseq toolkit according to Reference 2:\n\n\"The TrOCR models are built upon the Fairseq (Ott et al. 2019) which is a popular sequence modeling toolkit.\"\n\nSo the software type that the model microsoft/trocr-base-printed is trained on is Fairseq.",
    "answer_Chinese": "TrOCR 模型（包括 microsoft/trocr-base-printed）是根据参考文献 2 基于 Fairseq 工具包构建的：\n\n“TrOCR 模型基于 Fairseq（Ott 等人，2019 年）构建，这是一种流行的序列建模工具包。”\n\n因此模型 microsoft/trocr-base-printed 训练的软件类型是 Fairseq。",
    "answer_Arabic": "تم تصميم نماذج TrOCR، بما في ذلك microsoft/trocr-base-printed، بناءً على مجموعة أدوات Fairseq وفقًا للمرجع 2:\n\n\"تم بناء نماذج TrOCR على Fairseq (Ott et al. 2019) وهي مجموعة أدوات شائعة لنمذجة التسلسل.\"\n\nلذا فإن نوع البرنامج الذي تم تدريب نموذج Microsoft/trocr-base-printed عليه هو Fairseq.",
    "answer_French": "Les modèles TrOCR, y compris Microsoft/trocr-base-printed, sont construits sur la boîte à outils Fairseq selon la référence 2 :\n\n\"Les modèles TrOCR sont construits sur Fairseq (Ott et al. 2019), qui est une boîte à outils de modélisation de séquences populaire.\"\n\nAinsi, le type de logiciel sur lequel le modèle Microsoft/trocr-base-printed est formé est Fairseq.",
    "answer_Russian": "Модели TrOCR, в том числе напечатанные на базе microsoft/trocr, построены на основе набора инструментов Fairseq в соответствии со ссылкой 2:\n\n«Модели TrOCR построены на основе Fairseq (Отт и др., 2019), который является популярным набором инструментов для моделирования последовательностей».\n\nТаким образом, тип программного обеспечения, на котором обучается модель microsoft/trocr-base-printed, — это Fairseq.",
    "answer_Japanese": "Microsoft/trocr-base-printed を含む TrOCR モデルは、参考資料 2 に従って Fairseq ツールキットに基づいて構築されています。\n\n「TrOCR モデルは、人気のあるシーケンス モデリング ツールキットである Fairseq (Ott et al. 2019) に基づいて構築されています。」\n\nしたがって、モデルmicrosoft/trocr-base-printedがトレーニングされるソフトウェアの種類はFairseqです。"
  },
  {
    "question": "hours_used",
    "chain": "generation",
    "answer": "Based on the provided references, there is no specific information about the amount of time used to train the microsoft/trocr-base-printed model. The references mention using 32 V100 GPUs for pre-training and 8 V100 GPUs for fine-tuning, but do not specify the duration of training.\n\n[More Information Needed] on the exact training time for the microsoft/trocr-base-printed model.",
    "answer_Chinese": "根据提供的参考资料，没有关于训练 microsoft/trocr-base-printed 模型所用时间的具体信息。参考文献提到使用 32 个 V100 GPU 进行预训练，使用 8 个 V100 GPU 进行微调，但没有具体说明训练的持续时间。\n\n[需要更多信息] 关于 microsoft/trocr-base-printed 模型的确切训练时间。",
    "answer_Arabic": "استنادًا إلى المراجع المتوفرة، لا توجد معلومات محددة حول مقدار الوقت المستخدم لتدريب النموذج المطبوع من Microsoft/trocr-base. تشير المراجع إلى استخدام 32 وحدة معالجة رسوميات V100 للتدريب المسبق و8 وحدات معالجة رسوميات V100 للضبط الدقيق، ولكنها لم تحدد مدة التدريب.\n\n[يلزم مزيد من المعلومات] حول وقت التدريب الدقيق للنموذج المطبوع من Microsoft/trocr-base.",
    "answer_French": "Sur la base des références fournies, il n’existe aucune information spécifique sur le temps nécessaire à la formation du modèle Microsoft/trocr-base-printed. Les références mentionnent l'utilisation de 32 GPU V100 pour le pré-entraînement et de 8 GPU V100 pour le réglage fin, mais ne précisent pas la durée de la formation.\n\n[Plus d'informations nécessaires] sur le temps de formation exact pour le modèle imprimé Microsoft/Trocr-base.",
    "answer_Russian": "Судя по предоставленным ссылкам, нет конкретной информации о количестве времени, затраченном на обучение модели, напечатанной на базе Microsoft/trocr. В ссылках упоминается использование 32 графических процессоров V100 для предварительного обучения и 8 графических процессоров V100 для точной настройки, но не указывается продолжительность обучения.\n\n[Требуется дополнительная информация] о точном времени обучения для модели, напечатанной на базе Microsoft/trocr.",
    "answer_Japanese": "提供されている参考資料に基づくと、microsoft/trocr-base-printed モデルのトレーニングにかかる​​時間に関する具体的な情報はありません。参考資料には、事前トレーニングに 32 個の V100 GPU を使用し、微調整に 8 個の V100 GPU を使用することが記載されていますが、トレーニングの期間は指定されていません。\n\nMicrosoft/trocr-base-printed モデルの正確なトレーニング時間に関する [詳細情報が必要]。"
  },
  {
    "question": "cloud_provider",
    "chain": "generation",
    "answer": "[More Information Needed]\n\nThe provided references do not mention the specific cloud provider used for training the microsoft/trocr-base-printed model. They only state that \"We use 32 V100 GPUs with the memory of 32GBs for pre-training and 8 V100\" GPUs, but do not specify the cloud provider those GPUs are from.",
    "answer_Chinese": "[需要更多信息]\n\n提供的参考文献没有提及用于训练 microsoft/trocr-base-printed 模型的特定云提供商。他们只表示“我们使用32个V100 GPU，内存为32GB用于预训练和8个V100”GPU，但没有具体说明这些GPU来自云提供商。",
    "answer_Arabic": "[مطلوب مزيد من المعلومات]\n\nلا تذكر المراجع المقدمة موفر السحابة المحدد المستخدم لتدريب النموذج المطبوع من Microsoft/trocr-base. ينصون فقط على أننا \"نستخدم 32 وحدة معالجة رسوميات V100 بذاكرة 32 جيجابايت للتدريب المسبق و8 وحدات معالجة رسوميات V100\"، لكنهم لا يحددون موفر السحابة الذي تنتمي إليه وحدات معالجة الرسومات هذه.",
    "answer_French": "[Plus d'informations nécessaires]\n\nLes références fournies ne mentionnent pas le fournisseur de cloud spécifique utilisé pour former le modèle imprimé Microsoft/trocr-base-print. Ils indiquent seulement que \"Nous utilisons 32 GPU V100 avec une mémoire de 32 Go pour le pré-entraînement et 8 GPU V100\", mais ne précisent pas le fournisseur de cloud dont proviennent ces GPU.",
    "answer_Russian": "[Требуется дополнительная информация]\n\nВ предоставленных ссылках не упоминается конкретный поставщик облачных услуг, используемый для обучения модели, напечатанной на базе Microsoft/trocr. Они только заявляют, что «мы используем 32 графических процессора V100 с памятью 32 ГБ для предварительного обучения и 8 графических процессоров V100», но не указывают облачного провайдера, от которого получены эти графические процессоры.",
    "answer_Japanese": "[さらに詳しい情報が必要です]\n\n提供されている参考資料には、microsoft/trocr-base-printed モデルのトレーニングに使用される特定のクラウド プロバイダーについては言及されていません。 「事前トレーニング用に 32GB のメモリを備えた 32 個の V100 GPU と 8 個の V100」GPU を使用しているとだけ述べられており、それらの GPU が提供されているクラウド プロバイダーは特定されていません。"
  },
  {
    "question": "co2_emitted",
    "chain": "generation",
    "answer": "[More Information Needed]\n\nThe provided references do not contain any information about the amount of carbon emitted during the training of the microsoft/trocr-base-printed model. To answer this question, more specific details would be needed, such as the computing resources used for training, the duration of the training process, and the energy consumption of the hardware. Without these details, it is not possible to estimate the carbon emissions associated with training this particular model.",
    "answer_Chinese": "[需要更多信息]\n\n提供的参考文献不包含有关 microsoft/trocr-base-printed 模型训练期间碳排放量的任何信息。要回答这个问题，需要更具体的细节，例如用于训练的计算资源、训练过程的持续时间以及硬件的能耗。如果没有这些详细信息，就不可能估计与训练该特定模型相关的碳排放量。",
    "answer_Arabic": "[مطلوب مزيد من المعلومات]\n\nلا تحتوي المراجع المقدمة على أي معلومات حول كمية الكربون المنبعثة أثناء التدريب على النموذج المطبوع من Microsoft/trocr-base. للإجابة على هذا السؤال، ستكون هناك حاجة إلى تفاصيل أكثر تحديدًا، مثل موارد الحوسبة المستخدمة للتدريب، ومدة عملية التدريب، واستهلاك الأجهزة للطاقة. وبدون هذه التفاصيل، لا يمكن تقدير انبعاثات الكربون المرتبطة بتدريب هذا النموذج بالتحديد.",
    "answer_French": "[Plus d'informations nécessaires]\n\nLes références fournies ne contiennent aucune information sur la quantité de carbone émise lors de la formation du modèle imprimé Microsoft/trocr-base. Pour répondre à cette question, des détails plus précis seraient nécessaires, tels que les ressources informatiques utilisées pour la formation, la durée du processus de formation et la consommation énergétique du matériel. Sans ces détails, il n'est pas possible d'estimer les émissions de carbone associées à la formation de ce modèle particulier.",
    "answer_Russian": "[Требуется дополнительная информация]\n\nПредоставленные ссылки не содержат никакой информации о количестве углерода, выделяемого во время обучения модели, напечатанной на базе Microsoft/trocr. Чтобы ответить на этот вопрос, потребуются более конкретные детали, такие как вычислительные ресурсы, используемые для обучения, продолжительность процесса обучения и энергопотребление оборудования. Без этих деталей невозможно оценить выбросы углерода, связанные с обучением этой конкретной модели.",
    "answer_Japanese": "[さらに詳しい情報が必要です]\n\n提供されている参考資料には、microsoft/trocr-base-printed モデルのトレーニング中に排出される炭素の量に関する情報は含まれていません。この質問に答えるには、トレーニングに使用されるコンピューティング リソース、トレーニング プロセスの期間、ハードウェアのエネルギー消費など、より具体的な詳細が必要になります。これらの詳細がなければ、この特定のモデルのトレーニングに関連する炭素排出量を推定することはできません。"
  },
  {
    "question": "model_specs",
    "chain": "generation",
    "answer": "Model Architecture:\nTrOCR is built with the Transformer encoder-decoder architecture. The encoder is an image Transformer that extracts visual features from the input image, which is resized to 384x384 and split into a sequence of 16x16 patches. The decoder is a standard text Transformer for generating the wordpiece sequence, guided by the visual features and previous predictions.\n\nThe encoder is initialized with pre-trained models like DeiT (Touvron et al. 2021) and BEiT (Bao, Dong, and Wei 2021). [More Information Needed] on the specific pre-trained model used for microsoft/trocr-base-printed.\n\nThe decoder leverages pre-trained language models. [More Information Needed] on the specific pre-trained language model used in the decoder of microsoft/trocr-base-printed.\n\nObjective:\nTrOCR is an end-to-end text recognition approach that aims to recognize and transcribe text from images. It leverages pre-trained image Transformer and text Transformer models to jointly learn visual understanding and wordpiece-level text generation.\n\nThe model can be pre-trained on large-scale synthetic data and fine-tuned on human-labeled datasets for specific text recognition tasks such as printed, handwritten, and scene text recognition.\n\nTrOCR aims to achieve state-of-the-art performance on various OCR benchmark datasets without relying on complex pre/post-processing steps. It can also be easily extended to multilingual text recognition by using multilingual pre-trained models in the decoder and expanding the dictionary.",
    "answer_Chinese": "模型架构：\nTrOCR 采用 Transformer 编码器-解码器架构构建。编码器是一个图像 Transformer，它从输入图像中提取视觉特征，该图像大小调整为 384x384 并分割成一系列 16x16 的 patch。解码器是一个标准文本转换器，用于在视觉特征和先前预测的指导下生成单词序列。\n\n编码器使用 DeiT (Touvron et al. 2021) 和 BEiT (Bao, Dong, and Wei 2021) 等预训练模型进行初始化。 [需要更多信息] 有关用于 microsoft/trocr-base-printed 的特定预训练模型。\n\n解码器利用预先训练的语言模型。 [需要更多信息]关于 microsoft/trocr-base-printed 解码器中使用的特定预训练语言模型。\n\n客观的：\nTrOCR 是一种端到端文本识别方法，旨在从图像中识别和转录文本。它利用预先训练的图像 Transformer 和文本 Transformer 模型来共同学习视觉理解和单词级文本生成。\n\n该模型可以在大规模合成数据上进行预训练，并在人工标记的数据集上进行微调，以执行特定的文本识别任务，例如打印、手写和场景文本识别。\n\nTrOCR 旨在在各种 OCR 基准数据集上实现最先进的性能，而不依赖于复杂的预处理/后处理步骤。通过在解码器中使用多语言预训练模型并扩展字典，它还可以轻松扩展到多语言文本识别。",
    "answer_Arabic": "العمارة النموذجية:\nتم تصميم TrOCR باستخدام بنية وحدة فك ترميز وتشفير Transformer. برنامج التشفير عبارة عن محول صور يستخرج الميزات المرئية من الصورة المدخلة، والتي يتم تغيير حجمها إلى 384 × 384 وتقسيمها إلى سلسلة من تصحيحات 16 × 16. وحدة فك التشفير عبارة عن محول نصي قياسي لإنشاء تسلسل الكلمات، مسترشدًا بالميزات المرئية والتنبؤات السابقة.\n\nتتم تهيئة برنامج التشفير باستخدام نماذج مدربة مسبقًا مثل DeiT (Touvron et al. 2021) وBEiT (Bao وDong وWei 2021). [يلزم مزيد من المعلومات] حول النموذج المحدد الذي تم تدريبه مسبقًا والمستخدم لطباعة Microsoft/trocr-base.\n\nيستفيد جهاز فك التشفير من نماذج اللغة المدربة مسبقًا. [يلزم مزيد من المعلومات] حول نموذج اللغة المحدد الذي تم تدريبه مسبقًا والمستخدم في وحدة فك ترميز Microsoft/trocr-base-printed.\n\nموضوعي:\nTrOCR هو أسلوب شامل للتعرف على النص يهدف إلى التعرف على النص ونسخه من الصور. إنه يستفيد من نماذج محولات الصور ومحولات النصوص المدربة مسبقًا للتعلم بشكل مشترك الفهم البصري وإنشاء النص على مستوى الكلمة.\n\nيمكن تدريب النموذج مسبقًا على البيانات الاصطناعية واسعة النطاق وضبطه بدقة على مجموعات البيانات التي تحمل علامات بشرية لمهام محددة للتعرف على النص مثل التعرف على النصوص المطبوعة والمكتوبة بخط اليد والمشهد.\n\nيهدف TrOCR إلى تحقيق أداء متطور في مختلف مجموعات البيانات المعيارية للتعرف الضوئي على الحروف (OCR) دون الاعتماد على خطوات ما قبل/ما بعد المعالجة المعقدة. ويمكن أيضًا توسيعه بسهولة ليشمل التعرف على النص متعدد اللغات باستخدام نماذج متعددة اللغات مدربة مسبقًا في وحدة فك التشفير وتوسيع القاموس.",
    "answer_French": "Architecture du modèle :\nTrOCR est construit avec l'architecture encodeur-décodeur Transformer. L'encodeur est un transformateur d'image qui extrait les caractéristiques visuelles de l'image d'entrée, qui est redimensionnée à 384 x 384 et divisée en une séquence de 16 x 16 patchs. Le décodeur est un transformateur de texte standard permettant de générer la séquence de mots, guidé par les caractéristiques visuelles et les prédictions précédentes.\n\nL'encodeur est initialisé avec des modèles pré-entraînés comme DeiT (Touvron et al. 2021) et BEiT (Bao, Dong et Wei 2021). [Plus d'informations nécessaires] sur le modèle pré-entraîné spécifique utilisé pour Microsoft/trocr-base-printed.\n\nLe décodeur exploite des modèles de langage pré-entraînés. [Plus d'informations nécessaires] sur le modèle de langage pré-entraîné spécifique utilisé dans le décodeur de Microsoft/trocr-base-printed.\n\nObjectif:\nTrOCR est une approche de reconnaissance de texte de bout en bout qui vise à reconnaître et transcrire du texte à partir d'images. Il exploite des modèles de transformateur d'image et de texte pré-entraînés pour apprendre conjointement la compréhension visuelle et la génération de texte au niveau des mots.\n\nLe modèle peut être pré-entraîné sur des données synthétiques à grande échelle et affiné sur des ensembles de données étiquetés par l'homme pour des tâches de reconnaissance de texte spécifiques telles que la reconnaissance de textes imprimés, manuscrits et de scènes.\n\nTrOCR vise à atteindre des performances de pointe sur divers ensembles de données de référence OCR sans recourir à des étapes complexes de pré/post-traitement. Il peut également être facilement étendu à la reconnaissance de texte multilingue en utilisant des modèles multilingues pré-entraînés dans le décodeur et en élargissant le dictionnaire.",
    "answer_Russian": "Модельная архитектура:\nTrOCR построен на архитектуре кодера-декодера Transformer. Кодировщик — это преобразователь изображений, который извлекает визуальные особенности из входного изображения, размер которого изменяется до 384x384 и разбивается на последовательность фрагментов 16x16. Декодер представляет собой стандартный преобразователь текста для генерации последовательности слов, руководствуясь визуальными особенностями и предыдущими предсказаниями.\n\nКодер инициализируется с использованием предварительно обученных моделей, таких как DeiT (Touvron et al., 2021) и BEiT (Bao, Dong и Wei, 2021). [Требуется дополнительная информация] о конкретной предварительно обученной модели, используемой для печати на базе Microsoft/trocr.\n\nДекодер использует предварительно обученные языковые модели. [Требуется дополнительная информация] о конкретной предварительно обученной языковой модели, используемой в декодере microsoft/trocr-base-printed.\n\nЦель:\nTrOCR — это комплексный подход к распознаванию текста, целью которого является распознавание и расшифровка текста с изображений. Он использует предварительно обученные модели Трансформатора изображений и Трансформатора текста для совместного изучения визуального понимания и генерации текста на уровне слов.\n\nМодель может быть предварительно обучена на крупномасштабных синтетических данных и точно настроена на наборах данных, размеченных человеком, для конкретных задач распознавания текста, таких как распознавание печатного, рукописного текста и текста сцены.\n\nЦелью TrOCR является достижение высочайшей производительности на различных наборах эталонных данных OCR, не полагаясь на сложные этапы предварительной и последующей обработки. Его также можно легко расширить до распознавания многоязычного текста, используя многоязычные предварительно обученные модели в декодере и расширяя словарь.",
    "answer_Japanese": "モデルのアーキテクチャ:\nTrOCR は、Transformer エンコーダ/デコーダ アーキテクチャを使用して構築されています。エンコーダは、入力画像から視覚的特徴を抽出する画像トランスフォーマです。入力画像は 384x384 にサイズ変更され、一連の 16x16 パッチに分割されます。デコーダは、視覚的な特徴と以前の予測に基づいて単語列を生成するための標準的なテキスト Transformer です。\n\nエンコーダーは、DeiT (Touvron et al. 2021) や BEiT (Bao, Dong, and Wei 2021) のような事前トレーニングされたモデルを使用して初期化されます。 Microsoft/trocr-base-printed に使用される特定の事前トレーニング済みモデルに関する [詳細情報が必要]。\n\nデコーダは、事前トレーニングされた言語モデルを利用します。 Microsoft/trocr-base-printed のデコーダーで使用される特定の事前トレーニング済み言語モデルに関する [詳細情報が必要]。\n\n客観的：\nTrOCR は、画像からテキストを認識して転写することを目的としたエンドツーエンドのテキスト認識アプローチです。事前にトレーニングされた画像 Transformer モデルとテキスト Transformer モデルを活用して、視覚的な理解と単語レベルのテキスト生成を共同で学習します。\n\nこのモデルは、印刷されたテキスト、手書きのテキスト、シーンのテキスト認識などの特定のテキスト認識タスク向けに、大規模な合成データで事前トレーニングし、人間がラベル付けしたデータセットで微調整することができます。\n\nTrOCR は、複雑な前処理/後処理ステップに依存せずに、さまざまな OCR ベンチマーク データセットで最先端のパフォーマンスを達成することを目指しています。また、デコーダーで多言語の事前トレーニング済みモデルを使用し、辞書を拡張することで、多言語テキスト認識に簡単に拡張することもできます。"
  },
  {
    "question": "compute_infrastructure",
    "chain": "generation",
    "answer": "Based on the provided references, here is the compute infrastructure information I could find about the microsoft/trocr-base-printed model:\n\nWe use 32 V100 GPUs with the memory of 32GBs for pre-training and 8 V100 GPUs for fine-tuning. For all the models, the batch size is set to 2,048 and the learning rate is 5e-5.\n\nThe TrOCR-Base-SROIE model file can be downloaded from:\n[trocr-base-printed.pt](https://layoutlm.blob.core.windows.net/trocr/model_zoo/fairseq/trocr-base-printed.pt)\n\n[More Information Needed] on the exact training time, number of parameters, and other compute infrastructure details for the microsoft/trocr-base-printed model specifically.",
    "answer_Chinese": "根据提供的参考资料，以下是我可以找到的有关 microsoft/trocr-base-printed 模型的计算基础设施信息：\n\n我们使用 32 个内存为 32GB 的 V100 GPU 进行预训练，使用 8 个 V100 GPU 进行微调。对于所有模型，批量大小设置为 2,048，学习率为 5e-5。\n\nTrOCR-Base-SROIE 模型文件可以从以下位置下载：\n[trocr-base-printed.pt](https://layoutlm.blob.core.windows.net/trocr/model_zoo/fairseq/trocr-base-printed.pt)\n\n[需要更多信息] 有关 microsoft/trocr-base-printed 模型的确切训练时间、参数数量以及其他计算基础设施详细信息。",
    "answer_Arabic": "استنادًا إلى المراجع المتوفرة، إليك معلومات البنية التحتية للحوسبة التي يمكنني العثور عليها حول النموذج المطبوع من Microsoft/trocr-base:\n\nنحن نستخدم 32 وحدة معالجة رسوميات V100 مع ذاكرة تبلغ 32 جيجابايت للتدريب المسبق و8 وحدات معالجة رسوميات V100 للضبط الدقيق. بالنسبة لجميع النماذج، تم تعيين حجم الدفعة على 2,048 ومعدل التعلم هو 5e-5.\n\nيمكن تنزيل ملف نموذج TrOCR-Base-SROIE من:\n[trocr-base-printed.pt](https://layoutlm.blob.core.windows.net/trocr/model_zoo/fairseq/trocr-base-printed.pt)\n\n[يلزم مزيد من المعلومات] حول وقت التدريب الدقيق وعدد المعلمات وتفاصيل البنية التحتية الحسابية الأخرى لنموذج microsoft/trocr-base-printed على وجه التحديد.",
    "answer_French": "Sur la base des références fournies, voici les informations sur l'infrastructure de calcul que j'ai pu trouver sur le modèle Microsoft/trocr-base-printed :\n\nNous utilisons 32 GPU V100 avec une mémoire de 32 Go pour le pré-entraînement et 8 GPU V100 pour le réglage fin. Pour tous les modèles, la taille du lot est fixée à 2 048 et le taux d'apprentissage est de 5e-5.\n\nLe fichier modèle TrOCR-Base-SROIE peut être téléchargé à partir de :\n[trocr-base-printed.pt](https://layoutlm.blob.core.windows.net/trocr/model_zoo/fairseq/trocr-base-printed.pt)\n\n[Plus d'informations nécessaires] sur le temps de formation exact, le nombre de paramètres et d'autres détails de l'infrastructure de calcul pour le modèle imprimé Microsoft/trocr-base en particulier.",
    "answer_Russian": "Основываясь на предоставленных ссылках, вот информация о вычислительной инфраструктуре, которую я смог найти о модели, напечатанной на базе microsoft/trocr:\n\nМы используем 32 графических процессора V100 с памятью 32 ГБ для предварительного обучения и 8 графических процессоров V100 для тонкой настройки. Для всех моделей размер пакета установлен на уровне 2048, а скорость обучения — 5e-5.\n\nФайл модели TrOCR-Base-SROIE можно скачать по адресу:\n[trocr-base-printed.pt](https://layoutlm.blob.core.windows.net/trocr/model_zoo/fairseq/trocr-base-printed.pt)\n\n[Требуется дополнительная информация] о точном времени обучения, количестве параметров и других деталях вычислительной инфраструктуры для модели, напечатанной на базе Microsoft/trocr.",
    "answer_Japanese": "提供された参考資料に基づいて、microsoft/trocr-base-printed モデルに関して見つけたコンピューティング インフラストラクチャ情報は次のとおりです。\n\n事前トレーニングには 32 GB のメモリを備えた 32 個の V100 GPU を使用し、微調整には 8 個の V100 GPU を使用します。すべてのモデルで、バッチ サイズは 2,048 に設定され、学習率は 5e-5 です。\n\nTrOCR-Base-SROIE モデル ファイルは次からダウンロードできます。\n[trocr-base-printed.pt](https://layoutlm.blob.core.windows.net/trocr/model_zoo/fairseq/trocr-base-printed.pt)\n\n特に、microsoft/trocr-base-printed モデルの正確なトレーニング時間、パラメーターの数、その他のコンピューティング インフラストラクチャの詳細に関する [詳細情報が必要]。"
  }
]